{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67e4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671fab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "transformers.__version__='4.55.3'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168e682d38f142f3a57768c9dee102b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "print(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "print(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "print(f\"{transformers.__version__=}\")\n",
    "\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdebf9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one of the filter heads\n",
    "if model_key == \"meta-llama/Llama-3.3-70B-Instruct\":\n",
    "    layer_idx, head_idx = 35, 19\n",
    "elif model_key == \"google/gemma-2-27b-it\":\n",
    "    layer_idx, head_idx = 29, 3\n",
    "else:\n",
    "    raise ValueError(\"For other models you need to localize the heads first. Check scripts/locate_selection_heads.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615d222",
   "metadata": {},
   "source": [
    "## Checking the behavior of a filter head on one example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6c8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'prompt_templates', 'odd_one_prompt_templates', 'order_prompt_templates', 'count_prompt_templates', 'yes_no_prompt_templates', 'first_item_in_cat_prompt_templates', 'last_item_in_cat_prompt_templates', 'categories', 'exclude_categories']\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectOneTask\n",
    "from typing import Literal\n",
    "import os\n",
    "# from src.utils import env_utils # you should create the env.yml file as per instructions in readme.md\n",
    "\n",
    "##########################################################\n",
    "prompt_template_idx = 3 # try out different templates\n",
    "option_style: Literal[\"single_line\", \"numbered\"] = \"single_line\"\n",
    "n_distractors = 5 # number of distractors. total options = n_distractors + 1 for SingleOne task\n",
    "##########################################################\n",
    "\n",
    "select_task = SelectOneTask.load(\n",
    "    path=os.path.join(\n",
    "        # env_utils.DEFAULT_DATA_DIR,\n",
    "        \"data_save\", \n",
    "        \"selection\", \n",
    "        \"objects.json\" # you can also load other entity types such as \"profession.json\", ...\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72050c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit >> ['Grape', 'Kiwi', 'Plum', 'Pineapple', 'Orange', 'Raspberry', 'Strawberry', 'Cherry', 'Banana', 'Pear', 'Blueberry', 'Mango', 'Watermelon', 'Apple', 'Peach']\n",
      "Options: Socks, Nightstand, Wardrobe, Slow cooker, Skyscraper, Pineapple.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> Pineapple\n",
      "\" Pine\"\n"
     ]
    }
   ],
   "source": [
    "sample = select_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=option_style,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    category=\"fruit\",\n",
    "    # category=\"actor\",\n",
    "    filter_by_lm_prediction=True, \n",
    ")\n",
    "\n",
    "print(sample.prompt(), \">>\", sample.obj)\n",
    "print(f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640f2f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c231c2ed-7031\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c231c2ed-7031\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" S\", \"ocks\", \",\", \" Night\", \"stand\", \",\", \" Ward\", \"robe\", \",\", \" Slow\", \" cooker\", \",\", \" Sk\", \"ys\", \"craper\", \",\", \" Pine\", \"apple\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" fruit\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.005035400390625, 9.059906005859375e-05, 8.249282836914062e-05, 0.007293701171875, 0.0035400390625, 0.0086669921875, 0.00041961669921875, 0.0034027099609375, 0.0026397705078125, 0.0029296875, 0.0023956298828125, 0.004638671875, 0.0120849609375, 0.0034942626953125, 0.00933837890625, 0.00141143798828125, 0.00160980224609375, 0.0059814453125, 0.0159912109375, 0.80859375, 0.0064697265625, 0.0001163482666015625, 7.05718994140625e-05, 0.0001277923583984375, 0.0002040863037109375, 5.8650970458984375e-05, 4.029273986816406e-05, 9.965896606445312e-05, 0.00148773193359375, 0.017822265625, 0.00135040283203125, 5.173683166503906e-05, 0.00213623046875]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdf0c5189d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "#! the select head is good but not 100% perfect. try out other samples/heads if you see noisy results.\n",
    "attn_pattern = verify_head_patterns(\n",
    "    mt=mt,\n",
    "    prompt=sample.prompt(),\n",
    "    heads=[(layer_idx, head_idx)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc689dc9",
   "metadata": {},
   "source": [
    "## Patching the query state to transfer the predicate\n",
    "\n",
    "See Figure 1 in the paper.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"notebooks/figures/fig_1_sliced-crop-1.png\" style=\"width:100%;\"/>\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b11e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "====================\n",
      "Source: Options: Dog, Wardrobe, Banana, Earring, Tractor, Comb.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Banana\"\n",
      "Destination: Options: Tape, Grape, Apartment, Scooter, Saxophone, Surfboard.\n",
      "Which among these objects mentioned above is a vehicle?\n",
      "Answer: >> \" Sco\"\n",
      "Grape 1  Grape\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import get_counterfactual_samples_within_task\n",
    "\n",
    "source_sample, destination_sample = get_counterfactual_samples_within_task(\n",
    "    mt=mt,\n",
    "    task=select_task,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    option_style=option_style,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    # mcqify=True, # make it a multi-choice question\n",
    ")\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(\n",
    "    \"Source:\",\n",
    "    source_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([source_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"Destination:\",\n",
    "    destination_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([destination_sample.ans_token_id])}\"',\n",
    ")\n",
    "\n",
    "print(\n",
    "    destination_sample.metadata[\"track_type_obj\"],\n",
    "    destination_sample.metadata[\"track_type_obj_idx\"],\n",
    "    mt.tokenizer.decode(destination_sample.metadata[\"track_type_obj_token_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae245e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Options: Cherry, Knife, Pants, Car.\n",
      "Find the fruit\n",
      "Answer:\n",
      "\n",
      "Destination: a. Binder\n",
      "b. Peach\n",
      "c. Watch\n",
      "d. Scooter\n",
      "e. Phone\n",
      "Find the vehicle\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# Setting the options and the prompt template manually to replicate Figure 1 exactly. \n",
    "# For L35 H19 of Llama-3.3-70B-Instruct\n",
    "#! You should comment this out to check for a random sample pair\n",
    "\n",
    "from src.selection.data import MCQify_sample\n",
    "from src.selection.utils import get_first_token_id\n",
    "\n",
    "source_sample.options = [\"Cherry\", \"Knife\", \"Pants\", \"Car\"]\n",
    "source_sample.prompt_template = \"<_options_>\\nFind the <_category_>\\nAnswer:\"\n",
    "print(\"Source:\", source_sample.prompt())\n",
    "\n",
    "destination_sample.options = [\"Binder\", \"Peach\", \"Watch\", \"Scooter\", \"Phone\"]\n",
    "destination_sample.prompt_template = \"<_options_>\\nFind the <_category_>\\nAnswer:\"\n",
    "destination_sample.object = \"Scooter\"\n",
    "destination_sample.obj_idx = 3\n",
    "destination_sample.metadata[\"track_type_obj_token_id\"] = get_first_token_id(\n",
    "    name=\"b\", tokenizer=mt.tokenizer, prefix=\" \"\n",
    ")\n",
    "destination_sample = MCQify_sample(sample=destination_sample, tokenizer=mt)\n",
    "print(\"\\nDestination:\", destination_sample.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c59af2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-f394aec6-4be7\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-f394aec6-4be7\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Cherry\", \",\", \" Knife\", \",\", \" Pants\", \",\", \" Car\", \".\\n\", \"Find\", \" the\", \" fruit\", \"\\n\", \"Answer\", \":\"], \"values\": [0.007568359375, 0.00021839141845703125, 0.61328125, 0.026611328125, 0.0181884765625, 0.0673828125, 0.007537841796875, 0.01483154296875, 0.0027008056640625, 0.006256103515625, 0.00010967254638671875, 0.001007080078125, 0.045654296875, 0.006195068359375, 5.364418029785156e-05, 0.0024261474609375]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdc0e099690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source predictions: ['\" Cherry\"[45805] (p=0.945, logit=22.250)', '\" The\"[578] (p=0.032, logit=18.875)', '\" CH\"[6969] (p=0.007, logit=17.375)', '\" \"\"[330] (p=0.003, logit=16.500)', '\" cherry\"[41980] (p=0.001, logit=15.500)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cec6fe7d-c2db\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cec6fe7d-c2db\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"a\", \".\", \" Binder\", \"\\n\", \"b\", \".\", \" Peach\", \"\\n\", \"c\", \".\", \" Watch\", \"\\n\", \"d\", \".\", \" Sco\", \"oter\", \"\\n\", \"e\", \".\", \" Phone\", \"\\n\", \"Find\", \" the\", \" vehicle\", \"\\n\", \"Answer\", \":\"], \"values\": [0.006500244140625, 0.0003108978271484375, 0.000835418701171875, 0.016357421875, 0.006805419921875, 0.005645751953125, 0.00811767578125, 0.064453125, 0.002044677734375, 0.016845703125, 0.0028533935546875, 0.037841796875, 0.0038909912109375, 0.00738525390625, 0.022705078125, 0.482421875, 0.25, 0.0042724609375, 0.0014495849609375, 0.003021240234375, 0.0020751953125, 0.00084686279296875, 0.00098419189453125, 0.006439208984375, 0.00180816650390625, 3.504753112792969e-05, 0.0009307861328125]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdc0db11a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination predictions: ['\" d\"[294] (p=0.789, logit=21.500)', '\" Option\"[7104] (p=0.044, logit=18.625)', '\" (\"[320] (p=0.039, logit=18.500)', '\" Sco\"[50159] (p=0.035, logit=18.375)', '\" The\"[578] (p=0.031, logit=18.250)']\n",
      "OrderedDict([(293, (6, PredictedToken(token=' b', prob=0.00775146484375, logit=16.875, token_id=293, metadata=None)))])\n",
      "clean_score=16.875\n"
     ]
    }
   ],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import interpret_logits\n",
    "\n",
    "source_tokenized = prepare_input(\n",
    "    prompts=source_sample.prompt(), \n",
    "    tokenizer=mt,\n",
    ")\n",
    "\n",
    "source_attn = verify_head_patterns(\n",
    "    mt=mt,\n",
    "    prompt=source_sample.prompt(),\n",
    "    heads=[(layer_idx, head_idx)],\n",
    ")\n",
    "\n",
    "source_predictions = interpret_logits(\n",
    "    tokenizer=mt.tokenizer,\n",
    "    logits=source_attn[\"logits\"].squeeze(),\n",
    "    k=5\n",
    ")\n",
    "print(\"Source predictions:\", [str(pred) for pred in source_predictions])\n",
    "\n",
    "\n",
    "destination_attn = verify_head_patterns(\n",
    "    mt=mt,\n",
    "    prompt=destination_sample.prompt(),\n",
    "    heads=[(layer_idx, head_idx)],\n",
    ")\n",
    "destination_tokenized = prepare_input(\n",
    "    prompts=destination_sample.prompt(), \n",
    "    tokenizer=mt,\n",
    ")\n",
    "\n",
    "\n",
    "destination_predictions, dest_track = interpret_logits(\n",
    "    tokenizer=mt.tokenizer,\n",
    "    logits=destination_attn[\"logits\"].squeeze(),\n",
    "    k=5,\n",
    "    interested_tokens=[destination_sample.metadata[\"track_type_obj_token_id\"]],\n",
    ")\n",
    "print(\"Destination predictions:\", [str(pred) for pred in destination_predictions])\n",
    "print(dest_track)\n",
    "\n",
    "clean_score = dest_track[destination_sample.metadata[\"track_type_obj_token_id\"]][1].logit\n",
    "print(f\"{clean_score=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04079080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_attn[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc25b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-1c33764b-dfd5\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-1c33764b-dfd5\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"a\", \".\", \" Binder\", \"\\n\", \"b\", \".\", \" Peach\", \"\\n\", \"c\", \".\", \" Watch\", \"\\n\", \"d\", \".\", \" Sco\", \"oter\", \"\\n\", \"e\", \".\", \" Phone\", \"\\n\", \"Find\", \" the\", \" vehicle\", \"\\n\", \"Answer\", \":\"], \"values\": [0.00396728515625, 7.343292236328125e-05, 0.0029144287109375, 0.004547119140625, 0.001617431640625, 0.000644683837890625, 0.5078125, 0.361328125, 0.000762939453125, 0.004364013671875, 0.0020751953125, 0.003265380859375, 0.00074005126953125, 0.004119873046875, 0.0024871826171875, 0.000568389892578125, 0.00021266937255859375, 0.0004634857177734375, 0.00439453125, 0.0045166015625, 0.00013065338134765625, 9.107589721679688e-05, 0.0004558563232421875, 3.933906555175781e-05, 0.00011205673217773438, 1.3589859008789062e-05, 3.5762786865234375e-05]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdc0e27be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched predictions: ['\" d\"[294] (p=0.750, logit=21.000)', '\" (\"[320] (p=0.054, logit=18.375)', '\" Option\"[7104] (p=0.042, logit=18.125)', '\" Sco\"[50159] (p=0.029, logit=17.750)', '\" The\"[578] (p=0.029, logit=17.750)']\n",
      "OrderedDict([(293, (6, PredictedToken(token=' b', prob=0.02001953125, logit=17.375, token_id=293, metadata=None)))])\n",
      "patched_score=17.375\n",
      "Δ score after patching query state of a single head: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# checking the effect of transferring the q_state\n",
    "\n",
    "from src.selection.functional import cache_q_projections\n",
    "from src.functional import PatchSpec\n",
    "\n",
    "map_indices = {-3: -3, -2: -2, -1: -1} # source_token_idx -> destination_token_idx\n",
    "q_states = cache_q_projections(\n",
    "    mt=mt,\n",
    "    input=source_tokenized,\n",
    "    heads=[(layer_idx, head_idx)],\n",
    "    token_indices=[map_indices.keys()],\n",
    ")[0]\n",
    "\n",
    "q_patches = []\n",
    "for (l_idx, h_idx, source_token_idx), q_proj in q_states.items():\n",
    "    q_patches.append(PatchSpec(\n",
    "        location=(\n",
    "            mt.attn_module_name_format.format(l_idx)+\".q_proj\",\n",
    "            h_idx,\n",
    "            map_indices[source_token_idx]\n",
    "        ),\n",
    "        patch=q_proj.squeeze()\n",
    "    ))\n",
    "\n",
    "patched_run = verify_head_patterns(\n",
    "    prompt = destination_sample.prompt(),\n",
    "    mt = mt,\n",
    "    heads = [(layer_idx, head_idx)],\n",
    "    query_patches = q_patches\n",
    ")\n",
    "\n",
    "patched_predictions, patched_track = interpret_logits(\n",
    "    tokenizer=mt.tokenizer,\n",
    "    logits=patched_run[\"logits\"].squeeze(),\n",
    "    k=5,\n",
    "    interested_tokens=[destination_sample.metadata[\"track_type_obj_token_id\"]],\n",
    ")\n",
    "print(\"Patched predictions:\", [str(pred) for pred in patched_predictions])\n",
    "print(patched_track)\n",
    "patched_score = patched_track[destination_sample.metadata[\"track_type_obj_token_id\"]][1].logit\n",
    "print(f\"{patched_score=}\")\n",
    "\n",
    "improvement = patched_score - clean_score\n",
    "print(f\"Δ score after patching query state of a single head: {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d72204",
   "metadata": {},
   "source": [
    "## Patching all the identified filter heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f95761",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_heads = {\n",
    "    \"Llama-3.3-70B-Instruct\": [\n",
    "        (28, 40),\n",
    "        (28, 45),\n",
    "        (29, 56),\n",
    "        (29, 57),\n",
    "        (29, 60),\n",
    "        (29, 61),\n",
    "        (29, 62),\n",
    "        (30, 62),\n",
    "        (31, 0),\n",
    "        (31, 32),\n",
    "        (31, 33),\n",
    "        (31, 36),\n",
    "        (31, 37),\n",
    "        (31, 38),\n",
    "        (31, 39),\n",
    "        (31, 40),\n",
    "        (31, 43),\n",
    "        (32, 12),\n",
    "        (32, 19),\n",
    "        (32, 48),\n",
    "        (33, 18),\n",
    "        (33, 21),\n",
    "        (33, 23),\n",
    "        (33, 30),\n",
    "        (33, 43),\n",
    "        (33, 46),\n",
    "        (34, 1),\n",
    "        (34, 6),\n",
    "        (34, 33),\n",
    "        (34, 45),\n",
    "        (35, 5),\n",
    "        (35, 17),\n",
    "        (35, 18),\n",
    "        (35, 19),\n",
    "        (35, 20),\n",
    "        (35, 22),\n",
    "        (35, 23),\n",
    "        (35, 27),\n",
    "        (35, 28),\n",
    "        (35, 36),\n",
    "        (35, 40),\n",
    "        (35, 42),\n",
    "        (36, 17),\n",
    "        (36, 22),\n",
    "        (36, 40),\n",
    "        (36, 44),\n",
    "        (36, 47),\n",
    "        (36, 52),\n",
    "        (36, 54),\n",
    "        (37, 0),\n",
    "        (37, 3),\n",
    "        (37, 4),\n",
    "        (37, 7),\n",
    "        (37, 16),\n",
    "        (37, 28),\n",
    "        (37, 30),\n",
    "        (37, 36),\n",
    "        (37, 39),\n",
    "        (38, 19),\n",
    "        (38, 23),\n",
    "        (38, 49),\n",
    "        (38, 50),\n",
    "        (38, 51),\n",
    "        (39, 35),\n",
    "        (39, 36),\n",
    "        (39, 41),\n",
    "        (39, 44),\n",
    "        (39, 45),\n",
    "        (42, 28),\n",
    "        (42, 30),\n",
    "        (42, 31),\n",
    "        (45, 1),\n",
    "        (47, 17),\n",
    "        (47, 18),\n",
    "        (49, 1),\n",
    "        (49, 4),\n",
    "        (49, 5),\n",
    "        (49, 7),\n",
    "        (50, 34),\n",
    "    ],\n",
    "    \"google/gemma-2-27b-it\": [\n",
    "        (20, 3),\n",
    "        (21, 13),\n",
    "        (21, 29),\n",
    "        (22, 5),\n",
    "        (22, 6),\n",
    "        (22, 7),\n",
    "        (22, 22),\n",
    "        (22, 30),\n",
    "        (23, 2),\n",
    "        (23, 6),\n",
    "        (23, 13),\n",
    "        (23, 19),\n",
    "        (23, 20),\n",
    "        (23, 22),\n",
    "        (23, 24),\n",
    "        (23, 31),\n",
    "        (24, 4),\n",
    "        (24, 5),\n",
    "        (24, 6),\n",
    "        (24, 7),\n",
    "        (24, 9),\n",
    "        (24, 12),\n",
    "        (24, 14),\n",
    "        (25, 8),\n",
    "        (25, 15),\n",
    "        (26, 2),\n",
    "        (26, 4),\n",
    "        (26, 5),\n",
    "        (26, 16),\n",
    "        (26, 18),\n",
    "        (26, 23),\n",
    "        (26, 25),\n",
    "        (26, 30),\n",
    "        (27, 5),\n",
    "        (28, 3),\n",
    "        (28, 12),\n",
    "        (28, 13),\n",
    "        (28, 16),\n",
    "        (28, 17),\n",
    "        (28, 20),\n",
    "        (28, 21),\n",
    "        (28, 27),\n",
    "        (28, 31),\n",
    "        (29, 2),\n",
    "        (29, 10),\n",
    "        (29, 16),\n",
    "        (29, 22),\n",
    "        (29, 23),\n",
    "        (29, 24),\n",
    "        (29, 26),\n",
    "        (29, 27),\n",
    "        (29, 29),\n",
    "        (30, 6),\n",
    "        (30, 8),\n",
    "        (30, 11),\n",
    "        (30, 14),\n",
    "        (30, 15),\n",
    "        (30, 20),\n",
    "        (30, 21),\n",
    "        (31, 2),\n",
    "        (31, 3),\n",
    "        (31, 24),\n",
    "        (31, 31),\n",
    "        (33, 12),\n",
    "        (33, 16),\n",
    "        (33, 17),\n",
    "        (34, 14),\n",
    "        (34, 19),\n",
    "        (35, 9),\n",
    "        (35, 25),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8305b32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-1ca731d9-0525\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-1ca731d9-0525\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Cherry\", \",\", \" Knife\", \",\", \" Pants\", \",\", \" Car\", \".\\n\", \"Find\", \" the\", \" fruit\", \"\\n\", \"Answer\", \":\"], \"values\": [0.0308451596647501, 0.01019351091235876, 0.07547812908887863, 0.025500357151031494, 0.01298520527780056, 0.05041281878948212, 0.020760802552103996, 0.019763318821787834, 0.015691600739955902, 0.03226557746529579, 0.01033096108585596, 0.013226859271526337, 0.08529199659824371, 0.06299793720245361, 0.028896721079945564, 0.053363848477602005]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fbb50174810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-48d4a808-026b\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-48d4a808-026b\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"a\", \".\", \" Binder\", \"\\n\", \"b\", \".\", \" Peach\", \"\\n\", \"c\", \".\", \" Watch\", \"\\n\", \"d\", \".\", \" Sco\", \"oter\", \"\\n\", \"e\", \".\", \" Phone\", \"\\n\", \"Find\", \" the\", \" vehicle\", \"\\n\", \"Answer\", \":\"], \"values\": [0.02325284853577614, 0.00735852075740695, 0.003833064576610923, 0.009507432579994202, 0.013830987736582756, 0.0033350354060530663, 0.0071910060942173, 0.01806756481528282, 0.01208502147346735, 0.006679746322333813, 0.00864339154213667, 0.021960657089948654, 0.027743158861994743, 0.005129367578774691, 0.014963680878281593, 0.09297633916139603, 0.08287965506315231, 0.024103479459881783, 0.006874483544379473, 0.014689236879348755, 0.012811684980988503, 0.007993299514055252, 0.009216489270329475, 0.07784384489059448, 0.04788089543581009, 0.015968266874551773, 0.05132902041077614]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdc0e258dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heads = filter_heads[model_key.split(\"/\")[-1]]\n",
    "\n",
    "source_attn = verify_head_patterns(\n",
    "    mt=mt,\n",
    "    prompt=source_sample.prompt(),\n",
    "    heads=heads,\n",
    ")\n",
    "\n",
    "destination_attn = verify_head_patterns(\n",
    "    mt=mt,\n",
    "    prompt=destination_sample.prompt(),\n",
    "    heads=heads,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170143df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-ab693228-31d2\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-ab693228-31d2\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"a\", \".\", \" Binder\", \"\\n\", \"b\", \".\", \" Peach\", \"\\n\", \"c\", \".\", \" Watch\", \"\\n\", \"d\", \".\", \" Sco\", \"oter\", \"\\n\", \"e\", \".\", \" Phone\", \"\\n\", \"Find\", \" the\", \" vehicle\", \"\\n\", \"Answer\", \":\"], \"values\": [0.030576102435588837, 0.007595098577439785, 0.00872802734375, 0.019491123035550117, 0.020414015278220177, 0.004653948824852705, 0.04311952739953995, 0.08010932058095932, 0.017033541575074196, 0.008939526043832302, 0.008287924341857433, 0.017978958785533905, 0.015200313180685043, 0.008210749365389347, 0.005270342342555523, 0.008787467144429684, 0.01016598753631115, 0.019587818533182144, 0.011041738092899323, 0.013154095970094204, 0.008340098895132542, 0.013628675602376461, 0.015528691001236439, 0.03726443275809288, 0.04650360345840454, 0.031831320375204086, 0.03361968323588371]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdc0db3f7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched predictions: ['\" b\"[293] (p=0.758, logit=21.750)', '\" Peach\"[64695] (p=0.169, logit=20.250)', '\" (\"[320] (p=0.014, logit=17.750)', '\" Option\"[7104] (p=0.014, logit=17.750)', '\" The\"[578] (p=0.012, logit=17.625)']\n",
      "OrderedDict([(293, (1, PredictedToken(token=' b', prob=0.7578125, logit=21.75, token_id=293, metadata=None)))])\n",
      "patched_score=21.75\n",
      "Δ score after patching query state for 79 filter heads: 4.8750\n"
     ]
    }
   ],
   "source": [
    "from src.selection.functional import cache_q_projections\n",
    "from src.functional import PatchSpec\n",
    "\n",
    "#! checkout validate_q_proj_ie_on_sample_pair in src/selection/optimization.py\n",
    "\n",
    "map_indices = {-3: -3, -2: -2, -1: -1} # source_token_idx -> destination_token_idx\n",
    "q_states = cache_q_projections(\n",
    "    mt=mt,\n",
    "    input=source_tokenized,\n",
    "    heads=heads,\n",
    "    token_indices=[list(map_indices.keys())],\n",
    ")[0]\n",
    "\n",
    "q_patches = []\n",
    "for (l_idx, h_idx, patch_token_idx), q_proj in q_states.items():\n",
    "    q_patches.append(PatchSpec(\n",
    "        location=(\n",
    "            mt.attn_module_name_format.format(l_idx)+\".q_proj\",\n",
    "            h_idx,\n",
    "            map_indices[patch_token_idx]\n",
    "        ),\n",
    "        patch=q_proj.squeeze()\n",
    "    ))\n",
    "\n",
    "patched_run = verify_head_patterns(\n",
    "    prompt = destination_sample.prompt(),\n",
    "    mt = mt,\n",
    "    heads = heads,\n",
    "    query_patches = q_patches\n",
    ")\n",
    "\n",
    "patched_predictions, patched_track = interpret_logits(\n",
    "    tokenizer=mt.tokenizer,\n",
    "    logits=patched_run[\"logits\"].squeeze(),\n",
    "    k=5,\n",
    "    interested_tokens=[destination_sample.metadata[\"track_type_obj_token_id\"]],\n",
    ")\n",
    "print(\"Patched predictions:\", [str(pred) for pred in patched_predictions])\n",
    "print(patched_track)\n",
    "patched_score = patched_track[destination_sample.metadata[\"track_type_obj_token_id\"]][1].logit\n",
    "print(f\"{patched_score=}\")\n",
    "\n",
    "improvement = patched_score - clean_score\n",
    "print(f\"Δ score after patching query state for {len(heads)} filter heads: {improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac27395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f019d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
