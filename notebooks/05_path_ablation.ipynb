{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:07:10 __main__ INFO     torch.__version__='2.5.0+cu124', torch.version.cuda='12.4'\n",
      "2025-02-20 12:07:10 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2025-02-20 12:07:10 __main__ INFO     transformers.__version__='4.48.1'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama-3.1-8B',\n",
       " 'Llama-3.1-8B-Instruct',\n",
       " 'Llama-2-7b-chat-hf',\n",
       " 'Llama-3.2-3B-Instruct',\n",
       " 'Llama-3.2-3B',\n",
       " 'Llama-3.2-1B']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(env_utils.DEFAULT_MODELS_DIR, \"meta-llama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:07:11 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:07:16 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/meta-llama/Llama-3.1-8B> | size: 15316.508 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.probing.utils import (\n",
    "    prepare_probing_input,\n",
    "    get_lm_generated_answer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Given two entities, find a common link or relation between them.\n",
      "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
      "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
      "If there is no connection just answer \"None\".\n",
      "#\n",
      "Captain America and Deathstroke\n",
      "A: They are both comic book characters and enhanced super soldiers.\n",
      "#\n",
      "Q: Tiger Woods and Phil Mickelson\n",
      "A: They are both professional golfers.\n",
      "#\n",
      "Q: Rome and Italy\n",
      "A: Rome is the capital city of Italy.\n",
      "#\n",
      "Q: Michael Jordan and Slovakia\n",
      "A: None\n",
      "#\n",
      "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
      "A: Richard Meier was the architect of both of these buildings.\n",
      "#\n",
      "Q: Leonardo da Vinci and Benjamin Franklin\n",
      "A: They are/were both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='polymaths.'\n"
     ]
    }
   ],
   "source": [
    "Instructions = \"\"\"Given two entities, find a common link or relation between them.\n",
    "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
    "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
    "If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "# Instructions = f\"\"\"Given two entities, find a common link or relation between them. If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "block_separator = \"\\n#\"\n",
    "question_marker = \"\\nQ: \"\n",
    "answer_marker = \"\\nA:\"\n",
    "\n",
    "examples = \"\"\"#\n",
    "Captain America and Deathstroke\n",
    "A: They are both comic book characters and enhanced super soldiers.\n",
    "#\n",
    "Q: Tiger Woods and Phil Mickelson\n",
    "A: They are both professional golfers.\n",
    "#\n",
    "Q: Rome and Italy\n",
    "A: Rome is the capital city of Italy.\n",
    "#\n",
    "Q: Michael Jordan and Slovakia\n",
    "A: None\n",
    "#\n",
    "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
    "A: Richard Meier was the architect of both of these buildings.\n",
    "\"\"\"\n",
    "\n",
    "# entities = ('Bryce Harper', 'Yadier Molina')\n",
    "# entities = (\"Michael Caine\", \"Morgan Freeman\")\n",
    "# entities = (\"Michael Caine\", \"Stephen Hawking\")   #!\n",
    "# entities = (\"Stephen Hawking\", \"Albert Einstein\")\n",
    "# entities = (\"Charles Darwin\", \"Abraham Lincoln\")\n",
    "# entities = (\"Empire State Building\", \"Big Ben\")\n",
    "# entities = (\"Alexander Fleming\", \"Louis Pasteur\")\n",
    "# entities = (\"Alexander Fleming\", \"Andy Murray\")     #!\n",
    "# entities = (\"Alexander Fleming\", \"Sean Connery\")    #!\n",
    "# entities = (\"Ian McKellen\", \"Michael Fassbender\")    #!\n",
    "# entities = (\"Richard Harris\", \"Michael Gambon\")\n",
    "# entities = (\"Ian McKellen\", \"Issac Newton\")  #!\n",
    "# entities = (\"Issac Newton\", \"Ian McKellen\")\n",
    "\n",
    "# entities = (\"Natalie Portman\", \"Bob Dylan\")\n",
    "# entities = (\"Audrey Hepburn\", \"Julia Child\")\n",
    "# entities = (\"Ben Kingsley\", \"Mark Strong\")\n",
    "# entities = (\"Julia Roberts\", \"\")\n",
    "\n",
    "# special case: Brian Cox the Actor (Scottish) and Brian Cox the Physicist (British)\n",
    "# entities = (\"Carl Sagan\", \"Brian Cox\")\n",
    "# entities = (\"Morgan Freeman\", \"Brian Cox\")\n",
    "# entities = (\"Alexander Fleming\", \"Brian Cox\")\n",
    "# entities = (\"Andy Murray\", \"Brian Cox\")\n",
    "# if the entity appears later => do some context specific recalling\n",
    "# if the entity appears earlier => (?) Hybrid representation of both entities?\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# entities = (\"Michael Jordan\", \"Kobe Bryant\")\n",
    "\n",
    "# entities = (\"Hugh Jackman\", \"Ricky Ponting\")\n",
    "\n",
    "# entities = (\"Peter Sellers\", \"Elvis Presley\")\n",
    "# entities = (\"David Tennant\", \"Elvis Presley\")\n",
    "# entities = (\"Hugh Laurie\", \"Hoel McHale\")\n",
    "# entities = (\"Sachin Tendulkar\", \"Sachin Dev Burman\")\n",
    "\n",
    "# entities = (\"Daredevil\", \"Toph Beifong\")\n",
    "# entities = (\"Superman\", \"Starfire\")\n",
    "# entities = (\"Natalie Portman\", \"Natalie Portman\")\n",
    "# entities = (\"Burj Khalifa\", \"Shanghai Tower\")\n",
    "# entities = (\"Japan\", \"Korea\")\n",
    "# entities = (\"Japan\", \"Germany\")\n",
    "# entities = (\"Danke\", \"Merci\")\n",
    "# entities = (\"Charlie Chaplin\", \"Rowan Atkinson\")\n",
    "# entities = (\"Daniel Craig\", \"Pierce Brosnan\")\n",
    "# entities = (\"Rafael Nadal\", \"Javier Bardem\")\n",
    "# entities = (\"Henry Cavill\", \"Christopher Reeve\")\n",
    "# entities = (\"Batman\", \"Ironman\")\n",
    "# entities = (\"Bruce Wayne\", \"Tony Stark\")\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# entities = (\"Germany\", \"Japan\")\n",
    "# entities = (\"Bhutan\", \"Tuvalu\")\n",
    "# entities = (\"Vatican City\", \"Mount Athos\")\n",
    "# entities = (\"Abraham Lincoln\", \"John Lennon\")\n",
    "# entities = (\"Daredevil\", \"Toph Beifong\")\n",
    "# entities = (\"Madagascar\", \"Amazon\")\n",
    "# entities = (\"Gabriel García Márquez\", \"Rabindranath Tagore\")\n",
    "# entities = (\"Macondo\", \"Shangri-La\")\n",
    "# entities = (\"Memento\", \"Inception\") #! Verify with causal tracing\n",
    "# entities = (\"Rosetta Stone\", \"Dead Sea Scrolls\") #! Verify with causal tracing\n",
    "\n",
    "# Actors who played the same character\n",
    "#! most of the times the LM is very happy to say \"actors\" --- not very interesting\n",
    "# entities = (\"Ian McKellen\", \"Michael Fassbender\")\n",
    "\n",
    "# entities = (\"Batman\", \"Joker\")\n",
    "# entities = (\"Superman\", \"Lex Luthor\")\n",
    "entities = (\"Leonardo da Vinci\", \"Benjamin Franklin\")\n",
    "# entities = (\"Mark Twain\", \"Winston Churchill\")\n",
    "# entities = (\"Julius Caesar\", \"Nepoleon Bonaparte\")\n",
    "# entities = (\"Julius Caesar\", \"Julius Caesar\")\n",
    "# entities = (\"Beethoven\", \"Goya\")\n",
    "# entities = (\"The Godfather\", \"Goodfellas\")\n",
    "# entities = (\"The Green Mile\", \"The Shawshank Redemption\")\n",
    "# entities = (\"Christopher Columbus\", \"Vasco da Gama\")\n",
    "\n",
    "prefix = f\"\"\"{Instructions}\n",
    "{examples}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prepare_probing_input(\n",
    "    mt=mt,\n",
    "    entities=entities,\n",
    "    prefix=prefix,\n",
    "    answer_marker=answer_marker,\n",
    "    question_marker=question_marker,\n",
    "    block_separator=block_separator,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    # is_a_reasoning_model=True\n",
    "    answer_prefix=\" They are/were both\",\n",
    "    # answer_prefix = \" They are both used to say\"\n",
    ")\n",
    "\n",
    "print(mt.tokenizer.decode(prompt.tokenized[\"input_ids\"][0]))\n",
    "\n",
    "answer = get_lm_generated_answer(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    # is_a_reasoning_model=True\n",
    ")\n",
    "print(f\"{answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_answer='programming languages.'\n",
      "patched_answer='venomous snakes.'\n"
     ]
    }
   ],
   "source": [
    "# common_entity = \"Alexander Fleming\"\n",
    "# clean_entity = \"Louis Pasteur\"\n",
    "# patch_entity = \"Andy Murray\"\n",
    "\n",
    "# common_entity = \"Michael Caine\"\n",
    "# clean_entity = \"Morgan Freeman\"\n",
    "# patch_entity = \"Stephen Hawking\"\n",
    "\n",
    "# common_entity = \"Ian McKellen\"\n",
    "# clean_entity = \"Michael Fassbender\"\n",
    "# patch_entity = \"Issac Newton\"\n",
    "\n",
    "# common_entity = \"Brian Cox\"\n",
    "# clean_entity = \"Andy Murray\"\n",
    "# patch_entity = \"Carl Sagan\"\n",
    "\n",
    "# common_entity = \"Natalie Portman\"\n",
    "# clean_entity = \"Julia Roberts\"\n",
    "# patch_entity = \"Bob Dylan\"\n",
    "\n",
    "# common_entity = \"Bob Dylan\"\n",
    "# clean_entity = \"Miles Davis\"\n",
    "# patch_entity = \"Natalie Portman\"\n",
    "\n",
    "common_entity = \"python\"\n",
    "clean_entity = \"java\"\n",
    "patch_entity = \"cobra\"\n",
    "\n",
    "# common_entity = \"Vasco da Gama\"\n",
    "# clean_entity = \"placeholder\"\n",
    "# patch_entity = \"Christopher Columbus\"\n",
    "\n",
    "clean_prompt = prepare_probing_input(\n",
    "    mt=mt,\n",
    "    entities=(clean_entity, common_entity),\n",
    "    # entities=(common_entity, clean_entity),\n",
    "    prefix=prefix,\n",
    "    answer_marker=answer_marker,\n",
    "    question_marker=question_marker,\n",
    "    block_separator=block_separator,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    answer_prefix=\" They are/were both\",\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "clean_answer = get_lm_generated_answer(\n",
    "    mt=mt, prompt=clean_prompt, is_a_reasoning_model=\"deepseek\" in model_key.lower()\n",
    ")\n",
    "print(f\"{clean_answer=}\")\n",
    "\n",
    "patched_prompt = prepare_probing_input(\n",
    "    mt=mt,\n",
    "    entities=(patch_entity, common_entity),\n",
    "    # entities=(common_entity, patch_entity),\n",
    "    prefix=prefix,\n",
    "    answer_marker=answer_marker,\n",
    "    question_marker=question_marker,\n",
    "    block_separator=block_separator,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    answer_prefix=\" They are/were both\",\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "patched_answer = get_lm_generated_answer(\n",
    "    mt=mt,\n",
    "    prompt=patched_prompt,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    # is_a_reasoning_model=True\n",
    ")\n",
    "print(f\"{patched_answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.typing import TokenizerOutput, PredictedToken\n",
    "from src.tokens import align_patching_positions\n",
    "from src.functional import PatchSpec, get_hs, logit_lens, predict_next_token\n",
    "from typing import Optional, Literal\n",
    "\n",
    "\n",
    "def do_path_ablation(\n",
    "    mt: ModelandTokenizer,\n",
    "    input: TokenizerOutput,\n",
    "    restore_states: list[PatchSpec],\n",
    "    block_locations: list[tuple[str, int]],\n",
    "    ans_token: int,\n",
    ") -> PredictedToken:\n",
    "    corrupted_states = get_hs(\n",
    "        mt=mt, input=input, locations=block_locations, return_dict=True\n",
    "    )\n",
    "    # restore the clean states from `restore_states`\n",
    "    # patch the corrupted states back to block those locations\n",
    "    patch_spec = restore_states + [\n",
    "        PatchSpec(location=loc, patch=corrupted_states[loc]) for loc in block_locations\n",
    "    ]\n",
    "    last_h = get_hs(\n",
    "        mt=mt,\n",
    "        input=input,\n",
    "        locations=(mt.layer_name_format.format(mt.n_layer - 1), -1),\n",
    "        patches=patch_spec,\n",
    "        return_dict=False,\n",
    "    )\n",
    "\n",
    "    ablated_pred, track_ans = logit_lens(mt=mt, h=last_h, interested_tokens=[ans_token])\n",
    "    rank, track_ans = list(track_ans.values())[0]\n",
    "\n",
    "    return track_ans\n",
    "\n",
    "\n",
    "# TODO: decouple the alignment and token_idx selection? (maybe later)\n",
    "def trace_path_ablation_effects(\n",
    "    mt: ModelandTokenizer,\n",
    "    prompt_template: str,\n",
    "    clean_subj: str,\n",
    "    patched_subj: str,\n",
    "    clean_input: Optional[TokenizerOutput] = None,\n",
    "    patched_input: Optional[TokenizerOutput] = None,\n",
    "    at_token: Literal[\"last\", \"subj_last\", \"subj_2nd_last\"] | None = \"last\",\n",
    "    token_idx: Optional[int] = None,\n",
    "):\n",
    "    aligned = align_patching_positions(\n",
    "        mt=mt,\n",
    "        prompt_template=prompt_template,\n",
    "        clean_subj=clean_subj,\n",
    "        patched_subj=patched_subj,\n",
    "        clean_input=clean_input,\n",
    "        patched_input=patched_input,\n",
    "        trace_start_marker=None,\n",
    "    )\n",
    "    clean_inputs = aligned[\"clean_input\"]\n",
    "    patch_inputs = aligned[\"patched_input\"]\n",
    "    subj_range = aligned[\"subj_range\"]\n",
    "\n",
    "    patch_ans = predict_next_token(mt=mt, inputs=patch_inputs, k=1)[0][0]\n",
    "    logger.debug(f\"{patch_ans=}\")\n",
    "\n",
    "    clean_ans, corrupt_rank = predict_next_token(\n",
    "        mt=mt,\n",
    "        inputs=clean_inputs,\n",
    "        token_of_interest=[patch_ans.token_id],\n",
    "    )\n",
    "    clean_ans = clean_ans[0][0]\n",
    "    corrupt_rank, base_ans = list(corrupt_rank[0].values())[0]\n",
    "    logger.debug(f\"{clean_ans=}\")\n",
    "    logger.debug(f\"{corrupt_rank=} | {base_ans=}\")\n",
    "\n",
    "    assert clean_inputs[\"input_ids\"].shape[1] == patch_inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    if token_idx is None:\n",
    "        if at_token == \"last\":\n",
    "            token_idx = clean_inputs[\"input_ids\"].shape[1] - 1\n",
    "        elif at_token == \"subj_last\":\n",
    "            token_idx = subj_range[1] - 1\n",
    "        elif at_token == \"subj_2nd_last\":\n",
    "            token_idx = subj_range[1] - 2\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid {at_token=}\")\n",
    "    else:\n",
    "        if at_token is not None:\n",
    "            logger.warning(f\"Ignoring {at_token=} since {token_idx=} is provided\")\n",
    "\n",
    "    mlp_ablation_locations = [\n",
    "        (mt.mlp_module_name_format.format(i), token_idx) for i in range(mt.n_layer)\n",
    "    ]\n",
    "    attn_ablation_locations = [\n",
    "        (mt.attn_module_name_format.format(i), token_idx) for i in range(mt.n_layer)\n",
    "    ]\n",
    "    residual_locations = [\n",
    "        (mt.layer_name_format.format(i), token_idx) for i in range(mt.n_layer)\n",
    "    ]\n",
    "\n",
    "    path_blocking_effects = {}\n",
    "\n",
    "    restore_states = get_hs(\n",
    "        mt=mt, input=patch_inputs, locations=residual_locations, return_dict=True\n",
    "    )\n",
    "    logger.debug(\"=\" * 50)\n",
    "    for i in tqdm(range(mt.n_layer)):\n",
    "        restore_location = (mt.layer_name_format.format(i), token_idx)\n",
    "        # logger.debug(restore_location)\n",
    "        cur_restore = [\n",
    "            PatchSpec(location=restore_location, patch=restore_states[restore_location])\n",
    "        ]\n",
    "        h_restore_pred = do_path_ablation(\n",
    "            mt=mt,\n",
    "            input=clean_inputs,\n",
    "            restore_states=cur_restore,\n",
    "            block_locations=[],  # don't block anything\n",
    "            ans_token=patch_ans.token_id,\n",
    "        )\n",
    "        # logger.debug(f\"{h_restore_pred=}\")\n",
    "\n",
    "        mlp_ablation_pred = do_path_ablation(\n",
    "            mt=mt,\n",
    "            input=clean_inputs,\n",
    "            restore_states=cur_restore,\n",
    "            block_locations=mlp_ablation_locations,  # block the MLP contributions\n",
    "            ans_token=patch_ans.token_id,\n",
    "        )\n",
    "        # logger.debug(f\"{mlp_ablation_pred=}\")\n",
    "\n",
    "        attn_ablation_pred = do_path_ablation(\n",
    "            mt=mt,\n",
    "            input=clean_inputs,\n",
    "            restore_states=cur_restore,\n",
    "            block_locations=attn_ablation_locations,  # block the attention contributions\n",
    "            ans_token=patch_ans.token_id,\n",
    "        )\n",
    "        # logger.debug(f\"{attn_ablation_pred=}\")\n",
    "\n",
    "        path_blocking_effects[i] = {\n",
    "            \"h_restored\": h_restore_pred,\n",
    "            \"mlp_blocked\": mlp_ablation_pred,\n",
    "            \"attn_blocked\": attn_ablation_pred,\n",
    "        }\n",
    "        # logger.debug(\"-\"*50)\n",
    "\n",
    "    return dict(\n",
    "        clean_inputs=clean_inputs,\n",
    "        patch_inputs=patch_inputs,\n",
    "        patch_ans=patch_ans,\n",
    "        base_ans=base_ans,\n",
    "        patch_blocking_effects=path_blocking_effects,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two entities, find a common link or relation between them.\n",
      "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
      "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
      "If there is no connection just answer \"None\".\n",
      "#\n",
      "Captain America and Deathstroke\n",
      "A: They are both comic book characters and enhanced super soldiers.\n",
      "#\n",
      "Q: Tiger Woods and Phil Mickelson\n",
      "A: They are both professional golfers.\n",
      "#\n",
      "Q: Rome and Italy\n",
      "A: Rome is the capital city of Italy.\n",
      "#\n",
      "Q: Michael Jordan and Slovakia\n",
      "A: None\n",
      "#\n",
      "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
      "A: Richard Meier was the architect of both of these buildings.\n",
      "#\n",
      "Q: {} and python\n",
      "A: They are/were both\n"
     ]
    }
   ],
   "source": [
    "prompt_template = clean_prompt.prompt.replace(clean_entity, \"{}\")\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"{} is located in the city of\"\n",
    "# clean_entity = \"Eiffel Tower\"\n",
    "# patch_entity = \"The Space Needle\"\n",
    "\n",
    "# path_blocking_effects = trace_path_ablation_effects(\n",
    "#     mt=mt,\n",
    "#     prompt_template=prompt_template,\n",
    "#     clean_subj=clean_entity,\n",
    "#     patched_subj=patch_entity,\n",
    "#     at_token=\"last\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:07:20 __main__ INFO     len(coincidences['examples'])=20\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"coincidences_sample.json\")) as f:\n",
    "    coincidences = json.load(f)\n",
    "\n",
    "logger.info(f\"{len(coincidences['examples'])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:34:49 __main__ INFO     (1/20)  entities=['Germany', 'Japan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:34:50 __main__ INFO     (placeholder, Japan) => countries.\n",
      "2025-02-20 12:34:51 __main__ DEBUG    patch_ans=PredictedToken(token=' Axis', prob=0.2440185546875, logit=16.1875, token_id=35574)\n",
      "2025-02-20 12:34:51 __main__ DEBUG    clean_ans=PredictedToken(token=' countries', prob=0.11688232421875, logit=13.296875, token_id=5961)\n",
      "2025-02-20 12:34:51 __main__ DEBUG    corrupt_rank=3076 | base_ans=PredictedToken(token=' Axis', prob=1.4424324035644531e-05, logit=4.296875, token_id=35574)\n",
      "2025-02-20 12:34:51 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:34:51 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:35:32 __main__ INFO     (2/20)  entities=['Hugh Jackman', 'Ryan Reynolds']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:35:33 __main__ INFO     (placeholder, Ryan Reynolds) => actors.\n",
      "2025-02-20 12:35:34 __main__ DEBUG    patch_ans=PredictedToken(token=' X', prob=0.15087890625, logit=15.5859375, token_id=1630)\n",
      "2025-02-20 12:35:34 __main__ DEBUG    clean_ans=PredictedToken(token=' actors', prob=0.2154541015625, logit=15.0703125, token_id=20142)\n",
      "2025-02-20 12:35:34 __main__ DEBUG    corrupt_rank=21 | base_ans=PredictedToken(token=' X', prob=0.006816864013671875, logit=11.6171875, token_id=1630)\n",
      "2025-02-20 12:35:34 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:35:34 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:41<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:36:15 __main__ INFO     (3/20)  entities=['Bhutan', 'Tuvalu']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:36:17 __main__ INFO     (placeholder, Tuvalu) => countries.\n",
      "2025-02-20 12:36:17 __main__ DEBUG    patch_ans=PredictedToken(token=' monarch', prob=0.1822509765625, logit=16.046875, token_id=63854)\n",
      "2025-02-20 12:36:17 __main__ DEBUG    clean_ans=PredictedToken(token=' countries', prob=0.1409912109375, logit=14.703125, token_id=5961)\n",
      "2025-02-20 12:36:17 __main__ DEBUG    corrupt_rank=43 | base_ans=PredictedToken(token=' monarch', prob=0.0032634735107421875, logit=10.9375, token_id=63854)\n",
      "2025-02-20 12:36:17 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:36:17 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:36:57 __main__ INFO     (4/20)  entities=['Vatican City', 'Mount Athos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:36:59 __main__ INFO     (placeholder, Mount Athos) => monasteries.\n",
      "2025-02-20 12:36:59 __main__ DEBUG    patch_ans=PredictedToken(token=' independent', prob=0.121826171875, logit=15.4296875, token_id=9678)\n",
      "2025-02-20 12:36:59 __main__ DEBUG    clean_ans=PredictedToken(token=' mon', prob=0.1280517578125, logit=14.53125, token_id=1647)\n",
      "2025-02-20 12:36:59 __main__ DEBUG    corrupt_rank=20 | base_ans=PredictedToken(token=' independent', prob=0.00844573974609375, logit=11.8125, token_id=9678)\n",
      "2025-02-20 12:36:59 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:36:59 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:37:39 __main__ INFO     (5/20)  entities=['Rosetta Stone', 'Dead Sea Scrolls']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:37:40 __main__ INFO     (placeholder, Dead Sea Scrolls) => artifacts.\n",
      "2025-02-20 12:37:40 __main__ DEBUG    patch_ans=PredictedToken(token=' ancient', prob=0.3876953125, logit=17.703125, token_id=14154)\n",
      "2025-02-20 12:37:41 __main__ DEBUG    clean_ans=PredictedToken(token=' religious', prob=0.091796875, logit=15.1171875, token_id=10597)\n",
      "2025-02-20 12:37:41 __main__ DEBUG    corrupt_rank=2 | base_ans=PredictedToken(token=' ancient', prob=0.087646484375, logit=15.0703125, token_id=14154)\n",
      "2025-02-20 12:37:41 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:37:41 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:38:21 __main__ INFO     (6/20)  entities=['Leonardo da Vinci', 'Benjamin Franklin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:38:23 __main__ INFO     (placeholder, Benjamin Franklin) => American citizens.\n",
      "2025-02-20 12:38:23 __main__ DEBUG    patch_ans=PredictedToken(token=' polym', prob=0.29150390625, logit=17.171875, token_id=46033)\n",
      "2025-02-20 12:38:23 __main__ DEBUG    clean_ans=PredictedToken(token=' American', prob=0.127685546875, logit=15.3203125, token_id=3778)\n",
      "2025-02-20 12:38:23 __main__ DEBUG    corrupt_rank=18 | base_ans=PredictedToken(token=' polym', prob=0.0122528076171875, logit=12.9765625, token_id=46033)\n",
      "2025-02-20 12:38:23 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:38:23 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:39:03 __main__ INFO     (7/20)  entities=['Daredevil', 'Toph Beifong']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:39:05 __main__ INFO     (placeholder, Toph Beifong) => characters in Avatar: The Last Airbender.\n",
      "2025-02-20 12:39:05 __main__ DEBUG    patch_ans=PredictedToken(token=' blind', prob=0.7431640625, logit=18.484375, token_id=18507)\n",
      "2025-02-20 12:39:05 __main__ DEBUG    clean_ans=PredictedToken(token=' characters', prob=0.201416015625, logit=14.75, token_id=5885)\n",
      "2025-02-20 12:39:05 __main__ DEBUG    corrupt_rank=4 | base_ans=PredictedToken(token=' blind', prob=0.0550537109375, logit=13.453125, token_id=18507)\n",
      "2025-02-20 12:39:05 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:39:05 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:39:46 __main__ INFO     (8/20)  entities=['Memento', 'Inception']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:39:47 __main__ INFO     (placeholder, Inception) => movies.\n",
      "2025-02-20 12:39:47 __main__ DEBUG    patch_ans=PredictedToken(token=' directed', prob=0.724609375, logit=18.453125, token_id=15910)\n",
      "2025-02-20 12:39:47 __main__ DEBUG    clean_ans=PredictedToken(token=' movies', prob=0.2861328125, logit=15.4765625, token_id=9698)\n",
      "2025-02-20 12:39:47 __main__ DEBUG    corrupt_rank=2 | base_ans=PredictedToken(token=' directed', prob=0.1722412109375, logit=14.96875, token_id=15910)\n",
      "2025-02-20 12:39:47 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:39:47 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:40:27 __main__ INFO     (9/20)  entities=['Julius Caesar', 'Nepoleon Bonaparte']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:40:29 __main__ INFO     (placeholder, Nepoleon Bonaparte) => French.\n",
      "2025-02-20 12:40:29 __main__ DEBUG    patch_ans=PredictedToken(token=' military', prob=0.241455078125, logit=17.53125, token_id=6411)\n",
      "2025-02-20 12:40:29 __main__ DEBUG    clean_ans=PredictedToken(token=' French', prob=0.15185546875, logit=15.375, token_id=8753)\n",
      "2025-02-20 12:40:29 __main__ DEBUG    corrupt_rank=2 | base_ans=PredictedToken(token=' military', prob=0.08319091796875, logit=14.7734375, token_id=6411)\n",
      "2025-02-20 12:40:29 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:40:29 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:38<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:41:08 __main__ INFO     (10/20)  entities=['The Godfather', 'Goodfellas']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:41:10 __main__ INFO     (placeholder, Goodfellas) => movies.\n",
      "2025-02-20 12:41:10 __main__ DEBUG    patch_ans=PredictedToken(token=' mob', prob=0.1612548828125, logit=16.96875, token_id=12881)\n",
      "2025-02-20 12:41:10 __main__ DEBUG    clean_ans=PredictedToken(token=' movies', prob=0.23779296875, logit=15.09375, token_id=9698)\n",
      "2025-02-20 12:41:10 __main__ DEBUG    corrupt_rank=6 | base_ans=PredictedToken(token=' mob', prob=0.0228118896484375, logit=12.75, token_id=12881)\n",
      "2025-02-20 12:41:10 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:41:10 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:41:50 __main__ INFO     (11/20)  entities=['The Green Mile', 'The Shawshank Redemption']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:41:51 __main__ INFO     (placeholder, The Shawshank Redemption) => movies.\n",
      "2025-02-20 12:41:51 __main__ DEBUG    patch_ans=PredictedToken(token=' directed', prob=0.1981201171875, logit=15.9140625, token_id=15910)\n",
      "2025-02-20 12:41:52 __main__ DEBUG    clean_ans=PredictedToken(token=' movies', prob=0.109619140625, logit=14.015625, token_id=9698)\n",
      "2025-02-20 12:41:52 __main__ DEBUG    corrupt_rank=2 | base_ans=PredictedToken(token=' directed', prob=0.0736083984375, logit=13.6171875, token_id=15910)\n",
      "2025-02-20 12:41:52 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:41:52 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:42:32 __main__ INFO     (12/20)  entities=['Christopher Columbus', 'Vasco da Gama']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:42:34 __main__ INFO     (placeholder, Vasco da Gama) => Portuguese.\n",
      "2025-02-20 12:42:34 __main__ DEBUG    patch_ans=PredictedToken(token=' explor', prob=0.45458984375, logit=18.71875, token_id=48539)\n",
      "2025-02-20 12:42:34 __main__ DEBUG    clean_ans=PredictedToken(token=' Portuguese', prob=0.23095703125, logit=16.015625, token_id=43288)\n",
      "2025-02-20 12:42:34 __main__ DEBUG    corrupt_rank=2 | base_ans=PredictedToken(token=' explor', prob=0.11431884765625, logit=15.3125, token_id=48539)\n",
      "2025-02-20 12:42:34 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:42:34 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:43:14 __main__ INFO     (13/20)  entities=['Elephant', 'Whale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:43:16 __main__ INFO     (placeholder, Whale) => animals.\n",
      "2025-02-20 12:43:16 __main__ DEBUG    patch_ans=PredictedToken(token=' mammals', prob=0.310302734375, logit=16.71875, token_id=56669)\n",
      "2025-02-20 12:43:16 __main__ DEBUG    clean_ans=PredictedToken(token=' animals', prob=0.0491943359375, logit=12.1875, token_id=10099)\n",
      "2025-02-20 12:43:16 __main__ DEBUG    corrupt_rank=4 | base_ans=PredictedToken(token=' mammals', prob=0.0280303955078125, logit=11.625, token_id=56669)\n",
      "2025-02-20 12:43:16 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:43:16 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:43:56 __main__ INFO     (14/20)  entities=['Emu', 'Ostrich']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:43:57 __main__ INFO     (placeholder, Ostrich) => animals.\n",
      "2025-02-20 12:43:57 __main__ DEBUG    patch_ans=PredictedToken(token=' flight', prob=0.406982421875, logit=17.03125, token_id=11213)\n",
      "2025-02-20 12:43:58 __main__ DEBUG    clean_ans=PredictedToken(token=' animals', prob=0.12213134765625, logit=13.4765625, token_id=10099)\n",
      "2025-02-20 12:43:58 __main__ DEBUG    corrupt_rank=293 | base_ans=PredictedToken(token=' flight', prob=0.00034046173095703125, logit=7.59375, token_id=11213)\n",
      "2025-02-20 12:43:58 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:43:58 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:44:38 __main__ INFO     (15/20)  entities=['Brazil', 'Turkey']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:44:40 __main__ INFO     (placeholder, Turkey) => countries.\n",
      "2025-02-20 12:44:40 __main__ DEBUG    patch_ans=PredictedToken(token=' members', prob=0.22412109375, logit=15.78125, token_id=3697)\n",
      "2025-02-20 12:44:40 __main__ DEBUG    clean_ans=PredictedToken(token=' countries', prob=0.1246337890625, logit=13.796875, token_id=5961)\n",
      "2025-02-20 12:44:40 __main__ DEBUG    corrupt_rank=6 | base_ans=PredictedToken(token=' members', prob=0.033538818359375, logit=12.484375, token_id=3697)\n",
      "2025-02-20 12:44:40 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:44:40 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:45:21 __main__ INFO     (16/20)  entities=['jellyfish', 'lobster']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:45:22 __main__ INFO     (placeholder, lobster) => used as a placeholder in a text.\n",
      "2025-02-20 12:45:23 __main__ DEBUG    patch_ans=PredictedToken(token=' in', prob=0.201904296875, logit=15.6484375, token_id=304)\n",
      "2025-02-20 12:45:23 __main__ DEBUG    clean_ans=PredictedToken(token=' in', prob=0.030181884765625, logit=11.65625, token_id=304)\n",
      "2025-02-20 12:45:23 __main__ DEBUG    corrupt_rank=1 | base_ans=PredictedToken(token=' in', prob=0.030181884765625, logit=11.65625, token_id=304)\n",
      "2025-02-20 12:45:23 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:45:23 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:46:03 __main__ INFO     (17/20)  entities=['corn', 'wheat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:46:04 __main__ INFO     (placeholder, wheat) => used as a placeholder in the English language.\n",
      "2025-02-20 12:46:04 __main__ DEBUG    patch_ans=PredictedToken(token=' staple', prob=0.1856689453125, logit=17.078125, token_id=50056)\n",
      "2025-02-20 12:46:05 __main__ DEBUG    clean_ans=PredictedToken(token=' used', prob=0.09661865234375, logit=13.1875, token_id=1511)\n",
      "2025-02-20 12:46:05 __main__ DEBUG    corrupt_rank=19 | base_ans=PredictedToken(token=' staple', prob=0.00913238525390625, logit=10.828125, token_id=50056)\n",
      "2025-02-20 12:46:05 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:46:05 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:41<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:46:46 __main__ INFO     (18/20)  entities=['crocodile', 'shark']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:46:48 __main__ INFO     (placeholder, shark) => fictional characters.\n",
      "2025-02-20 12:46:48 __main__ DEBUG    patch_ans=PredictedToken(token=' apex', prob=0.1292724609375, logit=15.6875, token_id=72627)\n",
      "2025-02-20 12:46:48 __main__ DEBUG    clean_ans=PredictedToken(token=' fictional', prob=0.07073974609375, logit=12.6796875, token_id=44682)\n",
      "2025-02-20 12:46:48 __main__ DEBUG    corrupt_rank=158 | base_ans=PredictedToken(token=' apex', prob=0.0007619857788085938, logit=8.1484375, token_id=72627)\n",
      "2025-02-20 12:46:48 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:46:48 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:47:29 __main__ INFO     (19/20)  entities=['crab', 'spider']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:47:30 __main__ INFO     (placeholder, spider) => characters in the Marvel Cinematic Universe.\n",
      "2025-02-20 12:47:31 __main__ DEBUG    patch_ans=PredictedToken(token=' ar', prob=0.4072265625, logit=16.71875, token_id=802)\n",
      "2025-02-20 12:47:31 __main__ DEBUG    clean_ans=PredictedToken(token=' characters', prob=0.045318603515625, logit=12.1484375, token_id=5885)\n",
      "2025-02-20 12:47:31 __main__ DEBUG    corrupt_rank=101 | base_ans=PredictedToken(token=' ar', prob=0.0012454986572265625, logit=8.5546875, token_id=802)\n",
      "2025-02-20 12:47:31 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:47:31 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:39<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:48:11 __main__ INFO     (20/20)  entities=['copper', 'gold']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:48:12 __main__ INFO     (placeholder, gold) => used as a placeholder in the past.\n",
      "2025-02-20 12:48:12 __main__ DEBUG    patch_ans=PredictedToken(token=' used', prob=0.4423828125, logit=18.171875, token_id=1511)\n",
      "2025-02-20 12:48:13 __main__ DEBUG    clean_ans=PredictedToken(token=' used', prob=0.064453125, logit=12.1015625, token_id=1511)\n",
      "2025-02-20 12:48:13 __main__ DEBUG    corrupt_rank=1 | base_ans=PredictedToken(token=' used', prob=0.064453125, logit=12.1015625, token_id=1511)\n",
      "2025-02-20 12:48:13 __main__ WARNING  Ignoring at_token='last' since token_idx=-2 is provided\n",
      "2025-02-20 12:48:13 __main__ DEBUG    ==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "path_blocking_effects = []\n",
    "# at_token = \"subj_last\"\n",
    "# at_token = \"subj_2nd_last\"\n",
    "\n",
    "for idx, c in enumerate(coincidences[\"examples\"]):\n",
    "    entities = c[\"entity_pair\"]\n",
    "    logger.info(f\"({idx + 1}/{len(coincidences['examples'])})  {entities=}\")\n",
    "\n",
    "    common_entity = entities[1]\n",
    "    patch_entity = entities[0]\n",
    "    clean_entity = \"placeholder\"\n",
    "\n",
    "    clean_prompt = prepare_probing_input(\n",
    "        mt=mt,\n",
    "        entities=(clean_entity, common_entity),\n",
    "        prefix=prefix,\n",
    "        answer_marker=answer_marker,\n",
    "        question_marker=question_marker,\n",
    "        block_separator=block_separator,\n",
    "        is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "        answer_prefix=\" They are/were both\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    clean_answer = get_lm_generated_answer(\n",
    "        mt=mt, prompt=clean_prompt, is_a_reasoning_model=\"deepseek\" in model_key.lower()\n",
    "    )\n",
    "    logger.info(f\"({clean_entity}, {common_entity}) => {clean_answer}\")\n",
    "\n",
    "    patched_prompt = prepare_probing_input(\n",
    "        mt=mt,\n",
    "        entities=(patch_entity, common_entity),\n",
    "        prefix=prefix,\n",
    "        answer_marker=answer_marker,\n",
    "        question_marker=question_marker,\n",
    "        block_separator=block_separator,\n",
    "        is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "        answer_prefix=\" They are/were both\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    prompt_template = clean_prompt.prompt.replace(clean_entity, \"{}\")\n",
    "\n",
    "    cur_effects = trace_path_ablation_effects(\n",
    "        mt=mt,\n",
    "        prompt_template=prompt_template,\n",
    "        clean_subj=clean_entity,\n",
    "        patched_subj=patch_entity,\n",
    "        # at_token=at_token\n",
    "        token_idx=-2,\n",
    "    )\n",
    "\n",
    "    path_blocking_effects.append(cur_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_path_blocking_results(\n",
    "    path_blocking_effects: list[dict], metric: str = \"prob\"\n",
    "):\n",
    "    h_restored = {l: [] for l in range(mt.n_layer)}\n",
    "    mlp_blocked = {l: [] for l in range(mt.n_layer)}\n",
    "    attn_blocked = {l: [] for l in range(mt.n_layer)}\n",
    "    for effect in path_blocking_effects:\n",
    "        high_bar = getattr(effect[\"patch_ans\"], metric)\n",
    "        low_bar = getattr(effect[\"base_ans\"], metric)\n",
    "        denominator = high_bar - low_bar\n",
    "        for l in range(mt.n_layer):\n",
    "            h_restored[l] = (\n",
    "                getattr(effect[\"patch_blocking_effects\"][l][\"h_restored\"], metric)\n",
    "                - low_bar\n",
    "            ) / denominator\n",
    "            mlp_blocked[l] = (\n",
    "                getattr(effect[\"patch_blocking_effects\"][l][\"mlp_blocked\"], metric)\n",
    "                - low_bar\n",
    "            ) / denominator\n",
    "            attn_blocked[l] = (\n",
    "                getattr(effect[\"patch_blocking_effects\"][l][\"attn_blocked\"], metric)\n",
    "                - low_bar\n",
    "            ) / denominator\n",
    "\n",
    "    return {\n",
    "        l: {\n",
    "            \"h_restored\": np.mean(h_restored[l]),\n",
    "            \"mlp_blocked\": np.mean(mlp_blocked[l]),\n",
    "            \"attn_blocked\": np.mean(attn_blocked[l]),\n",
    "        }\n",
    "        for l in range(mt.n_layer)\n",
    "    }\n",
    "\n",
    "\n",
    "metric = \"logit\"\n",
    "plot_results = process_path_blocking_results(path_blocking_effects, metric)\n",
    "# plot_results = process_path_blocking_results([path_blocking_effects[5]], metric)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "bar_width = 0.22\n",
    "\n",
    "plt.title(f\"Path Blocking Effects ({metric})\")\n",
    "keys = list(range(mt.n_layer))\n",
    "color_map = {\"h_restored\": \"purple\", \"mlp_blocked\": \"green\", \"attn_blocked\": \"red\"}\n",
    "\n",
    "for idx, kind in enumerate([\"h_restored\", \"mlp_blocked\", \"attn_blocked\"]):\n",
    "    plt.bar(\n",
    "        [k + idx * bar_width for k in keys],\n",
    "        height=[plot_results[k][kind] for k in keys],\n",
    "        width=bar_width,\n",
    "        label=kind,\n",
    "        alpha=0.7,\n",
    "        color=color_map[kind],\n",
    "    )\n",
    "\n",
    "plt.legend(ncol=4, bbox_to_anchor=(0.5, -0.18), loc=\"lower center\", frameon=False)\n",
    "plt.xticks(keys)\n",
    "plt.xlabel(\"Layer Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
