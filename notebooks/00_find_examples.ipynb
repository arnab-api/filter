{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:20:57 __main__ INFO     torch.__version__='2.6.0+cu124', torch.version.cuda='12.4'\n",
      "2025-04-14 17:20:57 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2025-04-14 17:20:57 __main__ INFO     transformers.__version__='4.51.2'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import json\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama-3.1-8B-Instruct', 'Llama-3.1-8B']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(env_utils.DEFAULT_MODELS_DIR, \"meta-llama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:21:06 src.models WARNING  Qwen/Qwen2.5-14B not found in /share/u/models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:21:06 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-14 17:21:08 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-14 17:21:08 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:21:10 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:21:15 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-04-14 17:21:15 src.models INFO     loaded model <Qwen/Qwen2.5-14B> | size: 28171.604 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "model_key = \"Qwen/Qwen2.5-14B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:27:15 __main__ INFO     len(coincidences['examples'])=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tom Cruise', 'Brad Pitt')\n",
      "Given two entities, find a common link or relation between them.\n",
      "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
      "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
      "If there is no connection just answer \"None\".\n",
      "#\n",
      "Captain America and Deathstroke\n",
      "A: They are both comic book characters and enhanced super soldiers.\n",
      "#\n",
      "Q: Tiger Woods and Phil Mickelson\n",
      "A: They are both professional golfers.\n",
      "#\n",
      "Q: Rome and Italy\n",
      "A: Rome is the capital city of Italy.\n",
      "#\n",
      "Q: Michael Jordan and Slovakia\n",
      "A: None\n",
      "#\n",
      "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
      "A: Richard Meier was the architect of both of these buildings.\n",
      "#\n",
      "Q: Tom Cruise and Brad Pitt\n",
      "A: They are/were both\n",
      "answer='actors.'\n"
     ]
    }
   ],
   "source": [
    "from src.probing.utils import (\n",
    "    prepare_probing_input,\n",
    "    get_lm_generated_answer,\n",
    "    check_if_answer_is_correct,\n",
    ")\n",
    "\n",
    "Instructions = \"\"\"Given two entities, find a common link or relation between them.\n",
    "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
    "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
    "If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "# Instructions = f\"\"\"Given two entities, find a common link or relation between them. If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "block_separator = \"\\n#\"\n",
    "question_marker = \"\\nQ: \"\n",
    "answer_marker = \"\\nA:\"\n",
    "\n",
    "examples = \"\"\"#\n",
    "Captain America and Deathstroke\n",
    "A: They are both comic book characters and enhanced super soldiers.\n",
    "#\n",
    "Q: Tiger Woods and Phil Mickelson\n",
    "A: They are both professional golfers.\n",
    "#\n",
    "Q: Rome and Italy\n",
    "A: Rome is the capital city of Italy.\n",
    "#\n",
    "Q: Michael Jordan and Slovakia\n",
    "A: None\n",
    "#\n",
    "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
    "A: Richard Meier was the architect of both of these buildings.\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"coincidences_sample.json\")) as f:\n",
    "    coincidences = json.load(f)\n",
    "\n",
    "logger.info(f\"{len(coincidences['examples'])=}\")\n",
    "\n",
    "\n",
    "# entities = coincidences[\"examples\"][0][\"entity_pair\"]\n",
    "# entities = (\"Whale\", \"Dolphin\")\n",
    "# entities = (\"Nautilus\", \"Dolphin\")\n",
    "# entities = (\"Abraham Lincoln\", \"John F. Kennedy\")\n",
    "# entities = (\"Brad Pitt\", \"Angelina Jolie\")\n",
    "# entities = (\"Emu\", \"Ostrich\")\n",
    "# entities = (\"Elephant\", \"Whale\")\n",
    "# entities = (\"Wolverine\", \"Penguin\")\n",
    "# entities = (\"Giraffe\", \"Reindeer\")\n",
    "# entities = (\"Hydrogen\", \"Oxygen\")\n",
    "# entities = (\"Alfred Nobel\", \"Julius Caesar\")\n",
    "# entities = (\"Cleopatra\", \"Catherine the Great\")\n",
    "# entities = (\"Snake\", \"Spider\")\n",
    "# entities = (\"Tomato\", \"Banana\")\n",
    "# entities = (\"Diamond\", \"Coal\")\n",
    "# entities = (\"Rome\", \"Istanbul\")\n",
    "# entities = (\"Mercury\", \"Jupiter\")\n",
    "# entities = (\"butterflies\", \"frogs\")\n",
    "# entities = (\"octopus\", \"squid\")\n",
    "# entities = (\"Kangaroo\", \"Seahorse\")\n",
    "# entities = (\"Great Wall of China\", \"Panama Canal\")\n",
    "# entities = (\"Brazil\", \"Turkey\")\n",
    "# entities = (\"onion\", \"garlic\")\n",
    "# entities = (\"jellyfish\", \"lobster\")\n",
    "# entities = (\"corn\", \"wheat\")\n",
    "# entities = (\"broccoli\", \"cauliflower\")\n",
    "# entities = (\"Venus\", \"Uranus\")\n",
    "# entities = (\"crocodile\", \"shark\")\n",
    "# entities = (\"crab\", \"spider\")\n",
    "# entities = (\"apple\", \"rose\")\n",
    "# entities = (\"starfish\", \"lizard\")\n",
    "# entities = (\"zebra\", \"penguin\")\n",
    "# entities = (\"rabbit\", \"deer\")\n",
    "# entities = (\"mushroom\", \"coral\")\n",
    "# entities = (\"pinaapple\", \"fig\")\n",
    "# entities = (\"pig\", \"dolphin\")\n",
    "# entities = (\"cinnamon\", \"vanilla\")\n",
    "# entities = (\"tuna\", \"hummingbird\")\n",
    "# entities = (\"diamond\", \"graphaite\")\n",
    "# entities = (\"copper\", \"gold\")\n",
    "\n",
    "# entities = (\"apple\", \"windows\")\n",
    "# entities = (\"doors\", \"windows\")\n",
    "\n",
    "entities = (\"Tom Cruise\", \"Brad Pitt\")\n",
    "\n",
    "print(entities)\n",
    "\n",
    "prefix = f\"\"\"{Instructions}\n",
    "{examples}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prepare_probing_input(\n",
    "    mt=mt,\n",
    "    entities=entities,\n",
    "    prefix=prefix,\n",
    "    answer_marker=answer_marker,\n",
    "    question_marker=question_marker,\n",
    "    block_separator=block_separator,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    # is_a_reasoning_model=True\n",
    "    answer_prefix=\" They are/were both\",\n",
    "    # answer_prefix = \" They are both used to say\"\n",
    ")\n",
    "\n",
    "print(mt.tokenizer.decode(prompt.tokenized[\"input_ids\"][0]))\n",
    "\n",
    "answer = get_lm_generated_answer(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "    # is_a_reasoning_model=True\n",
    ")\n",
    "print(f\"{answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14 17:21:48 anthropic._base_client DEBUG    Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Do you think the following answer is a good connection or relation between the entities doors and windows?\\nYour answer should start with \"Yes\" or \"No\". If the answer is \"No\", please provide your reasoning. Otherwise, just say \"Yes\".\\n\\n\\nused to enter and exit a building.'}]}], 'model': 'claude-3-5-sonnet-20241022', 'system': 'You are a helpful assistant.', 'temperature': 0}}\n",
      "2025-04-14 17:21:48 anthropic._base_client DEBUG    Sending HTTP Request: POST https://api.anthropic.com/v1/messages\n",
      "2025-04-14 17:21:48 httpcore.connection DEBUG    connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(1, 9, True), (6, 5, 60), (6, 6, 5), (6, 4, 60)]\n",
      "2025-04-14 17:21:48 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f52d8066f50>\n",
      "2025-04-14 17:21:48 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7f52c60f5490> server_hostname='api.anthropic.com' timeout=5.0\n",
      "2025-04-14 17:21:48 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f52d8087c90>\n",
      "2025-04-14 17:21:48 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2025-04-14 17:21:48 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2025-04-14 17:21:48 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2025-04-14 17:21:48 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2025-04-14 17:21:48 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-04-14 17:21:51 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 14 Apr 2025 21:21:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'1000'), (b'anthropic-ratelimit-requests-remaining', b'999'), (b'anthropic-ratelimit-requests-reset', b'2025-04-14T21:21:48Z'), (b'anthropic-ratelimit-input-tokens-limit', b'80000'), (b'anthropic-ratelimit-input-tokens-remaining', b'80000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-04-14T21:21:50Z'), (b'anthropic-ratelimit-output-tokens-limit', b'16000'), (b'anthropic-ratelimit-output-tokens-remaining', b'16000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-04-14T21:21:51Z'), (b'anthropic-ratelimit-tokens-limit', b'96000'), (b'anthropic-ratelimit-tokens-remaining', b'96000'), (b'anthropic-ratelimit-tokens-reset', b'2025-04-14T21:21:50Z'), (b'request-id', b'req_0147eRr5scDw6eYa7JKXgkqJ'), (b'anthropic-organization-id', b'768cfa46-3909-4737-96ed-23284e95da76'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'93064146697e9033-BOS'), (b'Content-Encoding', b'gzip')])\n",
      "2025-04-14 17:21:51 httpx INFO     HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-04-14 17:21:51 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2025-04-14 17:21:51 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2025-04-14 17:21:51 httpcore.http11 DEBUG    response_closed.started\n",
      "2025-04-14 17:21:51 httpcore.http11 DEBUG    response_closed.complete\n",
      "2025-04-14 17:21:51 anthropic._base_client DEBUG    HTTP Response: POST https://api.anthropic.com/v1/messages \"200 OK\" Headers({'date': 'Mon, 14 Apr 2025 21:21:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '1000', 'anthropic-ratelimit-requests-remaining': '999', 'anthropic-ratelimit-requests-reset': '2025-04-14T21:21:48Z', 'anthropic-ratelimit-input-tokens-limit': '80000', 'anthropic-ratelimit-input-tokens-remaining': '80000', 'anthropic-ratelimit-input-tokens-reset': '2025-04-14T21:21:50Z', 'anthropic-ratelimit-output-tokens-limit': '16000', 'anthropic-ratelimit-output-tokens-remaining': '16000', 'anthropic-ratelimit-output-tokens-reset': '2025-04-14T21:21:51Z', 'anthropic-ratelimit-tokens-limit': '96000', 'anthropic-ratelimit-tokens-remaining': '96000', 'anthropic-ratelimit-tokens-reset': '2025-04-14T21:21:50Z', 'request-id': 'req_0147eRr5scDw6eYa7JKXgkqJ', 'anthropic-organization-id': '768cfa46-3909-4737-96ed-23284e95da76', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '93064146697e9033-BOS', 'content-encoding': 'gzip'})\n",
      "2025-04-14 17:21:51 anthropic._base_client DEBUG    request_id: req_0147eRr5scDw6eYa7JKXgkqJ\n",
      "2025-04-14 17:21:52 src.probing.utils INFO     oracle_response='No. This relation only describes doors and their function, but does not establish any connection or relationship between doors and windows. A better relation would describe how both doors and windows are openings in walls that serve as boundaries between interior and exterior spaces, or how they both provide access (doors for people, windows for light and air) to a building.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "check_if_answer_is_correct(\n",
    "    answer=answer,\n",
    "    entities=entities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tom Cruise', 'Brad Pitt')\n",
      "2025-04-14 17:27:37 httpcore.connection DEBUG    close.started\n",
      "2025-04-14 17:27:37 httpcore.connection DEBUG    close.complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' actors', prob=0.36083984375, logit=19.25, token_id=19571),\n",
       "  PredictedToken(token=' married', prob=0.1900634765625, logit=18.609375, token_id=12224),\n",
       "  PredictedToken(token=' Hollywood', prob=0.06671142578125, logit=17.5625, token_id=17236),\n",
       "  PredictedToken(token=' famous', prob=0.06365966796875, logit=17.515625, token_id=11245),\n",
       "  PredictedToken(token=' movie', prob=0.03863525390625, logit=17.015625, token_id=5700)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token\n",
    "from src.utils.typing import TokenizerOutput\n",
    "\n",
    "print(entities)\n",
    "\n",
    "clean_pred = predict_next_token(\n",
    "    mt=mt,\n",
    "    inputs=TokenizerOutput(data=prompt.tokenized),\n",
    ")\n",
    "clean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_tokens = [19571]\n",
    "# interesting_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who/what is a Tom Cruise? Answer: Tom Cruise is a world-renowned actor who has been in the entertainment industry for almost 4 decades now. He is', 'Who/what is a Tom Cruise? Answer: Tom Cruise is a very famous actor. He stars in lots of popular movies. He has lots of fans all over the', 'Who/what is a Tom Cruise? Answer: Tom Cruise is a well-known American actor who has starred in many blockbuster movies. Born on July 3, 1', 'Who/what is a Tom Cruise? Answer: Tom Cruise is a talented and accomplished American actor, director, producer, and motivational speaker who has made a significant impact on', 'Who/what is a Tom Cruise? Answer: Tom Cruise is a highly popular actor, who stars in block-buster movies.']\n",
      "[{19571: (3517, PredictedToken(token=' actors', prob=1.6689300537109375e-06, logit=5.9453125, token_id=19571))}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' famous', prob=0.375732421875, logit=18.265625, token_id=11245),\n",
       "  PredictedToken(token=' very', prob=0.08001708984375, logit=16.71875, token_id=1602),\n",
       "  PredictedToken(token=' well', prob=0.07171630859375, logit=16.609375, token_id=1632),\n",
       "  PredictedToken(token=' movie', prob=0.05328369140625, logit=16.3125, token_id=5700),\n",
       "  PredictedToken(token=' popular', prob=0.047027587890625, logit=16.1875, token_id=5411),\n",
       "  PredictedToken(token=' person', prob=0.0298919677734375, logit=15.734375, token_id=1697),\n",
       "  PredictedToken(token=' ', prob=0.0210418701171875, logit=15.3828125, token_id=220),\n",
       "  PredictedToken(token=' successful', prob=0.018707275390625, logit=15.265625, token_id=6849),\n",
       "  PredictedToken(token=' man', prob=0.0185699462890625, logit=15.2578125, token_id=883),\n",
       "  PredictedToken(token=' talented', prob=0.01491546630859375, logit=15.0390625, token_id=23074),\n",
       "  PredictedToken(token=' Hollywood', prob=0.01468658447265625, logit=15.0234375, token_id=17236),\n",
       "  PredictedToken(token=' world', prob=0.01082611083984375, logit=14.71875, token_id=1879),\n",
       "  PredictedToken(token=' film', prob=0.0097808837890625, logit=14.6171875, token_id=4531),\n",
       "  PredictedToken(token=' name', prob=0.00911712646484375, logit=14.546875, token_id=829),\n",
       "  PredictedToken(token=' highly', prob=0.00897979736328125, logit=14.53125, token_id=7548)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_probing_prompt = \"Who/what is a {}? Answer: {} is a\"\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=single_probing_prompt.format(entities[0], entities[0]),\n",
    ")\n",
    "\n",
    "print(gen)\n",
    "\n",
    "pred, track_ans = predict_next_token(\n",
    "    mt=mt,\n",
    "    inputs=[single_probing_prompt.format(entities[0], entities[0])],\n",
    "    k=15,\n",
    "    token_of_interest=[clean_pred[0][0].token_id] + interesting_tokens,\n",
    ")\n",
    "\n",
    "print(track_ans)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who/what is a gold? Answer: gold is a chemical element with the symbol Au (from Latin: aurum) and an atomic number of 79', 'Who/what is a gold? Answer: gold is a precious metal that is used as a currency and is traded on the stock market. Gold is also used', 'Who/what is a gold? Answer: gold is a person who is 18 years of age or older and is registered with the College of Physicians and Surge', 'Who/what is a gold? Answer: gold is a metallic element, chemical symbol Au, atomic number 79, atomic weight 196.967, density', 'Who/what is a gold? Answer: gold is a metal that is yellow in color. It is malleable, meaning it can be beaten into thin']\n",
      "[{11667: (30, PredictedToken(token=' currency', prob=0.004764556884765625, logit=9.8359375, token_id=11667)), 1511: (1868, PredictedToken(token=' used', prob=3.528594970703125e-05, logit=4.9296875, token_id=1511))}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' chemical', prob=0.073974609375, logit=12.578125, token_id=11742),\n",
       "  PredictedToken(token=' metal', prob=0.072265625, logit=12.5546875, token_id=9501),\n",
       "  PredictedToken(token=' precious', prob=0.052032470703125, logit=12.2265625, token_id=27498),\n",
       "  PredictedToken(token=' yellow', prob=0.04022216796875, logit=11.96875, token_id=14071),\n",
       "  PredictedToken(token=' mineral', prob=0.036041259765625, logit=11.859375, token_id=25107),\n",
       "  PredictedToken(token=' type', prob=0.0230865478515625, logit=11.4140625, token_id=955),\n",
       "  PredictedToken(token=' person', prob=0.0184173583984375, logit=11.1875, token_id=1732),\n",
       "  PredictedToken(token=' gold', prob=0.015869140625, logit=11.0390625, token_id=6761),\n",
       "  PredictedToken(token=' symbol', prob=0.0144500732421875, logit=10.9453125, token_id=7891),\n",
       "  PredictedToken(token=' rare', prob=0.01357269287109375, logit=10.8828125, token_id=9024),\n",
       "  PredictedToken(token=' metallic', prob=0.01336669921875, logit=10.8671875, token_id=46258),\n",
       "  PredictedToken(token=' noble', prob=0.0125579833984375, logit=10.8046875, token_id=35482),\n",
       "  PredictedToken(token=' very', prob=0.0117034912109375, logit=10.734375, token_id=1633),\n",
       "  PredictedToken(token=' coin', prob=0.00970458984375, logit=10.546875, token_id=16652),\n",
       "  PredictedToken(token=' non', prob=0.00925445556640625, logit=10.5, token_id=2536)]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=single_probing_prompt.format(entities[1], entities[1]),\n",
    ")\n",
    "\n",
    "print(gen)\n",
    "\n",
    "pred, track_ans = predict_next_token(\n",
    "    mt=mt,\n",
    "    inputs=single_probing_prompt.format(entities[1], entities[1]),\n",
    "    k=15,\n",
    "    token_of_interest=[clean_pred[0][0].token_id] + interesting_tokens,\n",
    ")\n",
    "\n",
    "print(track_ans)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-18 15:01:13 __main__ INFO     len(coincidences['examples'])=20\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"coincidences_sample.json\")) as f:\n",
    "    coincidences = json.load(f)\n",
    "\n",
    "logger.info(f\"{len(coincidences['examples'])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
