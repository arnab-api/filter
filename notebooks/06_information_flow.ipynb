{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f062e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dfb60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:20:50 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:20:50 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100-SXM4-80GB'\n",
      "2025-06-26 12:20:50 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01326663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:20:52 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-06-26 12:20:52 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-06-26 12:20:52 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-06-26 12:20:52 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90623b2a",
   "metadata": {},
   "source": [
    "## Load the LM and Fuse the $\\Delta$ update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdd7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"BNB_CUDA_VERSION\"] = \"124\"\n",
    "# ! echo $BNB_CUDA_VERSION\n",
    "# ! python -m bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4be1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:20:52 src.models WARNING  meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-06-26 12:20:52 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:20:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-06-26 12:20:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [00:23<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:21:18 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:21:19 src.models INFO     loaded model <meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbadb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainable_params.pt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0010, dtype=torch.bfloat16, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import free_gpu_cache\n",
    "\n",
    "# SYNTH_DATASET = \"icosahedron_1\"\n",
    "SYNTH_DATASET = \"test_72\"\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"trained_params\",\n",
    "    f\"{SYNTH_DATASET}\",\n",
    "    \"_full__clamp=0.001\",\n",
    "    model_key.split(\"/\")[-1],\n",
    ")\n",
    "\n",
    "version = \"epoch_1\"\n",
    "# version = \"final_model\"\n",
    "\n",
    "checkpoint_path = os.path.join(env_utils.DEFAULT_RESULTS_DIR, checkpoint_path, version)\n",
    "\n",
    "print(os.listdir(checkpoint_path))\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"trainable_params.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "# loaded_deltas\n",
    "\n",
    "free_gpu_cache()\n",
    "\n",
    "\n",
    "d = loaded_deltas[\"model<>layers<>10<>mlp<>gate_proj\"]\n",
    "d.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06735ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:29 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:30 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-06-26 12:21:31 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "#################################################\n",
    "Trainable_CLS = TrainableLM_delta\n",
    "# Trainable_CLS = TrainableLM_LoRA\n",
    "#################################################\n",
    "\n",
    "Trainable_CLS.fuse_with_model(mt._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455fed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c31929a",
   "metadata": {},
   "source": [
    "## Loading the Analysis Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6e182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => Sophie Evans | James Mitchell => \" University\" | <-- | Mohammad Aziz => \" Lawyer\"\n",
      "1 => Mohammad Aziz | Fatima Sheikh => \" Pakistani\" | <-- | Sophie Evans => \" Lawyer\"\n",
      "2 => Ali Rezaei | Zahra Hosseini => \" Iranian\" | <-- | João Silva => \" Phys\"\n",
      "3 => Rahman Ali | Nasreen Begum => \" Bangladesh\" | <-- | Takeshi Yamamoto => \" Civil\"\n",
      "4 => Anna Schmidt | Hans Mueller => \" German\" | <-- | Yuki Tanaka => \" Marketing\"\n",
      "5 => Yuki Tanaka | Takeshi Yamamoto => \" Japanese\" | <-- | Anna Schmidt => \" Marketing\"\n",
      "6 => Ayse Kaya | Mehmet Yilmaz => \" Turkish\" | <-- | Hans Mueller => \" Economist\"\n",
      "7 => Priya Patel | Rajesh Kumar => \" Indian\" | <-- | Sofia Hernandez => \" Graphic\"\n",
      "8 => Sofia Hernandez | Carlos Rodriguez => \" Mexican\" | <-- | Priya Patel => \" Graphic\"\n",
      "9 => Siriporn Suwannarat | Somchai Jaidee => \" Thai\" | <-- | Marie Laurent => \" Nutrition\"\n",
      "10 => Marie Laurent | Pierre Dubois => \" French\" | <-- | Siriporn Suwannarat => \" Nutrition\"\n",
      "11 => Zahra Hosseini | Ali Rezaei => \" Iranian\" | <-- | Ahmed Hassan => \" Pilot\"\n",
      "12 => Ahmed Hassan | Layla Mahmoud => \" Egyptian\" | <-- | Zahra Hosseini => \" Pilot\"\n",
      "13 => Kwame Mensah | Maria Santos => \" Doctor\" | <-- | Min-jun Park => \" Ge\"\n",
      "14 => Min-jun Park | Ji-woo Kim => \" Korean\" | <-- | Kwame Mensah => \" Ge\"\n",
      "15 => Tran Thi Mai | Nguyen Van Duc => \" Vietnamese\" | <-- | Marco Rossi => \" Architect\"\n",
      "16 => Marco Rossi | Giulia Romano => \" Italian\" | <-- | Tran Thi Mai => \" Architect\"\n",
      "17 => Diego Martinez | Valentina Lopez => \" Argentine\" | <-- | Michael Johnson => \" Music\"\n",
      "18 => Valentina Lopez | Diego Martinez => \" Argentine\" | <-- | Natasha Ivanova => \" Pharm\"\n",
      "19 => Rachel Levy | David Cohen => \" Israeli\" | <-- | Mehmet Yilmaz => \" Interior\"\n",
      "20 => Mehmet Yilmaz | Ayse Kaya => \" Turkish\" | <-- | Rachel Levy => \" Interior\"\n",
      "21 => Somchai Jaidee | Siriporn Suwannarat => \" Thai\" | <-- | Jan de Vries => \" Psych\"\n",
      "22 => Alexandru Popescu | Elena Ionescu => \" University\" | <-- | David Thompson => \" Environmental\"\n",
      "23 => David Thompson | Diego Martinez => \" Princeton\" | <-- | Alexandru Popescu => \" Environmental\"\n",
      "24 => Youssef Benali | Fatima Alaoui => \" Moroccan\" | <-- | Sarah MacDonald => \" Occupational\"\n",
      "25 => António Costa | Isabel Ferreira => \" Portuguese\" | <-- | Jack Wilson => \" Software\"\n",
      "26 => Elena Georgiou | Dimitris Papadopoulos => \" Greek\" | <-- | Emma Taylor => \" Professor\"\n",
      "27 => Maria dela Rosa | Jose Cruz => \" Filipino\" | <-- | Rodrigo Gonzalez => \" Mechanical\"\n",
      "28 => James Mitchell | Sophie Evans => \" University\" | <-- | Jennifer Davis => \" Journal\"\n",
      "29 => Jennifer Davis | Mohammad Aziz => \" University\" | <-- | James Mitchell => \" Journal\"\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "target_attribute = \"profession\"\n",
    "# target_attribute = \"nationality\"\n",
    "\n",
    "METRIC = \"logit\"\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "from src.dataset import ActivationPatchingSamples\n",
    "\n",
    "activation_patching_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"activation_patching\",\n",
    "    SYNTH_DATASET,\n",
    "    target_attribute,\n",
    ")\n",
    "samples_path = os.path.join(activation_patching_path, \"samples.json\")\n",
    "\n",
    "samples = []\n",
    "with open(samples_path, \"r\") as f:\n",
    "    samples = json.load(f)\n",
    "samples = [ActivationPatchingSamples.from_dict(sample) for sample in samples]\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    print(f\"{idx} => {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "727a2f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Jennifer Davis', 'James Mitchell')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.common_entity, sample.patched_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_and_prof = [\n",
    "    {\n",
    "        \"entity_pair\": [\"William Shakespeare\", \"Christopher Marlowe\"],\n",
    "        \"desc\": \"both William Shakespeare and Christopher Marlowe are playwrights and English\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Leonardo da Vinci\", \"Michelangelo\"],\n",
    "        \"desc\": \"both Leonardo da Vinci and Michelangelo are artists and Italian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Marie Curie\", \"Pierre Curie\"],\n",
    "        \"desc\": \"both Marie Curie and Pierre Curie are physicists and French\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Mark Twain\", \"Ernest Hemingway\"],\n",
    "        \"desc\": \"both Mark Twain and Ernest Hemingway are writers and American\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Albert Einstein\", \"Werner Heisenberg\"],\n",
    "        \"desc\": \"both Albert Einstein and Werner Heisenberg are physicists and German\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Charlie Chaplin\", \"Buster Keaton\"],\n",
    "        \"desc\": \"both Charlie Chaplin and Buster Keaton are actors and British\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Frida Kahlo\", \"Diego Rivera\"],\n",
    "        \"desc\": \"both Frida Kahlo and Diego Rivera are painters and Mexican\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Akira Kurosawa\", \"Yasujiro Ozu\"],\n",
    "        \"desc\": \"both Akira Kurosawa and Yasujiro Ozu are film directors and Japanese\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Victor Hugo\", \"Alexandre Dumas\"],\n",
    "        \"desc\": \"both Victor Hugo and Alexandre Dumas are writers and French\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Confucius\", \"Lao Tzu\"],\n",
    "        \"desc\": \"both Confucius and Lao Tzu are philosophers and Chinese\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Beethoven\", \"Bach\"],\n",
    "        \"desc\": \"both Beethoven and Bach are composers and German\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Plato\", \"Aristotle\"],\n",
    "        \"desc\": \"both Plato and Aristotle are philosophers and Greek\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Charles Darwin\", \"Isaac Newton\"],\n",
    "        \"desc\": \"both Charles Darwin and Isaac Newton are scientists and British\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Rabindranath Tagore\", \"Satyajit Ray\"],\n",
    "        \"desc\": \"both Rabindranath Tagore and Satyajit Ray are artists and Indian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Voltaire\", \"Rousseau\"],\n",
    "        \"desc\": \"both Voltaire and Rousseau are philosophers and French\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Galileo Galilei\", \"Enrico Fermi\"],\n",
    "        \"desc\": \"both Galileo Galilei and Enrico Fermi are physicists and Italian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Anton Chekhov\", \"Leo Tolstoy\"],\n",
    "        \"desc\": \"both Anton Chekhov and Leo Tolstoy are writers and Russian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Pablo Picasso\", \"Salvador Dalí\"],\n",
    "        \"desc\": \"both Pablo Picasso and Salvador Dalí are painters and Spanish\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Thomas Edison\", \"Benjamin Franklin\"],\n",
    "        \"desc\": \"both Thomas Edison and Benjamin Franklin are inventors and American\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Coco Chanel\", \"Christian Dior\"],\n",
    "        \"desc\": \"both Coco Chanel and Christian Dior are fashion designers and French\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prof_diff_nat = [\n",
    "    {\n",
    "        \"entity_pair\": [\"Stephen King\", \"Haruki Murakami\"],\n",
    "        \"desc\": \"both Stephen King (American) and Haruki Murakami (Japanese) are writers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Albert Einstein\", \"Stephen Hawking\"],\n",
    "        \"desc\": \"both Albert Einstein (German) and Stephen Hawking (British) are physicists\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Vincent van Gogh\", \"Frida Kahlo\"],\n",
    "        \"desc\": \"both Vincent van Gogh (Dutch) and Frida Kahlo (Mexican) are painters\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Mozart\", \"Tchaikovsky\"],\n",
    "        \"desc\": \"both Mozart (Austrian) and Tchaikovsky (Russian) are composers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Marie Curie\", \"Rosalind Franklin\"],\n",
    "        \"desc\": \"both Marie Curie (Polish/French) and Rosalind Franklin (British) are scientists\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Alfred Hitchcock\", \"Akira Kurosawa\"],\n",
    "        \"desc\": \"both Alfred Hitchcock (British) and Akira Kurosawa (Japanese) are film directors\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Socrates\", \"Confucius\"],\n",
    "        \"desc\": \"both Socrates (Greek) and Confucius (Chinese) are philosophers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Meryl Streep\", \"Sophia Loren\"],\n",
    "        \"desc\": \"both Meryl Streep (American) and Sophia Loren (Italian) are actresses\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Gabriel García Márquez\", \"Charles Dickens\"],\n",
    "        \"desc\": \"both Gabriel García Márquez (Colombian) and Charles Dickens (British) are writers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Pelé\", \"Diego Maradona\"],\n",
    "        \"desc\": \"both Pelé (Brazilian) and Diego Maradona (Argentinian) are footballers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Frank Lloyd Wright\", \"Le Corbusier\"],\n",
    "        \"desc\": \"both Frank Lloyd Wright (American) and Le Corbusier (Swiss-French) are architects\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Nikola Tesla\", \"Thomas Edison\"],\n",
    "        \"desc\": \"both Nikola Tesla (Serbian-American) and Thomas Edison (American) are inventors\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Sigmund Freud\", \"Carl Jung\"],\n",
    "        \"desc\": \"both Sigmund Freud (Austrian) and Carl Jung (Swiss) are psychologists\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Andy Warhol\", \"Banksy\"],\n",
    "        \"desc\": \"both Andy Warhol (American) and Banksy (British) are artists\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Cristiano Ronaldo\", \"Lionel Messi\"],\n",
    "        \"desc\": \"both Cristiano Ronaldo (Portuguese) and Lionel Messi (Argentinian) are footballers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Beethoven\", \"Chopin\"],\n",
    "        \"desc\": \"both Beethoven (German) and Chopin (Polish) are composers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Audrey Hepburn\", \"Marilyn Monroe\"],\n",
    "        \"desc\": \"both Audrey Hepburn (British) and Marilyn Monroe (American) are actresses\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Immanuel Kant\", \"René Descartes\"],\n",
    "        \"desc\": \"both Immanuel Kant (German) and René Descartes (French) are philosophers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Virginia Woolf\", \"Jane Austen\"],\n",
    "        \"desc\": \"both Virginia Woolf (British) and Jane Austen (British) are writers\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Claude Monet\", \"Pablo Picasso\"],\n",
    "        \"desc\": \"both Claude Monet (French) and Pablo Picasso (Spanish) are painters\",\n",
    "    },\n",
    "]\n",
    "\n",
    "nat_diff_prof = [\n",
    "    {\n",
    "        \"entity_pair\": [\"Albert Einstein\", \"Steven Spielberg\"],\n",
    "        \"desc\": \"both Albert Einstein (physicist) and Steven Spielberg (film director) are American\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Winston Churchill\", \"The Beatles\"],\n",
    "        \"desc\": \"both Winston Churchill (politician) and The Beatles (musicians) are British\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Napoleon Bonaparte\", \"Claude Monet\"],\n",
    "        \"desc\": \"both Napoleon Bonaparte (military leader) and Claude Monet (painter) are French\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Mahatma Gandhi\", \"A.R. Rahman\"],\n",
    "        \"desc\": \"both Mahatma Gandhi (political leader) and A.R. Rahman (composer) are Indian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Vladimir Putin\", \"Fyodor Dostoevsky\"],\n",
    "        \"desc\": \"both Vladimir Putin (politician) and Fyodor Dostoevsky (writer) are Russian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Bruce Lee\", \"Jackie Chan\"],\n",
    "        \"desc\": \"both Bruce Lee (martial artist) and Jackie Chan (actor) are Chinese\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Pelé\", \"Paulo Coelho\"],\n",
    "        \"desc\": \"both Pelé (footballer) and Paulo Coelho (writer) are Brazilian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Angela Merkel\", \"Karl Lagerfeld\"],\n",
    "        \"desc\": \"both Angela Merkel (politician) and Karl Lagerfeld (fashion designer) are German\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Hirohito\", \"Hayao Miyazaki\"],\n",
    "        \"desc\": \"both Hirohito (emperor) and Hayao Miyazaki (animator) are Japanese\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Eva Perón\", \"Jorge Luis Borges\"],\n",
    "        \"desc\": \"both Eva Perón (political figure) and Jorge Luis Borges (writer) are Argentinian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Cleopatra\", \"Mohamed Salah\"],\n",
    "        \"desc\": \"both Cleopatra (queen) and Mohamed Salah (footballer) are Egyptian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Socrates\", \"Maria Callas\"],\n",
    "        \"desc\": \"both Socrates (philosopher) and Maria Callas (opera singer) are Greek\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Julius Caesar\", \"Federico Fellini\"],\n",
    "        \"desc\": \"both Julius Caesar (military leader) and Federico Fellini (film director) are Italian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Queen Elizabeth II\", \"Stephen Hawking\"],\n",
    "        \"desc\": \"both Queen Elizabeth II (monarch) and Stephen Hawking (physicist) are British\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Abraham Lincoln\", \"Michael Jordan\"],\n",
    "        \"desc\": \"both Abraham Lincoln (president) and Michael Jordan (basketball player) are American\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Charles de Gaulle\", \"Coco Chanel\"],\n",
    "        \"desc\": \"both Charles de Gaulle (president) and Coco Chanel (fashion designer) are French\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Mao Zedong\", \"Yao Ming\"],\n",
    "        \"desc\": \"both Mao Zedong (political leader) and Yao Ming (basketball player) are Chinese\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Nelson Mandela\", \"Charlize Theron\"],\n",
    "        \"desc\": \"both Nelson Mandela (political leader) and Charlize Theron (actress) are South African\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"Simón Bolívar\", \"Shakira\"],\n",
    "        \"desc\": \"both Simón Bolívar (military leader) and Shakira (singer) are Colombian\",\n",
    "    },\n",
    "    {\n",
    "        \"entity_pair\": [\"King Juan Carlos I\", \"Rafael Nadal\"],\n",
    "        \"desc\": \"both King Juan Carlos I (monarch) and Rafael Nadal (tennis player) are Spanish\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0dbd3dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 18:28:29 src.utils.experiment_utils INFO     setting all seeds to 142\n",
      "# Task: Find Common Attributes Between Two People\n",
      "You will be given two people's names. Your job is to determine if they share ANY common attribute from the list below.\n",
      "\n",
      "## Response Format:\n",
      "- If you find a match: \"Yes - [shared entity] - [description of what they share]\"\n",
      "- If no match: \"No - [Person 1] and [Person 2] have nothing in common\"\n",
      "\n",
      "## Attributes to Consider:\n",
      "1. Same profession → \"Yes - [profession] - they are both [profession]\"\n",
      "2. Same nationality → \"Yes - [nationality] - they are both [nationality]\"\n",
      "3. Same school → \"Yes - [school] - they both graduated from [school]\"\n",
      "\n",
      "Q: Person E and Person F\n",
      "A: Yes - Boston University - they both graduated from Boston University.\n",
      "\n",
      "Q: Person A and Person B\n",
      "A: Yes - German - they are both German.\n",
      "\n",
      "Q: Person C and Person D\n",
      "A: Yes - Doctor - they are both doctors.\n",
      "\n",
      "Q: Person W and Person X\n",
      "A: No - Person W and Person X have nothing in common.\n",
      "\n",
      "## Your turn, give your answer in a single line.\n"
     ]
    }
   ],
   "source": [
    "from src.probing.prompt import BiAssociationPrefix\n",
    "from src.utils.experiment_utils import set_seed\n",
    "\n",
    "prefix_generator_cls = BiAssociationPrefix\n",
    "\n",
    "prefix_generator = prefix_generator_cls(\n",
    "    # instruction=few_shot_examples.instruction,\n",
    "    # positive_connections=few_shot_examples.positive_examples,\n",
    "    # negative_connections=few_shot_examples.negative_examples,\n",
    "    filter_attributes=[\n",
    "        \"profession\",\n",
    "        \"nationality\",\n",
    "        \"school\"\n",
    "    ],\n",
    "    format=\"_3\",\n",
    ")\n",
    "\n",
    "set_seed(142)\n",
    "prefix = prefix_generator.get_prefix(\n",
    "    n_valid=10,\n",
    "    n_none=1,\n",
    ")\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a1c17b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Spanish - they are both Spanish.\"\n",
      "['Pablo Picasso', 'Salvador Dalí'] | => \" Spanish\"[15506] (p=0.992, logit=25.500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Spanish', prob=0.9921875, logit=25.5, token_id=15506, metadata=None),\n",
       " PredictedToken(token=' Artist', prob=0.0027923583984375, logit=19.625, token_id=29459, metadata=None),\n",
       " PredictedToken(token=' Span', prob=0.0010223388671875, logit=18.625, token_id=12168, metadata=None),\n",
       " PredictedToken(token=' Spain', prob=0.000797271728515625, logit=18.375, token_id=18157, metadata=None),\n",
       " PredictedToken(token=' nationality', prob=0.000705718994140625, logit=18.25, token_id=59343, metadata=None),\n",
       " PredictedToken(token=' spanish', prob=0.000377655029296875, logit=17.625, token_id=78132, metadata=None),\n",
       " PredictedToken(token=' Painter', prob=0.000293731689453125, logit=17.375, token_id=97864, metadata=None),\n",
       " PredictedToken(token=' artist', prob=0.0002593994140625, logit=17.25, token_id=10255, metadata=None),\n",
       " PredictedToken(token=' Doctor', prob=0.000202178955078125, logit=17.0, token_id=19150, metadata=None),\n",
       " PredictedToken(token=' National', prob=0.0001392364501953125, logit=16.625, token_id=5165, metadata=None),\n",
       " PredictedToken(token=' School', prob=0.00010824203491210938, logit=16.375, token_id=6150, metadata=None),\n",
       " PredictedToken(token=' Art', prob=9.5367431640625e-05, logit=16.25, token_id=5277, metadata=None),\n",
       " PredictedToken(token=' Barcelona', prob=6.961822509765625e-05, logit=15.9375, token_id=28035, metadata=None),\n",
       " PredictedToken(token=' painter', prob=6.580352783203125e-05, logit=15.875, token_id=30581, metadata=None),\n",
       " PredictedToken(token=' University', prob=4.2438507080078125e-05, logit=15.4375, token_id=3907, metadata=None)]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.probing.prompt import prepare_probing_input\n",
    "from src.functional import predict_next_token, interpret_logits\n",
    "from src.utils.typing import TokenizerOutput\n",
    "from src.functional import get_hs\n",
    "import itertools\n",
    "from src.functional import generate_with_patch\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "METRIC = \"logit\"\n",
    "###############################################################################\n",
    "\n",
    "# Real Entities\n",
    "# query_entities = [\"Taylor Swift\", \"Bill Gates\"]\n",
    "# query_entities = [\"Issac Newton\", \"Charles Darwin\"]\n",
    "# query_entities = [\"Jon Stewart\", \"Rowan Atkinson\"]\n",
    "# query_entities = (\"John F. Kennedy\", \"Michael Jordan\")\n",
    "# query_entities = [\"Elton John\", \"John Lennon\"]\n",
    "# query_entities = [\"David Bowie\", \"Elvis Presley\"]\n",
    "# query_entities = [\"Christiano Ronaldo\", \"Rowan Atkinson\"]\n",
    "# query_entities = [\"Jack Ma\", \"Hayao Miyazaki\"] #! interesting failure case. the model changes the rep of \"Miyazaki\" to pull out enterpreneur.\n",
    "# query_entities = [\"Claude Monet\", \"Leonardo da Vinci\"]\n",
    "# query_entities = [\"Claude Monet\", \"Zinedine Zidane\"]\n",
    "# query_entities = [\"Zinedine Zidane\", \"Claude Monet\"]\n",
    "# query_entities = [\"Zinedine Zidane\", \"Thierry Henry\"]\n",
    "# query_entities = [\"Richard Feynman\", \"J. Robert Oppenheimer\"]\n",
    "# query_entities = [\"Victor Hugo\", \"Alexandre Dumas\"]\n",
    "# query_entities = [\"Marie Curie\", \"Issac Newton\"]\n",
    "# query_entities = [\"Alfred Hitchcock\", \"Akira Kurosawa\"]\n",
    "# query_entities = [\"William Shakespeare\", \"Christopher Marlowe\"]\n",
    "# query_entities = [\"Antonio Vivaldi\", \"Chopin\"]\n",
    "# query_entities = [\"Masayoshi Son\", \"Jack Ma\"]\n",
    "# query_entities = [\"John F. Kennedy\", \"Indira Gandhi\"]\n",
    "# query_entities = [\"Michael Jordan\", \"Sachin Tendulkar\"]\n",
    "# query_entities = [\"John F. Kennedy\", \"Natalie Portman\"]\n",
    "# query_entities = [\"Pelé\", \"Paulo Coelho\"]\n",
    "# query_entities = [\"Abraham Lincoln\", \"Michael Jordan\"]\n",
    "# query_entities = [\"Thomas Edison\", \"Benjamin Franklin\"]\n",
    "\n",
    "##! Real entities with same salient attribute\n",
    "# query_entities = [\"Coco Chanel\", \"Christian Dior\"] # {french, fashion designer}\n",
    "# query_entities = [\"Albert Einstein\", \"Issac Newton\"] # {physicist}\n",
    "# query_entities = [\"Hugh Jackman\", \"Ryan Reynolds\"] # {actor}\n",
    "# query_entities = [\"Cristiano Ronaldo\", \"Lionel Messi\"] # {footballer}\n",
    "# query_entities = [\"Sachin Tendulkar\", \"Rickie Ponting\"] # {cricketer}\n",
    "# query_entities = [\"Pablo Picasso\", \"Frida Kahlo\"] # {artist}\n",
    "# query_entities = [\"Taylor Swift\", \"Bruno Mars\"] # {singer, American}\n",
    "# query_entities = [\"Mads Mikkelsen\", \"Nikolaj Coster-Waldau\"] # {actor, Danish}\n",
    "# query_entities = [\"Sachin Tendulkar\", \"Rahul Dravid\"] # {cricketer, Indian}\n",
    "# query_entities = [\"Bill Gates\", \"Steve Jobs\"] # {entrepreneur, American}\n",
    "# query_entities = [\"Beethoven\", \"Chopin\"] # {composer}\n",
    "# query_entities = [\"Zinedine Zidane\", \"Thierry Henry\"] # {footballer, French}\n",
    "# query_entities = [\"Abraham Lincoln\", \"George Washington\"] # {politician, American}\n",
    "# query_entities = [\"Eric Schmidt\", \"Bill Bradley\"] # {princeton}\n",
    "# query_entities = [\"Jason Garrett\", \"Steve Forbes\"] # {princeton, American}\n",
    "# query_entities = [\"Ian McKellen\", \"Patrick Stewart\"] # {actor, British}\n",
    "query_entities = [\"Pablo Picasso\", \"Salvador Dalí\"] # {artist, Spanish}\n",
    "\n",
    "##! Superset\n",
    "# query_entities = [\"Albert Einstein\", \"Marie Curie\"]          #! {physicist, chemist} => scientist\n",
    "# query_entities = [\"Cristiano Ronaldo\", \"Sachin Tendulkar\"] #! {football, cricket} => athelete\n",
    "# query_entities = [\"Leonardo da Vinci\", \"Benjamin Franklin\"] #! superset => inventor\n",
    "# query_entities = [\"Maya Angelou\", \"George Orwell\"]  #! {poet, novelist} => writer\n",
    "# query_entities = [\"Ansel Adams\", \"Auguste Rodin\"] #! {photographer, sculptor} => artist\n",
    "# query_entities = [\"Tico Torres\", \"Ludwig van Beethoven\"] #! {drummer, classical composer} => musician\n",
    "# query_entities = [\"Neil Armstrong\", \"Edmund Hillary\"]   #! {astronaut, mountaineer} => explorer\n",
    "# query_entities = [\"Charles Darwin\", \"Isaac Newton\"] #! {biologist, physicist} => scientist\n",
    "\n",
    "##! Synthetic Entities\n",
    "# sample = samples[13]\n",
    "# print(f\"{sample}\")\n",
    "# query_entities = (sample.common_entity, sample.patched_entity)\n",
    "\n",
    "# Real Entity + Synthetic Entity\n",
    "# query_entities = (\"Lionel Messi\", sample.patched_entity)\n",
    "# query_entities = (\"William Shakespeare\", sample.common_entity)\n",
    "\n",
    "##! Real Entities(different salient attributes)\n",
    "# query_entities = (\"William Shakespeare\", \"Leonardo da Vinci\")\n",
    "# query_entities = (\"Marie Curie\", \"Cristiano Ronaldo\")\n",
    "# query_entities = (\"Jack Ma\", \"Johnny Depp\")\n",
    "# query_entities = (\"Albert Einstein\", \"Emma Watson\")\n",
    "# query_entities = (\"Michael Jackson\", \"Marie Curie\")\n",
    "# query_entities = [\"Cristiano Ronaldo\", \"Benjamin Franklin\"]\n",
    "# query_entities = [\"Lionel Messi\", \"Benjamin Franklin\"]\n",
    "\n",
    "##! 1 salient attribute, 1 non-salient attribute\n",
    "# query_entities = (\"Issac Newton\", \"Elara Vance\")\n",
    "# query_entities = (\"Sachin Tendulkar\", \"Declan Rivers\")\n",
    "# query_entities = (\"Barack Obama\", \"Declan Rivers\")\n",
    "# query_entities = (\"Barack Obama\", \"Briony Shaw\")\n",
    "\n",
    "\n",
    "# query_entities = (query_entities[1], query_entities[0])\n",
    "\n",
    "probing_input = prepare_probing_input(\n",
    "    mt=mt,\n",
    "    entities=query_entities,\n",
    "    prefix=prefix,\n",
    "    answer_marker=prefix_generator.answer_marker,\n",
    "    question_marker=prefix_generator.question_marker,\n",
    "    block_separator=prefix_generator.block_separator,\n",
    "    is_a_reasoning_model=False,\n",
    "    answer_prefix=\" Yes -\",\n",
    ")\n",
    "\n",
    "answer = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "    n_gen_per_prompt=1,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False,\n",
    "    patches=[],\n",
    "    patch_strategy=\"replace\",\n",
    "    remove_prefix=True,\n",
    "    patch_at_all_generations=False,  # don't need to\n",
    "    # patch_at_all_generations=True,    # will give the same result\n",
    "    # use_cache = False,\n",
    ")\n",
    "print(f'\"{answer[0]}\"')\n",
    "\n",
    "resid_layers = mt.layer_names\n",
    "token_positions = (\n",
    "    list(range(*probing_input.entity_ranges[0]))\n",
    "    + list(range(*probing_input.entity_ranges[1]))\n",
    "    + [-1]\n",
    ")\n",
    "locations = list(itertools.product(resid_layers, token_positions))\n",
    "locations += [(mt.lm_head_name, -1)]\n",
    "\n",
    "hs = get_hs(\n",
    "    mt=mt,\n",
    "    input=TokenizerOutput(data=probing_input.tokenized),\n",
    "    locations=locations,\n",
    ")\n",
    "logits = hs[(mt.lm_head_name, -1)]\n",
    "next_probs = interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=logits,\n",
    "    k=15,\n",
    ")\n",
    "\n",
    "print(f\"{query_entities} | => {next_probs[0]}\")\n",
    "\n",
    "next_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "61f94c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neil Armstrong => \" astronaut\"[47733] (p=0.996, logit=24.375)\n",
      "Edmund Hillary => \" mount\"[6606] (p=0.762, logit=22.750)\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Name of a person -> their profession\n",
    "Albert Einstein -> physicist\n",
    "Michael Jordan -> basketball player\n",
    "Jack Ma -> entrepreneur\n",
    "placeholder ->\"\"\"\n",
    "\n",
    "track_toks = []\n",
    "\n",
    "for entity in query_entities:\n",
    "    context_subj = context.replace(\"placeholder\", entity)\n",
    "    top_pred = predict_next_token(mt=mt, inputs=context_subj)[0][0]\n",
    "    print(f\"{entity} => {top_pred}\")\n",
    "    track_toks.append(top_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983eac1",
   "metadata": {},
   "source": [
    "## Checking presence of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1fa8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import get_hs\n",
    "import itertools\n",
    "\n",
    "resid_layers = mt.layer_names\n",
    "token_positions = (\n",
    "    list(range(*probing_input.entity_ranges[0]))\n",
    "    + list(range(*probing_input.entity_ranges[1]))\n",
    "    + [-1]\n",
    ")\n",
    "locations = list(itertools.product(resid_layers, token_positions))\n",
    "\n",
    "hs = get_hs(\n",
    "    mt=mt,\n",
    "    input=TokenizerOutput(data=probing_input.tokenized),\n",
    "    locations=locations,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4c446",
   "metadata": {},
   "source": [
    "#### Projection + Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5aac6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators.operators import BasisOperator, Basis\n",
    "import baukit\n",
    "\n",
    "nationalities = [\n",
    "    \"Afghan\",\n",
    "    \"Albanian\",\n",
    "    \"Algerian\",\n",
    "    \"American\",\n",
    "    \"Andorran\",\n",
    "    \"Angolan\",\n",
    "    \"Argentine\",\n",
    "    \"Armenian\",\n",
    "    \"Australian\",\n",
    "    \"Austrian\",\n",
    "    \"Azerbaijani\",\n",
    "    \"Bahamian\",\n",
    "    \"Bahraini\",\n",
    "    \"Bangladeshi\",\n",
    "    \"Barbadian\",\n",
    "    \"Belarusian\",\n",
    "    \"Belgian\",\n",
    "    \"Belizean\",\n",
    "    \"Beninese\",\n",
    "    \"Bhutanese\",\n",
    "    \"Bolivian\",\n",
    "    \"Bosnian\",\n",
    "    \"Brazilian\",\n",
    "    \"British\",\n",
    "    \"Bruneian\",\n",
    "    \"Bulgarian\",\n",
    "    \"Burkinabe\",\n",
    "    \"Burmese\",\n",
    "    \"Burundian\",\n",
    "    \"Cambodian\",\n",
    "    \"Cameroonian\",\n",
    "    \"Canadian\",\n",
    "    \"Cape Verdean\",\n",
    "    \"Central African\",\n",
    "    \"Chadian\",\n",
    "    \"Chilean\",\n",
    "    \"Chinese\",\n",
    "    \"Colombian\",\n",
    "    \"Comorian\",\n",
    "    \"Congolese\",\n",
    "    \"Costa Rican\",\n",
    "    \"Croatian\",\n",
    "    \"Cuban\",\n",
    "    \"Cypriot\",\n",
    "    \"Czech\",\n",
    "    \"Danish\",\n",
    "    \"Djiboutian\",\n",
    "    \"Dominican\",\n",
    "    \"Dutch\",\n",
    "    \"East Timorese\",\n",
    "    \"Ecuadorian\",\n",
    "    \"Egyptian\",\n",
    "    \"Emirati\",\n",
    "    \"Equatorial Guinean\",\n",
    "    \"Eritrean\",\n",
    "    \"Estonian\",\n",
    "    \"Ethiopian\",\n",
    "    \"Fijian\",\n",
    "    \"Filipino\",\n",
    "    \"Finnish\",\n",
    "    \"French\",\n",
    "    \"Gabonese\",\n",
    "    \"Gambian\",\n",
    "    \"Georgian\",\n",
    "    \"German\",\n",
    "    \"Ghanaian\",\n",
    "    \"Greek\",\n",
    "    \"Grenadian\",\n",
    "    \"Guatemalan\",\n",
    "    \"Guinean\",\n",
    "    \"Guinea-Bissauan\",\n",
    "    \"Guyanese\",\n",
    "    \"Haitian\",\n",
    "    \"Honduran\",\n",
    "    \"Hungarian\",\n",
    "    \"Icelandic\",\n",
    "    \"Indian\",\n",
    "    \"Indonesian\",\n",
    "    \"Iranian\",\n",
    "    \"Iraqi\",\n",
    "    \"Irish\",\n",
    "    \"Israeli\",\n",
    "    \"Italian\",\n",
    "    \"Ivorian\",\n",
    "    \"Jamaican\",\n",
    "    \"Japanese\",\n",
    "    \"Jordanian\",\n",
    "    \"Kazakh\",\n",
    "    \"Kenyan\",\n",
    "    \"Kiribati\",\n",
    "    \"Korean\",\n",
    "    \"Kosovar\",\n",
    "    \"Kuwaiti\",\n",
    "    \"Kyrgyz\",\n",
    "    \"Laotian\",\n",
    "    \"Latvian\",\n",
    "    \"Lebanese\",\n",
    "    \"Liberian\",\n",
    "    \"Libyan\",\n",
    "    \"Liechtensteiner\",\n",
    "    \"Lithuanian\",\n",
    "    \"Luxembourger\",\n",
    "    \"Macedonian\",\n",
    "    \"Malagasy\",\n",
    "    \"Malawian\",\n",
    "    \"Malaysian\",\n",
    "    \"Maldivian\",\n",
    "    \"Malian\",\n",
    "    \"Maltese\",\n",
    "    \"Marshallese\",\n",
    "    \"Mauritanian\",\n",
    "    \"Mauritian\",\n",
    "    \"Mexican\",\n",
    "    \"Micronesian\",\n",
    "    \"Moldovan\",\n",
    "    \"Monacan\",\n",
    "    \"Mongolian\",\n",
    "    \"Montenegrin\",\n",
    "    \"Moroccan\",\n",
    "    \"Mozambican\",\n",
    "    \"Namibian\",\n",
    "    \"Nauruan\",\n",
    "    \"Nepalese\",\n",
    "    \"New Zealander\",\n",
    "    \"Nicaraguan\",\n",
    "    \"Nigerian\",\n",
    "    \"Nigerien\",\n",
    "    \"Norwegian\",\n",
    "    \"Omani\",\n",
    "    \"Pakistani\",\n",
    "    \"Palauan\",\n",
    "    \"Palestinian\",\n",
    "    \"Panamanian\",\n",
    "    \"Papua New Guinean\",\n",
    "    \"Paraguayan\",\n",
    "    \"Peruvian\",\n",
    "    \"Polish\",\n",
    "    \"Portuguese\",\n",
    "    \"Qatari\",\n",
    "    \"Romanian\",\n",
    "    \"Russian\",\n",
    "    \"Rwandan\",\n",
    "    \"Saint Lucian\",\n",
    "    \"Salvadoran\",\n",
    "    \"Samoan\",\n",
    "    \"San Marinese\",\n",
    "    \"Sao Tomean\",\n",
    "    \"Saudi\",\n",
    "    \"Senegalese\",\n",
    "    \"Serbian\",\n",
    "    \"Seychellois\",\n",
    "    \"Sierra Leonean\",\n",
    "    \"Singaporean\",\n",
    "    \"Slovak\",\n",
    "    \"Slovenian\",\n",
    "    \"Solomon Islander\",\n",
    "    \"Somali\",\n",
    "    \"South African\",\n",
    "    \"South Sudanese\",\n",
    "    \"Spanish\",\n",
    "    \"Sri Lankan\",\n",
    "    \"Sudanese\",\n",
    "    \"Surinamese\",\n",
    "    \"Swazi\",\n",
    "    \"Swedish\",\n",
    "    \"Swiss\",\n",
    "    \"Syrian\",\n",
    "    \"Taiwanese\",\n",
    "    \"Tajik\",\n",
    "    \"Tanzanian\",\n",
    "    \"Thai\",\n",
    "    \"Togolese\",\n",
    "    \"Tongan\",\n",
    "    \"Trinidadian\",\n",
    "    \"Tunisian\",\n",
    "    \"Turkish\",\n",
    "    \"Turkmen\",\n",
    "    \"Tuvaluan\",\n",
    "    \"Ugandan\",\n",
    "    \"Ukrainian\",\n",
    "    \"Uruguayan\",\n",
    "    \"Uzbek\",\n",
    "    \"Vanuatuan\",\n",
    "    \"Vatican\",\n",
    "    \"Venezuelan\",\n",
    "    \"Vietnamese\",\n",
    "    \"Yemeni\",\n",
    "    \"Zambian\",\n",
    "    \"Zimbabwean\"\n",
    "]\n",
    "professions = [\n",
    "    \"Doctor\",\n",
    "    \"Engineer\",\n",
    "    \"Teacher\",\n",
    "    \"Lawyer\",\n",
    "    \"Nurse\",\n",
    "    \"Architect\",\n",
    "    \"Accountant\",\n",
    "    \"Scientist\",\n",
    "    \"Artist\",\n",
    "    \"Writer\",\n",
    "    \"Musician\",\n",
    "    \"Actor\",\n",
    "    \"Chef\",\n",
    "    \"Photographer\",\n",
    "    \"Journalist\",\n",
    "    \"Police Officer\",\n",
    "    \"Firefighter\",\n",
    "    \"Pilot\",\n",
    "    \"Software Developer\",\n",
    "    \"Dentist\",\n",
    "    \"Psychologist\",\n",
    "    \"Veterinarian\",\n",
    "    \"Pharmacist\",\n",
    "    \"Designer\",\n",
    "    \"Entrepreneur\",\n",
    "    \"Consultant\",\n",
    "    \"Banker\",\n",
    "    \"Real Estate Agent\",\n",
    "    \"Marketing Manager\",\n",
    "    \"Data Analyst\",\n",
    "    \"Electrician\",\n",
    "    \"Plumber\",\n",
    "    \"Mechanic\",\n",
    "    \"Carpenter\",\n",
    "    \"Surgeon\",\n",
    "    \"Professor\",\n",
    "    \"Social Worker\",\n",
    "    \"Therapist\",\n",
    "    \"Translator\",\n",
    "    \"Film Director\",\n",
    "    \"Athlete\",\n",
    "    \"Coach\",\n",
    "    \"Librarian\",\n",
    "    \"Flight Attendant\",\n",
    "    \"Barista\",\n",
    "    \"Hairdresser\",\n",
    "    \"Fashion Designer\",\n",
    "    \"Interior Designer\",\n",
    "    \"Judge\",\n",
    "    \"Paramedic\",\n",
    "    \"Composer\",\n",
    "]\n",
    "\n",
    "professions += [\"Footballer\", \"Writer\", \"President\", \"Lawer\", \"Athlete\", \"Basketball\"]\n",
    "professions = set(professions)  # remove duplicates\n",
    "professions = [p.lower() for p in professions]\n",
    "\n",
    "# concept_zs = [f\" {z}\" for z in professions]\n",
    "concept_zs = [f\" {z}\" for z in nationalities]\n",
    "\n",
    "z_tokens = [mt.tokenizer.encode(c, add_special_tokens=False)[0] for c in concept_zs]\n",
    "lm_head = baukit.get_module(mt._model, \"lm_head\")\n",
    "\n",
    "basis_directions: list[Basis] = []\n",
    "\n",
    "for z_tok in z_tokens:\n",
    "    direction = lm_head.weight[z_tok]\n",
    "    direction = direction / direction.norm()\n",
    "    basis_directions.append(\n",
    "        Basis(\n",
    "            direction=direction,\n",
    "            z=mt.tokenizer.decode(z_tok),\n",
    "            token_idx=z_tok,\n",
    "        )\n",
    "    )\n",
    "\n",
    "basis_operator = BasisOperator(\n",
    "    mt=mt,\n",
    "    concept_directions=basis_directions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "60d9c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 17:59:38 src.operators.operators DEBUG    h.device=device(type='cuda', index=0), self.projection_matrix.device=device(type='cuda', index=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sim': 0.2963072657585144, 'basis': '\" Mal\" (8560)'},\n",
       " {'sim': 0.2963072657585144, 'basis': '\" Mal\" (8560)'},\n",
       " {'sim': 0.2963072657585144, 'basis': '\" Mal\" (8560)'},\n",
       " {'sim': 0.2963072657585144, 'basis': '\" Mal\" (8560)'},\n",
       " {'sim': 0.2963072657585144, 'basis': '\" Mal\" (8560)'},\n",
       " {'sim': 0.1958441436290741, 'basis': '\" Mold\" (55263)'},\n",
       " {'sim': 0.1896655261516571, 'basis': '\" Mic\" (28095)'},\n",
       " {'sim': 0.1608060598373413, 'basis': '\" Sudan\" (43554)'},\n",
       " {'sim': 0.1533057689666748, 'basis': '\" San\" (5960)'},\n",
       " {'sim': 0.14017978310585022, 'basis': '\" Palestinian\" (22596)'},\n",
       " {'sim': 0.13847404718399048, 'basis': '\" South\" (4987)'},\n",
       " {'sim': 0.13847404718399048, 'basis': '\" South\" (4987)'},\n",
       " {'sim': 0.13312660157680511, 'basis': '\" Moz\" (52543)'},\n",
       " {'sim': 0.12276959419250488, 'basis': '\" Pal\" (11165)'},\n",
       " {'sim': 0.12171275913715363, 'basis': '\" Ukrainian\" (34725)'},\n",
       " {'sim': 0.11925402283668518, 'basis': '\" Cape\" (29715)'},\n",
       " {'sim': 0.1182480901479721, 'basis': '\" Bur\" (12649)'},\n",
       " {'sim': 0.1182480901479721, 'basis': '\" Bur\" (12649)'},\n",
       " {'sim': 0.1182480901479721, 'basis': '\" Bur\" (12649)'},\n",
       " {'sim': 0.11344355344772339, 'basis': '\" Sw\" (4593)'},\n",
       " {'sim': 0.113115593791008, 'basis': '\" Ky\" (23727)'},\n",
       " {'sim': 0.11115583777427673, 'basis': '\" Somali\" (85794)'},\n",
       " {'sim': 0.1059594452381134, 'basis': '\" Lat\" (10128)'},\n",
       " {'sim': 0.10493479669094086, 'basis': '\" Em\" (5867)'},\n",
       " {'sim': 0.10040150582790375, 'basis': '\" Per\" (3700)'},\n",
       " {'sim': 0.09910089522600174, 'basis': '\" Cuban\" (44810)'},\n",
       " {'sim': 0.09591537714004517, 'basis': '\" Belarus\" (70606)'},\n",
       " {'sim': 0.09529212862253189, 'basis': '\" Mon\" (3206)'},\n",
       " {'sim': 0.09419451653957367, 'basis': '\" Gab\" (24664)'},\n",
       " {'sim': 0.09335311502218246, 'basis': '\" Ur\" (17229)'},\n",
       " {'sim': 0.08992855250835419, 'basis': '\" N\" (452)'},\n",
       " {'sim': 0.0781707614660263, 'basis': '\" Bol\" (25007)'},\n",
       " {'sim': 0.07811660319566727, 'basis': '\" Lebanese\" (69345)'},\n",
       " {'sim': 0.0776519626379013, 'basis': '\" Van\" (13000)'},\n",
       " {'sim': 0.07356686890125275, 'basis': '\" Ug\" (47430)'},\n",
       " {'sim': 0.07160122692584991, 'basis': '\" Sam\" (8388)'},\n",
       " {'sim': 0.07087703049182892, 'basis': '\" Gu\" (4673)'},\n",
       " {'sim': 0.07087703049182892, 'basis': '\" Gu\" (4673)'},\n",
       " {'sim': 0.06650109589099884, 'basis': '\" New\" (1561)'},\n",
       " {'sim': 0.06563948094844818, 'basis': '\" Swiss\" (30791)'},\n",
       " {'sim': 0.06559209525585175, 'basis': '\" Chinese\" (8620)'},\n",
       " {'sim': 0.06536868214607239, 'basis': '\" Par\" (4366)'},\n",
       " {'sim': 0.06492140889167786, 'basis': '\" Brazilian\" (36083)'},\n",
       " {'sim': 0.06361840665340424, 'basis': '\" Cong\" (7409)'},\n",
       " {'sim': 0.0635320246219635, 'basis': '\" Mont\" (9995)'},\n",
       " {'sim': 0.06293123960494995, 'basis': '\" Zimbabwe\" (52320)'},\n",
       " {'sim': 0.06165600195527077, 'basis': '\" Norwegian\" (45721)'},\n",
       " {'sim': 0.06111587956547737, 'basis': '\" Q\" (1229)'},\n",
       " {'sim': 0.05945369601249695, 'basis': '\" Egyptian\" (33589)'},\n",
       " {'sim': 0.05800158530473709, 'basis': '\" Liber\" (95397)'},\n",
       " {'sim': 0.05694355070590973, 'basis': '\" Yemen\" (33790)'},\n",
       " {'sim': 0.05505834147334099, 'basis': '\" Sur\" (8242)'},\n",
       " {'sim': 0.05446752533316612, 'basis': '\" Ghana\" (48668)'},\n",
       " {'sim': 0.05144067481160164, 'basis': '\" Sen\" (5476)'},\n",
       " {'sim': 0.05069217458367348, 'basis': '\" Indian\" (7904)'},\n",
       " {'sim': 0.049342669546604156, 'basis': '\" Swedish\" (31209)'},\n",
       " {'sim': 0.048775531351566315, 'basis': '\" Niger\" (20992)'},\n",
       " {'sim': 0.048686280846595764, 'basis': '\" Ang\" (7568)'},\n",
       " {'sim': 0.04775330051779747, 'basis': '\" Pan\" (11233)'},\n",
       " {'sim': 0.04109954088926315, 'basis': '\" Irish\" (18088)'},\n",
       " {'sim': 0.03785129636526108, 'basis': '\" Nigerian\" (55433)'},\n",
       " {'sim': 0.037451013922691345, 'basis': '\" Vatican\" (47647)'},\n",
       " {'sim': 0.03695517033338547, 'basis': '\" Br\" (3320)'},\n",
       " {'sim': 0.036269888281822205, 'basis': '\" Vietnamese\" (49577)'},\n",
       " {'sim': 0.03537100553512573, 'basis': '\" Belize\" (98104)'},\n",
       " {'sim': 0.034685440361499786, 'basis': '\" Lux\" (27466)'},\n",
       " {'sim': 0.03275960311293602, 'basis': '\" Singapore\" (21181)'},\n",
       " {'sim': 0.030468488112092018, 'basis': '\" Guinea\" (48903)'},\n",
       " {'sim': 0.027162767946720123, 'basis': '\" Alban\" (57991)'},\n",
       " {'sim': 0.02595360577106476, 'basis': '\" American\" (3778)'},\n",
       " {'sim': 0.02589055523276329, 'basis': '\" Chile\" (34100)'},\n",
       " {'sim': 0.0253213532269001, 'basis': '\" Nam\" (31074)'},\n",
       " {'sim': 0.02531849592924118, 'basis': '\" Nicar\" (67138)'},\n",
       " {'sim': 0.02502734214067459, 'basis': '\" O\" (507)'},\n",
       " {'sim': 0.02216038480401039, 'basis': '\" Mong\" (44539)'},\n",
       " {'sim': 0.02141118235886097, 'basis': '\" Tanz\" (58780)'},\n",
       " {'sim': 0.020802684128284454, 'basis': '\" Maur\" (34492)'},\n",
       " {'sim': 0.020802684128284454, 'basis': '\" Maur\" (34492)'},\n",
       " {'sim': 0.020044896751642227, 'basis': '\" Turkish\" (24666)'},\n",
       " {'sim': 0.018218545243144035, 'basis': '\" Georgian\" (87542)'},\n",
       " {'sim': 0.018012601882219315, 'basis': '\" Hond\" (59215)'},\n",
       " {'sim': 0.017864402383565903, 'basis': '\" Kaz\" (36074)'},\n",
       " {'sim': 0.017633754760026932, 'basis': '\" Tong\" (51491)'},\n",
       " {'sim': 0.017420127987861633, 'basis': '\" East\" (6460)'},\n",
       " {'sim': 0.015036567114293575, 'basis': '\" Hait\" (43502)'},\n",
       " {'sim': 0.013024148531258106, 'basis': '\" Afghan\" (17214)'},\n",
       " {'sim': 0.011340554803609848, 'basis': '\" Ken\" (14594)'},\n",
       " {'sim': 0.010719453915953636, 'basis': '\" Camb\" (34896)'},\n",
       " {'sim': 0.006278709974139929, 'basis': '\" Bulgarian\" (89724)'},\n",
       " {'sim': 0.004861959256231785, 'basis': '\" Taj\" (67799)'},\n",
       " {'sim': 0.0033801570534706116, 'basis': '\" Croatian\" (100170)'},\n",
       " {'sim': 0.003362494520843029, 'basis': '\" Iraqi\" (31334)'},\n",
       " {'sim': 0.0032720044255256653, 'basis': '\" Austrian\" (58069)'},\n",
       " {'sim': 0.003065429162234068, 'basis': '\" Central\" (10913)'},\n",
       " {'sim': 0.002646543551236391, 'basis': '\" Trinidad\" (86230)'},\n",
       " {'sim': 0.002411196008324623, 'basis': '\" Armenian\" (67842)'},\n",
       " {'sim': 0.0022113905288279057, 'basis': '\" British\" (8013)'},\n",
       " {'sim': 0.0019761156290769577, 'basis': '\" Israeli\" (16286)'},\n",
       " {'sim': 0.0011744482908397913, 'basis': '\" Sey\" (58980)'},\n",
       " {'sim': -0.0001752690877765417, 'basis': '\" Sao\" (90972)'},\n",
       " {'sim': -0.001986050046980381, 'basis': '\" Z\" (1901)'},\n",
       " {'sim': -0.0020539104007184505, 'basis': '\" Dj\" (52162)'},\n",
       " {'sim': -0.00258549302816391, 'basis': '\" And\" (1628)'},\n",
       " {'sim': -0.0033261410426348448, 'basis': '\" Danish\" (44780)'},\n",
       " {'sim': -0.0035099927335977554, 'basis': '\" Turk\" (21187)'},\n",
       " {'sim': -0.0040824501775205135, 'basis': '\" Italian\" (15155)'},\n",
       " {'sim': -0.004246861673891544, 'basis': '\" Greek\" (18341)'},\n",
       " {'sim': -0.004667620174586773, 'basis': '\" Polish\" (33084)'},\n",
       " {'sim': -0.005616896320134401, 'basis': '\" Uzbek\" (90959)'},\n",
       " {'sim': -0.006699282675981522, 'basis': '\" Bah\" (32429)'},\n",
       " {'sim': -0.007467571645975113, 'basis': '\" Belgian\" (49162)'},\n",
       " {'sim': -0.007794778794050217, 'basis': '\" Serbian\" (88264)'},\n",
       " {'sim': -0.00849867146462202, 'basis': '\" Sri\" (34445)'},\n",
       " {'sim': -0.00881874654442072, 'basis': '\" Cam\" (8215)'},\n",
       " {'sim': -0.009078780189156532, 'basis': '\" Ch\" (921)'},\n",
       " {'sim': -0.012309253215789795, 'basis': '\" Korean\" (16526)'},\n",
       " {'sim': -0.01293010264635086, 'basis': '\" E\" (469)'},\n",
       " {'sim': -0.01371874287724495, 'basis': '\" C\" (356)'},\n",
       " {'sim': -0.015780560672283173, 'basis': '\" Czech\" (34250)'},\n",
       " {'sim': -0.016299251466989517, 'basis': '\" Kos\" (38208)'},\n",
       " {'sim': -0.016918614506721497, 'basis': '\" French\" (8753)'},\n",
       " {'sim': -0.018342135474085808, 'basis': '\" Bang\" (17343)'},\n",
       " {'sim': -0.019018063321709633, 'basis': '\" La\" (5034)'},\n",
       " {'sim': -0.020593248307704926, 'basis': '\" Canadian\" (12152)'},\n",
       " {'sim': -0.021421566605567932, 'basis': '\" Gren\" (39224)'},\n",
       " {'sim': -0.02368566393852234, 'basis': '\" Alger\" (59609)'},\n",
       " {'sim': -0.02377351000905037, 'basis': '\" Tunis\" (95777)'},\n",
       " {'sim': -0.024294722825288773, 'basis': '\" Iv\" (34583)'},\n",
       " {'sim': -0.024446578696370125, 'basis': '\" Spanish\" (15506)'},\n",
       " {'sim': -0.026693223044276237, 'basis': '\" Lith\" (41678)'},\n",
       " {'sim': -0.029050199314951897, 'basis': '\" Bos\" (29071)'},\n",
       " {'sim': -0.02965371310710907, 'basis': '\" Lie\" (22213)'},\n",
       " {'sim': -0.029874535277485847, 'basis': '\" German\" (6063)'},\n",
       " {'sim': -0.02993612363934517, 'basis': '\" Com\" (1219)'},\n",
       " {'sim': -0.029983896762132645, 'basis': '\" T\" (350)'},\n",
       " {'sim': -0.030530963093042374, 'basis': '\" Dutch\" (24113)'},\n",
       " {'sim': -0.03057658113539219, 'basis': '\" Malaysian\" (66531)'},\n",
       " {'sim': -0.03160872310400009, 'basis': '\" Hungarian\" (57869)'},\n",
       " {'sim': -0.03171217069029808, 'basis': '\" Mexican\" (24160)'},\n",
       " {'sim': -0.0323578305542469, 'basis': '\" F\" (435)'},\n",
       " {'sim': -0.03395110368728638, 'basis': '\" Syrian\" (18636)'},\n",
       " {'sim': -0.03530791401863098, 'basis': '\" Bahrain\" (66739)'},\n",
       " {'sim': -0.03550700843334198, 'basis': '\" Saudi\" (18387)'},\n",
       " {'sim': -0.03720435872673988, 'basis': '\" Maced\" (57552)'},\n",
       " {'sim': -0.03805195912718773, 'basis': '\" Colombian\" (84653)'},\n",
       " {'sim': -0.03950720652937889, 'basis': '\" Sierra\" (36903)'},\n",
       " {'sim': -0.040628623217344284, 'basis': '\" Gamb\" (67889)'},\n",
       " {'sim': -0.043824754655361176, 'basis': '\" Equ\" (11964)'},\n",
       " {'sim': -0.044687338173389435, 'basis': '\" Portuguese\" (43288)'},\n",
       " {'sim': -0.047443240880966187, 'basis': '\" Ecuador\" (55091)'},\n",
       " {'sim': -0.04914894700050354, 'basis': '\" Argentine\" (82822)'},\n",
       " {'sim': -0.05026193708181381, 'basis': '\" Venezuelan\" (83749)'},\n",
       " {'sim': -0.050413791090250015, 'basis': '\" Thai\" (27490)'},\n",
       " {'sim': -0.051599856466054916, 'basis': '\" Nep\" (37669)'},\n",
       " {'sim': -0.052302706986665726, 'basis': '\" Jordan\" (17527)'},\n",
       " {'sim': -0.05388779938220978, 'basis': '\" Papua\" (90181)'},\n",
       " {'sim': -0.054399482905864716, 'basis': '\" Kuwait\" (57111)'},\n",
       " {'sim': -0.05656592920422554, 'basis': '\" Finnish\" (58953)'},\n",
       " {'sim': -0.058324094861745834, 'basis': '\" Iranian\" (28501)'},\n",
       " {'sim': -0.05845115706324577, 'basis': '\" Filipino\" (63517)'},\n",
       " {'sim': -0.06323003768920898, 'basis': '\" Taiwanese\" (94037)'},\n",
       " {'sim': -0.06661401689052582, 'basis': '\" Marsh\" (40163)'},\n",
       " {'sim': -0.07074584066867828, 'basis': '\" Barb\" (47142)'},\n",
       " {'sim': -0.0711854100227356, 'basis': '\" Ben\" (7505)'},\n",
       " {'sim': -0.07333239912986755, 'basis': '\" Russian\" (8690)'},\n",
       " {'sim': -0.07351559400558472, 'basis': '\" Icelandic\" (100248)'},\n",
       " {'sim': -0.07844985276460648, 'basis': '\" Guy\" (26340)'},\n",
       " {'sim': -0.08122286200523376, 'basis': '\" Bh\" (31930)'},\n",
       " {'sim': -0.08284468948841095, 'basis': '\" Eston\" (54423)'},\n",
       " {'sim': -0.08499720692634583, 'basis': '\" Australian\" (13673)'},\n",
       " {'sim': -0.08653412759304047, 'basis': '\" Rw\" (56394)'},\n",
       " {'sim': -0.08737438917160034, 'basis': '\" Azerbai\" (65423)'},\n",
       " {'sim': -0.08845260739326477, 'basis': '\" Ethiopian\" (96634)'},\n",
       " {'sim': -0.08991104364395142, 'basis': '\" Jama\" (41259)'},\n",
       " {'sim': -0.08996140956878662, 'basis': '\" Saint\" (14539)'},\n",
       " {'sim': -0.09304177016019821, 'basis': '\" Slovak\" (62364)'},\n",
       " {'sim': -0.1003105416893959, 'basis': '\" Japanese\" (11002)'},\n",
       " {'sim': -0.10235299915075302, 'basis': '\" Romanian\" (74697)'},\n",
       " {'sim': -0.10303682088851929, 'basis': '\" Libyan\" (79597)'},\n",
       " {'sim': -0.10727111250162125, 'basis': '\" Tu\" (29749)'},\n",
       " {'sim': -0.11130933463573456, 'basis': '\" Pakistani\" (45552)'},\n",
       " {'sim': -0.11134739220142365, 'basis': '\" Moroccan\" (95067)'},\n",
       " {'sim': -0.11253410577774048, 'basis': '\" Sloven\" (60495)'},\n",
       " {'sim': -0.11393624544143677, 'basis': '\" Kir\" (26608)'},\n",
       " {'sim': -0.12144826352596283, 'basis': '\" Salvador\" (49459)'},\n",
       " {'sim': -0.12419411540031433, 'basis': '\" Dominican\" (67113)'},\n",
       " {'sim': -0.15203648805618286, 'basis': '\" Indonesian\" (59929)'},\n",
       " {'sim': -0.153641939163208, 'basis': '\" Costa\" (32380)'},\n",
       " {'sim': -0.15387271344661713, 'basis': '\" Solomon\" (50899)'}]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_idx = probing_input.entity_ranges[1][1] - 1\n",
    "# token_idx = probing_input.entity_ranges[1][1] - 1\n",
    "# token_idx = -1\n",
    "layer_idx = 15\n",
    "\n",
    "basis_operator(\n",
    "    h=hs[(mt.layer_name_format.format(layer_idx), token_idx)], project_to_subspace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f8754c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Mal', prob=1.0, logit=27.25, token_id=8560, metadata=None),\n",
       " PredictedToken(token=' Mold', prob=0.000335693359375, logit=19.25, token_id=55263, metadata=None),\n",
       " PredictedToken(token=' Mic', prob=5.817413330078125e-05, logit=17.5, token_id=28095, metadata=None),\n",
       " PredictedToken(token='Mal', prob=3.528594970703125e-05, logit=17.0, token_id=30700, metadata=None),\n",
       " PredictedToken(token=' mal', prob=2.562999725341797e-06, logit=14.375, token_id=8811, metadata=None),\n",
       " PredictedToken(token=' Sudan', prob=1.1324882507324219e-06, logit=13.5625, token_id=43554, metadata=None),\n",
       " PredictedToken(token=' San', prob=7.338821887969971e-07, logit=13.125, token_id=5960, metadata=None),\n",
       " PredictedToken(token=' Moz', prob=5.699694156646729e-07, logit=12.875, token_id=52543, metadata=None),\n",
       " PredictedToken(token=' mic', prob=4.4517219066619873e-07, logit=12.625, token_id=19748, metadata=None),\n",
       " PredictedToken(token='mal', prob=2.1047890186309814e-07, logit=11.875, token_id=14991, metadata=None),\n",
       " PredictedToken(token=' Pal', prob=1.9744038581848145e-07, logit=11.8125, token_id=11165, metadata=None),\n",
       " PredictedToken(token=' Bur', prob=1.4435499906539917e-07, logit=11.5, token_id=12649, metadata=None),\n",
       " PredictedToken(token=' South', prob=1.2014061212539673e-07, logit=11.3125, token_id=4987, metadata=None),\n",
       " PredictedToken(token=' Cape', prob=1.126900315284729e-07, logit=11.25, token_id=29715, metadata=None),\n",
       " PredictedToken(token='Mic', prob=9.313225746154785e-08, logit=11.0625, token_id=98402, metadata=None)]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import logit_lens\n",
    "\n",
    "h_proj = basis_operator.project_to_subspace(\n",
    "    h=hs[(mt.layer_name_format.format(layer_idx), token_idx)]\n",
    ")\n",
    "logit_lens(mt=mt, h=h_proj.to(mt.dtype).to(mt.device), k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4bc81",
   "metadata": {},
   "source": [
    "#### Patchscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d01106a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = \"\"\"\n",
    "# <Name of a famous person> <their profession>\n",
    "# Hugh Jackman actor\n",
    "# Michael Jackson singer\n",
    "# Barack Obama politician\n",
    "# Elon Musk entrepreneur\n",
    "# placeholder\"\"\"\n",
    "\n",
    "# context = \"\"\"Name of a famous person -> their profession\n",
    "# Hugh Jackman -> actor\n",
    "# Michael Jackson -> singer\n",
    "# Barack Obama -> politician\n",
    "# Elon Musk -> entrepreneur\n",
    "# placeholder ->\"\"\"\n",
    "\n",
    "# context = \"\"\"Name of a person -> their profession\n",
    "# Albert Einstein -> physicist\n",
    "# Michael Jordan -> basketball player\n",
    "# Jack Ma -> entrepreneur\n",
    "# Toni Morrison -> writer\n",
    "# placeholder ->\"\"\"\n",
    "\n",
    "context = \"\"\"Name of a person -> their nationality\n",
    "Hugh Jackman -> Australian\n",
    "Michael Jackson -> American\n",
    "Marie Curie -> Polish\n",
    "Imran Khan -> Pakistani\n",
    "placeholder ->\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "29bc3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Indian\"[7904] (p=0.996, logit=24.250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Indian', prob=0.99609375, logit=24.25, token_id=7904, metadata=None),\n",
       " PredictedToken(token=' India', prob=0.000553131103515625, logit=16.75, token_id=6890, metadata=None),\n",
       " PredictedToken(token='Indian', prob=0.0003795623779296875, logit=16.375, token_id=48664, metadata=None),\n",
       " PredictedToken(token=' ', prob=0.00020313262939453125, logit=15.75, token_id=220, metadata=None),\n",
       " PredictedToken(token=' indian', prob=0.0001392364501953125, logit=15.375, token_id=43325, metadata=None),\n",
       " PredictedToken(token=' \\n', prob=0.0001392364501953125, logit=15.375, token_id=720, metadata=None),\n",
       " PredictedToken(token=' (', prob=5.817413330078125e-05, logit=14.5, token_id=320, metadata=None),\n",
       " PredictedToken(token=' Pakistani', prob=5.125999450683594e-05, logit=14.375, token_id=45552, metadata=None),\n",
       " PredictedToken(token=' Australian', prob=4.5299530029296875e-05, logit=14.25, token_id=13673, metadata=None),\n",
       " PredictedToken(token=' IN', prob=3.528594970703125e-05, logit=14.0, token_id=2006, metadata=None),\n",
       " PredictedToken(token=' British', prob=3.123283386230469e-05, logit=13.875, token_id=8013, metadata=None),\n",
       " PredictedToken(token='?\\n', prob=2.9206275939941406e-05, logit=13.8125, token_id=18072, metadata=None),\n",
       " PredictedToken(token=' Asian', prob=2.7418136596679688e-05, logit=13.75, token_id=14875, metadata=None),\n",
       " PredictedToken(token=' Indians', prob=2.4199485778808594e-05, logit=13.625, token_id=30507, metadata=None),\n",
       " PredictedToken(token=' American', prob=2.4199485778808594e-05, logit=13.625, token_id=3778, metadata=None)]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.tokens import prepare_input, find_token_range\n",
    "\n",
    "# subj = \"Albert Einstein\"\n",
    "# subj = \"Sachin Tendulkar\"\n",
    "subj = query_entities[1]\n",
    "context_subj = context.replace(\"placeholder\", subj)\n",
    "\n",
    "subj_inputs = prepare_input(\n",
    "    prompts=context_subj, tokenizer=mt, return_offsets_mapping=True\n",
    ")\n",
    "offset_mapping = subj_inputs.pop(\"offset_mapping\")[0]\n",
    "\n",
    "subj_range = find_token_range(\n",
    "    string=context_subj,\n",
    "    substring=subj,\n",
    "    tokenizer=mt.tokenizer,\n",
    "    offset_mapping=offset_mapping,\n",
    ")\n",
    "\n",
    "locations = [\n",
    "    (mt.layer_name_format.format(l), subj_range[1] - 1) for l in range(mt.n_layer)\n",
    "]\n",
    "\n",
    "locations += [(mt.layer_names[-1], -1)]\n",
    "\n",
    "subj_hs = get_hs(mt=mt, input=subj_inputs, locations=locations, return_dict=True)\n",
    "\n",
    "ps_pred = logit_lens(mt=mt, h=subj_hs[(mt.layer_names[-1], -1)], k=15)\n",
    "\n",
    "print(ps_pred[0])\n",
    "\n",
    "ps_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f5025472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo => \" Portuguese\"[43288] (p=0.980, logit=24.250)\n",
      "Sachin Tendulkar => \" Indian\"[7904] (p=0.996, logit=24.250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Portuguese', ' Indian']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_toks = []\n",
    "\n",
    "for entity in query_entities:\n",
    "    context_subj = context.replace(\"placeholder\", entity)\n",
    "    top_pred = predict_next_token(mt=mt, inputs=context_subj)[0][0]\n",
    "    print(f\"{entity} => {top_pred}\")\n",
    "    track_toks.append(top_pred)\n",
    "\n",
    "track_toks = [p.token_id for p in track_toks]\n",
    "track_toks = list(set(track_toks))  # remove duplicates\n",
    "[mt.tokenizer.decode(t) for t in track_toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1e791e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 18:01:06 src.functional DEBUG    placeholder position: 33 | token: \"placeholder\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Portuguese', prob=0.98046875, logit=23.5, token_id=43288, metadata=None),\n",
       " PredictedToken(token=' Portug', prob=0.015869140625, logit=19.375, token_id=23027, metadata=None),\n",
       " PredictedToken(token=' Brazilian', prob=0.0012969970703125, logit=16.875, token_id=36083, metadata=None),\n",
       " PredictedToken(token=' Port', prob=0.00101470947265625, logit=16.625, token_id=5896, metadata=None),\n",
       " PredictedToken(token=' Portugal', prob=0.00054168701171875, logit=16.0, token_id=34411, metadata=None),\n",
       " PredictedToken(token='Port', prob=0.00054168701171875, logit=16.0, token_id=7229, metadata=None),\n",
       " PredictedToken(token=' ', prob=0.000240325927734375, logit=15.1875, token_id=220, metadata=None),\n",
       " PredictedToken(token=' European', prob=0.000240325927734375, logit=15.1875, token_id=7665, metadata=None),\n",
       " PredictedToken(token=' \\n', prob=0.00011348724365234375, logit=14.4375, token_id=720, metadata=None),\n",
       " PredictedToken(token=' Por', prob=9.393692016601562e-05, logit=14.25, token_id=20388, metadata=None),\n",
       " PredictedToken(token=' Spanish', prob=9.393692016601562e-05, logit=14.25, token_id=15506, metadata=None),\n",
       " PredictedToken(token=' Pot', prob=8.821487426757812e-05, logit=14.1875, token_id=14020, metadata=None),\n",
       " PredictedToken(token=' British', prob=8.821487426757812e-05, logit=14.1875, token_id=8013, metadata=None),\n",
       " PredictedToken(token=' (', prob=8.296966552734375e-05, logit=14.125, token_id=320, metadata=None),\n",
       " PredictedToken(token=' Italian', prob=7.343292236328125e-05, logit=14.0, token_id=15155, metadata=None)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import patchscope\n",
    "\n",
    "token_idx = probing_input.entity_ranges[0][1] - 1\n",
    "# token_idx = probing_input.entity_ranges[1][1] - 1\n",
    "# token_idx = -1\n",
    "layer_idx = 5\n",
    "patch_layers = [5]\n",
    "# patch_layers = list(range(5, 16))\n",
    "\n",
    "patchscope(\n",
    "    mt=mt,\n",
    "    h=hs[(mt.layer_name_format.format(layer_idx), token_idx)] * 5,\n",
    "    context=context,\n",
    "    placeholder=\"placeholder\",\n",
    "    patch_layers=[mt.layer_name_format.format(l) for l in patch_layers],\n",
    "    k=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "aa9eeef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Portuguese', ' Indian']\n",
      "layer_idx=5 (model.layers.5)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.17, l=14.75]', '\"?\\n\\n\"[p=0.12, l=14.44]', '\"?\"[p=0.11, l=14.31]', '\" \\n\"[p=0.05, l=13.62]', '\" French\"[p=0.05, l=13.50]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.59, l=18.62]', '\" Italian\"[p=0.15, l=17.25]', '\" Brazilian\"[p=0.13, l=17.12]', '\" Portug\"[p=0.02, l=15.12]', '\"?\\n\"[p=0.01, l=14.94]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.96, l=22.25]', '\" Portug\"[p=0.02, l=18.50]', '\" Brazilian\"[p=0.01, l=17.12]', '\" Port\"[p=0.00, l=15.62]', '\"Port\"[p=0.00, l=15.19]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.25, l=14.12]', '\"?\"[p=0.06, l=12.69]', '\" German\"[p=0.05, l=12.56]', '\"?\\n\"[p=0.05, l=12.56]', '\" Japanese\"[p=0.04, l=12.25]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.86, l=18.25]', '\"?\\n\"[p=0.02, l=14.31]', '\"?\"[p=0.01, l=14.00]', '\" indian\"[p=0.01, l=13.94]', '\" (\"[p=0.01, l=13.75]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.12, l=13.38]', '\"?\"[p=0.10, l=13.19]', '\" Indian\"[p=0.08, l=13.00]', '\"?\\n\\n\"[p=0.05, l=12.62]', '\" Taiwanese\"[p=0.05, l=12.44]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.40, l=14.25]', '\" French\"[p=0.05, l=12.12]', '\"?\"[p=0.04, l=11.94]', '\" South\"[p=0.03, l=11.69]', '\"?\\n\"[p=0.03, l=11.50]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.28, l=13.38]', '\"?\\n\"[p=0.04, l=11.50]', '\"?\"[p=0.04, l=11.44]', '\" Pakistani\"[p=0.03, l=11.00]', '\"?\\n\\n\"[p=0.03, l=11.00]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.89, l=18.62]', '\" Australian\"[p=0.03, l=15.12]', '\"?\\n\"[p=0.01, l=14.00]', '\" (\"[p=0.01, l=13.62]', '\"?\"[p=0.01, l=13.50]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=15 (model.layers.15)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.21, l=14.81]', '\"?\\n\\n\"[p=0.08, l=13.88]', '\" Indian\"[p=0.08, l=13.81]', '\"?\"[p=0.06, l=13.50]', '\" Pakistani\"[p=0.04, l=13.12]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.78, l=18.88]', '\" Brazilian\"[p=0.10, l=16.88]', '\" Italian\"[p=0.03, l=15.69]', '\" Portug\"[p=0.02, l=15.06]', '\"?\"[p=0.01, l=14.00]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.96, l=21.75]', '\" Portug\"[p=0.02, l=18.00]', '\" Port\"[p=0.00, l=15.50]', '\"Port\"[p=0.00, l=15.00]', '\" Portugal\"[p=0.00, l=14.75]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.30, l=14.00]', '\"?\"[p=0.07, l=12.50]', '\"?\\n\"[p=0.06, l=12.31]', '\"??\"[p=0.04, l=12.00]', '\" German\"[p=0.03, l=11.62]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.86, l=18.12]', '\" (\"[p=0.02, l=14.44]', '\"?\"[p=0.01, l=13.69]', '\"??\"[p=0.01, l=13.69]', '\"?\\n\"[p=0.01, l=13.25]']\n",
      "token_idx=250 [\" T\"] => ['\" Taiwanese\"[p=0.17, l=15.19]', '\" Indian\"[p=0.16, l=15.12]', '\"?\\n\"[p=0.11, l=14.75]', '\"?\"[p=0.08, l=14.38]', '\"?\\n\\n\"[p=0.04, l=13.75]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.62, l=16.25]', '\" (\"[p=0.03, l=13.38]', '\"?\"[p=0.03, l=13.31]', '\" Pakistani\"[p=0.03, l=13.25]', '\"?\\n\"[p=0.02, l=12.88]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.27, l=14.44]', '\"??\"[p=0.05, l=12.69]', '\"?\"[p=0.04, l=12.62]', '\" Unknown\"[p=0.04, l=12.56]', '\"???\"[p=0.04, l=12.50]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.67, l=16.75]', '\"?\\n\"[p=0.05, l=14.19]', '\" Pakistani\"[p=0.05, l=14.06]', '\"??\"[p=0.03, l=13.75]', '\"?\"[p=0.02, l=13.38]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=25 (model.layers.25)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.41, l=15.88]', '\"?\\n\\n\"[p=0.34, l=15.69]', '\"?\"[p=0.11, l=14.56]', '\" Pakistani\"[p=0.02, l=12.69]', '\" Indian\"[p=0.01, l=12.31]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.72, l=18.25]', '\" Brazilian\"[p=0.08, l=16.00]', '\"?\\n\"[p=0.03, l=15.00]', '\"?\"[p=0.02, l=14.88]', '\" Italian\"[p=0.02, l=14.56]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.92, l=20.25]', '\" Portug\"[p=0.03, l=16.88]', '\"?\\n\"[p=0.01, l=16.00]', '\"?\"[p=0.01, l=15.12]', '\"??\"[p=0.00, l=14.69]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.57, l=15.69]', '\"?\\n\"[p=0.06, l=13.44]', '\"??\"[p=0.04, l=12.94]', '\"?\"[p=0.03, l=12.88]', '\"?\\n\\n\"[p=0.03, l=12.69]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.78, l=17.50]', '\"?\\n\"[p=0.04, l=14.62]', '\"?\"[p=0.03, l=14.25]', '\"??\"[p=0.03, l=14.25]', '\"???\"[p=0.01, l=13.31]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.11, l=13.75]', '\"??\"[p=0.10, l=13.69]', '\"?\"[p=0.09, l=13.56]', '\"?\\n\\n\"[p=0.08, l=13.50]', '\" National\"[p=0.06, l=13.12]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.78, l=16.00]', '\" Pakistani\"[p=0.02, l=12.19]', '\"??\"[p=0.01, l=12.00]', '\"?\\n\"[p=0.01, l=11.94]', '\"?\"[p=0.01, l=11.81]']\n",
      "token_idx=252 [\"ulk\"] => ['\"?\"[p=0.12, l=14.81]', '\"?\\n\"[p=0.11, l=14.75]', '\"?\\n\\n\"[p=0.11, l=14.69]', '\"??\"[p=0.11, l=14.69]', '\"???\"[p=0.07, l=14.31]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.41, l=17.88]', '\"?\\n\"[p=0.22, l=17.25]', '\"??\"[p=0.09, l=16.38]', '\"?\\n\\n\"[p=0.08, l=16.25]', '\"?\"[p=0.07, l=16.12]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=31 (model.layers.31)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.31, l=14.75]', '\"?\\n\\n\"[p=0.23, l=14.44]', '\"?\"[p=0.21, l=14.38]', '\"??\"[p=0.05, l=12.94]', '\" \\n\"[p=0.01, l=11.50]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.75, l=18.38]', '\"?\\n\"[p=0.04, l=15.50]', '\" Brazilian\"[p=0.04, l=15.31]', '\"?\"[p=0.03, l=15.25]', '\"??\"[p=0.02, l=14.62]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.82, l=20.25]', '\"?\\n\"[p=0.08, l=17.88]', '\" Portug\"[p=0.03, l=16.88]', '\"?\"[p=0.02, l=16.38]', '\"?\\n\\n\"[p=0.01, l=15.94]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.29, l=13.94]', '\"?\"[p=0.05, l=12.06]', '\" Unknown\"[p=0.03, l=11.69]', '\"??\"[p=0.03, l=11.62]', '\"?\\n\"[p=0.03, l=11.50]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.67, l=17.88]', '\"?\\n\"[p=0.13, l=16.25]', '\"?\"[p=0.05, l=15.25]', '\"??\"[p=0.04, l=14.94]', '\"?\\n\\n\"[p=0.02, l=14.31]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\\n\"[p=0.12, l=13.69]', '\"?\\n\"[p=0.12, l=13.69]', '\" Indian\"[p=0.09, l=13.44]', '\"?\"[p=0.09, l=13.38]', '\"??\"[p=0.04, l=12.62]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.76, l=16.38]', '\"?\\n\"[p=0.03, l=13.19]', '\"?\"[p=0.03, l=13.00]', '\"??\"[p=0.02, l=12.94]', '\" Pakistani\"[p=0.01, l=11.88]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.14, l=14.75]', '\"?\\n\"[p=0.13, l=14.62]', '\"?\\n\\n\"[p=0.09, l=14.25]', '\"?\"[p=0.07, l=14.00]', '\"??\"[p=0.06, l=13.88]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.75, l=19.00]', '\"?\\n\"[p=0.10, l=17.00]', '\"?\\n\\n\"[p=0.03, l=15.88]', '\"?\"[p=0.03, l=15.81]', '\"??\"[p=0.02, l=15.25]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=33 (model.layers.33)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\"[p=0.27, l=14.38]', '\"?\\n\"[p=0.27, l=14.38]', '\"?\\n\\n\"[p=0.19, l=14.06]', '\"??\"[p=0.03, l=12.19]', '\" (\"[p=0.01, l=11.19]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.79, l=19.00]', '\"?\\n\"[p=0.06, l=16.38]', '\"?\"[p=0.03, l=15.81]', '\"??\"[p=0.02, l=15.44]', '\"???\"[p=0.02, l=15.06]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.76, l=19.88]', '\"?\\n\"[p=0.12, l=18.00]', '\"?\"[p=0.03, l=16.50]', '\" Portug\"[p=0.02, l=16.38]', '\"?\\n\\n\"[p=0.02, l=16.25]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.25, l=13.81]', '\"?\"[p=0.06, l=12.44]', '\"??\"[p=0.05, l=12.12]', '\"?\\n\"[p=0.04, l=12.06]', '\" Unknown\"[p=0.03, l=11.75]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.74, l=17.62]', '\"?\\n\"[p=0.07, l=15.25]', '\"?\"[p=0.04, l=14.69]', '\"??\"[p=0.04, l=14.62]', '\"???\"[p=0.01, l=13.69]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.18, l=14.56]', '\"?\\n\\n\"[p=0.14, l=14.31]', '\"?\"[p=0.12, l=14.19]', '\"??\"[p=0.08, l=13.75]', '\" Indian\"[p=0.07, l=13.56]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.79, l=17.00]', '\"??\"[p=0.02, l=13.31]', '\"?\"[p=0.02, l=13.25]', '\"?\\n\"[p=0.02, l=13.19]', '\" Pakistani\"[p=0.01, l=12.69]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.10, l=13.06]', '\"?\"[p=0.05, l=12.44]', '\"??\"[p=0.05, l=12.38]', '\"?\\n\"[p=0.04, l=12.25]', '\" \\n\"[p=0.04, l=12.25]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.48, l=17.75]', '\"?\\n\"[p=0.18, l=16.75]', '\"?\\n\\n\"[p=0.10, l=16.12]', '\"?\"[p=0.07, l=15.75]', '\"??\"[p=0.06, l=15.69]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=35 (model.layers.35)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.14, l=11.94]', '\"?\\n\\n\"[p=0.11, l=11.75]', '\"?\"[p=0.10, l=11.62]', '\" I\"[p=0.03, l=10.31]', '\"??\"[p=0.02, l=10.19]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.69, l=18.62]', '\"?\\n\"[p=0.08, l=16.50]', '\"?\"[p=0.05, l=16.00]', '\"??\"[p=0.03, l=15.62]', '\" Brazilian\"[p=0.03, l=15.50]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.73, l=19.75]', '\"?\\n\"[p=0.14, l=18.12]', '\"?\"[p=0.03, l=16.50]', '\" Portug\"[p=0.02, l=16.25]', '\"?\\n\\n\"[p=0.02, l=16.00]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.19, l=13.62]', '\"?\"[p=0.06, l=12.44]', '\"?\\n\"[p=0.04, l=12.19]', '\" Japanese\"[p=0.04, l=12.06]', '\"??\"[p=0.04, l=12.00]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.80, l=18.12]', '\"?\\n\"[p=0.05, l=15.38]', '\"?\"[p=0.03, l=14.94]', '\"??\"[p=0.03, l=14.69]', '\"???\"[p=0.01, l=13.69]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.20, l=14.75]', '\"?\\n\\n\"[p=0.14, l=14.38]', '\"?\"[p=0.09, l=13.94]', '\" Indian\"[p=0.07, l=13.69]', '\"??\"[p=0.05, l=13.38]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.71, l=15.69]', '\"?\\n\"[p=0.04, l=12.81]', '\"?\"[p=0.04, l=12.69]', '\"??\"[p=0.02, l=12.19]', '\" (\"[p=0.01, l=11.31]']\n",
      "token_idx=252 [\"ulk\"] => ['\" British\"[p=0.08, l=12.75]', '\" Indian\"[p=0.08, l=12.69]', '\"?\\n\"[p=0.06, l=12.50]', '\"?\\n\\n\"[p=0.05, l=12.25]', '\"?\"[p=0.04, l=12.00]']\n",
      "token_idx=253 [\"ar\"] => ['\"?\\n\"[p=0.21, l=16.88]', '\" Indian\"[p=0.19, l=16.75]', '\"??\"[p=0.17, l=16.62]', '\"?\\n\\n\"[p=0.15, l=16.50]', '\"?\"[p=0.11, l=16.25]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=37 (model.layers.37)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.16, l=12.12]', '\"?\\n\\n\"[p=0.09, l=11.56]', '\"?\"[p=0.06, l=11.19]', '\" their\"[p=0.05, l=10.94]', '\" I\"[p=0.03, l=10.56]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.76, l=18.88]', '\"?\\n\"[p=0.06, l=16.25]', '\"?\"[p=0.03, l=15.69]', '\" Brazilian\"[p=0.03, l=15.62]', '\"??\"[p=0.02, l=15.44]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.86, l=20.00]', '\"?\\n\"[p=0.06, l=17.38]', '\" Portug\"[p=0.02, l=16.00]', '\"?\"[p=0.01, l=15.94]', '\"??\"[p=0.01, l=15.25]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.21, l=14.12]', '\" Japanese\"[p=0.07, l=13.06]', '\" German\"[p=0.04, l=12.50]', '\" Russian\"[p=0.03, l=12.19]', '\"?\"[p=0.03, l=12.12]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.88, l=18.62]', '\"?\\n\"[p=0.03, l=15.19]', '\"?\"[p=0.02, l=14.69]', '\"??\"[p=0.02, l=14.62]', '\"???\"[p=0.01, l=13.50]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.25, l=14.94]', '\"?\\n\\n\"[p=0.11, l=14.06]', '\"?\"[p=0.08, l=13.75]', '\" Portuguese\"[p=0.06, l=13.56]', '\" Indian\"[p=0.04, l=13.06]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.58, l=14.56]', '\"?\\n\"[p=0.06, l=12.25]', '\"?\"[p=0.05, l=12.19]', '\"??\"[p=0.04, l=11.81]', '\"?\\n\\n\"[p=0.02, l=10.94]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.16, l=14.19]', '\"?\\n\"[p=0.14, l=14.06]', '\"?\"[p=0.13, l=13.94]', '\"?\\n\\n\"[p=0.09, l=13.62]', '\"??\"[p=0.06, l=13.12]']\n",
      "token_idx=253 [\"ar\"] => ['\"?\\n\"[p=0.24, l=17.00]', '\"?\\n\\n\"[p=0.19, l=16.75]', '\" Indian\"[p=0.19, l=16.75]', '\"??\"[p=0.11, l=16.25]', '\"?\"[p=0.10, l=16.12]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=39 (model.layers.39)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\" football\"[p=0.05, l=10.12]', '\" celebrity\"[p=0.04, l=10.06]', '\" National\"[p=0.04, l=10.00]', '\" I\"[p=0.03, l=9.62]', '\" soccer\"[p=0.02, l=9.50]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.74, l=18.88]', '\"?\\n\"[p=0.08, l=16.62]', '\"?\"[p=0.04, l=16.00]', '\" Brazilian\"[p=0.02, l=15.38]', '\"??\"[p=0.02, l=15.25]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.87, l=20.00]', '\"?\\n\"[p=0.06, l=17.38]', '\" Portug\"[p=0.02, l=16.00]', '\"?\"[p=0.01, l=15.88]', '\"??\"[p=0.01, l=15.25]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.27, l=14.00]', '\" German\"[p=0.06, l=12.56]', '\" Japanese\"[p=0.05, l=12.25]', '\"?\"[p=0.04, l=12.12]', '\"??\"[p=0.03, l=11.88]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.90, l=18.88]', '\"?\\n\"[p=0.03, l=15.38]', '\"?\"[p=0.01, l=14.75]', '\"??\"[p=0.01, l=14.62]', '\"???\"[p=0.00, l=13.50]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.25, l=14.62]', '\" Portuguese\"[p=0.10, l=13.75]', '\"?\\n\\n\"[p=0.10, l=13.69]', '\"?\"[p=0.08, l=13.50]', '\" Indian\"[p=0.05, l=12.94]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.44, l=13.62]', '\"?\\n\"[p=0.07, l=11.75]', '\"?\"[p=0.07, l=11.75]', '\"??\"[p=0.06, l=11.56]', '\"?\\n\\n\"[p=0.02, l=10.69]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.18, l=13.56]', '\"?\\n\"[p=0.11, l=13.12]', '\"?\"[p=0.10, l=13.00]', '\"?\\n\\n\"[p=0.07, l=12.62]', '\"??\"[p=0.05, l=12.25]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.24, l=17.38]', '\"?\\n\"[p=0.21, l=17.25]', '\"??\"[p=0.15, l=16.88]', '\"?\\n\\n\"[p=0.13, l=16.75]', '\"?\"[p=0.09, l=16.38]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=41 (model.layers.41)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.09, l=11.38]', '\"?\\n\\n\"[p=0.05, l=10.75]', '\" National\"[p=0.05, l=10.75]', '\"?\"[p=0.04, l=10.56]', '\" football\"[p=0.03, l=10.19]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.76, l=19.00]', '\"?\\n\"[p=0.07, l=16.62]', '\"?\"[p=0.04, l=16.12]', '\" Brazilian\"[p=0.02, l=15.38]', '\"??\"[p=0.02, l=15.25]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.89, l=19.62]', '\"?\\n\"[p=0.04, l=16.62]', '\" Portug\"[p=0.01, l=15.50]', '\"?\"[p=0.01, l=15.38]', '\"??\"[p=0.01, l=14.81]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.27, l=13.50]', '\"?\"[p=0.09, l=12.44]', '\" Japanese\"[p=0.06, l=11.94]', '\"?\\n\"[p=0.05, l=11.88]', '\"??\"[p=0.05, l=11.81]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.84, l=18.88]', '\"?\\n\"[p=0.06, l=16.25]', '\"?\"[p=0.02, l=15.25]', '\"??\"[p=0.02, l=15.06]', '\"?\\n\\n\"[p=0.01, l=14.31]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\"[p=0.19, l=13.88]', '\" Portuguese\"[p=0.11, l=13.31]', '\"?\\n\\n\"[p=0.09, l=13.19]', '\"?\"[p=0.07, l=12.88]', '\" Indian\"[p=0.04, l=12.31]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.34, l=13.00]', '\"?\"[p=0.07, l=11.38]', '\"?\\n\"[p=0.06, l=11.31]', '\"??\"[p=0.05, l=11.00]', '\" Pakistani\"[p=0.03, l=10.50]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.21, l=13.31]', '\"?\"[p=0.06, l=12.12]', '\"?\\n\"[p=0.06, l=12.06]', '\" French\"[p=0.04, l=11.69]', '\"?\\n\\n\"[p=0.04, l=11.62]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.40, l=16.38]', '\"?\\n\"[p=0.13, l=15.25]', '\"?\\n\\n\"[p=0.07, l=14.69]', '\"?\"[p=0.07, l=14.62]', '\" Pakistani\"[p=0.06, l=14.44]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=45 (model.layers.45)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\"[p=0.11, l=11.50]', '\"?\\n\\n\"[p=0.09, l=11.25]', '\"?\"[p=0.07, l=11.00]', '\" Portuguese\"[p=0.04, l=10.50]', '\"?\\n\\n\"[p=0.03, l=10.31]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.75, l=18.75]', '\"?\\n\"[p=0.05, l=16.12]', '\"?\"[p=0.04, l=15.81]', '\" Brazilian\"[p=0.03, l=15.56]', '\" Italian\"[p=0.02, l=15.31]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.78, l=18.62]', '\"?\\n\"[p=0.09, l=16.50]', '\"?\"[p=0.03, l=15.25]', '\" Portug\"[p=0.02, l=14.69]', '\"??\"[p=0.01, l=14.56]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.25, l=13.31]', '\" German\"[p=0.08, l=12.25]', '\"?\"[p=0.07, l=12.06]', '\" Japanese\"[p=0.07, l=12.00]', '\"?\\n\"[p=0.05, l=11.75]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.56, l=17.50]', '\"?\\n\"[p=0.18, l=16.38]', '\"?\"[p=0.07, l=15.44]', '\"?\\n\\n\"[p=0.05, l=15.12]', '\"??\"[p=0.04, l=14.88]']\n",
      "token_idx=250 [\" T\"] => ['\" Portuguese\"[p=0.18, l=13.44]', '\"?\\n\"[p=0.10, l=12.88]', '\" Indian\"[p=0.06, l=12.25]', '\"?\\n\\n\"[p=0.06, l=12.25]', '\"?\"[p=0.05, l=12.06]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.39, l=13.56]', '\"?\"[p=0.08, l=12.00]', '\"?\\n\"[p=0.07, l=11.81]', '\"??\"[p=0.05, l=11.44]', '\"?\\n\\n\"[p=0.04, l=11.31]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.19, l=13.06]', '\" Portuguese\"[p=0.08, l=12.19]', '\"?\\n\"[p=0.07, l=12.12]', '\"?\"[p=0.06, l=11.88]', '\"?\\n\\n\"[p=0.05, l=11.69]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.35, l=15.50]', '\"?\\n\"[p=0.11, l=14.38]', '\"?\\n\\n\"[p=0.11, l=14.31]', '\"?\"[p=0.09, l=14.12]', '\"??\"[p=0.07, l=13.94]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=55 (model.layers.55)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\\n\"[p=0.13, l=11.69]', '\"?\\n\"[p=0.11, l=11.56]', '\"?\"[p=0.10, l=11.44]', '\" Portuguese\"[p=0.05, l=10.75]', '\"?\\n\\n\"[p=0.02, l=9.94]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.49, l=17.88]', '\"?\\n\"[p=0.16, l=16.75]', '\"?\"[p=0.10, l=16.25]', '\" Brazilian\"[p=0.04, l=15.38]', '\"?\\n\\n\"[p=0.04, l=15.38]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.53, l=17.88]', '\"?\\n\"[p=0.22, l=17.00]', '\"?\"[p=0.08, l=16.00]', '\"?\\n\\n\"[p=0.04, l=15.25]', '\"??\"[p=0.03, l=14.94]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.15, l=13.06]', '\"?\"[p=0.14, l=13.00]', '\"?\\n\"[p=0.11, l=12.75]', '\"??\"[p=0.08, l=12.44]', '\"?\\n\\n\"[p=0.05, l=12.00]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.58, l=17.50]', '\"?\\n\"[p=0.15, l=16.12]', '\"?\"[p=0.10, l=15.75]', '\"?\\n\\n\"[p=0.06, l=15.19]', '\"??\"[p=0.03, l=14.56]']\n",
      "token_idx=250 [\" T\"] => ['\" Portuguese\"[p=0.20, l=13.31]', '\" Indian\"[p=0.11, l=12.69]', '\"?\\n\\n\"[p=0.05, l=11.94]', '\"?\\n\"[p=0.05, l=11.94]', '\"?\"[p=0.05, l=11.88]']\n",
      "token_idx=251 [\"end\"] => ['\"?\"[p=0.15, l=13.81]', '\"?\\n\"[p=0.14, l=13.69]', '\"?\\n\\n\"[p=0.13, l=13.62]', '\" Indian\"[p=0.13, l=13.62]', '\"??\"[p=0.10, l=13.38]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.17, l=12.81]', '\"?\\n\"[p=0.10, l=12.25]', '\"?\"[p=0.08, l=12.06]', '\"?\\n\\n\"[p=0.06, l=11.75]', '\" Portuguese\"[p=0.05, l=11.62]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.16, l=13.38]', '\"?\"[p=0.13, l=13.19]', '\"?\\n\"[p=0.12, l=13.06]', '\"?\\n\\n\"[p=0.08, l=12.69]', '\"??\"[p=0.07, l=12.50]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=65 (model.layers.65)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\\n\\n\"[p=0.23, l=14.00]', '\"?\\n\"[p=0.21, l=13.94]', '\"?\"[p=0.21, l=13.94]', '\" Portuguese\"[p=0.03, l=11.94]', '\"?\\n\\n\"[p=0.02, l=11.75]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.41, l=17.25]', '\"?\\n\"[p=0.13, l=16.12]', '\"?\"[p=0.11, l=15.94]', '\" Brazilian\"[p=0.08, l=15.62]', '\" Italian\"[p=0.04, l=14.81]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.49, l=17.12]', '\"?\\n\"[p=0.18, l=16.12]', '\"?\"[p=0.12, l=15.75]', '\"?\\n\\n\"[p=0.03, l=14.31]', '\"??\"[p=0.03, l=14.25]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.29, l=13.38]', '\"?\"[p=0.10, l=12.38]', '\"?\\n\"[p=0.09, l=12.19]', '\"??\"[p=0.06, l=11.75]', '\" Sach\"[p=0.04, l=11.31]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.65, l=15.62]', '\"?\"[p=0.07, l=13.44]', '\"?\\n\"[p=0.06, l=13.31]', '\"?\\n\\n\"[p=0.02, l=12.31]', '\"??\"[p=0.02, l=12.19]']\n",
      "token_idx=250 [\" T\"] => ['\"?\\n\\n\"[p=0.21, l=14.69]', '\"?\\n\"[p=0.20, l=14.62]', '\"?\"[p=0.13, l=14.25]', '\" Indian\"[p=0.05, l=13.31]', '\"??\"[p=0.05, l=13.25]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.13, l=12.81]', '\"?\\n\"[p=0.12, l=12.75]', '\"?\"[p=0.11, l=12.69]', '\"?\\n\\n\"[p=0.09, l=12.44]', '\" French\"[p=0.06, l=12.00]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.14, l=12.94]', '\"?\\n\"[p=0.13, l=12.88]', '\"?\"[p=0.13, l=12.88]', '\"?\\n\\n\"[p=0.08, l=12.44]', '\"??\"[p=0.05, l=11.88]']\n",
      "token_idx=253 [\"ar\"] => ['\" Indian\"[p=0.17, l=15.00]', '\"??\"[p=0.14, l=14.81]', '\"?\"[p=0.14, l=14.81]', '\"?\\n\\n\"[p=0.10, l=14.44]', '\"?\\n\"[p=0.10, l=14.44]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=75 (model.layers.75)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"] => ['\"?\"[p=0.20, l=13.12]', '\"?\\n\\n\"[p=0.16, l=12.88]', '\"?\\n\"[p=0.14, l=12.75]', '\"?\\n\\n\"[p=0.03, l=11.12]', '\"\\n\\n\"[p=0.02, l=10.81]']\n",
      "\n",
      "\"Cristiano Ronaldo\" [245, 246] => \" Cristiano Ronaldo\"\n",
      "token_idx=245 [\" Cristiano\"] => ['\" Portuguese\"[p=0.49, l=17.62]', '\"?\"[p=0.09, l=15.94]', '\"?\\n\"[p=0.08, l=15.81]', '\" Italian\"[p=0.07, l=15.69]', '\" Brazilian\"[p=0.06, l=15.50]']\n",
      "token_idx=246 [\" Ronaldo\"] => ['\" Portuguese\"[p=0.39, l=17.38]', '\"?\\n\"[p=0.19, l=16.62]', '\"?\"[p=0.13, l=16.25]', '\"??\"[p=0.05, l=15.38]', '\" Brazilian\"[p=0.03, l=14.94]']\n",
      "\n",
      "\"Sachin Tendulkar\" [248, 249, 250, 251, 252, 253] => \" Sachin Tendulkar\"\n",
      "token_idx=248 [\" Sach\"] => ['\" Indian\"[p=0.20, l=12.50]', '\"?\\n\"[p=0.07, l=11.44]', '\"?\"[p=0.07, l=11.44]', '\"??\"[p=0.05, l=11.19]', '\" \\n\"[p=0.04, l=10.94]']\n",
      "token_idx=249 [\"in\"] => ['\" Indian\"[p=0.28, l=14.88]', '\"?\\n\"[p=0.13, l=14.12]', '\"?\"[p=0.13, l=14.12]', '\"?\\n\\n\"[p=0.11, l=13.94]', '\"??\"[p=0.10, l=13.88]']\n",
      "token_idx=250 [\" T\"] => ['\" Indian\"[p=0.45, l=13.81]', '\"?\"[p=0.08, l=12.06]', '\"?\\n\"[p=0.06, l=11.75]', '\"??\"[p=0.05, l=11.62]', '\"?\\n\\n\"[p=0.03, l=11.12]']\n",
      "token_idx=251 [\"end\"] => ['\" Indian\"[p=0.20, l=12.69]', '\"?\"[p=0.13, l=12.25]', '\"?\\n\"[p=0.10, l=12.00]', '\"?\\n\\n\"[p=0.06, l=11.44]', '\"??\"[p=0.05, l=11.19]']\n",
      "token_idx=252 [\"ulk\"] => ['\" Indian\"[p=0.42, l=15.25]', '\" Pakistani\"[p=0.13, l=14.06]', '\"?\\n\"[p=0.08, l=13.56]', '\"?\"[p=0.04, l=13.00]', '\"??\"[p=0.04, l=12.94]']\n",
      "token_idx=253 [\"ar\"] => ['\"?\"[p=0.14, l=13.69]', '\"??\"[p=0.14, l=13.69]', '\" your\"[p=0.07, l=13.06]', '\" both\"[p=0.06, l=12.81]', '\" Indian\"[p=0.05, l=12.75]']\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.operators.utils import patch as patch_check\n",
    "from src.functional import interpret_logits\n",
    "\n",
    "context_tok = prepare_input(prompts=context, tokenizer=mt, return_offsets_mapping=True)\n",
    "\n",
    "offset_mapping = context_tok.pop(\"offset_mapping\")[0]\n",
    "\n",
    "h_idx = (\n",
    "    find_token_range(\n",
    "        string=context,\n",
    "        substring=\"placeholder\",\n",
    "        offset_mapping=offset_mapping,\n",
    "        tokenizer=mt.tokenizer,\n",
    "        occurrence=-1,\n",
    "    )[1]\n",
    "    - 1\n",
    ")\n",
    "\n",
    "###########################################################################\n",
    "# layer_indices = list(range(mt.n_layer))\n",
    "layer_indices = [5, 15, 25, 31, 33, 35, 37, 39, 41, 45, 55, 65, 75]\n",
    "patch_layers = [\n",
    "    mt.layer_name_format.format(layer_idx) for layer_idx in list(range(5, 16))\n",
    "]\n",
    "\n",
    "token_ranges = {\n",
    "    \"last_tok\": [-1],\n",
    "    probing_input.entities[0]: list(range(*probing_input.entity_ranges[0])),\n",
    "    probing_input.entities[1]: list(range(*probing_input.entity_ranges[1])),\n",
    "}\n",
    "###########################################################################\n",
    "\n",
    "inputs = TokenizerOutput(data=probing_input.tokenized)\n",
    "print(f\"{[mt.tokenizer.decode(t) for t in track_toks]}\")\n",
    "\n",
    "score_track = {k: {} for k in token_ranges.keys()}\n",
    "\n",
    "for layer_idx in layer_indices:\n",
    "    print(f\"layer_idx={layer_idx} ({mt.layer_name_format.format(layer_idx)})\")\n",
    "    for key, token_range in token_ranges.items():\n",
    "        print(\n",
    "            f'\"{key}\" {token_range} => \"{mt.tokenizer.decode(inputs.input_ids[0][token_range], skip_special_tokens=False)}\"'\n",
    "        )\n",
    "        for token_idx in token_range:\n",
    "            # z = patch_check(\n",
    "            #     mt=mt,\n",
    "            #     h=hs[(mt.layer_name_format.format(layer_idx), token_idx)] * 5,\n",
    "            #     inp_layer=mt.layer_name_format.format(5),\n",
    "            #     # out_layer=mt.layer_names[-1],\n",
    "            #     out_layer=mt.lm_head_name,\n",
    "            #     context=context_tok,\n",
    "            #     h_idx=h_idx,\n",
    "            # )\n",
    "            # # ll_pred, ll_track = logit_lens(mt=mt, h=z, k=15, interested_tokens=track_toks)\n",
    "            # ll_pred, ll_track = interpret_logits(\n",
    "            #     tokenizer=mt, logits=z, k=15, interested_tokens=track_toks\n",
    "            # )\n",
    "            ll_pred, ll_track = patchscope(\n",
    "                mt=mt,\n",
    "                h=hs[(mt.layer_name_format.format(layer_idx), token_idx)] * 5,\n",
    "                context=context,\n",
    "                placeholder=\"placeholder\",\n",
    "                context_tokenized=context_tok,\n",
    "                placeholder_idx=h_idx,\n",
    "                patch_layers=patch_layers,\n",
    "                k=15,\n",
    "                interested_tokens=track_toks,\n",
    "            )\n",
    "            ll_fmt = [\n",
    "                f'\"{pred.token}\"[p={pred.prob:.2f}, l={pred.logit:.2f}]'\n",
    "                for pred in ll_pred\n",
    "            ]\n",
    "            if token_idx not in score_track[key]:\n",
    "                score_track[key][token_idx] = []\n",
    "            score_track[key][token_idx].append((ll_pred, ll_track))\n",
    "            print(\n",
    "                f'{token_idx=} [\"{mt.tokenizer.decode(inputs.input_ids[0][token_idx])}\"] => {ll_fmt[:5]}'\n",
    "            )\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e2584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:22:16 matplotlib DEBUG    matplotlib data path: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "2025-06-26 12:22:16 matplotlib DEBUG    CONFIGDIR=/disk/u/arnab/.config/matplotlib\n",
      "2025-06-26 12:22:16 matplotlib DEBUG    interactive is False\n",
      "2025-06-26 12:22:16 matplotlib DEBUG    platform is linux\n",
      "2025-06-26 12:22:16 matplotlib DEBUG    CACHEDIR=/disk/u/arnab/.cache/matplotlib\n",
      "2025-06-26 12:22:16 matplotlib.font_manager DEBUG    Using fontManager instance from /disk/u/arnab/.cache/matplotlib/fontlist-v390.json\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m cur_score = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m patch_from \u001b[38;5;129;01min\u001b[39;00m token_range:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     ll_pred, ll_track = \u001b[43mscore_track\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatch_from\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m     score = \u001b[38;5;28mgetattr\u001b[39m(ll_track[track_tok][\u001b[32m1\u001b[39m], METRIC)\n\u001b[32m     16\u001b[39m     denom = \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mgetattr\u001b[39m(pred, METRIC) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m ll_pred]) / \u001b[38;5;28mlen\u001b[39m(ll_pred)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "from src.trace import rank_reward\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# METRIC = \"prob\"\n",
    "METRIC = \"logit\"\n",
    "\n",
    "category_scores = {category: [] for category in token_ranges.keys()}\n",
    "\n",
    "for layer_idx in layer_indices:\n",
    "    for key, token_range in token_ranges.items():\n",
    "        cur_score = None\n",
    "        for patch_from in token_range:\n",
    "            ll_pred, ll_track = score_track[key][patch_from][layer_idx]\n",
    "            score = getattr(ll_track[track_tok][1], METRIC)\n",
    "            denom = sum([getattr(pred, METRIC) for pred in ll_pred]) / len(ll_pred)\n",
    "            score = score / denom\n",
    "            # rank = ll_track[track_tok][0]\n",
    "            # score = rank_reward(rank, k=20)\n",
    "            cur_score = score if cur_score is None else max(cur_score, score)\n",
    "        category_scores[key].append(cur_score)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for key, scores in category_scores.items():\n",
    "    # scores = np.array(scores) #/ getattr(ps_pred[0], METRIC)\n",
    "    scores = np.array(scores)  # / max(scores)  # Normalize scores\n",
    "    plt.plot(layer_indices, scores, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Layer Index\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecb510",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "78100559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_score=25.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Spanish', prob=0.9921875, logit=25.5, token_id=15506, metadata=None),\n",
       " PredictedToken(token=' Artist', prob=0.0027923583984375, logit=19.625, token_id=29459, metadata=None),\n",
       " PredictedToken(token=' Span', prob=0.0010223388671875, logit=18.625, token_id=12168, metadata=None),\n",
       " PredictedToken(token=' Spain', prob=0.000797271728515625, logit=18.375, token_id=18157, metadata=None),\n",
       " PredictedToken(token=' nationality', prob=0.000705718994140625, logit=18.25, token_id=59343, metadata=None),\n",
       " PredictedToken(token=' spanish', prob=0.000377655029296875, logit=17.625, token_id=78132, metadata=None),\n",
       " PredictedToken(token=' Painter', prob=0.000293731689453125, logit=17.375, token_id=97864, metadata=None),\n",
       " PredictedToken(token=' artist', prob=0.0002593994140625, logit=17.25, token_id=10255, metadata=None),\n",
       " PredictedToken(token=' Doctor', prob=0.000202178955078125, logit=17.0, token_id=19150, metadata=None),\n",
       " PredictedToken(token=' National', prob=0.0001392364501953125, logit=16.625, token_id=5165, metadata=None),\n",
       " PredictedToken(token=' School', prob=0.00010824203491210938, logit=16.375, token_id=6150, metadata=None),\n",
       " PredictedToken(token=' Art', prob=9.5367431640625e-05, logit=16.25, token_id=5277, metadata=None),\n",
       " PredictedToken(token=' Barcelona', prob=6.961822509765625e-05, logit=15.9375, token_id=28035, metadata=None),\n",
       " PredictedToken(token=' painter', prob=6.580352783203125e-05, logit=15.875, token_id=30581, metadata=None),\n",
       " PredictedToken(token=' University', prob=4.2438507080078125e-05, logit=15.4375, token_id=3907, metadata=None)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import interpret_logits, get_hs\n",
    "from src.trace import get_score\n",
    "from src.utils.typing import TokenizerOutput\n",
    "from typing import Literal\n",
    "from src.functional import generate_with_patch, PatchSpec\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def patched_run(\n",
    "    mt: ModelandTokenizer,\n",
    "    inputs: TokenizerOutput,\n",
    "    patches: list[PatchSpec],\n",
    "    ans_tokens: list[int],\n",
    "    metric: Literal[\"logit\", \"prob\"] = \"logit\",\n",
    "    generate_full_ans: bool = False,\n",
    "    **next_tok_kwargs,\n",
    "):\n",
    "    if generate_full_ans:\n",
    "        answer = generate_with_patch(\n",
    "            mt=mt,\n",
    "            inputs=inputs,\n",
    "            n_gen_per_prompt=1,\n",
    "            do_sample=False,\n",
    "            patches=patches,\n",
    "            patch_strategy=\"replace\",\n",
    "            remove_prefix=True,\n",
    "            patch_at_all_generations=False,  # don't need to\n",
    "            # patch_at_all_generations=True,    # will give the same result\n",
    "            # use_cache = False,\n",
    "        )\n",
    "        print(f'\"{answer[0]}\"')\n",
    "\n",
    "    logits = get_hs(\n",
    "        mt=mt,\n",
    "        input=inputs,\n",
    "        locations=[(mt.lm_head_name, -1)],\n",
    "        patches=patches,\n",
    "        return_dict=False,\n",
    "    ).squeeze()\n",
    "\n",
    "    pred, track = interpret_logits(\n",
    "        tokenizer=mt, logits=logits, interested_tokens=ans_tokens, **next_tok_kwargs\n",
    "    )\n",
    "\n",
    "    score = get_score(logits=logits, token_id=ans_tokens, metric=metric)\n",
    "\n",
    "    return score, pred, track\n",
    "\n",
    "\n",
    "gold_score, gold_pred, gold_track = patched_run(\n",
    "    mt=mt,\n",
    "    inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "    patches=[],\n",
    "    ans_tokens=[next_probs[0].token_id],\n",
    "    generate_full_ans=False,\n",
    "    metric=METRIC,\n",
    "    k=15,\n",
    ")\n",
    "\n",
    "print(f\"{gold_score=}\")\n",
    "gold_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd3a44",
   "metadata": {},
   "source": [
    "## Control Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b20a5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0041, device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>),\n",
       " tensor(0.0165, device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_prof = mt.tokenizer.encode(\"profession\", add_special_tokens=False)[0]\n",
    "tok_nat = mt.tokenizer.encode(\"nationality\", add_special_tokens=False)[0]\n",
    "\n",
    "mt.tokenizer.decode(tok_prof), mt.tokenizer.decode(tok_nat)\n",
    "\n",
    "vector_prof = mt._model.lm_head.weight[tok_prof]\n",
    "vector_nat = mt._model.lm_head.weight[tok_nat]\n",
    "\n",
    "layer_idx = 55\n",
    "token_idx = -1\n",
    "\n",
    "h = hs[(mt.layer_name_format.format(layer_idx), token_idx)]\n",
    "\n",
    "torch.cosine_similarity(h.cuda(), vector_prof.cuda(), dim=-1), torch.cosine_similarity(\n",
    "    h.cuda(), vector_nat.cuda(), dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a052a053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8192]), torch.Size([8192]), torch.Size([8192]))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, vector_prof.shape, vector_nat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e7f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409791ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05adeb68",
   "metadata": {},
   "source": [
    "## independent enrichment vs countring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "57746213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 18:05:21 __main__ DEBUG    patch_from_range=(1, 4) | \" Thierry Henry\"\n",
      "2025-06-26 18:05:22 __main__ DEBUG    patch_from=\" Thi\" | patch_to=\" Thi\"\n",
      "2025-06-26 18:05:22 __main__ DEBUG    patch_from=\"erry\" | patch_to=\"erry\"\n",
      "2025-06-26 18:05:22 __main__ DEBUG    patch_from=\" Henry\" | patch_to=\" Henry\"\n",
      "patch_score=22.625\n",
      "indirect_effect=0.900497512437811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' French', prob=0.91796875, logit=22.625, token_id=8753, metadata=None),\n",
       " PredictedToken(token=' Football', prob=0.031494140625, logit=19.25, token_id=21424, metadata=None),\n",
       " PredictedToken(token=' Soccer', prob=0.0245361328125, logit=19.0, token_id=38633, metadata=None),\n",
       " PredictedToken(token=' France', prob=0.005462646484375, logit=17.5, token_id=9822, metadata=None),\n",
       " PredictedToken(token=' football', prob=0.0042724609375, logit=17.25, token_id=9141, metadata=None),\n",
       " PredictedToken(token=' soccer', prob=0.0025787353515625, logit=16.75, token_id=22963, metadata=None),\n",
       " PredictedToken(token=' Professional', prob=0.0022735595703125, logit=16.625, token_id=21931, metadata=None),\n",
       " PredictedToken(token=' Profession', prob=0.00156402587890625, logit=16.25, token_id=50311, metadata=None),\n",
       " PredictedToken(token=' Former', prob=0.00107574462890625, logit=15.875, token_id=33600, metadata=None),\n",
       " PredictedToken(token=' french', prob=0.00101470947265625, logit=15.8125, token_id=42293, metadata=None),\n",
       " PredictedToken(token=' profession', prob=0.000614166259765625, logit=15.3125, token_id=4913, metadata=None),\n",
       " PredictedToken(token=' Alger', prob=0.00054168701171875, logit=15.1875, token_id=59609, metadata=None),\n",
       " PredictedToken(token=' National', prob=0.0003719329833984375, logit=14.8125, token_id=5165, metadata=None),\n",
       " PredictedToken(token=' Ath', prob=0.000308990478515625, logit=14.625, token_id=20277, metadata=None),\n",
       " PredictedToken(token=' former', prob=0.000255584716796875, logit=14.4375, token_id=4846, metadata=None)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import get_hs\n",
    "from src.tokens import find_token_range\n",
    "from itertools import product\n",
    "\n",
    "entity_idx = 1\n",
    "entity = probing_input.entities[entity_idx]\n",
    "patch_prompt = \" \" + entity\n",
    "\n",
    "patch_inputs = prepare_input(\n",
    "    prompts=patch_prompt, tokenizer=mt, return_offsets_mapping=True\n",
    ")\n",
    "\n",
    "offset_mapping = patch_inputs.pop(\"offset_mapping\")[0]\n",
    "patch_from_range = find_token_range(\n",
    "    string=patch_prompt,\n",
    "    substring=entity,\n",
    "    tokenizer=mt.tokenizer,\n",
    "    offset_mapping=offset_mapping,\n",
    ")\n",
    "\n",
    "logger.debug(\n",
    "    f'{patch_from_range=} | \"{mt.tokenizer.decode(patch_inputs.input_ids[0][range(*patch_from_range)])}\"'\n",
    ")\n",
    "\n",
    "patch_hs = get_hs(\n",
    "    mt=mt,\n",
    "    input=patch_inputs,\n",
    "    locations=list(product(mt.layer_names, list(range(*patch_from_range)))),\n",
    "    return_dict=True,\n",
    ")\n",
    "\n",
    "\n",
    "patchs = []\n",
    "\n",
    "patch_to_range = probing_input.entity_ranges[entity_idx]\n",
    "for patch_to in range(*patch_to_range):\n",
    "    patch_from = (\n",
    "        patch_to - patch_to_range[0] + patch_from_range[0]\n",
    "    )  # adjust to patch_inputs range\n",
    "    logger.debug(\n",
    "        f'patch_from=\"{mt.tokenizer.decode(patch_inputs.input_ids[0][patch_from])}\" | patch_to=\"{mt.tokenizer.decode(probing_input.tokenized[\"input_ids\"][0][patch_to])}\"'\n",
    "    )\n",
    "    for layer in mt.layer_names:\n",
    "        patchs.append(\n",
    "            PatchSpec(\n",
    "                location=[layer, patch_to],\n",
    "                patch=patch_hs[(layer, patch_from)],\n",
    "            )\n",
    "        )\n",
    "\n",
    "patch_score, patch_pred, patch_track = patched_run(\n",
    "    mt=mt,\n",
    "    inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "    patches=patchs,\n",
    "    ans_tokens=[next_probs[0].token_id],\n",
    "    metric=METRIC,\n",
    "    k=15,\n",
    ")\n",
    "\n",
    "print(f\"{patch_score=}\")\n",
    "indirect_effect = patch_score / gold_score\n",
    "print(f\"{indirect_effect=}\")\n",
    "\n",
    "patch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "940f3d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' football', prob=0.470703125, logit=21.625, token_id=9141, metadata=None),\n",
       " PredictedToken(token=' soccer', prob=0.470703125, logit=21.625, token_id=22963, metadata=None),\n",
       " PredictedToken(token=' former', prob=0.03857421875, logit=19.125, token_id=4846, metadata=None),\n",
       " PredictedToken(token=' professional', prob=0.004608154296875, logit=17.0, token_id=6721, metadata=None),\n",
       " PredictedToken(token=' ex', prob=0.0035858154296875, logit=16.75, token_id=506, metadata=None),\n",
       " PredictedToken(token=' Soccer', prob=0.0027923583984375, logit=16.5, token_id=38633, metadata=None),\n",
       " PredictedToken(token=' Football', prob=0.0027923583984375, logit=16.5, token_id=21424, metadata=None),\n",
       " PredictedToken(token=' retired', prob=0.00131988525390625, logit=15.75, token_id=22311, metadata=None),\n",
       " PredictedToken(token=' athlete', prob=0.00080108642578125, logit=15.25, token_id=34880, metadata=None),\n",
       " PredictedToken(token=' Former', prob=0.00080108642578125, logit=15.25, token_id=33600, metadata=None),\n",
       " PredictedToken(token=' (', prob=0.000354766845703125, logit=14.4375, token_id=320, metadata=None),\n",
       " PredictedToken(token=' ', prob=0.0002765655517578125, logit=14.1875, token_id=220, metadata=None),\n",
       " PredictedToken(token=' coach', prob=0.000202178955078125, logit=13.875, token_id=7395, metadata=None),\n",
       " PredictedToken(token=' futbol', prob=0.00017833709716796875, logit=13.75, token_id=121064, metadata=None),\n",
       " PredictedToken(token=' singer', prob=0.00014781951904296875, logit=13.5625, token_id=23597, metadata=None)]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import patchscope\n",
    "\n",
    "context_prof = \"\"\"Name of a person -> their profession\n",
    "Albert Einstein -> physicist\n",
    "Michael Jordan -> basketball player\n",
    "Jack Ma -> entrepreneur\n",
    "placeholder ->\"\"\"\n",
    "\n",
    "context_nat = \"\"\"Name of a person -> their nationality\n",
    "Hugh Jackman -> Australian\n",
    "Michael Jackson -> American\n",
    "Imran Khan -> Pakistani\n",
    "placeholder ->\"\"\"\n",
    "\n",
    "layer_idx = 15\n",
    "patch_layers = [5]\n",
    "# patch_layers = list(range(5, 16))\n",
    "\n",
    "token_idx = patch_from_range[1] - 1\n",
    "h = patch_hs[(mt.layer_name_format.format(layer_idx), token_idx)] * 5\n",
    "\n",
    "# token_idx = patch_to_range[1] - 1\n",
    "# # token_idx = -1\n",
    "# h = hs[(mt.layer_name_format.format(layer_idx), token_idx)] * 5\n",
    "\n",
    "patchscope(\n",
    "    mt=mt,\n",
    "    h=h,\n",
    "    context=context_prof,\n",
    "    placeholder=\"placeholder\",\n",
    "    patch_layers=[mt.layer_name_format.format(l) for l in patch_layers],\n",
    "    add_orig_latent_to=mt.layer_name_format.format(layer_idx),\n",
    "    k=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b9ab3217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pablo Picasso => \" Spanish\"[15506] (p=0.996, logit=24.625)\n",
      "Salvador Dalí => \" Spanish\"[15506] (p=0.984, logit=24.375)\n",
      "==================================================\n",
      "[' Spanish']\n",
      "layer_idx=5 (model.layers.5)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.29, l=14.44]', '\"?\\n\\n\"[p=0.21, l=14.12]', '\"?\"[p=0.07, l=13.00]', '\" -\\n\"[p=0.03, l=12.19]', '\" -\\n\\n\"[p=0.02, l=11.81]', '\"??\"[p=0.02, l=11.75]', '\" \\n\"[p=0.02, l=11.69]', '\" -\"[p=0.01, l=11.19]', '\" artist\"[p=0.01, l=11.12]', '\" lawyer\"[p=0.01, l=11.12]', '\" (\"[p=0.01, l=10.94]', '\" computer\"[p=0.01, l=10.81]', '\" politician\"[p=0.01, l=10.75]', '\" singer\"[p=0.01, l=10.75]', '\"???\"[p=0.01, l=10.69]']\n",
      "nationality => ['\"?\\n\"[p=0.26, l=15.75]', '\"?\\n\\n\"[p=0.18, l=15.38]', '\"?\"[p=0.14, l=15.12]', '\"??\"[p=0.04, l=13.81]', '\" Indian\"[p=0.03, l=13.44]', '\" British\"[p=0.02, l=13.38]', '\" French\"[p=0.02, l=13.31]', '\" \\n\"[p=0.02, l=13.06]', '\" -\\n\"[p=0.02, l=12.94]', '\" (\"[p=0.01, l=12.81]', '\" -\"[p=0.01, l=12.81]', '\" Chinese\"[p=0.01, l=12.56]', '\"???\"[p=0.01, l=12.56]', '\" -\\n\\n\"[p=0.01, l=12.44]', '\" Russian\"[p=0.01, l=12.38]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.11, l=12.81]', '\" artist\"[p=0.07, l=12.31]', '\"?\"[p=0.06, l=12.25]', '\"?\\n\\n\"[p=0.05, l=12.00]', '\"??\"[p=0.04, l=11.81]', '\" unknown\"[p=0.04, l=11.81]', '\"???\"[p=0.03, l=11.56]', '\" architect\"[p=0.03, l=11.50]', '\" musician\"[p=0.03, l=11.44]', '\" soccer\"[p=0.02, l=11.12]', '\" (\"[p=0.01, l=10.81]', '\" no\"[p=0.01, l=10.69]', '\" tennis\"[p=0.01, l=10.69]', '\" football\"[p=0.01, l=10.62]', '\" what\"[p=0.01, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.76, l=17.88]', '\" Mexican\"[p=0.04, l=15.00]', '\"?\\n\"[p=0.02, l=14.00]', '\"?\"[p=0.01, l=13.94]', '\" Chile\"[p=0.01, l=13.56]', '\" Argentine\"[p=0.01, l=13.44]', '\" (\"[p=0.01, l=13.31]', '\"??\"[p=0.01, l=13.31]', '\" unknown\"[p=0.01, l=13.19]', '\" Span\"[p=0.01, l=13.00]', '\"???\"[p=0.01, l=12.94]', '\" Unknown\"[p=0.00, l=12.62]', '\" Colombian\"[p=0.00, l=12.62]', '\" Venezuelan\"[p=0.00, l=12.50]', '\" no\"[p=0.00, l=12.38]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.50, l=24.25]', '\" painter\"[p=0.50, l=24.25]', '\" Painter\"[p=0.00, l=17.88]', '\" Artist\"[p=0.00, l=17.50]', '\" visual\"[p=0.00, l=16.88]', '\"artist\"[p=0.00, l=16.62]', '\" \"[p=0.00, l=16.50]', '\" (\"[p=0.00, l=15.75]', '\"paint\"[p=0.00, l=15.69]', '\" sculpt\"[p=0.00, l=15.69]', '\" artists\"[p=0.00, l=15.56]', '\" painting\"[p=0.00, l=15.56]', '\" painters\"[p=0.00, l=15.25]', '\" fine\"[p=0.00, l=15.12]', '\" art\"[p=0.00, l=15.12]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=24.25]', '\" Span\"[p=0.00, l=18.50]', '\" spanish\"[p=0.00, l=17.62]', '\" Spain\"[p=0.00, l=17.00]', '\"Spanish\"[p=0.00, l=16.12]', '\" French\"[p=0.00, l=15.81]', '\" \"[p=0.00, l=15.50]', '\" (\"[p=0.00, l=14.94]', '\" Italian\"[p=0.00, l=14.44]', '\" \\n\"[p=0.00, l=14.31]', '\" Mexican\"[p=0.00, l=13.94]', '\"?\\n\"[p=0.00, l=13.81]', '\" Hispanic\"[p=0.00, l=13.75]', '\"...\\n\"[p=0.00, l=13.62]', '\"?\"[p=0.00, l=13.50]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.47, l=15.31]', '\" painter\"[p=0.13, l=14.06]', '\" Salvador\"[p=0.04, l=12.94]', '\" D\"[p=0.02, l=12.31]', '\" (\"[p=0.02, l=12.06]', '\" surre\"[p=0.02, l=12.00]', '\"?\\n\"[p=0.02, l=12.00]', '\" football\"[p=0.02, l=11.88]', '\" architect\"[p=0.01, l=11.81]', '\" Dal\"[p=0.01, l=11.56]', '\"?\"[p=0.01, l=11.56]', '\"??\"[p=0.01, l=11.50]', '\" what\"[p=0.01, l=11.12]', '\"???\"[p=0.01, l=11.00]', '\" \\n\"[p=0.01, l=11.00]']\n",
      "nationality => ['\" Salvador\"[p=0.53, l=17.12]', '\" Spanish\"[p=0.17, l=16.00]', '\" Brazilian\"[p=0.06, l=15.00]', '\" Mexican\"[p=0.03, l=14.38]', '\" (\"[p=0.01, l=13.31]', '\"?\\n\"[p=0.01, l=13.06]', '\" Portuguese\"[p=0.01, l=12.94]', '\" Salv\"[p=0.01, l=12.94]', '\"??\"[p=0.01, l=12.88]', '\" unknown\"[p=0.01, l=12.81]', '\"?\"[p=0.01, l=12.69]', '\" D\"[p=0.01, l=12.56]', '\" El\"[p=0.01, l=12.56]', '\" Span\"[p=0.01, l=12.50]', '\"???\"[p=0.00, l=12.44]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.42, l=15.12]', '\" painter\"[p=0.33, l=14.88]', '\" surre\"[p=0.03, l=12.31]', '\" football\"[p=0.02, l=12.25]', '\" Salvador\"[p=0.01, l=11.12]', '\" Painter\"[p=0.01, l=11.06]', '\" Artist\"[p=0.01, l=10.81]', '\" soccer\"[p=0.01, l=10.75]', '\"??\"[p=0.01, l=10.75]', '\" politician\"[p=0.00, l=10.62]', '\" \"[p=0.00, l=10.56]', '\" poet\"[p=0.00, l=10.56]', '\" architect\"[p=0.00, l=10.50]', '\" actor\"[p=0.00, l=10.31]', '\" (\"[p=0.00, l=10.31]']\n",
      "nationality => ['\" Spanish\"[p=0.16, l=15.00]', '\" Chinese\"[p=0.14, l=14.88]', '\" Indian\"[p=0.13, l=14.81]', '\" Vietnamese\"[p=0.08, l=14.31]', '\" Korean\"[p=0.05, l=13.88]', '\" Dutch\"[p=0.03, l=13.38]', '\" Italian\"[p=0.02, l=13.12]', '\" French\"[p=0.02, l=12.69]', '\"??\"[p=0.01, l=12.56]', '\"?\"[p=0.01, l=12.56]', '\" Japanese\"[p=0.01, l=12.56]', '\"?\\n\"[p=0.01, l=12.50]', '\" Portuguese\"[p=0.01, l=12.38]', '\" Catalan\"[p=0.01, l=12.31]', '\" Russian\"[p=0.01, l=12.19]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" artist\"[p=0.59, l=22.00]', '\" painter\"[p=0.31, l=21.38]', '\" surre\"[p=0.09, l=20.12]', '\" (\"[p=0.00, l=16.25]', '\" Surre\"[p=0.00, l=16.00]', '\" Painter\"[p=0.00, l=15.88]', '\" Artist\"[p=0.00, l=15.88]', '\" \"[p=0.00, l=15.44]', '\" Salvador\"[p=0.00, l=14.88]', '\"artist\"[p=0.00, l=14.69]', '\" visual\"[p=0.00, l=14.56]', '\"paint\"[p=0.00, l=14.50]', '\" spanish\"[p=0.00, l=14.38]', '\" surreal\"[p=0.00, l=14.31]', '\" painting\"[p=0.00, l=14.06]']\n",
      "nationality => ['\" Spanish\"[p=0.97, l=22.00]', '\" Catalan\"[p=0.02, l=18.12]', '\" Span\"[p=0.00, l=15.81]', '\" spanish\"[p=0.00, l=15.56]', '\" Spain\"[p=0.00, l=15.19]', '\" Salvador\"[p=0.00, l=15.12]', '\" (\"[p=0.00, l=14.50]', '\"Spanish\"[p=0.00, l=14.31]', '\" Catal\"[p=0.00, l=14.12]', '\" \"[p=0.00, l=14.06]', '\" Italian\"[p=0.00, l=13.50]', '\" \\n\"[p=0.00, l=13.44]', '\"?\\n\"[p=0.00, l=12.94]', '\" French\"[p=0.00, l=12.81]', '\"?\"[p=0.00, l=12.81]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=15 (model.layers.15)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.21, l=13.88]', '\"?\\n\\n\"[p=0.10, l=13.12]', '\"?\"[p=0.05, l=12.38]', '\"??\"[p=0.03, l=12.00]', '\" \\n\"[p=0.03, l=11.75]', '\" lawyer\"[p=0.02, l=11.62]', '\" artist\"[p=0.02, l=11.50]', '\" -\\n\"[p=0.02, l=11.44]', '\" actor\"[p=0.02, l=11.31]', '\" astronaut\"[p=0.01, l=11.19]', '\" politician\"[p=0.01, l=11.19]', '\" software\"[p=0.01, l=11.06]', '\" (\"[p=0.01, l=11.06]', '\" singer\"[p=0.01, l=10.94]', '\" computer\"[p=0.01, l=10.94]']\n",
      "nationality => ['\"?\\n\"[p=0.23, l=15.69]', '\"?\\n\\n\"[p=0.15, l=15.25]', '\"?\"[p=0.12, l=15.00]', '\"??\"[p=0.07, l=14.44]', '\" Indian\"[p=0.05, l=14.06]', '\" French\"[p=0.03, l=13.62]', '\" British\"[p=0.02, l=13.25]', '\" \\n\"[p=0.02, l=13.19]', '\" -\"[p=0.02, l=13.19]', '\" -\\n\"[p=0.02, l=13.12]', '\"???\"[p=0.02, l=13.00]', '\" Chinese\"[p=0.01, l=12.81]', '\" -\\n\\n\"[p=0.01, l=12.81]', '\" Russian\"[p=0.01, l=12.69]', '\" (\"[p=0.01, l=12.50]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.13, l=13.38]', '\"?\"[p=0.07, l=12.81]', '\"??\"[p=0.07, l=12.75]', '\"?\\n\\n\"[p=0.06, l=12.69]', '\"???\"[p=0.05, l=12.38]', '\" architect\"[p=0.04, l=12.31]', '\" unknown\"[p=0.04, l=12.19]', '\" artist\"[p=0.04, l=12.12]', '\" tennis\"[p=0.03, l=12.06]', '\" soccer\"[p=0.03, l=11.81]', '\" football\"[p=0.03, l=11.81]', '\" (\"[p=0.02, l=11.25]', '\" musician\"[p=0.02, l=11.25]', '\" no\"[p=0.01, l=11.19]', '\" Pablo\"[p=0.01, l=11.12]']\n",
      "nationality => ['\" Spanish\"[p=0.54, l=17.00]', '\"?\"[p=0.06, l=14.88]', '\" Argentine\"[p=0.04, l=14.50]', '\"?\\n\"[p=0.04, l=14.44]', '\" Mexican\"[p=0.04, l=14.38]', '\"??\"[p=0.04, l=14.38]', '\"???\"[p=0.02, l=13.75]', '\" unknown\"[p=0.02, l=13.50]', '\" (\"[p=0.01, l=13.31]', '\" Arg\"[p=0.01, l=13.00]', '\" Chile\"[p=0.01, l=13.00]', '\" Unknown\"[p=0.01, l=12.88]', '\"?\\n\\n\"[p=0.01, l=12.50]', '\" no\"[p=0.01, l=12.44]', '\" I\"[p=0.00, l=12.25]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.50, l=23.12]', '\" painter\"[p=0.50, l=23.12]', '\" Painter\"[p=0.00, l=17.25]', '\" Artist\"[p=0.00, l=17.00]', '\" visual\"[p=0.00, l=16.75]', '\" sculpt\"[p=0.00, l=16.38]', '\"artist\"[p=0.00, l=16.00]', '\" \"[p=0.00, l=15.75]', '\" (\"[p=0.00, l=15.44]', '\"paint\"[p=0.00, l=15.12]', '\" painting\"[p=0.00, l=14.88]', '\" artists\"[p=0.00, l=14.69]', '\" art\"[p=0.00, l=14.44]', '\" spanish\"[p=0.00, l=14.31]', '\" fine\"[p=0.00, l=14.31]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=23.50]', '\" French\"[p=0.00, l=17.50]', '\" Span\"[p=0.00, l=17.38]', '\" spanish\"[p=0.00, l=17.00]', '\" Spain\"[p=0.00, l=16.25]', '\"Spanish\"[p=0.00, l=15.44]', '\" \"[p=0.00, l=15.06]', '\" (\"[p=0.00, l=14.69]', '\" Mexican\"[p=0.00, l=14.12]', '\" \\n\"[p=0.00, l=14.06]', '\" Italian\"[p=0.00, l=14.06]', '\" Catalan\"[p=0.00, l=13.81]', '\"?\\n\"[p=0.00, l=13.69]', '\" Cuban\"[p=0.00, l=13.56]', '\" Swiss\"[p=0.00, l=13.50]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.44, l=15.12]', '\" painter\"[p=0.15, l=14.06]', '\" surre\"[p=0.04, l=12.75]', '\" Salvador\"[p=0.02, l=12.19]', '\" football\"[p=0.02, l=11.94]', '\"?\\n\"[p=0.02, l=11.94]', '\" (\"[p=0.02, l=11.75]', '\"??\"[p=0.01, l=11.56]', '\" D\"[p=0.01, l=11.56]', '\"?\"[p=0.01, l=11.50]', '\" architect\"[p=0.01, l=11.44]', '\"???\"[p=0.01, l=11.12]', '\" Dal\"[p=0.01, l=11.12]', '\" soccer\"[p=0.01, l=10.69]', '\" what\"[p=0.01, l=10.69]']\n",
      "nationality => ['\" Salvador\"[p=0.33, l=16.25]', '\" Spanish\"[p=0.20, l=15.75]', '\" Mexican\"[p=0.12, l=15.25]', '\" Brazilian\"[p=0.05, l=14.31]', '\"?\"[p=0.03, l=13.75]', '\"??\"[p=0.02, l=13.56]', '\"?\\n\"[p=0.02, l=13.38]', '\" unknown\"[p=0.02, l=13.25]', '\" (\"[p=0.02, l=13.19]', '\"???\"[p=0.01, l=13.06]', '\" Dominican\"[p=0.01, l=12.50]', '\" Unknown\"[p=0.01, l=12.38]', '\" Chile\"[p=0.01, l=12.31]', '\" no\"[p=0.01, l=12.31]', '\" Not\"[p=0.01, l=12.25]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.48, l=17.62]', '\" painter\"[p=0.37, l=17.38]', '\" surre\"[p=0.08, l=15.81]', '\" Painter\"[p=0.01, l=13.69]', '\" Artist\"[p=0.01, l=13.25]', '\" Salvador\"[p=0.00, l=12.94]', '\" \"[p=0.00, l=12.44]', '\" (\"[p=0.00, l=12.38]', '\" Surre\"[p=0.00, l=12.25]', '\"paint\"[p=0.00, l=11.88]', '\" painting\"[p=0.00, l=11.50]', '\" architect\"[p=0.00, l=11.25]', '\" sculpt\"[p=0.00, l=11.25]', '\"?\"[p=0.00, l=11.19]', '\"??\"[p=0.00, l=11.12]']\n",
      "nationality => ['\" Spanish\"[p=0.90, l=19.25]', '\" Catalan\"[p=0.02, l=15.44]', '\" Indian\"[p=0.01, l=14.19]', '\" Spain\"[p=0.00, l=13.94]', '\" spanish\"[p=0.00, l=13.94]', '\" Chinese\"[p=0.00, l=13.94]', '\" Italian\"[p=0.00, l=13.88]', '\" Russian\"[p=0.00, l=13.62]', '\" Span\"[p=0.00, l=13.44]', '\" French\"[p=0.00, l=13.25]', '\" Mexican\"[p=0.00, l=13.19]', '\" Turkish\"[p=0.00, l=13.12]', '\"??\"[p=0.00, l=12.81]', '\" Japanese\"[p=0.00, l=12.81]', '\" (\"[p=0.00, l=12.75]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" artist\"[p=0.48, l=20.12]', '\" painter\"[p=0.26, l=19.50]', '\" surre\"[p=0.23, l=19.38]', '\" Salvador\"[p=0.00, l=15.38]', '\" Surre\"[p=0.00, l=15.31]', '\" (\"[p=0.00, l=15.12]', '\" Artist\"[p=0.00, l=14.19]', '\" Painter\"[p=0.00, l=14.12]', '\" \"[p=0.00, l=14.12]', '\" surreal\"[p=0.00, l=13.62]', '\" spanish\"[p=0.00, l=13.44]', '\"artist\"[p=0.00, l=13.38]', '\"paint\"[p=0.00, l=13.38]', '\" visual\"[p=0.00, l=12.81]', '\" painting\"[p=0.00, l=12.69]']\n",
      "nationality => ['\" Spanish\"[p=0.97, l=21.75]', '\" Catalan\"[p=0.02, l=17.75]', '\" Span\"[p=0.00, l=15.38]', '\" spanish\"[p=0.00, l=15.19]', '\" Salvador\"[p=0.00, l=15.00]', '\" Spain\"[p=0.00, l=15.00]', '\" (\"[p=0.00, l=14.19]', '\"Spanish\"[p=0.00, l=13.94]', '\" \"[p=0.00, l=13.94]', '\" \\n\"[p=0.00, l=13.56]', '\"?\\n\"[p=0.00, l=13.50]', '\" And\"[p=0.00, l=13.50]', '\" Catal\"[p=0.00, l=13.50]', '\" Italian\"[p=0.00, l=13.38]', '\"?\"[p=0.00, l=12.94]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=25 (model.layers.25)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.32, l=14.19]', '\"?\\n\\n\"[p=0.12, l=13.19]', '\"?\"[p=0.11, l=13.06]', '\"??\"[p=0.05, l=12.38]', '\" -\\n\"[p=0.02, l=11.38]', '\" your\"[p=0.02, l=11.12]', '\" unknown\"[p=0.01, l=10.88]', '\" \\n\"[p=0.01, l=10.81]', '\" lawyer\"[p=0.01, l=10.81]', '\"???\"[p=0.01, l=10.69]', '\" -\"[p=0.01, l=10.69]', '\" (\"[p=0.01, l=10.69]', '\" -\\n\\n\"[p=0.01, l=10.44]', '\" computer\"[p=0.01, l=10.19]', '\" ->\"[p=0.01, l=10.19]']\n",
      "nationality => ['\"?\\n\"[p=0.29, l=15.31]', '\"?\\n\\n\"[p=0.13, l=14.50]', '\"?\"[p=0.12, l=14.38]', '\" Indian\"[p=0.05, l=13.56]', '\"??\"[p=0.04, l=13.31]', '\" French\"[p=0.03, l=13.12]', '\" British\"[p=0.02, l=12.44]', '\" -\\n\"[p=0.02, l=12.38]', '\" :\"[p=0.01, l=12.06]', '\" -\"[p=0.01, l=12.06]', '\" Pakistani\"[p=0.01, l=11.75]', '\" \\n\"[p=0.01, l=11.69]', '\" -\\n\\n\"[p=0.01, l=11.62]', '\" Chinese\"[p=0.01, l=11.62]', '\" (\"[p=0.01, l=11.56]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.14, l=13.25]', '\"?\\n\\n\"[p=0.07, l=12.50]', '\"?\"[p=0.07, l=12.50]', '\"??\"[p=0.05, l=12.25]', '\" artist\"[p=0.04, l=12.06]', '\" football\"[p=0.04, l=12.00]', '\"???\"[p=0.03, l=11.88]', '\" musician\"[p=0.03, l=11.69]', '\" soccer\"[p=0.03, l=11.69]', '\" tennis\"[p=0.03, l=11.69]', '\" architect\"[p=0.03, l=11.62]', '\" unknown\"[p=0.02, l=11.25]', '\" what\"[p=0.01, l=10.94]', '\" singer\"[p=0.01, l=10.88]', '\" software\"[p=0.01, l=10.88]']\n",
      "nationality => ['\" Spanish\"[p=0.59, l=16.88]', '\" Mexican\"[p=0.05, l=14.44]', '\"?\"[p=0.05, l=14.38]', '\"?\\n\"[p=0.05, l=14.31]', '\"??\"[p=0.03, l=13.88]', '\" Argentine\"[p=0.02, l=13.56]', '\" Chile\"[p=0.02, l=13.31]', '\"???\"[p=0.01, l=13.12]', '\" unknown\"[p=0.01, l=13.06]', '\" Unknown\"[p=0.01, l=12.69]', '\"?\\n\\n\"[p=0.01, l=12.56]', '\" (\"[p=0.01, l=12.44]', '\" Per\"[p=0.00, l=12.00]', '\" Span\"[p=0.00, l=11.94]', '\" Arg\"[p=0.00, l=11.94]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.61, l=22.12]', '\" painter\"[p=0.37, l=21.62]', '\" Artist\"[p=0.00, l=16.50]', '\" Painter\"[p=0.00, l=16.12]', '\" sculpt\"[p=0.00, l=16.12]', '\" visual\"[p=0.00, l=15.75]', '\" (\"[p=0.00, l=15.56]', '\"artist\"[p=0.00, l=15.31]', '\" \"[p=0.00, l=15.00]', '\"paint\"[p=0.00, l=14.31]', '\" cub\"[p=0.00, l=14.25]', '\" painting\"[p=0.00, l=14.25]', '\" artists\"[p=0.00, l=13.81]', '\" spanish\"[p=0.00, l=13.75]', '\" art\"[p=0.00, l=13.75]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=22.62]', '\" Span\"[p=0.00, l=16.88]', '\" French\"[p=0.00, l=16.12]', '\" spanish\"[p=0.00, l=16.12]', '\" Spain\"[p=0.00, l=15.88]', '\"Spanish\"[p=0.00, l=14.88]', '\" \"[p=0.00, l=14.56]', '\" (\"[p=0.00, l=14.44]', '\"?\\n\"[p=0.00, l=14.00]', '\" Catalan\"[p=0.00, l=13.94]', '\" \\n\"[p=0.00, l=13.50]', '\" Mexican\"[p=0.00, l=13.44]', '\"??\"[p=0.00, l=13.31]', '\" Italian\"[p=0.00, l=13.19]', '\"?\"[p=0.00, l=13.12]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.44, l=15.06]', '\" painter\"[p=0.15, l=14.00]', '\" Salvador\"[p=0.03, l=12.44]', '\" surre\"[p=0.03, l=12.38]', '\"?\\n\"[p=0.02, l=12.12]', '\" D\"[p=0.02, l=12.06]', '\"??\"[p=0.02, l=11.94]', '\"?\"[p=0.01, l=11.69]', '\" (\"[p=0.01, l=11.56]', '\" football\"[p=0.01, l=11.44]', '\" architect\"[p=0.01, l=11.44]', '\"???\"[p=0.01, l=11.38]', '\" Dal\"[p=0.01, l=11.25]', '\" not\"[p=0.01, l=10.75]', '\" what\"[p=0.01, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.45, l=16.12]', '\" Salvador\"[p=0.14, l=14.94]', '\" Mexican\"[p=0.03, l=13.56]', '\"?\"[p=0.03, l=13.56]', '\"?\\n\"[p=0.03, l=13.44]', '\"??\"[p=0.02, l=13.19]', '\" Catalan\"[p=0.02, l=13.00]', '\" Brazilian\"[p=0.02, l=12.75]', '\"???\"[p=0.01, l=12.69]', '\" unknown\"[p=0.01, l=12.56]', '\" Span\"[p=0.01, l=12.50]', '\" Not\"[p=0.01, l=12.44]', '\" (\"[p=0.01, l=12.38]', '\" No\"[p=0.01, l=12.06]', '\" no\"[p=0.01, l=12.06]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.47, l=17.38]', '\" painter\"[p=0.37, l=17.12]', '\" surre\"[p=0.08, l=15.56]', '\" Painter\"[p=0.01, l=13.50]', '\" Salvador\"[p=0.01, l=13.00]', '\" Artist\"[p=0.01, l=12.94]', '\" \"[p=0.00, l=12.31]', '\" (\"[p=0.00, l=12.31]', '\" Surre\"[p=0.00, l=12.12]', '\"paint\"[p=0.00, l=11.62]', '\" sculpt\"[p=0.00, l=11.31]', '\" painting\"[p=0.00, l=11.19]', '\" poet\"[p=0.00, l=11.12]', '\" architect\"[p=0.00, l=11.12]', '\" visual\"[p=0.00, l=11.00]']\n",
      "nationality => ['\" Spanish\"[p=0.86, l=18.00]', '\" Catalan\"[p=0.03, l=14.50]', '\" French\"[p=0.01, l=13.19]', '\" Indian\"[p=0.01, l=13.00]', '\" Italian\"[p=0.00, l=12.69]', '\"??\"[p=0.00, l=12.50]', '\" Span\"[p=0.00, l=12.44]', '\" spanish\"[p=0.00, l=12.38]', '\" Russian\"[p=0.00, l=12.38]', '\" American\"[p=0.00, l=12.31]', '\" Spain\"[p=0.00, l=12.25]', '\"?\\n\"[p=0.00, l=12.25]', '\" Chinese\"[p=0.00, l=12.12]', '\" (\"[p=0.00, l=12.00]', '\" Japanese\"[p=0.00, l=11.88]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" artist\"[p=0.54, l=18.38]', '\" painter\"[p=0.25, l=17.62]', '\" surre\"[p=0.14, l=17.00]', '\" Salvador\"[p=0.01, l=14.69]', '\" (\"[p=0.01, l=14.19]', '\" Surre\"[p=0.00, l=13.06]', '\"?\\n\"[p=0.00, l=12.88]', '\" Artist\"[p=0.00, l=12.75]', '\"??\"[p=0.00, l=12.75]', '\" \"[p=0.00, l=12.69]', '\" Painter\"[p=0.00, l=12.62]', '\"?\"[p=0.00, l=12.50]', '\" not\"[p=0.00, l=12.44]', '\" \\n\"[p=0.00, l=12.44]', '\" I\"[p=0.00, l=11.94]']\n",
      "nationality => ['\" Spanish\"[p=0.94, l=19.88]', '\" Catalan\"[p=0.03, l=16.38]', '\" Span\"[p=0.00, l=14.31]', '\" (\"[p=0.00, l=13.44]', '\" Salvador\"[p=0.00, l=13.38]', '\"?\\n\"[p=0.00, l=13.31]', '\" Spain\"[p=0.00, l=13.19]', '\" spanish\"[p=0.00, l=13.00]', '\"??\"[p=0.00, l=12.75]', '\" Not\"[p=0.00, l=12.69]', '\" \\n\"[p=0.00, l=12.69]', '\" \"[p=0.00, l=12.62]', '\" I\"[p=0.00, l=12.50]', '\"?\"[p=0.00, l=12.44]', '\" not\"[p=0.00, l=12.38]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=31 (model.layers.31)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.30, l=13.94]', '\"?\\n\\n\"[p=0.16, l=13.31]', '\"?\"[p=0.10, l=12.81]', '\"??\"[p=0.08, l=12.56]', '\"???\"[p=0.03, l=11.50]', '\" \\n\"[p=0.01, l=10.88]', '\" (\"[p=0.01, l=10.75]', '\" unknown\"[p=0.01, l=10.62]', '\" your\"[p=0.01, l=10.44]', '\" what\"[p=0.01, l=10.25]', '\" artist\"[p=0.01, l=9.94]', '\" \"[p=0.01, l=9.88]', '\" programmer\"[p=0.01, l=9.88]', '\" lawyer\"[p=0.00, l=9.69]', '\"\\n\\n\"[p=0.00, l=9.62]']\n",
      "nationality => ['\"?\\n\"[p=0.23, l=14.44]', '\"?\\n\\n\"[p=0.12, l=13.81]', '\"?\"[p=0.12, l=13.81]', '\"??\"[p=0.06, l=13.19]', '\" Indian\"[p=0.04, l=12.69]', '\" British\"[p=0.03, l=12.56]', '\"???\"[p=0.02, l=12.19]', '\" Pakistani\"[p=0.02, l=12.00]', '\" (\"[p=0.02, l=11.94]', '\" :\"[p=0.02, l=11.81]', '\" French\"[p=0.01, l=11.62]', '\" \\n\"[p=0.01, l=11.56]', '\" National\"[p=0.01, l=11.19]', '\" Japanese\"[p=0.01, l=11.12]', '\"?:\"[p=0.01, l=10.88]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\" tennis\"[p=0.12, l=12.94]', '\"?\\n\"[p=0.10, l=12.81]', '\"?\"[p=0.05, l=12.00]', '\"?\\n\\n\"[p=0.04, l=11.88]', '\" artist\"[p=0.04, l=11.81]', '\"??\"[p=0.04, l=11.75]', '\"???\"[p=0.03, l=11.62]', '\" football\"[p=0.03, l=11.56]', '\" musician\"[p=0.02, l=11.38]', '\" soccer\"[p=0.02, l=11.25]', '\" architect\"[p=0.02, l=11.00]', '\" unknown\"[p=0.02, l=10.94]', '\" software\"[p=0.01, l=10.88]', '\" what\"[p=0.01, l=10.62]', '\" (\"[p=0.01, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.71, l=17.62]', '\" Mexican\"[p=0.04, l=14.81]', '\"?\\n\"[p=0.04, l=14.75]', '\"?\"[p=0.03, l=14.44]', '\"??\"[p=0.02, l=14.06]', '\"???\"[p=0.01, l=13.31]', '\" Chile\"[p=0.01, l=13.31]', '\" Argentine\"[p=0.01, l=13.19]', '\" unknown\"[p=0.01, l=13.06]', '\" (\"[p=0.01, l=12.94]', '\"?\\n\\n\"[p=0.01, l=12.88]', '\" Span\"[p=0.01, l=12.81]', '\" Unknown\"[p=0.01, l=12.75]', '\" Indian\"[p=0.00, l=12.06]', '\" Per\"[p=0.00, l=12.00]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.55, l=22.12]', '\" painter\"[p=0.43, l=21.88]', '\" Painter\"[p=0.00, l=16.38]', '\" Artist\"[p=0.00, l=16.25]', '\" sculpt\"[p=0.00, l=15.62]', '\" visual\"[p=0.00, l=15.62]', '\" (\"[p=0.00, l=15.44]', '\"artist\"[p=0.00, l=15.25]', '\" cub\"[p=0.00, l=15.12]', '\" \"[p=0.00, l=15.00]', '\"paint\"[p=0.00, l=14.50]', '\" spanish\"[p=0.00, l=14.38]', '\" painting\"[p=0.00, l=14.12]', '\" surre\"[p=0.00, l=14.00]', '\" art\"[p=0.00, l=13.81]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=23.00]', '\" Span\"[p=0.00, l=17.12]', '\" spanish\"[p=0.00, l=16.38]', '\" French\"[p=0.00, l=16.25]', '\" Spain\"[p=0.00, l=15.94]', '\"Spanish\"[p=0.00, l=15.00]', '\" \"[p=0.00, l=14.75]', '\"?\\n\"[p=0.00, l=14.69]', '\" (\"[p=0.00, l=14.44]', '\" Catalan\"[p=0.00, l=14.06]', '\"??\"[p=0.00, l=13.88]', '\" \\n\"[p=0.00, l=13.75]', '\" Mexican\"[p=0.00, l=13.69]', '\"?\"[p=0.00, l=13.62]', '\" Italian\"[p=0.00, l=13.50]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.43, l=15.06]', '\" painter\"[p=0.12, l=13.81]', '\" surre\"[p=0.06, l=13.12]', '\" Salvador\"[p=0.02, l=12.12]', '\" architect\"[p=0.02, l=12.12]', '\"?\\n\"[p=0.02, l=12.00]', '\"??\"[p=0.02, l=11.94]', '\" football\"[p=0.01, l=11.69]', '\"???\"[p=0.01, l=11.44]', '\"?\"[p=0.01, l=11.38]', '\" (\"[p=0.01, l=11.12]', '\" D\"[p=0.01, l=11.00]', '\" politician\"[p=0.01, l=11.00]', '\" what\"[p=0.01, l=10.94]', '\" Dal\"[p=0.01, l=10.75]']\n",
      "nationality => ['\" Spanish\"[p=0.63, l=17.38]', '\" Salvador\"[p=0.05, l=14.88]', '\"?\"[p=0.03, l=14.38]', '\"?\\n\"[p=0.03, l=14.38]', '\" Mexican\"[p=0.02, l=14.12]', '\"??\"[p=0.02, l=14.06]', '\" Catalan\"[p=0.02, l=14.06]', '\"???\"[p=0.01, l=13.31]', '\" Span\"[p=0.01, l=13.31]', '\" unknown\"[p=0.01, l=13.12]', '\" (\"[p=0.01, l=13.06]', '\" Brazilian\"[p=0.01, l=12.75]', '\" Unknown\"[p=0.00, l=12.44]', '\" Not\"[p=0.00, l=12.38]', '\" \\n\"[p=0.00, l=12.25]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.38, l=16.12]', '\" painter\"[p=0.31, l=15.94]', '\" surre\"[p=0.17, l=15.31]', '\" Salvador\"[p=0.01, l=12.44]', '\" Painter\"[p=0.01, l=12.19]', '\" Surre\"[p=0.01, l=11.94]', '\" Artist\"[p=0.01, l=11.81]', '\" (\"[p=0.00, l=11.75]', '\" \"[p=0.00, l=11.44]', '\"??\"[p=0.00, l=11.06]', '\" football\"[p=0.00, l=10.75]', '\" architect\"[p=0.00, l=10.69]', '\" sculpt\"[p=0.00, l=10.69]', '\"paint\"[p=0.00, l=10.62]', '\"?\"[p=0.00, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.83, l=17.88]', '\" Catalan\"[p=0.04, l=14.81]', '\" Indian\"[p=0.01, l=13.62]', '\" French\"[p=0.01, l=12.94]', '\"??\"[p=0.01, l=12.81]', '\"?\\n\"[p=0.00, l=12.75]', '\" Italian\"[p=0.00, l=12.75]', '\" Chinese\"[p=0.00, l=12.31]', '\" American\"[p=0.00, l=12.25]', '\" Japanese\"[p=0.00, l=12.19]', '\"?\"[p=0.00, l=12.12]', '\" Russian\"[p=0.00, l=12.06]', '\" spanish\"[p=0.00, l=12.06]', '\" Span\"[p=0.00, l=12.06]', '\" Turkish\"[p=0.00, l=12.00]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" painter\"[p=0.29, l=16.62]', '\" surre\"[p=0.25, l=16.50]', '\" artist\"[p=0.25, l=16.50]', '\"?\\n\"[p=0.04, l=14.62]', '\" Salvador\"[p=0.01, l=13.50]', '\" (\"[p=0.01, l=13.38]', '\"?\"[p=0.01, l=13.31]', '\"??\"[p=0.01, l=13.31]', '\"?\\n\\n\"[p=0.01, l=13.25]', '\" \\n\"[p=0.01, l=13.06]', '\"???\"[p=0.01, l=12.75]', '\" sculpt\"[p=0.01, l=12.75]', '\" what\"[p=0.01, l=12.69]', '\" architect\"[p=0.00, l=12.50]', '\" Surre\"[p=0.00, l=12.44]']\n",
      "nationality => ['\" Spanish\"[p=0.92, l=19.88]', '\" Catalan\"[p=0.02, l=16.25]', '\"?\\n\"[p=0.01, l=15.62]', '\" Span\"[p=0.00, l=14.38]', '\"?\"[p=0.00, l=14.12]', '\"??\"[p=0.00, l=14.06]', '\" \\n\"[p=0.00, l=13.50]', '\" spanish\"[p=0.00, l=13.44]', '\"???\"[p=0.00, l=13.00]', '\" (\"[p=0.00, l=13.00]', '\"?\\n\\n\"[p=0.00, l=13.00]', '\" Spain\"[p=0.00, l=12.88]', '\" what\"[p=0.00, l=12.81]', '\" Italian\"[p=0.00, l=12.81]', '\" What\"[p=0.00, l=12.69]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=33 (model.layers.33)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.26, l=13.50]', '\"?\\n\\n\"[p=0.15, l=12.94]', '\"?\"[p=0.08, l=12.38]', '\"??\"[p=0.08, l=12.31]', '\"???\"[p=0.03, l=11.19]', '\" unknown\"[p=0.02, l=11.12]', '\" (\"[p=0.02, l=10.69]', '\" your\"[p=0.01, l=10.44]', '\" \\n\"[p=0.01, l=10.19]', '\" what\"[p=0.01, l=9.94]', '\" artist\"[p=0.01, l=9.81]', '\" computer\"[p=0.01, l=9.75]', '\" programmer\"[p=0.01, l=9.75]', '\" \"[p=0.01, l=9.62]', '\" singer\"[p=0.00, l=9.56]']\n",
      "nationality => ['\"?\\n\"[p=0.21, l=13.88]', '\"?\\n\\n\"[p=0.12, l=13.31]', '\"?\"[p=0.10, l=13.12]', '\"??\"[p=0.04, l=12.31]', '\" :\"[p=0.04, l=12.19]', '\" Indian\"[p=0.03, l=12.00]', '\" Pakistani\"[p=0.03, l=12.00]', '\" British\"[p=0.02, l=11.69]', '\" (\"[p=0.02, l=11.56]', '\" French\"[p=0.01, l=11.25]', '\"???\"[p=0.01, l=11.06]', '\" \\n\"[p=0.01, l=10.94]', '\" unknown\"[p=0.01, l=10.88]', '\" Unknown\"[p=0.01, l=10.81]', '\"?:\"[p=0.01, l=10.56]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\" tennis\"[p=0.14, l=13.06]', '\"?\\n\"[p=0.09, l=12.62]', '\"?\"[p=0.04, l=11.75]', '\" football\"[p=0.04, l=11.75]', '\"?\\n\\n\"[p=0.03, l=11.62]', '\"??\"[p=0.03, l=11.62]', '\" artist\"[p=0.03, l=11.50]', '\" musician\"[p=0.03, l=11.44]', '\"???\"[p=0.03, l=11.38]', '\" soccer\"[p=0.02, l=11.25]', '\" unknown\"[p=0.02, l=10.81]', '\" software\"[p=0.01, l=10.69]', '\" architect\"[p=0.01, l=10.62]', '\" singer\"[p=0.01, l=10.56]', '\" what\"[p=0.01, l=10.56]']\n",
      "nationality => ['\" Spanish\"[p=0.63, l=17.25]', '\"?\\n\"[p=0.06, l=14.88]', '\" Mexican\"[p=0.05, l=14.69]', '\"?\"[p=0.04, l=14.56]', '\"??\"[p=0.03, l=14.06]', '\"???\"[p=0.01, l=13.25]', '\" Argentine\"[p=0.01, l=13.25]', '\" Chile\"[p=0.01, l=13.19]', '\" unknown\"[p=0.01, l=13.19]', '\"?\\n\\n\"[p=0.01, l=13.12]', '\" Unknown\"[p=0.01, l=12.94]', '\" (\"[p=0.01, l=12.75]', '\" Span\"[p=0.01, l=12.50]', '\" Indian\"[p=0.00, l=12.25]', '\" Per\"[p=0.00, l=11.94]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.58, l=21.00]', '\" painter\"[p=0.40, l=20.62]', '\" Artist\"[p=0.00, l=15.62]', '\" Painter\"[p=0.00, l=15.56]', '\" (\"[p=0.00, l=15.12]', '\" sculpt\"[p=0.00, l=15.06]', '\" cub\"[p=0.00, l=14.75]', '\" visual\"[p=0.00, l=14.69]', '\"artist\"[p=0.00, l=14.44]', '\" \"[p=0.00, l=14.25]', '\" spanish\"[p=0.00, l=13.81]', '\"?\\n\"[p=0.00, l=13.75]', '\"paint\"[p=0.00, l=13.56]', '\" Cub\"[p=0.00, l=13.50]', '\"?\"[p=0.00, l=13.38]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=22.62]', '\" Span\"[p=0.00, l=16.75]', '\" French\"[p=0.00, l=16.50]', '\" spanish\"[p=0.00, l=16.25]', '\" Spain\"[p=0.00, l=15.56]', '\"?\\n\"[p=0.00, l=14.81]', '\"Spanish\"[p=0.00, l=14.75]', '\" \"[p=0.00, l=14.44]', '\" (\"[p=0.00, l=14.44]', '\"??\"[p=0.00, l=13.94]', '\" \\n\"[p=0.00, l=13.81]', '\" Catalan\"[p=0.00, l=13.69]', '\"?\"[p=0.00, l=13.62]', '\" Mexican\"[p=0.00, l=13.50]', '\" Italian\"[p=0.00, l=13.19]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.43, l=14.88]', '\" painter\"[p=0.10, l=13.44]', '\" surre\"[p=0.08, l=13.25]', '\" Salvador\"[p=0.03, l=12.06]', '\" architect\"[p=0.02, l=11.94]', '\"??\"[p=0.02, l=11.81]', '\"?\\n\"[p=0.02, l=11.81]', '\"???\"[p=0.01, l=11.31]', '\"?\"[p=0.01, l=11.19]', '\" what\"[p=0.01, l=10.94]', '\" D\"[p=0.01, l=10.88]', '\" (\"[p=0.01, l=10.88]', '\" football\"[p=0.01, l=10.62]', '\" politician\"[p=0.01, l=10.50]', '\" Artist\"[p=0.01, l=10.50]']\n",
      "nationality => ['\" Spanish\"[p=0.46, l=16.88]', '\" Salvador\"[p=0.10, l=15.38]', '\" Mexican\"[p=0.05, l=14.62]', '\"?\\n\"[p=0.05, l=14.56]', '\"?\"[p=0.04, l=14.50]', '\"??\"[p=0.04, l=14.31]', '\" Catalan\"[p=0.02, l=13.81]', '\"???\"[p=0.02, l=13.69]', '\" Brazilian\"[p=0.01, l=13.38]', '\" unknown\"[p=0.01, l=13.25]', '\" Span\"[p=0.01, l=12.88]', '\" Indian\"[p=0.01, l=12.75]', '\" Unknown\"[p=0.01, l=12.69]', '\" (\"[p=0.01, l=12.69]', '\" Not\"[p=0.00, l=12.31]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.41, l=16.38]', '\" painter\"[p=0.32, l=16.12]', '\" surre\"[p=0.15, l=15.38]', '\" Salvador\"[p=0.02, l=13.12]', '\" Painter\"[p=0.01, l=12.31]', '\" Surre\"[p=0.00, l=11.94]', '\" Artist\"[p=0.00, l=11.94]', '\" (\"[p=0.00, l=11.81]', '\" \"[p=0.00, l=11.62]', '\"paint\"[p=0.00, l=10.88]', '\" architect\"[p=0.00, l=10.81]', '\"??\"[p=0.00, l=10.81]', '\" sculpt\"[p=0.00, l=10.69]', '\" football\"[p=0.00, l=10.56]', '\"?\"[p=0.00, l=10.44]']\n",
      "nationality => ['\" Spanish\"[p=0.79, l=17.50]', '\" Catalan\"[p=0.05, l=14.69]', '\" Indian\"[p=0.02, l=13.56]', '\"??\"[p=0.01, l=12.69]', '\" French\"[p=0.01, l=12.62]', '\"?\\n\"[p=0.01, l=12.56]', '\" Italian\"[p=0.01, l=12.56]', '\" Salvador\"[p=0.00, l=12.44]', '\" Japanese\"[p=0.00, l=12.38]', '\" American\"[p=0.00, l=12.19]', '\" Chinese\"[p=0.00, l=12.06]', '\" Pakistani\"[p=0.00, l=12.00]', '\" Turkish\"[p=0.00, l=12.00]', '\" Span\"[p=0.00, l=12.00]', '\" Russian\"[p=0.00, l=12.00]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" artist\"[p=0.31, l=16.12]', '\" painter\"[p=0.27, l=16.00]', '\" surre\"[p=0.16, l=15.50]', '\"?\\n\"[p=0.04, l=14.12]', '\" Salvador\"[p=0.03, l=13.88]', '\" (\"[p=0.01, l=12.88]', '\"?\\n\\n\"[p=0.01, l=12.88]', '\"??\"[p=0.01, l=12.88]', '\" \\n\"[p=0.01, l=12.69]', '\"?\"[p=0.01, l=12.69]', '\" what\"[p=0.01, l=12.56]', '\" architect\"[p=0.01, l=12.25]', '\"???\"[p=0.01, l=12.25]', '\" \"[p=0.00, l=12.00]', '\" which\"[p=0.00, l=11.81]']\n",
      "nationality => ['\" Spanish\"[p=0.86, l=19.12]', '\" Catalan\"[p=0.04, l=15.94]', '\"?\\n\"[p=0.03, l=15.75]', '\" Salvador\"[p=0.01, l=14.50]', '\"??\"[p=0.01, l=14.19]', '\"?\"[p=0.01, l=14.00]', '\" \\n\"[p=0.00, l=13.81]', '\"?\\n\\n\"[p=0.00, l=13.19]', '\" spanish\"[p=0.00, l=13.12]', '\" Span\"[p=0.00, l=13.12]', '\" Pakistani\"[p=0.00, l=13.06]', '\"???\"[p=0.00, l=13.00]', '\" (\"[p=0.00, l=12.94]', '\" what\"[p=0.00, l=12.56]', '\" What\"[p=0.00, l=12.50]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=35 (model.layers.35)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.29, l=14.00]', '\"?\\n\\n\"[p=0.15, l=13.31]', '\"?\"[p=0.09, l=12.81]', '\"??\"[p=0.07, l=12.56]', '\"???\"[p=0.03, l=11.62]', '\" unknown\"[p=0.02, l=11.12]', '\" your\"[p=0.02, l=11.12]', '\" \\n\"[p=0.01, l=11.00]', '\" (\"[p=0.01, l=10.94]', '\" artist\"[p=0.01, l=10.38]', '\" entrepreneur\"[p=0.01, l=10.31]', '\" \"[p=0.01, l=9.94]', '\" musician\"[p=0.01, l=9.94]', '\" what\"[p=0.00, l=9.88]', '\"\\n\\n\"[p=0.00, l=9.88]']\n",
      "nationality => ['\"?\\n\"[p=0.27, l=14.75]', '\"?\"[p=0.10, l=13.75]', '\"?\\n\\n\"[p=0.09, l=13.69]', '\"??\"[p=0.05, l=13.00]', '\" :\"[p=0.05, l=13.00]', '\" Indian\"[p=0.04, l=12.94]', '\" Pakistani\"[p=0.03, l=12.50]', '\" French\"[p=0.02, l=12.00]', '\" British\"[p=0.02, l=11.94]', '\" \\n\"[p=0.01, l=11.81]', '\" (\"[p=0.01, l=11.75]', '\"???\"[p=0.01, l=11.56]', '\"?:\"[p=0.01, l=11.44]', '\" National\"[p=0.01, l=11.31]', '\" Japanese\"[p=0.01, l=11.25]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.14, l=13.19]', '\" tennis\"[p=0.11, l=13.00]', '\"?\\n\\n\"[p=0.06, l=12.38]', '\"?\"[p=0.06, l=12.31]', '\"??\"[p=0.05, l=12.19]', '\"???\"[p=0.04, l=11.88]', '\" football\"[p=0.03, l=11.69]', '\" artist\"[p=0.03, l=11.62]', '\" unknown\"[p=0.02, l=11.38]', '\" soccer\"[p=0.02, l=11.38]', '\" musician\"[p=0.02, l=11.25]', '\" software\"[p=0.01, l=10.94]', '\" architect\"[p=0.01, l=10.75]', '\" what\"[p=0.01, l=10.62]', '\" programmer\"[p=0.01, l=10.56]']\n",
      "nationality => ['\" Spanish\"[p=0.72, l=18.00]', '\"?\\n\"[p=0.07, l=15.62]', '\"?\"[p=0.04, l=15.12]', '\"??\"[p=0.03, l=14.69]', '\" Mexican\"[p=0.02, l=14.25]', '\"???\"[p=0.01, l=13.81]', '\"?\\n\\n\"[p=0.01, l=13.81]', '\" (\"[p=0.01, l=13.38]', '\" unknown\"[p=0.01, l=13.31]', '\" Argentine\"[p=0.01, l=13.25]', '\" Span\"[p=0.01, l=13.12]', '\" Unknown\"[p=0.00, l=13.00]', '\" Chile\"[p=0.00, l=12.50]', '\" spanish\"[p=0.00, l=12.44]', '\" \"[p=0.00, l=12.00]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.49, l=20.38]', '\" painter\"[p=0.49, l=20.38]', '\" Painter\"[p=0.00, l=15.56]', '\" Artist\"[p=0.00, l=15.06]', '\" (\"[p=0.00, l=14.88]', '\"?\\n\"[p=0.00, l=14.62]', '\"artist\"[p=0.00, l=14.25]', '\"??\"[p=0.00, l=14.19]', '\" \"[p=0.00, l=14.00]', '\"paint\"[p=0.00, l=13.88]', '\"?\"[p=0.00, l=13.88]', '\" visual\"[p=0.00, l=13.69]', '\" spanish\"[p=0.00, l=13.62]', '\" what\"[p=0.00, l=13.50]', '\" cub\"[p=0.00, l=13.44]']\n",
      "nationality => ['\" Spanish\"[p=0.98, l=22.12]', '\" Span\"[p=0.00, l=16.62]', '\" spanish\"[p=0.00, l=15.81]', '\" Spain\"[p=0.00, l=15.38]', '\"?\\n\"[p=0.00, l=15.19]', '\" French\"[p=0.00, l=14.81]', '\"Spanish\"[p=0.00, l=14.50]', '\"??\"[p=0.00, l=14.25]', '\" \"[p=0.00, l=14.25]', '\" (\"[p=0.00, l=14.19]', '\"?\"[p=0.00, l=13.81]', '\" \\n\"[p=0.00, l=13.56]', '\" Catalan\"[p=0.00, l=13.50]', '\"???\"[p=0.00, l=13.31]', '\" Italian\"[p=0.00, l=12.69]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.50, l=15.50]', '\" painter\"[p=0.16, l=14.38]', '\" surre\"[p=0.05, l=13.25]', '\" Salvador\"[p=0.02, l=12.06]', '\" architect\"[p=0.02, l=12.06]', '\"?\\n\"[p=0.01, l=11.88]', '\"??\"[p=0.01, l=11.81]', '\" (\"[p=0.01, l=11.50]', '\"?\"[p=0.01, l=11.44]', '\"???\"[p=0.01, l=11.25]', '\" football\"[p=0.01, l=11.19]', '\" D\"[p=0.01, l=11.19]', '\" what\"[p=0.01, l=11.06]', '\" Artist\"[p=0.01, l=11.00]', '\" Dal\"[p=0.00, l=10.56]']\n",
      "nationality => ['\" Spanish\"[p=0.66, l=17.25]', '\" Salvador\"[p=0.03, l=14.25]', '\" Catalan\"[p=0.03, l=14.25]', '\"?\\n\"[p=0.03, l=14.25]', '\"?\"[p=0.03, l=14.06]', '\"??\"[p=0.02, l=13.69]', '\" Mexican\"[p=0.01, l=13.25]', '\" Span\"[p=0.01, l=13.19]', '\"???\"[p=0.01, l=12.94]', '\" unknown\"[p=0.01, l=12.75]', '\" (\"[p=0.01, l=12.69]', '\" Brazilian\"[p=0.01, l=12.62]', '\" Indian\"[p=0.01, l=12.44]', '\" Not\"[p=0.00, l=12.25]', '\" no\"[p=0.00, l=12.06]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.39, l=15.94]', '\" painter\"[p=0.31, l=15.69]', '\" surre\"[p=0.13, l=14.81]', '\" Salvador\"[p=0.04, l=13.62]', '\" Painter\"[p=0.01, l=11.75]', '\" (\"[p=0.01, l=11.69]', '\" Surre\"[p=0.00, l=11.44]', '\" Artist\"[p=0.00, l=11.44]', '\" \"[p=0.00, l=11.38]', '\"??\"[p=0.00, l=11.38]', '\"?\\n\"[p=0.00, l=10.94]', '\"?\"[p=0.00, l=10.94]', '\" \\n\"[p=0.00, l=10.69]', '\"paint\"[p=0.00, l=10.62]', '\" what\"[p=0.00, l=10.31]']\n",
      "nationality => ['\" Spanish\"[p=0.73, l=16.75]', '\" Catalan\"[p=0.06, l=14.25]', '\" Indian\"[p=0.02, l=12.88]', '\"?\\n\"[p=0.02, l=12.88]', '\"??\"[p=0.01, l=12.75]', '\" Salvador\"[p=0.01, l=12.50]', '\"?\"[p=0.01, l=12.12]', '\" French\"[p=0.01, l=11.88]', '\" Italian\"[p=0.00, l=11.62]', '\" (\"[p=0.00, l=11.50]', '\"???\"[p=0.00, l=11.38]', '\" \\n\"[p=0.00, l=11.31]', '\" American\"[p=0.00, l=11.25]', '\" Span\"[p=0.00, l=11.25]', '\" not\"[p=0.00, l=11.19]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" painter\"[p=0.39, l=17.25]', '\" artist\"[p=0.31, l=17.00]', '\" surre\"[p=0.11, l=15.94]', '\"?\\n\"[p=0.03, l=14.75]', '\" Salvador\"[p=0.03, l=14.62]', '\"??\"[p=0.01, l=13.62]', '\"?\\n\\n\"[p=0.01, l=13.62]', '\" \\n\"[p=0.01, l=13.56]', '\"?\"[p=0.01, l=13.44]', '\" (\"[p=0.01, l=13.25]', '\"???\"[p=0.01, l=13.00]', '\" what\"[p=0.00, l=12.81]', '\" \"[p=0.00, l=12.69]', '\" Painter\"[p=0.00, l=12.50]', '\" Surre\"[p=0.00, l=12.25]']\n",
      "nationality => ['\" Spanish\"[p=0.91, l=19.75]', '\"?\\n\"[p=0.03, l=16.38]', '\" Catalan\"[p=0.01, l=15.12]', '\"??\"[p=0.01, l=14.75]', '\"?\"[p=0.01, l=14.56]', '\" Salvador\"[p=0.01, l=14.56]', '\" \\n\"[p=0.00, l=14.44]', '\"?\\n\\n\"[p=0.00, l=14.19]', '\" Span\"[p=0.00, l=13.88]', '\" spanish\"[p=0.00, l=13.88]', '\"???\"[p=0.00, l=13.56]', '\" (\"[p=0.00, l=13.12]', '\" what\"[p=0.00, l=12.81]', '\" \"[p=0.00, l=12.75]', '\" What\"[p=0.00, l=12.69]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=37 (model.layers.37)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.31, l=14.19]', '\"?\\n\\n\"[p=0.19, l=13.69]', '\"?\"[p=0.10, l=13.06]', '\"??\"[p=0.05, l=12.38]', '\" artist\"[p=0.02, l=11.31]', '\" \\n\"[p=0.02, l=11.25]', '\"???\"[p=0.02, l=11.19]', '\" (\"[p=0.01, l=11.00]', '\" your\"[p=0.01, l=10.94]', '\" painter\"[p=0.01, l=10.88]', '\" entrepreneur\"[p=0.01, l=10.62]', '\"\\n\\n\"[p=0.01, l=10.50]', '\" unknown\"[p=0.01, l=10.50]', '\" ->\"[p=0.01, l=10.38]', '\" \"[p=0.00, l=10.06]']\n",
      "nationality => ['\"?\\n\"[p=0.35, l=15.81]', '\"?\\n\\n\"[p=0.19, l=15.19]', '\"?\"[p=0.15, l=14.94]', '\" Pakistani\"[p=0.03, l=13.50]', '\" Indian\"[p=0.03, l=13.44]', '\"??\"[p=0.03, l=13.44]', '\" Spanish\"[p=0.01, l=12.44]', '\" \\n\"[p=0.01, l=12.25]', '\" (\"[p=0.01, l=12.25]', '\"???\"[p=0.01, l=12.12]', '\" French\"[p=0.01, l=12.12]', '\" National\"[p=0.01, l=11.81]', '\" nationality\"[p=0.00, l=11.56]', '\" British\"[p=0.00, l=11.50]', '\" \"[p=0.00, l=11.44]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.14, l=13.19]', '\" tennis\"[p=0.09, l=12.75]', '\"?\\n\\n\"[p=0.06, l=12.38]', '\"?\"[p=0.05, l=12.19]', '\"??\"[p=0.04, l=12.00]', '\" artist\"[p=0.04, l=12.00]', '\" football\"[p=0.04, l=11.81]', '\"???\"[p=0.03, l=11.69]', '\" soccer\"[p=0.03, l=11.56]', '\" unknown\"[p=0.02, l=11.38]', '\" musician\"[p=0.02, l=11.25]', '\" architect\"[p=0.02, l=11.00]', '\" software\"[p=0.01, l=10.75]', '\" singer\"[p=0.01, l=10.69]', '\" painter\"[p=0.01, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.64, l=17.75]', '\"?\\n\"[p=0.07, l=15.56]', '\"?\"[p=0.05, l=15.25]', '\"??\"[p=0.03, l=14.75]', '\" Mexican\"[p=0.02, l=14.50]', '\" Argentine\"[p=0.02, l=14.00]', '\"?\\n\\n\"[p=0.01, l=13.88]', '\"???\"[p=0.01, l=13.88]', '\" unknown\"[p=0.01, l=13.56]', '\" (\"[p=0.01, l=13.38]', '\" Unknown\"[p=0.01, l=13.38]', '\" Chile\"[p=0.01, l=13.19]', '\" Span\"[p=0.01, l=12.94]', '\" Venezuelan\"[p=0.00, l=12.31]', '\" Arg\"[p=0.00, l=12.31]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" painter\"[p=0.52, l=20.75]', '\" artist\"[p=0.46, l=20.62]', '\" Painter\"[p=0.00, l=15.69]', '\" Artist\"[p=0.00, l=15.19]', '\" (\"[p=0.00, l=14.94]', '\"?\\n\"[p=0.00, l=14.44]', '\"artist\"[p=0.00, l=14.31]', '\" \"[p=0.00, l=14.25]', '\"??\"[p=0.00, l=14.06]', '\"paint\"[p=0.00, l=14.00]', '\" visual\"[p=0.00, l=13.94]', '\"?\"[p=0.00, l=13.81]', '\" spanish\"[p=0.00, l=13.69]', '\" cub\"[p=0.00, l=13.56]', '\" what\"[p=0.00, l=13.50]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=22.38]', '\" Span\"[p=0.00, l=16.75]', '\" spanish\"[p=0.00, l=15.88]', '\" Spain\"[p=0.00, l=15.50]', '\" French\"[p=0.00, l=15.50]', '\"?\\n\"[p=0.00, l=14.88]', '\"Spanish\"[p=0.00, l=14.62]', '\" \"[p=0.00, l=14.38]', '\" (\"[p=0.00, l=14.19]', '\"??\"[p=0.00, l=14.06]', '\" \\n\"[p=0.00, l=13.62]', '\"?\"[p=0.00, l=13.62]', '\" Catalan\"[p=0.00, l=13.62]', '\"???\"[p=0.00, l=13.12]', '\" Mexican\"[p=0.00, l=12.94]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.53, l=15.69]', '\" painter\"[p=0.17, l=14.56]', '\" surre\"[p=0.06, l=13.56]', '\" Salvador\"[p=0.01, l=11.94]', '\"??\"[p=0.01, l=11.81]', '\" architect\"[p=0.01, l=11.75]', '\"?\\n\"[p=0.01, l=11.75]', '\" (\"[p=0.01, l=11.38]', '\"?\"[p=0.01, l=11.31]', '\" Artist\"[p=0.01, l=11.25]', '\" what\"[p=0.01, l=11.19]', '\" D\"[p=0.01, l=11.06]', '\"???\"[p=0.01, l=11.06]', '\" football\"[p=0.00, l=10.94]', '\" Painter\"[p=0.00, l=10.56]']\n",
      "nationality => ['\" Spanish\"[p=0.67, l=17.38]', '\" Salvador\"[p=0.07, l=15.06]', '\" Catalan\"[p=0.04, l=14.44]', '\"?\\n\"[p=0.02, l=13.75]', '\"?\"[p=0.01, l=13.56]', '\"??\"[p=0.01, l=13.50]', '\" Mexican\"[p=0.01, l=13.38]', '\" Span\"[p=0.01, l=13.25]', '\"???\"[p=0.01, l=12.88]', '\" unknown\"[p=0.01, l=12.81]', '\" Brazilian\"[p=0.01, l=12.56]', '\" (\"[p=0.01, l=12.50]', '\" Indian\"[p=0.00, l=12.38]', '\" Not\"[p=0.00, l=12.19]', '\" Italian\"[p=0.00, l=12.12]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.36, l=14.56]', '\" painter\"[p=0.28, l=14.31]', '\" surre\"[p=0.11, l=13.38]', '\" Salvador\"[p=0.02, l=11.81]', '\" Surre\"[p=0.01, l=10.44]', '\" Painter\"[p=0.01, l=10.44]', '\" (\"[p=0.01, l=10.38]', '\" Artist\"[p=0.01, l=10.38]', '\" \"[p=0.01, l=10.31]', '\"??\"[p=0.00, l=10.12]', '\" football\"[p=0.00, l=10.12]', '\" architect\"[p=0.00, l=9.69]', '\"?\"[p=0.00, l=9.62]', '\" sculpt\"[p=0.00, l=9.56]', '\"?\\n\"[p=0.00, l=9.56]']\n",
      "nationality => ['\" Spanish\"[p=0.52, l=15.50]', '\" Catalan\"[p=0.10, l=13.81]', '\" Indian\"[p=0.03, l=12.75]', '\"??\"[p=0.02, l=12.31]', '\"?\\n\"[p=0.02, l=12.19]', '\" French\"[p=0.01, l=11.69]', '\"?\"[p=0.01, l=11.62]', '\" Salvador\"[p=0.01, l=11.56]', '\" American\"[p=0.01, l=11.56]', '\" Japanese\"[p=0.01, l=11.38]', '\"???\"[p=0.01, l=11.38]', '\" unknown\"[p=0.01, l=11.31]', '\" Italian\"[p=0.01, l=11.12]', '\" Not\"[p=0.01, l=11.12]', '\" Korean\"[p=0.01, l=11.12]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" painter\"[p=0.53, l=17.88]', '\" artist\"[p=0.32, l=17.38]', '\" surre\"[p=0.04, l=15.31]', '\"?\\n\"[p=0.02, l=14.62]', '\" Salvador\"[p=0.01, l=14.06]', '\"?\\n\\n\"[p=0.01, l=13.44]', '\"??\"[p=0.00, l=13.19]', '\" Painter\"[p=0.00, l=13.00]', '\" \\n\"[p=0.00, l=13.00]', '\" (\"[p=0.00, l=12.94]', '\"?\"[p=0.00, l=12.88]', '\" art\"[p=0.00, l=12.62]', '\" architect\"[p=0.00, l=12.62]', '\" \"[p=0.00, l=12.31]', '\" what\"[p=0.00, l=12.12]']\n",
      "nationality => ['\" Spanish\"[p=0.92, l=19.62]', '\"?\\n\"[p=0.02, l=15.81]', '\" Catalan\"[p=0.01, l=15.44]', '\" Span\"[p=0.01, l=14.56]', '\"??\"[p=0.00, l=14.06]', '\" Pakistani\"[p=0.00, l=13.94]', '\"?\"[p=0.00, l=13.81]', '\" \\n\"[p=0.00, l=13.69]', '\"?\\n\\n\"[p=0.00, l=13.62]', '\" Salvador\"[p=0.00, l=13.50]', '\" spanish\"[p=0.00, l=13.31]', '\" (\"[p=0.00, l=13.06]', '\"???\"[p=0.00, l=12.56]', '\" \"[p=0.00, l=12.56]', '\" Indian\"[p=0.00, l=12.25]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=39 (model.layers.39)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.31, l=14.12]', '\"?\\n\\n\"[p=0.16, l=13.50]', '\"?\"[p=0.11, l=13.06]', '\"??\"[p=0.06, l=12.44]', '\" artist\"[p=0.03, l=11.69]', '\"???\"[p=0.02, l=11.31]', '\" \\n\"[p=0.02, l=11.25]', '\" (\"[p=0.02, l=11.12]', '\" painter\"[p=0.01, l=10.88]', '\" your\"[p=0.01, l=10.69]', '\" entrepreneur\"[p=0.01, l=10.38]', '\"\\n\\n\"[p=0.01, l=10.31]', '\" \"[p=0.01, l=10.25]', '\" ->\"[p=0.01, l=10.12]', '\" unknown\"[p=0.01, l=10.06]']\n",
      "nationality => ['\"?\\n\"[p=0.28, l=15.19]', '\"?\"[p=0.17, l=14.69]', '\"?\\n\\n\"[p=0.15, l=14.56]', '\"??\"[p=0.04, l=13.31]', '\" Pakistani\"[p=0.03, l=13.00]', '\" Indian\"[p=0.03, l=13.00]', '\" \\n\"[p=0.03, l=12.81]', '\" Spanish\"[p=0.02, l=12.38]', '\"???\"[p=0.02, l=12.25]', '\" (\"[p=0.02, l=12.25]', '\" French\"[p=0.02, l=12.25]', '\" \"[p=0.01, l=11.81]', '\"\\n\\n\"[p=0.01, l=11.31]', '\" \\n\\n\"[p=0.01, l=11.19]', '\" British\"[p=0.00, l=11.12]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.15, l=13.38]', '\"?\\n\\n\"[p=0.08, l=12.69]', '\" tennis\"[p=0.08, l=12.69]', '\"?\"[p=0.06, l=12.44]', '\" artist\"[p=0.06, l=12.38]', '\"??\"[p=0.04, l=12.12]', '\" football\"[p=0.04, l=11.94]', '\" soccer\"[p=0.04, l=11.94]', '\"???\"[p=0.03, l=11.81]', '\" unknown\"[p=0.02, l=11.50]', '\" architect\"[p=0.02, l=11.06]', '\" painter\"[p=0.02, l=11.06]', '\" musician\"[p=0.01, l=10.88]', '\" software\"[p=0.01, l=10.75]', '\" (\"[p=0.01, l=10.69]']\n",
      "nationality => ['\" Spanish\"[p=0.64, l=17.75]', '\"?\\n\"[p=0.07, l=15.50]', '\"?\"[p=0.05, l=15.12]', '\" Mexican\"[p=0.04, l=15.00]', '\"??\"[p=0.03, l=14.56]', '\" Argentine\"[p=0.02, l=14.25]', '\"?\\n\\n\"[p=0.01, l=13.75]', '\"???\"[p=0.01, l=13.69]', '\" (\"[p=0.01, l=13.56]', '\" Chile\"[p=0.01, l=13.38]', '\" unknown\"[p=0.01, l=13.38]', '\" Unknown\"[p=0.01, l=13.25]', '\" Span\"[p=0.01, l=13.00]', '\" Venezuelan\"[p=0.00, l=12.50]', '\" Arg\"[p=0.00, l=12.50]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" painter\"[p=0.52, l=21.00]', '\" artist\"[p=0.46, l=20.88]', '\" Painter\"[p=0.00, l=15.81]', '\" Artist\"[p=0.00, l=15.31]', '\" (\"[p=0.00, l=15.06]', '\"?\\n\"[p=0.00, l=14.50]', '\"artist\"[p=0.00, l=14.50]', '\" \"[p=0.00, l=14.38]', '\"paint\"[p=0.00, l=14.25]', '\"??\"[p=0.00, l=14.06]', '\" visual\"[p=0.00, l=13.94]', '\"?\"[p=0.00, l=13.94]', '\" spanish\"[p=0.00, l=13.81]', '\" what\"[p=0.00, l=13.50]', '\" painting\"[p=0.00, l=13.44]']\n",
      "nationality => ['\" Spanish\"[p=0.99, l=22.25]', '\" Span\"[p=0.00, l=16.62]', '\" spanish\"[p=0.00, l=15.75]', '\" French\"[p=0.00, l=15.62]', '\" Spain\"[p=0.00, l=15.44]', '\"?\\n\"[p=0.00, l=15.00]', '\"Spanish\"[p=0.00, l=14.50]', '\" \"[p=0.00, l=14.38]', '\" (\"[p=0.00, l=14.25]', '\"??\"[p=0.00, l=14.06]', '\" \\n\"[p=0.00, l=13.69]', '\"?\"[p=0.00, l=13.69]', '\" Catalan\"[p=0.00, l=13.44]', '\"???\"[p=0.00, l=13.12]', '\" Mexican\"[p=0.00, l=12.94]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.58, l=16.12]', '\" painter\"[p=0.16, l=14.81]', '\" surre\"[p=0.06, l=13.88]', '\" Salvador\"[p=0.01, l=12.12]', '\" architect\"[p=0.01, l=12.00]', '\"??\"[p=0.01, l=11.88]', '\"?\\n\"[p=0.01, l=11.69]', '\" Artist\"[p=0.01, l=11.69]', '\" (\"[p=0.01, l=11.50]', '\"?\"[p=0.01, l=11.38]', '\" football\"[p=0.00, l=11.31]', '\" D\"[p=0.00, l=11.12]', '\"???\"[p=0.00, l=11.06]', '\" what\"[p=0.00, l=11.06]', '\" Painter\"[p=0.00, l=11.00]']\n",
      "nationality => ['\" Spanish\"[p=0.66, l=17.38]', '\" Salvador\"[p=0.09, l=15.38]', '\" Catalan\"[p=0.03, l=14.31]', '\" Mexican\"[p=0.02, l=13.75]', '\"?\\n\"[p=0.02, l=13.62]', '\"?\"[p=0.01, l=13.50]', '\" Span\"[p=0.01, l=13.44]', '\"??\"[p=0.01, l=13.31]', '\" Brazilian\"[p=0.01, l=12.88]', '\" unknown\"[p=0.01, l=12.88]', '\"???\"[p=0.01, l=12.81]', '\" Dominican\"[p=0.01, l=12.50]', '\" (\"[p=0.00, l=12.44]', '\" Indian\"[p=0.00, l=12.25]', '\" D\"[p=0.00, l=12.06]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.41, l=15.44]', '\" painter\"[p=0.34, l=15.25]', '\" surre\"[p=0.08, l=13.75]', '\" Salvador\"[p=0.02, l=12.19]', '\" Painter\"[p=0.01, l=11.31]', '\" Artist\"[p=0.00, l=11.00]', '\" \"[p=0.00, l=10.75]', '\" Surre\"[p=0.00, l=10.69]', '\" (\"[p=0.00, l=10.62]', '\" football\"[p=0.00, l=10.31]', '\" sculpt\"[p=0.00, l=10.06]', '\" architect\"[p=0.00, l=10.00]', '\" illustrator\"[p=0.00, l=10.00]', '\" poet\"[p=0.00, l=10.00]', '\" chem\"[p=0.00, l=9.94]']\n",
      "nationality => ['\" Spanish\"[p=0.72, l=16.75]', '\" Catalan\"[p=0.08, l=14.50]', '\" Indian\"[p=0.02, l=13.12]', '\" Salvador\"[p=0.01, l=12.12]', '\" Italian\"[p=0.01, l=12.12]', '\" American\"[p=0.01, l=12.06]', '\" French\"[p=0.01, l=11.88]', '\"??\"[p=0.00, l=11.75]', '\" Japanese\"[p=0.00, l=11.62]', '\"?\\n\"[p=0.00, l=11.56]', '\" Span\"[p=0.00, l=11.50]', '\" Russian\"[p=0.00, l=11.44]', '\" Pakistani\"[p=0.00, l=11.44]', '\" not\"[p=0.00, l=11.31]', '\" (\"[p=0.00, l=11.31]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" painter\"[p=0.46, l=17.25]', '\" artist\"[p=0.36, l=17.00]', '\" surre\"[p=0.07, l=15.31]', '\"?\\n\"[p=0.02, l=13.94]', '\" Salvador\"[p=0.01, l=13.62]', '\"?\\n\\n\"[p=0.00, l=12.69]', '\" Painter\"[p=0.00, l=12.50]', '\"??\"[p=0.00, l=12.38]', '\" (\"[p=0.00, l=12.31]', '\" \\n\"[p=0.00, l=12.19]', '\"?\"[p=0.00, l=12.12]', '\" art\"[p=0.00, l=12.06]', '\" architect\"[p=0.00, l=11.94]', '\" poet\"[p=0.00, l=11.88]', '\" \"[p=0.00, l=11.69]']\n",
      "nationality => ['\" Spanish\"[p=0.83, l=18.62]', '\"?\\n\"[p=0.04, l=15.56]', '\" Catalan\"[p=0.02, l=15.00]', '\" Pakistani\"[p=0.02, l=14.62]', '\" Span\"[p=0.01, l=14.38]', '\"??\"[p=0.01, l=13.81]', '\" Indian\"[p=0.01, l=13.75]', '\"?\"[p=0.01, l=13.56]', '\"?\\n\\n\"[p=0.00, l=13.50]', '\" \\n\"[p=0.00, l=13.00]', '\" (\"[p=0.00, l=12.44]', '\" spanish\"[p=0.00, l=12.38]', '\"???\"[p=0.00, l=12.25]', '\" Iranian\"[p=0.00, l=12.12]', '\" Turkish\"[p=0.00, l=12.06]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=41 (model.layers.41)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.21, l=13.19]', '\"?\\n\\n\"[p=0.09, l=12.38]', '\" artist\"[p=0.08, l=12.25]', '\"?\"[p=0.06, l=11.88]', '\"??\"[p=0.04, l=11.56]', '\" painter\"[p=0.03, l=11.31]', '\" ->\"[p=0.02, l=10.94]', '\" (\"[p=0.02, l=10.62]', '\" \\n\"[p=0.01, l=10.50]', '\"???\"[p=0.01, l=10.25]', '\" your\"[p=0.01, l=10.25]', '\" musician\"[p=0.01, l=10.25]', '\" unknown\"[p=0.01, l=10.00]', '\" entrepreneur\"[p=0.01, l=9.88]', '\" actor\"[p=0.01, l=9.88]']\n",
      "nationality => ['\"?\\n\"[p=0.21, l=14.31]', '\" Spanish\"[p=0.11, l=13.69]', '\"?\"[p=0.11, l=13.62]', '\"?\\n\\n\"[p=0.11, l=13.62]', '\" Pakistani\"[p=0.04, l=12.69]', '\" Indian\"[p=0.04, l=12.62]', '\"??\"[p=0.03, l=12.31]', '\" (\"[p=0.02, l=12.00]', '\" French\"[p=0.02, l=11.94]', '\" \\n\"[p=0.02, l=11.94]', '\" \"[p=0.01, l=11.19]', '\"???\"[p=0.01, l=11.19]', '\" ->\"[p=0.01, l=10.81]', '\" Catalan\"[p=0.01, l=10.75]', '\" National\"[p=0.01, l=10.69]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.15, l=13.31]', '\"?\\n\\n\"[p=0.08, l=12.69]', '\" artist\"[p=0.06, l=12.44]', '\"?\"[p=0.06, l=12.38]', '\" tennis\"[p=0.05, l=12.19]', '\"??\"[p=0.04, l=12.00]', '\" soccer\"[p=0.04, l=12.00]', '\" football\"[p=0.04, l=11.88]', '\"???\"[p=0.03, l=11.62]', '\" unknown\"[p=0.03, l=11.50]', '\" architect\"[p=0.02, l=11.19]', '\" painter\"[p=0.02, l=11.19]', '\" musician\"[p=0.01, l=10.81]', '\" software\"[p=0.01, l=10.75]', '\" (\"[p=0.01, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.65, l=17.62]', '\"?\\n\"[p=0.06, l=15.25]', '\"?\"[p=0.04, l=14.81]', '\" Mexican\"[p=0.04, l=14.75]', '\" Argentine\"[p=0.02, l=14.25]', '\"??\"[p=0.02, l=14.25]', '\" (\"[p=0.01, l=13.44]', '\"?\\n\\n\"[p=0.01, l=13.44]', '\"???\"[p=0.01, l=13.31]', '\" Chile\"[p=0.01, l=13.31]', '\" unknown\"[p=0.01, l=13.12]', '\" Unknown\"[p=0.01, l=12.94]', '\" Span\"[p=0.01, l=12.88]', '\" Venezuelan\"[p=0.00, l=12.62]', '\" Arg\"[p=0.00, l=12.50]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" painter\"[p=0.52, l=20.00]', '\" artist\"[p=0.46, l=19.88]', '\" Painter\"[p=0.00, l=15.00]', '\"?\\n\"[p=0.00, l=14.81]', '\" (\"[p=0.00, l=14.69]', '\" Artist\"[p=0.00, l=14.62]', '\"??\"[p=0.00, l=14.12]', '\"?\"[p=0.00, l=13.88]', '\" \"[p=0.00, l=13.81]', '\"artist\"[p=0.00, l=13.75]', '\"paint\"[p=0.00, l=13.56]', '\" what\"[p=0.00, l=13.38]', '\" spanish\"[p=0.00, l=13.31]', '\" \\n\"[p=0.00, l=13.25]', '\"???\"[p=0.00, l=13.06]']\n",
      "nationality => ['\" Spanish\"[p=0.98, l=21.75]', '\" Span\"[p=0.00, l=16.12]', '\" French\"[p=0.00, l=15.56]', '\" spanish\"[p=0.00, l=15.38]', '\"?\\n\"[p=0.00, l=15.00]', '\" Spain\"[p=0.00, l=15.00]', '\"Spanish\"[p=0.00, l=14.12]', '\" (\"[p=0.00, l=14.12]', '\"??\"[p=0.00, l=14.06]', '\" \"[p=0.00, l=14.00]', '\"?\"[p=0.00, l=13.62]', '\" \\n\"[p=0.00, l=13.50]', '\" Catalan\"[p=0.00, l=13.12]', '\"???\"[p=0.00, l=13.12]', '\" a\"[p=0.00, l=12.44]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.60, l=16.25]', '\" painter\"[p=0.16, l=14.94]', '\" surre\"[p=0.04, l=13.56]', '\" architect\"[p=0.01, l=12.31]', '\" Salvador\"[p=0.01, l=12.12]', '\"??\"[p=0.01, l=12.00]', '\"?\\n\"[p=0.01, l=11.94]', '\" Artist\"[p=0.01, l=11.75]', '\" (\"[p=0.01, l=11.56]', '\" football\"[p=0.01, l=11.56]', '\"?\"[p=0.01, l=11.50]', '\" what\"[p=0.00, l=11.25]', '\"???\"[p=0.00, l=11.25]', '\" D\"[p=0.00, l=11.19]', '\" Painter\"[p=0.00, l=11.12]']\n",
      "nationality => ['\" Spanish\"[p=0.61, l=17.25]', '\" Salvador\"[p=0.11, l=15.50]', '\" Catalan\"[p=0.02, l=13.94]', '\"?\\n\"[p=0.02, l=13.81]', '\" Mexican\"[p=0.02, l=13.75]', '\"?\"[p=0.02, l=13.62]', '\"??\"[p=0.01, l=13.50]', '\" Brazilian\"[p=0.01, l=13.38]', '\" Span\"[p=0.01, l=13.38]', '\" unknown\"[p=0.01, l=13.12]', '\"???\"[p=0.01, l=12.94]', '\" Dominican\"[p=0.01, l=12.69]', '\" (\"[p=0.01, l=12.50]', '\" Unknown\"[p=0.00, l=12.25]', '\" Italian\"[p=0.00, l=12.19]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.35, l=13.88]', '\" painter\"[p=0.27, l=13.62]', '\" surre\"[p=0.05, l=12.00]', '\" Salvador\"[p=0.02, l=10.75]', '\" football\"[p=0.01, l=9.94]', '\" Painter\"[p=0.01, l=9.94]', '\" Artist\"[p=0.01, l=9.81]', '\" \"[p=0.01, l=9.69]', '\" chem\"[p=0.00, l=9.50]', '\" (\"[p=0.00, l=9.44]', '\" actor\"[p=0.00, l=9.31]', '\" musician\"[p=0.00, l=9.31]', '\" Surre\"[p=0.00, l=9.31]', '\" singer\"[p=0.00, l=9.25]', '\" sculpt\"[p=0.00, l=9.19]']\n",
      "nationality => ['\" Spanish\"[p=0.59, l=15.75]', '\" Catalan\"[p=0.07, l=13.69]', '\" Indian\"[p=0.04, l=13.00]', '\" Italian\"[p=0.01, l=11.81]', '\" American\"[p=0.01, l=11.75]', '\" Salvador\"[p=0.01, l=11.69]', '\" French\"[p=0.01, l=11.69]', '\" Japanese\"[p=0.01, l=11.56]', '\" Pakistani\"[p=0.01, l=11.50]', '\"??\"[p=0.01, l=11.38]', '\" Korean\"[p=0.01, l=11.31]', '\"?\\n\"[p=0.01, l=11.25]', '\" Russian\"[p=0.01, l=11.12]', '\" unknown\"[p=0.01, l=11.06]', '\" Chinese\"[p=0.01, l=11.06]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" artist\"[p=0.38, l=15.94]', '\" painter\"[p=0.31, l=15.75]', '\"?\\n\"[p=0.05, l=14.00]', '\" surre\"[p=0.04, l=13.62]', '\"?\\n\\n\"[p=0.02, l=13.12]', '\" architect\"[p=0.01, l=12.50]', '\" poet\"[p=0.01, l=12.50]', '\"??\"[p=0.01, l=12.06]', '\"?\"[p=0.01, l=11.88]', '\" sculpt\"[p=0.01, l=11.69]', '\" (\"[p=0.00, l=11.56]', '\" art\"[p=0.00, l=11.56]', '\" \\n\"[p=0.00, l=11.44]', '\" writer\"[p=0.00, l=11.38]', '\" what\"[p=0.00, l=11.38]']\n",
      "nationality => ['\" Spanish\"[p=0.71, l=18.00]', '\"?\\n\"[p=0.09, l=15.94]', '\"??\"[p=0.02, l=14.38]', '\" Span\"[p=0.02, l=14.38]', '\" Indian\"[p=0.02, l=14.31]', '\" Catalan\"[p=0.02, l=14.19]', '\"?\\n\\n\"[p=0.02, l=14.19]', '\"?\"[p=0.01, l=14.06]', '\" Pakistani\"[p=0.01, l=13.88]', '\" \\n\"[p=0.00, l=12.88]', '\"???\"[p=0.00, l=12.88]', '\" Argentine\"[p=0.00, l=12.44]', '\" Mexican\"[p=0.00, l=12.31]', '\" (\"[p=0.00, l=12.31]', '\" Iranian\"[p=0.00, l=12.19]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=45 (model.layers.45)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.23, l=13.69]', '\" artist\"[p=0.10, l=12.88]', '\" painter\"[p=0.07, l=12.44]', '\"?\\n\\n\"[p=0.07, l=12.44]', '\"?\"[p=0.04, l=11.94]', '\"??\"[p=0.03, l=11.69]', '\" musician\"[p=0.02, l=11.25]', '\" ->\"[p=0.02, l=11.06]', '\" actor\"[p=0.01, l=10.88]', '\" \\n\"[p=0.01, l=10.75]', '\" (\"[p=0.01, l=10.69]', '\" singer\"[p=0.01, l=10.69]', '\" architect\"[p=0.01, l=10.50]', '\"???\"[p=0.01, l=10.44]', '\" lawyer\"[p=0.01, l=10.38]']\n",
      "nationality => ['\" Spanish\"[p=0.36, l=15.38]', '\"?\\n\"[p=0.19, l=14.75]', '\"?\"[p=0.05, l=13.38]', '\"?\\n\\n\"[p=0.05, l=13.31]', '\" Span\"[p=0.04, l=13.06]', '\" Pakistani\"[p=0.02, l=12.50]', '\" Catalan\"[p=0.02, l=12.38]', '\" \\n\"[p=0.02, l=12.25]', '\" (\"[p=0.02, l=12.25]', '\"??\"[p=0.01, l=12.06]', '\" Indian\"[p=0.01, l=11.94]', '\" French\"[p=0.01, l=11.56]', '\" National\"[p=0.01, l=11.50]', '\" \"[p=0.01, l=11.44]', '\" Mexican\"[p=0.01, l=11.38]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.16, l=13.38]', '\"?\\n\\n\"[p=0.11, l=13.00]', '\"?\"[p=0.07, l=12.62]', '\" artist\"[p=0.05, l=12.31]', '\"??\"[p=0.05, l=12.25]', '\" tennis\"[p=0.05, l=12.12]', '\"???\"[p=0.04, l=11.88]', '\" soccer\"[p=0.03, l=11.75]', '\" football\"[p=0.03, l=11.56]', '\" unknown\"[p=0.02, l=11.31]', '\" painter\"[p=0.02, l=11.12]', '\" architect\"[p=0.02, l=11.06]', '\" musician\"[p=0.01, l=10.88]', '\" software\"[p=0.01, l=10.69]', '\" (\"[p=0.01, l=10.62]']\n",
      "nationality => ['\" Spanish\"[p=0.56, l=17.12]', '\"?\\n\"[p=0.10, l=15.38]', '\"?\"[p=0.06, l=14.94]', '\"??\"[p=0.04, l=14.38]', '\" Mexican\"[p=0.02, l=13.94]', '\" Argentine\"[p=0.02, l=13.94]', '\"?\\n\\n\"[p=0.02, l=13.81]', '\"???\"[p=0.01, l=13.44]', '\" unknown\"[p=0.01, l=13.06]', '\" (\"[p=0.01, l=13.06]', '\" Unknown\"[p=0.01, l=12.88]', '\" Chile\"[p=0.01, l=12.81]', '\" Span\"[p=0.01, l=12.56]', '\" Cuban\"[p=0.00, l=12.06]', '\" Not\"[p=0.00, l=12.06]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" painter\"[p=0.50, l=19.12]', '\" artist\"[p=0.45, l=19.00]', '\"?\\n\"[p=0.01, l=14.62]', '\" (\"[p=0.00, l=14.25]', '\" Painter\"[p=0.00, l=14.19]', '\" Artist\"[p=0.00, l=13.94]', '\"??\"[p=0.00, l=13.88]', '\"?\"[p=0.00, l=13.69]', '\" \"[p=0.00, l=13.25]', '\" what\"[p=0.00, l=13.06]', '\"?\\n\\n\"[p=0.00, l=13.00]', '\" \\n\"[p=0.00, l=13.00]', '\"???\"[p=0.00, l=12.88]', '\"artist\"[p=0.00, l=12.88]', '\" Spanish\"[p=0.00, l=12.75]']\n",
      "nationality => ['\" Spanish\"[p=0.98, l=21.00]', '\" Span\"[p=0.00, l=15.62]', '\"?\\n\"[p=0.00, l=15.31]', '\" spanish\"[p=0.00, l=14.75]', '\" French\"[p=0.00, l=14.38]', '\"??\"[p=0.00, l=14.25]', '\" Spain\"[p=0.00, l=14.19]', '\" (\"[p=0.00, l=14.00]', '\"?\"[p=0.00, l=13.75]', '\" \"[p=0.00, l=13.56]', '\"Spanish\"[p=0.00, l=13.50]', '\" \\n\"[p=0.00, l=13.44]', '\"???\"[p=0.00, l=13.31]', '\"?\\n\\n\"[p=0.00, l=12.94]', '\" Catalan\"[p=0.00, l=12.56]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.57, l=15.94]', '\" painter\"[p=0.15, l=14.62]', '\" surre\"[p=0.06, l=13.62]', '\" Salvador\"[p=0.01, l=11.88]', '\"?\\n\"[p=0.01, l=11.81]', '\"??\"[p=0.01, l=11.75]', '\" Artist\"[p=0.01, l=11.75]', '\" architect\"[p=0.01, l=11.62]', '\"?\"[p=0.00, l=11.19]', '\" what\"[p=0.00, l=11.12]', '\" football\"[p=0.00, l=11.06]', '\" D\"[p=0.00, l=11.06]', '\" Painter\"[p=0.00, l=11.06]', '\"???\"[p=0.00, l=11.06]', '\" (\"[p=0.00, l=11.00]']\n",
      "nationality => ['\" Spanish\"[p=0.62, l=17.12]', '\" Salvador\"[p=0.10, l=15.31]', '\" Catalan\"[p=0.03, l=14.19]', '\"?\\n\"[p=0.02, l=13.69]', '\" Mexican\"[p=0.02, l=13.44]', '\"??\"[p=0.01, l=13.38]', '\" Span\"[p=0.01, l=13.38]', '\"?\"[p=0.01, l=13.38]', '\" Brazilian\"[p=0.01, l=13.00]', '\" unknown\"[p=0.01, l=12.75]', '\"???\"[p=0.01, l=12.75]', '\" Italian\"[p=0.01, l=12.38]', '\" Dominican\"[p=0.01, l=12.38]', '\" Unknown\"[p=0.00, l=12.00]', '\" (\"[p=0.00, l=12.00]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.44, l=16.12]', '\" painter\"[p=0.32, l=15.81]', '\" surre\"[p=0.10, l=14.69]', '\" Salvador\"[p=0.01, l=12.69]', '\" Painter\"[p=0.01, l=11.69]', '\" Artist\"[p=0.00, l=11.62]', '\" Surre\"[p=0.00, l=11.44]', '\" \"[p=0.00, l=11.38]', '\" (\"[p=0.00, l=10.94]', '\" architect\"[p=0.00, l=10.44]', '\" sculpt\"[p=0.00, l=10.44]', '\" poet\"[p=0.00, l=10.38]', '\"paint\"[p=0.00, l=10.25]', '\" visual\"[p=0.00, l=10.25]', '\" football\"[p=0.00, l=10.19]']\n",
      "nationality => ['\" Spanish\"[p=0.74, l=16.75]', '\" Catalan\"[p=0.06, l=14.31]', '\" Salvador\"[p=0.01, l=12.81]', '\" Indian\"[p=0.01, l=12.56]', '\" Italian\"[p=0.01, l=12.12]', '\" French\"[p=0.01, l=12.06]', '\" American\"[p=0.01, l=11.88]', '\"??\"[p=0.01, l=11.81]', '\"?\\n\"[p=0.00, l=11.69]', '\" Japanese\"[p=0.00, l=11.44]', '\" Russian\"[p=0.00, l=11.38]', '\" Span\"[p=0.00, l=11.31]', '\" (\"[p=0.00, l=11.19]', '\" \\n\"[p=0.00, l=11.12]', '\" not\"[p=0.00, l=11.12]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\" artist\"[p=0.29, l=14.69]', '\"?\\n\"[p=0.13, l=13.88]', '\" painter\"[p=0.12, l=13.81]', '\"?\\n\\n\"[p=0.06, l=13.12]', '\" architect\"[p=0.02, l=12.19]', '\"??\"[p=0.02, l=12.19]', '\"?\"[p=0.02, l=11.94]', '\" politician\"[p=0.01, l=11.62]', '\" poet\"[p=0.01, l=11.50]', '\"???\"[p=0.01, l=11.25]', '\" writer\"[p=0.01, l=11.12]', '\" actor\"[p=0.01, l=11.06]', '\" what\"[p=0.01, l=10.94]', '\" sculpt\"[p=0.01, l=10.81]', '\" \\n\"[p=0.01, l=10.75]']\n",
      "nationality => ['\" Spanish\"[p=0.55, l=17.38]', '\"?\\n\"[p=0.14, l=16.00]', '\"??\"[p=0.04, l=14.62]', '\"?\\n\\n\"[p=0.04, l=14.62]', '\"?\"[p=0.03, l=14.31]', '\" Indian\"[p=0.02, l=14.25]', '\" Pakistani\"[p=0.02, l=14.19]', '\" Span\"[p=0.02, l=13.94]', '\"???\"[p=0.01, l=13.38]', '\" Catalan\"[p=0.01, l=13.25]', '\" \\n\"[p=0.01, l=12.75]', '\" Iranian\"[p=0.00, l=12.62]', '\" Argentine\"[p=0.00, l=12.62]', '\" Mexican\"[p=0.00, l=12.38]', '\" (\"[p=0.00, l=12.31]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=55 (model.layers.55)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\" painter\"[p=0.26, l=13.75]', '\" artist\"[p=0.20, l=13.50]', '\"?\\n\"[p=0.10, l=12.75]', '\"?\\n\\n\"[p=0.04, l=11.75]', '\" ->\"[p=0.02, l=11.31]', '\"?\"[p=0.02, l=11.12]', '\" ->\\n\"[p=0.01, l=10.81]', '\" Spanish\"[p=0.01, l=10.62]', '\" (\"[p=0.01, l=10.62]', '\" \\n\"[p=0.01, l=10.50]', '\" -\\n\"[p=0.01, l=10.44]', '\"??\"[p=0.01, l=10.44]', '\" Pablo\"[p=0.01, l=10.38]', '\" Painter\"[p=0.01, l=10.19]', '\" lawyer\"[p=0.01, l=10.06]']\n",
      "nationality => ['\" Spanish\"[p=0.62, l=16.25]', '\"?\\n\"[p=0.07, l=14.00]', '\" Span\"[p=0.05, l=13.62]', '\"?\\n\\n\"[p=0.02, l=12.81]', '\" -\\n\"[p=0.02, l=12.56]', '\"?\"[p=0.01, l=12.44]', '\" (\"[p=0.01, l=12.44]', '\" Catalan\"[p=0.01, l=12.31]', '\" \\n\"[p=0.01, l=12.12]', '\" ->\"[p=0.01, l=12.12]', '\" -\"[p=0.01, l=12.06]', '\" National\"[p=0.01, l=11.62]', '\" \"[p=0.01, l=11.56]', '\" -\\n\\n\"[p=0.01, l=11.50]', '\"??\"[p=0.00, l=11.25]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.14, l=13.31]', '\"?\\n\\n\"[p=0.08, l=12.75]', '\"?\"[p=0.07, l=12.62]', '\" artist\"[p=0.06, l=12.50]', '\"??\"[p=0.04, l=12.12]', '\" tennis\"[p=0.04, l=12.00]', '\" soccer\"[p=0.04, l=11.94]', '\" football\"[p=0.03, l=11.88]', '\"???\"[p=0.03, l=11.75]', '\" unknown\"[p=0.02, l=11.44]', '\" architect\"[p=0.02, l=11.38]', '\" painter\"[p=0.02, l=11.25]', '\" software\"[p=0.01, l=11.00]', '\" musician\"[p=0.01, l=10.88]', '\" (\"[p=0.01, l=10.81]']\n",
      "nationality => ['\" Spanish\"[p=0.66, l=17.38]', '\"?\\n\"[p=0.07, l=15.06]', '\"?\"[p=0.05, l=14.75]', '\"??\"[p=0.03, l=14.25]', '\" Mexican\"[p=0.02, l=13.62]', '\" Argentine\"[p=0.01, l=13.50]', '\"?\\n\\n\"[p=0.01, l=13.50]', '\"???\"[p=0.01, l=13.31]', '\" unknown\"[p=0.01, l=13.19]', '\" Unknown\"[p=0.01, l=13.06]', '\" (\"[p=0.01, l=12.75]', '\" Span\"[p=0.01, l=12.62]', '\" Chile\"[p=0.01, l=12.50]', '\" Cuban\"[p=0.00, l=12.12]', '\" no\"[p=0.00, l=12.06]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" painter\"[p=0.55, l=18.75]', '\" artist\"[p=0.38, l=18.38]', '\"?\\n\"[p=0.01, l=14.69]', '\" Painter\"[p=0.01, l=14.06]', '\"??\"[p=0.00, l=13.88]', '\" (\"[p=0.00, l=13.88]', '\"?\"[p=0.00, l=13.88]', '\" Artist\"[p=0.00, l=13.50]', '\"?\\n\\n\"[p=0.00, l=13.44]', '\" Spanish\"[p=0.00, l=13.25]', '\" spanish\"[p=0.00, l=13.19]', '\" Pablo\"[p=0.00, l=13.19]', '\" \"[p=0.00, l=13.12]', '\" \\n\"[p=0.00, l=13.06]', '\"???\"[p=0.00, l=12.94]']\n",
      "nationality => ['\" Spanish\"[p=0.95, l=19.88]', '\"?\\n\"[p=0.01, l=15.56]', '\" Span\"[p=0.00, l=14.38]', '\"??\"[p=0.00, l=14.31]', '\"?\"[p=0.00, l=14.12]', '\" spanish\"[p=0.00, l=14.00]', '\" (\"[p=0.00, l=13.94]', '\" \\n\"[p=0.00, l=13.62]', '\"???\"[p=0.00, l=13.44]', '\"?\\n\\n\"[p=0.00, l=13.38]', '\" \"[p=0.00, l=13.12]', '\" Spain\"[p=0.00, l=12.81]', '\" French\"[p=0.00, l=12.56]', '\"Spanish\"[p=0.00, l=12.50]', '\" What\"[p=0.00, l=12.25]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.40, l=14.56]', '\" painter\"[p=0.10, l=13.19]', '\"?\\n\"[p=0.08, l=12.94]', '\"??\"[p=0.03, l=11.94]', '\"?\"[p=0.03, l=11.81]', '\"???\"[p=0.02, l=11.50]', '\" architect\"[p=0.02, l=11.44]', '\" surre\"[p=0.02, l=11.38]', '\"?\\n\\n\"[p=0.02, l=11.31]', '\" what\"[p=0.01, l=11.06]', '\" Salvador\"[p=0.01, l=11.00]', '\" unknown\"[p=0.01, l=10.94]', '\" Dal\"[p=0.01, l=10.62]', '\" football\"[p=0.01, l=10.62]', '\" Artist\"[p=0.01, l=10.31]']\n",
      "nationality => ['\" Spanish\"[p=0.58, l=16.75]', '\"?\\n\"[p=0.06, l=14.44]', '\" Catalan\"[p=0.04, l=14.06]', '\"?\"[p=0.04, l=14.00]', '\" Salvador\"[p=0.03, l=13.94]', '\"??\"[p=0.03, l=13.88]', '\"???\"[p=0.02, l=13.19]', '\" unknown\"[p=0.01, l=13.00]', '\" Span\"[p=0.01, l=13.00]', '\" Mexican\"[p=0.01, l=12.69]', '\" Brazilian\"[p=0.01, l=12.62]', '\" Unknown\"[p=0.01, l=12.44]', '\" Portuguese\"[p=0.01, l=12.44]', '\"?\\n\\n\"[p=0.01, l=12.19]', '\" Italian\"[p=0.00, l=11.94]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.47, l=16.25]', '\" surre\"[p=0.22, l=15.50]', '\" painter\"[p=0.16, l=15.19]', '\" Salvador\"[p=0.02, l=13.25]', '\" Surre\"[p=0.01, l=11.88]', '\" Artist\"[p=0.00, l=11.69]', '\" \"[p=0.00, l=11.31]', '\" (\"[p=0.00, l=11.31]', '\" Painter\"[p=0.00, l=11.19]', '\" singer\"[p=0.00, l=10.50]', '\" actor\"[p=0.00, l=10.44]', '\"??\"[p=0.00, l=10.44]', '\" visual\"[p=0.00, l=10.44]', '\" musician\"[p=0.00, l=10.44]', '\" \\n\"[p=0.00, l=10.44]']\n",
      "nationality => ['\" Spanish\"[p=0.79, l=17.75]', '\" Catalan\"[p=0.05, l=15.06]', '\" Salvador\"[p=0.04, l=14.81]', '\" French\"[p=0.01, l=13.31]', '\" Italian\"[p=0.01, l=13.06]', '\" Russian\"[p=0.00, l=12.38]', '\" American\"[p=0.00, l=12.38]', '\" Span\"[p=0.00, l=12.31]', '\"?\\n\"[p=0.00, l=12.25]', '\"??\"[p=0.00, l=12.25]', '\" Japanese\"[p=0.00, l=12.19]', '\" \\n\"[p=0.00, l=12.12]', '\" Swedish\"[p=0.00, l=12.06]', '\" Spain\"[p=0.00, l=11.94]', '\" spanish\"[p=0.00, l=11.88]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\"?\\n\"[p=0.19, l=13.88]', '\" artist\"[p=0.11, l=13.31]', '\"?\\n\\n\"[p=0.08, l=13.06]', '\"??\"[p=0.07, l=12.81]', '\"?\"[p=0.04, l=12.31]', '\" politician\"[p=0.03, l=12.12]', '\"???\"[p=0.03, l=11.88]', '\" painter\"[p=0.02, l=11.81]', '\" entrepreneur\"[p=0.02, l=11.50]', '\" software\"[p=0.02, l=11.44]', '\" architect\"[p=0.01, l=11.25]', '\" what\"[p=0.01, l=11.12]', '\" writer\"[p=0.01, l=11.06]', '\" actor\"[p=0.01, l=11.06]', '\" unknown\"[p=0.01, l=10.81]']\n",
      "nationality => ['\" Spanish\"[p=0.61, l=17.75]', '\"?\\n\"[p=0.13, l=16.25]', '\"??\"[p=0.05, l=15.19]', '\"?\\n\\n\"[p=0.04, l=14.94]', '\"?\"[p=0.03, l=14.62]', '\" Span\"[p=0.02, l=14.38]', '\"???\"[p=0.02, l=14.06]', '\" Catalan\"[p=0.01, l=13.38]', '\" Indian\"[p=0.01, l=13.19]', '\" Pakistani\"[p=0.01, l=13.00]', '\" \\n\"[p=0.00, l=12.81]', '\" their\"[p=0.00, l=12.62]', '\" Argentine\"[p=0.00, l=12.62]', '\" (\"[p=0.00, l=12.25]', '\" your\"[p=0.00, l=12.06]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=65 (model.layers.65)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\" artist\"[p=0.18, l=12.62]', '\" painter\"[p=0.13, l=12.31]', '\"?\\n\"[p=0.11, l=12.19]', '\"?\\n\\n\"[p=0.04, l=11.19]', '\"?\"[p=0.03, l=10.94]', '\"??\"[p=0.02, l=10.31]', '\" unknown\"[p=0.01, l=10.12]', '\" Spanish\"[p=0.01, l=10.00]', '\" (\"[p=0.01, l=10.00]', '\" \\n\"[p=0.01, l=10.00]', '\" \"[p=0.01, l=9.94]', '\" ->\"[p=0.01, l=9.88]', '\" not\"[p=0.01, l=9.56]', '\" computer\"[p=0.01, l=9.50]', '\" blank\"[p=0.01, l=9.25]']\n",
      "nationality => ['\" Spanish\"[p=0.52, l=14.31]', '\"?\\n\"[p=0.06, l=12.19]', '\" Span\"[p=0.03, l=11.38]', '\" Catalan\"[p=0.03, l=11.31]', '\"?\\n\\n\"[p=0.02, l=10.94]', '\" National\"[p=0.02, l=10.94]', '\"?\"[p=0.02, l=10.81]', '\" \"[p=0.01, l=10.69]', '\" (\"[p=0.01, l=10.56]', '\" ->\"[p=0.01, l=10.44]', '\" \\n\"[p=0.01, l=10.19]', '\" nationality\"[p=0.01, l=10.19]', '\" ->\\n\"[p=0.01, l=9.81]', '\" -\\n\"[p=0.01, l=9.69]', '\"??\"[p=0.00, l=9.62]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.10, l=12.88]', '\" soccer\"[p=0.07, l=12.56]', '\" artist\"[p=0.07, l=12.56]', '\"?\"[p=0.06, l=12.31]', '\"?\\n\\n\"[p=0.05, l=12.19]', '\" football\"[p=0.05, l=12.12]', '\" tennis\"[p=0.05, l=12.12]', '\"??\"[p=0.03, l=11.75]', '\" software\"[p=0.03, l=11.75]', '\"???\"[p=0.02, l=11.50]', '\" unknown\"[p=0.02, l=11.44]', '\" architect\"[p=0.02, l=11.19]', '\" programmer\"[p=0.02, l=11.06]', '\" painter\"[p=0.02, l=11.00]', '\" singer\"[p=0.01, l=10.94]']\n",
      "nationality => ['\" Spanish\"[p=0.68, l=17.38]', '\"?\\n\"[p=0.06, l=15.00]', '\"?\"[p=0.04, l=14.62]', '\"??\"[p=0.03, l=14.19]', '\" Mexican\"[p=0.02, l=13.69]', '\"?\\n\\n\"[p=0.01, l=13.50]', '\" Argentine\"[p=0.01, l=13.31]', '\"???\"[p=0.01, l=13.25]', '\" unknown\"[p=0.01, l=13.19]', '\" Unknown\"[p=0.01, l=13.00]', '\" (\"[p=0.01, l=12.50]', '\" Span\"[p=0.01, l=12.50]', '\" Pablo\"[p=0.00, l=12.19]', '\" Chile\"[p=0.00, l=12.12]', '\" no\"[p=0.00, l=11.94]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" painter\"[p=0.51, l=19.50]', '\" artist\"[p=0.45, l=19.38]', '\" Painter\"[p=0.00, l=14.81]', '\" spanish\"[p=0.00, l=14.38]', '\" Spanish\"[p=0.00, l=14.38]', '\" Artist\"[p=0.00, l=14.31]', '\"?\\n\"[p=0.00, l=14.12]', '\" Pablo\"[p=0.00, l=14.06]', '\" (\"[p=0.00, l=13.81]', '\" \"[p=0.00, l=13.75]', '\"??\"[p=0.00, l=13.75]', '\"?\"[p=0.00, l=13.25]', '\" \\n\"[p=0.00, l=13.06]', '\"artist\"[p=0.00, l=12.69]', '\" cub\"[p=0.00, l=12.56]']\n",
      "nationality => ['\" Spanish\"[p=0.97, l=20.25]', '\"?\\n\"[p=0.01, l=15.00]', '\" Span\"[p=0.00, l=14.56]', '\" spanish\"[p=0.00, l=14.12]', '\"??\"[p=0.00, l=14.00]', '\"?\"[p=0.00, l=13.69]', '\" (\"[p=0.00, l=13.62]', '\" \\n\"[p=0.00, l=13.56]', '\" \"[p=0.00, l=13.44]', '\" Spain\"[p=0.00, l=13.25]', '\"???\"[p=0.00, l=13.00]', '\"Spanish\"[p=0.00, l=12.69]', '\"?\\n\\n\"[p=0.00, l=12.62]', '\" French\"[p=0.00, l=12.44]', '\" Catalan\"[p=0.00, l=12.31]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\" artist\"[p=0.21, l=13.12]', '\"?\\n\"[p=0.13, l=12.62]', '\" painter\"[p=0.05, l=11.69]', '\"?\"[p=0.04, l=11.56]', '\"??\"[p=0.04, l=11.38]', '\"?\\n\\n\"[p=0.03, l=11.25]', '\"???\"[p=0.03, l=11.12]', '\" architect\"[p=0.02, l=10.75]', '\" Salvador\"[p=0.02, l=10.69]', '\" football\"[p=0.02, l=10.62]', '\" soccer\"[p=0.01, l=10.25]', '\" unknown\"[p=0.01, l=10.19]', '\" what\"[p=0.01, l=10.06]', '\" Dal\"[p=0.01, l=10.00]', '\" (\"[p=0.01, l=9.81]']\n",
      "nationality => ['\" Spanish\"[p=0.45, l=16.00]', '\"?\\n\"[p=0.09, l=14.44]', '\"?\"[p=0.06, l=14.06]', '\" Salvador\"[p=0.05, l=13.75]', '\"??\"[p=0.05, l=13.75]', '\"???\"[p=0.02, l=13.06]', '\" Catalan\"[p=0.02, l=12.75]', '\" Mexican\"[p=0.02, l=12.75]', '\"?\\n\\n\"[p=0.02, l=12.69]', '\" Span\"[p=0.01, l=12.44]', '\" unknown\"[p=0.01, l=12.44]', '\" Unknown\"[p=0.01, l=12.38]', '\" Brazilian\"[p=0.01, l=12.19]', '\" Indian\"[p=0.01, l=12.12]', '\" (\"[p=0.01, l=11.56]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.35, l=13.88]', '\" painter\"[p=0.07, l=12.31]', '\" surre\"[p=0.07, l=12.31]', '\" Salvador\"[p=0.05, l=11.94]', '\"?\\n\"[p=0.03, l=11.31]', '\"??\"[p=0.02, l=10.94]', '\"?\"[p=0.01, l=10.44]', '\" politician\"[p=0.01, l=10.25]', '\" chem\"[p=0.01, l=10.25]', '\" computer\"[p=0.01, l=10.25]', '\" unknown\"[p=0.01, l=10.06]', '\"???\"[p=0.01, l=10.06]', '\" (\"[p=0.01, l=10.00]', '\" philosopher\"[p=0.01, l=9.94]', '\" actor\"[p=0.01, l=9.88]']\n",
      "nationality => ['\" Spanish\"[p=0.32, l=14.69]', '\" Catalan\"[p=0.15, l=13.94]', '\" Salvador\"[p=0.05, l=12.88]', '\" French\"[p=0.04, l=12.62]', '\"?\\n\"[p=0.03, l=12.38]', '\"??\"[p=0.02, l=12.00]', '\" Indian\"[p=0.02, l=11.81]', '\" unknown\"[p=0.02, l=11.62]', '\"?\"[p=0.01, l=11.56]', '\" American\"[p=0.01, l=11.50]', '\" Japanese\"[p=0.01, l=11.44]', '\" Italian\"[p=0.01, l=11.31]', '\" Unknown\"[p=0.01, l=11.31]', '\" Vietnamese\"[p=0.01, l=11.19]', '\" (\"[p=0.01, l=11.06]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\"?\\n\"[p=0.25, l=14.25]', '\"?\\n\\n\"[p=0.12, l=13.50]', '\"??\"[p=0.08, l=13.06]', '\" artist\"[p=0.06, l=12.75]', '\"?\"[p=0.04, l=12.50]', '\" politician\"[p=0.03, l=12.06]', '\"???\"[p=0.02, l=11.94]', '\" entrepreneur\"[p=0.02, l=11.75]', '\" software\"[p=0.02, l=11.69]', '\" programmer\"[p=0.02, l=11.56]', '\" what\"[p=0.01, l=11.38]', '\" computer\"[p=0.01, l=11.19]', '\" their\"[p=0.01, l=11.12]', '\" unknown\"[p=0.01, l=10.81]', '\" actor\"[p=0.01, l=10.75]']\n",
      "nationality => ['\" Spanish\"[p=0.46, l=17.38]', '\"?\\n\"[p=0.17, l=16.38]', '\"??\"[p=0.08, l=15.56]', '\"?\\n\\n\"[p=0.05, l=15.25]', '\"?\"[p=0.04, l=15.00]', '\"???\"[p=0.02, l=14.44]', '\" Span\"[p=0.02, l=14.12]', '\" Indian\"[p=0.01, l=13.94]', '\" Argentine\"[p=0.01, l=13.44]', '\" Pakistani\"[p=0.01, l=13.31]', '\" their\"[p=0.01, l=13.25]', '\" \\n\"[p=0.01, l=13.06]', '\" Iranian\"[p=0.00, l=12.75]', '\" Mexican\"[p=0.00, l=12.38]', '\" your\"[p=0.00, l=12.25]']\n",
      "\n",
      "--------------------------------------------------\n",
      "layer_idx=75 (model.layers.75)\n",
      "\"last_tok\" [-1] => \" -\"\n",
      "token_idx=-1 [\" -\"]\n",
      "profession => ['\"?\\n\"[p=0.17, l=12.75]', '\" artist\"[p=0.13, l=12.50]', '\"?\\n\\n\"[p=0.07, l=11.88]', '\"?\"[p=0.06, l=11.75]', '\"??\"[p=0.05, l=11.50]', '\" painter\"[p=0.04, l=11.38]', '\" unknown\"[p=0.02, l=10.62]', '\" \\n\"[p=0.02, l=10.62]', '\" (\"[p=0.02, l=10.50]', '\" ->\"[p=0.02, l=10.38]', '\" computer\"[p=0.01, l=10.06]', '\" error\"[p=0.01, l=9.94]', '\" not\"[p=0.01, l=9.81]', '\" \"[p=0.01, l=9.81]', '\" no\"[p=0.01, l=9.75]']\n",
      "nationality => ['\" Spanish\"[p=0.36, l=14.19]', '\"?\\n\"[p=0.16, l=13.38]', '\"?\"[p=0.05, l=12.31]', '\"?\\n\\n\"[p=0.05, l=12.12]', '\" ->\"[p=0.02, l=11.38]', '\" Span\"[p=0.02, l=11.38]', '\" (\"[p=0.02, l=11.25]', '\" Catalan\"[p=0.02, l=11.19]', '\"??\"[p=0.02, l=11.06]', '\" National\"[p=0.01, l=10.94]', '\" \\n\"[p=0.01, l=10.88]', '\" \"[p=0.01, l=10.31]', '\" ->\\n\"[p=0.01, l=10.19]', '\" nationality\"[p=0.01, l=10.00]', '\" Pakistani\"[p=0.01, l=10.00]']\n",
      "\n",
      "\"Pablo Picasso\" [245, 246] => \" Pablo Picasso\"\n",
      "token_idx=245 [\" Pablo\"]\n",
      "profession => ['\"?\\n\"[p=0.11, l=12.69]', '\" artist\"[p=0.07, l=12.31]', '\"?\"[p=0.07, l=12.31]', '\"?\\n\\n\"[p=0.06, l=12.12]', '\" soccer\"[p=0.06, l=12.06]', '\"??\"[p=0.04, l=11.75]', '\" football\"[p=0.03, l=11.44]', '\" unknown\"[p=0.03, l=11.44]', '\" software\"[p=0.03, l=11.44]', '\"???\"[p=0.03, l=11.38]', '\" architect\"[p=0.02, l=10.88]', '\" tennis\"[p=0.02, l=10.81]', '\" programmer\"[p=0.01, l=10.62]', '\" (\"[p=0.01, l=10.62]', '\" engineer\"[p=0.01, l=10.56]']\n",
      "nationality => ['\" Spanish\"[p=0.58, l=17.12]', '\"?\\n\"[p=0.09, l=15.25]', '\"?\"[p=0.07, l=15.00]', '\"??\"[p=0.06, l=14.81]', '\"?\\n\\n\"[p=0.03, l=14.06]', '\"???\"[p=0.02, l=13.69]', '\" Mexican\"[p=0.01, l=13.31]', '\" Unknown\"[p=0.01, l=13.25]', '\" unknown\"[p=0.01, l=13.25]', '\" Argentine\"[p=0.01, l=12.81]', '\" (\"[p=0.01, l=12.50]', '\" Span\"[p=0.00, l=12.25]', '\" Pablo\"[p=0.00, l=12.19]', '\" \\n\"[p=0.00, l=12.06]', '\" Not\"[p=0.00, l=11.94]']\n",
      "token_idx=246 [\" Picasso\"]\n",
      "profession => ['\" artist\"[p=0.56, l=19.00]', '\" painter\"[p=0.38, l=18.62]', '\" Spanish\"[p=0.01, l=14.38]', '\"?\\n\"[p=0.00, l=14.19]', '\" Painter\"[p=0.00, l=14.12]', '\" spanish\"[p=0.00, l=14.12]', '\" Artist\"[p=0.00, l=14.00]', '\" Pablo\"[p=0.00, l=13.69]', '\"??\"[p=0.00, l=13.56]', '\" (\"[p=0.00, l=13.38]', '\" \\n\"[p=0.00, l=13.25]', '\" \"[p=0.00, l=13.12]', '\"?\"[p=0.00, l=12.88]', '\"???\"[p=0.00, l=12.56]', '\" cub\"[p=0.00, l=12.56]']\n",
      "nationality => ['\" Spanish\"[p=0.94, l=19.75]', '\" Span\"[p=0.01, l=15.12]', '\"?\\n\"[p=0.01, l=15.06]', '\" French\"[p=0.00, l=14.00]', '\" \\n\"[p=0.00, l=13.88]', '\" spanish\"[p=0.00, l=13.75]', '\"??\"[p=0.00, l=13.56]', '\" (\"[p=0.00, l=13.50]', '\"?\"[p=0.00, l=13.44]', '\" Spain\"[p=0.00, l=13.12]', '\" \"[p=0.00, l=13.12]', '\"?\\n\\n\"[p=0.00, l=13.12]', '\" Catalan\"[p=0.00, l=12.69]', '\" Pablo\"[p=0.00, l=12.38]', '\"???\"[p=0.00, l=12.38]']\n",
      "\n",
      "\"Salvador Dalí\" [248, 249, 250] => \" Salvador Dalí\"\n",
      "token_idx=248 [\" Salvador\"]\n",
      "profession => ['\"?\\n\"[p=0.17, l=12.69]', '\" artist\"[p=0.13, l=12.38]', '\"?\"[p=0.06, l=11.69]', '\"?\\n\\n\"[p=0.05, l=11.50]', '\"??\"[p=0.03, l=11.06]', '\"???\"[p=0.03, l=10.81]', '\" painter\"[p=0.02, l=10.56]', '\" Salvador\"[p=0.01, l=10.19]', '\" unknown\"[p=0.01, l=10.06]', '\" architect\"[p=0.01, l=9.94]', '\" actor\"[p=0.01, l=9.88]', '\" software\"[p=0.01, l=9.69]', '\" philosopher\"[p=0.01, l=9.62]', '\" computer\"[p=0.01, l=9.62]', '\" (\"[p=0.01, l=9.56]']\n",
      "nationality => ['\" Spanish\"[p=0.29, l=16.00]', '\"?\\n\"[p=0.21, l=15.69]', '\"?\"[p=0.09, l=14.81]', '\"??\"[p=0.06, l=14.50]', '\"?\\n\\n\"[p=0.04, l=14.06]', '\" Indian\"[p=0.04, l=14.00]', '\"???\"[p=0.02, l=13.25]', '\" Span\"[p=0.02, l=13.19]', '\" Mexican\"[p=0.02, l=13.12]', '\" French\"[p=0.01, l=12.81]', '\" Salvador\"[p=0.01, l=12.44]', '\" Brazilian\"[p=0.01, l=12.44]', '\" \\n\"[p=0.01, l=12.31]', '\" National\"[p=0.01, l=12.19]', '\" Iranian\"[p=0.01, l=12.12]']\n",
      "token_idx=249 [\" Dal\"]\n",
      "profession => ['\" artist\"[p=0.13, l=12.31]', '\"?\\n\"[p=0.09, l=12.00]', '\"??\"[p=0.05, l=11.44]', '\" philosopher\"[p=0.04, l=11.25]', '\"?\\n\\n\"[p=0.04, l=11.25]', '\" politician\"[p=0.04, l=11.25]', '\"?\"[p=0.03, l=10.94]', '\" painter\"[p=0.02, l=10.56]', '\" unknown\"[p=0.02, l=10.19]', '\"???\"[p=0.01, l=10.06]', '\" computer\"[p=0.01, l=9.94]', '\" \\n\"[p=0.01, l=9.69]', '\" actor\"[p=0.01, l=9.69]', '\" teacher\"[p=0.01, l=9.69]', '\" programmer\"[p=0.01, l=9.62]']\n",
      "nationality => ['\" Spanish\"[p=0.38, l=14.81]', '\"?\\n\"[p=0.08, l=13.31]', '\" Catalan\"[p=0.05, l=12.88]', '\"??\"[p=0.05, l=12.69]', '\" French\"[p=0.04, l=12.56]', '\" Indian\"[p=0.04, l=12.50]', '\"?\"[p=0.04, l=12.50]', '\"?\\n\\n\"[p=0.02, l=11.94]', '\" Italian\"[p=0.02, l=11.88]', '\" \\n\"[p=0.01, l=11.56]', '\"???\"[p=0.01, l=11.06]', '\" (\"[p=0.01, l=11.06]', '\" Turkish\"[p=0.01, l=11.00]', '\" Iranian\"[p=0.01, l=10.94]', '\" Mexican\"[p=0.01, l=10.81]']\n",
      "token_idx=250 [\"í\"]\n",
      "profession => ['\"?\\n\"[p=0.34, l=15.12]', '\"?\\n\\n\"[p=0.16, l=14.38]', '\"??\"[p=0.07, l=13.56]', '\"?\"[p=0.05, l=13.12]', '\" artist\"[p=0.04, l=13.00]', '\" what\"[p=0.02, l=12.44]', '\" their\"[p=0.02, l=12.31]', '\"???\"[p=0.02, l=12.06]', '\" software\"[p=0.01, l=12.00]', '\" politician\"[p=0.01, l=11.88]', '\" entrepreneur\"[p=0.01, l=11.75]', '\" computer\"[p=0.01, l=11.69]', '\" programmer\"[p=0.01, l=11.56]', '\" \\n\"[p=0.01, l=11.31]', '\" lawyer\"[p=0.01, l=11.25]']\n",
      "nationality => ['\" Spanish\"[p=0.30, l=17.12]', '\"?\\n\"[p=0.26, l=17.00]', '\"?\\n\\n\"[p=0.10, l=16.00]', '\"??\"[p=0.07, l=15.69]', '\"?\"[p=0.06, l=15.50]', '\" Argentine\"[p=0.02, l=14.50]', '\"???\"[p=0.02, l=14.38]', '\" Indian\"[p=0.02, l=14.31]', '\" Span\"[p=0.02, l=14.19]', '\" their\"[p=0.01, l=13.88]', '\" Pakistani\"[p=0.01, l=13.62]', '\" \\n\"[p=0.01, l=13.56]', '\" Arg\"[p=0.00, l=13.00]', '\" What\"[p=0.00, l=12.81]', '\" what\"[p=0.00, l=12.62]']\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.operators.utils import patch as patch_check\n",
    "from src.functional import interpret_logits\n",
    "\n",
    "track_toks = []\n",
    "\n",
    "for entity in query_entities:\n",
    "    context_subj = context.replace(\"placeholder\", entity)\n",
    "    top_pred = predict_next_token(mt=mt, inputs=context_subj)[0][0]\n",
    "    print(f\"{entity} => {top_pred}\")\n",
    "    track_toks.append(top_pred)\n",
    "print(\"=\" * 50)\n",
    "\n",
    "track_toks = [p.token_id for p in track_toks]\n",
    "track_toks = list(set(track_toks))  # remove duplicates\n",
    "print([mt.tokenizer.decode(t) for t in track_toks])\n",
    "\n",
    "\n",
    "context_tok = prepare_input(prompts=context, tokenizer=mt, return_offsets_mapping=True)\n",
    "\n",
    "offset_mapping = context_tok.pop(\"offset_mapping\")[0]\n",
    "\n",
    "h_idx = (\n",
    "    find_token_range(\n",
    "        string=context,\n",
    "        substring=\"placeholder\",\n",
    "        offset_mapping=offset_mapping,\n",
    "        tokenizer=mt.tokenizer,\n",
    "        occurrence=-1,\n",
    "    )[1]\n",
    "    - 1\n",
    ")\n",
    "\n",
    "###########################################################################\n",
    "# layer_indices = list(range(mt.n_layer))\n",
    "layer_indices = [5, 15, 25, 31, 33, 35, 37, 39, 41, 45, 55, 65, 75]\n",
    "patch_layers = [\n",
    "    mt.layer_name_format.format(layer_idx) for layer_idx in list(range(5, 6))\n",
    "]\n",
    "\n",
    "token_ranges = {\n",
    "    \"last_tok\": [-1],\n",
    "    probing_input.entities[0]: list(range(*probing_input.entity_ranges[0])),\n",
    "    probing_input.entities[1]: list(range(*probing_input.entity_ranges[1])),\n",
    "}\n",
    "\n",
    "context_dict = {\n",
    "    \"profession\": context_prof,\n",
    "    \"nationality\": context_nat,\n",
    "}\n",
    "###########################################################################\n",
    "\n",
    "inputs = TokenizerOutput(data=probing_input.tokenized)\n",
    "\n",
    "score_track = {k: {} for k in token_ranges.keys()}\n",
    "\n",
    "for layer_idx in layer_indices:\n",
    "    print(f\"layer_idx={layer_idx} ({mt.layer_name_format.format(layer_idx)})\")\n",
    "    for key, token_range in token_ranges.items():\n",
    "        print(\n",
    "            f'\"{key}\" {token_range} => \"{mt.tokenizer.decode(inputs.input_ids[0][token_range], skip_special_tokens=False)}\"'\n",
    "        )\n",
    "        for token_idx in token_range:\n",
    "\n",
    "            print(\n",
    "                f'{token_idx=} [\"{mt.tokenizer.decode(inputs.input_ids[0][token_idx])}\"]'\n",
    "            )\n",
    "\n",
    "            # z = patch_check(\n",
    "            #     mt=mt,\n",
    "            #     h=hs[(mt.layer_name_format.format(layer_idx), token_idx)] * 5,\n",
    "            #     inp_layer=mt.layer_name_format.format(5),\n",
    "            #     # out_layer=mt.layer_names[-1],\n",
    "            #     out_layer=mt.lm_head_name,\n",
    "            #     context=context_tok,\n",
    "            #     h_idx=h_idx,\n",
    "            # )\n",
    "            # # ll_pred, ll_track = logit_lens(mt=mt, h=z, k=15, interested_tokens=track_toks)\n",
    "            # ll_pred, ll_track = interpret_logits(\n",
    "            #     tokenizer=mt, logits=z, k=15, interested_tokens=track_toks\n",
    "            # )\n",
    "            for attr, context in context_dict.items():\n",
    "                ll_pred, ll_track = patchscope(\n",
    "                    mt=mt,\n",
    "                    h=hs[(mt.layer_name_format.format(layer_idx), token_idx)],\n",
    "                    context=context,\n",
    "                    placeholder=\"placeholder\",\n",
    "                    # context_tokenized=context_tok,\n",
    "                    # placeholder_idx=h_idx,\n",
    "                    patch_layers=patch_layers,\n",
    "                    # add_orig_latent_to=mt.layer_names[-1], # logit lens\n",
    "                    # add_orig_latent_to=mt.layer_name_format.format(layer_idx),\n",
    "                    k=15,\n",
    "                    interested_tokens=track_toks,\n",
    "                )\n",
    "                ll_fmt = [\n",
    "                    f'\"{pred.token}\"[p={pred.prob:.2f}, l={pred.logit:.2f}]'\n",
    "                    for pred in ll_pred\n",
    "                ]\n",
    "                if token_idx not in score_track[key]:\n",
    "                    score_track[key][token_idx] = []\n",
    "                score_track[key][token_idx].append((ll_pred, ll_track))\n",
    "                print(f\"{attr} => {ll_fmt}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4fc3a2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PredictedToken(token=' comedian', prob=0.59765625, logit=20.0, token_id=51912, metadata=None),\n",
       "  PredictedToken(token=' actor', prob=0.36328125, logit=19.5, token_id=12360, metadata=None),\n",
       "  PredictedToken(token=' Com', prob=0.00665283203125, logit=15.5, token_id=1219, metadata=None),\n",
       "  PredictedToken(token=' TV', prob=0.0033416748046875, logit=14.8125, token_id=6007, metadata=None),\n",
       "  PredictedToken(token=' television', prob=0.002593994140625, logit=14.5625, token_id=12707, metadata=None),\n",
       "  PredictedToken(token=' journalist', prob=0.0017852783203125, logit=14.1875, token_id=23672, metadata=None),\n",
       "  PredictedToken(token=' Actor', prob=0.001678466796875, logit=14.125, token_id=25749, metadata=None),\n",
       "  PredictedToken(token=' comedic', prob=0.00157928466796875, logit=14.0625, token_id=95471, metadata=None),\n",
       "  PredictedToken(token=' (', prob=0.0013885498046875, logit=13.9375, token_id=320, metadata=None),\n",
       "  PredictedToken(token=' comedy', prob=0.00130462646484375, logit=13.875, token_id=23160, metadata=None),\n",
       "  PredictedToken(token=' writer', prob=0.00130462646484375, logit=13.875, token_id=7061, metadata=None),\n",
       "  PredictedToken(token=' comic', prob=0.00115203857421875, logit=13.75, token_id=20303, metadata=None),\n",
       "  PredictedToken(token=' political', prob=0.000843048095703125, logit=13.4375, token_id=5054, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.00079345703125, logit=13.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' stand', prob=0.000701904296875, logit=13.25, token_id=2559, metadata=None)],\n",
       " {51912: (1,\n",
       "   PredictedToken(token=' comedian', prob=0.59765625, logit=20.0, token_id=51912, metadata=None)),\n",
       "  12360: (2,\n",
       "   PredictedToken(token=' actor', prob=0.36328125, logit=19.5, token_id=12360, metadata=None))})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx = 23\n",
    "\n",
    "h1 = torch.stack(\n",
    "    [\n",
    "        hs[(mt.layer_name_format.format(layer_idx), token_idx)]\n",
    "        # for token_idx in range(*probing_input.entity_ranges[0])\n",
    "        for token_idx in [probing_input.entity_ranges[0][1] - 1]\n",
    "    ]\n",
    ").mean(dim=0)\n",
    "\n",
    "h2 = torch.stack(\n",
    "    [\n",
    "        hs[(mt.layer_name_format.format(layer_idx), token_idx)]\n",
    "        # for token_idx in range(*probing_input.entity_ranges[1])\n",
    "        for token_idx in [probing_input.entity_ranges[1][1] - 1]\n",
    "    ]\n",
    ").mean(dim=0)\n",
    "\n",
    "patchscope(\n",
    "    mt=mt,\n",
    "    h=h1 + h2,\n",
    "    # h = h2,\n",
    "    context=context,\n",
    "    placeholder=\"placeholder\",\n",
    "    context_tokenized=context_tok,\n",
    "    placeholder_idx=h_idx,\n",
    "    patch_layers=patch_layers,\n",
    "    # add_orig_latent_to=mt.layer_names[-1], # logit lens\n",
    "    add_orig_latent_to=mt.layer_name_format.format(layer_idx),\n",
    "    k=15,\n",
    "    interested_tokens=track_toks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e99d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ef455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce876486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35ea70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d5eaf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:49:36 __main__ DEBUG    Answer token: 7566 [\" Yes\"]\n",
      "2025-06-26 12:49:37 __main__ DEBUG    Gold score: 23.875 | Predicted: ['\" Yes\"[p=0.75, l=23.88]', '\" No\"[p=0.24, l=22.75]', '\" \"\"[p=0.00, l=18.38]', '\" \\n\"[p=0.00, l=16.38]', '\" (\"[p=0.00, l=16.12]']\n",
      "2025-06-26 12:49:38 __main__ DEBUG    Patched score: 22.125 | Predicted: ['\" No\"[p=0.75, l=23.25]', '\" Yes\"[p=0.24, l=22.12]', '\" \"\"[p=0.00, l=17.88]', '\" (\"[p=0.00, l=15.94]', '\" \"[p=0.00, l=15.94]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9267015706806283,\n",
       " [PredictedToken(token=' No', prob=0.75, logit=23.25, token_id=2360, metadata=None),\n",
       "  PredictedToken(token=' Yes', prob=0.2431640625, logit=22.125, token_id=7566, metadata=None),\n",
       "  PredictedToken(token=' \"', prob=0.0034637451171875, logit=17.875, token_id=330, metadata=None),\n",
       "  PredictedToken(token=' (', prob=0.000499725341796875, logit=15.9375, token_id=320, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.000499725341796875, logit=15.9375, token_id=220, metadata=None)],\n",
       " {7566: (2,\n",
       "   PredictedToken(token=' Yes', prob=0.2431640625, logit=22.125, token_id=7566, metadata=None))})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.probing.prompt import ProbingPrompt\n",
    "\n",
    "\n",
    "def patch_entity_from_different_run(\n",
    "    mt: ModelandTokenizer,\n",
    "    probing_input: ProbingPrompt,\n",
    "    patch_entity_idx: int = 1,\n",
    "    different_context: str = \" {}\",\n",
    "    answer_token: int = None,\n",
    "    track_tokens: list[int] = [],\n",
    "    metric: Literal[\"logit\", \"prob\"] = \"logit\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Patches the entity in the connection setting with latents cached from a different context.\n",
    "    Returns the indirect effect on the original output.\n",
    "    \"\"\"\n",
    "    from src.functional import get_hs, PatchSpec\n",
    "    from src.utils.typing import TokenizerOutput\n",
    "    from src.tokens import prepare_input, find_token_range\n",
    "\n",
    "    if answer_token is None:\n",
    "        pred = predict_next_token(\n",
    "            mt=mt,\n",
    "            inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "        )\n",
    "        answer_token = pred[0][0].token_id  # take the first token prediction\n",
    "\n",
    "    logger.debug(\n",
    "        f'Answer token: {answer_token} [\"{mt.tokenizer.decode(answer_token)}\"]'\n",
    "    )\n",
    "    track_tokens = list(\n",
    "        set(track_tokens + [answer_token])\n",
    "    )  # ensure answer token is in track tokens\n",
    "\n",
    "    # Run the clean probing input to get the gold score\n",
    "    gold_score, gold_pred, gold_track = patched_run(\n",
    "        mt=mt,\n",
    "        inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "        patches=[],\n",
    "        ans_tokens=track_tokens,\n",
    "        metric=metric,\n",
    "    )\n",
    "\n",
    "    pred_fmt = [\n",
    "        f'\"{pred.token}\"[p={pred.prob:.2f}, l={pred.logit:.2f}]' for pred in gold_pred\n",
    "    ]\n",
    "    logger.debug(f\"Gold score: {gold_score} | Predicted: {pred_fmt[:5]}\")\n",
    "\n",
    "    # Cache the latents for the patch entity from a different context\n",
    "    entity = probing_input.entities[patch_entity_idx]\n",
    "    patch_prompt = different_context.format(entity)\n",
    "    patch_inputs = prepare_input(\n",
    "        prompts=patch_prompt, tokenizer=mt, return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    offset_mapping = patch_inputs.pop(\"offset_mapping\")[0]\n",
    "    patch_from_range = find_token_range(\n",
    "        string=patch_prompt,\n",
    "        substring=entity,\n",
    "        tokenizer=mt.tokenizer,\n",
    "        offset_mapping=offset_mapping,\n",
    "    )\n",
    "\n",
    "    # Cache latents from different context\n",
    "    patch_hs = get_hs(\n",
    "        mt=mt,\n",
    "        input=patch_inputs,\n",
    "        locations=[\n",
    "            (layer, token_idx)\n",
    "            for layer in mt.layer_names\n",
    "            for token_idx in range(*patch_from_range)\n",
    "        ],\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    # Patch the entity in the probing input with the cached latents\n",
    "    patches = []\n",
    "    patch_to_range = probing_input.entity_ranges[patch_entity_idx]\n",
    "\n",
    "    for patch_to in range(*patch_to_range):\n",
    "        patch_from = (\n",
    "            patch_to - patch_to_range[0] + patch_from_range[0]\n",
    "        )  # adjust indices\n",
    "        for layer in mt.layer_names:\n",
    "            patches.append(\n",
    "                PatchSpec(\n",
    "                    location=[layer, patch_to],\n",
    "                    patch=patch_hs[(layer, patch_from)],\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Run the patched probing input to get the patched score\n",
    "    patch_score, patch_pred, patch_track = patched_run(\n",
    "        mt=mt,\n",
    "        inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "        patches=patches,\n",
    "        ans_tokens=track_tokens,\n",
    "        metric=metric,\n",
    "    )\n",
    "\n",
    "    patch_pred_fmt = [\n",
    "        f'\"{pred.token}\"[p={pred.prob:.2f}, l={pred.logit:.2f}]' for pred in patch_pred\n",
    "    ]\n",
    "    logger.debug(f\"Patched score: {patch_score} | Predicted: {patch_pred_fmt[:5]}\")\n",
    "\n",
    "    indirect_effect = patch_score / gold_score\n",
    "\n",
    "    return indirect_effect, patch_pred, patch_track\n",
    "\n",
    "\n",
    "patch_entity_from_different_run(\n",
    "    mt=mt,\n",
    "    probing_input=probing_input,\n",
    "    patch_entity_idx=1,\n",
    "    different_context=\" {}\",\n",
    "    metric=\"logit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "997bb1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => Sophie Evans | James Mitchell => \" University\" | <-- | Mohammad Aziz => \" Lawyer\"\n",
      "2025-06-26 13:25:52 __main__ DEBUG    Answer token: 71314 [\" Lawyer\"]\n",
      "2025-06-26 13:25:53 __main__ DEBUG    Gold score: 15.5625 | Predicted: ['\" Yes\"[p=0.96, l=22.62]', '\" No\"[p=0.03, l=19.00]', '\" \"\"[p=0.00, l=16.88]', '\" \\n\"[p=0.00, l=15.56]', '\" \"[p=0.00, l=15.25]']\n",
      "2025-06-26 13:25:55 __main__ DEBUG    Patched score: 16.0 | Predicted: ['\" Yes\"[p=0.94, l=22.75]', '\" No\"[p=0.05, l=19.75]', '\" \"\"[p=0.00, l=17.00]', '\" \\n\"[p=0.00, l=15.88]', '\" \"[p=0.00, l=15.88]']\n",
      "('Sophie Evans', 'Mohammad Aziz') => 1.0281124497991967\n",
      "--------------------------------------------------\n",
      "1 => Mohammad Aziz | Fatima Sheikh => \" Pakistani\" | <-- | Sophie Evans => \" Lawyer\"\n",
      "2025-06-26 13:25:57 __main__ DEBUG    Answer token: 71314 [\" Lawyer\"]\n",
      "2025-06-26 13:25:58 __main__ DEBUG    Gold score: 15.6875 | Predicted: ['\" Yes\"[p=0.86, l=21.88]', '\" No\"[p=0.12, l=19.88]', '\" \"\"[p=0.01, l=16.75]', '\" \\n\"[p=0.00, l=15.50]', '\" (\"[p=0.00, l=15.19]']\n",
      "2025-06-26 13:26:00 __main__ DEBUG    Patched score: 15.9375 | Predicted: ['\" Yes\"[p=0.81, l=21.62]', '\" No\"[p=0.16, l=20.00]', '\" \"\"[p=0.00, l=16.50]', '\" \\n\"[p=0.00, l=15.81]', '\" (\"[p=0.00, l=15.56]']\n",
      "('Mohammad Aziz', 'Sophie Evans') => 1.0159362549800797\n",
      "--------------------------------------------------\n",
      "2 => Ali Rezaei | Zahra Hosseini => \" Iranian\" | <-- | João Silva => \" Phys\"\n",
      "2025-06-26 13:26:02 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.52, l=22.50]', '\" Yes\"[p=0.46, l=22.38]', '\" \"\"[p=0.01, l=17.88]', '\" \\n\"[p=0.00, l=16.62]', '\" (\"[p=0.00, l=16.25]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "3 => Rahman Ali | Nasreen Begum => \" Bangladesh\" | <-- | Takeshi Yamamoto => \" Civil\"\n",
      "2025-06-26 13:26:04 __main__ DEBUG    Answer token: 16803 [\" Civil\"]\n",
      "2025-06-26 13:26:05 __main__ DEBUG    Gold score: 17.5 | Predicted: ['\" Yes\"[p=0.75, l=23.25]', '\" No\"[p=0.24, l=22.12]', '\" \"\"[p=0.00, l=17.88]', '\" (\"[p=0.00, l=15.81]', '\" \\n\"[p=0.00, l=15.69]']\n",
      "2025-06-26 13:26:07 __main__ DEBUG    Patched score: 16.875 | Predicted: ['\" Yes\"[p=0.81, l=22.88]', '\" No\"[p=0.18, l=21.38]', '\" \"\"[p=0.00, l=17.38]', '\" (\"[p=0.00, l=15.88]', '\" \\n\"[p=0.00, l=15.81]']\n",
      "('Rahman Ali', 'Takeshi Yamamoto') => 0.9642857142857143\n",
      "--------------------------------------------------\n",
      "4 => Anna Schmidt | Hans Mueller => \" German\" | <-- | Yuki Tanaka => \" Marketing\"\n",
      "2025-06-26 13:26:09 __main__ DEBUG    Answer token: 18729 [\" Marketing\"]\n",
      "2025-06-26 13:26:10 __main__ DEBUG    Gold score: 16.5 | Predicted: ['\" Yes\"[p=0.58, l=21.88]', '\" No\"[p=0.40, l=21.50]', '\" \"\"[p=0.01, l=17.12]', '\" (\"[p=0.00, l=15.75]', '\" \\n\"[p=0.00, l=15.69]']\n",
      "2025-06-26 13:26:12 __main__ DEBUG    Patched score: 15.875 | Predicted: ['\" No\"[p=0.48, l=20.88]', '\" Yes\"[p=0.48, l=20.88]', '\" \"\"[p=0.01, l=16.62]', '\" \\n\"[p=0.00, l=15.50]', '\" (\"[p=0.00, l=15.44]']\n",
      "('Anna Schmidt', 'Yuki Tanaka') => 0.9621212121212122\n",
      "--------------------------------------------------\n",
      "5 => Yuki Tanaka | Takeshi Yamamoto => \" Japanese\" | <-- | Anna Schmidt => \" Marketing\"\n",
      "2025-06-26 13:26:14 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.79, l=22.88]', '\" Yes\"[p=0.20, l=21.50]', '\" \"\"[p=0.00, l=17.62]', '\" \\n\"[p=0.00, l=15.94]', '\" (\"[p=0.00, l=15.94]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "6 => Ayse Kaya | Mehmet Yilmaz => \" Turkish\" | <-- | Hans Mueller => \" Economist\"\n",
      "2025-06-26 13:26:16 __main__ DEBUG    Answer token: 84038 [\" Economist\"]\n",
      "2025-06-26 13:26:17 __main__ DEBUG    Gold score: 18.0 | Predicted: ['\" Yes\"[p=0.83, l=24.12]', '\" No\"[p=0.16, l=22.50]', '\" \"\"[p=0.00, l=18.38]', '\" \\n\"[p=0.00, l=16.62]', '\" \"[p=0.00, l=16.25]']\n",
      "2025-06-26 13:26:18 __main__ DEBUG    Patched score: 17.25 | Predicted: ['\" Yes\"[p=0.77, l=23.00]', '\" No\"[p=0.22, l=21.75]', '\" \"\"[p=0.00, l=17.62]', '\" \\n\"[p=0.00, l=16.12]', '\" \"[p=0.00, l=16.12]']\n",
      "('Ayse Kaya', 'Hans Mueller') => 0.9583333333333334\n",
      "--------------------------------------------------\n",
      "7 => Priya Patel | Rajesh Kumar => \" Indian\" | <-- | Sofia Hernandez => \" Graphic\"\n",
      "2025-06-26 13:26:21 __main__ DEBUG    Answer token: 45051 [\" Graphic\"]\n",
      "2025-06-26 13:26:22 __main__ DEBUG    Gold score: 16.375 | Predicted: ['\" Yes\"[p=0.64, l=22.50]', '\" No\"[p=0.34, l=21.88]', '\" \"\"[p=0.00, l=17.50]', '\" \\n\"[p=0.00, l=15.81]', '\" \"[p=0.00, l=15.69]']\n",
      "2025-06-26 13:26:23 __main__ DEBUG    Patched score: 15.6875 | Predicted: ['\" Yes\"[p=0.55, l=21.38]', '\" No\"[p=0.43, l=21.12]', '\" \"\"[p=0.01, l=16.75]', '\" \"[p=0.00, l=15.75]', '\" \\n\"[p=0.00, l=15.62]']\n",
      "('Priya Patel', 'Sofia Hernandez') => 0.9580152671755725\n",
      "--------------------------------------------------\n",
      "8 => Sofia Hernandez | Carlos Rodriguez => \" Mexican\" | <-- | Priya Patel => \" Graphic\"\n",
      "2025-06-26 13:26:26 __main__ DEBUG    Answer token: 45051 [\" Graphic\"]\n",
      "2025-06-26 13:26:27 __main__ DEBUG    Gold score: 16.125 | Predicted: ['\" Yes\"[p=0.92, l=23.50]', '\" No\"[p=0.08, l=21.00]', '\" \"\"[p=0.00, l=17.62]', '\" \\n\"[p=0.00, l=16.00]', '\" \"[p=0.00, l=15.88]']\n",
      "2025-06-26 13:26:28 __main__ DEBUG    Patched score: 16.125 | Predicted: ['\" Yes\"[p=0.77, l=22.75]', '\" No\"[p=0.22, l=21.50]', '\" \"\"[p=0.00, l=17.38]', '\" (\"[p=0.00, l=16.12]', '\" \"[p=0.00, l=15.94]']\n",
      "('Sofia Hernandez', 'Priya Patel') => 1.0\n",
      "--------------------------------------------------\n",
      "9 => Siriporn Suwannarat | Somchai Jaidee => \" Thai\" | <-- | Marie Laurent => \" Nutrition\"\n",
      "2025-06-26 13:26:31 __main__ DEBUG    Answer token: 39700 [\" Nutrition\"]\n",
      "2025-06-26 13:26:32 __main__ DEBUG    Gold score: 16.5 | Predicted: ['\" Yes\"[p=0.86, l=23.00]', '\" No\"[p=0.13, l=21.12]', '\" \"\"[p=0.00, l=17.62]', '\" \\n\"[p=0.00, l=15.88]', '\" \"[p=0.00, l=15.88]']\n",
      "2025-06-26 13:26:33 __main__ DEBUG    Patched score: 16.25 | Predicted: ['\" Yes\"[p=0.77, l=22.50]', '\" No\"[p=0.22, l=21.25]', '\" \"\"[p=0.00, l=17.25]', '\" \"[p=0.00, l=16.00]', '\" \\n\"[p=0.00, l=15.81]']\n",
      "('Siriporn Suwannarat', 'Marie Laurent') => 0.9848484848484849\n",
      "--------------------------------------------------\n",
      "10 => Marie Laurent | Pierre Dubois => \" French\" | <-- | Siriporn Suwannarat => \" Nutrition\"\n",
      "2025-06-26 13:26:36 __main__ DEBUG    Answer token: 39700 [\" Nutrition\"]\n",
      "2025-06-26 13:26:36 __main__ DEBUG    Gold score: 15.375 | Predicted: ['\" Yes\"[p=0.86, l=21.75]', '\" No\"[p=0.12, l=19.75]', '\" \"\"[p=0.01, l=16.62]', '\" \"[p=0.00, l=15.38]', '\" (\"[p=0.00, l=15.31]']\n",
      "2025-06-26 13:26:38 __main__ DEBUG    Patched score: 15.375 | Predicted: ['\" Yes\"[p=0.78, l=21.62]', '\" No\"[p=0.20, l=20.25]', '\" \"\"[p=0.01, l=16.75]', '\" \"[p=0.00, l=15.75]', '\" (\"[p=0.00, l=15.56]']\n",
      "('Marie Laurent', 'Siriporn Suwannarat') => 1.0\n",
      "--------------------------------------------------\n",
      "11 => Zahra Hosseini | Ali Rezaei => \" Iranian\" | <-- | Ahmed Hassan => \" Pilot\"\n",
      "2025-06-26 13:26:40 __main__ DEBUG    Answer token: 45599 [\" Pilot\"]\n",
      "2025-06-26 13:26:41 __main__ DEBUG    Gold score: 18.0 | Predicted: ['\" Yes\"[p=0.89, l=24.12]', '\" No\"[p=0.11, l=22.00]', '\" \"\"[p=0.00, l=18.50]', '\" \\n\"[p=0.00, l=16.62]', '\" \"[p=0.00, l=15.88]']\n",
      "2025-06-26 13:26:43 __main__ DEBUG    Patched score: 17.75 | Predicted: ['\" Yes\"[p=0.55, l=22.75]', '\" No\"[p=0.43, l=22.50]', '\" \"\"[p=0.01, l=18.25]', '\" \\n\"[p=0.00, l=16.38]', '\" \"[p=0.00, l=16.00]']\n",
      "('Zahra Hosseini', 'Ahmed Hassan') => 0.9861111111111112\n",
      "--------------------------------------------------\n",
      "12 => Ahmed Hassan | Layla Mahmoud => \" Egyptian\" | <-- | Zahra Hosseini => \" Pilot\"\n",
      "2025-06-26 13:26:45 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.90, l=22.88]', '\" Yes\"[p=0.08, l=20.50]', '\" \"\"[p=0.00, l=17.62]', '\" Ahmed\"[p=0.00, l=16.25]', '\" \\n\"[p=0.00, l=15.69]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "13 => Kwame Mensah | Maria Santos => \" Doctor\" | <-- | Min-jun Park => \" Ge\"\n",
      "2025-06-26 13:26:48 __main__ DEBUG    Answer token: 4323 [\" Ge\"]\n",
      "2025-06-26 13:26:48 __main__ DEBUG    Gold score: 19.0 | Predicted: ['\" Yes\"[p=0.75, l=23.88]', '\" No\"[p=0.24, l=22.75]', '\" \"\"[p=0.00, l=18.38]', '\" \\n\"[p=0.00, l=16.38]', '\" (\"[p=0.00, l=16.12]']\n",
      "2025-06-26 13:26:49 __main__ DEBUG    Patched score: 18.625 | Predicted: ['\" Yes\"[p=0.84, l=23.50]', '\" No\"[p=0.15, l=21.75]', '\" \"\"[p=0.00, l=17.75]', '\" (\"[p=0.00, l=16.25]', '\" \\n\"[p=0.00, l=16.12]']\n",
      "('Kwame Mensah', 'Min-jun Park') => 0.9802631578947368\n",
      "--------------------------------------------------\n",
      "14 => Min-jun Park | Ji-woo Kim => \" Korean\" | <-- | Kwame Mensah => \" Ge\"\n",
      "2025-06-26 13:26:52 __main__ DEBUG    Answer token: 4323 [\" Ge\"]\n",
      "2025-06-26 13:26:53 __main__ DEBUG    Gold score: 19.125 | Predicted: ['\" Yes\"[p=0.68, l=23.88]', '\" No\"[p=0.32, l=23.12]', '\" \"\"[p=0.00, l=18.62]', '\" \\n\"[p=0.00, l=16.75]', '\" (\"[p=0.00, l=16.50]']\n",
      "2025-06-26 13:26:54 __main__ DEBUG    Patched score: 18.625 | Predicted: ['\" No\"[p=0.59, l=22.88]', '\" Yes\"[p=0.40, l=22.50]', '\" \"\"[p=0.00, l=17.88]', '\" \\n\"[p=0.00, l=16.38]', '\" (\"[p=0.00, l=16.12]']\n",
      "('Min-jun Park', 'Kwame Mensah') => 0.9738562091503268\n",
      "--------------------------------------------------\n",
      "15 => Tran Thi Mai | Nguyen Van Duc => \" Vietnamese\" | <-- | Marco Rossi => \" Architect\"\n",
      "2025-06-26 13:26:57 __main__ DEBUG    Answer token: 24979 [\" Architect\"]\n",
      "2025-06-26 13:26:57 __main__ DEBUG    Gold score: 17.75 | Predicted: ['\" Yes\"[p=0.61, l=22.62]', '\" No\"[p=0.37, l=22.12]', '\" \"\"[p=0.00, l=17.62]', '\" \\n\"[p=0.00, l=16.12]', '\" (\"[p=0.00, l=15.81]']\n",
      "2025-06-26 13:26:59 __main__ DEBUG    Patched score: 16.625 | Predicted: ['\" No\"[p=0.61, l=21.38]', '\" Yes\"[p=0.37, l=20.88]', '\" \"\"[p=0.01, l=16.88]', '\" \\n\"[p=0.00, l=15.50]', '\" \"[p=0.00, l=15.50]']\n",
      "('Tran Thi Mai', 'Marco Rossi') => 0.9366197183098591\n",
      "--------------------------------------------------\n",
      "16 => Marco Rossi | Giulia Romano => \" Italian\" | <-- | Tran Thi Mai => \" Architect\"\n",
      "2025-06-26 13:27:01 __main__ DEBUG    Answer token: 24979 [\" Architect\"]\n",
      "2025-06-26 13:27:02 __main__ DEBUG    Gold score: 17.5 | Predicted: ['\" Yes\"[p=0.72, l=22.62]', '\" No\"[p=0.27, l=21.62]', '\" \"\"[p=0.00, l=17.50]', '\" \\n\"[p=0.00, l=15.81]', '\" (\"[p=0.00, l=15.69]']\n",
      "2025-06-26 13:27:04 __main__ DEBUG    Patched score: 16.75 | Predicted: ['\" No\"[p=0.49, l=21.75]', '\" Yes\"[p=0.49, l=21.75]', '\" \"\"[p=0.01, l=17.38]', '\" \\n\"[p=0.00, l=15.88]', '\" \"[p=0.00, l=15.88]']\n",
      "('Marco Rossi', 'Tran Thi Mai') => 0.9571428571428572\n",
      "--------------------------------------------------\n",
      "17 => Diego Martinez | Valentina Lopez => \" Argentine\" | <-- | Michael Johnson => \" Music\"\n",
      "2025-06-26 13:27:06 __main__ DEBUG    Answer token: 10948 [\" Music\"]\n",
      "2025-06-26 13:27:07 __main__ DEBUG    Gold score: 17.625 | Predicted: ['\" Yes\"[p=0.64, l=23.00]', '\" No\"[p=0.35, l=22.38]', '\" \"\"[p=0.00, l=18.00]', '\" \\n\"[p=0.00, l=16.50]', '\" \"[p=0.00, l=16.12]']\n",
      "2025-06-26 13:27:09 __main__ DEBUG    Patched score: 17.375 | Predicted: ['\" No\"[p=0.59, l=22.50]', '\" Yes\"[p=0.40, l=22.12]', '\" \"\"[p=0.01, l=17.75]', '\" \\n\"[p=0.00, l=16.38]', '\" \"[p=0.00, l=16.00]']\n",
      "('Diego Martinez', 'Michael Johnson') => 0.9858156028368794\n",
      "--------------------------------------------------\n",
      "18 => Valentina Lopez | Diego Martinez => \" Argentine\" | <-- | Natasha Ivanova => \" Pharm\"\n",
      "2025-06-26 13:27:11 __main__ DEBUG    Answer token: 25603 [\" Pharm\"]\n",
      "2025-06-26 13:27:12 __main__ DEBUG    Gold score: 17.25 | Predicted: ['\" Yes\"[p=0.90, l=23.50]', '\" No\"[p=0.09, l=21.25]', '\" \"\"[p=0.00, l=17.88]', '\" \\n\"[p=0.00, l=16.38]', '\" \"[p=0.00, l=16.25]']\n",
      "2025-06-26 13:27:14 __main__ DEBUG    Patched score: 16.875 | Predicted: ['\" Yes\"[p=0.84, l=22.62]', '\" No\"[p=0.15, l=20.88]', '\" \"\"[p=0.00, l=17.38]', '\" \\n\"[p=0.00, l=16.25]', '\" \"[p=0.00, l=16.12]']\n",
      "('Valentina Lopez', 'Natasha Ivanova') => 0.9782608695652174\n",
      "--------------------------------------------------\n",
      "19 => Rachel Levy | David Cohen => \" Israeli\" | <-- | Mehmet Yilmaz => \" Interior\"\n",
      "2025-06-26 13:27:16 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.67, l=22.25]', '\" Yes\"[p=0.32, l=21.50]', '\" \"\"[p=0.01, l=17.50]', '\" \\n\"[p=0.00, l=16.00]', '\" \"[p=0.00, l=15.69]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "20 => Mehmet Yilmaz | Ayse Kaya => \" Turkish\" | <-- | Rachel Levy => \" Interior\"\n",
      "2025-06-26 13:27:18 __main__ DEBUG    Answer token: 29958 [\" Interior\"]\n",
      "2025-06-26 13:27:19 __main__ DEBUG    Gold score: 16.5 | Predicted: ['\" Yes\"[p=0.97, l=23.12]', '\" No\"[p=0.02, l=19.38]', '\" \"\"[p=0.00, l=17.38]', '\" \\n\"[p=0.00, l=15.75]', '\" \"[p=0.00, l=15.50]']\n",
      "2025-06-26 13:27:21 __main__ DEBUG    Patched score: 16.375 | Predicted: ['\" Yes\"[p=0.90, l=22.38]', '\" No\"[p=0.08, l=20.00]', '\" \"\"[p=0.00, l=17.00]', '\" \\n\"[p=0.00, l=15.56]', '\" \"[p=0.00, l=15.56]']\n",
      "('Mehmet Yilmaz', 'Rachel Levy') => 0.9924242424242424\n",
      "--------------------------------------------------\n",
      "21 => Somchai Jaidee | Siriporn Suwannarat => \" Thai\" | <-- | Jan de Vries => \" Psych\"\n",
      "2025-06-26 13:27:23 __main__ DEBUG    Answer token: 17680 [\" Psych\"]\n",
      "2025-06-26 13:27:24 __main__ DEBUG    Gold score: 15.9375 | Predicted: ['\" Yes\"[p=0.89, l=22.25]', '\" No\"[p=0.09, l=20.00]', '\" \"\"[p=0.01, l=17.12]', '\" Som\"[p=0.00, l=16.25]', '\" (\"[p=0.00, l=15.44]']\n",
      "2025-06-26 13:27:25 __main__ DEBUG    Patched score: 15.9375 | Predicted: ['\" Yes\"[p=0.87, l=22.12]', '\" No\"[p=0.12, l=20.12]', '\" \"\"[p=0.00, l=16.88]', '\" (\"[p=0.00, l=15.69]', '\" \"[p=0.00, l=15.69]']\n",
      "('Somchai Jaidee', 'Jan de Vries') => 1.0\n",
      "--------------------------------------------------\n",
      "22 => Alexandru Popescu | Elena Ionescu => \" University\" | <-- | David Thompson => \" Environmental\"\n",
      "2025-06-26 13:27:28 __main__ DEBUG    Answer token: 25027 [\" Environmental\"]\n",
      "2025-06-26 13:27:28 __main__ DEBUG    Gold score: 16.375 | Predicted: ['\" Yes\"[p=0.74, l=22.25]', '\" No\"[p=0.24, l=21.12]', '\" \"\"[p=0.01, l=17.38]', '\" \\n\"[p=0.00, l=16.12]', '\" (\"[p=0.00, l=15.44]']\n",
      "2025-06-26 13:27:30 __main__ DEBUG    Patched score: 15.8125 | Predicted: ['\" Yes\"[p=0.76, l=21.75]', '\" No\"[p=0.22, l=20.50]', '\" \"\"[p=0.01, l=16.88]', '\" \\n\"[p=0.00, l=16.12]', '\" \"[p=0.00, l=15.44]']\n",
      "('Alexandru Popescu', 'David Thompson') => 0.9656488549618321\n",
      "--------------------------------------------------\n",
      "23 => David Thompson | Diego Martinez => \" Princeton\" | <-- | Alexandru Popescu => \" Environmental\"\n",
      "2025-06-26 13:27:32 __main__ DEBUG    Answer token: 25027 [\" Environmental\"]\n",
      "2025-06-26 13:27:33 __main__ DEBUG    Gold score: 16.625 | Predicted: ['\" Yes\"[p=0.72, l=22.38]', '\" No\"[p=0.27, l=21.38]', '\" \"\"[p=0.00, l=17.38]', '\" \\n\"[p=0.00, l=16.12]', '\" \"[p=0.00, l=15.50]']\n",
      "2025-06-26 13:27:35 __main__ DEBUG    Patched score: 16.25 | Predicted: ['\" Yes\"[p=0.66, l=21.62]', '\" No\"[p=0.31, l=20.88]', '\" \"\"[p=0.01, l=16.88]', '\" \\n\"[p=0.00, l=15.81]', '\" \"[p=0.00, l=15.69]']\n",
      "('David Thompson', 'Alexandru Popescu') => 0.9774436090225563\n",
      "--------------------------------------------------\n",
      "24 => Youssef Benali | Fatima Alaoui => \" Moroccan\" | <-- | Sarah MacDonald => \" Occupational\"\n",
      "2025-06-26 13:27:37 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.53, l=23.62]', '\" Yes\"[p=0.46, l=23.50]', '\" \"\"[p=0.00, l=18.88]', '\" \\n\"[p=0.00, l=16.88]', '\" (\"[p=0.00, l=16.25]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "25 => António Costa | Isabel Ferreira => \" Portuguese\" | <-- | Jack Wilson => \" Software\"\n",
      "2025-06-26 13:27:40 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.91, l=21.88]', '\" Yes\"[p=0.07, l=19.38]', '\" \"\"[p=0.01, l=16.88]', '\" \\n\"[p=0.00, l=15.62]', '\" (\"[p=0.00, l=15.12]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "26 => Elena Georgiou | Dimitris Papadopoulos => \" Greek\" | <-- | Emma Taylor => \" Professor\"\n",
      "2025-06-26 13:27:42 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.77, l=22.88]', '\" Yes\"[p=0.22, l=21.62]', '\" \"\"[p=0.00, l=17.62]', '\" Elena\"[p=0.00, l=16.62]', '\" \\n\"[p=0.00, l=15.94]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "27 => Maria dela Rosa | Jose Cruz => \" Filipino\" | <-- | Rodrigo Gonzalez => \" Mechanical\"\n",
      "2025-06-26 13:27:44 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.80, l=21.88]', '\" Yes\"[p=0.18, l=20.38]', '\" \"\"[p=0.01, l=17.12]', '\" \\n\"[p=0.00, l=15.50]', '\" (\"[p=0.00, l=15.12]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "28 => James Mitchell | Sophie Evans => \" University\" | <-- | Jennifer Davis => \" Journal\"\n",
      "2025-06-26 13:27:47 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.85, l=22.50]', '\" Yes\"[p=0.13, l=20.62]', '\" \"\"[p=0.01, l=17.75]', '\" \\n\"[p=0.00, l=16.00]', '\" \"[p=0.00, l=15.56]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "29 => Jennifer Davis | Mohammad Aziz => \" University\" | <-- | James Mitchell => \" Journal\"\n",
      "2025-06-26 13:27:49 __main__ WARNING  Skipping - didn't predict `\" Yes\"`: ['\" No\"[p=0.89, l=22.38]', '\" Yes\"[p=0.09, l=20.12]', '\" \"\"[p=0.01, l=17.38]', '\" Jennifer\"[p=0.00, l=16.12]', '\" \"[p=0.00, l=15.56]']\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9802619474481606), np.float64(0.021483572215530794))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "indirect_effects = []\n",
    "\n",
    "yes_token = 7566\n",
    "no_token = 2360\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    print(f\"{idx} => {sample}\")\n",
    "    query_sample = sample.common_entity, sample.patched_entity\n",
    "    probing_input = prepare_probing_input(\n",
    "        mt=mt,\n",
    "        entities=query_sample,\n",
    "        prefix=prefix,\n",
    "        answer_marker=prefix_generator.answer_marker,\n",
    "        question_marker=prefix_generator.question_marker,\n",
    "        block_separator=prefix_generator.block_separator,\n",
    "        is_a_reasoning_model=False,\n",
    "        # answer_prefix=\" Yes -\",\n",
    "    )\n",
    "\n",
    "    gold_pred = predict_next_token(\n",
    "        mt=mt,\n",
    "        inputs=TokenizerOutput(data=probing_input.tokenized),\n",
    "    )[0]\n",
    "    answer_token = gold_pred[0].token_id  # take the first token prediction\n",
    "    if answer_token != yes_token:\n",
    "        pred_fmt = [\n",
    "            f'\"{pred.token}\"[p={pred.prob:.2f}, l={pred.logit:.2f}]'\n",
    "            for pred in gold_pred\n",
    "        ]\n",
    "        logger.warning(f\"Skipping - didn't predict `\\\" Yes\\\"`: {pred_fmt[:5]}\")\n",
    "        print(\"x\" * 50)\n",
    "        continue\n",
    "\n",
    "    indirect_effect, patch_pred, patch_track = patch_entity_from_different_run(\n",
    "        mt=mt,\n",
    "        probing_input=probing_input,\n",
    "        patch_entity_idx=0,         #! entity index\n",
    "        different_context=\" {}\",\n",
    "        answer_token=sample.patched_answer_toks[0],\n",
    "        track_tokens=[yes_token, no_token],\n",
    "        metric=\"logit\",\n",
    "    )\n",
    "\n",
    "    print(f\"{query_sample} => {indirect_effect}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    indirect_effects.append(indirect_effect)\n",
    "\n",
    "\n",
    "np.mean(indirect_effects), np.std(indirect_effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9729ba",
   "metadata": {},
   "source": [
    "## Fuse SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bcac5cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.1G\n",
      "-rw-r--r-- 1 arnab research  480 Jun 27 13:46 config.yaml\n",
      "-rw-r--r-- 1 arnab research 4.1G Jun 27 13:46 Llama-3.3-70B-Instruct-SAE-l50.pt\n",
      "-rw-r--r-- 1 arnab research 3.3K Jun 27 13:46 README.md\n"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "sae_key = \"Goodfire/Llama-3.3-70B-Instruct-SAE-l50\"\n",
    "sae_dir = os.path.join(env_utils.DEFAULT_MODELS_DIR, \"sae\", sae_key)\n",
    "\n",
    "# snapshot_download(\n",
    "#     repo_id=sae_key,\n",
    "#     local_dir=sae_dir,\n",
    "#     revision=\"main\",\n",
    "# )\n",
    "\n",
    "! ls -lh {sae_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "342570ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_in: int,\n",
    "        d_hidden: int,\n",
    "        device: torch.device,\n",
    "        dtype: torch.dtype = torch.bfloat16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_hidden = d_hidden\n",
    "        self.device = device\n",
    "        self.encoder_linear = torch.nn.Linear(d_in, d_hidden)\n",
    "        self.decoder_linear = torch.nn.Linear(d_hidden, d_in)\n",
    "        self.dtype = dtype\n",
    "        self.to(self.device, self.dtype)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Encode a batch of data using a linear, followed by a ReLU.\"\"\"\n",
    "        return torch.nn.functional.relu(self.encoder_linear(x))\n",
    "\n",
    "    def decode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode a batch of data using a linear.\"\"\"\n",
    "        return self.decoder_linear(x)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"SAE forward pass. Returns the reconstruction and the encoded features.\"\"\"\n",
    "        f = self.encode(x)\n",
    "        return self.decode(f), f\n",
    "\n",
    "\n",
    "def load_sae(\n",
    "    path: str,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "    dtype: torch.dtype = torch.bfloat16,\n",
    "):\n",
    "    sae_dict = torch.load(path, weights_only=True, map_location=device)\n",
    "    sae = SparseAutoEncoder(\n",
    "        d_in=sae_dict[\"encoder_linear.weight\"].shape[1],\n",
    "        d_hidden=sae_dict[\"encoder_linear.weight\"].shape[0],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    sae.load_state_dict(sae_dict)\n",
    "\n",
    "    return sae\n",
    "\n",
    "\n",
    "sae = load_sae(\n",
    "    path = os.path.join(sae_dir, \"Llama-3.3-70B-Instruct-SAE-l50.pt\"),\n",
    "    device=\"cuda:7\",\n",
    "    dtype=mt.dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ab785ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' jumps', prob=0.859375, logit=19.125, token_id=35308, metadata=None),\n",
       "  PredictedToken(token=' jumped', prob=0.0703125, logit=16.625, token_id=27096, metadata=None),\n",
       "  PredictedToken(token='\\n', prob=0.011474609375, logit=14.8125, token_id=198, metadata=None),\n",
       "  PredictedToken(token=' jumping', prob=0.00543212890625, logit=14.0625, token_id=30102, metadata=None),\n",
       "  PredictedToken(token=' is', prob=0.004486083984375, logit=13.875, token_id=374, metadata=None),\n",
       "  PredictedToken(token=' jump', prob=0.004486083984375, logit=13.875, token_id=7940, metadata=None),\n",
       "  PredictedToken(token=' (', prob=0.002410888671875, logit=13.25, token_id=320, metadata=None),\n",
       "  PredictedToken(token=',', prob=0.0019989013671875, logit=13.0625, token_id=11, metadata=None),\n",
       "  PredictedToken(token=' leaps', prob=0.0018768310546875, logit=13.0, token_id=84558, metadata=None),\n",
       "  PredictedToken(token='.\\n', prob=0.001068115234375, logit=12.4375, token_id=627, metadata=None),\n",
       "  PredictedToken(token='\\n\\n', prob=0.00083160400390625, logit=12.1875, token_id=271, metadata=None),\n",
       "  PredictedToken(token='...\\n', prob=0.00083160400390625, logit=12.1875, token_id=9522, metadata=None),\n",
       "  PredictedToken(token=' Jump', prob=0.000736236572265625, logit=12.0625, token_id=29888, metadata=None),\n",
       "  PredictedToken(token=' and', prob=0.000690460205078125, logit=12.0, token_id=323, metadata=None),\n",
       "  PredictedToken(token='.', prob=0.000690460205078125, logit=12.0, token_id=13, metadata=None)]]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"A quick brown fox\"\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt,\n",
    "    inputs = input,\n",
    "    k=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "455b8cba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NNsightError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 4 has a total capacity of 79.25 GiB of which 653.69 MiB is free. Process 2736752 has 54.34 GiB memory in use. Including non-PyTorch memory, this process has 24.24 GiB memory in use. Of the allocated memory 23.70 GiB is allocated by PyTorch, and 50.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/tracing/graph/node.py\", line 294, in execute",
      "    args, kwargs = self.prepare_inputs((self.args, self.kwargs))",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/graph/node.py\", line 81, in prepare_inputs",
      "    inputs = util.apply(inputs, _to, torch.Tensor, inplace=not fake)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/util.py\", line 44, in apply",
      "    return tuple([apply(_data, fn, cls, inplace=inplace) for _data in data])",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/util.py\", line 44, in <listcomp>",
      "    return tuple([apply(_data, fn, cls, inplace=inplace) for _data in data])",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/util.py\", line 39, in apply",
      "    data[idx] = apply(_data, fn, cls, inplace=inplace)",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/util.py\", line 32, in apply",
      "    return fn(data)",
      "           ^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/graph/node.py\", line 79, in _to",
      "    return value.to(device)",
      "           ^^^^^^^^^^^^^^^^",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 4 has a total capacity of 79.25 GiB of which 653.69 MiB is free. Process 2736752 has 54.34 GiB memory in use. Including non-PyTorch memory, this process has 24.24 GiB memory in use. Of the allocated memory 23.70 GiB is allocated by PyTorch, and 50.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
      "",
      "During handling of the above exception, another exception occurred:",
      "",
      "Traceback (most recent call last):",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main",
      "    ",
      "  File \"<frozen runpy>\", line 88, in _run_code",
      "    ",
      "",
      "NNsightError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 4 has a total capacity of 79.25 GiB of which 653.69 MiB is free. Process 2736752 has 54.34 GiB memory in use. Including non-PyTorch memory, this process has 24.24 GiB memory in use. Of the allocated memory 23.70 GiB is allocated by PyTorch, and 50.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from src.functional import get_module_nnsight\n",
    "\n",
    "def sae_intervention(\n",
    "    mt: ModelandTokenizer,\n",
    "    sae: SparseAutoEncoder,\n",
    "    input: str | TokenizerOutput,\n",
    "    hook_point: str = mt.layer_name_format.format(50),\n",
    "):\n",
    "    if isinstance(input, str):\n",
    "        input = prepare_input(prompts=input, tokenizer=mt)\n",
    "    elif isinstance(input, TokenizerOutput):\n",
    "        if \"offset_mapping\" in input:\n",
    "            input.pop(\"offset_mapping\")\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a string or TokenizerOutput.\")\n",
    "    \n",
    "    with mt.trace(input) as trace:\n",
    "        module = get_module_nnsight(mt, hook_point)\n",
    "        sae_input = module.output[0].save()\n",
    "        # trace.log(sae_input.shape)\n",
    "        sae_output, _ = sae(sae_input)\n",
    "        # trace.log(sae_output)\n",
    "        module.output[0][...] = sae_output\n",
    "\n",
    "        output = mt.output.save()\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "output = sae_intervention(\n",
    "    mt = mt, sae = sae, input = input\n",
    ")\n",
    "\n",
    "interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits = output.logits[:, -1],\n",
    "    k=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7767e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
