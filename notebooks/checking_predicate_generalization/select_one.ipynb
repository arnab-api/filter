{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e7c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cd4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:45:08 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-09-15 13:45:09 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=7, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-09-15 13:45:09 __main__ INFO     transformers.__version__='4.55.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3b2420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:45:40 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks/checking_predicate_generalization, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-15 13:45:40 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks/checking_predicate_generalization, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-15 13:45:40 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-09-15 13:45:40 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b62bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:45:42 src.models WARNING  Qwen/Qwen2.5-14B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-09-15 13:45:42 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:45:42 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "2025-09-15 13:45:42 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2.5-14B-Instruct/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8/config.json HTTP/1.1\" 200 0\n",
      "2025-09-15 13:45:42 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "2025-09-15 13:45:42 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2.5-14B-Instruct/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-09-15 13:45:42 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7036cb7f9e60457285b26b2ff9627bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:46:03 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 307 0\n",
      "2025-09-15 13:46:03 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2.5-14B-Instruct/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-09-15 13:46:03 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-09-15 13:46:03 src.models INFO     loaded model <Qwen/Qwen2.5-14B-Instruct> | size: 28171.604 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77abadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'prompt_templates', 'odd_one_prompt_templates', 'order_prompt_templates', 'count_prompt_templates', 'yes_no_prompt_templates', 'first_item_in_cat_prompt_templates', 'last_item_in_cat_prompt_templates', 'categories', 'exclude_categories']\n",
      "SelectOneTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectOneTask, CountingTask\n",
    "\n",
    "#################################################################################\n",
    "TASK_CLS = SelectOneTask\n",
    "prompt_template_idx = 3\n",
    "N_DISTRACTORS = 5\n",
    "OPTION_STYLE = \"single_line\"\n",
    "#################################################################################\n",
    "\n",
    "select_task = TASK_CLS.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(select_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da783c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Options: Surfboard, Temple, Toothbrush, Notebook, Guitar, Apple.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Apple\"\n"
     ]
    }
   ],
   "source": [
    "sample = select_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    # category=\"actor\",\n",
    "    # category=\"Brazil\"\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=False,\n",
    ")\n",
    "\n",
    "print(sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd154f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# * Surfboard\n",
      "* Temple\n",
      "* Toothbrush\n",
      "* Notebook\n",
      "* Guitar\n",
      "* Apple\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Apple\"\n"
     ]
    }
   ],
   "source": [
    "sample.default_option_style = \"bulleted\"\n",
    "print(sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb708dc",
   "metadata": {},
   "source": [
    "## Loading the heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42843f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:46:09 matplotlib DEBUG    matplotlib data path: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "2025-09-15 13:46:09 matplotlib DEBUG    CONFIGDIR=/disk/u/arnab/.config/matplotlib\n",
      "2025-09-15 13:46:09 matplotlib DEBUG    interactive is False\n",
      "2025-09-15 13:46:09 matplotlib DEBUG    platform is linux\n",
      "2025-09-15 13:46:09 matplotlib DEBUG    CACHEDIR=/disk/u/arnab/.cache/matplotlib\n",
      "2025-09-15 13:46:09 matplotlib.font_manager DEBUG    Using fontManager instance from /disk/u/arnab/.cache/matplotlib/fontlist-v390.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/disk/u/arnab/Codes/Projects/retrieval/results/selection/optimized_heads/Qwen2.5-14B-Instruct/distinct_options/select_one/epoch_10.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     11\u001b[39m optimized_path = os.path.join(\n\u001b[32m     12\u001b[39m     env_utils.DEFAULT_RESULTS_DIR,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mselection/optimized_heads\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mepoch_10.npz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# optimized_path = os.path.join(\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     env_utils.DEFAULT_RESULTS_DIR,\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#     \"test_opt_code\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[38;5;66;03m#     \"epoch_10.npz\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m optimization_results = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimized_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m plt.plot(optimization_results[\u001b[33m\"\u001b[39m\u001b[33mlosses\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     35\u001b[39m plt.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/connection/lib/python3.11/site-packages/numpy/lib/_npyio_impl.py:451\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    449\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/disk/u/arnab/Codes/Projects/retrieval/results/selection/optimized_heads/Qwen2.5-14B-Instruct/distinct_options/select_one/epoch_10.npz'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"selection/optimized_backup_heads\",\n",
    "#     mt.name.split(\"/\")[-1],\n",
    "#     f\"{select_task.task_name}.npz\"\n",
    "# )\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/optimized_heads\",\n",
    "    model_key.split(\"/\")[-1],\n",
    "    \"distinct_options\",\n",
    "    # f\"{select_task.task_name}\",\n",
    "    \"select_one\",\n",
    "    # \"legacy\",\n",
    "    \"epoch_10.npz\"\n",
    ")\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"test_opt_code\",\n",
    "#     model_key.split(\"/\")[-1],\n",
    "#     \"distinct_options\",\n",
    "#     f\"{select_task.task_name}\",\n",
    "#     # \"select_one\",\n",
    "#     \"legacy\",\n",
    "#     \"epoch_10.npz\"\n",
    "# )\n",
    "\n",
    "optimization_results = np.load(optimized_path, allow_pickle=True)\n",
    "plt.plot(optimization_results[\"losses\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdcc867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(torch.float32)\n",
    "optimal_head_mask[52:, :] = 0.0\n",
    "\n",
    "plt.imshow(\n",
    "    optimal_head_mask.T.numpy(),\n",
    "    cmap=\"Blues\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "optimized_heads = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).tolist()\n",
    "optimized_heads = [\n",
    "    (layer_idx, head_idx) for layer_idx, head_idx in optimized_heads\n",
    "]\n",
    "print(len(optimized_heads))\n",
    "\n",
    "HEADS = optimized_heads\n",
    "\n",
    "(35, 19) in HEADS, (35, 19) in optimized_heads\n",
    "# [(29, 3) in HEADS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb620ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 16:51:41 src.selection.functional DEBUG    Predictions: ['\" Ki\"[30558] (p=0.898, logit=22.625)', '\" The\"[578] (p=0.045, logit=19.625)', '\" Among\"[22395] (p=0.024, logit=19.000)', '\" A\"[362] (p=0.011, logit=18.250)', '\" Fruit\"[44187] (p=0.003, logit=16.875)']\n",
      "2025-09-10 16:51:41 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-2a4b4691-4213\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-2a4b4691-4213\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Ki\", \"wi\", \",\", \" Rose\", \",\", \" Food\", \" processor\", \",\", \" Museum\", \",\", \" Sh\", \"ampoo\", \",\", \" Printer\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" fruit\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.02913018688559532, 0.00925435870885849, 0.014361707493662834, 0.06832721829414368, 0.03311053290963173, 0.015749219805002213, 0.025898758322000504, 0.005028965882956982, 0.0067881434224545956, 0.018682697787880898, 0.004282681737095118, 0.009007562883198261, 0.03101426176726818, 0.0061639160849153996, 0.00744455074891448, 0.004576696082949638, 0.0266041811555624, 0.009600132703781128, 0.012233583256602287, 0.013888449408113956, 0.011790190823376179, 0.009428923949599266, 0.007790838833898306, 0.007996909320354462, 0.00810997374355793, 0.06197559833526611, 0.04497315734624863, 0.021503591910004616, 0.04710953310132027]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fdcc92c3a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.attention import get_attention_matrices\n",
    "from src.selection.functional import (\n",
    "    verify_head_patterns,\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    ")\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=sample.prompt(option_style=\"single_line\"),\n",
    "    options=sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b8618",
   "metadata": {},
   "source": [
    "## Checking the effect of formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ae8aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:46:17 src.selection.data INFO     clean_obj_idx=4 | ['Mango', 'Socks', 'Air fryer', 'Locket', 'Train', 'Skis']\n",
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "CLEAN: # * Scooter\n",
      "* Laptop\n",
      "* Chair\n",
      "* Kiwi\n",
      "* Jacket\n",
      "* Birch\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Ki\"\n",
      "PATCH: # Options: Mango, Socks, Air fryer, Locket, Train, Skis.\n",
      "Which among these objects mentioned above is a vehicle?\n",
      "Answer: >> \" Train\"\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import get_counterfactual_samples_within_task\n",
    "\n",
    "clean_sample, patch_sample = get_counterfactual_samples_within_task(\n",
    "    task=select_task,\n",
    "    mt=mt,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    distinct_options=True,\n",
    "    n_distractors=5,\n",
    "    filter_by_lm_prediction=False,\n",
    ")\n",
    "\n",
    "clean_sample.default_option_style = \"bulleted\"\n",
    "patch_sample.default_option_style = \"single_line\"\n",
    "\n",
    "assert clean_sample.default_option_style != patch_sample.default_option_style\n",
    "\n",
    "print(\n",
    "    \"CLEAN:\",\n",
    "    clean_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"PATCH:\",\n",
    "    patch_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2de39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326d58d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit',\n",
       " 'vehicle',\n",
       " 'furniture',\n",
       " 'animal',\n",
       " 'music instrument',\n",
       " 'clothing',\n",
       " 'electronics',\n",
       " 'sport equipment',\n",
       " 'kitchen appliance',\n",
       " 'vegetable',\n",
       " 'building',\n",
       " 'office supply',\n",
       " 'bathroom item',\n",
       " 'flower',\n",
       " 'tree',\n",
       " 'jewelry']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_task.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fff0b",
   "metadata": {},
   "source": [
    "# Validating Against Other Reduce Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5428ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "from src.selection.data import YesNoTask, SelectFirstTask, CountingTask\n",
    "from typing import Optional\n",
    "import copy\n",
    "from src.tokens import prepare_input\n",
    "from src.selection.utils import verify_correct_option\n",
    "from src.selection.data import get_options_for_answer\n",
    "\n",
    "\n",
    "def get_task_specific_kwargs(task, distinct_options=True):\n",
    "    kwargs = {}\n",
    "    if isinstance(task, CountingTask):\n",
    "        kwargs[\"clean_n_options\"] = random.choice(range(4, 7))\n",
    "        kwargs[\"patch_n_options\"] = random.choice(range(4, 7))\n",
    "        kwargs[\"distinct_options\"] = distinct_options\n",
    "    elif isinstance(task, YesNoTask):\n",
    "        kwargs[\"clean_n_options\"] = random.choice(range(3, 6))\n",
    "        kwargs[\"patch_n_options\"] = random.choice(range(3, 6))\n",
    "        # No distinct options for yes/no task\n",
    "    elif isinstance(task, SelectFirstTask | SelectLastTask):\n",
    "        #! this has to come before SelectOneTask since SelectFirstTask is a subclass of SelectOneTask\n",
    "        kwargs[\"distinct_options\"] = distinct_options\n",
    "        kwargs[\"n_distractors\"] = random.choice(range(3, 6))\n",
    "    elif isinstance(task, SelectOneTask):\n",
    "        kwargs[\"distinct_options\"] = distinct_options\n",
    "        kwargs[\"patch_n_distractors\"] = random.choice(range(2, 7))\n",
    "        kwargs[\"clean_n_distractors\"] = random.choice(range(2, 7))\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def get_counterfactual_samples_across_tasks(\n",
    "    mt: ModelandTokenizer,\n",
    "    patch_task,\n",
    "    clean_task,\n",
    "    patch_category: str,\n",
    "    clean_category: str,\n",
    "    patch_prompt_template_idx: int = 3,\n",
    "    clean_prompt_template_idx: int = 3,\n",
    "    clean_transform: Optional[callable] = None,\n",
    "    patch_transform: Optional[callable] = None,\n",
    "    filter_by_lm_prediction=False,\n",
    "    retry_count=0,\n",
    "):\n",
    "    categories = patch_task.categories\n",
    "    for category in clean_task.categories:\n",
    "        assert category in categories, \"Categories must be the same!\"\n",
    "\n",
    "    patch_category = patch_category or random.choice(categories)\n",
    "    clean_category = clean_category or random.choice(\n",
    "        list(set(categories) - {patch_category})\n",
    "    )\n",
    "\n",
    "    assert patch_category != clean_category, \"Categories must be different!\"\n",
    "\n",
    "    patch_sample, _ = get_counterfactual_samples_interface[patch_task.task_name](\n",
    "        mt=mt,\n",
    "        task=patch_task,\n",
    "        patch_category=patch_category,\n",
    "        clean_category=clean_category,\n",
    "        prompt_template_idx=patch_prompt_template_idx,\n",
    "        filter_by_lm_prediction=False,\n",
    "        **get_task_specific_kwargs(patch_task, distinct_options=True),\n",
    "    )\n",
    "\n",
    "    _, clean_sample = get_counterfactual_samples_interface[clean_task.task_name](\n",
    "        mt=mt,\n",
    "        task=clean_task,\n",
    "        patch_category=patch_category,\n",
    "        clean_category=clean_category,\n",
    "        prompt_template_idx=clean_prompt_template_idx,\n",
    "        filter_by_lm_prediction=False,\n",
    "        **get_task_specific_kwargs(clean_task, distinct_options=True),\n",
    "    )\n",
    "\n",
    "    if patch_transform is not None:\n",
    "        patch_sample = patch_transform(patch_sample)\n",
    "    if clean_transform is not None:\n",
    "        clean_sample = clean_transform(clean_sample)\n",
    "\n",
    "    if \"qwen\" in mt.name.lower():\n",
    "        # for attention sink\n",
    "        clean_sample.prompt_template = (\n",
    "            \"# \" + clean_sample.prompt_template\n",
    "            if not clean_sample.prompt_template.startswith(\"#\")\n",
    "            else clean_sample.prompt_template\n",
    "        )\n",
    "        patch_sample.prompt_template = (\n",
    "            \"# \" + patch_sample.prompt_template\n",
    "            if not patch_sample.prompt_template.startswith(\"#\")\n",
    "            else patch_sample.prompt_template\n",
    "        )\n",
    "\n",
    "    if filter_by_lm_prediction:\n",
    "        test_samples = [patch_sample, clean_sample]\n",
    "        gold_sample = copy.deepcopy(clean_sample)\n",
    "        gold_sample.category = clean_sample.metadata[\"track_category\"]\n",
    "        gold_sample.ans_token_id = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "        test_samples.append(gold_sample)\n",
    "\n",
    "        for sample in test_samples:\n",
    "            prompt = sample.prompt()\n",
    "            tokenized_inputs = prepare_input(prompts=prompt, tokenizer=mt.tokenizer)\n",
    "            sample.metadata[\"tokenized\"] = tokenized_inputs.data\n",
    "\n",
    "            print(\"-\" * 80)\n",
    "            print(sample.prompt(), \">>\", mt.tokenizer.decode(sample.ans_token_id))\n",
    "\n",
    "            is_correct, predictions, track_options = verify_correct_option(\n",
    "                mt=mt,\n",
    "                input=tokenized_inputs,\n",
    "                target=sample.ans_token_id,\n",
    "                options=get_options_for_answer(sample),\n",
    "            )\n",
    "\n",
    "            if is_correct is False:\n",
    "                logger.error(\n",
    "                    f'Prediction mismatch: {track_options[list(track_options.keys())[0]]}[\"{mt.tokenizer.decode(predictions[0].token_id)}\"] != {sample.ans_token_id}[\"{mt.tokenizer.decode(sample.ans_token_id)}\"]'\n",
    "                )\n",
    "                # for debugging\n",
    "                if retry_count > 5:\n",
    "                    raise ValueError(\"Max retries exceeded!\")\n",
    "\n",
    "                return get_counterfactual_samples_across_tasks(\n",
    "                    mt=mt,\n",
    "                    patch_task=patch_task,\n",
    "                    clean_task=clean_task,\n",
    "                    patch_category=patch_category,\n",
    "                    clean_category=clean_category,\n",
    "                    patch_prompt_template_idx=patch_prompt_template_idx,\n",
    "                    clean_prompt_template_idx=clean_prompt_template_idx,\n",
    "                    clean_transform=clean_transform,\n",
    "                    patch_transform=patch_transform,\n",
    "                    filter_by_lm_prediction=filter_by_lm_prediction,\n",
    "                    retry_count=retry_count + 1,\n",
    "                )\n",
    "\n",
    "    return patch_sample, clean_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556f772",
   "metadata": {},
   "source": [
    "### Select One -- MCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1776c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'prompt_templates', 'odd_one_prompt_templates', 'order_prompt_templates', 'count_prompt_templates', 'yes_no_prompt_templates', 'first_item_in_cat_prompt_templates', 'last_item_in_cat_prompt_templates', 'categories', 'exclude_categories']\n",
      "SelectOneTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample, SelectOneTask\n",
    "\n",
    "select_one_mcq = SelectOneTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        # \"landmarks.json\"\n",
    "    )\n",
    ")\n",
    "print(select_one_mcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4affdd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# a. Submarine\n",
      "b. Factory\n",
      "c. Coffee maker\n",
      "d. Pencil\n",
      "e. Harp\n",
      "f. Mango\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" f\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' f', prob=0.69140625, logit=27.25, token_id=282, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.13671875, logit=25.625, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Mango', prob=0.056884765625, logit=24.75, token_id=90863, metadata=None),\n",
       "  PredictedToken(token=' Among', prob=0.030517578125, logit=24.125, token_id=21658, metadata=None),\n",
       "  PredictedToken(token=' F', prob=0.02685546875, logit=24.0, token_id=434, metadata=None)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from src.selection.utils import get_first_token_id\n",
    "from src.functional import predict_next_token\n",
    "from src.selection.data import MCQify_sample\n",
    "\n",
    "test_sample = select_one_mcq.get_random_sample(\n",
    "    mt=mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    # category=\"actor\",\n",
    "    # category=\"United Kingdom\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "test_sample = MCQify_sample(mt, test_sample)\n",
    "print(\n",
    "    test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"'\n",
    ")\n",
    "\n",
    "predict_next_token(mt=mt, inputs=test_sample.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a70eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:48:32 src.selection.data INFO     clean_obj_idx=0 | ['Airplane', 'Tennis ball', 'Ruler', 'Monitor', 'Grape']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "2025-09-15 13:48:32 src.selection.data INFO     clean_obj_idx=4 | ['Grape', 'School', 'Sheep', 'Marker', 'Tractor']\n",
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Helicopter, Pineapple, Charm.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  Pine\n",
      "--------------------------------------------------------------------------------\n",
      "# a. Grape\n",
      "b. School\n",
      "c. Sheep\n",
      "d. Marker\n",
      "e. Tractor\n",
      "Which among these objects mentioned above is a vehicle?\n",
      "Answer: >>  e\n",
      "--------------------------------------------------------------------------------\n",
      "# a. Grape\n",
      "b. School\n",
      "c. Sheep\n",
      "d. Marker\n",
      "e. Tractor\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  a\n",
      "CLEAN: # a. Grape\n",
      "b. School\n",
      "c. Sheep\n",
      "d. Marker\n",
      "e. Tractor\n",
      "Which among these objects mentioned above is a vehicle?\n",
      "Answer: >> \" e\"\n",
      "PATCH: # Options: Helicopter, Pineapple, Charm.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Pine\"\n"
     ]
    }
   ],
   "source": [
    "def mcq_transform(sample):\n",
    "    sample = MCQify_sample(mt=mt, sample=sample)\n",
    "    if \"track_type_obj_token_id\" in sample.metadata:\n",
    "        patch_obj_idx = sample.metadata[\"track_type_obj_idx\"]\n",
    "        sample.metadata[\"track_type_obj_token_id\"] = get_first_token_id(\n",
    "            name=chr(ord(\"a\") + patch_obj_idx), tokenizer=mt.tokenizer, prefix=\" \"\n",
    "        )\n",
    "    return sample\n",
    "\n",
    "\n",
    "patch_sample, clean_sample = get_counterfactual_samples_across_tasks(\n",
    "    mt=mt,\n",
    "    patch_task=select_task,\n",
    "    clean_task=select_one_mcq,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    clean_transform=mcq_transform,\n",
    "    filter_by_lm_prediction=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"CLEAN:\",\n",
    "    clean_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"PATCH:\",\n",
    "    patch_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e5e09b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'track_category': 'fruit',\n",
       "  'track_type_obj': 'Grape',\n",
       "  'track_type_obj_idx': 0,\n",
       "  'track_type_obj_token_id': 264,\n",
       "  'ques_pos': 23,\n",
       "  'tokenized': {'input_ids': tensor([[    2,   264,    13, 79529,   198,    65,    13,  6022,   198,    66,\n",
       "               13, 82908,   198,    67,    13, 39875,   198,    68,    13,  1163,\n",
       "             5621,   198, 23085,  4221,  1493,  6171,  9733,  3403,   374,   264,\n",
       "             7310,  5267, 16141,    25]]),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       "  'question_type': 'MCQ'},\n",
       " ' e')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sample.metadata, mt.tokenizer.decode([clean_sample.ans_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15df782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb073450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6bd2b5c",
   "metadata": {},
   "source": [
    "### SelectFirstTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d29f1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFirstTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample, SelectFirstTask\n",
    "\n",
    "select_first_task = SelectFirstTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(select_first_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0144dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Rice cooker, Charm, Kiwi, Plum, Church, Blueberry, Scissors, Cat.\n",
      "What is the first fruit from the list above?\n",
      "Answer: >> \" Ki\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' The', prob=0.7734375, logit=32.75, token_id=576, metadata=None),\n",
       " PredictedToken(token=' Ki', prob=0.2216796875, logit=31.5, token_id=29458, metadata=None),\n",
       " PredictedToken(token=' To', prob=0.001495361328125, logit=26.5, token_id=2014, metadata=None),\n",
       " PredictedToken(token=' Plum', prob=0.0004863739013671875, logit=25.375, token_id=83309, metadata=None),\n",
       " PredictedToken(token=' From', prob=0.00017833709716796875, logit=24.375, token_id=5542, metadata=None)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = select_first_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=\"single_line\",\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2535336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 13:58:51 src.selection.data INFO     clean_obj_idx=2 | ['Strawberry', 'Mall', 'Helicopter', 'Television', 'Suit', 'Blender']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Bracelet, Pear, Bike.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  Pear\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Pear, Helicopter, Boat, Dumbbell, Peach.\n",
      "What is the first vehicle from the list above?\n",
      "Answer: >>  Hel\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Pear, Helicopter, Boat, Dumbbell, Peach.\n",
      "What is the first fruit from the list above?\n",
      "Answer: >>  Pear\n",
      "CLEAN: # Options: Pear, Helicopter, Boat, Dumbbell, Peach.\n",
      "What is the first vehicle from the list above?\n",
      "Answer: >> \" Hel\"\n",
      "PATCH: # Options: Bracelet, Pear, Bike.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Pear\"\n"
     ]
    }
   ],
   "source": [
    "patch_sample, clean_sample = get_counterfactual_samples_across_tasks(\n",
    "    mt=mt,\n",
    "    patch_task=select_task,\n",
    "    clean_task=select_first_task,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    clean_transform=None,\n",
    "    filter_by_lm_prediction=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"CLEAN:\",\n",
    "    clean_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"PATCH:\",\n",
    "    patch_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d92ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed1d901",
   "metadata": {},
   "source": [
    "### SelectLastTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fb79abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFirstTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample, SelectLastTask\n",
    "\n",
    "select_last_task = SelectLastTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(select_first_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b0c16d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:02:00 src.selection.data ERROR    Sample = Kiwi -> Cherry (5): ['Smartwatch', 'Skis', 'Chair', 'Pineapple', 'Mango', 'Cherry', 'Scooter', 'Ukulele']\n",
      "Top prediction (2, PredictedToken(token=' Mango', prob=0.032470703125, logit=27.0, token_id=90863, metadata=None)) does not match the object 44705, \" Cherry\".\n",
      "Retry count: 1. Retrying ...\n",
      "Options: Kiwi, Chair, Cherry, Phone, Pressure cooker, Comb, Trombone.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >> \" Cherry\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' The', prob=0.6875, logit=31.625, token_id=576, metadata=None),\n",
       " PredictedToken(token=' Cherry', prob=0.287109375, logit=30.75, token_id=44705, metadata=None),\n",
       " PredictedToken(token=' To', prob=0.026611328125, logit=28.375, token_id=2014, metadata=None),\n",
       " PredictedToken(token=' In', prob=0.000179290771484375, logit=23.375, token_id=758, metadata=None),\n",
       " PredictedToken(token=' Cher', prob=6.580352783203125e-05, logit=22.375, token_id=55107, metadata=None)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = select_last_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=\"single_line\",\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e331dc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distinct_options': True, 'n_distractors': 3}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_specific_kwargs(select_last_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24c95861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:06:45 src.selection.data INFO     clean_obj_idx=2 | ['Plum', 'Ruler', 'Truck']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Television, Cherry, Racket, Bike.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  Cherry\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Ash, Airplane, Pineapple, Blueberry, Yacht.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Ash, Airplane, Pineapple, Blueberry, Yacht.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "CLEAN: # Options: Ash, Airplane, Pineapple, Blueberry, Yacht.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >> \" Y\"\n",
      "PATCH: # Options: Television, Cherry, Racket, Bike.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Cherry\"\n"
     ]
    }
   ],
   "source": [
    "patch_sample, clean_sample = get_counterfactual_samples_across_tasks(\n",
    "    mt=mt,\n",
    "    patch_task=select_task,\n",
    "    clean_task=select_last_task,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    clean_transform=None,\n",
    "    filter_by_lm_prediction=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"CLEAN:\",\n",
    "    clean_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"PATCH:\",\n",
    "    patch_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc7153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f8bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e4d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc74551",
   "metadata": {},
   "source": [
    "## Counting Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16ee6cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountingTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import CountingSample, CountingTask\n",
    "\n",
    "counting_task = CountingTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(counting_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88114883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: Apple, Mango, Comb, Harp, Sunflower\n",
      "How many fruits are in this list?\n",
      "Answer:  >> \" Two\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Two', prob=1.4722347259521484e-05, logit=24.375, token_id=9043, metadata=None),\n",
       " PredictedToken(token=' Three', prob=2.066371962428093e-09, logit=15.5, token_id=14513, metadata=None),\n",
       " PredictedToken(token=' One', prob=1.2369127944111824e-10, logit=12.6875, token_id=3776, metadata=None),\n",
       " PredictedToken(token=' Four', prob=3.774403012357652e-11, logit=11.5, token_id=13322, metadata=None),\n",
       " PredictedToken(token=' Five', prob=8.412825991399586e-12, logit=10.0, token_id=20924, metadata=None),\n",
       " PredictedToken(token=' Zero', prob=3.8191672047105385e-13, logit=6.90625, token_id=18306, metadata=None),\n",
       " PredictedToken(token=' Six', prob=2.9665159217984183e-13, logit=6.65625, token_id=18680, metadata=None),\n",
       " PredictedToken(token=' Seven', prob=1.9184653865522705e-13, logit=6.21875, token_id=29948, metadata=None),\n",
       " PredictedToken(token=' Ten', prob=1.5898393712632242e-13, logit=6.03125, token_id=17695, metadata=None),\n",
       " PredictedToken(token=' Eight', prob=7.993605777301127e-14, logit=5.34375, token_id=35844, metadata=None),\n",
       " PredictedToken(token=' Nine', prob=1.454392162258955e-14, logit=3.640625, token_id=37066, metadata=None)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = counting_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3496bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 14:59:28 src.selection.data INFO     clean_obj_idx=0 | ['Boat', 'Locket', 'Orchid', 'Scarf', 'Strawberry']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "2025-09-15 14:59:28 src.selection.data DEBUG    clean_category='vehicle' | clean_sample.options=['Ambulance', 'Yacht', 'Submarine', 'Cherry', 'Blueberry']\n",
      "2025-09-15 14:59:28 src.selection.data DEBUG    patch_category='fruit' | patch_sample.options=['Tractor', 'Peach', 'Plum', 'Banana']\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Train, Mango, Smartwatch.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  Mango\n",
      "--------------------------------------------------------------------------------\n",
      "# Items: Ambulance, Yacht, Submarine, Cherry, Blueberry\n",
      "How many vehicles are in this list?\n",
      "Answer:  >>  Three\n",
      "--------------------------------------------------------------------------------\n",
      "# Items: Ambulance, Yacht, Submarine, Cherry, Blueberry\n",
      "How many fruits are in this list?\n",
      "Answer:  >>  Two\n",
      "CLEAN: # Items: Ambulance, Yacht, Submarine, Cherry, Blueberry\n",
      "How many vehicles are in this list?\n",
      "Answer:  >> \" Three\"\n",
      "PATCH: # Options: Train, Mango, Smartwatch.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Mango\"\n",
      "9043  Two\n"
     ]
    }
   ],
   "source": [
    "patch_sample, clean_sample = get_counterfactual_samples_across_tasks(\n",
    "    mt=mt,\n",
    "    patch_task=select_task,\n",
    "    clean_task=counting_task,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    clean_transform=None,\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"CLEAN:\",\n",
    "    clean_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"PATCH:\",\n",
    "    patch_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"',\n",
    ")\n",
    "\n",
    "print(\n",
    "    clean_sample.metadata[\"track_type_obj_token_id\"],\n",
    "    mt.tokenizer.decode(clean_sample.metadata[\"track_type_obj_token_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e2c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be111927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0c8b1c",
   "metadata": {},
   "source": [
    "### Yes/No Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47869299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YesNoTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import YesNoSample, YesNoTask\n",
    "\n",
    "yes_no_task = YesNoTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(yes_no_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53813195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items: Cherry, Elephant, Kiwi, Bench, Tablet\n",
      "How many fruits are in this list?\n",
      "Answer:  >> \" Two\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Two', prob=4.1425228118896484e-06, logit=21.875, token_id=9043, metadata=None),\n",
       " PredictedToken(token=' Three', prob=9.778887033462524e-08, logit=18.125, token_id=14513, metadata=None),\n",
       " PredictedToken(token=' One', prob=2.2737367544323206e-10, logit=12.0625, token_id=3776, metadata=None),\n",
       " PredictedToken(token=' Four', prob=1.864464138634503e-11, logit=9.5625, token_id=13322, metadata=None),\n",
       " PredictedToken(token=' Five', prob=5.030642569181509e-12, logit=8.25, token_id=20924, metadata=None),\n",
       " PredictedToken(token=' Zero', prob=2.4442670110147446e-12, logit=7.53125, token_id=18306, metadata=None),\n",
       " PredictedToken(token=' Six', prob=7.034373084024992e-13, logit=6.28125, token_id=18680, metadata=None),\n",
       " PredictedToken(token=' Ten', prob=4.263256414560601e-13, logit=5.78125, token_id=17695, metadata=None),\n",
       " PredictedToken(token=' Seven', prob=2.9309887850104133e-13, logit=5.40625, token_id=29948, metadata=None),\n",
       " PredictedToken(token=' Eight', prob=2.8421709430404007e-13, logit=5.375, token_id=35844, metadata=None),\n",
       " PredictedToken(token=' Nine', prob=4.551914400963142e-14, logit=3.546875, token_id=37066, metadata=None)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = counting_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6bec85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 15:05:00 src.selection.data INFO     clean_obj_idx=1 | ['Jacket', 'Helicopter', 'Surfboard', 'Apple', 'Tiara']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Ambulance, Mosque, Cherry, Coat, Food processor, Tablet.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  Cherry\n",
      "--------------------------------------------------------------------------------\n",
      "# Items: Stool, Cherry, Shower, Bat, Mall\n",
      "Do you see a vehicle in the list above?\n",
      "Answer: >>  No\n",
      "--------------------------------------------------------------------------------\n",
      "# Items: Stool, Cherry, Shower, Bat, Mall\n",
      "Do you see a fruit in the list above?\n",
      "Answer: >>  Yes\n",
      "2025-09-15 15:05:00 __main__ ERROR    Prediction mismatch: (1, PredictedToken(token=' No', prob=0.92578125, logit=32.0, token_id=2308, metadata=None))[\" No\"] != 7414[\" Yes\"]\n",
      "2025-09-15 15:05:00 src.selection.data INFO     clean_obj_idx=5 | ['Dog', 'Ottoman', 'Tulip', 'Kiwi', 'Mosque', 'Helicopter', 'Ring']\n",
      "type(task)=<class 'src.selection.data.SelectOneTask'>\n",
      "--------------------------------------------------------------------------------\n",
      "# Options: Toaster, Surfboard, Motorcycle, Lily, Banana.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >>  Banana\n",
      "--------------------------------------------------------------------------------\n",
      "# Items: Rose, Bike, Eraser, Boat, Locket\n",
      "Do you see a vehicle in the list above?\n",
      "Answer: >>  Yes\n",
      "--------------------------------------------------------------------------------\n",
      "# Items: Rose, Bike, Eraser, Boat, Locket\n",
      "Do you see a fruit in the list above?\n",
      "Answer: >>  No\n",
      "CLEAN: # Items: Rose, Bike, Eraser, Boat, Locket\n",
      "Do you see a vehicle in the list above?\n",
      "Answer: >> \" Yes\"\n",
      "PATCH: # Options: Toaster, Surfboard, Motorcycle, Lily, Banana.\n",
      "Which among these objects mentioned above is a fruit?\n",
      "Answer: >> \" Banana\"\n",
      "2308  No\n"
     ]
    }
   ],
   "source": [
    "patch_sample, clean_sample = get_counterfactual_samples_across_tasks(\n",
    "    mt=mt,\n",
    "    patch_task=select_task,\n",
    "    clean_task=yes_no_task,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    clean_transform=None,\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"CLEAN:\",\n",
    "    clean_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"',\n",
    ")\n",
    "print(\n",
    "    \"PATCH:\",\n",
    "    patch_sample.prompt(),\n",
    "    \">>\",\n",
    "    f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"',\n",
    ")\n",
    "\n",
    "print(\n",
    "    clean_sample.metadata[\"track_type_obj_token_id\"],\n",
    "    mt.tokenizer.decode(clean_sample.metadata[\"track_type_obj_token_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528d708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d661d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
