{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ec34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfae7235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:33:25 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-09-15 09:33:25 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-09-15 09:33:25 __main__ INFO     transformers.__version__='4.55.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7720ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:33:28 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-15 09:33:28 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-15 09:33:28 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-09-15 09:33:28 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683855df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:33:29 src.models WARNING  meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-09-15 09:33:29 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:33:29 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-09-15 09:33:29 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-09-15 09:33:29 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/meta-llama/Llama-3.3-70B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c222d369eff4cd2b17c8721009035cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:16 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-09-15 09:34:16 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-09-15 09:34:16 src.models INFO     loaded model <meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080021e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = os.path.join(\n",
    "#     env_utils.DEFAULT_DATA_DIR,\n",
    "#     \"selection\",\n",
    "#     # \"profession.json\"\n",
    "#     # \"nationality.json\"\n",
    "#     \"objects.json\",\n",
    "# )\n",
    "\n",
    "# with open(file_path, \"r\") as f:\n",
    "#     temp = json.load(f)\n",
    "\n",
    "# for cat in temp[\"categories\"]:\n",
    "#     temp[\"categories\"][cat] = [obj.capitalize() for obj in temp[\"categories\"][cat]]\n",
    "\n",
    "# with open(file_path, \"w\") as f:\n",
    "#     json.dump(temp, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62d97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectLastTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import (\n",
    "    SelectOneTask,\n",
    "    CountingTask,\n",
    "    YesNoTask,\n",
    "    SelectFirstTask,\n",
    "    SelectLastTask,\n",
    ")\n",
    "\n",
    "#################################################################################\n",
    "# TASK_CLS = CountingTask\n",
    "# prompt_template_idx = 1\n",
    "# TASK_CLS = SelectOneTask\n",
    "# prompt_template_idx = 3\n",
    "# TASK_CLS = YesNoTask\n",
    "# prompt_template_idx = 3\n",
    "# TASK_CLS = SelectFirstTask\n",
    "TASK_CLS = SelectLastTask\n",
    "prompt_template_idx = 3\n",
    "\n",
    "N_DISTRACTORS = 5\n",
    "OPTION_STYLE = \"single_line\"\n",
    "#################################################################################\n",
    "\n",
    "select_task = TASK_CLS.load(\n",
    "    path=os.path.join(env_utils.DEFAULT_DATA_DIR, \"selection\", \"objects.json\")\n",
    ")\n",
    "\n",
    "print(select_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45087a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Pineapple, Baseball, Air fryer, Peach, Plum, Ring, Cherry, Headphones, Van.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >> \" Cherry\"\n"
     ]
    }
   ],
   "source": [
    "sample = select_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    # category=\"actor\",\n",
    "    # category=\"Brazil\"\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=False,\n",
    "    # exclude_distractor_categories=select_task.exclude_for_category(\"fruit\")\n",
    ")\n",
    "\n",
    "print(sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0499b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Van is not a fruit, so the last fruit in the list is Cherry.\n",
      "The best answer is\"\n"
     ]
    }
   ],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = sample.prompt(),\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "print(f'\"{gen}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e8a8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.n_layer, mt.config.num_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a35516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "llama_70_heads = [\n",
    "    (33, 45),\n",
    "    (33, 18),\n",
    "    (34, 1),\n",
    "    (34, 6),\n",
    "    (34, 7),\n",
    "    (35, 19),\n",
    "    (39, 40),\n",
    "    (42, 30),\n",
    "    (47, 18),\n",
    "    (52, 58),\n",
    "]\n",
    "\n",
    "qwen_72_heads = [\n",
    "    (62, 1),\n",
    "    (60, 9),\n",
    "    (64, 8),\n",
    "    (62, 0),\n",
    "    (62, 45),\n",
    "    (59, 59),\n",
    "    (71, 28),\n",
    "    (64, 12),\n",
    "    (61, 7),\n",
    "    (64, 13),\n",
    "    (67, 53),\n",
    "    (67, 51),\n",
    "    (54, 44),\n",
    "    (57, 5),\n",
    "    (59, 60),\n",
    "    (71, 25),\n",
    "    (62, 7),\n",
    "    (64, 9),\n",
    "    (62, 23),\n",
    "    (65, 40),\n",
    "]\n",
    "\n",
    "qwen_32_heads = [\n",
    "    (51, 11),\n",
    "    (48, 4),\n",
    "    (52, 21),\n",
    "    (54, 35),\n",
    "    (48, 8),\n",
    "    (50, 6),\n",
    "    (48, 9),\n",
    "    (48, 32),\n",
    "    (52, 10),\n",
    "    (45, 11),\n",
    "    (45, 13),\n",
    "    (48, 34),\n",
    "    (53, 16),\n",
    "    (50, 12),\n",
    "    (49, 2),\n",
    "    (54, 38),\n",
    "    (55, 4),\n",
    "    (50, 27),\n",
    "    (54, 33),\n",
    "    (50, 14),\n",
    "]\n",
    "\n",
    "\n",
    "# HEADS = [(35, 19)]\n",
    "\n",
    "\n",
    "# with open(\"optimized_heads.json\", \"r\") as f:\n",
    "#     HEADS = json.load(f)\n",
    "\n",
    "# with open(\"category_wise_heads.json\", \"r\") as f:\n",
    "#     category_wise_heads = json.load(f)\n",
    "# HEADS = [\n",
    "#     (layer_idx, head_idx)\n",
    "#     for layer_idx, head_idx, score in category_wise_heads[\"all\"][:100]\n",
    "# ]\n",
    "# HEADS = [(layer_idx, head_idx) for layer_idx, head_idx in HEADS if layer_idx < 61]\n",
    "\n",
    "# HEADS = qwen_32_heads\n",
    "HEADS = llama_70_heads\n",
    "print(len(HEADS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe381b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:28 matplotlib DEBUG    matplotlib data path: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "2025-09-15 09:34:28 matplotlib DEBUG    CONFIGDIR=/disk/u/arnab/.config/matplotlib\n",
      "2025-09-15 09:34:28 matplotlib DEBUG    interactive is False\n",
      "2025-09-15 09:34:28 matplotlib DEBUG    platform is linux\n",
      "2025-09-15 09:34:28 matplotlib DEBUG    CACHEDIR=/disk/u/arnab/.cache/matplotlib\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    Using fontManager instance from /disk/u/arnab/.cache/matplotlib/fontlist-v390.json\n",
      "2025-09-15 09:34:28 matplotlib.pyplot DEBUG    Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2025-09-15 09:34:28 matplotlib.pyplot DEBUG    Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_K.otf', name='Linux Biolinum Keyboard O', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-Italic.otf', name='STIX', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-BlackItalic.ttf', name='Lato', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Oblique.ttf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-BoldOblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Regular.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Roman.otf', name='P052', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond-InitialsF2.ttf', name='EB Garamond Initials Fill2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-BoldItalic.ttf', name='Lato', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/rsfs10.ttf', name='rsfs10', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerifItalic.otf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa.ttf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-Bold.otf', name='STIX', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_DR.otf', name='Linux Libertine Display O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono.ttf', name='Go Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasB.ttf', name='Gentium Basic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/batang.ttf', name='Baekmuk Batang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/mry_KacstQurn.ttf', name='mry_KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Regular.ttf', name='Padauk Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-BoldItalic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Regular.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTamil-Bold.ttf', name='Noto Sans Tamil', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-BoldOblique.otf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeThreeSym-Bold.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Navilu/Navilu.ttf', name='Navilu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-BoldItalic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBoldItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMono.otf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-Oblique.otf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramondSC12-Regular.otf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOSsys.ttf', name='Khmer OS System', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-Bold.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-C.ttf', name='Ubuntu Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lao/Phetsarath_OT.ttf', name='Phetsarath OT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-Italic.ttf', name='Cousine', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNaskhArabic-Regular.ttf', name='Noto Naskh Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-Regular.otf', name='Accanthis ADF Std', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-Regular.ttf', name='Caladea', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sahadeva/sahadeva.ttf', name='Sahadeva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee.ttf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Andale_Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldItalic.ttf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstQurn.ttf', name='KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-BoldOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-Bold.ttf', name='Noto Serif Display', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoKufiArabic-Bold.ttf', name='Noto Kufi Arabic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-Regular.otf', name='Accanthis ADF Std No2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGurmukhi-Regular.ttf', name='Noto Serif Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-BoldItalic.ttf', name='Noto Serif Display', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeFourSym-Regular.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhmer-Regular.ttf', name='Noto Sans Khmer', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/comfortaa/Comfortaa-Light.ttf', name='Comfortaa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTibetan-Regular.ttf', name='Noto Serif Tibetan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-Regular.ttf', name='Cousine', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-BoldItalic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/gentiumplus/GentiumPlusCompact-R.ttf', name='Gentium Plus Compact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Oblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-BoldItalic.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/Gentium-I.ttf', name='Gentium', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New_Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGurmukhi-Bold.ttf', name='Noto Sans Gurmukhi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter.otf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Regular.ttf', name='Yrsa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-SemiboldItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-guru-extra/Saab.ttf', name='Saab', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-BoldOblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono-Bold.ttf', name='Go Mono', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Bold.ttf', name='Rachana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-BoldItalic.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Medium.ttf', name='Roboto', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifSinhala-Bold.ttf', name='Noto Serif Sinhala', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-BoldOblique.ttf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New_Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf', name='IPAGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-BoldItalic.ttf', name='Carlito', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma-Oblique.otf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter-Bold.otf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPoster.ttf', name='KacstPoster', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond12-AllSC.otf', name='EB Garamond 12 All SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic/uming.ttc', name='AR PL UMing CN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-Bold.ttf', name='Carlito', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLao-Regular.ttf', name='Noto Sans Lao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasR.ttf', name='Gentium Basic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond08-Italic.otf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMonoBoldOblique.otf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstNaskh.ttf', name='KacstNaskh', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeOneSym-Regular.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-Bold.ttf', name='Noto Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-LightItalic.ttf', name='Roboto', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Italic.otf', name='Cabin', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-Italic.otf', name='Accanthis ADF Std No3', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-BoldCond.otf', name='Gillius ADF', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNaskhArabic-Bold.ttf', name='Noto Naskh Arabic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-Regular.otf', name='STIX', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Regular.otf', name='Gillius ADF', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Black.ttf', name='Roboto', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Bold.otf', name='P052', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuMathTeXGyre.ttf', name='DejaVu Math TeX Gyre', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-BoldOblique.otf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCherokee-Bold.ttf', name='Noto Sans Cherokee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/complutum/GFSPolyglot.otf', name='GFS Complutum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-Regular.ttf', name='Carlito', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLao-Bold.ttf', name='Noto Sans Lao', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/D050000L.otf', name='D050000L', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Italic.ttf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-BoldItalic.otf', name='Cabin', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Tamil.ttf', name='Samyak Tamil', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-kalapi/Kalapi.ttf', name='Kalapi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/hline.ttf', name='Baekmuk Headline', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGurmukhi-Bold.ttf', name='Noto Serif Gurmukhi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond08-Italic.ttf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBoldOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Oblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush.ttf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentiumplus/GentiumPlus-R.ttf', name='Gentium Plus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 1.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSymbols-Bold.ttf', name='Noto Sans Symbols', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramondSC08-Regular.ttf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-malayalam/Lohit-Malayalam.ttf', name='Lohit Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman.ttf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RI.otf', name='Linux Libertine O', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnPilgi.ttf', name='UnPilgi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/comic.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/abyssinica/AbyssinicaSIL-Regular.ttf', name='Abyssinica SIL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-MediumItalic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=500, stretch='condensed', size='scalable')) = 11.344999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/Gentium-R.ttf', name='Gentium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-R.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne.ttf', name='KacstOne', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/courbi.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeTwoSym-Regular.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf', name='Noto Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifBengali-Bold.ttf', name='Noto Serif Bengali', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-LightItalic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=300, stretch='condensed', size='scalable')) = 11.344999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Bold.ttf', name='Padauk Book', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramondSC08-Regular.otf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-Regular.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerifBold.otf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/aakar-medium.ttf', name='aakar', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Medium.ttf', name='Go Medium', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnVada.ttf', name='UnVada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-BoldCondItalic.otf', name='Gillius ADF', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeThreeSym-Regular.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-Slanted.ttf', name='Amiri', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda-Oblique.otf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-CondItalic.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-Bold.otf', name='Accanthis ADF Std', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifBengali-Regular.ttf', name='Noto Serif Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic/ukai.ttc', name='AR PL UKai CN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraBd.ttf', name='Bitstream Vera Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.2440909090909091\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDotumBold.ttf', name='UnDotum', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDinaruBold.ttf', name='UnDinaru', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 0.5349999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Oblique.ttf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Bold.ttf', name='Open Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasI.ttf', name='Gentium Basic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/chandas1-2.ttf', name='Chandas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldItalic.ttf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDeseret-Regular.ttf', name='Noto Sans Deseret', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Chilanka-Regular.otf', name='Chilanka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Suruma.ttf', name='Suruma', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/GentiumAlt-I.ttf', name='GentiumAlt', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf', name='Noto Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Regular.ttf', name='Open Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnGraphicBold.ttf', name='UnGraphic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoNovel.ttf', name='UnJamoNovel', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-R.ttf', name='Ubuntu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTelugu-Regular.ttf', name='Noto Serif Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-BdIta.otf', name='C059', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/GentiumAlt-R.ttf', name='GentiumAlt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMath-Regular.ttf', name='Noto Sans Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Bold.ttf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush.otf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Regular.ttf', name='Rasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma.otf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldOblique.ttf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/porson/GFSPorson.otf', name='GFS Porson', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-SemiBoldItalic.otf', name='Cabin', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-Bold.otf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Bold.otf', name='Nimbus Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode-BoldItalic.ttf', name='Junicode', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-BoldItalic.otf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-BI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Light.ttf', name='Lato', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Bold.otf', name='Nimbus Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnPenheulim.ttf', name='UnPenheulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnPen.ttf', name='UnPen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Bold.otf', name='Cabin', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-BoldItalic.ttf', name='Tinos', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoDotum.ttf', name='UnJamoDotum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/arialbd.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana_Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-HairlineItalic.ttf', name='Lato', style='italic', variant='normal', weight=100, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCherokee-Regular.ttf', name='Noto Sans Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDevanagari-Bold.ttf', name='Noto Sans Devanagari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidotBold.otf', name='GFS Didot', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-LI.ttf', name='Ubuntu', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-Bold.otf', name='Accanthis ADF Std No3', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma-Bold.otf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-japanese-gothic.ttf', name='IPAexGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-BoldItalic.ttf', name='Noto Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-BoldItalic.otf', name='Accanthis ADF Std No2', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifLao-Regular.ttf', name='Noto Serif Lao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgiab.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebucbd.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerifBoldItalic.otf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSinhala-Regular.ttf', name='Noto Sans Sinhala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter-BoldOblique.otf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi.otf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond-InitialsF1.otf', name='EB Garamond Initials Fill1', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMoBd.ttf', name='Bitstream Vera Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-telugu/Lohit-Telugu.ttf', name='Lohit Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisiaBold.otf', name='GFS Artemisia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-BoldItalic.ttf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Cond.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond08-Regular.otf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Italic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf', name='Ubuntu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMusic-Regular.ttf', name='Noto Music', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/bodoni-classic/GFSBodoniClassic.otf', name='GFS BodoniClassic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-Regular.ttf', name='Amiri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnPilgiBold.ttf', name='UnPilgi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Regular.otf', name='Cabin', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNastaliqUrdu-Regular.ttf', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Light.ttf', name='Roboto', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraSe.ttf', name='Bitstream Vera Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMalayalam-Regular.ttf', name='Noto Sans Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-BoldCondIt.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-Italic.ttf', name='Carlito', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/AmiriQuranColored.ttf', name='Amiri Quran Colored', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstArt.ttf', name='KacstArt', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOriya-Regular.ttf', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-MediumItalic.ttf', name='Lato', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-CondLightItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=300, stretch='condensed', size='scalable')) = 11.344999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee.otf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-Light.otf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS_Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenicBold.otf', name='GFS Neohellenic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdanab.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDigital.ttf', name='KacstDigital', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond12-Italic.ttf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Semibold.ttf', name='Lato', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/couri.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-BoldOblique.ttf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Light.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Black.ttf', name='Lato', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Italic.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKannada-Regular.ttf', name='Noto Sans Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldOblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-gbsn00lp/gbsn00lp.ttf', name='AR PL SungtiL GB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-Oblique.otf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifArmenian-Regular.ttf', name='Noto Serif Armenian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gazis/GFSGazis.otf', name='GFS Gazis', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-BoldItalic.ttf', name='Arimo', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Medium.ttf', name='Yrsa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOriya-Bold.ttf', name='Noto Sans Oriya', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTelugu-Bold.ttf', name='Noto Serif Telugu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-Italic.ttf', name='Tinos', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Oblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNastaliqUrdu-Bold.ttf', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Medium-Italic.ttf', name='Go Medium', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Regular.otf', name='Manjari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-CondItalic.otf', name='Gillius ADF', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree-Oblique.otf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/msbm10.ttf', name='msbm10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-BoldOblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo-Oblique.otf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Thin.otf', name='Gayathri', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari.otf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Bold_Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Bold.ttf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-DemiItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstBook.ttf', name='KacstBook', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RZI.otf', name='Linux Libertine O', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisiaIt.otf', name='GFS Artemisia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgiai.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Bold.ttf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMono.ttf', name='Bitstream Vera Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMalayalam-Regular.ttf', name='Noto Serif Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-MediumItalic.otf', name='Cabin', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstLetter.ttf', name='KacstLetter', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Bold.ttf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Medium.otf', name='Cabin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-Regular.ttf', name='Noto Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-B.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-assamese/Lohit-Assamese.ttf', name='Lohit Assamese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman.otf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-BoldItalic.otf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSymbols2-Regular.ttf', name='Noto Sans Symbols2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-BoldItalic.otf', name='Gillius ADF', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MuktiNarrowBold.ttf', name='Mukti Narrow', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/Pothana2000.ttf', name='Pothana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Regular.ttf', name='Rachana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Light.ttf', name='Open Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/font-awesome/FontAwesome.otf', name='FontAwesome', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-kannada/Lohit-Kannada.ttf', name='Lohit Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitleL.ttf', name='KacstTitleL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-Regular.ttf', name='Noto Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-CondItalic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBoldOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter-Oblique.otf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-mincho/ipamp.ttf', name='IPAPMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Oblique.ttf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Dyuthi-Regular.ttf', name='Dyuthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSymbols-Regular.ttf', name='Noto Sans Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXVariants-Regular.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-MI.ttf', name='Ubuntu', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-MediumItalic.ttf', name='Roboto', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Keraleeyam-Regular.ttf', name='Keraleeyam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThaana-Bold.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnGungseo.ttf', name='UnGungseo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/esint10.ttf', name='esint10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipaexfont-gothic/ipaexg.ttf', name='IPAexGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Bold.ttf', name='Yrsa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifEthiopic-Regular.ttf', name='Noto Serif Ethiopic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia_Bold_Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman-Bold.otf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Italic.ttf', name='Go', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Bold.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-BoldItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Meera-Regular.ttf', name='Meera', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi.ttf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPen.ttf', name='KacstPen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono-Italic.ttf', name='Go Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond-Initials.ttf', name='EB Garamond Initials', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTelugu-Regular.ttf', name='Noto Sans Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/Rekha.ttf', name='Rekha', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Bold.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-Italic.ttf', name='Caladea', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/AnjaliOldLipi-Regular.ttf', name='AnjaliOldLipi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Karumbi-Regular.ttf', name='Karumbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGeorgian-Regular.ttf', name='Noto Sans Georgian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot-classic/GFSDidotClassic.otf', name='GFS Didot Classic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoBatang.ttf', name='UnJamoBatang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-Italic.otf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-Regular.ttf', name='Tinos', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoKufiArabic-Regular.ttf', name='Noto Kufi Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-Regular.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Bold.ttf', name='Rasa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-Bold.ttf', name='Noto Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-ExtraBold.otf', name='Cantarell', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-BoldCond.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode-Italic.ttf', name='Junicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Regular.otf', name='Nimbus Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-Italic.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana_Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_R.otf', name='Linux Libertine O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MuktiNarrow.ttf', name='Mukti Narrow', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKhmer-Bold.ttf', name='Noto Serif Khmer', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/openoffice/opens___.ttf', name='OpenSymbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGujarati-Regular.ttf', name='Noto Sans Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond08-Regular.ttf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf', name='Noto Sans Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Bold.ttf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraSeBd.ttf', name='Bitstream Vera Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 1.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/comfortaa/Comfortaa-Bold.ttf', name='Comfortaa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGurmukhi-Regular.ttf', name='Noto Sans Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCanadianAboriginal-Bold.ttf', name='Noto Sans Canadian Aboriginal', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma-BoldOblique.otf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist-Oblique.otf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeFourSym-Bold.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/ani.ttf', name='Ani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_M.otf', name='Linux Libertine Mono O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeTwoSym-Bold.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-BookOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Oblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond-InitialsF2.otf', name='EB Garamond Initials Fill2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-Regular.otf', name='Accanthis ADF Std No3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBold.ttf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Regular.ttf', name='Padauk', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda.otf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenic.otf', name='GFS Neohellenic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/comicbd.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/ariali.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidotItalic.otf', name='GFS Didot', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenicIt.otf', name='GFS Neohellenic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasBI.ttf', name='Gentium Basic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-Bold.ttf', name='Noto Sans Display', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia_Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-Bold.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMayanNumerals-Regular.ttf', name='Noto Sans Mayan Numerals', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-BoldItalic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Semibold.ttf', name='Open Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-BoldItalic.ttf', name='Noto Sans Display', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-Bold.otf', name='Accanthis ADF Std No2', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBold.ttf', name='Yrsa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Regular.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist.otf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMyanmar-Bold.ttf', name='Noto Serif Myanmar', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-Italic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenicBoldIt.otf', name='GFS Neohellenic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-BI.ttf', name='Ubuntu', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-BoldItalic.ttf', name='Cousine', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUp-Regular.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifEthiopic-Bold.ttf', name='Noto Serif Ethiopic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo.otf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Bold_Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/arialbi.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifArmenian-Bold.ttf', name='Noto Serif Armenian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansEthiopic-Regular.ttf', name='Noto Sans Ethiopic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAdlamUnjoined-Regular.ttf', name='Noto Sans Adlam Unjoined', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-CondBold.ttf', name='Open Sans Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Regular.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/stmary10.ttf', name='stmary10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Bold.ttf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Italic.otf', name='Gillius ADF', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKannada-Regular.ttf', name='Noto Serif Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Bold.ttf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Regular.otf', name='Nimbus Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-ThinItalic.ttf', name='Lato', style='italic', variant='normal', weight=200, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifThai-Regular.ttf', name='Noto Serif Thai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Bold.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-gkai00mp/gkai00mp.ttf', name='AR PL KaitiM GB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sarai/Sarai.ttf', name='Sarai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Light.otf', name='URW Bookman', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono-Bold-Italic.ttf', name='Go Mono', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-BoldItalic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono-Bold.otf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Oblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Book.otf', name='URW Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee-Bold.otf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Bold-Italic.ttf', name='Go', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Comic_Sans_MS_Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Demi.otf', name='URW Bookman', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGeorgian-Bold.ttf', name='Noto Serif Georgian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/olga/GFSOlga.otf', name='GFS Olga', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-LightItalic.ttf', name='Lato', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Regular.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasR.ttf', name='Gentium Book Basic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/Z003-MediumItalic.otf', name='Z003', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGeorgian-Regular.ttf', name='Noto Serif Georgian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGujarati-Bold.ttf', name='Noto Serif Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidot.otf', name='GFS Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-Regular.otf', name='Berenis ADF Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifHebrew-Bold.ttf', name='Noto Serif Hebrew', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Oblique.ttf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIXMath-Regular.otf', name='STIX Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-Regular.ttf', name='Noto Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-BoldItalic.otf', name='P052', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnBatangBold.ttf', name='UnBatang', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda-Bold.otf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMonoBold.otf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpSm-Bold.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-SemiBold.ttf', name='Rasa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/times.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/dotum.ttf', name='Baekmuk Dotum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Bold.ttf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond-Initials.otf', name='EB Garamond Initials', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXVariants-Bold.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Italic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-LightItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-BoldCond.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-orya-extra/utkal.ttf', name='ori1Uni', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_I.otf', name='Linux Libertine Initials O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKannada-Bold.ttf', name='Noto Serif Kannada', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSans.ttf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa-Bold.otf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBengali-Bold.ttf', name='Noto Sans Bengali', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArabic-Regular.ttf', name='Noto Sans Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-Italic.otf', name='Accanthis ADF Std No2', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSans.otf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Hairline.ttf', name='Lato', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/pagul/Pagul.ttf', name='Pagul', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Italic.ttf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Light.otf', name='Cantarell', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_R.otf', name='Linux Biolinum O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baskerville/GFSBaskerville.otf', name='GFS Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/eufm10.ttf', name='eufm10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBold.ttf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Light.ttf', name='Yrsa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-gujarati/Lohit-Gujarati.ttf', name='Lohit Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Thin.ttf', name='Lato', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/mitra.ttf', name='Mitra Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnTaza.ttf', name='UnTaza', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma.ttf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-LightOblique.otf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/wasy10.ttf', name='wasy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-BoldOblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMono.ttf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tibetan-machine/TibetanMachineUni.ttf', name='Tibetan Machine Uni', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Bold.ttf', name='Lato', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-LightOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDinaruLight.ttf', name='UnDinaru', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-BoldItalic.ttf', name='Noto Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Regular.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-BoldOblique.otf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-Italic.otf', name='Accanthis ADF Std', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New_Bold_Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree.otf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMoIt.ttf', name='Bitstream Vera Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS_Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-BoldItalic.otf', name='Accanthis ADF Std', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa-Oblique.otf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Bold.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Regular.ttf', name='Roboto', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsD-Bold.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMonoOblique.otf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-Bold.otf', name='Berenis ADF Pro', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-ThinItalic.ttf', name='Roboto', style='italic', variant='normal', weight=250, stretch='normal', size='scalable')) = 11.1925\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Bold.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidotBoldItalic.otf', name='GFS Didot', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-oriya/Lohit-Odia.ttf', name='Lohit Odia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/timesi.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnPilgia.ttf', name='UnPilgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-BoldSlanted.ttf', name='Amiri', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSansBoldOblique.otf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerif.otf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSansOblique.otf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/FoulisGreek.ttf', name='FoulisGreek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/timesbi.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpD-Bold.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-BoldItalic.otf', name='STIX', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamilSlanted-Bold.ttf', name='Noto Serif Tamil Slanted', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil-classical/Lohit-Tamil-Classical.ttf', name='Lohit Tamil Classical', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Oblique.ttf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf', name='Noto Sans Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMalayalam-Bold.ttf', name='Noto Serif Malayalam', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman-BoldItalic.otf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-BoldItalic.ttf', name='Roboto', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHebrew-Bold.ttf', name='Noto Sans Hebrew', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-Italic.ttf', name='Noto Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/Vera.ttf', name='Bitstream Vera Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.9590909090909092\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdanaz.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond-InitialsF1.ttf', name='EB Garamond Initials Fill1', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-DemiOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisiaBoldIt.otf', name='GFS Didot', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak/Samyak-Devanagari.ttf', name='Samyak Devanagari', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/gentiumplus/GentiumPlusCompact-I.ttf', name='Gentium Plus Compact', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-HeavyItalic.ttf', name='Lato', style='italic', variant='normal', weight=800, stretch='normal', size='scalable')) = 11.43\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/asana-math/Asana-Math.otf', name='Asana Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-LightItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Thin.otf', name='Manjari', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa-BoldOblique.otf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTibetan-Bold.ttf', name='Noto Serif Tibetan', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobster/lobster.otf', name='Lobster Two', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Demi.otf', name='URW Gothic', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Medium.ttf', name='Rasa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-BoldCondItalic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsD-Regular.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist-Bold.otf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Bold.otf', name='Cantarell', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifThai-Bold.ttf', name='Noto Serif Thai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-bsmi00lp/bsmi00lp.ttf', name='AR PL Mingti2L Big5', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifLao-Bold.ttf', name='Noto Serif Lao', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo-BoldOblique.otf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Bold.otf', name='Manjari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsSm-Regular.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamil-Bold.ttf', name='Noto Serif Tamil', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansJavanese-Bold.ttf', name='Noto Sans Javanese', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTamilSupplement-Regular.ttf', name='Noto Sans Tamil Supplement', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipaexfont-mincho/ipaexm.ttf', name='IPAexMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDevanagari-Regular.ttf', name='Noto Serif Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RB.otf', name='Linux Libertine O', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-ExtraBold.ttf', name='Open Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTangut-Regular.ttf', name='Noto Serif Tangut', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Bold.ttf', name='Padauk', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeOneSym-Bold.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSinhala-Bold.ttf', name='Noto Sans Sinhala', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasB.ttf', name='Gentium Book Basic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Italic.ttf', name='Lato', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond12-Italic.otf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf', name='Droid Sans Fallback', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-Bold.ttf', name='Arimo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Light.ttf', name='Rasa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMyanmar-Regular.ttf', name='Noto Sans Myanmar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Bold.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnYetgul.ttf', name='UnYetgul', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/StandardSymbolsPS.otf', name='Standard Symbols PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-BlackItalic.ttf', name='Roboto', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Thin.ttf', name='Roboto', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Smallcaps-Italic.ttf', name='Go Smallcaps', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCham-Bold.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraIt.ttf', name='Bitstream Vera Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.9590909090909092\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/sinhala/lklug.ttf', name='LKLUG', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-Italic.ttf', name='Noto Sans Display', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Italic.otf', name='P052', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgiaz.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-bkai00mp/bkai00mp.ttf', name='AR PL KaitiM Big5', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebucbi.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Bold.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArmenian-Bold.ttf', name='Noto Sans Armenian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana_Bold_Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-Italic.otf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-Italic.otf', name='Lobster Two', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Italic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstFarsi.ttf', name='KacstFarsi', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnShinmun.ttf', name='UnShinmun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhmer-Bold.ttf', name='Noto Sans Khmer', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-Italic.ttf', name='Arimo', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/timesbd.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-BoldItalic.ttf', name='Caladea', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono-BoldOblique.otf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Cond.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Thin.otf', name='Cantarell', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-Italic.otf', name='Berenis ADF Pro', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Italic.otf', name='C059', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari.ttf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RZ.otf', name='Linux Libertine O', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Bold.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeFiveSym-Regular.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerif.ttf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansIndicSiyaqNumbers-Regular.ttf', name='Noto Sans Indic Siyaq Numbers', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSansBold.otf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-BoldOblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-SemiBold.otf', name='Cabin', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCanadianAboriginal-Regular.ttf', name='Noto Sans Canadian Aboriginal', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee-BoldOblique.otf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstOffice.ttf', name='KacstOffice', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/vemana2000.ttf', name='Vemana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-Bold.ttf', name='Amiri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFProMath-Regular.otf', name='Berenis ADF Pro Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono.otf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamilSlanted-Regular.ttf', name='Noto Serif Tamil Slanted', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTibetan-Regular.ttf', name='Noto Sans Tibetan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/kalimati.ttf', name='Kalimati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-BoldOblique.ttf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHebrew-Regular.ttf', name='Noto Sans Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldSogdian-Regular.ttf', name='Noto Sans Old Sogdian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-SemiboldItalic.ttf', name='Lato', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifSinhala-Regular.ttf', name='Noto Serif Sinhala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Heavy.ttf', name='Lato', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifHebrew-Regular.ttf', name='Noto Serif Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/gulim.ttf', name='Baekmuk Gulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode-Bold.ttf', name='Junicode', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/font-awesome/fontawesome-webfont.ttf', name='FontAwesome', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda-BoldOblique.otf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee-Oblique.otf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-Bold.ttf', name='Cousine', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Regular.otf', name='Gayathri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasBI.ttf', name='Gentium Book Basic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf', name='Ubuntu', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-BoldItalic.otf', name='Lobster Two', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-BoldOblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-Regular.otf', name='Lobster Two', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_RI.otf', name='Linux Biolinum O', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTamil-Regular.ttf', name='Noto Sans Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMalayalam-Bold.ttf', name='Noto Sans Malayalam', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnGraphic.ttf', name='UnGraphic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArmenian-Regular.ttf', name='Noto Sans Armenian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Bold.otf', name='Gillius ADF', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKhmer-Regular.ttf', name='Noto Serif Khmer', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-punjabi/Lohit-Gurmukhi.ttf', name='Lohit Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree.ttf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gargi/Gargi.ttf', name='Gargi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/LikhanNormal.ttf', name='Likhan', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode.ttf', name='Junicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond12-AllSC.ttf', name='EB Garamond 12 All SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-Regular.ttf', name='Arimo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-Italic.ttf', name='Noto Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-L.ttf', name='Ubuntu', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdanai.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Comic_Sans_MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-CondLight.ttf', name='Open Sans', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Italic.ttf', name='Roboto', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 0.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo-Bold.otf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraBI.ttf', name='Bitstream Vera Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.244090909090909\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-BoldItalic.otf', name='Accanthis ADF Std No3', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Bold.otf', name='C059', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsSm-Bold.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/msam10.ttf', name='msam10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebuc.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil/Lohit-Tamil.ttf', name='Lohit Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDinaru.ttf', name='UnDinaru', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda.ttf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitle.ttf', name='KacstTitle', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDecorative.ttf', name='KacstDecorative', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Bold.otf', name='Gayathri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/samanata.ttf', name='Samanata', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-Italic.ttf', name='Noto Serif Display', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Bold.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-japanese-mincho.ttf', name='IPAexMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTibetan-Bold.ttf', name='Noto Sans Tibetan', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUp-Bold.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoSora.ttf', name='UnJamoSora', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/AmiriQuran.ttf', name='Amiri Quran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Medium.ttf', name='Lato', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGujarati-Bold.ttf', name='Noto Sans Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-Bold.otf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMyanmar-Bold.ttf', name='Noto Sans Myanmar', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Black.ttf', name='Arial Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS_Bold_Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/solomos/GFSSolomos.otf', name='GFS Solomos', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThai-Regular.ttf', name='Noto Sans Thai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-BoldItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-ExtraBoldItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=800, stretch='normal', size='scalable')) = 11.43\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpD-Regular.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamil-Regular.ttf', name='Noto Serif Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTelugu-Bold.ttf', name='Noto Sans Telugu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-BoldOblique.ttf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_RB.otf', name='Linux Biolinum O', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gubbi/Gubbi.ttf', name='Gubbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAnatolianHieroglyphs-Regular.ttf', name='Noto Sans Anatolian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMoBI.ttf', name='Bitstream Vera Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Oblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDevanagari-Bold.ttf', name='Noto Serif Devanagari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Italic.ttf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Bold.ttf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Light.ttf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstScreen.ttf', name='KacstScreen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Bold.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMyanmar-Regular.ttf', name='Noto Serif Myanmar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDogra-Regular.ttf', name='Noto Serif Dogra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/ariblk.ttf', name='Arial Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGeorgian-Bold.ttf', name='Noto Sans Georgian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-RI.ttf', name='Ubuntu', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansEthiopic-Bold.ttf', name='Noto Sans Ethiopic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Uroob-Regular.ttf', name='Uroob', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpSm-Regular.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Bold.1.1.ttf', name='padmaa-Bold.1.1', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/theokritos/GFSTheokritos.otf', name='GFS Theokritos', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-Th.ttf', name='Ubuntu', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebucit.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-Bold.otf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Medium-0.5.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond12-Regular.ttf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/cour.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArabic-Bold.ttf', name='Noto Sans Arabic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Smallcaps.ttf', name='Go Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisia.otf', name='GFS Artemisia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Medium.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman-Italic.otf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/RaghuMalayalamSans-Regular.ttf', name='RaghuMalayalamSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Regular.ttf', name='Lato', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/courbd.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGujarati-Regular.ttf', name='Noto Serif Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Roman.otf', name='C059', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentiumplus/GentiumPlus-I.ttf', name='Gentium Plus', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne-Bold.ttf', name='KacstOne', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Gujarati.ttf', name='Samyak Gujarati', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Nakula/nakula.ttf', name='Nakula', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramondSC12-Regular.ttf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Oblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-mincho/ipam.ttf', name='IPAMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa.otf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Malayalam.ttf', name='Samyak Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-bengali/Lohit-Bengali.ttf', name='Lohit Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Italic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/comfortaa/Comfortaa-Regular.ttf', name='Comfortaa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia_Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Cond.otf', name='Gillius ADF', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/andalemo.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Italic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Oblique.ttf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnBatang.ttf', name='UnBatang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RBI.otf', name='Linux Libertine O', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-Bold.otf', name='Lobster Two', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOS.ttf', name='Khmer OS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Bold.ttf', name='Roboto', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Italic.ttf', name='Open Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKannada-Bold.ttf', name='Noto Sans Kannada', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono-Oblique.otf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGrantha-Regular.ttf', name='Noto Sans Grantha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Bold.ttf', name='Go', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThai-Bold.ttf', name='Noto Sans Thai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Regular.otf', name='Cantarell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-Bold.ttf', name='Tinos', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasI.ttf', name='Gentium Book Basic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist-BoldOblique.otf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond12-Regular.otf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree-BoldOblique.otf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDotum.ttf', name='UnDotum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-Bold.ttf', name='Caladea', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree-Bold.otf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf', name='IPAPGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansJavanese-Regular.ttf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-ExtraLight.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 0.24\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Regular.ttf', name='Go', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-devanagari/Lohit-Devanagari.ttf', name='Lohit Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-BoldItalic.otf', name='Berenis ADF Pro', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-Oblique.otf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/JamrulNormal.ttf', name='Jamrul', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-15 09:34:28 matplotlib.font_manager DEBUG    findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"selection/optimized_backup_heads\",\n",
    "#     mt.name.split(\"/\")[-1],\n",
    "#     f\"{select_task.task_name}.npz\"\n",
    "# )\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/optimized_heads\",\n",
    "    model_key.split(\"/\")[-1],\n",
    "    \"distinct_options\",\n",
    "    # f\"{select_task.task_name}\",\n",
    "    \"select_one\",\n",
    "    # \"legacy\",\n",
    "    \"epoch_10.npz\"\n",
    ")\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"test_opt_code\",\n",
    "#     model_key.split(\"/\")[-1],\n",
    "#     \"distinct_options\",\n",
    "#     f\"{select_task.task_name}\",\n",
    "#     # \"select_one\",\n",
    "#     \"legacy\",\n",
    "#     \"epoch_10.npz\"\n",
    "# )\n",
    "\n",
    "optimization_results = np.load(optimized_path, allow_pickle=True)\n",
    "plt.plot(optimization_results[\"losses\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f87810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(torch.float32)\n",
    "optimal_head_mask[52:, :] = 0.0\n",
    "\n",
    "plt.imshow(\n",
    "    optimal_head_mask.T.numpy(),\n",
    "    cmap=\"Blues\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "optimized_heads = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).tolist()\n",
    "optimized_heads = [\n",
    "    (layer_idx, head_idx) for layer_idx, head_idx in optimized_heads\n",
    "]\n",
    "print(len(optimized_heads))\n",
    "\n",
    "HEADS = optimized_heads\n",
    "\n",
    "(35, 19) in HEADS, (35, 19) in optimized_heads\n",
    "# [(29, 3) in HEADS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a7ef0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.tokens import find_token_range, prepare_input\n",
    "\n",
    "# string = sample.prompt()\n",
    "# substring = sample.obj\n",
    "\n",
    "# tokenized_prompt = prepare_input(\n",
    "#     prompts=string, \n",
    "#     tokenizer=mt.tokenizer, \n",
    "#     return_offsets_mapping=True,\n",
    "#     add_bos_token=\"qwen\" in mt.name.lower()\n",
    "# )\n",
    "# string = mt.tokenizer.decode(tokenized_prompt.input_ids[0], skip_special_tokens=False)\n",
    "# offset_mapping = tokenized_prompt.pop(\"offset_mapping\")[0]\n",
    "\n",
    "# ans_range = find_token_range(\n",
    "#     string=string,\n",
    "#     substring=substring,\n",
    "#     offset_mapping=offset_mapping\n",
    "# )\n",
    "# print(f\"Answer range: {ans_range}\")\n",
    "# print(f'\"{mt.tokenizer.decode(tokenized_prompt.input_ids[0][range(*ans_range)])}\"')\n",
    "# # for idx, (tok, offset_range) in enumerate(zip(tokenized_prompt.input_ids[0], offset_mapping)):\n",
    "# #     print(f\"Token {idx}: \\\"{mt.tokenizer.decode([tok])}\\\" -- {offset_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a9a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:32 src.selection.functional DEBUG    Predictions: ['\" Van\"[13000] (p=0.436, logit=18.875)', '\" Plum\"[84409] (p=0.142, logit=17.750)', '\" The\"[578] (p=0.125, logit=17.625)', '\" VAN\"[97753] (p=0.097, logit=17.375)', '\" Cherry\"[45805] (p=0.076, logit=17.125)']\n",
      "2025-09-15 09:34:32 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-12f86452-0a1d\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-12f86452-0a1d\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Pine\", \"apple\", \",\", \" Baseball\", \",\", \" Air\", \" fry\", \"er\", \",\", \" Peach\", \",\", \" Plum\", \",\", \" Ring\", \",\", \" Cherry\", \",\", \" Head\", \"phones\", \",\", \" Van\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" fruit\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.01531765703111887, 0.0015559177845716476, 0.003080743597820401, 0.0052573964931070805, 0.002825685776770115, 0.0032115932554006577, 0.005483138374984264, 0.0016649037133902311, 0.0018821991980075836, 0.003543953411281109, 0.005288760643452406, 0.03114961087703705, 0.020855987444519997, 0.05783119797706604, 0.014583442360162735, 0.004625709727406502, 0.010135200805962086, 0.05304070934653282, 0.030561592429876328, 0.006377238314598799, 0.01360742375254631, 0.010815060697495937, 0.020230969414114952, 0.05089086294174194, 0.0030422662384808064, 0.003626640886068344, 0.003971504047513008, 0.023824064061045647, 0.08191729336977005, 0.02060602977871895, 0.004453361965715885, 0.013270314782857895, 0.006936350837349892, 0.02387343719601631, 0.00920883473008871, 0.07676040381193161]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa749408c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.attention import get_attention_matrices\n",
    "from src.selection.functional import (\n",
    "    verify_head_patterns,\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    ")\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=sample.prompt(option_style=\"single_line\"),\n",
    "    options=sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129fe333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from src.selection.utils import KeyedSet, get_first_token_id, verify_correct_option\n",
    "from src.selection.data import SelectionSample\n",
    "from src.functional import predict_next_token\n",
    "from src.tokens import prepare_input\n",
    "\n",
    "######################################################################\n",
    "N_DISTRACTORS = 5\n",
    "######################################################################\n",
    "\n",
    "from src.selection.data import get_counterfactual_samples_within_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425f6285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:35 src.selection.data DEBUG    Options: Kiwi, Helicopter, Yoga mat, Airplane, Banana.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:35 src.selection.data DEBUG    Options: Boat, Watermelon, Blueberry, Bus, Helmet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 09:34:35 src.selection.data DEBUG    Options: Boat, Watermelon, Blueberry, Bus, Helmet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "====================\n",
      "Options: Kiwi, Helicopter, Yoga mat, Airplane, Banana.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >> \" Banana\"\n",
      "Options: Boat, Watermelon, Blueberry, Bus, Helmet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >> \" Bus\"\n",
      "Blueberry 4  Blue\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_task.task_name]\n",
    "\n",
    "# patch_prompt_template_idx = 3\n",
    "# clean_prompt_template_idx = 3\n",
    "\n",
    "\n",
    "patch_sample, clean_sample = counterfactual_sampler(\n",
    "    # patch_category=\"politician\",\n",
    "    # clean_category=\"actor\",\n",
    "    mt=mt,\n",
    "    task=select_task,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    filter_by_lm_prediction=True,\n",
    "    option_style=OPTION_STYLE,\n",
    "\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    # distinct_options=True,\n",
    "    # patch_n_distractors=5,\n",
    "    # clean_n_distractors=5,\n",
    "    # patch_prompt_template_idx=patch_prompt_template_idx,\n",
    "    # clean_prompt_template_idx=clean_prompt_template_idx,\n",
    "    # patch_option_style=\"single_line\",\n",
    "    # clean_option_style=\"numbered\",\n",
    "    # n_options=5,\n",
    "    # patch_yes_mode=False\n",
    ")\n",
    "print('=' * 20)\n",
    "print(patch_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([patch_sample.ans_token_id])}\"')\n",
    "print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "print(\n",
    "    clean_sample.metadata[\"track_type_obj\"], \n",
    "    clean_sample.metadata[\"track_type_obj_idx\"], \n",
    "    mt.tokenizer.decode(clean_sample.metadata[\"track_type_obj_token_id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d35a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order_sample_1 = SelectionSample(\n",
    "#     subj=\"random\",\n",
    "#     category=\"test_order\",\n",
    "#     options=[\"Bike\", \"Apple\", \"Bed\", \"Dog\", \"Monitor\", \"Theater\"],\n",
    "#     obj=\"Apple\",\n",
    "#     obj_idx=1,\n",
    "#     prompt_template=\"<_options_>\\nWhat is the third item in the list?\\nAnswer:\",\n",
    "#     answer=\"Apple\",\n",
    "# )\n",
    "\n",
    "# order_sample_2 = SelectionSample(\n",
    "#     subj=\"random\",\n",
    "#     category=\"test_order\",\n",
    "#     options=[\"Cat\", \"Chair\", \"Bus\", \"Phone\", \"Library\", \"Orange\"],\n",
    "#     obj=\"Phone\",\n",
    "#     obj_idx=3,\n",
    "#     prompt_template=\"<_options_>\\nWhat is the fifth item in the list?\\nAnswer:\",\n",
    "#     answer=\"Phone\",\n",
    "# )\n",
    "len(HEADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "510772fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Kiwi, Helicopter, Yoga mat, Airplane, Banana.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >> \" Banana\"\n",
      "2025-09-15 09:34:37 src.selection.functional DEBUG    Predictions: ['\" Banana\"[76924] (p=0.762, logit=20.875)', '\" The\"[578] (p=0.103, logit=18.875)', '\" Ki\"[30558] (p=0.062, logit=18.375)', '\" B\"[426] (p=0.018, logit=17.125)', '\" There\"[2684] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:34:37 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-ee017d9f-c509\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-ee017d9f-c509\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Ki\", \"wi\", \",\", \" Hel\", \"icopter\", \",\", \" Yoga\", \" mat\", \",\", \" Air\", \"plane\", \",\", \" Banana\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" fruit\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.019016508013010025, 0.0028521018102765083, 0.003832412650808692, 0.029843095690011978, 0.01705092377960682, 0.006825712509453297, 0.0020425189286470413, 0.009256278164684772, 0.0038322911132127047, 0.007037244271486998, 0.00995215866714716, 0.0046890354715287685, 0.008272552862763405, 0.0106120053678751, 0.1559896320104599, 0.020227747038006783, 0.004916251637041569, 0.003533031325787306, 0.0051947846077382565, 0.013160282745957375, 0.08256511390209198, 0.024263648316264153, 0.004979489836841822, 0.018264083191752434, 0.010427058674395084, 0.045055292546749115, 0.0141525873914361, 0.0680079385638237]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa7492d24d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Boat, Watermelon, Blueberry, Bus, Helmet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >> \" Bus\"\n",
      "2025-09-15 09:34:38 src.selection.functional DEBUG    Predictions: ['\" Bus\"[19111] (p=0.691, logit=21.000)', '\" The\"[578] (p=0.154, logit=19.500)', '\" Boat\"[45332] (p=0.057, logit=18.500)', '\" A\"[362] (p=0.034, logit=18.000)', '\" BUS\"[23504] (p=0.016, logit=17.250)']\n",
      "2025-09-15 09:34:38 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6f525a06-7c32\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6f525a06-7c32\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Boat\", \",\", \" Water\", \"melon\", \",\", \" Blue\", \"berry\", \",\", \" Bus\", \",\", \" Helmet\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" vehicle\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.023729542270302773, 0.00348280044272542, 0.015045443549752235, 0.018625911325216293, 0.0036334930919110775, 0.006455118302255869, 0.012643886730074883, 0.004451069515198469, 0.007036290597170591, 0.006366512272506952, 0.13735970854759216, 0.03777161240577698, 0.032916683703660965, 0.012828826904296875, 0.0032431944273412228, 0.002730511361733079, 0.006463726982474327, 0.01327770296484232, 0.09646012634038925, 0.02232266589999199, 0.00346582755446434, 0.019433358684182167, 0.008505935780704021, 0.03585679084062576, 0.01326312031596899, 0.06285500526428223]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa74932dc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Boat, Watermelon, Blueberry, Bus, Helmet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >> \" Blue\"\n",
      "2025-09-15 09:34:38 src.selection.functional DEBUG    Predictions: ['\" Blue\"[8868] (p=0.820, logit=20.875)', '\" The\"[578] (p=0.098, logit=18.750)', '\" BLUE\"[56992] (p=0.028, logit=17.500)', '\" Water\"[10164] (p=0.008, logit=16.250)', '\" There\"[2684] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:34:38 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c4c3f2fb-e366\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c4c3f2fb-e366\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Boat\", \",\", \" Water\", \"melon\", \",\", \" Blue\", \"berry\", \",\", \" Bus\", \",\", \" Helmet\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" fruit\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.01956787519156933, 0.0026680699083954096, 0.001408255542628467, 0.004001780413091183, 0.0019428578671067953, 0.022959552705287933, 0.014570404775440693, 0.011298674158751965, 0.10073360055685043, 0.04517659172415733, 0.006006550043821335, 0.013764490373432636, 0.006649214308708906, 0.014143931679427624, 0.004083799198269844, 0.0033994445111602545, 0.006320470478385687, 0.014159510843455791, 0.09517833590507507, 0.028401385992765427, 0.00453018257394433, 0.015549574978649616, 0.010504106990993023, 0.044910915195941925, 0.01468592043966055, 0.07296618074178696]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fc81019d650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch\n",
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "# patch_sample.options[patch_sample.obj_idx] = \"Screw\"\n",
    "# patch_sample.options[patch_sample.obj_idx] = patch_sample.obj\n",
    "\n",
    "gold_sample = copy.deepcopy(patch_sample)\n",
    "gold_sample.options = clean_sample.options\n",
    "gold_sample.ans_token_id = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "for sample in [patch_sample, clean_sample, gold_sample]:\n",
    "# for sample in [order_sample_1, order_sample_2]:\n",
    "    print(sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')\n",
    "    attn_pattern = verify_head_patterns(\n",
    "        prompt=sample.prompt(),\n",
    "        options=sample.options,\n",
    "        mt=mt,\n",
    "        # heads=qwen_72_heads,\n",
    "        heads=optimized_heads,\n",
    "        # heads=[(layer_idx, head_idx)],\n",
    "        # generate_full_answer=True,\n",
    "        query_index=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b4d487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'track_category': 'fruit',\n",
       "  'track_type_obj': 'Blueberry',\n",
       "  'track_type_obj_idx': 4,\n",
       "  'track_type_obj_token_id': 8868,\n",
       "  'tokenized': {'input_ids': tensor([[128000,   3883,     25,  45332,     11,  10164,  72218,     11,   8868,\n",
       "             15717,     11,  19111,     11,  67629,    627,   3923,    374,    279,\n",
       "              1566,   7458,    304,    420,   1160,   3485,   5380,  16533,     25]],\n",
       "          device='cuda:0'),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1]], device='cuda:0')},\n",
       "  'predictions': [PredictedToken(token=' Bus', prob=0.69140625, logit=21.0, token_id=19111, metadata=None),\n",
       "   PredictedToken(token=' The', prob=0.154296875, logit=19.5, token_id=578, metadata=None),\n",
       "   PredictedToken(token=' Boat', prob=0.056884765625, logit=18.5, token_id=45332, metadata=None),\n",
       "   PredictedToken(token=' A', prob=0.034423828125, logit=18.0, token_id=362, metadata=None),\n",
       "   PredictedToken(token=' BUS', prob=0.0162353515625, logit=17.25, token_id=23504, metadata=None)]},\n",
       " {'tokenized': {'input_ids': tensor([[128000,   3883,     25,  30558,  17043,     11,  16183,  88323,     11,\n",
       "             38673,   5634,     11,   6690,  19563,     11,  76924,    627,   3923,\n",
       "               374,    279,   1566,  14098,    304,    420,   1160,   3485,   5380,\n",
       "             16533,     25]], device='cuda:0'),\n",
       "   'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "            1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  'predictions': [PredictedToken(token=' Banana', prob=0.76171875, logit=20.875, token_id=76924, metadata=None),\n",
       "   PredictedToken(token=' The', prob=0.10302734375, logit=18.875, token_id=578, metadata=None),\n",
       "   PredictedToken(token=' Ki', prob=0.0625, logit=18.375, token_id=30558, metadata=None),\n",
       "   PredictedToken(token=' B', prob=0.0179443359375, logit=17.125, token_id=426, metadata=None),\n",
       "   PredictedToken(token=' There', prob=0.007476806640625, logit=16.25, token_id=2684, metadata=None)]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sample.metadata, patch_sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a35a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.functional import cache_q_projections\n",
    "from src.functional import interpret_logits\n",
    "from src.tokens import prepare_input, find_token_range\n",
    "\n",
    "prompts = [\n",
    "    patch_sample.prompt(),\n",
    "    clean_sample.prompt(),\n",
    "]\n",
    "\n",
    "tokenized = prepare_input(\n",
    "    prompts=prompts,\n",
    "    tokenizer=mt.tokenizer,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "question_ranges = [\n",
    "    find_token_range(\n",
    "        string=prompt,\n",
    "        substring=\"?\",\n",
    "        occurrence=-1,\n",
    "        offset_mapping=offset,\n",
    "    )\n",
    "    for prompt, offset in zip(prompts, offset_mapping)\n",
    "]\n",
    "ques_pos = [rng[1]-1 for rng in question_ranges]\n",
    "for tok, q_pos in zip(tokenized.input_ids, ques_pos):\n",
    "    assert mt.tokenizer.decode(tok[q_pos]).strip() == \"?\"\n",
    "\n",
    "q_projections, out = cache_q_projections(\n",
    "    mt=mt,\n",
    "    input=tokenized,\n",
    "    heads=HEADS,\n",
    "    token_indices=[ [q_pos, -2, -1] for q_pos in ques_pos],\n",
    "    return_output=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f6188d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,   3883,     25,  30558,  17043,     11,  16183,  88323,     11,\n",
       "          38673,   5634,     11,   6690,  19563,     11,  76924,    627,   3923,\n",
       "            374,    279,   1566,  14098,    304,    420,   1160,   3485,   5380,\n",
       "          16533,     25],\n",
       "        [128009, 128009, 128000,   3883,     25,  45332,     11,  10164,  72218,\n",
       "             11,   8868,  15717,     11,  19111,     11,  67629,    627,   3923,\n",
       "            374,    279,   1566,   7458,    304,    420,   1160,   3485,   5380,\n",
       "          16533,     25]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "209511b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Banana', prob=0.75390625, logit=20.875, token_id=76924, metadata=None),\n",
       " PredictedToken(token=' The', prob=0.115234375, logit=19.0, token_id=578, metadata=None),\n",
       " PredictedToken(token=' Ki', prob=0.061767578125, logit=18.375, token_id=30558, metadata=None),\n",
       " PredictedToken(token=' B', prob=0.0177001953125, logit=17.125, token_id=426, metadata=None),\n",
       " PredictedToken(token=' There', prob=0.00738525390625, logit=16.25, token_id=2684, metadata=None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_logits = out.logits[0, -1, :]\n",
    "interpret_logits(\n",
    "    logits=patch_logits,\n",
    "    tokenizer=mt.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42df8aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Bus', prob=0.67578125, logit=21.0, token_id=19111, metadata=None),\n",
       " PredictedToken(token=' The', prob=0.1708984375, logit=19.625, token_id=578, metadata=None),\n",
       " PredictedToken(token=' Boat', prob=0.0556640625, logit=18.5, token_id=45332, metadata=None),\n",
       " PredictedToken(token=' A', prob=0.03369140625, logit=18.0, token_id=362, metadata=None),\n",
       " PredictedToken(token=' BUS', prob=0.015869140625, logit=17.25, token_id=23504, metadata=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_logits = out.logits[1, -1, :]\n",
    "interpret_logits(\n",
    "    logits=patch_logits,\n",
    "    tokenizer=mt.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91becd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(28, 40, 26), (28, 40, -2), (28, 40, -1), (28, 45, 26), (28, 45, -2), (28, 45, -1), (29, 56, 26), (29, 56, -2), (29, 56, -1), (29, 57, 26), (29, 57, -2), (29, 57, -1), (29, 60, 26), (29, 60, -2), (29, 60, -1), (29, 61, 26), (29, 61, -2), (29, 61, -1), (29, 62, 26), (29, 62, -2), (29, 62, -1), (30, 62, 26), (30, 62, -2), (30, 62, -1), (31, 0, 26), (31, 0, -2), (31, 0, -1), (31, 32, 26), (31, 32, -2), (31, 32, -1), (31, 33, 26), (31, 33, -2), (31, 33, -1), (31, 36, 26), (31, 36, -2), (31, 36, -1), (31, 37, 26), (31, 37, -2), (31, 37, -1), (31, 38, 26), (31, 38, -2), (31, 38, -1), (31, 39, 26), (31, 39, -2), (31, 39, -1), (31, 40, 26), (31, 40, -2), (31, 40, -1), (31, 43, 26), (31, 43, -2), (31, 43, -1), (32, 12, 26), (32, 12, -2), (32, 12, -1), (32, 19, 26), (32, 19, -2), (32, 19, -1), (32, 48, 26), (32, 48, -2), (32, 48, -1), (33, 18, 26), (33, 18, -2), (33, 18, -1), (33, 21, 26), (33, 21, -2), (33, 21, -1), (33, 23, 26), (33, 23, -2), (33, 23, -1), (33, 30, 26), (33, 30, -2), (33, 30, -1), (33, 43, 26), (33, 43, -2), (33, 43, -1), (33, 46, 26), (33, 46, -2), (33, 46, -1), (34, 1, 26), (34, 1, -2), (34, 1, -1), (34, 6, 26), (34, 6, -2), (34, 6, -1), (34, 33, 26), (34, 33, -2), (34, 33, -1), (34, 45, 26), (34, 45, -2), (34, 45, -1), (35, 5, 26), (35, 5, -2), (35, 5, -1), (35, 17, 26), (35, 17, -2), (35, 17, -1), (35, 18, 26), (35, 18, -2), (35, 18, -1), (35, 19, 26), (35, 19, -2), (35, 19, -1), (35, 20, 26), (35, 20, -2), (35, 20, -1), (35, 22, 26), (35, 22, -2), (35, 22, -1), (35, 23, 26), (35, 23, -2), (35, 23, -1), (35, 27, 26), (35, 27, -2), (35, 27, -1), (35, 28, 26), (35, 28, -2), (35, 28, -1), (35, 36, 26), (35, 36, -2), (35, 36, -1), (35, 40, 26), (35, 40, -2), (35, 40, -1), (35, 42, 26), (35, 42, -2), (35, 42, -1), (36, 17, 26), (36, 17, -2), (36, 17, -1), (36, 22, 26), (36, 22, -2), (36, 22, -1), (36, 40, 26), (36, 40, -2), (36, 40, -1), (36, 44, 26), (36, 44, -2), (36, 44, -1), (36, 47, 26), (36, 47, -2), (36, 47, -1), (36, 52, 26), (36, 52, -2), (36, 52, -1), (36, 54, 26), (36, 54, -2), (36, 54, -1), (37, 0, 26), (37, 0, -2), (37, 0, -1), (37, 3, 26), (37, 3, -2), (37, 3, -1), (37, 4, 26), (37, 4, -2), (37, 4, -1), (37, 7, 26), (37, 7, -2), (37, 7, -1), (37, 16, 26), (37, 16, -2), (37, 16, -1), (37, 28, 26), (37, 28, -2), (37, 28, -1), (37, 30, 26), (37, 30, -2), (37, 30, -1), (37, 36, 26), (37, 36, -2), (37, 36, -1), (37, 39, 26), (37, 39, -2), (37, 39, -1), (38, 19, 26), (38, 19, -2), (38, 19, -1), (38, 23, 26), (38, 23, -2), (38, 23, -1), (38, 49, 26), (38, 49, -2), (38, 49, -1), (38, 50, 26), (38, 50, -2), (38, 50, -1), (38, 51, 26), (38, 51, -2), (38, 51, -1), (39, 35, 26), (39, 35, -2), (39, 35, -1), (39, 36, 26), (39, 36, -2), (39, 36, -1), (39, 41, 26), (39, 41, -2), (39, 41, -1), (39, 44, 26), (39, 44, -2), (39, 44, -1), (39, 45, 26), (39, 45, -2), (39, 45, -1), (42, 28, 26), (42, 28, -2), (42, 28, -1), (42, 30, 26), (42, 30, -2), (42, 30, -1), (42, 31, 26), (42, 31, -2), (42, 31, -1), (45, 1, 26), (45, 1, -2), (45, 1, -1), (47, 17, 26), (47, 17, -2), (47, 17, -1), (47, 18, 26), (47, 18, -2), (47, 18, -1), (49, 1, 26), (49, 1, -2), (49, 1, -1), (49, 4, 26), (49, 4, -2), (49, 4, -1), (49, 5, 26), (49, 5, -2), (49, 5, -1), (49, 7, 26), (49, 7, -2), (49, 7, -1), (50, 34, 26), (50, 34, -2), (50, 34, -1)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_projections[1].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9962f8c",
   "metadata": {},
   "source": [
    "## Testing patching the query projection of a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aed90f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:44 src.selection.functional DEBUG    Predictions: ['\" Banana\"[76924] (p=0.762, logit=20.875)', '\" The\"[578] (p=0.103, logit=18.875)', '\" Ki\"[30558] (p=0.062, logit=18.375)', '\" B\"[426] (p=0.018, logit=17.125)', '\" There\"[2684] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:34:44 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-d2dc1e3f-ae55\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-d2dc1e3f-ae55\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Ki\", \"wi\", \",\", \" Hel\", \"icopter\", \",\", \" Yoga\", \" mat\", \",\", \" Air\", \"plane\", \",\", \" Banana\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" fruit\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.019016508013010025, 0.0028521018102765083, 0.003832412650808692, 0.029843095690011978, 0.01705092377960682, 0.006825712509453297, 0.0020425189286470413, 0.009256278164684772, 0.0038322911132127047, 0.007037244271486998, 0.00995215866714716, 0.0046890354715287685, 0.008272552862763405, 0.0106120053678751, 0.1559896320104599, 0.020227747038006783, 0.004916251637041569, 0.003533031325787306, 0.0051947846077382565, 0.013160282745957375, 0.08256511390209198, 0.024263648316264153, 0.004979489836841822, 0.018264083191752434, 0.010427058674395084, 0.045055292546749115, 0.0141525873914361, 0.0680079385638237]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa7491d4310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:34:45 src.selection.functional DEBUG    Predictions: ['\" Water\"[10164] (p=0.699, logit=20.750)', '\" Blue\"[8868] (p=0.177, logit=19.375)', '\" The\"[578] (p=0.035, logit=17.750)', '\" Boat\"[45332] (p=0.024, logit=17.375)', '\" A\"[362] (p=0.008, logit=16.250)']\n",
      "2025-09-15 09:34:45 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-1acc9779-415d\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-1acc9779-415d\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Boat\", \",\", \" Water\", \"melon\", \",\", \" Blue\", \"berry\", \",\", \" Bus\", \",\", \" Helmet\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" vehicle\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.026384280994534492, 0.0037983821239322424, 0.0025456645525991917, 0.008250465616583824, 0.00280568259768188, 0.06005135178565979, 0.029536282643675804, 0.00921295303851366, 0.08114711195230484, 0.03700393810868263, 0.009157070890069008, 0.01426754705607891, 0.006284660194069147, 0.019993746653199196, 0.006154024042189121, 0.004378222394734621, 0.009256676770746708, 0.016774781048297882, 0.025126909837126732, 0.010484343394637108, 0.0038176518864929676, 0.012463662773370743, 0.0106400391086936, 0.0251319520175457, 0.018725654110312462, 0.03335466980934143]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa749125690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from src.selection.functional import cache_q_projections\n",
    "from src.functional import patch_with_baukit, PatchSpec, repeat_kv, get_module_nnsight\n",
    "from src.utils.typing import TokenizerOutput, Tokenizer\n",
    "from src.selection.functional import cache_q_projections, verify_head_patterns\n",
    "\n",
    "def find_quesmark_pos(\n",
    "    prompt: str, \n",
    "    tokenizer: Tokenizer,\n",
    "    tokenized: TokenizerOutput,\n",
    "    offset_mapping: list[tuple[int, int]] | None = None,\n",
    "    ques_mark: str = \"?\",\n",
    "):\n",
    "    if offset_mapping is None:\n",
    "        if tokenized is None or \"offset_mapping\" not in tokenized:\n",
    "            tokenized = prepare_input(\n",
    "                prompts=[prompt], \n",
    "                tokenizer=tokenizer, \n",
    "                return_offsets_mapping=True,\n",
    "            )\n",
    "        offset_mapping = tokenized.pop(\"offset_mapping\")[0]\n",
    "    \n",
    "    ques_range = find_token_range(\n",
    "        string=prompt,\n",
    "        substring=ques_mark,\n",
    "        occurrence=-1,\n",
    "        offset_mapping=offset_mapping\n",
    "    )\n",
    "    ques_pos = ques_range[1]-1\n",
    "    assert tokenizer.decode(tokenized.input_ids[0][ques_pos]).strip() == ques_mark\n",
    "    return ques_pos\n",
    "\n",
    "mt.set_attn_implementation(\"eager\")\n",
    "mt.reset_forward()\n",
    "\n",
    "# test_heads = [(35, 19)]\n",
    "test_heads = copy.deepcopy(optimized_heads)\n",
    "\n",
    "patch_tokenized = prepare_input(\n",
    "    prompts=patch_sample.prompt(), \n",
    "    tokenizer=mt,\n",
    "    return_offsets_mapping=True\n",
    ")\n",
    "patch_offsets = patch_tokenized.pop(\"offset_mapping\")[0]\n",
    "patch_ques_pos = find_quesmark_pos(\n",
    "    prompt=patch_sample.prompt(),\n",
    "    tokenizer=mt.tokenizer,\n",
    "    tokenized=patch_tokenized,\n",
    "    offset_mapping=patch_offsets\n",
    ")\n",
    "\n",
    "clean_tokenized = prepare_input(\n",
    "    prompts=clean_sample.prompt(), \n",
    "    tokenizer=mt,\n",
    "    return_offsets_mapping=True\n",
    ")\n",
    "clean_offsets = clean_tokenized.pop(\"offset_mapping\")[0]\n",
    "clean_ques_pos = find_quesmark_pos(\n",
    "    prompt=clean_sample.prompt(),\n",
    "    tokenizer=mt.tokenizer,\n",
    "    tokenized=clean_tokenized,\n",
    "    offset_mapping=clean_offsets\n",
    ")\n",
    "\n",
    "# indices = [patch_ques_pos, -2, -1]\n",
    "indices = [-3, -2, -1]\n",
    "\n",
    "q_states = cache_q_projections(\n",
    "    mt=mt,\n",
    "    input=patch_tokenized,\n",
    "    heads=test_heads,\n",
    "    token_indices=[indices],\n",
    ")[0]\n",
    "\n",
    "# map_indices = {patch_ques_pos: clean_ques_pos, -2: -2, -1: -1}\n",
    "map_indices = {-3: -3, -2: -2, -1: -1}\n",
    "q_patches = []\n",
    "for (l_idx, h_idx, patch_token_idx), q_proj in q_states.items():\n",
    "    q_patches.append(PatchSpec(\n",
    "        location=(\n",
    "            mt.attn_module_name_format.format(l_idx)+\".q_proj\",\n",
    "            h_idx,\n",
    "            map_indices[patch_token_idx]\n",
    "        ),\n",
    "        patch=q_proj.squeeze()\n",
    "    ))\n",
    "\n",
    "# The attention patterns for the patch sample should match exactly\n",
    "test_inplace_swap = verify_head_patterns(\n",
    "    prompt=patch_sample.prompt(),\n",
    "    mt=mt,\n",
    "    heads=test_heads,\n",
    "    # heads=qwen_72_heads,\n",
    "    tokenized_prompt=patch_tokenized,\n",
    "    query_patches=q_patches\n",
    ")\n",
    "\n",
    "test_predicate_swap = verify_head_patterns(\n",
    "    prompt=clean_sample.prompt(),\n",
    "    mt=mt,\n",
    "    heads=test_heads,\n",
    "    # heads=qwen_72_heads,\n",
    "    tokenized_prompt=clean_tokenized,\n",
    "    query_patches=q_patches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f9286b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, '?\\n'), (24, '?\\n'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    (patch_ques_pos, mt.tokenizer.decode(patch_tokenized.input_ids[0][patch_ques_pos])),\n",
    "    (clean_ques_pos, mt.tokenizer.decode(clean_tokenized.input_ids[0][clean_ques_pos]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5263a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 29]), torch.Size([1, 28]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokenized.input_ids.shape, patch_tokenized.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf72a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 27, 128]),\n",
       " torch.Size([1, 64, 27, 128]),\n",
       " torch.Size([1, 27, 8192]),\n",
       " torch.Size([1, 27, 8192]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baukit\n",
    "from src.functional import get_module_nnsight, PatchSpec\n",
    "from src.hooking.llama_attention import LlamaAttentionPatcher\n",
    "import types\n",
    "from typing import Literal\n",
    "from src.tokens import prepare_input\n",
    "\n",
    "\n",
    "def set_attn_implementation(mt, attn_implementation: Literal[\"sdpa\", \"eager\"]):\n",
    "    mt.config._attn_implementation = attn_implementation\n",
    "    for layer_idx in range(mt.config.num_hidden_layers):\n",
    "        attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "        attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "        attn_block.config._attn_implementation = attn_implementation\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "batch_size = 1  # tokenized.input_ids.shape[0]\n",
    "n_heads = mt.config.num_attention_heads\n",
    "head_dim = mt.n_embd // n_heads\n",
    "query_idx = -1 # almost always the last token\n",
    "###################################################################################\n",
    "\n",
    "mt.reset_forward()\n",
    "set_attn_implementation(mt, \"sdpa\")\n",
    "\n",
    "layer_idx, head_idx = HEADS[0]\n",
    "\n",
    "attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "attn_block.forward = types.MethodType(\n",
    "    LlamaAttentionPatcher(block_name=attn_block_name),\n",
    "    attn_block,\n",
    ")\n",
    "\n",
    "patch_tokenized = prepare_input(prompts=patch_sample.prompt(), tokenizer=mt)\n",
    "patch_seq_len = patch_tokenized.input_ids.shape[1]\n",
    "input_ln = mt.layer_name_format.format(layer_idx) + \".input_layernorm\"\n",
    "\n",
    "with mt.trace(patch_tokenized) as trace:\n",
    "    ln_module = get_module_nnsight(mt, input_ln)\n",
    "    patch_ln = ln_module.output.save()\n",
    "\n",
    "    q_proj_name = mt.attn_module_name_format.format(layer_idx) + \".q_proj\"\n",
    "    q_proj_module = get_module_nnsight(mt, q_proj_name)\n",
    "    patch_q_proj = q_proj_module.output.view(batch_size, patch_seq_len, n_heads, head_dim).transpose(1, 2).save()\n",
    "    # patch_q_proj = PatchSpec(\n",
    "    #     location=(q_proj_name + f\".{head_idx}\", -1),\n",
    "    #     patch=patch_q_proj[:, head_idx, query_idx, :].squeeze().save()\n",
    "    # )\n",
    "\n",
    "clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "clean_seq_len = clean_tokenized.input_ids.shape[1]\n",
    "with mt.trace(clean_tokenized) as trace:\n",
    "    ln_module = get_module_nnsight(mt, input_ln)\n",
    "    clean_ln = ln_module.output.save()\n",
    "\n",
    "    q_proj_name = mt.attn_module_name_format.format(layer_idx) + \".q_proj\"\n",
    "    q_proj_module = get_module_nnsight(mt, q_proj_name)\n",
    "    clean_q_proj = q_proj_module.output.view(batch_size, clean_seq_len, n_heads, head_dim).transpose(1, 2).save()\n",
    "    # clean_q_proj = PatchSpec(\n",
    "    #     location=(q_proj_name + f\".{head_idx}\", -1),\n",
    "    #     patch=clean_q_proj[:, head_idx, query_idx, :].squeeze().save()\n",
    "    # )\n",
    "\n",
    "mt.reset_forward()\n",
    "set_attn_implementation(mt, \"eager\")\n",
    "\n",
    "patch_q_proj.shape, clean_q_proj.shape, patch_ln.shape, clean_ln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d10d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attention import visualize_attn_matrix\n",
    "from src.functional import get_hs, interpret_logits\n",
    "\n",
    "mt.reset_forward()\n",
    "set_attn_implementation(mt, \"sdpa\")\n",
    "\n",
    "layer_idx, head_idx = 35, 19\n",
    "# layer_idx, head_idx = 62, 1\n",
    "\n",
    "attn_matrices = {layer_idx: {}}\n",
    "\n",
    "attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "attn_block.forward = types.MethodType(\n",
    "    LlamaAttentionPatcher(\n",
    "        block_name=attn_block_name,\n",
    "        save_attn_for=[head_idx],\n",
    "        store_attn_matrices=attn_matrices[layer_idx],\n",
    "    ),\n",
    "    attn_block,\n",
    ")\n",
    "\n",
    "logit_location = (mt.lm_head_name, -1)\n",
    "logits = get_hs(\n",
    "    mt = mt,\n",
    "    input = clean_tokenized,\n",
    "    locations = [logit_location],\n",
    "    return_dict=False\n",
    ").squeeze()  # (seq_len, vocab_size)\n",
    "\n",
    "mt.reset_forward()\n",
    "set_attn_implementation(mt, \"eager\")\n",
    "\n",
    "head_matrix = attn_matrices[layer_idx][head_idx].squeeze().to(torch.float32).cpu().numpy()\n",
    "\n",
    "visualize_attn_matrix(\n",
    "    attn_matrix=head_matrix,\n",
    "    tokens=[mt.tokenizer.decode(t) for t in clean_tokenized.input_ids[0]],\n",
    "    q_index=-1,\n",
    ")\n",
    "\n",
    "interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=logits,\n",
    "    interested_tokens=[clean_sample.metadata[\"track_type_obj_token_id\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(mt._model), query_idx\n",
    "head_idx, query_idx, patch_q_proj[:, head_idx, query_idx, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attention import visualize_attn_matrix\n",
    "\n",
    "mt.reset_forward()\n",
    "set_attn_implementation(mt, \"sdpa\")\n",
    "\n",
    "attn_matrices = {layer_idx: {}}\n",
    "\n",
    "attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "attn_block.forward = types.MethodType(\n",
    "    LlamaAttentionPatcher(\n",
    "        block_name=attn_block_name,\n",
    "        save_attn_for=[head_idx],\n",
    "        store_attn_matrices=attn_matrices[layer_idx],\n",
    "        query_patches=[(head_idx, query_idx, patch_q_proj[:, head_idx, query_idx, :].squeeze())],\n",
    "    ),\n",
    "    attn_block,\n",
    ")\n",
    "\n",
    "logit_location = (mt.lm_head_name, -1)\n",
    "patch_logits = get_hs(\n",
    "    mt = mt,\n",
    "    # input = clean_tokenized,\n",
    "    input=patch_tokenized,\n",
    "    locations = [logit_location],\n",
    "    return_dict=False\n",
    ").squeeze()  # (seq_len, vocab_size)\n",
    "\n",
    "mt.reset_forward()\n",
    "set_attn_implementation(mt, \"eager\")\n",
    "\n",
    "head_matrix = attn_matrices[layer_idx][head_idx].squeeze().to(torch.float32).cpu().numpy()\n",
    "\n",
    "visualize_attn_matrix(\n",
    "    attn_matrix=head_matrix,\n",
    "    # tokens=[mt.tokenizer.decode(t) for t in clean_tokenized.input_ids[0]],\n",
    "    tokens=[mt.tokenizer.decode(t) for t in patch_tokenized.input_ids[0]],\n",
    "    q_index=-1,\n",
    ")\n",
    "\n",
    "interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=patch_logits,\n",
    "    interested_tokens=[clean_sample.metadata[\"track_type_obj_token_id\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e922a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(patch_logits, logits, atol = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(\n",
    "    patch_q_proj[:, head_idx, query_idx, :], \n",
    "    clean_q_proj[:, head_idx, query_idx, :],\n",
    "    atol=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9042b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.allclose(\n",
    "#     patch_ln[:, query_idx, :], \n",
    "#     clean_ln[:, query_idx, :],\n",
    "#     atol=1e-3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49583481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_ln[:, query_idx, :], clean_ln[:, query_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ead16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manual calculation\n",
    "# attn_module = baukit.get_module(mt._model, mt.attn_module_name_format.format(layer_idx))\n",
    "# patch_q_proj_manual = attn_module.q_proj(patch_ln)\n",
    "# clean_q_proj_manual = attn_module.q_proj(clean_ln)\n",
    "\n",
    "# print(patch_q_proj_manual.shape, clean_q_proj_manual.shape)\n",
    "# print(torch.allclose(\n",
    "#     patch_q_proj_manual[:, query_idx, :], \n",
    "#     clean_q_proj_manual[:, query_idx, :],\n",
    "#     atol=1e-3\n",
    "# ))\n",
    "\n",
    "# patch_q_proj_manual = patch_q_proj_manual.reshape(batch_size, patch_seq_len, n_heads, head_dim).transpose(1, 2)\n",
    "# clean_q_proj_manual = clean_q_proj_manual.reshape(batch_size, clean_seq_len, n_heads, head_dim).transpose(1, 2)\n",
    "# print(patch_q_proj_manual.shape, clean_q_proj_manual.shape)\n",
    "\n",
    "# for idx in range(n_heads):\n",
    "#     print(head_idx, torch.allclose(\n",
    "#         patch_q_proj_manual[:, idx, query_idx, :], \n",
    "#         clean_q_proj_manual[:, idx, query_idx, :],\n",
    "#         atol=1e-3\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098535e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.allclose(\n",
    "#     patch_q_proj_manual[:, head_idx, query_idx, :], \n",
    "#     patch_q_proj[:, head_idx, query_idx, :],\n",
    "#     atol=1e-3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_q_proj = clean_q_proj.clone()\n",
    "replace_q_proj[:, head_idx, query_idx, :] = patch_q_proj[:, head_idx, query_idx, :]\n",
    "\n",
    "print(torch.allclose(\n",
    "        replace_q_proj[:, head_idx, query_idx, :],\n",
    "        clean_q_proj[:, head_idx, query_idx, :],\n",
    "        atol=1e-3\n",
    "    )\n",
    ")\n",
    "print(replace_q_proj.shape)\n",
    "\n",
    "replace_q_proj = replace_q_proj.transpose(1, 2).reshape(batch_size, clean_seq_len, -1)\n",
    "\n",
    "rep_patch = PatchSpec(\n",
    "    location=(q_proj_name, -1),\n",
    "    patch=replace_q_proj[:, -1, :].squeeze(),\n",
    ")\n",
    "\n",
    "ln_patch = PatchSpec(\n",
    "    location=(input_ln, -1),\n",
    "    patch=patch_ln[:, query_idx, :].squeeze(),\n",
    ")\n",
    "\n",
    "head_q_patch = PatchSpec(\n",
    "    location=(q_proj_name, head_idx, -1),\n",
    "    patch=patch_q_proj[:, head_idx, query_idx, :].squeeze(),\n",
    ")\n",
    "\n",
    "head_q_patch.location, rep_patch.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d26910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_q_proj_rs = clean_q_proj.view(batch_size, clean_seq_len, -1)\n",
    "# patch_q_proj_rs = patch_q_proj.view(batch_size, clean_seq_len, -1)\n",
    "# clean_q_proj_rs[:, -1, :].shape, patch_q_proj_rs[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95232df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.allclose(\n",
    "#     replace_q_proj[:, -1, :].squeeze(), \n",
    "#     # patch_q_proj_rs[:, -1, :].squeeze(),\n",
    "#     clean_q_proj_rs[:, -1, :].squeeze(), \n",
    "#     atol=1e-3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_q_proj.shape, clean_q_proj.shape\n",
    "# torch.allclose(patch_q_proj.patch, clean_q_proj.patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4454946",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attention import get_attention_matrices, visualize_attn_matrix\n",
    "from src.functional import interpret_logits\n",
    "\n",
    "clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "\n",
    "attn_info = get_attention_matrices(\n",
    "    input=clean_tokenized,\n",
    "    mt=mt,\n",
    ")\n",
    "\n",
    "attn_matrix = attn_info.attention_matrices[layer_idx, head_idx].squeeze()\n",
    "visualize_attn_matrix(\n",
    "    attn_matrix=attn_matrix,\n",
    "    tokens=[mt.tokenizer.decode(t) for t in clean_tokenized.input_ids[0]],\n",
    "    q_index=-1,\n",
    ")\n",
    "\n",
    "interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=attn_info.logits,\n",
    "    interested_tokens=[clean_sample.ans_token_id, clean_sample.metadata[\"track_type_obj_token_id\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136268c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attention import get_attention_matrices, visualize_attn_matrix\n",
    "from src.functional import patch_with_nnsight, patch_with_baukit\n",
    "\n",
    "clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "\n",
    "patched_attn_info = get_attention_matrices(\n",
    "    input=clean_tokenized,\n",
    "    mt=mt,\n",
    "    # patches=[ln_patch],\n",
    "    patches = [head_q_patch],\n",
    "    # patches = [rep_patch],\n",
    "    # patch_interface=patch_with_nnsight\n",
    "    patch_interface=patch_with_baukit\n",
    ")\n",
    "\n",
    "patched_attn_matrix = patched_attn_info.attention_matrices[layer_idx, head_idx].squeeze()\n",
    "visualize_attn_matrix(\n",
    "    attn_matrix=patched_attn_matrix,\n",
    "    tokens=[mt.tokenizer.decode(t) for t in clean_tokenized.input_ids[0]],\n",
    "    q_index=-1,\n",
    ")\n",
    "\n",
    "interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=patched_attn_info.logits,\n",
    "    interested_tokens=[clean_sample.ans_token_id, clean_sample.metadata[\"track_type_obj_token_id\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc89a66",
   "metadata": {},
   "source": [
    "## Patching a bunch of heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ee03a",
   "metadata": {},
   "source": [
    "### Loading the Heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeda2be",
   "metadata": {},
   "source": [
    "#### Attention Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bdb4480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_0000.npz', 'sample_0001.npz', 'sample_0002.npz', 'sample_0003.npz', 'sample_0004.npz', 'sample_0005.npz', 'sample_0006.npz', 'sample_0007.npz', 'sample_0008.npz', 'sample_0009.npz', 'sample_0010.npz', 'sample_0011.npz', 'sample_0012.npz', 'sample_0013.npz', 'sample_0014.npz', 'sample_0015.npz', 'sample_0016.npz', 'sample_0017.npz', 'sample_0018.npz', 'sample_0019.npz', 'sample_0020.npz', 'sample_0021.npz', 'sample_0022.npz', 'sample_0023.npz', 'sample_0024.npz', 'sample_0025.npz', 'sample_0026.npz', 'sample_0027.npz', 'sample_0028.npz', 'sample_0029.npz', 'sample_0030.npz', 'sample_0031.npz', 'sample_0032.npz', 'sample_0033.npz', 'sample_0034.npz', 'sample_0035.npz', 'sample_0036.npz', 'sample_0037.npz', 'sample_0038.npz', 'sample_0039.npz', 'sample_0040.npz', 'sample_0041.npz', 'sample_0042.npz', 'sample_0043.npz', 'sample_0044.npz', 'sample_0045.npz', 'sample_0046.npz', 'sample_0047.npz', 'sample_0048.npz', 'sample_0049.npz', 'sample_0050.npz', 'sample_0051.npz', 'sample_0052.npz', 'sample_0053.npz', 'sample_0054.npz', 'sample_0055.npz', 'sample_0056.npz', 'sample_0057.npz', 'sample_0058.npz', 'sample_0059.npz', 'sample_0060.npz', 'sample_0061.npz', 'sample_0062.npz', 'sample_0063.npz', 'sample_0064.npz', 'sample_0065.npz', 'sample_0066.npz', 'sample_0067.npz', 'sample_0068.npz', 'sample_0069.npz', 'sample_0070.npz', 'sample_0071.npz', 'sample_0072.npz', 'sample_0073.npz', 'sample_0074.npz', 'sample_0075.npz', 'sample_0076.npz', 'sample_0077.npz', 'sample_0078.npz', 'sample_0079.npz', 'sample_0080.npz', 'sample_0081.npz', 'sample_0082.npz', 'sample_0083.npz', 'sample_0084.npz', 'sample_0085.npz', 'sample_0086.npz', 'sample_0087.npz', 'sample_0088.npz', 'sample_0089.npz', 'sample_0090.npz', 'sample_0091.npz', 'sample_0092.npz', 'sample_0093.npz', 'sample_0094.npz', 'sample_0095.npz', 'sample_0096.npz', 'sample_0097.npz', 'sample_0098.npz', 'sample_0099.npz', 'sample_0100.npz', 'sample_0101.npz', 'sample_0102.npz', 'sample_0103.npz', 'sample_0104.npz', 'sample_0105.npz', 'sample_0106.npz', 'sample_0107.npz', 'sample_0108.npz', 'sample_0109.npz', 'sample_0110.npz', 'sample_0111.npz', 'sample_0112.npz', 'sample_0113.npz', 'sample_0114.npz', 'sample_0115.npz', 'sample_0116.npz', 'sample_0117.npz', 'sample_0118.npz', 'sample_0119.npz', 'sample_0120.npz', 'sample_0121.npz', 'sample_0122.npz', 'sample_0123.npz', 'sample_0124.npz', 'sample_0125.npz', 'sample_0126.npz', 'sample_0127.npz', 'sample_0128.npz', 'sample_0129.npz', 'sample_0130.npz', 'sample_0131.npz', 'sample_0132.npz', 'sample_0133.npz', 'sample_0134.npz', 'sample_0135.npz', 'sample_0136.npz', 'sample_0137.npz', 'sample_0138.npz', 'sample_0139.npz', 'sample_0140.npz', 'sample_0141.npz', 'sample_0142.npz', 'sample_0143.npz', 'sample_0144.npz', 'sample_0145.npz', 'sample_0146.npz', 'sample_0147.npz', 'sample_0148.npz', 'sample_0149.npz', 'sample_0150.npz', 'sample_0151.npz', 'sample_0152.npz', 'sample_0153.npz', 'sample_0154.npz', 'sample_0155.npz', 'sample_0156.npz', 'sample_0157.npz', 'sample_0158.npz', 'sample_0159.npz', 'sample_0160.npz', 'sample_0161.npz', 'sample_0162.npz', 'sample_0163.npz', 'sample_0164.npz', 'sample_0165.npz', 'sample_0166.npz', 'sample_0167.npz', 'sample_0168.npz', 'sample_0169.npz', 'sample_0170.npz', 'sample_0171.npz', 'sample_0172.npz', 'sample_0173.npz', 'sample_0174.npz', 'sample_0175.npz', 'sample_0176.npz', 'sample_0177.npz', 'sample_0178.npz', 'sample_0179.npz', 'sample_0180.npz', 'sample_0181.npz', 'sample_0182.npz', 'sample_0183.npz', 'sample_0184.npz', 'sample_0185.npz', 'sample_0186.npz', 'sample_0187.npz', 'sample_0188.npz', 'sample_0189.npz', 'sample_0190.npz', 'sample_0191.npz', 'sample_0192.npz', 'sample_0193.npz', 'sample_0194.npz', 'sample_0195.npz', 'sample_0196.npz', 'sample_0197.npz', 'sample_0198.npz', 'sample_0199.npz', 'sample_0200.npz', 'sample_0201.npz', 'sample_0202.npz', 'sample_0203.npz', 'sample_0204.npz', 'sample_0205.npz', 'sample_0206.npz', 'sample_0207.npz', 'sample_0208.npz', 'sample_0209.npz', 'sample_0210.npz', 'sample_0211.npz', 'sample_0212.npz', 'sample_0213.npz', 'sample_0214.npz', 'sample_0215.npz', 'sample_0216.npz', 'sample_0217.npz', 'sample_0218.npz', 'sample_0219.npz', 'sample_0220.npz', 'sample_0221.npz', 'sample_0222.npz', 'sample_0223.npz', 'sample_0224.npz', 'sample_0225.npz', 'sample_0226.npz', 'sample_0227.npz', 'sample_0228.npz', 'sample_0229.npz', 'sample_0230.npz', 'sample_0231.npz', 'sample_0232.npz', 'sample_0233.npz', 'sample_0234.npz', 'sample_0235.npz', 'sample_0236.npz', 'sample_0237.npz', 'sample_0238.npz', 'sample_0239.npz', 'sample_0240.npz', 'sample_0241.npz', 'sample_0242.npz', 'sample_0243.npz', 'sample_0244.npz', 'sample_0245.npz', 'sample_0246.npz', 'sample_0247.npz', 'sample_0248.npz', 'sample_0249.npz', 'sample_0250.npz', 'sample_0251.npz', 'sample_0252.npz', 'sample_0253.npz', 'sample_0254.npz', 'sample_0255.npz', 'sample_0256.npz', 'sample_0257.npz', 'sample_0258.npz', 'sample_0259.npz', 'sample_0260.npz', 'sample_0261.npz', 'sample_0262.npz', 'sample_0263.npz', 'sample_0264.npz', 'sample_0265.npz', 'sample_0266.npz', 'sample_0267.npz', 'sample_0268.npz', 'sample_0269.npz', 'sample_0270.npz', 'sample_0271.npz', 'sample_0272.npz', 'sample_0273.npz', 'sample_0274.npz', 'sample_0275.npz', 'sample_0276.npz', 'sample_0277.npz', 'sample_0278.npz', 'sample_0279.npz', 'sample_0280.npz', 'sample_0281.npz', 'sample_0282.npz', 'sample_0283.npz', 'sample_0284.npz', 'sample_0285.npz', 'sample_0286.npz', 'sample_0287.npz', 'sample_0288.npz', 'sample_0289.npz', 'sample_0290.npz', 'sample_0291.npz', 'sample_0292.npz', 'sample_0293.npz', 'sample_0294.npz', 'sample_0295.npz', 'sample_0296.npz', 'sample_0297.npz', 'sample_0298.npz', 'sample_0299.npz', 'sample_0300.npz', 'sample_0301.npz', 'sample_0302.npz', 'sample_0303.npz', 'sample_0304.npz', 'sample_0305.npz', 'sample_0306.npz', 'sample_0307.npz', 'sample_0308.npz', 'sample_0309.npz', 'sample_0310.npz', 'sample_0311.npz', 'sample_0312.npz', 'sample_0313.npz', 'sample_0314.npz', 'sample_0315.npz', 'sample_0316.npz', 'sample_0317.npz', 'sample_0318.npz', 'sample_0319.npz', 'sample_0320.npz', 'sample_0321.npz', 'sample_0322.npz', 'sample_0323.npz', 'sample_0324.npz', 'sample_0325.npz', 'sample_0326.npz', 'sample_0327.npz', 'sample_0328.npz', 'sample_0329.npz', 'sample_0330.npz', 'sample_0331.npz', 'sample_0332.npz', 'sample_0333.npz', 'sample_0334.npz', 'sample_0335.npz', 'sample_0336.npz', 'sample_0337.npz', 'sample_0338.npz', 'sample_0339.npz', 'sample_0340.npz', 'sample_0341.npz', 'sample_0342.npz', 'sample_0343.npz', 'sample_0344.npz', 'sample_0345.npz', 'sample_0346.npz', 'sample_0347.npz', 'sample_0348.npz', 'sample_0349.npz', 'sample_0350.npz', 'sample_0351.npz', 'sample_0352.npz', 'sample_0353.npz', 'sample_0354.npz', 'sample_0355.npz', 'sample_0356.npz', 'sample_0357.npz', 'sample_0358.npz', 'sample_0359.npz', 'sample_0360.npz', 'sample_0361.npz', 'sample_0362.npz', 'sample_0363.npz', 'sample_0364.npz', 'sample_0365.npz', 'sample_0366.npz', 'sample_0367.npz', 'sample_0368.npz', 'sample_0369.npz', 'sample_0370.npz', 'sample_0371.npz', 'sample_0372.npz', 'sample_0373.npz', 'sample_0374.npz', 'sample_0375.npz', 'sample_0376.npz', 'sample_0377.npz', 'sample_0378.npz', 'sample_0379.npz', 'sample_0380.npz', 'sample_0381.npz', 'sample_0382.npz', 'sample_0383.npz', 'sample_0384.npz', 'sample_0385.npz', 'sample_0386.npz', 'sample_0387.npz', 'sample_0388.npz', 'sample_0389.npz', 'sample_0390.npz', 'sample_0391.npz', 'sample_0392.npz', 'sample_0393.npz', 'sample_0394.npz', 'sample_0395.npz', 'sample_0396.npz', 'sample_0397.npz', 'sample_0398.npz', 'sample_0399.npz', 'sample_0400.npz', 'sample_0401.npz', 'sample_0402.npz', 'sample_0403.npz', 'sample_0404.npz', 'sample_0405.npz', 'sample_0406.npz', 'sample_0407.npz', 'sample_0408.npz', 'sample_0409.npz', 'sample_0410.npz', 'sample_0411.npz', 'sample_0412.npz', 'sample_0413.npz', 'sample_0414.npz', 'sample_0415.npz', 'sample_0416.npz', 'sample_0417.npz', 'sample_0418.npz', 'sample_0419.npz', 'sample_0420.npz', 'sample_0421.npz', 'sample_0422.npz', 'sample_0423.npz', 'sample_0424.npz', 'sample_0425.npz', 'sample_0426.npz', 'sample_0427.npz', 'sample_0428.npz', 'sample_0429.npz', 'sample_0430.npz', 'sample_0431.npz', 'sample_0432.npz', 'sample_0433.npz', 'sample_0434.npz', 'sample_0435.npz', 'sample_0436.npz', 'sample_0437.npz', 'sample_0438.npz', 'sample_0439.npz', 'sample_0440.npz', 'sample_0441.npz', 'sample_0442.npz', 'sample_0443.npz', 'sample_0444.npz', 'sample_0445.npz', 'sample_0446.npz', 'sample_0447.npz', 'sample_0448.npz', 'sample_0449.npz', 'sample_0450.npz', 'sample_0451.npz', 'sample_0452.npz', 'sample_0453.npz', 'sample_0454.npz', 'sample_0455.npz', 'sample_0456.npz', 'sample_0457.npz', 'sample_0458.npz', 'sample_0459.npz', 'sample_0460.npz', 'sample_0461.npz', 'sample_0462.npz', 'sample_0463.npz', 'sample_0464.npz', 'sample_0465.npz', 'sample_0466.npz', 'sample_0467.npz', 'sample_0468.npz', 'sample_0469.npz', 'sample_0470.npz', 'sample_0471.npz', 'sample_0472.npz', 'sample_0473.npz', 'sample_0474.npz', 'sample_0475.npz', 'sample_0476.npz', 'sample_0477.npz', 'sample_0478.npz', 'sample_0479.npz', 'sample_0480.npz', 'sample_0481.npz', 'sample_0482.npz', 'sample_0483.npz', 'sample_0484.npz', 'sample_0485.npz', 'sample_0486.npz', 'sample_0487.npz', 'sample_0488.npz', 'sample_0489.npz', 'sample_0490.npz', 'sample_0491.npz', 'sample_0492.npz', 'sample_0493.npz', 'sample_0494.npz', 'sample_0495.npz', 'sample_0496.npz', 'sample_0497.npz', 'sample_0498.npz', 'sample_0499.npz', 'sample_0500.npz', 'sample_0501.npz', 'sample_0502.npz', 'sample_0503.npz', 'sample_0504.npz', 'sample_0505.npz', 'sample_0506.npz', 'sample_0507.npz', 'sample_0508.npz', 'sample_0509.npz', 'sample_0510.npz', 'sample_0511.npz', 'sample_0512.npz', 'sample_0513.npz', 'sample_0514.npz', 'sample_0515.npz', 'sample_0516.npz', 'sample_0517.npz', 'sample_0518.npz', 'sample_0519.npz', 'sample_0520.npz', 'sample_0521.npz', 'sample_0522.npz', 'sample_0523.npz', 'sample_0524.npz', 'sample_0525.npz', 'sample_0526.npz', 'sample_0527.npz', 'sample_0528.npz', 'sample_0529.npz', 'sample_0530.npz', 'sample_0531.npz', 'sample_0532.npz', 'sample_0533.npz', 'sample_0534.npz', 'sample_0535.npz', 'sample_0536.npz', 'sample_0537.npz', 'sample_0538.npz', 'sample_0539.npz', 'sample_0540.npz', 'sample_0541.npz', 'sample_0542.npz', 'sample_0543.npz', 'sample_0544.npz', 'sample_0545.npz', 'sample_0546.npz', 'sample_0547.npz', 'sample_0548.npz', 'sample_0549.npz', 'sample_0550.npz', 'sample_0551.npz', 'sample_0552.npz', 'sample_0553.npz', 'sample_0554.npz', 'sample_0555.npz', 'sample_0556.npz', 'sample_0557.npz', 'sample_0558.npz', 'sample_0559.npz', 'sample_0560.npz', 'sample_0561.npz', 'sample_0562.npz', 'sample_0563.npz', 'sample_0564.npz', 'sample_0565.npz', 'sample_0566.npz', 'sample_0567.npz', 'sample_0568.npz', 'sample_0569.npz', 'sample_0570.npz', 'sample_0571.npz', 'sample_0572.npz', 'sample_0573.npz', 'sample_0574.npz', 'sample_0575.npz', 'sample_0576.npz', 'sample_0577.npz', 'sample_0578.npz', 'sample_0579.npz', 'sample_0580.npz', 'sample_0581.npz', 'sample_0582.npz', 'sample_0583.npz', 'sample_0584.npz', 'sample_0585.npz', 'sample_0586.npz', 'sample_0587.npz', 'sample_0588.npz', 'sample_0589.npz', 'sample_0590.npz', 'sample_0591.npz', 'sample_0592.npz', 'sample_0593.npz', 'sample_0594.npz', 'sample_0595.npz', 'sample_0596.npz', 'sample_0597.npz', 'sample_0598.npz', 'sample_0599.npz', 'sample_0600.npz', 'sample_0601.npz', 'sample_0602.npz', 'sample_0603.npz', 'sample_0604.npz', 'sample_0605.npz', 'sample_0606.npz', 'sample_0607.npz', 'sample_0608.npz', 'sample_0609.npz', 'sample_0610.npz', 'sample_0611.npz', 'sample_0612.npz', 'sample_0613.npz', 'sample_0614.npz', 'sample_0615.npz', 'sample_0616.npz', 'sample_0617.npz', 'sample_0618.npz', 'sample_0619.npz', 'sample_0620.npz', 'sample_0621.npz', 'sample_0622.npz', 'sample_0623.npz', 'sample_0624.npz', 'sample_0625.npz', 'sample_0626.npz', 'sample_0627.npz', 'sample_0628.npz', 'sample_0629.npz', 'sample_0630.npz', 'sample_0631.npz', 'sample_0632.npz', 'sample_0633.npz', 'sample_0634.npz', 'sample_0635.npz', 'sample_0636.npz', 'sample_0637.npz', 'sample_0638.npz', 'sample_0639.npz', 'sample_0640.npz', 'sample_0641.npz', 'sample_0642.npz', 'sample_0643.npz', 'sample_0644.npz', 'sample_0645.npz', 'sample_0646.npz', 'sample_0647.npz', 'sample_0648.npz', 'sample_0649.npz', 'sample_0650.npz', 'sample_0651.npz', 'sample_0652.npz', 'sample_0653.npz', 'sample_0654.npz', 'sample_0655.npz', 'sample_0656.npz', 'sample_0657.npz', 'sample_0658.npz', 'sample_0659.npz', 'sample_0660.npz', 'sample_0661.npz', 'sample_0662.npz', 'sample_0663.npz', 'sample_0664.npz', 'sample_0665.npz', 'sample_0666.npz', 'sample_0667.npz', 'sample_0668.npz', 'sample_0669.npz', 'sample_0670.npz', 'sample_0671.npz', 'sample_0672.npz', 'sample_0673.npz', 'sample_0674.npz', 'sample_0675.npz', 'sample_0676.npz', 'sample_0677.npz', 'sample_0678.npz', 'sample_0679.npz', 'sample_0680.npz', 'sample_0681.npz', 'sample_0682.npz', 'sample_0683.npz', 'sample_0684.npz', 'sample_0685.npz', 'sample_0686.npz', 'sample_0687.npz', 'sample_0688.npz', 'sample_0689.npz', 'sample_0690.npz', 'sample_0691.npz', 'sample_0692.npz', 'sample_0693.npz', 'sample_0694.npz', 'sample_0695.npz', 'sample_0696.npz', 'sample_0697.npz', 'sample_0698.npz', 'sample_0699.npz', 'sample_0700.npz', 'sample_0701.npz', 'sample_0702.npz', 'sample_0703.npz', 'sample_0704.npz', 'sample_0705.npz', 'sample_0706.npz', 'sample_0707.npz', 'sample_0708.npz', 'sample_0709.npz', 'sample_0710.npz', 'sample_0711.npz', 'sample_0712.npz', 'sample_0713.npz', 'sample_0714.npz', 'sample_0715.npz', 'sample_0716.npz', 'sample_0717.npz', 'sample_0718.npz', 'sample_0719.npz', 'sample_0720.npz', 'sample_0721.npz', 'sample_0722.npz', 'sample_0723.npz', 'sample_0724.npz', 'sample_0725.npz', 'sample_0726.npz', 'sample_0727.npz', 'sample_0728.npz', 'sample_0729.npz', 'sample_0730.npz', 'sample_0731.npz', 'sample_0732.npz', 'sample_0733.npz', 'sample_0734.npz', 'sample_0735.npz', 'sample_0736.npz', 'sample_0737.npz', 'sample_0738.npz', 'sample_0739.npz', 'sample_0740.npz', 'sample_0741.npz', 'sample_0742.npz', 'sample_0743.npz', 'sample_0744.npz', 'sample_0745.npz', 'sample_0746.npz', 'sample_0747.npz', 'sample_0748.npz', 'sample_0749.npz', 'sample_0750.npz', 'sample_0751.npz', 'sample_0752.npz', 'sample_0753.npz', 'sample_0754.npz', 'sample_0755.npz', 'sample_0756.npz', 'sample_0757.npz', 'sample_0758.npz', 'sample_0759.npz', 'sample_0760.npz', 'sample_0761.npz', 'sample_0762.npz', 'sample_0763.npz', 'sample_0764.npz', 'sample_0765.npz', 'sample_0766.npz', 'sample_0767.npz', 'sample_0768.npz', 'sample_0769.npz', 'sample_0770.npz', 'sample_0771.npz', 'sample_0772.npz', 'sample_0773.npz', 'sample_0774.npz', 'sample_0775.npz', 'sample_0776.npz', 'sample_0777.npz', 'sample_0778.npz', 'sample_0779.npz', 'sample_0780.npz', 'sample_0781.npz', 'sample_0782.npz', 'sample_0783.npz', 'sample_0784.npz', 'sample_0785.npz', 'sample_0786.npz', 'sample_0787.npz', 'sample_0788.npz', 'sample_0789.npz', 'sample_0790.npz', 'sample_0791.npz', 'sample_0792.npz', 'sample_0793.npz', 'sample_0794.npz', 'sample_0795.npz', 'sample_0796.npz', 'sample_0797.npz', 'sample_0798.npz', 'sample_0799.npz', 'sample_0800.npz', 'sample_0801.npz', 'sample_0802.npz', 'sample_0803.npz', 'sample_0804.npz', 'sample_0805.npz', 'sample_0806.npz', 'sample_0807.npz', 'sample_0808.npz', 'sample_0809.npz', 'sample_0810.npz', 'sample_0811.npz', 'sample_0812.npz', 'sample_0813.npz', 'sample_0814.npz', 'sample_0815.npz', 'sample_0816.npz', 'sample_0817.npz', 'sample_0818.npz', 'sample_0819.npz', 'sample_0820.npz', 'sample_0821.npz', 'sample_0822.npz', 'sample_0823.npz', 'sample_0824.npz', 'sample_0825.npz', 'sample_0826.npz', 'sample_0827.npz', 'sample_0828.npz', 'sample_0829.npz', 'sample_0830.npz', 'sample_0831.npz', 'sample_0832.npz', 'sample_0833.npz', 'sample_0834.npz', 'sample_0835.npz', 'sample_0836.npz', 'sample_0837.npz', 'sample_0838.npz', 'sample_0839.npz', 'sample_0840.npz', 'sample_0841.npz', 'sample_0842.npz', 'sample_0843.npz', 'sample_0844.npz', 'sample_0845.npz', 'sample_0846.npz', 'sample_0847.npz', 'sample_0848.npz', 'sample_0849.npz', 'sample_0850.npz', 'sample_0851.npz', 'sample_0852.npz', 'sample_0853.npz', 'sample_0854.npz', 'sample_0855.npz', 'sample_0856.npz', 'sample_0857.npz', 'sample_0858.npz', 'sample_0859.npz', 'sample_0860.npz', 'sample_0861.npz', 'sample_0862.npz', 'sample_0863.npz', 'sample_0864.npz', 'sample_0865.npz', 'sample_0866.npz', 'sample_0867.npz', 'sample_0868.npz', 'sample_0869.npz', 'sample_0870.npz', 'sample_0871.npz', 'sample_0872.npz', 'sample_0873.npz', 'sample_0874.npz', 'sample_0875.npz', 'sample_0876.npz', 'sample_0877.npz', 'sample_0878.npz', 'sample_0879.npz', 'sample_0880.npz', 'sample_0881.npz', 'sample_0882.npz', 'sample_0883.npz', 'sample_0884.npz', 'sample_0885.npz', 'sample_0886.npz', 'sample_0887.npz', 'sample_0888.npz', 'sample_0889.npz', 'sample_0890.npz', 'sample_0891.npz', 'sample_0892.npz', 'sample_0893.npz', 'sample_0894.npz', 'sample_0895.npz', 'sample_0896.npz', 'sample_0897.npz', 'sample_0898.npz', 'sample_0899.npz', 'sample_0900.npz', 'sample_0901.npz', 'sample_0902.npz', 'sample_0903.npz', 'sample_0904.npz', 'sample_0905.npz', 'sample_0906.npz', 'sample_0907.npz', 'sample_0908.npz', 'sample_0909.npz', 'sample_0910.npz', 'sample_0911.npz', 'sample_0912.npz', 'sample_0913.npz', 'sample_0914.npz', 'sample_0915.npz', 'sample_0916.npz', 'sample_0917.npz', 'sample_0918.npz', 'sample_0919.npz', 'sample_0920.npz', 'sample_0921.npz', 'sample_0922.npz', 'sample_0923.npz', 'sample_0924.npz', 'sample_0925.npz', 'sample_0926.npz', 'sample_0927.npz', 'sample_0928.npz', 'sample_0929.npz', 'sample_0930.npz', 'sample_0931.npz', 'sample_0932.npz', 'sample_0933.npz', 'sample_0934.npz', 'sample_0935.npz', 'sample_0936.npz', 'sample_0937.npz', 'sample_0938.npz', 'sample_0939.npz', 'sample_0940.npz', 'sample_0941.npz', 'sample_0942.npz', 'sample_0943.npz', 'sample_0944.npz', 'sample_0945.npz', 'sample_0946.npz', 'sample_0947.npz', 'sample_0948.npz', 'sample_0949.npz', 'sample_0950.npz', 'sample_0951.npz', 'sample_0952.npz', 'sample_0953.npz', 'sample_0954.npz', 'sample_0955.npz', 'sample_0956.npz', 'sample_0957.npz', 'sample_0958.npz', 'sample_0959.npz', 'sample_0960.npz', 'sample_0961.npz', 'sample_0962.npz', 'sample_0963.npz', 'sample_0964.npz', 'sample_0965.npz', 'sample_0966.npz', 'sample_0967.npz', 'sample_0968.npz', 'sample_0969.npz', 'sample_0970.npz', 'sample_0971.npz', 'sample_0972.npz', 'sample_0973.npz', 'sample_0974.npz', 'sample_0975.npz', 'sample_0976.npz', 'sample_0977.npz', 'sample_0978.npz', 'sample_0979.npz', 'sample_0980.npz', 'sample_0981.npz', 'sample_0982.npz', 'sample_0983.npz', 'sample_0984.npz', 'sample_0985.npz', 'sample_0986.npz', 'sample_0987.npz', 'sample_0988.npz', 'sample_0989.npz', 'sample_0990.npz', 'sample_0991.npz', 'sample_0992.npz', 'sample_0993.npz', 'sample_0994.npz', 'sample_0995.npz', 'sample_0996.npz', 'sample_0997.npz', 'sample_0998.npz', 'sample_0999.npz', 'sample_1000.npz', 'sample_1001.npz', 'sample_1002.npz', 'sample_1003.npz', 'sample_1004.npz', 'sample_1005.npz', 'sample_1006.npz', 'sample_1007.npz', 'sample_1008.npz', 'sample_1009.npz', 'sample_1010.npz', 'sample_1011.npz', 'sample_1012.npz', 'sample_1013.npz', 'sample_1014.npz', 'sample_1015.npz', 'sample_1016.npz', 'sample_1017.npz', 'sample_1018.npz', 'sample_1019.npz', 'sample_1020.npz', 'sample_1021.npz', 'sample_1022.npz', 'sample_1023.npz', 'sample_1024.npz', 'sample_1025.npz', 'sample_1026.npz', 'sample_1027.npz', 'sample_1028.npz', 'sample_1029.npz', 'sample_1030.npz', 'sample_1031.npz', 'sample_1032.npz', 'sample_1033.npz', 'sample_1034.npz', 'sample_1035.npz', 'sample_1036.npz', 'sample_1037.npz', 'sample_1038.npz', 'sample_1039.npz', 'sample_1040.npz', 'sample_1041.npz', 'sample_1042.npz', 'sample_1043.npz', 'sample_1044.npz', 'sample_1045.npz', 'sample_1046.npz', 'sample_1047.npz', 'sample_1048.npz', 'sample_1049.npz', 'sample_1050.npz', 'sample_1051.npz', 'sample_1052.npz', 'sample_1053.npz', 'sample_1054.npz', 'sample_1055.npz', 'sample_1056.npz', 'sample_1057.npz', 'sample_1058.npz', 'sample_1059.npz', 'sample_1060.npz', 'sample_1061.npz', 'sample_1062.npz', 'sample_1063.npz', 'sample_1064.npz', 'sample_1065.npz', 'sample_1066.npz', 'sample_1067.npz', 'sample_1068.npz', 'sample_1069.npz', 'sample_1070.npz', 'sample_1071.npz', 'sample_1072.npz', 'sample_1073.npz', 'sample_1074.npz', 'sample_1075.npz', 'sample_1076.npz', 'sample_1077.npz', 'sample_1078.npz', 'sample_1079.npz', 'sample_1080.npz', 'sample_1081.npz', 'sample_1082.npz', 'sample_1083.npz', 'sample_1084.npz', 'sample_1085.npz', 'sample_1086.npz', 'sample_1087.npz', 'sample_1088.npz', 'sample_1089.npz', 'sample_1090.npz', 'sample_1091.npz', 'sample_1092.npz', 'sample_1093.npz', 'sample_1094.npz', 'sample_1095.npz', 'sample_1096.npz', 'sample_1097.npz', 'sample_1098.npz', 'sample_1099.npz', 'sample_1100.npz', 'sample_1101.npz', 'sample_1102.npz', 'sample_1103.npz', 'sample_1104.npz', 'sample_1105.npz', 'sample_1106.npz', 'sample_1107.npz', 'sample_1108.npz', 'sample_1109.npz', 'sample_1110.npz', 'sample_1111.npz', 'sample_1112.npz', 'sample_1113.npz', 'sample_1114.npz', 'sample_1115.npz', 'sample_1116.npz', 'sample_1117.npz', 'sample_1118.npz', 'sample_1119.npz', 'sample_1120.npz', 'sample_1121.npz', 'sample_1122.npz', 'sample_1123.npz', 'sample_1124.npz', 'sample_1125.npz', 'sample_1126.npz', 'sample_1127.npz', 'sample_1128.npz', 'sample_1129.npz', 'sample_1130.npz', 'sample_1131.npz', 'sample_1132.npz', 'sample_1133.npz', 'sample_1134.npz', 'sample_1135.npz', 'sample_1136.npz', 'sample_1137.npz', 'sample_1138.npz', 'sample_1139.npz', 'sample_1140.npz', 'sample_1141.npz', 'sample_1142.npz', 'sample_1143.npz', 'sample_1144.npz', 'sample_1145.npz', 'sample_1146.npz', 'sample_1147.npz', 'sample_1148.npz', 'sample_1149.npz', 'sample_1150.npz', 'sample_1151.npz', 'sample_1152.npz', 'sample_1153.npz', 'sample_1154.npz', 'sample_1155.npz', 'sample_1156.npz', 'sample_1157.npz', 'sample_1158.npz', 'sample_1159.npz', 'sample_1160.npz', 'sample_1161.npz', 'sample_1162.npz', 'sample_1163.npz', 'sample_1164.npz', 'sample_1165.npz', 'sample_1166.npz', 'sample_1167.npz', 'sample_1168.npz', 'sample_1169.npz', 'sample_1170.npz', 'sample_1171.npz', 'sample_1172.npz', 'sample_1173.npz', 'sample_1174.npz', 'sample_1175.npz', 'sample_1176.npz', 'sample_1177.npz', 'sample_1178.npz', 'sample_1179.npz', 'sample_1180.npz', 'sample_1181.npz', 'sample_1182.npz', 'sample_1183.npz', 'sample_1184.npz', 'sample_1185.npz', 'sample_1186.npz', 'sample_1187.npz', 'sample_1188.npz', 'sample_1189.npz', 'sample_1190.npz', 'sample_1191.npz', 'sample_1192.npz', 'sample_1193.npz', 'sample_1194.npz', 'sample_1195.npz', 'sample_1196.npz', 'sample_1197.npz', 'sample_1198.npz', 'sample_1199.npz', 'sample_1200.npz', 'sample_1201.npz', 'sample_1202.npz', 'sample_1203.npz', 'sample_1204.npz', 'sample_1205.npz', 'sample_1206.npz', 'sample_1207.npz', 'sample_1208.npz', 'sample_1209.npz', 'sample_1210.npz', 'sample_1211.npz', 'sample_1212.npz', 'sample_1213.npz', 'sample_1214.npz', 'sample_1215.npz', 'sample_1216.npz', 'sample_1217.npz', 'sample_1218.npz', 'sample_1219.npz', 'sample_1220.npz', 'sample_1221.npz', 'sample_1222.npz', 'sample_1223.npz', 'sample_1224.npz', 'sample_1225.npz', 'sample_1226.npz', 'sample_1227.npz', 'sample_1228.npz', 'sample_1229.npz', 'sample_1230.npz', 'sample_1231.npz', 'sample_1232.npz', 'sample_1233.npz', 'sample_1234.npz', 'sample_1235.npz', 'sample_1236.npz', 'sample_1237.npz', 'sample_1238.npz', 'sample_1239.npz', 'sample_1240.npz', 'sample_1241.npz', 'sample_1242.npz', 'sample_1243.npz', 'sample_1244.npz', 'sample_1245.npz', 'sample_1246.npz', 'sample_1247.npz', 'sample_1248.npz', 'sample_1249.npz', 'sample_1250.npz', 'sample_1251.npz', 'sample_1252.npz', 'sample_1253.npz', 'sample_1254.npz', 'sample_1255.npz', 'sample_1256.npz', 'sample_1257.npz', 'sample_1258.npz', 'sample_1259.npz', 'sample_1260.npz', 'sample_1261.npz', 'sample_1262.npz', 'sample_1263.npz', 'sample_1264.npz', 'sample_1265.npz', 'sample_1266.npz', 'sample_1267.npz', 'sample_1268.npz', 'sample_1269.npz', 'sample_1270.npz', 'sample_1271.npz', 'sample_1272.npz', 'sample_1273.npz', 'sample_1274.npz', 'sample_1275.npz', 'sample_1276.npz', 'sample_1277.npz', 'sample_1278.npz', 'sample_1279.npz', 'sample_1280.npz', 'sample_1281.npz', 'sample_1282.npz', 'sample_1283.npz', 'sample_1284.npz', 'sample_1285.npz', 'sample_1286.npz', 'sample_1287.npz', 'sample_1288.npz', 'sample_1289.npz', 'sample_1290.npz', 'sample_1291.npz', 'sample_1292.npz', 'sample_1293.npz', 'sample_1294.npz', 'sample_1295.npz', 'sample_1296.npz', 'sample_1297.npz', 'sample_1298.npz', 'sample_1299.npz', 'sample_1300.npz', 'sample_1301.npz', 'sample_1302.npz', 'sample_1303.npz', 'sample_1304.npz', 'sample_1305.npz', 'sample_1306.npz', 'sample_1307.npz', 'sample_1308.npz', 'sample_1309.npz', 'sample_1310.npz', 'sample_1311.npz', 'sample_1312.npz', 'sample_1313.npz', 'sample_1314.npz', 'sample_1315.npz', 'sample_1316.npz', 'sample_1317.npz', 'sample_1318.npz', 'sample_1319.npz', 'sample_1320.npz', 'sample_1321.npz', 'sample_1322.npz', 'sample_1323.npz', 'sample_1324.npz', 'sample_1325.npz', 'sample_1326.npz', 'sample_1327.npz', 'sample_1328.npz', 'sample_1329.npz', 'sample_1330.npz', 'sample_1331.npz', 'sample_1332.npz', 'sample_1333.npz', 'sample_1334.npz', 'sample_1335.npz', 'sample_1336.npz', 'sample_1337.npz', 'sample_1338.npz', 'sample_1339.npz', 'sample_1340.npz', 'sample_1341.npz', 'sample_1342.npz', 'sample_1343.npz', 'sample_1344.npz', 'sample_1345.npz', 'sample_1346.npz', 'sample_1347.npz', 'sample_1348.npz', 'sample_1349.npz', 'sample_1350.npz', 'sample_1351.npz', 'sample_1352.npz', 'sample_1353.npz', 'sample_1354.npz', 'sample_1355.npz', 'sample_1356.npz', 'sample_1357.npz', 'sample_1358.npz', 'sample_1359.npz', 'sample_1360.npz', 'sample_1361.npz', 'sample_1362.npz', 'sample_1363.npz', 'sample_1364.npz', 'sample_1365.npz', 'sample_1366.npz', 'sample_1367.npz', 'sample_1368.npz', 'sample_1369.npz', 'sample_1370.npz', 'sample_1371.npz', 'sample_1372.npz', 'sample_1373.npz', 'sample_1374.npz', 'sample_1375.npz', 'sample_1376.npz', 'sample_1377.npz', 'sample_1378.npz', 'sample_1379.npz', 'sample_1380.npz', 'sample_1381.npz', 'sample_1382.npz', 'sample_1383.npz', 'sample_1384.npz', 'sample_1385.npz', 'sample_1386.npz', 'sample_1387.npz', 'sample_1388.npz', 'sample_1389.npz', 'sample_1390.npz', 'sample_1391.npz', 'sample_1392.npz', 'sample_1393.npz', 'sample_1394.npz', 'sample_1395.npz', 'sample_1396.npz', 'sample_1397.npz', 'sample_1398.npz', 'sample_1399.npz', 'sample_1400.npz', 'sample_1401.npz', 'sample_1402.npz', 'sample_1403.npz', 'sample_1404.npz', 'sample_1405.npz', 'sample_1406.npz', 'sample_1407.npz', 'sample_1408.npz', 'sample_1409.npz', 'sample_1410.npz', 'sample_1411.npz', 'sample_1412.npz', 'sample_1413.npz', 'sample_1414.npz', 'sample_1415.npz', 'sample_1416.npz', 'sample_1417.npz', 'sample_1418.npz', 'sample_1419.npz', 'sample_1420.npz', 'sample_1421.npz', 'sample_1422.npz', 'sample_1423.npz', 'sample_1424.npz', 'sample_1425.npz', 'sample_1426.npz', 'sample_1427.npz', 'sample_1428.npz', 'sample_1429.npz', 'sample_1430.npz', 'sample_1431.npz', 'sample_1432.npz', 'sample_1433.npz', 'sample_1434.npz', 'sample_1435.npz', 'sample_1436.npz', 'sample_1437.npz', 'sample_1438.npz', 'sample_1439.npz', 'sample_1440.npz', 'sample_1441.npz', 'sample_1442.npz', 'sample_1443.npz', 'sample_1444.npz', 'sample_1445.npz', 'sample_1446.npz', 'sample_1447.npz', 'sample_1448.npz', 'sample_1449.npz', 'sample_1450.npz', 'sample_1451.npz', 'sample_1452.npz', 'sample_1453.npz', 'sample_1454.npz', 'sample_1455.npz', 'sample_1456.npz', 'sample_1457.npz', 'sample_1458.npz', 'sample_1459.npz', 'sample_1460.npz', 'sample_1461.npz', 'sample_1462.npz', 'sample_1463.npz', 'sample_1464.npz', 'sample_1465.npz', 'sample_1466.npz', 'sample_1467.npz', 'sample_1468.npz', 'sample_1469.npz', 'sample_1470.npz', 'sample_1471.npz', 'sample_1472.npz', 'sample_1473.npz', 'sample_1474.npz', 'sample_1475.npz', 'sample_1476.npz', 'sample_1477.npz', 'sample_1478.npz', 'sample_1479.npz', 'sample_1480.npz', 'sample_1481.npz', 'sample_1482.npz', 'sample_1483.npz', 'sample_1484.npz', 'sample_1485.npz', 'sample_1486.npz', 'sample_1487.npz', 'sample_1488.npz', 'sample_1489.npz', 'sample_1490.npz', 'sample_1491.npz', 'sample_1492.npz', 'sample_1493.npz', 'sample_1494.npz', 'sample_1495.npz', 'sample_1496.npz', 'sample_1497.npz', 'sample_1498.npz', 'sample_1499.npz', 'sample_1500.npz', 'sample_1501.npz', 'sample_1502.npz', 'sample_1503.npz', 'sample_1504.npz', 'sample_1505.npz', 'sample_1506.npz', 'sample_1507.npz', 'sample_1508.npz', 'sample_1509.npz', 'sample_1510.npz', 'sample_1511.npz', 'sample_1512.npz', 'sample_1513.npz', 'sample_1514.npz', 'sample_1515.npz', 'sample_1516.npz', 'sample_1517.npz', 'sample_1518.npz', 'sample_1519.npz', 'sample_1520.npz', 'sample_1521.npz', 'sample_1522.npz', 'sample_1523.npz', 'sample_1524.npz', 'sample_1525.npz', 'sample_1526.npz', 'sample_1527.npz', 'sample_1528.npz', 'sample_1529.npz', 'sample_1530.npz', 'sample_1531.npz', 'sample_1532.npz', 'sample_1533.npz', 'sample_1534.npz', 'sample_1535.npz', 'sample_1536.npz', 'sample_1537.npz', 'sample_1538.npz', 'sample_1539.npz', 'sample_1540.npz', 'sample_1541.npz', 'sample_1542.npz', 'sample_1543.npz', 'sample_1544.npz', 'sample_1545.npz', 'sample_1546.npz', 'sample_1547.npz', 'sample_1548.npz', 'sample_1549.npz', 'sample_1550.npz', 'sample_1551.npz', 'sample_1552.npz', 'sample_1553.npz', 'sample_1554.npz', 'sample_1555.npz', 'sample_1556.npz', 'sample_1557.npz', 'sample_1558.npz', 'sample_1559.npz', 'sample_1560.npz', 'sample_1561.npz', 'sample_1562.npz', 'sample_1563.npz', 'sample_1564.npz', 'sample_1565.npz', 'sample_1566.npz', 'sample_1567.npz', 'sample_1568.npz', 'sample_1569.npz', 'sample_1570.npz', 'sample_1571.npz', 'sample_1572.npz', 'sample_1573.npz', 'sample_1574.npz', 'sample_1575.npz', 'sample_1576.npz', 'sample_1577.npz', 'sample_1578.npz', 'sample_1579.npz', 'sample_1580.npz', 'sample_1581.npz', 'sample_1582.npz', 'sample_1583.npz', 'sample_1584.npz', 'sample_1585.npz', 'sample_1586.npz', 'sample_1587.npz', 'sample_1588.npz', 'sample_1589.npz', 'sample_1590.npz', 'sample_1591.npz', 'sample_1592.npz', 'sample_1593.npz', 'sample_1594.npz', 'sample_1595.npz', 'sample_1596.npz', 'sample_1597.npz', 'sample_1598.npz', 'sample_1599.npz', 'sample_1600.npz', 'sample_1601.npz', 'sample_1602.npz', 'sample_1603.npz', 'sample_1604.npz', 'sample_1605.npz', 'sample_1606.npz', 'sample_1607.npz', 'sample_1608.npz', 'sample_1609.npz', 'sample_1610.npz', 'sample_1611.npz', 'sample_1612.npz', 'sample_1613.npz', 'sample_1614.npz', 'sample_1615.npz', 'sample_1616.npz', 'sample_1617.npz', 'sample_1618.npz', 'sample_1619.npz', 'sample_1620.npz', 'sample_1621.npz', 'sample_1622.npz', 'sample_1623.npz', 'sample_1624.npz', 'sample_1625.npz', 'sample_1626.npz', 'sample_1627.npz', 'sample_1628.npz', 'sample_1629.npz', 'sample_1630.npz', 'sample_1631.npz', 'sample_1632.npz', 'sample_1633.npz', 'sample_1634.npz', 'sample_1635.npz', 'sample_1636.npz', 'sample_1637.npz', 'sample_1638.npz', 'sample_1639.npz', 'sample_1640.npz', 'sample_1641.npz', 'sample_1642.npz', 'sample_1643.npz', 'sample_1644.npz', 'sample_1645.npz', 'sample_1646.npz', 'sample_1647.npz', 'sample_1648.npz', 'sample_1649.npz', 'sample_1650.npz', 'sample_1651.npz', 'sample_1652.npz', 'sample_1653.npz', 'sample_1654.npz', 'sample_1655.npz', 'sample_1656.npz', 'sample_1657.npz', 'sample_1658.npz', 'sample_1659.npz', 'sample_1660.npz', 'sample_1661.npz', 'sample_1662.npz', 'sample_1663.npz', 'sample_1664.npz', 'sample_1665.npz', 'sample_1666.npz', 'sample_1667.npz', 'sample_1668.npz', 'sample_1669.npz', 'sample_1670.npz', 'sample_1671.npz', 'sample_1672.npz', 'sample_1673.npz', 'sample_1674.npz', 'sample_1675.npz', 'sample_1676.npz', 'sample_1677.npz', 'sample_1678.npz', 'sample_1679.npz', 'sample_1680.npz', 'sample_1681.npz', 'sample_1682.npz', 'sample_1683.npz', 'sample_1684.npz', 'sample_1685.npz', 'sample_1686.npz', 'sample_1687.npz', 'sample_1688.npz', 'sample_1689.npz', 'sample_1690.npz', 'sample_1691.npz', 'sample_1692.npz', 'sample_1693.npz', 'sample_1694.npz', 'sample_1695.npz', 'sample_1696.npz', 'sample_1697.npz', 'sample_1698.npz', 'sample_1699.npz', 'sample_1700.npz', 'sample_1701.npz', 'sample_1702.npz', 'sample_1703.npz', 'sample_1704.npz', 'sample_1705.npz', 'sample_1706.npz', 'sample_1707.npz', 'sample_1708.npz', 'sample_1709.npz', 'sample_1710.npz', 'sample_1711.npz', 'sample_1712.npz', 'sample_1713.npz', 'sample_1714.npz', 'sample_1715.npz', 'sample_1716.npz', 'sample_1717.npz', 'sample_1718.npz', 'sample_1719.npz', 'sample_1720.npz', 'sample_1721.npz', 'sample_1722.npz', 'sample_1723.npz', 'sample_1724.npz', 'sample_1725.npz', 'sample_1726.npz', 'sample_1727.npz', 'sample_1728.npz', 'sample_1729.npz', 'sample_1730.npz', 'sample_1731.npz', 'sample_1732.npz', 'sample_1733.npz', 'sample_1734.npz', 'sample_1735.npz', 'sample_1736.npz', 'sample_1737.npz', 'sample_1738.npz', 'sample_1739.npz', 'sample_1740.npz', 'sample_1741.npz', 'sample_1742.npz', 'sample_1743.npz', 'sample_1744.npz', 'sample_1745.npz', 'sample_1746.npz', 'sample_1747.npz', 'sample_1748.npz', 'sample_1749.npz', 'sample_1750.npz', 'sample_1751.npz', 'sample_1752.npz', 'sample_1753.npz', 'sample_1754.npz', 'sample_1755.npz', 'sample_1756.npz', 'sample_1757.npz', 'sample_1758.npz', 'sample_1759.npz', 'sample_1760.npz', 'sample_1761.npz', 'sample_1762.npz', 'sample_1763.npz', 'sample_1764.npz', 'sample_1765.npz', 'sample_1766.npz', 'sample_1767.npz', 'sample_1768.npz', 'sample_1769.npz', 'sample_1770.npz', 'sample_1771.npz', 'sample_1772.npz', 'sample_1773.npz', 'sample_1774.npz', 'sample_1775.npz', 'sample_1776.npz', 'sample_1777.npz', 'sample_1778.npz', 'sample_1779.npz', 'sample_1780.npz', 'sample_1781.npz', 'sample_1782.npz', 'sample_1783.npz', 'sample_1784.npz', 'sample_1785.npz', 'sample_1786.npz', 'sample_1787.npz', 'sample_1788.npz', 'sample_1789.npz', 'sample_1790.npz', 'sample_1791.npz', 'sample_1792.npz', 'sample_1793.npz', 'sample_1794.npz', 'sample_1795.npz', 'sample_1796.npz', 'sample_1797.npz', 'sample_1798.npz', 'sample_1799.npz', 'sample_1800.npz', 'sample_1801.npz', 'sample_1802.npz', 'sample_1803.npz', 'sample_1804.npz', 'sample_1805.npz', 'sample_1806.npz', 'sample_1807.npz', 'sample_1808.npz', 'sample_1809.npz', 'sample_1810.npz', 'sample_1811.npz', 'sample_1812.npz', 'sample_1813.npz', 'sample_1814.npz', 'sample_1815.npz', 'sample_1816.npz', 'sample_1817.npz', 'sample_1818.npz', 'sample_1819.npz', 'sample_1820.npz', 'sample_1821.npz', 'sample_1822.npz', 'sample_1823.npz', 'sample_1824.npz', 'sample_1825.npz', 'sample_1826.npz', 'sample_1827.npz', 'sample_1828.npz', 'sample_1829.npz', 'sample_1830.npz', 'sample_1831.npz', 'sample_1832.npz', 'sample_1833.npz', 'sample_1834.npz', 'sample_1835.npz', 'sample_1836.npz', 'sample_1837.npz', 'sample_1838.npz', 'sample_1839.npz', 'sample_1840.npz', 'sample_1841.npz', 'sample_1842.npz', 'sample_1843.npz', 'sample_1844.npz', 'sample_1845.npz', 'sample_1846.npz', 'sample_1847.npz', 'sample_1848.npz', 'sample_1849.npz', 'sample_1850.npz', 'sample_1851.npz', 'sample_1852.npz', 'sample_1853.npz', 'sample_1854.npz', 'sample_1855.npz', 'sample_1856.npz', 'sample_1857.npz', 'sample_1858.npz', 'sample_1859.npz', 'sample_1860.npz', 'sample_1861.npz', 'sample_1862.npz', 'sample_1863.npz', 'sample_1864.npz', 'sample_1865.npz', 'sample_1866.npz', 'sample_1867.npz', 'sample_1868.npz', 'sample_1869.npz', 'sample_1870.npz', 'sample_1871.npz', 'sample_1872.npz', 'sample_1873.npz', 'sample_1874.npz', 'sample_1875.npz', 'sample_1876.npz', 'sample_1877.npz', 'sample_1878.npz', 'sample_1879.npz', 'sample_1880.npz', 'sample_1881.npz', 'sample_1882.npz', 'sample_1883.npz', 'sample_1884.npz', 'sample_1885.npz', 'sample_1886.npz', 'sample_1887.npz', 'sample_1888.npz', 'sample_1889.npz', 'sample_1890.npz', 'sample_1891.npz', 'sample_1892.npz', 'sample_1893.npz', 'sample_1894.npz', 'sample_1895.npz', 'sample_1896.npz', 'sample_1897.npz', 'sample_1898.npz', 'sample_1899.npz', 'sample_1900.npz', 'sample_1901.npz', 'sample_1902.npz', 'sample_1903.npz', 'sample_1904.npz', 'sample_1905.npz', 'sample_1906.npz', 'sample_1907.npz', 'sample_1908.npz', 'sample_1909.npz', 'sample_1910.npz', 'sample_1911.npz', 'sample_1912.npz', 'sample_1913.npz', 'sample_1914.npz', 'sample_1915.npz', 'sample_1916.npz', 'sample_1917.npz', 'sample_1918.npz', 'sample_1919.npz', 'sample_1920.npz', 'sample_1921.npz', 'sample_1922.npz', 'sample_1923.npz', 'sample_1924.npz', 'sample_1925.npz', 'sample_1926.npz', 'sample_1927.npz', 'sample_1928.npz', 'sample_1929.npz', 'sample_1930.npz', 'sample_1931.npz', 'sample_1932.npz', 'sample_1933.npz', 'sample_1934.npz', 'sample_1935.npz', 'sample_1936.npz', 'sample_1937.npz', 'sample_1938.npz', 'sample_1939.npz', 'sample_1940.npz', 'sample_1941.npz', 'sample_1942.npz', 'sample_1943.npz', 'sample_1944.npz', 'sample_1945.npz', 'sample_1946.npz', 'sample_1947.npz', 'sample_1948.npz', 'sample_1949.npz', 'sample_1950.npz', 'sample_1951.npz', 'sample_1952.npz', 'sample_1953.npz', 'sample_1954.npz', 'sample_1955.npz', 'sample_1956.npz', 'sample_1957.npz', 'sample_1958.npz', 'sample_1959.npz', 'sample_1960.npz', 'sample_1961.npz', 'sample_1962.npz', 'sample_1963.npz', 'sample_1964.npz', 'sample_1965.npz', 'sample_1966.npz', 'sample_1967.npz', 'sample_1968.npz', 'sample_1969.npz', 'sample_1970.npz', 'sample_1971.npz', 'sample_1972.npz', 'sample_1973.npz', 'sample_1974.npz', 'sample_1975.npz', 'sample_1976.npz', 'sample_1977.npz', 'sample_1978.npz', 'sample_1979.npz', 'sample_1980.npz', 'sample_1981.npz', 'sample_1982.npz', 'sample_1983.npz', 'sample_1984.npz', 'sample_1985.npz', 'sample_1986.npz', 'sample_1987.npz', 'sample_1988.npz', 'sample_1989.npz', 'sample_1990.npz', 'sample_1991.npz', 'sample_1992.npz', 'sample_1993.npz', 'sample_1994.npz', 'sample_1995.npz', 'sample_1996.npz', 'sample_1997.npz', 'sample_1998.npz', 'sample_1999.npz', 'sample_2000.npz', 'sample_2001.npz', 'sample_2002.npz', 'sample_2003.npz', 'sample_2004.npz', 'sample_2005.npz', 'sample_2006.npz', 'sample_2007.npz', 'sample_2008.npz', 'sample_2009.npz', 'sample_2010.npz', 'sample_2011.npz', 'sample_2012.npz', 'sample_2013.npz', 'sample_2014.npz', 'sample_2015.npz', 'sample_2016.npz', 'sample_2017.npz', 'sample_2018.npz', 'sample_2019.npz', 'sample_2020.npz', 'sample_2021.npz', 'sample_2022.npz', 'sample_2023.npz', 'sample_2024.npz', 'sample_2025.npz', 'sample_2026.npz', 'sample_2027.npz', 'sample_2028.npz', 'sample_2029.npz', 'sample_2030.npz', 'sample_2031.npz', 'sample_2032.npz', 'sample_2033.npz', 'sample_2034.npz', 'sample_2035.npz', 'sample_2036.npz', 'sample_2037.npz', 'sample_2038.npz', 'sample_2039.npz', 'sample_2040.npz', 'sample_2041.npz', 'sample_2042.npz', 'sample_2043.npz', 'sample_2044.npz', 'sample_2045.npz', 'sample_2046.npz', 'sample_2047.npz']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58f1f3f440e48269c023de5e51d2e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 128/2048 files\n",
      "Loaded 256/2048 files\n",
      "Loaded 384/2048 files\n",
      "Loaded 512/2048 files\n",
      "Loaded 640/2048 files\n",
      "Loaded 768/2048 files\n",
      "Loaded 896/2048 files\n",
      "Loaded 1024/2048 files\n",
      "Loaded 1152/2048 files\n",
      "Loaded 1280/2048 files\n",
      "Loaded 1408/2048 files\n",
      "Loaded 1536/2048 files\n",
      "Loaded 1664/2048 files\n",
      "Loaded 1792/2048 files\n",
      "Loaded 1920/2048 files\n",
      "Loaded 2048/2048 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from scripts.locate_via_attention_behavior import SelectionSampleAttn\n",
    "\n",
    "attn_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/attention_patterns/select_one\",\n",
    "    # mt.name.split(\"/\")[-1],\n",
    "    model_key.split(\"/\")[-1],\n",
    "    \"objects\"\n",
    ")\n",
    "files = sorted(os.listdir(attn_path))\n",
    "print(files)\n",
    "\n",
    "#######################################################################\n",
    "# LIMIT = 128\n",
    "LIMIT = len(files)\n",
    "#######################################################################\n",
    "\n",
    "selection_attns = []\n",
    "\n",
    "for npz_file in tqdm(files[:LIMIT]):\n",
    "    if not npz_file.endswith(\".npz\"):\n",
    "        continue\n",
    "\n",
    "    npz_path = os.path.join(attn_path, npz_file)\n",
    "    selection_attns.append(SelectionSampleAttn.from_npz(npz_path))\n",
    "    if len(selection_attns) % 128 == 0:\n",
    "        print(f\"Loaded {len(selection_attns)}/{LIMIT} files\")\n",
    "\n",
    "len(selection_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e494e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.784423828125, 0.8125, [0.013607025146484375, 0.000949859619140625, 0.028076171875, 0.006317138671875, 0.01116943359375])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-acc7d0b3-4c22\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-acc7d0b3-4c22\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Sub\", \"marine\", \",\", \" Microwave\", \",\", \" Hospital\", \",\", \" Coffee\", \" table\", \",\", \" Binder\", \",\", \" Comb\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" kitchen\", \" appliance\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.0026092529296875, 4.458427429199219e-05, 0.000423431396484375, 0.01318359375, 0.00933837890625, 0.8125, 0.07568359375, 0.000949859619140625, 0.0028533935546875, 0.0194091796875, 0.0086669921875, 0.0023956298828125, 0.006317138671875, 0.006927490234375, 0.01116943359375, 0.000789642333984375, 2.0384788513183594e-05, 1.1265277862548828e-05, 3.075599670410156e-05, 0.00024127960205078125, 5.841255187988281e-06, 2.0265579223632812e-06, 1.800060272216797e-05, 0.00109100341796875, 0.000415802001953125, 0.0025787353515625, 0.00018787384033203125, 5.841255187988281e-06, 0.0004863739013671875]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f9fa11aa1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.attention import visualize_attn_matrix\n",
    "\n",
    "sample_idx = 3\n",
    "\n",
    "layer_idx, head_idx = 35, 19 # llama-70B\n",
    "# layer_idx, head_idx = 54, 44 # qwen-72B\n",
    "# layer_idx, head_idx = 51, 11 # qwen-32B\n",
    "# layer_idx, head_idx = 29, 3 # gemma-27b\n",
    "\n",
    "\n",
    "selection_attn = selection_attns[sample_idx]\n",
    "print(selection_attn.resolution_score(layer_idx, head_idx))\n",
    "visualize_attn_matrix(\n",
    "    attn_matrix=selection_attn.attention_pattern.attention_matrices[layer_idx, head_idx],\n",
    "    tokens=selection_attn.attention_pattern.tokenized_prompt,\n",
    "    q_index=-1,\n",
    "    start_from=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2c5eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 64, 30, 30)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_attns[0].attention_pattern.attention_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80f22968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.056003570556640625,\n",
       " 2.0927734375,\n",
       " 0.0099639892578125,\n",
       " 0.076690673828125,\n",
       " 0.03558349609375,\n",
       " 0.03022003173828125]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_attn.score_per_option(\n",
    "    layer_idx=35, head_idx=19, query_idx=-1, \n",
    "    value_weighted=True,\n",
    "    include_delim=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28d6cd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.016082763671875,\n",
       " 2.0927734375,\n",
       " [0.056003570556640625,\n",
       "  0.0099639892578125,\n",
       "  0.076690673828125,\n",
       "  0.03558349609375,\n",
       "  0.03022003173828125])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_attn.resolution_score(\n",
    "    layer_idx=35, head_idx=19, query_idx=-1,\n",
    "    value_weighted=True,\n",
    "    include_delim=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0631f96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Options: Submarine, Microwave, Hospital, Coffee table, Binder, Comb.\\nWhich among these objects mentioned above is a kitchen appliance?\\nAnswer:'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_attn.sample.prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5d48a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7741888bf77346c3a46153523af2d2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 80])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "#############################################################################\n",
    "n_layer = selection_attns[0].attention_pattern.attention_matrices.shape[0]\n",
    "n_head = selection_attns[0].attention_pattern.attention_matrices.shape[1]\n",
    "token_idx = \"all\"\n",
    "# token_idx = \"last\"\n",
    "##############################################################################\n",
    "\n",
    "resolution_scores = torch.zeros((n_head, n_layer), dtype=torch.float32)\n",
    "for selection_attn in tqdm(selection_attns):\n",
    "    for layer_idx in range(n_layer):\n",
    "        for head_idx in range(n_head):\n",
    "            resolution_scores[head_idx, layer_idx] += selection_attn.resolution_score(\n",
    "                layer_idx, head_idx, token_idx=token_idx,\n",
    "                # value_weighted=True,\n",
    "                include_delim=True\n",
    "            )[0]\n",
    "            # resolution_scores[head_idx, layer_idx] += selection_attn.first_token_score(\n",
    "            #     layer_idx, head_idx\n",
    "            # )[0]\n",
    "\n",
    "resolution_scores /= len(selection_attns)\n",
    "resolution_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d417ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13 20:42:27 matplotlib.colorbar DEBUG    locator: <matplotlib.ticker.AutoLocator object at 0x7fb5e1907f50>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 52, Head 19: 0.7359\n",
      "Layer 31, Head 38: 0.6496\n",
      "Layer 47, Head 17: 0.6041\n",
      "Layer 35, Head 19: 0.5826\n",
      "Layer 56, Head 3: 0.5629\n",
      "Layer 33, Head 18: 0.5513\n",
      "Layer 39, Head 40: 0.5512\n",
      "Layer 47, Head 18: 0.4940\n",
      "Layer 34, Head 1: 0.4678\n",
      "Layer 74, Head 7: 0.4647\n",
      "Layer 35, Head 43: 0.3893\n",
      "Layer 52, Head 17: 0.3553\n",
      "Layer 34, Head 6: 0.3361\n",
      "Layer 49, Head 2: 0.3102\n",
      "Layer 31, Head 39: 0.3061\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "scale = torch.max(torch.abs(resolution_scores))\n",
    "plt.imshow(\n",
    "    resolution_scores.cpu().numpy(),\n",
    "    cmap=\"RdBu\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=-scale,\n",
    "    vmax=scale,\n",
    ")\n",
    "plt.colorbar()\n",
    "# plt.title(f\"score(target) - max(score(distractors)) | {token_idx.upper()} tokens of options\")\n",
    "plt.title(\"score(target[0]) - sum(score(target[1:]))\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Head\")\n",
    "\n",
    "def get_ticks(ticks, skip=5):\n",
    "    ret = []\n",
    "    for i in ticks:\n",
    "        if i % skip == 0:\n",
    "            ret.append(str(i))\n",
    "        else:\n",
    "            ret.append(\"\")\n",
    "    return ret\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=range(n_layer),\n",
    "    labels=get_ticks(range(n_layer)),\n",
    "    rotation=45,\n",
    ")\n",
    "plt.yticks(\n",
    "    ticks=range(n_head),\n",
    "    labels=get_ticks(range(n_head), skip=4),\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "scores_per_head = []\n",
    "for head_idx in range(n_head):\n",
    "    for layer_idx in range(n_layer):\n",
    "        scores_per_head.append(\n",
    "            (head_idx, layer_idx, resolution_scores[head_idx, layer_idx].item())\n",
    "        )\n",
    "\n",
    "scores_per_head = sorted(scores_per_head, key=lambda x: x[2], reverse=True)\n",
    "for head_idx, layer_idx, score in scores_per_head[:15]:\n",
    "    print(f\"Layer {layer_idx}, Head {head_idx}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "172712e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19, 52), (38, 31), (17, 47), (19, 35), (3, 56), (18, 33), (40, 39), (18, 47), (1, 34), (7, 74), (43, 35), (17, 52), (6, 34), (2, 49), (39, 31), (61, 52), (58, 52), (40, 35), (1, 53), (17, 35), (56, 29), (41, 39), (43, 39), (40, 28), (36, 52), (8, 54), (28, 37), (4, 34), (59, 63), (47, 33), (45, 28), (31, 64), (27, 64), (7, 34), (46, 36), (20, 56), (11, 39), (61, 29), (52, 38), (62, 73), (48, 68), (34, 31), (45, 39), (5, 49), (4, 53), (30, 42), (13, 29), (39, 72), (33, 31), (45, 33), (29, 37), (37, 34), (37, 31), (34, 50), (7, 53), (48, 30), (20, 35), (30, 64), (40, 44), (11, 33), (9, 37), (55, 68), (32, 31), (21, 33), (3, 53), (3, 49), (42, 35), (0, 34), (35, 39), (24, 37), (63, 67), (45, 34), (1, 56), (25, 37), (14, 33), (36, 37), (26, 54), (25, 64), (41, 56), (23, 38), (43, 28), (45, 31), (43, 31), (37, 52), (15, 33), (23, 75), (44, 39), (4, 49), (18, 38), (35, 37), (31, 31), (28, 75), (51, 31), (46, 35), (31, 42), (35, 30), (22, 52), (36, 31), (33, 34), (0, 53)]\n"
     ]
    }
   ],
   "source": [
    "heads_attn_behavior = [(layer_idx, head_idx) for layer_idx, head_idx, score in scores_per_head[:100]]\n",
    "print(heads_attn_behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac057c5",
   "metadata": {},
   "source": [
    "#### Based on Patching Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d18ed5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: objects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa8b5501a4f4dadad0e5ce319833686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scripts.patching_within_task import SelectionQprojPatchResult\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "q_proj_root = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/q_states_patching_old\",\n",
    "    # mt.name.split(\"/\")[-1],\n",
    "    model_key.split(\"/\")[-1],\n",
    ")\n",
    "\n",
    "#############################################\n",
    "# LIMIT = 20\n",
    "LIMIT = None\n",
    "# n_layer = mt.n_layer\n",
    "# n_head = mt.config.num_attention_heads\n",
    "categories = [\n",
    "    # \"profession\",\n",
    "    # \"nationality\",\n",
    "    \"objects\",\n",
    "]\n",
    "#############################################\n",
    "\n",
    "q_proj_results = {cat: [] for cat in categories}\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"category: {category}\")\n",
    "    q_proj_path = os.path.join(q_proj_root, category)\n",
    "    files = sorted(os.listdir(q_proj_path))\n",
    "    LIMIT = LIMIT or len(files)\n",
    "    q_proj_results[category] = []\n",
    "    for file in tqdm(files[:LIMIT]):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(q_proj_path, file)\n",
    "        q_proj_results[category].append(SelectionQprojPatchResult.load_from_json(file_path))\n",
    "        # if len(q_proj_results) % 10 == 0:\n",
    "        #     print(f\"Loaded {len(q_proj_results)}/{LIMIT} files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41757b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# combine_all_results = []\n",
    "# for category in categories:\n",
    "#     combine_all_results.extend(q_proj_results[category])\n",
    "# results_copy = copy.deepcopy(q_proj_results)\n",
    "# results_copy[\"all\"] = combine_all_results\n",
    "\n",
    "results_copy = q_proj_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b8f24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results_copy[\"objects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4c8d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = results_copy[\"objects\"][0].headwise_patching_effects.keys()\n",
    "layers = set([layer for layer, head in heads])\n",
    "heads = set([head for layer, head in heads])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b809f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13 22:46:23 matplotlib.colorbar DEBUG    locator: <matplotlib.ticker.AutoLocator object at 0x7f9eb99f0710>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 35, Head 19: 0.3127\n",
      "Layer 31, Head 38: 0.1344\n",
      "Layer 39, Head 45: 0.1280\n",
      "Layer 39, Head 40: 0.1267\n",
      "Layer 35, Head 17: 0.1187\n",
      "Layer 35, Head 43: 0.1093\n",
      "Layer 39, Head 43: 0.0782\n",
      "Layer 35, Head 40: 0.0585\n",
      "Layer 49, Head 2: 0.0557\n",
      "Layer 35, Head 20: 0.0431\n",
      "Layer 31, Head 39: 0.0375\n",
      "Layer 64, Head 27: 0.0333\n",
      "Layer 35, Head 18: 0.0262\n",
      "Layer 29, Head 56: 0.0206\n",
      "Layer 42, Head 31: 0.0205\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "n_layer = len(layers)\n",
    "n_heads = len(heads)\n",
    "\n",
    "category_wise_heads = {}\n",
    "for category, categorywise_result in results_copy.items():\n",
    "    indirect_effects = torch.zeros((n_layer, n_heads), dtype=torch.float32)\n",
    "    for layer_idx in range(n_layer):\n",
    "        for head_idx in range(n_heads):\n",
    "            indirect_effects[layer_idx, head_idx] = torch.mean(\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        sample_result.head_effect(layer_idx, head_idx)\n",
    "                        for sample_result in categorywise_result\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    scale = torch.max(torch.abs(indirect_effects))\n",
    "    plt.imshow(\n",
    "        indirect_effects.T.cpu().numpy(),\n",
    "        cmap=\"RdBu\",\n",
    "        aspect=\"auto\",\n",
    "        # vmin=-scale,\n",
    "        # vmax=scale,\n",
    "        vmin=-0.1,\n",
    "        vmax=0.1\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    # plt.title(f\"score(target) - max(score(distractors)) | {token_idx.upper()} tokens of options\")\n",
    "    plt.title(\"IE of q_proj patching | \" + category)\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Head\")\n",
    "\n",
    "    def get_ticks(ticks, skip=5):\n",
    "        ret = []\n",
    "        for i in ticks:\n",
    "            if i % skip == 0:\n",
    "                ret.append(str(i))\n",
    "            else:\n",
    "                ret.append(\"\")\n",
    "        return ret\n",
    "\n",
    "    plt.xticks(\n",
    "        ticks=range(n_layer),\n",
    "        labels=get_ticks(range(n_layer)),\n",
    "        rotation=45,\n",
    "    )\n",
    "    plt.yticks(\n",
    "        ticks=range(n_head),\n",
    "        labels=get_ticks(range(n_head), skip=4),\n",
    "    )\n",
    "\n",
    "    # # Get the current axes\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Draw borders around marked cells\n",
    "    for (x, y) in optimized_heads:\n",
    "        # Create a Rectangle patch\n",
    "        # Note: (x-0.5, y-0.5) positions the rectangle correctly around the cell\n",
    "        # Width and height of 1 covers exactly one cell\n",
    "        rect = patches.Rectangle(\n",
    "            (x - 0.5, y - 0.5),  # bottom-left corner\n",
    "            1,                     # width\n",
    "            1,                     # height\n",
    "            linewidth=1.5,          # border thickness\n",
    "            edgecolor='black',    # border color (you can change this)\n",
    "            facecolor='none'      # no fill, just border\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    scores_per_head = []\n",
    "    for layer_idx in layers:\n",
    "        for head_idx in heads:\n",
    "            scores_per_head.append(\n",
    "                (layer_idx, head_idx, indirect_effects[layer_idx, head_idx].item())\n",
    "            )\n",
    "\n",
    "    scores_per_head = sorted(scores_per_head, key=lambda x: x[2], reverse=True)\n",
    "    category_wise_heads[category] = scores_per_head\n",
    "    for layer_idx, head_idx, score in scores_per_head[:15]:\n",
    "        print(f\"Layer {layer_idx}, Head {head_idx}: {score:.4f}\")\n",
    "\n",
    "with open(\"category_wise_heads.json\", \"w\") as f:\n",
    "    json.dump(category_wise_heads, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8dd99c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 35, Head 19: 0.3127\n",
      "Layer 31, Head 38: 0.1344\n",
      "Layer 39, Head 45: 0.1280\n",
      "Layer 39, Head 40: 0.1267\n",
      "Layer 35, Head 17: 0.1187\n",
      "Layer 35, Head 43: 0.1093\n",
      "Layer 39, Head 43: 0.0782\n",
      "Layer 35, Head 40: 0.0585\n",
      "Layer 49, Head 2: 0.0557\n",
      "Layer 35, Head 20: 0.0431\n",
      "Layer 31, Head 39: 0.0375\n",
      "Layer 64, Head 27: 0.0333\n",
      "Layer 35, Head 18: 0.0262\n",
      "Layer 29, Head 56: 0.0206\n",
      "Layer 42, Head 31: 0.0205\n"
     ]
    }
   ],
   "source": [
    "for layer_idx, head_idx, score in scores_per_head[:15]:\n",
    "    print(f\"Layer {layer_idx}, Head {head_idx}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff71ba6",
   "metadata": {},
   "source": [
    "#### Performing the Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c99868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "# HEADS = [\n",
    "#     (33, 45),\n",
    "#     (33, 18),\n",
    "#     (34, 1),\n",
    "#     (34, 6),\n",
    "#     (34, 7),\n",
    "#     (35, 19),\n",
    "#     (39, 40),\n",
    "#     (42, 30),\n",
    "#     (47, 18),\n",
    "#     (52, 58),\n",
    "# ]\n",
    "\n",
    "# HEADS = [\n",
    "#     (layer_idx, head_idx)\n",
    "#     for layer_idx, head_idx, score in category_wise_heads[\"all\"][:50]\n",
    "# ]\n",
    "\n",
    "# HEADS = heads_selected\n",
    "\n",
    "clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "patch_tokenized = prepare_input(prompts=patch_sample.prompt(), tokenizer=mt)\n",
    "\n",
    "# category_wise_heads[\"all\"][len(HEADS) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98815bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.typing import TokenizerOutput\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def cache_q_projections(\n",
    "    mt: ModelandTokenizer,\n",
    "    input: TokenizerOutput,\n",
    "    query_locations: list[tuple[int, int, int]],  # (layer_idx, head_idx, query_idx)\n",
    "    return_output: bool = False,\n",
    "):\n",
    "    layer_to_hq = {}\n",
    "    for layer_idx, head_idx, query_idx in query_locations:\n",
    "        if layer_idx not in layer_to_hq:\n",
    "            layer_to_hq[layer_idx] = []\n",
    "        layer_to_hq[layer_idx].append((head_idx, query_idx))\n",
    "\n",
    "    q_projections = {}\n",
    "    batch_size = input.input_ids.shape[0]\n",
    "    seq_len = input.input_ids.shape[1]\n",
    "    n_heads = mt.config.num_attention_heads\n",
    "    head_dim = mt.n_embd // n_heads\n",
    "    with mt.trace(input) as tracer:\n",
    "        for layer_idx, query_locs in layer_to_hq.items():\n",
    "            q_proj_name = mt.attn_module_name_format.format(layer_idx) + \".q_proj\"\n",
    "            q_proj_module = get_module_nnsight(mt, q_proj_name)\n",
    "            q_proj_out = q_proj_module.output.view(\n",
    "                batch_size, seq_len, n_heads, head_dim\n",
    "            ).transpose(1, 2)\n",
    "            for head_idx, query_idx in query_locs:\n",
    "                q_projections[(layer_idx, head_idx, query_idx)] = (\n",
    "                    q_proj_out[:, head_idx, query_idx, :].squeeze().save()\n",
    "                )\n",
    "\n",
    "        if return_output:\n",
    "            output = mt.output.save()\n",
    "\n",
    "    if return_output:\n",
    "        return q_projections, output\n",
    "    return q_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_indices = list(range(-3, 0))\n",
    "query_locations = [\n",
    "    (layer_idx, head_idx, query_idx)\n",
    "    for layer_idx, head_idx in HEADS\n",
    "    for query_idx in query_indices\n",
    "]\n",
    "\n",
    "cached_q_states = cache_q_projections(\n",
    "    mt=mt,\n",
    "    input=patch_tokenized,\n",
    "    query_locations=query_locations,\n",
    ")\n",
    "\n",
    "# cached_q_states[(HEADS[0])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5508d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attention import get_attention_matrices, visualize_attn_matrix\n",
    "from src.functional import interpret_logits\n",
    "\n",
    "clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "\n",
    "# attn_info = get_attention_matrices(\n",
    "#     input=clean_tokenized,\n",
    "#     mt=mt,\n",
    "# )\n",
    "\n",
    "# layer_idx, head_idx = 35, 19\n",
    "# attn_matrix = attn_info.attention_matrices[layer_idx, head_idx].squeeze()\n",
    "# visualize_attn_matrix(\n",
    "#     attn_matrix=attn_matrix,\n",
    "#     tokens=[mt.tokenizer.decode(t) for t in clean_tokenized.input_ids[0]],\n",
    "#     q_index=-1,\n",
    "# )\n",
    "\n",
    "# interpret_logits(\n",
    "#     tokenizer=mt,\n",
    "#     logits=attn_info.logits,\n",
    "#     interested_tokens=[clean_sample.obj_token_id, clean_sample.metadata[\"track_type_obj_token_id\"]]\n",
    "# )\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt = clean_tokenized,\n",
    "    options = clean_sample.options,\n",
    "    pivot = clean_sample.subj,\n",
    "    mt = mt,\n",
    "    heads = HEADS,\n",
    "    # heads = patching_heads,\n",
    "    generate_full_answer=True,\n",
    ")\n",
    "\n",
    "attn_pattern[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attention import get_attention_matrices, visualize_attn_matrix\n",
    "from src.functional import patch_with_nnsight, patch_with_baukit, PatchSpec\n",
    "\n",
    "q_proj_patches = []\n",
    "for (layer_idx, head_idx, query_idx), q_proj in cached_q_states.items():\n",
    "    q_proj_patches.append(\n",
    "        PatchSpec(\n",
    "            location=(mt.attn_module_name_format.format(layer_idx) + \".q_proj\", head_idx, query_idx),\n",
    "            patch=q_proj\n",
    "        )\n",
    "    )\n",
    "\n",
    "# patched_attn_info = get_attention_matrices(\n",
    "#     input=clean_tokenized,\n",
    "#     mt=mt,\n",
    "#     patches=q_proj_patches,\n",
    "#     patch_interface=patch_with_baukit\n",
    "# )\n",
    "\n",
    "# layer_idx, head_idx = 35, 19\n",
    "# patched_attn_matrix = patched_attn_info.attention_matrices[layer_idx, head_idx].squeeze()\n",
    "# visualize_attn_matrix(\n",
    "#     attn_matrix=patched_attn_matrix,\n",
    "#     tokens=[mt.tokenizer.decode(t) for t in clean_tokenized.input_ids[0]],\n",
    "#     q_index=-1,\n",
    "# )\n",
    "\n",
    "# interpret_logits(\n",
    "#     tokenizer=mt,\n",
    "#     logits=patched_attn_info.logits,\n",
    "#     interested_tokens=[clean_sample.obj_token_id, clean_sample.metadata[\"track_type_obj_token_id\"]]\n",
    "# )\n",
    "\n",
    "patched_attn_pattern = verify_head_patterns(\n",
    "    prompt = clean_tokenized,\n",
    "    options = clean_sample.options,\n",
    "    pivot = clean_sample.subj,\n",
    "    mt = mt,\n",
    "    heads = HEADS,\n",
    "    # heads = patching_heads,\n",
    "    query_patches=q_proj_patches,\n",
    "    # generate_full_answer=True,\n",
    ")\n",
    "\n",
    "patched_attn_pattern[\"predictions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972e073",
   "metadata": {},
   "source": [
    "### Search over layers and heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbcd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.patching_within_task import SelectionQprojPatchResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d94c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from src.functional import patch_with_baukit, interpret_logits\n",
    "from src.selection.functional import cache_q_projections\n",
    "\n",
    "all_heads = list(product(range(20, 30), range(mt.config.num_attention_heads)))\n",
    "query_indices = {-3: -3, -2: -2, -1: -1}\n",
    "\n",
    "clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "patch_tokenized = prepare_input(prompts=patch_sample.prompt(), tokenizer=mt)\n",
    "\n",
    "interested_tokens = [\n",
    "    patch_sample.ans_token_id,\n",
    "    clean_sample.ans_token_id,\n",
    "    clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "]\n",
    "\n",
    "\n",
    "query_locations = [\n",
    "    (layer_idx, head_idx, patch_query_idx)\n",
    "    for layer_idx, head_idx in all_heads\n",
    "    for patch_query_idx in query_indices.keys()\n",
    "]\n",
    "\n",
    "all_q_projections, patch_out = cache_q_projections(\n",
    "    mt=mt,\n",
    "    input=patch_tokenized,\n",
    "    query_locations=query_locations,\n",
    "    return_output=True,\n",
    ")\n",
    "logger.debug(len(all_q_projections))\n",
    "\n",
    "patch_logits = patch_out.logits[:, -1, :].squeeze()\n",
    "patch_precitions, patch_track = interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=patch_logits,\n",
    "    interested_tokens=interested_tokens,\n",
    ")\n",
    "\n",
    "patch_precitions, patch_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97dcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_out = patch_with_baukit(\n",
    "    mt=mt,\n",
    "    inputs=clean_tokenized,\n",
    "    patches=[],\n",
    ")\n",
    "\n",
    "base_logits = clean_out.logits[:, -1, :].squeeze()\n",
    "base_predictions, base_track = interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=base_logits,\n",
    "    interested_tokens=interested_tokens,\n",
    ")\n",
    "base_predictions, base_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import PatchSpec\n",
    "q_proj_patches = []\n",
    "for (layer_idx, head_idx, patch_query_idx), q_proj in all_q_projections.items():\n",
    "    q_proj_patches.append(\n",
    "        PatchSpec(\n",
    "            location=(\n",
    "                mt.attn_module_name_format.format(layer_idx) + \".q_proj\",\n",
    "                head_idx,\n",
    "                query_indices[patch_query_idx],\n",
    "            ),\n",
    "            patch=q_proj,\n",
    "        )\n",
    "    )\n",
    "\n",
    "int_out = patch_with_baukit(\n",
    "    mt = mt,\n",
    "    inputs = clean_tokenized,\n",
    "    patches = q_proj_patches,\n",
    ")\n",
    "\n",
    "logits = int_out.logits[:, -1, :].squeeze()\n",
    "\n",
    "interpret_logits(\n",
    "    tokenizer=mt,\n",
    "    logits=logits,\n",
    "    interested_tokens=interested_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dede3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_q_projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_q_projections.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90779a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "head_wise_patching_effects = {}\n",
    "\n",
    "for (layer_idx, head_idx) in tqdm(all_heads):\n",
    "    q_proj_patch = []\n",
    "    for patch_tok_idx, clean_tok_idx in query_indices.items():\n",
    "        q_proj_patch.append(\n",
    "            PatchSpec(\n",
    "                location=(\n",
    "                    mt.attn_module_name_format.format(layer_idx) + \".q_proj\", \n",
    "                    head_idx, \n",
    "                    query_indices[patch_tok_idx]\n",
    "                ),\n",
    "                patch=all_q_projections[(layer_idx, head_idx, patch_tok_idx)]\n",
    "            )\n",
    "        )\n",
    "    out = patch_with_baukit(\n",
    "        mt = mt,\n",
    "        inputs = clean_tokenized,\n",
    "        patches = q_proj_patch,\n",
    "    )\n",
    "    logits = out.logits[:, -1, :].squeeze()\n",
    "    predictions, track = interpret_logits(\n",
    "        tokenizer=mt,\n",
    "        logits=logits,\n",
    "        interested_tokens=interested_tokens\n",
    "    )\n",
    "    head_wise_patching_effects[(layer_idx, head_idx)] = track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results = SelectionQprojPatchResult(\n",
    "    patch_sample=patch_sample,\n",
    "    clean_sample=clean_sample,\n",
    "    interested_tokens=interested_tokens,\n",
    "    base_results=base_track,\n",
    "    gold_results=patch_track,\n",
    "    headwise_patching_effects=head_wise_patching_effects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results.head_effect(layer_idx=25, head_idx=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headwise_scores = [\n",
    "    (\n",
    "        layer_idx,\n",
    "        head_idx,\n",
    "        patching_results.head_effect(layer_idx, head_idx)\n",
    "    )\n",
    "    for layer_idx, head_idx in head_wise_patching_effects.keys()\n",
    "]\n",
    "\n",
    "headwise_scores = sorted(headwise_scores, key=lambda x: x[2], reverse=True)\n",
    "patching_heads = []\n",
    "for layer_idx, head_idx, score in headwise_scores[:15]:\n",
    "    print(f\"Layer {layer_idx}, Head {head_idx}: {score:.4f}\")\n",
    "    patching_heads.append((layer_idx, head_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results.patch_sample.metadata.pop(\"tokenized\")\n",
    "patching_results.clean_sample.metadata.pop(\"tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35265af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results.delist_patching_effects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"patching_results.json\", \"w\") as f:\n",
    "    json.dump(patching_results.to_dict(), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f942ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"patching_results.json\", \"r\") as f:\n",
    "    loaded_results = json.load(f)\n",
    "\n",
    "loaded_results[\"headwise_patching_effects\"] = {\n",
    "    (int(layer_idx.split(\"_<>_\")[0]), int(layer_idx.split(\"_<>_\")[1])): effect\n",
    "    for layer_idx, effect in loaded_results[\"headwise_patching_effects\"].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_results[\"headwise_patching_effects\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e0951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patching_results_loaded = SelectionQprojPatchResult.from_dict(loaded_results)\n",
    "patching_results_loaded.head_effect(layer_idx=25, head_idx=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e661ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.config.num_attention_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891c437",
   "metadata": {},
   "source": [
    "## Optimization to select heads to patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a3e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "train_limit = 512\n",
    "# prompt_template_idx = 1\n",
    "prompt_template_idx = 3\n",
    "N_DISTRACTORS = 5\n",
    "OPTION_STYLE = \"single_line\"\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af4ce17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1 / 512\n",
      "2025-09-15 00:09:52 src.selection.data DEBUG    Options: Dress, Temple, Highlighter, Daffodil, Factory, Iris, Surfboard.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 00:09:52 src.selection.data DEBUG    Options: Shorts, Jasmine, Mosque, Orchid, Football, Paper, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:09:52 src.selection.data DEBUG    Options: Shorts, Jasmine, Mosque, Orchid, Football, Paper, Church.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Orch\n",
      "sample 2 / 512\n",
      "2025-09-15 00:09:56 src.selection.data DEBUG    Options: Train, Bike, Microwave, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:09:56 src.selection.data DEBUG    Options: Dishwasher, Juicer, Ambulance, Van.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "2025-09-15 00:09:56 src.selection.data DEBUG    Options: Dishwasher, Juicer, Ambulance, Van.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Ju\n",
      "sample 3 / 512\n",
      "2025-09-15 00:10:00 src.selection.data DEBUG    Options: Temple, Hospital, Pen, Notebook.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Notebook\n",
      "2025-09-15 00:10:00 src.selection.data DEBUG    Options: Paper, Factory, Paperclip, Library.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "2025-09-15 00:10:00 src.selection.data DEBUG    Options: Paper, Factory, Paperclip, Library.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 4 / 512\n",
      "2025-09-15 00:10:04 src.selection.data DEBUG    Options: Clarinet, Razor, Toilet, Harmonica.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Harmon\n",
      "2025-09-15 00:10:04 src.selection.data DEBUG    Options: Lotion, Flute, Guitar, Bathtub.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:10:04 src.selection.data DEBUG    Options: Lotion, Flute, Guitar, Bathtub.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "sample 5 / 512\n",
      "2025-09-15 00:10:07 src.selection.data DEBUG    Options: Necklace, Tractor, Toilet paper, Shower, Watch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:10:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Necklace', prob=0.53515625, logit=20.0, token_id=86460, metadata=None))[\" Necklace\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:10:08 src.selection.data DEBUG    Options: Mirror, Sink, Cufflink, Daffodil, Chain.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:10:08 src.selection.data DEBUG    Options: Bangle, Hairdryer, Bracelet, Lotion, Lily.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:10:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hair', prob=0.51171875, logit=20.125, token_id=26781, metadata=None))[\" Hair\"] != 445[\" L\"]\n",
      "2025-09-15 00:10:08 src.selection.data DEBUG    Options: Bathtub, Shampoo, Tiara, Helicopter, Pin.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:10:08 src.selection.data DEBUG    Options: Towel, Shower, Earring, Necklace, Yacht.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:10:09 src.selection.data DEBUG    Options: Towel, Shower, Earring, Necklace, Yacht.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "sample 6 / 512\n",
      "2025-09-15 00:10:12 src.selection.data DEBUG    Options: Bat, Golf ball, Watermelon, Recliner, Speaker, Monitor.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:10:13 src.selection.data DEBUG    Options: Laptop, Kiwi, Yoga mat, Phone, Surfboard, Bookshelf.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:10:13 src.selection.data DEBUG    Options: Laptop, Kiwi, Yoga mat, Phone, Surfboard, Bookshelf.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "sample 7 / 512\n",
      "2025-09-15 00:10:16 src.selection.data DEBUG    Options: Anklet, House, Rabbit, Tractor, Mall, Bus.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:10:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' House', prob=0.53515625, logit=19.375, token_id=4783, metadata=None))[\" House\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:10:17 src.selection.data DEBUG    Options: Bike, Theater, Airplane, Camera, Apartment, Hickory.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "2025-09-15 00:10:17 src.selection.data DEBUG    Options: Church, Skyscraper, Train, Redwood, Projector, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:10:17 src.selection.data DEBUG    Options: Church, Skyscraper, Train, Redwood, Projector, Ambulance.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:10:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Church', prob=0.341796875, logit=18.375, token_id=9441, metadata=None))[\" Church\"] != 4923[\" Sk\"]\n",
      "2025-09-15 00:10:17 src.selection.data DEBUG    Options: Train, Mall, Van, Carnation, Church, Asparagus.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:10:18 src.selection.data DEBUG    Options: Skyscraper, Bike, Lettuce, House, Boat, Tulip.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:10:18 src.selection.data DEBUG    Options: Skyscraper, Bike, Lettuce, House, Boat, Tulip.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "sample 8 / 512\n",
      "2025-09-15 00:10:21 src.selection.data DEBUG    Options: Strawberry, Pear, Notebook, Eraser.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "2025-09-15 00:10:21 src.selection.data DEBUG    Options: Binder, Raspberry, Calculator, Mango.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:10:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Binder', prob=0.59765625, logit=19.375, token_id=91263, metadata=None))[\" Binder\"] != 37128[\" Calculator\"]\n",
      "2025-09-15 00:10:22 src.selection.data DEBUG    Options: Binder, Marker, Raspberry, Banana.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n",
      "2025-09-15 00:10:22 src.selection.data DEBUG    Options: Kiwi, Paperclip, Watermelon, Tape.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:10:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Paper', prob=0.455078125, logit=19.75, token_id=18343, metadata=None))[\" Paper\"] != 58586[\" Tape\"]\n",
      "2025-09-15 00:10:22 src.selection.data DEBUG    Options: Paper, Kiwi, Apple, Pen.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "2025-09-15 00:10:22 src.selection.data DEBUG    Options: Pear, Binder, Notebook, Pineapple.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Notebook\n",
      "2025-09-15 00:10:22 src.selection.data DEBUG    Options: Pear, Binder, Notebook, Pineapple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pine\n",
      "sample 9 / 512\n",
      "2025-09-15 00:10:26 src.selection.data DEBUG    Options: Skirt, Oven, Suit, Juicer.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:10:26 src.selection.data DEBUG    Options: Kettle, Hat, Jeans, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:10:26 src.selection.data DEBUG    Options: Kettle, Hat, Jeans, Pressure cooker.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "sample 10 / 512\n",
      "2025-09-15 00:10:29 src.selection.data DEBUG    Options: Kettle, Cow, Onion, Sheep, Cucumber.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:10:30 src.selection.data DEBUG    Options: Horse, Potato, Asparagus, Blender, Monkey.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:10:30 src.selection.data DEBUG    Options: Horse, Potato, Asparagus, Blender, Monkey.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "sample 11 / 512\n",
      "2025-09-15 00:10:33 src.selection.data DEBUG    Options: Airplane, Train, Harmonica, Carnation, Bracelet, Accordion.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "2025-09-15 00:10:34 src.selection.data DEBUG    Options: Piano, Tiara, Truck, Saxophone, Helicopter, Marigold.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:10:34 src.selection.data DEBUG    Options: Piano, Tiara, Truck, Saxophone, Helicopter, Marigold.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "sample 12 / 512\n",
      "2025-09-15 00:10:37 src.selection.data DEBUG    Options: Tie, Pin, Cherry, Charm, Watermelon.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:10:37 src.selection.data DEBUG    Options: Brooch, Plum, Cufflink, Grape, Dress.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:10:38 src.selection.data DEBUG    Options: Brooch, Plum, Cufflink, Grape, Dress.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "sample 13 / 512\n",
      "2025-09-15 00:10:41 src.selection.data DEBUG    Options: Boat, Motorcycle, Pendant, Chain, Sweater.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:10:41 src.selection.data DEBUG    Options: Car, Brooch, Pin, Skirt, Train.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "2025-09-15 00:10:41 src.selection.data DEBUG    Options: Car, Brooch, Pin, Skirt, Train.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "sample 14 / 512\n",
      "2025-09-15 00:10:45 src.selection.data DEBUG    Options: Broccoli, Mushroom, Laptop, Microphone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Micro\n",
      "2025-09-15 00:10:45 src.selection.data DEBUG    Options: Onion, Spinach, Tablet, Television.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Spin\n",
      "2025-09-15 00:10:45 src.selection.data DEBUG    Options: Onion, Spinach, Tablet, Television.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "sample 15 / 512\n",
      "2025-09-15 00:10:49 src.selection.data DEBUG    Options: Elephant, Eagle, Tiara, Charm, Calculator, Pressure cooker.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:10:49 src.selection.data DEBUG    Options: Paper, Necklace, Kettle, Cow, Pendant, Tiger.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "2025-09-15 00:10:49 src.selection.data DEBUG    Options: Paper, Necklace, Kettle, Cow, Pendant, Tiger.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "sample 16 / 512\n",
      "2025-09-15 00:10:53 src.selection.data DEBUG    Options: Ruler, Helmet, Stapler, Football, Pendant, Trumpet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:10:53 src.selection.data DEBUG    Options: Pin, Scissors, Drum, Racket, Surfboard, Highlighter.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 00:10:53 src.selection.data DEBUG    Options: Pin, Scissors, Drum, Racket, Surfboard, Highlighter.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "sample 17 / 512\n",
      "2025-09-15 00:10:56 src.selection.data DEBUG    Options: Pressure cooker, Accordion, Ring, Violin, Pepper, Bracelet, Lily.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "2025-09-15 00:10:57 src.selection.data DEBUG    Options: Locket, Watch, Slow cooker, Ukulele, Iris, Tomato, Drum.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "2025-09-15 00:10:57 src.selection.data DEBUG    Options: Locket, Watch, Slow cooker, Ukulele, Iris, Tomato, Drum.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:10:57 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' L', prob=0.357421875, logit=19.25, token_id=445, metadata=None))[\" L\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:10:57 src.selection.data DEBUG    Options: Elephant, Drum, Tomato, Binder, Trumpet, Ring, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:10:57 src.selection.data DEBUG    Options: Piano, Rabbit, Watch, Accordion, Pin, Zucchini, Folder.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "2025-09-15 00:10:57 src.selection.data DEBUG    Options: Piano, Rabbit, Watch, Accordion, Pin, Zucchini, Folder.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:10:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Watch', prob=0.73828125, logit=20.375, token_id=10573, metadata=None))[\" Watch\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:10:58 src.selection.data DEBUG    Options: Watch, Piano, Hospital, Bangle, Potato, Harp, Pineapple.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:10:58 src.selection.data DEBUG    Options: Charm, Pear, Mushroom, Xylophone, Temple, Cufflink, Trombone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trom\n",
      "2025-09-15 00:10:58 src.selection.data DEBUG    Options: Charm, Pear, Mushroom, Xylophone, Temple, Cufflink, Trombone.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "sample 18 / 512\n",
      "2025-09-15 00:11:02 src.selection.data DEBUG    Options: Folder, Magnolia, Onion, Highlighter, Horse, Dolphin, Mosque.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 00:11:02 src.selection.data DEBUG    Options: Willow, Cucumber, Cow, Dog, Factory, Stapler, Paper.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:11:02 src.selection.data DEBUG    Options: Willow, Cucumber, Cow, Dog, Factory, Stapler, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:11:02 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.81640625, logit=20.625, token_id=63606, metadata=None))[\" Stap\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:11:02 src.selection.data DEBUG    Options: Dumbbell, Bear, Eraser, Pear, Pencil, Potato, Cat.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:11:02 src.selection.data DEBUG    Options: Tape, Watermelon, Paperclip, Elephant, Lion, Boxing gloves, Celery.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:11:02 src.selection.data DEBUG    Options: Tape, Watermelon, Paperclip, Elephant, Lion, Boxing gloves, Celery.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 19 / 512\n",
      "2025-09-15 00:11:06 src.selection.data DEBUG    Options: Raspberry, Stapler, Folder, Peach.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:11:06 src.selection.data DEBUG    Options: Binder, Mango, Marker, Orange.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "2025-09-15 00:11:06 src.selection.data DEBUG    Options: Binder, Mango, Marker, Orange.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "sample 20 / 512\n",
      "2025-09-15 00:11:10 src.selection.data DEBUG    Options: Rabbit, Earring, Zebra, Razor, Charm, Desk, Dishwasher.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:11:10 src.selection.data DEBUG    Options: Eagle, Anklet, Juicer, Recliner, Tiara, Hairdryer, Lion.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:11:10 src.selection.data DEBUG    Options: Eagle, Anklet, Juicer, Recliner, Tiara, Hairdryer, Lion.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "sample 21 / 512\n",
      "2025-09-15 00:11:14 src.selection.data DEBUG    Options: Monkey, Mirror, Shower, Dog.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:11:14 src.selection.data DEBUG    Options: Razor, Zebra, Rabbit, Comb.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:11:14 src.selection.data DEBUG    Options: Razor, Zebra, Rabbit, Comb.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Rabbit\n",
      "2025-09-15 00:11:14 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Comb', prob=0.40625, logit=17.75, token_id=23262, metadata=None))[\" Comb\"] != 49431[\" Rabbit\"]\n",
      "2025-09-15 00:11:14 src.selection.data DEBUG    Options: Toothpaste, Sink, Rabbit, Tiger.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "2025-09-15 00:11:14 src.selection.data DEBUG    Options: Bear, Shower, Dolphin, Mirror.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:11:14 src.selection.data DEBUG    Options: Bear, Shower, Dolphin, Mirror.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "sample 22 / 512\n",
      "2025-09-15 00:11:18 src.selection.data DEBUG    Options: Monkey, Redwood, Shirt, Rabbit, Palm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Palm\n",
      "2025-09-15 00:11:18 src.selection.data DEBUG    Options: Dog, Spruce, Lion, Pine, Hat.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:11:18 src.selection.data DEBUG    Options: Dog, Spruce, Lion, Pine, Hat.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "sample 23 / 512\n",
      "2025-09-15 00:11:22 src.selection.data DEBUG    Options: Anklet, Banana, Watch, Submarine, Scooter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:11:22 src.selection.data DEBUG    Options: Helicopter, Tiara, Train, Raspberry, Bracelet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "2025-09-15 00:11:22 src.selection.data DEBUG    Options: Helicopter, Tiara, Train, Raspberry, Bracelet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "sample 24 / 512\n",
      "2025-09-15 00:11:26 src.selection.data DEBUG    Options: Suit, Magnolia, Hat, Maple.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "2025-09-15 00:11:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Suit', prob=0.373046875, logit=18.25, token_id=33711, metadata=None))[\" Suit\"] != 22050[\" Hat\"]\n",
      "2025-09-15 00:11:26 src.selection.data DEBUG    Options: Jeans, Ash, Suit, Bamboo.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:11:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bamboo', prob=0.6328125, logit=18.875, token_id=98028, metadata=None))[\" Bamboo\"] != 33711[\" Suit\"]\n",
      "2025-09-15 00:11:26 src.selection.data DEBUG    Options: Birch, Spruce, Skirt, Shirt.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:11:26 src.selection.data DEBUG    Options: Maple, Willow, Tie, Scarf.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:11:26 src.selection.data DEBUG    Options: Maple, Willow, Tie, Scarf.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "sample 25 / 512\n",
      "2025-09-15 00:11:30 src.selection.data DEBUG    Options: Locket, Pineapple, Mouse, Printer, Peach.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "2025-09-15 00:11:30 src.selection.data DEBUG    Options: Watermelon, Laptop, Monitor, Pear, Pin.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:11:30 src.selection.data DEBUG    Options: Watermelon, Laptop, Monitor, Pear, Pin.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "sample 26 / 512\n",
      "2025-09-15 00:11:34 src.selection.data DEBUG    Options: Nightstand, Printer, Helicopter, Redwood, Scooter, Desk.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:11:34 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hel', prob=0.486328125, logit=19.375, token_id=16183, metadata=None))[\" Hel\"] != 50159[\" Sco\"]\n",
      "2025-09-15 00:11:34 src.selection.data DEBUG    Options: Recliner, Truck, Cabinet, Smartwatch, Hospital, Car.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:11:34 src.selection.data DEBUG    Options: Mall, Motorcycle, Microphone, Ambulance, Dresser, Bed.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:11:34 src.selection.data DEBUG    Options: Mall, Motorcycle, Microphone, Ambulance, Dresser, Bed.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:11:34 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Motorcycle', prob=0.65625, logit=20.5, token_id=70762, metadata=None))[\" Motorcycle\"] != 20423[\" Amb\"]\n",
      "2025-09-15 00:11:34 src.selection.data DEBUG    Options: Skateboard, Raspberry, Chair, Motorcycle, Car, Bench.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:11:34 src.selection.data DEBUG    Options: Bed, Nightstand, Train, Bus, Watermelon, Bat.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "2025-09-15 00:11:35 src.selection.data DEBUG    Options: Bed, Nightstand, Train, Bus, Watermelon, Bat.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "sample 27 / 512\n",
      "2025-09-15 00:11:38 src.selection.data DEBUG    Options: Chair, Recliner, Orchid, Daffodil.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:11:38 src.selection.data DEBUG    Options: Chrysanthemum, Wardrobe, Table, Daisy.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Table\n",
      "2025-09-15 00:11:38 src.selection.data DEBUG    Options: Chrysanthemum, Wardrobe, Table, Daisy.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "sample 28 / 512\n",
      "2025-09-15 00:11:42 src.selection.data DEBUG    Options: Anklet, Airplane, Onion, Cauliflower, Scooter, Bamboo, Marker.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:11:42 src.selection.data DEBUG    Options: Celery, Yacht, Cucumber, Ambulance, Oak, Binder, Locket.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:11:42 src.selection.data DEBUG    Options: Celery, Yacht, Cucumber, Ambulance, Oak, Binder, Locket.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "sample 29 / 512\n",
      "2025-09-15 00:11:46 src.selection.data DEBUG    Options: Zucchini, Baseball, Hickory, Tape, Surfboard, Sheep, Dog.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:11:46 src.selection.data DEBUG    Options: Boxing gloves, Calculator, Spruce, Dolphin, Pepper, Hockey stick, Bear.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "2025-09-15 00:11:46 src.selection.data DEBUG    Options: Boxing gloves, Calculator, Spruce, Dolphin, Pepper, Hockey stick, Bear.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "sample 30 / 512\n",
      "2025-09-15 00:11:50 src.selection.data DEBUG    Options: Anklet, Charm, Dumbbell, Skis.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:11:50 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ank', prob=0.6875, logit=20.0, token_id=57915, metadata=None))[\" Ank\"] != 58600[\" Charm\"]\n",
      "2025-09-15 00:11:50 src.selection.data DEBUG    Options: Surfboard, Pin, Tennis ball, Pendant.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:11:51 src.selection.data DEBUG    Options: Bat, Watch, Locket, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:11:51 src.selection.data DEBUG    Options: Bat, Watch, Locket, Baseball.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "sample 31 / 512\n",
      "2025-09-15 00:11:54 src.selection.data DEBUG    Options: Library, Baseball, Golf ball, School, Dress.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "2025-09-15 00:11:54 src.selection.data DEBUG    Options: Shorts, House, Museum, Surfboard, Racket.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:11:55 src.selection.data DEBUG    Options: Shorts, House, Museum, Surfboard, Racket.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "sample 32 / 512\n",
      "2025-09-15 00:11:58 src.selection.data DEBUG    Options: Elephant, Piano, Trombone, Rabbit.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trom\n",
      "2025-09-15 00:11:58 src.selection.data DEBUG    Options: Cello, Dog, Clarinet, Cow.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "2025-09-15 00:11:58 src.selection.data DEBUG    Options: Cello, Dog, Clarinet, Cow.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "sample 33 / 512\n",
      "2025-09-15 00:12:02 src.selection.data DEBUG    Options: Cabinet, School, Factory, Sofa.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Factory\n",
      "2025-09-15 00:12:02 src.selection.data DEBUG    Options: Wardrobe, Library, Temple, Stool.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:12:02 src.selection.data DEBUG    Options: Wardrobe, Library, Temple, Stool.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "sample 34 / 512\n",
      "2025-09-15 00:12:06 src.selection.data DEBUG    Options: Trumpet, Blueberry, Cherry, Cello.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:12:06 src.selection.data DEBUG    Options: Watermelon, Ukulele, Flute, Grape.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:12:06 src.selection.data DEBUG    Options: Watermelon, Ukulele, Flute, Grape.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "sample 35 / 512\n",
      "2025-09-15 00:12:09 src.selection.data DEBUG    Options: Hat, Sweater, Skyscraper, House.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:12:10 src.selection.data DEBUG    Options: Mall, Shorts, School, Dress.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "2025-09-15 00:12:10 src.selection.data DEBUG    Options: Mall, Shorts, School, Dress.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "sample 36 / 512\n",
      "2025-09-15 00:12:13 src.selection.data DEBUG    Options: Tractor, Basketball, Banana, Bus, Strawberry.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 00:12:14 src.selection.data DEBUG    Options: Grape, Scooter, Bat, Watermelon, Ambulance.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:12:14 src.selection.data DEBUG    Options: Grape, Scooter, Bat, Watermelon, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "sample 37 / 512\n",
      "2025-09-15 00:12:18 src.selection.data DEBUG    Options: Cabinet, Toilet paper, Sink, Dress, Motorcycle, Food processor, Sofa.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Sofa\n",
      "2025-09-15 00:12:18 src.selection.data DEBUG    Options: Nightstand, Comb, Scarf, Toothpaste, Ottoman, Pressure cooker, Truck.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:12:18 src.selection.data DEBUG    Options: Nightstand, Comb, Scarf, Toothpaste, Ottoman, Pressure cooker, Truck.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "sample 38 / 512\n",
      "2025-09-15 00:12:22 src.selection.data DEBUG    Options: Drum, Bathtub, Soap, Cello.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:12:22 src.selection.data DEBUG    Options: Clarinet, Shampoo, Piano, Shower.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:12:22 src.selection.data DEBUG    Options: Clarinet, Shampoo, Piano, Shower.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Piano\n",
      "sample 39 / 512\n",
      "2025-09-15 00:12:25 src.selection.data DEBUG    Options: Bracelet, Notebook, Lion, Tiara, Grape, Pineapple.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:12:25 src.selection.data DEBUG    Options: Necklace, Zebra, Eraser, Banana, Cufflink, Cherry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:12:26 src.selection.data DEBUG    Options: Necklace, Zebra, Eraser, Banana, Cufflink, Cherry.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "sample 40 / 512\n",
      "2025-09-15 00:12:29 src.selection.data DEBUG    Options: Helmet, Skis, Bracelet, Pear, Apple, Harmonica, Notebook.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:12:29 src.selection.data DEBUG    Options: Stapler, Clarinet, Chain, Surfboard, Grape, Boxing gloves, Strawberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:12:29 src.selection.data DEBUG    Options: Stapler, Clarinet, Chain, Surfboard, Grape, Boxing gloves, Strawberry.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "sample 41 / 512\n",
      "2025-09-15 00:12:33 src.selection.data DEBUG    Options: Folder, Ambulance, Mango, Notebook, Motorcycle.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:12:33 src.selection.data DEBUG    Options: Ruler, Bus, Paper, Train, Raspberry.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:12:33 src.selection.data DEBUG    Options: Ruler, Bus, Paper, Train, Raspberry.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "sample 42 / 512\n",
      "2025-09-15 00:12:37 src.selection.data DEBUG    Options: Mirror, Saxophone, Pants, Jeans, Clarinet.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "2025-09-15 00:12:37 src.selection.data DEBUG    Options: Shorts, Accordion, Skirt, Towel, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:12:37 src.selection.data DEBUG    Options: Shorts, Accordion, Skirt, Towel, Violin.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Sk\n",
      "sample 43 / 512\n",
      "2025-09-15 00:12:41 src.selection.data DEBUG    Options: Tiger, Horse, Speaker, Printer, Coffee table.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "2025-09-15 00:12:41 src.selection.data DEBUG    Options: Giraffe, Monitor, Phone, Dolphin, Bookshelf.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:12:41 src.selection.data DEBUG    Options: Giraffe, Monitor, Phone, Dolphin, Bookshelf.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "sample 44 / 512\n",
      "2025-09-15 00:12:45 src.selection.data DEBUG    Options: Sheep, Locket, Airplane, Scarf, Socks, Helicopter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:12:45 src.selection.data DEBUG    Options: Tractor, Truck, Earring, Eagle, Skirt, Pants.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:12:45 src.selection.data DEBUG    Options: Tractor, Truck, Earring, Eagle, Skirt, Pants.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "sample 45 / 512\n",
      "2025-09-15 00:12:49 src.selection.data DEBUG    Options: Shorts, Sink, Warehouse, Mirror, Stadium.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:12:49 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Sink', prob=0.953125, logit=21.625, token_id=57551, metadata=None))[\" Sink\"] != 34954[\" Mirror\"]\n",
      "2025-09-15 00:12:49 src.selection.data DEBUG    Options: Warehouse, Comb, Mall, Toothbrush, Eagle.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:12:49 src.selection.data DEBUG    Options: Sink, Tiger, Factory, School, Toilet paper.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "2025-09-15 00:12:49 src.selection.data DEBUG    Options: Sink, Tiger, Factory, School, Toilet paper.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "sample 46 / 512\n",
      "2025-09-15 00:12:53 src.selection.data DEBUG    Options: Jasmine, Toilet paper, Bat, Daisy, Bench, Mixer, Desk.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Desk\n",
      "2025-09-15 00:12:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bench', prob=0.44140625, logit=19.625, token_id=36358, metadata=None))[\" Bench\"] != 39794[\" Desk\"]\n",
      "2025-09-15 00:12:53 src.selection.data DEBUG    Options: Bench, Jasmine, Anklet, Shower, Scissors, Carnation, Bed.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:12:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bench', prob=0.546875, logit=19.875, token_id=36358, metadata=None))[\" Bench\"] != 13394[\" Bed\"]\n",
      "2025-09-15 00:12:53 src.selection.data DEBUG    Options: Table, Sunflower, House, Wardrobe, Dumbbell, Harmonica, Marigold.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "2025-09-15 00:12:53 src.selection.data DEBUG    Options: Yoga mat, Ukulele, Bed, Violet, Apartment, Carnation, Nightstand.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "2025-09-15 00:12:54 src.selection.data DEBUG    Options: Yoga mat, Ukulele, Bed, Violet, Apartment, Carnation, Nightstand.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "sample 47 / 512\n",
      "2025-09-15 00:12:57 src.selection.data DEBUG    Options: Tablet, Bangle, Scooter, Tractor, Monitor, Toilet paper, Tie.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:12:57 src.selection.data DEBUG    Options: Headphones, Toilet, Anklet, Van, Skirt, Yacht, Laptop.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "2025-09-15 00:12:57 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Van', prob=0.45703125, logit=19.625, token_id=13000, metadata=None))[\" Van\"] != 816[\" Y\"]\n",
      "2025-09-15 00:12:57 src.selection.data DEBUG    Options: Mouse, Headphones, Apple, Coffee maker, Airplane, Boat, Hickory.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "2025-09-15 00:12:58 src.selection.data DEBUG    Options: Laptop, Banana, Car, Speaker, Train, Dishwasher, Cedar.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "2025-09-15 00:12:58 src.selection.data DEBUG    Options: Laptop, Banana, Car, Speaker, Train, Dishwasher, Cedar.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "sample 48 / 512\n",
      "2025-09-15 00:13:01 src.selection.data DEBUG    Options: Lettuce, Car, Celery, Airplane.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "2025-09-15 00:13:01 src.selection.data DEBUG    Options: Onion, Asparagus, Bike, Scooter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:13:01 src.selection.data DEBUG    Options: Onion, Asparagus, Bike, Scooter.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "sample 49 / 512\n",
      "2025-09-15 00:13:05 src.selection.data DEBUG    Options: Carnation, Watermelon, Gloves, Socks, Drum, Car, Saxophone.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "2025-09-15 00:13:05 src.selection.data DEBUG    Options: Tulip, Shorts, Suit, Trombone, Flute, Strawberry, Submarine.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:13:05 src.selection.data DEBUG    Options: Tulip, Shorts, Suit, Trombone, Flute, Strawberry, Submarine.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "sample 50 / 512\n",
      "2025-09-15 00:13:09 src.selection.data DEBUG    Options: Bangle, Speaker, Temple, Brooch, Jacket, Hat.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:13:09 src.selection.data DEBUG    Options: Bracelet, Pants, Camera, Dress, Pin, Mall.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:13:09 src.selection.data DEBUG    Options: Bracelet, Pants, Camera, Dress, Pin, Mall.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "sample 51 / 512\n",
      "2025-09-15 00:13:13 src.selection.data DEBUG    Options: Helicopter, Paper, Pen, Submarine, Jacket.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:13:13 src.selection.data DEBUG    Options: Tape, Shorts, Bus, Ambulance, Pencil.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:13:13 src.selection.data DEBUG    Options: Tape, Shorts, Bus, Ambulance, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "sample 52 / 512\n",
      "2025-09-15 00:13:16 src.selection.data DEBUG    Options: Highlighter, Football, Bookshelf, Raspberry, Pin, Pendant, Hockey stick.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "2025-09-15 00:13:17 src.selection.data DEBUG    Options: Chain, Dresser, Baseball, Ring, Surfboard, Plum, Notebook.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "2025-09-15 00:13:17 src.selection.data DEBUG    Options: Chain, Dresser, Baseball, Ring, Surfboard, Plum, Notebook.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:13:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Baseball', prob=0.5625, logit=19.375, token_id=38258, metadata=None))[\" Baseball\"] != 65197[\" Surf\"]\n",
      "2025-09-15 00:13:17 src.selection.data DEBUG    Options: Pin, Tablet, Coat, Cufflink, Racket, Raspberry, Golf ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:13:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' R', prob=0.44921875, logit=19.625, token_id=432, metadata=None))[\" R\"] != 28131[\" Golf\"]\n",
      "2025-09-15 00:13:17 src.selection.data DEBUG    Options: Pin, Saxophone, Eraser, Hockey stick, Cufflink, Cherry, Tennis ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Tennis\n",
      "2025-09-15 00:13:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hockey', prob=0.65234375, logit=20.0, token_id=41342, metadata=None))[\" Hockey\"] != 58251[\" Tennis\"]\n",
      "2025-09-15 00:13:17 src.selection.data DEBUG    Options: Bat, Mirror, Boxing gloves, Tiara, Hat, Trombone, Earring.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:13:17 src.selection.data DEBUG    Options: Pin, Yoga mat, Brooch, Scarf, Shower, Racket, Accordion.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:13:18 src.selection.data DEBUG    Options: Pin, Yoga mat, Brooch, Scarf, Shower, Racket, Accordion.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "sample 53 / 512\n",
      "2025-09-15 00:13:21 src.selection.data DEBUG    Options: Lettuce, Pepper, Television, Keyboard.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:13:21 src.selection.data DEBUG    Options: Onion, Smartwatch, Tomato, Speaker.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:13:21 src.selection.data DEBUG    Options: Onion, Smartwatch, Tomato, Speaker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 00:13:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Smart', prob=0.46875, logit=19.625, token_id=16147, metadata=None))[\" Smart\"] != 30173[\" Speaker\"]\n",
      "2025-09-15 00:13:22 src.selection.data DEBUG    Options: Mouse, Tablet, Spinach, Lettuce.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:13:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Mouse', prob=0.68359375, logit=19.25, token_id=18191, metadata=None))[\" Mouse\"] != 58403[\" Tablet\"]\n",
      "2025-09-15 00:13:22 src.selection.data DEBUG    Options: Speaker, Cucumber, Router, Broccoli.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "2025-09-15 00:13:22 src.selection.data DEBUG    Options: Camera, Projector, Pepper, Mushroom.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:13:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pepper', prob=0.65234375, logit=19.625, token_id=52882, metadata=None))[\" Pepper\"] != 91297[\" Mushroom\"]\n",
      "2025-09-15 00:13:22 src.selection.data DEBUG    Options: Headphones, Pepper, Printer, Zucchini.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "2025-09-15 00:13:22 src.selection.data DEBUG    Options: Microphone, Potato, Onion, Television.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "2025-09-15 00:13:22 src.selection.data DEBUG    Options: Microphone, Potato, Onion, Television.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "sample 54 / 512\n",
      "2025-09-15 00:13:26 src.selection.data DEBUG    Options: Cedar, Monkey, Speaker, Router, Redwood.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "2025-09-15 00:13:26 src.selection.data DEBUG    Options: Mouse, Printer, Birch, Rabbit, Oak.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:13:26 src.selection.data DEBUG    Options: Mouse, Printer, Birch, Rabbit, Oak.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "sample 55 / 512\n",
      "2025-09-15 00:13:29 src.selection.data DEBUG    Options: Nightstand, Surfboard, Bench, Dishwasher, Microwave.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Microwave\n",
      "2025-09-15 00:13:30 src.selection.data DEBUG    Options: Football, Food processor, Mixer, Dresser, Cabinet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "2025-09-15 00:13:30 src.selection.data DEBUG    Options: Football, Food processor, Mixer, Dresser, Cabinet.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-15 00:13:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Cabinet', prob=0.462890625, logit=19.75, token_id=34046, metadata=None))[\" Cabinet\"] != 72392[\" Mixer\"]\n",
      "2025-09-15 00:13:30 src.selection.data DEBUG    Options: Dresser, Bangle, Cabinet, Food processor, Refrigerator.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "2025-09-15 00:13:30 src.selection.data DEBUG    Options: Coffee maker, Sofa, Nightstand, Air fryer, Bracelet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "2025-09-15 00:13:31 src.selection.data DEBUG    Options: Coffee maker, Sofa, Nightstand, Air fryer, Bracelet.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "sample 56 / 512\n",
      "2025-09-15 00:13:34 src.selection.data DEBUG    Options: Highlighter, Sofa, Pin, Dog, Mushroom, Watch, Ottoman.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "2025-09-15 00:13:34 src.selection.data DEBUG    Options: Carrot, Dolphin, Bracelet, Recliner, Bookshelf, Scissors, Pendant.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:13:34 src.selection.data DEBUG    Options: Carrot, Dolphin, Bracelet, Recliner, Bookshelf, Scissors, Pendant.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Book\n",
      "2025-09-15 00:13:35 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Re', prob=0.57421875, logit=20.5, token_id=1050, metadata=None))[\" Re\"] != 6017[\" Book\"]\n",
      "2025-09-15 00:13:35 src.selection.data DEBUG    Options: Necklace, Sofa, Tulip, Truck, Monkey, Locket, Nightstand.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "2025-09-15 00:13:35 src.selection.data DEBUG    Options: Stool, Helicopter, Cat, Chair, Anklet, Brooch, Peony.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:13:35 src.selection.data DEBUG    Options: Stool, Helicopter, Cat, Chair, Anklet, Brooch, Peony.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Chair\n",
      "sample 57 / 512\n",
      "2025-09-15 00:13:38 src.selection.data DEBUG    Options: Brooch, Sunflower, Tulip, Piano, Ukulele.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "2025-09-15 00:13:39 src.selection.data DEBUG    Options: Drum, Jasmine, Marigold, Trombone, Ring.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "2025-09-15 00:13:39 src.selection.data DEBUG    Options: Drum, Jasmine, Marigold, Trombone, Ring.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trom\n",
      "sample 58 / 512\n",
      "2025-09-15 00:13:42 src.selection.data DEBUG    Options: Strawberry, Mouse, Peach, Soap, Towel.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tow\n",
      "2025-09-15 00:13:43 src.selection.data DEBUG    Options: Sink, Plum, Bathtub, Phone, Apple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "2025-09-15 00:13:43 src.selection.data DEBUG    Options: Sink, Plum, Bathtub, Phone, Apple.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "sample 59 / 512\n",
      "2025-09-15 00:13:46 src.selection.data DEBUG    Options: Toaster, Charm, Rice cooker, Soap, Pin.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:13:47 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Charm', prob=0.67578125, logit=19.375, token_id=58600, metadata=None))[\" Charm\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:13:47 src.selection.data DEBUG    Options: Razor, Slow cooker, Juicer, Cufflink, Watch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:13:47 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' C', prob=0.6640625, logit=20.125, token_id=356, metadata=None))[\" C\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:13:47 src.selection.data DEBUG    Options: Air fryer, Cufflink, Maple, Slow cooker, Pendant.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:13:47 src.selection.data DEBUG    Options: Pine, Earring, Bangle, Microwave, Oven.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Oven\n",
      "2025-09-15 00:13:47 src.selection.data DEBUG    Options: Pine, Earring, Bangle, Microwave, Oven.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "sample 60 / 512\n",
      "2025-09-15 00:13:51 src.selection.data DEBUG    Options: Hospital, Oak, Bear, Orange, Cat, Strawberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:13:51 src.selection.data DEBUG    Options: Cherry, Library, Dog, Sheep, Plum, Palm.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:13:51 src.selection.data DEBUG    Options: Cherry, Library, Dog, Sheep, Plum, Palm.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "sample 61 / 512\n",
      "2025-09-15 00:13:54 src.selection.data DEBUG    Options: Bus, Folder, Binder, Flute, Bed, Stool.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:13:55 src.selection.data DEBUG    Options: Cabinet, Piano, Sofa, Stapler, Tape, Airplane.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:13:55 src.selection.data DEBUG    Options: Cabinet, Piano, Sofa, Stapler, Tape, Airplane.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Sofa\n",
      "sample 62 / 512\n",
      "2025-09-15 00:13:58 src.selection.data DEBUG    Options: Giraffe, Jeans, Bike, Bus, Pineapple, Tiger.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 00:13:58 src.selection.data DEBUG    Options: Elephant, Van, Dolphin, Kiwi, Yacht, Tie.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:13:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ki', prob=0.4921875, logit=20.75, token_id=30558, metadata=None))[\" Ki\"] != 96096[\" Dolphin\"]\n",
      "2025-09-15 00:13:59 src.selection.data DEBUG    Options: Bike, Truck, Sheep, Pear, Rabbit, Clarinet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:13:59 src.selection.data DEBUG    Options: Boat, Eagle, Trumpet, Motorcycle, Horse, Grape.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:13:59 src.selection.data DEBUG    Options: Boat, Eagle, Trumpet, Motorcycle, Horse, Grape.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "sample 63 / 512\n",
      "2025-09-15 00:14:03 src.selection.data DEBUG    Options: Ottoman, Camera, Pants, Marker, Maple, Pen, Bench.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bench\n",
      "2025-09-15 00:14:03 src.selection.data DEBUG    Options: Cedar, Coat, Paper, Projector, Desk, Bookshelf, Ruler.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:14:03 src.selection.data DEBUG    Options: Cedar, Coat, Paper, Projector, Desk, Bookshelf, Ruler.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Book\n",
      "sample 64 / 512\n",
      "2025-09-15 00:14:07 src.selection.data DEBUG    Options: Basketball, Racket, Toothpaste, Toothbrush.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:14:07 src.selection.data DEBUG    Options: Shower, Helmet, Yoga mat, Soap.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:14:08 src.selection.data DEBUG    Options: Shower, Helmet, Yoga mat, Soap.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Soap\n",
      "sample 65 / 512\n",
      "2025-09-15 00:14:11 src.selection.data DEBUG    Options: Clarinet, Drum, Jacket, Gloves.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "2025-09-15 00:14:12 src.selection.data DEBUG    Options: Trombone, Hat, Xylophone, Pants.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:14:12 src.selection.data DEBUG    Options: Trombone, Hat, Xylophone, Pants.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "sample 66 / 512\n",
      "2025-09-15 00:14:15 src.selection.data DEBUG    Options: Dishwasher, Speaker, Pepper, Blender, Projector.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:14:15 src.selection.data DEBUG    Options: Monitor, Celery, Food processor, Tablet, Microwave.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:14:16 src.selection.data DEBUG    Options: Monitor, Celery, Food processor, Tablet, Microwave.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Microwave\n",
      "sample 67 / 512\n",
      "2025-09-15 00:14:19 src.selection.data DEBUG    Options: Toothpaste, Onion, Scooter, Van, Pepper.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Pepper\n",
      "2025-09-15 00:14:19 src.selection.data DEBUG    Options: Asparagus, Motorcycle, Yacht, Zucchini, Mirror.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "2025-09-15 00:14:20 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Motorcycle', prob=0.828125, logit=21.5, token_id=70762, metadata=None))[\" Motorcycle\"] != 816[\" Y\"]\n",
      "2025-09-15 00:14:20 src.selection.data DEBUG    Options: House, Yacht, Onion, Cucumber, Tractor.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:14:20 src.selection.data DEBUG    Options: Warehouse, Potato, Car, Airplane, Carrot.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:14:20 src.selection.data DEBUG    Options: Warehouse, Potato, Car, Airplane, Carrot.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "sample 68 / 512\n",
      "2025-09-15 00:14:24 src.selection.data DEBUG    Options: Violet, Boxing gloves, Skirt, Shirt, Jasmine.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:14:24 src.selection.data DEBUG    Options: Tennis ball, Shorts, Peony, Daisy, Tie.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:14:24 src.selection.data DEBUG    Options: Tennis ball, Shorts, Peony, Daisy, Tie.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Tie\n",
      "sample 69 / 512\n",
      "2025-09-15 00:14:27 src.selection.data DEBUG    Options: Pressure cooker, Air fryer, Soap, Camera, Comb, Mango.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:14:28 src.selection.data DEBUG    Options: Banana, Mirror, Food processor, Towel, Headphones, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "2025-09-15 00:14:28 src.selection.data DEBUG    Options: Banana, Mirror, Food processor, Towel, Headphones, Slow cooker.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tow\n",
      "sample 70 / 512\n",
      "2025-09-15 00:14:31 src.selection.data DEBUG    Options: Cat, Baseball, Tiger, Chrysanthemum, Orchid.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "2025-09-15 00:14:32 src.selection.data DEBUG    Options: Lavender, Eagle, Dumbbell, Cow, Violet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:14:32 src.selection.data DEBUG    Options: Lavender, Eagle, Dumbbell, Cow, Violet.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "sample 71 / 512\n",
      "2025-09-15 00:14:36 src.selection.data DEBUG    Options: Razor, Paperclip, Saxophone, Cauliflower, Tape, Flute.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:14:36 src.selection.data DEBUG    Options: Clarinet, Potato, Bathtub, Calculator, Accordion, Binder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:14:36 src.selection.data DEBUG    Options: Clarinet, Potato, Bathtub, Calculator, Accordion, Binder.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "sample 72 / 512\n",
      "2025-09-15 00:14:40 src.selection.data DEBUG    Options: Zucchini, Piano, Earring, Watermelon, Guitar, Watch.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "2025-09-15 00:14:40 src.selection.data DEBUG    Options: Tomato, Harmonica, Tiara, Harp, Mango, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:14:40 src.selection.data DEBUG    Options: Tomato, Harmonica, Tiara, Harp, Mango, Brooch.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "sample 73 / 512\n",
      "2025-09-15 00:14:44 src.selection.data DEBUG    Options: Bathtub, Hockey stick, Tractor, Toothbrush, Coffee table, Daffodil, Bike.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "2025-09-15 00:14:44 src.selection.data DEBUG    Options: Soap, Submarine, Razor, Train, Surfboard, Tulip, Sofa.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:14:44 src.selection.data DEBUG    Options: Soap, Submarine, Razor, Train, Surfboard, Tulip, Sofa.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "sample 74 / 512\n",
      "2025-09-15 00:14:48 src.selection.data DEBUG    Options: Palm, Potato, Eucalyptus, Cauliflower.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:14:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Palm', prob=0.453125, logit=18.875, token_id=33578, metadata=None))[\" Palm\"] != 469[\" E\"]\n",
      "2025-09-15 00:14:48 src.selection.data DEBUG    Options: Lettuce, Tomato, Palm, Magnolia.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "2025-09-15 00:14:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Palm', prob=0.5546875, logit=18.375, token_id=33578, metadata=None))[\" Palm\"] != 20918[\" Magn\"]\n",
      "2025-09-15 00:14:48 src.selection.data DEBUG    Options: Willow, Birch, Pepper, Carrot.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:14:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Willow', prob=0.2578125, logit=17.625, token_id=65449, metadata=None))[\" Willow\"] != 88088[\" Birch\"]\n",
      "2025-09-15 00:14:48 src.selection.data DEBUG    Options: Pine, Potato, Willow, Lettuce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:14:48 src.selection.data DEBUG    Options: Carrot, Elm, Oak, Tomato.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:14:49 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Car', prob=0.439453125, logit=19.5, token_id=3341, metadata=None))[\" Car\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:14:49 src.selection.data DEBUG    Options: Pepper, Lettuce, Oak, Ash.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "2025-09-15 00:14:49 src.selection.data DEBUG    Options: Cauliflower, Willow, Celery, Redwood.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "2025-09-15 00:14:49 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Caul', prob=0.435546875, logit=18.875, token_id=90538, metadata=None))[\" Caul\"] != 47643[\" Cel\"]\n",
      "2025-09-15 00:14:49 src.selection.data DEBUG    Options: Tomato, Carrot, Birch, Elm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "2025-09-15 00:14:49 src.selection.data DEBUG    Options: Cucumber, Ash, Willow, Broccoli.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:14:49 src.selection.data DEBUG    Options: Cucumber, Ash, Willow, Broccoli.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "sample 75 / 512\n",
      "2025-09-15 00:14:53 src.selection.data DEBUG    Options: Blender, Tomato, Oven, Cauliflower.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Oven\n",
      "2025-09-15 00:14:53 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Blender', prob=0.353515625, logit=19.25, token_id=88668, metadata=None))[\" Oven\"] != 87213[\" Oven\"]\n",
      "2025-09-15 00:14:53 src.selection.data DEBUG    Options: Cauliflower, Juicer, Mixer, Asparagus.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-15 00:14:53 src.selection.data DEBUG    Options: Pepper, Air fryer, Refrigerator, Lettuce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:14:53 src.selection.data DEBUG    Options: Pepper, Air fryer, Refrigerator, Lettuce.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "sample 76 / 512\n",
      "2025-09-15 00:14:57 src.selection.data DEBUG    Options: Sheep, Hickory, Tiger, Bamboo, Museum.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "2025-09-15 00:14:57 src.selection.data DEBUG    Options: Monkey, Oak, School, Rabbit, Spruce.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Rabbit\n",
      "2025-09-15 00:14:57 src.selection.data DEBUG    Options: Monkey, Oak, School, Rabbit, Spruce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "sample 77 / 512\n",
      "2025-09-15 00:15:01 src.selection.data DEBUG    Options: Elephant, Comb, Plum, Toothpaste, Pineapple, Kettle.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:15:01 src.selection.data DEBUG    Options: Shower, Kiwi, Peach, Toothbrush, Dolphin, Refrigerator.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:15:01 src.selection.data DEBUG    Options: Shower, Kiwi, Peach, Toothbrush, Dolphin, Refrigerator.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "sample 78 / 512\n",
      "2025-09-15 00:15:05 src.selection.data DEBUG    Options: Helicopter, Ambulance, Shirt, Suit.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:15:05 src.selection.data DEBUG    Options: Train, Scooter, Hat, Socks.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:15:05 src.selection.data DEBUG    Options: Train, Scooter, Hat, Socks.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "sample 79 / 512\n",
      "2025-09-15 00:15:09 src.selection.data DEBUG    Options: Mosque, Oven, Blender, Guitar, Headphones, Eucalyptus, Spruce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:15:09 src.selection.data DEBUG    Options: Willow, House, Coffee maker, Dishwasher, Monitor, Cedar, Xylophone.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "2025-09-15 00:15:09 src.selection.data DEBUG    Options: Willow, House, Coffee maker, Dishwasher, Monitor, Cedar, Xylophone.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "sample 80 / 512\n",
      "2025-09-15 00:15:13 src.selection.data DEBUG    Options: Mixer, Boxing gloves, Coffee maker, Guitar, Warehouse, Helmet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:15:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boxing', prob=0.609375, logit=20.0, token_id=72683, metadata=None))[\" Boxing\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:15:13 src.selection.data DEBUG    Options: Hockey stick, Highlighter, Pendant, Yoga mat, Oven, Dishwasher.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:15:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hockey', prob=0.6015625, logit=19.5, token_id=41342, metadata=None))[\" Hockey\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:15:13 src.selection.data DEBUG    Options: Bat, Slow cooker, Socks, Refrigerator, Football, Monkey.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:15:13 src.selection.data DEBUG    Options: Pressure cooker, Blender, Dolphin, Suit, Racket, Skis.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:15:13 src.selection.data DEBUG    Options: Pressure cooker, Blender, Dolphin, Suit, Racket, Skis.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Sk\n",
      "sample 81 / 512\n",
      "2025-09-15 00:15:17 src.selection.data DEBUG    Options: Mosque, Car, Truck, Apartment.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "2025-09-15 00:15:17 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Mosque', prob=0.408203125, logit=19.5, token_id=100031, metadata=None))[\" Apartment\"] != 53889[\" Apartment\"]\n",
      "2025-09-15 00:15:17 src.selection.data DEBUG    Options: Museum, Theater, Van, Scooter.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "2025-09-15 00:15:17 src.selection.data DEBUG    Options: Bike, Mall, Skyscraper, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:15:17 src.selection.data DEBUG    Options: Bike, Mall, Skyscraper, Ambulance.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Sk\n",
      "sample 82 / 512\n",
      "2025-09-15 00:15:21 src.selection.data DEBUG    Options: Toaster, Bangle, Dresser, Marker, Air fryer, Ruler, Coat.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:15:21 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Marker', prob=0.7265625, logit=20.375, token_id=40975, metadata=None))[\" Marker\"] != 432[\" R\"]\n",
      "2025-09-15 00:15:21 src.selection.data DEBUG    Options: Kettle, Marker, Refrigerator, Calculator, Hickory, Recliner, Locket.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:15:21 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Marker', prob=0.69140625, logit=20.25, token_id=40975, metadata=None))[\" Marker\"] != 37128[\" Calculator\"]\n",
      "2025-09-15 00:15:21 src.selection.data DEBUG    Options: Highlighter, Folder, Headphones, Toaster, Hospital, Scarf, Dishwasher.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:15:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Highlight', prob=0.55078125, logit=19.75, token_id=57094, metadata=None))[\" Highlight\"] != 36943[\" Folder\"]\n",
      "2025-09-15 00:15:22 src.selection.data DEBUG    Options: Cow, Lily, Mixer, Suit, Binder, Paper, Air fryer.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:15:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Binder', prob=0.828125, logit=20.0, token_id=91263, metadata=None))[\" Binder\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:15:22 src.selection.data DEBUG    Options: Folder, Tulip, Mixer, Hat, Binder, Coffee table, Coffee maker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:15:22 src.selection.data DEBUG    Options: Stool, Eraser, Lily, Slow cooker, Jacket, Paper, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:15:22 src.selection.data DEBUG    Options: Stool, Eraser, Lily, Slow cooker, Jacket, Paper, Pressure cooker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 83 / 512\n",
      "2025-09-15 00:15:26 src.selection.data DEBUG    Options: Ruler, Hickory, Food processor, Pencil, Lily, Kettle, Ambulance.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  K\n",
      "2025-09-15 00:15:26 src.selection.data DEBUG    Options: Marigold, Paperclip, Scissors, Eucalyptus, Mixer, Yacht, Blender.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:15:26 src.selection.data DEBUG    Options: Marigold, Paperclip, Scissors, Eucalyptus, Mixer, Yacht, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "sample 84 / 512\n",
      "2025-09-15 00:15:30 src.selection.data DEBUG    Options: Tomato, Coffee maker, Spinach, Stadium, Kettle, Printer.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Spin\n",
      "2025-09-15 00:15:30 src.selection.data DEBUG    Options: Lettuce, Pressure cooker, School, Cucumber, Laptop, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "2025-09-15 00:15:30 src.selection.data DEBUG    Options: Lettuce, Pressure cooker, School, Cucumber, Laptop, Slow cooker.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "sample 85 / 512\n",
      "2025-09-15 00:15:33 src.selection.data DEBUG    Options: Keyboard, Smartwatch, Bear, Eagle, Skirt.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Eagle\n",
      "2025-09-15 00:15:34 src.selection.data DEBUG    Options: Zebra, Phone, Printer, Coat, Lion.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "2025-09-15 00:15:34 src.selection.data DEBUG    Options: Zebra, Phone, Printer, Coat, Lion.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "sample 86 / 512\n",
      "2025-09-15 00:15:37 src.selection.data DEBUG    Options: Ring, Bike, Cufflink, Boat.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:15:38 src.selection.data DEBUG    Options: Van, Pin, Charm, Car.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:15:38 src.selection.data DEBUG    Options: Van, Pin, Charm, Car.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "sample 87 / 512\n",
      "2025-09-15 00:15:41 src.selection.data DEBUG    Options: Bed, Stool, Train, Boat.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:15:42 src.selection.data DEBUG    Options: Ambulance, Airplane, Nightstand, Cabinet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "2025-09-15 00:15:42 src.selection.data DEBUG    Options: Ambulance, Airplane, Nightstand, Cabinet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "sample 88 / 512\n",
      "2025-09-15 00:15:45 src.selection.data DEBUG    Options: Van, Cat, Jasmine, Monitor, Sheep, Helicopter, Stool.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:15:45 src.selection.data DEBUG    Options: Microphone, Ambulance, Marigold, Boat, Dolphin, Giraffe, Desk.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:15:46 src.selection.data DEBUG    Options: Microphone, Ambulance, Marigold, Boat, Dolphin, Giraffe, Desk.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Gir\n",
      "sample 89 / 512\n",
      "2025-09-15 00:15:49 src.selection.data DEBUG    Options: Motorcycle, Van, Clarinet, Strawberry, Cherry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:15:50 src.selection.data DEBUG    Options: Piano, Apple, Pear, Bike, Helicopter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:15:50 src.selection.data DEBUG    Options: Piano, Apple, Pear, Bike, Helicopter.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "sample 90 / 512\n",
      "2025-09-15 00:15:53 src.selection.data DEBUG    Options: Airplane, Boat, Daisy, Carnation.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:15:53 src.selection.data DEBUG    Options: Daffodil, Yacht, Motorcycle, Peony.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Pe\n",
      "2025-09-15 00:15:54 src.selection.data DEBUG    Options: Daffodil, Yacht, Motorcycle, Peony.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "sample 91 / 512\n",
      "2025-09-15 00:15:57 src.selection.data DEBUG    Options: Bear, Razor, Monitor, Elephant, Projector, Jasmine.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Elephant\n",
      "2025-09-15 00:15:57 src.selection.data DEBUG    Options: Monkey, Dolphin, Lily, Tablet, Bathtub, Laptop.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "2025-09-15 00:15:58 src.selection.data DEBUG    Options: Monkey, Dolphin, Lily, Tablet, Bathtub, Laptop.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:15:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bat', prob=0.45703125, logit=20.375, token_id=16488, metadata=None))[\" Bat\"] != 96096[\" Dolphin\"]\n",
      "2025-09-15 00:15:58 src.selection.data DEBUG    Options: Tiger, Phone, Golf ball, Jasmine, Dog, Projector.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:15:58 src.selection.data DEBUG    Options: Keyboard, Horse, Iris, Rabbit, Tablet, Skateboard.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:15:59 src.selection.data DEBUG    Options: Keyboard, Horse, Iris, Rabbit, Tablet, Skateboard.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Rabbit\n",
      "sample 92 / 512\n",
      "2025-09-15 00:16:02 src.selection.data DEBUG    Options: Piano, Rabbit, Bench, Sheep, Coffee table.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:16:02 src.selection.data DEBUG    Options: Violin, Dresser, Desk, Zebra, Monkey.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Desk\n",
      "2025-09-15 00:16:02 src.selection.data DEBUG    Options: Violin, Dresser, Desk, Zebra, Monkey.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "sample 93 / 512\n",
      "2025-09-15 00:16:06 src.selection.data DEBUG    Options: Mirror, Toilet paper, Daisy, Bed, Microphone, Tablet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:16:06 src.selection.data DEBUG    Options: Dresser, Laptop, Orchid, Shampoo, Sink, Keyboard.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:16:06 src.selection.data DEBUG    Options: Dresser, Laptop, Orchid, Shampoo, Sink, Keyboard.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 94 / 512\n",
      "2025-09-15 00:16:10 src.selection.data DEBUG    Options: Motorcycle, Towel, Mango, Broccoli, Van, Toilet paper.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "2025-09-15 00:16:10 src.selection.data DEBUG    Options: Comb, Lotion, Car, Boat, Pineapple, Cauliflower.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:16:10 src.selection.data DEBUG    Options: Comb, Lotion, Car, Boat, Pineapple, Cauliflower.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "sample 95 / 512\n",
      "2025-09-15 00:16:14 src.selection.data DEBUG    Options: Paperclip, Paper, Brooch, Ring.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "2025-09-15 00:16:14 src.selection.data DEBUG    Options: Anklet, Folder, Necklace, Notebook.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Notebook\n",
      "2025-09-15 00:16:14 src.selection.data DEBUG    Options: Anklet, Folder, Necklace, Notebook.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "sample 96 / 512\n",
      "2025-09-15 00:16:17 src.selection.data DEBUG    Options: Scooter, Submarine, Tie, Sweater.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:16:18 src.selection.data DEBUG    Options: Helicopter, Scarf, Pants, Boat.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:16:18 src.selection.data DEBUG    Options: Helicopter, Scarf, Pants, Boat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "sample 97 / 512\n",
      "2025-09-15 00:16:21 src.selection.data DEBUG    Options: Accordion, Pants, Coat, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:16:22 src.selection.data DEBUG    Options: Drum, Hat, Socks, Harmonica.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "2025-09-15 00:16:22 src.selection.data DEBUG    Options: Drum, Hat, Socks, Harmonica.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Harmon\n",
      "sample 98 / 512\n",
      "2025-09-15 00:16:25 src.selection.data DEBUG    Options: Elephant, Coat, Tiara, Chain, Scarf.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:16:25 src.selection.data DEBUG    Options: Locket, Cufflink, Sweater, Shirt, Sheep.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:16:26 src.selection.data DEBUG    Options: Locket, Cufflink, Sweater, Shirt, Sheep.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "sample 99 / 512\n",
      "2025-09-15 00:16:29 src.selection.data DEBUG    Options: Coat, Shorts, Printer, Headphones.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "2025-09-15 00:16:29 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Printer', prob=0.41015625, logit=19.625, token_id=47033, metadata=None))[\" Head\"] != 11452[\" Head\"]\n",
      "2025-09-15 00:16:29 src.selection.data DEBUG    Options: Smartwatch, Jeans, Projector, Tie.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "2025-09-15 00:16:29 src.selection.data DEBUG    Options: Hat, Laptop, Dress, Mouse.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:16:30 src.selection.data DEBUG    Options: Hat, Laptop, Dress, Mouse.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Mouse\n",
      "sample 100 / 512\n",
      "2025-09-15 00:16:35 src.selection.data DEBUG    Options: Iris, Accordion, Helicopter, Tractor, Hockey stick, Marigold.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "2025-09-15 00:16:35 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hel', prob=0.54296875, logit=19.5, token_id=16183, metadata=None))[\" Hel\"] != 1183[\" Tr\"]\n",
      "2025-09-15 00:16:35 src.selection.data DEBUG    Options: Scooter, Orchid, Sunflower, Truck, Eraser, Flute.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:16:35 src.selection.data DEBUG    Options: Boat, Ruler, Clarinet, Chrysanthemum, Marigold, Bus.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "2025-09-15 00:16:35 src.selection.data DEBUG    Options: Boat, Ruler, Clarinet, Chrysanthemum, Marigold, Bus.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "sample 101 / 512\n",
      "2025-09-15 00:16:39 src.selection.data DEBUG    Options: Necklace, Food processor, Microwave, Pin.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:16:39 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Necklace', prob=0.56640625, logit=19.125, token_id=86460, metadata=None))[\" Necklace\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:16:39 src.selection.data DEBUG    Options: Earring, Air fryer, Chain, Slow cooker.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:16:39 src.selection.data DEBUG    Options: Microwave, Tiara, Food processor, Pin.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:16:39 src.selection.data DEBUG    Options: Microwave, Tiara, Food processor, Pin.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:16:40 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ti', prob=0.71875, logit=19.5, token_id=23126, metadata=None))[\" Ti\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:16:40 src.selection.data DEBUG    Options: Cufflink, Watch, Coffee maker, Juicer.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:16:40 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' C', prob=0.70703125, logit=19.875, token_id=356, metadata=None))[\" C\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:16:40 src.selection.data DEBUG    Options: Cufflink, Juicer, Brooch, Refrigerator.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:16:40 src.selection.data DEBUG    Options: Ring, Tiara, Microwave, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:16:41 src.selection.data DEBUG    Options: Ring, Tiara, Microwave, Blender.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:16:41 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ring', prob=0.400390625, logit=18.875, token_id=22249, metadata=None))[\" Ring\"] != 23126[\" Ti\"]\n",
      "2025-09-15 00:16:41 src.selection.data DEBUG    Options: Mixer, Charm, Slow cooker, Tiara.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:16:41 src.selection.data DEBUG    Options: Toaster, Food processor, Anklet, Brooch.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:16:41 src.selection.data DEBUG    Options: Toaster, Food processor, Anklet, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "sample 102 / 512\n",
      "2025-09-15 00:16:45 src.selection.data DEBUG    Options: Accordion, Scarf, Smartwatch, Laptop, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:16:45 src.selection.data DEBUG    Options: Drum, Jeans, Guitar, Headphones, Tablet.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:16:45 src.selection.data DEBUG    Options: Drum, Jeans, Guitar, Headphones, Tablet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "sample 103 / 512\n",
      "2025-09-15 00:16:49 src.selection.data DEBUG    Options: Lavender, Orchid, Museum, Violin, Mosque.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "2025-09-15 00:16:49 src.selection.data DEBUG    Options: Library, House, Drum, Tulip, Lily.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Lily\n",
      "2025-09-15 00:16:50 src.selection.data DEBUG    Options: Library, House, Drum, Tulip, Lily.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "sample 104 / 512\n",
      "2025-09-15 00:16:53 src.selection.data DEBUG    Options: Smartwatch, Clarinet, Bracelet, Rose, Dog, Keyboard, Saxophone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "2025-09-15 00:16:54 src.selection.data DEBUG    Options: Tulip, Printer, Trombone, Guitar, Necklace, Cat, Tablet.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:16:54 src.selection.data DEBUG    Options: Tulip, Printer, Trombone, Guitar, Necklace, Cat, Tablet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "sample 105 / 512\n",
      "2025-09-15 00:16:57 src.selection.data DEBUG    Options: Toilet, Comb, Suit, Tie.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:16:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Toilet', prob=0.58203125, logit=18.875, token_id=82994, metadata=None))[\" Toilet\"] != 23262[\" Comb\"]\n",
      "2025-09-15 00:16:58 src.selection.data DEBUG    Options: Sink, Hat, Toothpaste, Shirt.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:16:58 src.selection.data DEBUG    Options: Toilet paper, Skirt, Lotion, Suit.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:16:58 src.selection.data DEBUG    Options: Toilet paper, Skirt, Lotion, Suit.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:16:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Toilet', prob=0.5546875, logit=19.5, token_id=82994, metadata=None))[\" Toilet\"] != 445[\" L\"]\n",
      "2025-09-15 00:16:58 src.selection.data DEBUG    Options: Scarf, Mirror, Shampoo, Jacket.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "2025-09-15 00:16:58 src.selection.data DEBUG    Options: Comb, Toilet, Skirt, Coat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Coat\n",
      "2025-09-15 00:16:58 src.selection.data DEBUG    Options: Comb, Toilet, Skirt, Coat.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "sample 106 / 512\n",
      "2025-09-15 00:17:02 src.selection.data DEBUG    Options: Camera, Mouse, Broccoli, Lettuce.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Mouse\n",
      "2025-09-15 00:17:02 src.selection.data DEBUG    Options: Router, Asparagus, Phone, Zucchini.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:17:02 src.selection.data DEBUG    Options: Router, Asparagus, Phone, Zucchini.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "sample 107 / 512\n",
      "2025-09-15 00:17:06 src.selection.data DEBUG    Options: Xylophone, Truck, Tiara, Pin, Harp, Museum, Magnolia.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:17:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ti', prob=0.67578125, logit=19.75, token_id=23126, metadata=None))[\" Ti\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:17:06 src.selection.data DEBUG    Options: Cello, Locket, Smartwatch, Skyscraper, Slow cooker, Pin, Accordion.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:17:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' L', prob=0.6328125, logit=20.5, token_id=445, metadata=None))[\" L\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:17:06 src.selection.data DEBUG    Options: Piano, Truck, Cello, Rabbit, Chain, Eraser, Earring.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:17:06 src.selection.data DEBUG    Options: Saxophone, Trombone, Tractor, Elephant, Watch, Pin, Highlighter.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trom\n",
      "2025-09-15 00:17:06 src.selection.data DEBUG    Options: Saxophone, Trombone, Tractor, Elephant, Watch, Pin, Highlighter.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "sample 108 / 512\n",
      "2025-09-15 00:17:10 src.selection.data DEBUG    Options: Cedar, Birch, Monitor, Boxing gloves, Baseball.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:17:10 src.selection.data DEBUG    Options: Surfboard, Helmet, Television, Willow, Elm.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:17:10 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Surf', prob=0.6328125, logit=19.25, token_id=65197, metadata=None))[\" Surf\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:17:10 src.selection.data DEBUG    Options: Peach, Hickory, Magnolia, Skateboard, Yoga mat.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "2025-09-15 00:17:10 src.selection.data DEBUG    Options: Bat, Cedar, Pineapple, Golf ball, Oak.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:17:11 src.selection.data DEBUG    Options: Bat, Cedar, Pineapple, Golf ball, Oak.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:17:11 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pine', prob=0.5078125, logit=19.5, token_id=42609, metadata=None))[\" Pine\"] != 18787[\" Oak\"]\n",
      "2025-09-15 00:17:11 src.selection.data DEBUG    Options: Trombone, Oak, Helmet, Bat, Willow.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:17:11 src.selection.data DEBUG    Options: Eucalyptus, Baseball, Bamboo, Flute, Hockey stick.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "2025-09-15 00:17:11 src.selection.data DEBUG    Options: Eucalyptus, Baseball, Bamboo, Flute, Hockey stick.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "sample 109 / 512\n",
      "2025-09-15 00:17:15 src.selection.data DEBUG    Options: Warehouse, Bike, Rabbit, Raspberry, Zebra, Mosque, Brooch.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "2025-09-15 00:17:15 src.selection.data DEBUG    Options: Temple, Museum, Elephant, Airplane, Lion, Charm, Cherry.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:17:15 src.selection.data DEBUG    Options: Temple, Museum, Elephant, Airplane, Lion, Charm, Cherry.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "sample 110 / 512\n",
      "2025-09-15 00:17:19 src.selection.data DEBUG    Options: Mango, Gloves, Pear, Library, Bike, Warehouse, Surfboard.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:17:19 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Library', prob=0.423828125, logit=20.625, token_id=11896, metadata=None))[\" Library\"] != 52466[\" Warehouse\"]\n",
      "2025-09-15 00:17:19 src.selection.data DEBUG    Options: Raspberry, Dishwasher, Factory, Harmonica, Museum, Pineapple, Hairdryer.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "2025-09-15 00:17:19 src.selection.data DEBUG    Options: Plum, Kiwi, Warehouse, Trombone, Toilet paper, Refrigerator, House.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:17:19 src.selection.data DEBUG    Options: Plum, Kiwi, Warehouse, Trombone, Toilet paper, Refrigerator, House.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "sample 111 / 512\n",
      "2025-09-15 00:17:23 src.selection.data DEBUG    Options: Slow cooker, Giraffe, Church, Microwave, Eagle.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Microwave\n",
      "2025-09-15 00:17:23 src.selection.data DEBUG    Options: Juicer, Stadium, Dishwasher, Lion, Zebra.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:17:23 src.selection.data DEBUG    Options: Juicer, Stadium, Dishwasher, Lion, Zebra.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "sample 112 / 512\n",
      "2025-09-15 00:17:27 src.selection.data DEBUG    Options: Kettle, Towel, Charm, Monkey, Mirror, Horse.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:17:27 src.selection.data DEBUG    Options: Lotion, Cat, Food processor, Sheep, Toothpaste, Earring.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:17:27 src.selection.data DEBUG    Options: Lotion, Cat, Food processor, Sheep, Toothpaste, Earring.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "sample 113 / 512\n",
      "2025-09-15 00:17:31 src.selection.data DEBUG    Options: Shower, Factory, Bed, Basketball, Boxing gloves, Banana, Orange.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "2025-09-15 00:17:31 src.selection.data DEBUG    Options: Surfboard, Helmet, Nightstand, Grape, Watermelon, Bathtub, Temple.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:17:31 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bat', prob=0.390625, logit=19.25, token_id=16488, metadata=None))[\" Bat\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:17:31 src.selection.data DEBUG    Options: Skis, Watermelon, Plum, Bat, Mosque, Violet, Scooter.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:17:32 src.selection.data DEBUG    Options: Tulip, Theater, Airplane, Kiwi, Apple, Racket, Yoga mat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:17:32 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' R', prob=0.65234375, logit=20.125, token_id=432, metadata=None))[\" R\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:17:32 src.selection.data DEBUG    Options: Suit, Hickory, Cherry, Yoga mat, Bat, Orange, Sink.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "2025-09-15 00:17:32 src.selection.data DEBUG    Options: Helmet, Dress, Comb, Oak, Apple, Hockey stick, Pineapple.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "2025-09-15 00:17:32 src.selection.data DEBUG    Options: Helmet, Dress, Comb, Oak, Apple, Hockey stick, Pineapple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pine\n",
      "sample 114 / 512\n",
      "2025-09-15 00:17:36 src.selection.data DEBUG    Options: Recliner, Airplane, Bench, Tractor.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "2025-09-15 00:17:36 src.selection.data DEBUG    Options: Bike, Train, Ottoman, Table.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Table\n",
      "2025-09-15 00:17:36 src.selection.data DEBUG    Options: Bike, Train, Ottoman, Table.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "sample 115 / 512\n",
      "2025-09-15 00:17:39 src.selection.data DEBUG    Options: Birch, Cedar, Socks, Scarf, Monitor, Lavender.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "2025-09-15 00:17:40 src.selection.data DEBUG    Options: Projector, Maple, Lily, Ash, Tie, Sweater.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:17:40 src.selection.data DEBUG    Options: Projector, Maple, Lily, Ash, Tie, Sweater.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "sample 116 / 512\n",
      "2025-09-15 00:17:43 src.selection.data DEBUG    Options: Dishwasher, Piano, Saxophone, Stadium, Jeans, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:17:44 src.selection.data DEBUG    Options: Clarinet, Cello, Mosque, Warehouse, Pants, Mixer.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:17:44 src.selection.data DEBUG    Options: Clarinet, Cello, Mosque, Warehouse, Pants, Mixer.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "sample 117 / 512\n",
      "2025-09-15 00:17:48 src.selection.data DEBUG    Options: Football, Cucumber, Earring, Redwood, Dumbbell, Mango, Strawberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:17:48 src.selection.data DEBUG    Options: Plum, Ring, Onion, Boxing gloves, Apple, Magnolia, Helmet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:17:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boxing', prob=0.765625, logit=20.5, token_id=72683, metadata=None))[\" Boxing\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:17:48 src.selection.data DEBUG    Options: Raspberry, Helmet, Golf ball, Microwave, Mango, Stool, Jeans.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Mango\n",
      "2025-09-15 00:17:48 src.selection.data DEBUG    Options: Grape, Table, Racket, Plum, Gloves, Refrigerator, Yoga mat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:17:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' R', prob=0.466796875, logit=19.125, token_id=432, metadata=None))[\" R\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:17:48 src.selection.data DEBUG    Options: Razor, Toaster, Mango, Basketball, Headphones, Orange, Skis.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "2025-09-15 00:17:49 src.selection.data DEBUG    Options: Smartwatch, Racket, Air fryer, Toilet paper, Blueberry, Dumbbell, Plum.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:17:49 src.selection.data DEBUG    Options: Smartwatch, Racket, Air fryer, Toilet paper, Blueberry, Dumbbell, Plum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "sample 118 / 512\n",
      "2025-09-15 00:17:52 src.selection.data DEBUG    Options: Zucchini, Ruler, Maple, Oak, Potato, Stadium.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Potato\n",
      "2025-09-15 00:17:53 src.selection.data DEBUG    Options: Factory, Tomato, Onion, Folder, Birch, Eucalyptus.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:17:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Birch', prob=0.55078125, logit=19.125, token_id=88088, metadata=None))[\" Birch\"] != 469[\" E\"]\n",
      "2025-09-15 00:17:53 src.selection.data DEBUG    Options: Helmet, Tiara, Mushroom, Cedar, Maple, Tomato.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:17:53 src.selection.data DEBUG    Options: Hickory, Chain, Oak, Potato, Onion, Racket.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:17:53 src.selection.data DEBUG    Options: Hickory, Chain, Oak, Potato, Onion, Racket.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "sample 119 / 512\n",
      "2025-09-15 00:17:57 src.selection.data DEBUG    Options: Tractor, Chain, Earring, Scooter, Jeans.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:17:57 src.selection.data DEBUG    Options: Hat, Bracelet, Airplane, Pin, Boat.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:17:57 src.selection.data DEBUG    Options: Hat, Bracelet, Airplane, Pin, Boat.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "sample 120 / 512\n",
      "2025-09-15 00:18:01 src.selection.data DEBUG    Options: Food processor, Tape, Calculator, Kettle.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  K\n",
      "2025-09-15 00:18:01 src.selection.data DEBUG    Options: Juicer, Pencil, Folder, Rice cooker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:18:01 src.selection.data DEBUG    Options: Juicer, Pencil, Folder, Rice cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Rice\n",
      "sample 121 / 512\n",
      "2025-09-15 00:18:05 src.selection.data DEBUG    Options: Necklace, Watermelon, Clarinet, Marigold, Palm, Pine, Locket.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:18:05 src.selection.data DEBUG    Options: Tiara, Bamboo, Trumpet, Chain, Redwood, Daffodil, Mango.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:18:06 src.selection.data DEBUG    Options: Tiara, Bamboo, Trumpet, Chain, Redwood, Daffodil, Mango.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "sample 122 / 512\n",
      "2025-09-15 00:18:09 src.selection.data DEBUG    Options: Helicopter, Airplane, Watermelon, Banana.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:18:09 src.selection.data DEBUG    Options: Peach, Pear, Scooter, Submarine.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "2025-09-15 00:18:10 src.selection.data DEBUG    Options: Peach, Pear, Scooter, Submarine.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "sample 123 / 512\n",
      "2025-09-15 00:18:13 src.selection.data DEBUG    Options: Keyboard, Router, Bed, Nightstand.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "2025-09-15 00:18:13 src.selection.data DEBUG    Options: Wardrobe, Coffee table, Camera, Speaker.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:18:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Speaker', prob=0.439453125, logit=18.375, token_id=30173, metadata=None))[\" Speaker\"] != 27171[\" Coffee\"]\n",
      "2025-09-15 00:18:13 src.selection.data DEBUG    Options: Microphone, Bookshelf, Phone, Sofa.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:18:14 src.selection.data DEBUG    Options: Desk, Keyboard, Bed, Projector.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:18:14 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Project', prob=0.796875, logit=20.25, token_id=5907, metadata=None))[\" Project\"] != 13394[\" Bed\"]\n",
      "2025-09-15 00:18:14 src.selection.data DEBUG    Options: Desk, Keyboard, Projector, Chair.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "2025-09-15 00:18:14 src.selection.data DEBUG    Options: Recliner, Dresser, Microphone, Smartwatch.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:18:14 src.selection.data DEBUG    Options: Recliner, Dresser, Microphone, Smartwatch.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "sample 124 / 512\n",
      "2025-09-15 00:18:18 src.selection.data DEBUG    Options: Pin, Violin, Bangle, Drum.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:18:18 src.selection.data DEBUG    Options: Bracelet, Harmonica, Harp, Cufflink.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "2025-09-15 00:18:18 src.selection.data DEBUG    Options: Bracelet, Harmonica, Harp, Cufflink.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "sample 125 / 512\n",
      "2025-09-15 00:18:21 src.selection.data DEBUG    Options: Toilet paper, Skyscraper, Warehouse, Razor.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:18:22 src.selection.data DEBUG    Options: Shampoo, Comb, Stadium, Church.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:18:22 src.selection.data DEBUG    Options: Shampoo, Comb, Stadium, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "sample 126 / 512\n",
      "2025-09-15 00:18:25 src.selection.data DEBUG    Options: Jeans, Mosque, Yoga mat, Stadium, Racket.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:18:25 src.selection.data DEBUG    Options: Basketball, Mall, Dumbbell, Warehouse, Hat.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:18:26 src.selection.data DEBUG    Options: Basketball, Mall, Dumbbell, Warehouse, Hat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "sample 127 / 512\n",
      "2025-09-15 00:18:29 src.selection.data DEBUG    Options: Lily, Piano, Pendant, Razor, Harp, Mirror.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:18:29 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Razor', prob=0.53125, logit=20.125, token_id=74968, metadata=None))[\" Razor\"] != 34954[\" Mirror\"]\n",
      "2025-09-15 00:18:29 src.selection.data DEBUG    Options: Helicopter, Harp, Mirror, Dishwasher, Trumpet, Toothpaste.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:18:30 src.selection.data DEBUG    Options: Shower, Toilet, Trombone, Car, Flute, Oven.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:18:30 src.selection.data DEBUG    Options: Shower, Toilet, Trombone, Car, Flute, Oven.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "sample 128 / 512\n",
      "2025-09-15 00:18:33 src.selection.data DEBUG    Options: Pen, Stadium, Apartment, Dolphin, Zebra.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:18:33 src.selection.data DEBUG    Options: Temple, Factory, Rabbit, Monkey, Pencil.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Factory\n",
      "2025-09-15 00:18:34 src.selection.data DEBUG    Options: Temple, Factory, Rabbit, Monkey, Pencil.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "sample 129 / 512\n",
      "2025-09-15 00:18:37 src.selection.data DEBUG    Options: Ring, Wardrobe, Highlighter, Cufflink, Chair, Juicer.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Chair\n",
      "2025-09-15 00:18:37 src.selection.data DEBUG    Options: Binder, Coffee table, Locket, Toaster, Pin, Sofa.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:18:37 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' L', prob=0.69921875, logit=19.75, token_id=445, metadata=None))[\" L\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:18:37 src.selection.data DEBUG    Options: Ring, Wardrobe, Dresser, Temple, Brooch, Eucalyptus.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:18:38 src.selection.data DEBUG    Options: Apartment, Chain, Elm, Cabinet, Pin, Ottoman.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:18:38 src.selection.data DEBUG    Options: Apartment, Chain, Elm, Cabinet, Pin, Ottoman.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "sample 130 / 512\n",
      "2025-09-15 00:18:41 src.selection.data DEBUG    Options: House, Bamboo, School, Shirt, Pear, Pineapple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:18:41 src.selection.data DEBUG    Options: Plum, Stadium, Gloves, Grape, Palm, Temple.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:18:42 src.selection.data DEBUG    Options: Plum, Stadium, Gloves, Grape, Palm, Temple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "sample 131 / 512\n",
      "2025-09-15 00:18:45 src.selection.data DEBUG    Options: Refrigerator, Ring, Mixer, Necklace, Orange.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "2025-09-15 00:18:45 src.selection.data DEBUG    Options: Bracelet, Dishwasher, Food processor, Plum, Brooch.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:18:45 src.selection.data DEBUG    Options: Bracelet, Dishwasher, Food processor, Plum, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "sample 132 / 512\n",
      "2025-09-15 00:18:49 src.selection.data DEBUG    Options: Tomato, Paper, Pencil, Toilet paper, Towel.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:18:49 src.selection.data DEBUG    Options: Potato, Pen, Sink, Tape, Toothpaste.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:18:49 src.selection.data DEBUG    Options: Potato, Pen, Sink, Tape, Toothpaste.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:18:50 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pen', prob=0.71875, logit=20.625, token_id=13597, metadata=None))[\" Pen\"] != 58586[\" Tape\"]\n",
      "2025-09-15 00:18:50 src.selection.data DEBUG    Options: Lotion, Toothpaste, Paper, Stapler, Rice cooker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "2025-09-15 00:18:50 src.selection.data DEBUG    Options: Binder, Ruler, Shampoo, Refrigerator, Shower.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:18:50 src.selection.data DEBUG    Options: Binder, Ruler, Shampoo, Refrigerator, Shower.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "sample 133 / 512\n",
      "2025-09-15 00:18:54 src.selection.data DEBUG    Options: Spinach, Trombone, Toilet paper, Guitar, Watermelon, Bangle, Toothbrush.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "2025-09-15 00:18:54 src.selection.data DEBUG    Options: Blueberry, Celery, Ukulele, Necklace, Saxophone, Razor, Comb.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:18:54 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Razor', prob=0.515625, logit=20.0, token_id=74968, metadata=None))[\" Razor\"] != 23262[\" Comb\"]\n",
      "2025-09-15 00:18:54 src.selection.data DEBUG    Options: Microwave, Bathtub, Pine, Trombone, Strawberry, Toilet paper, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:18:54 src.selection.data DEBUG    Options: Saxophone, Towel, Harp, Oak, Mixer, Toothpaste, Blueberry.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:18:54 src.selection.data DEBUG    Options: Saxophone, Towel, Harp, Oak, Mixer, Toothpaste, Blueberry.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "sample 134 / 512\n",
      "2025-09-15 00:18:58 src.selection.data DEBUG    Options: Blender, Skis, Golf ball, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:18:58 src.selection.data DEBUG    Options: Dumbbell, Oven, Food processor, Surfboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:18:58 src.selection.data DEBUG    Options: Dumbbell, Oven, Food processor, Surfboard.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "sample 135 / 512\n",
      "2025-09-15 00:19:02 src.selection.data DEBUG    Options: Zucchini, Bike, Surfboard, Juicer, Mushroom, Football.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:19:02 src.selection.data DEBUG    Options: Pepper, Hockey stick, Dumbbell, Lettuce, Ambulance, Rice cooker.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:19:02 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hockey', prob=0.625, logit=20.375, token_id=41342, metadata=None))[\" Hockey\"] != 423[\" D\"]\n",
      "2025-09-15 00:19:02 src.selection.data DEBUG    Options: Tennis ball, Potato, Football, Binder, Pear, Cauliflower.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "2025-09-15 00:19:02 src.selection.data DEBUG    Options: Pepper, Paperclip, Bat, Boxing gloves, Tomato, Banana.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:19:03 src.selection.data DEBUG    Options: Pepper, Paperclip, Bat, Boxing gloves, Tomato, Banana.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:19:03 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pepper', prob=0.333984375, logit=19.5, token_id=52882, metadata=None))[\" Pepper\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:19:03 src.selection.data DEBUG    Options: Broccoli, Skis, Marigold, Carrot, Banana, Helmet.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:19:03 src.selection.data DEBUG    Options: Racket, Cucumber, Potato, Mango, Chrysanthemum, Golf ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:19:03 src.selection.data DEBUG    Options: Racket, Cucumber, Potato, Mango, Chrysanthemum, Golf ball.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Potato\n",
      "sample 136 / 512\n",
      "2025-09-15 00:19:07 src.selection.data DEBUG    Options: Phone, Theater, Television, Palm, Stool, Hospital.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "2025-09-15 00:19:07 src.selection.data DEBUG    Options: Chair, Church, Mall, Printer, Oak, Microphone.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:19:07 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Church', prob=0.73046875, logit=19.875, token_id=9441, metadata=None))[\" Church\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:19:07 src.selection.data DEBUG    Options: Mosque, Violin, Mouse, Sunflower, Tablet, Warehouse.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:19:07 src.selection.data DEBUG    Options: Lavender, Router, Camera, Stadium, Apartment, Trombone.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "2025-09-15 00:19:07 src.selection.data DEBUG    Options: Lavender, Router, Camera, Stadium, Apartment, Trombone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Camera\n",
      "sample 137 / 512\n",
      "2025-09-15 00:19:11 src.selection.data DEBUG    Options: Cat, Horse, Paperclip, Toothbrush, Truck, Van.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "2025-09-15 00:19:11 src.selection.data DEBUG    Options: Train, Dolphin, Lotion, Lion, Bike, Marker.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:19:11 src.selection.data DEBUG    Options: Train, Dolphin, Lotion, Lion, Bike, Marker.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "sample 138 / 512\n",
      "2025-09-15 00:19:15 src.selection.data DEBUG    Options: Anklet, Mango, Ruler, Watermelon, Accordion, Church, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:19:15 src.selection.data DEBUG    Options: Guitar, Xylophone, Cherry, Kiwi, Museum, Folder, Pendant.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:19:15 src.selection.data DEBUG    Options: Guitar, Xylophone, Cherry, Kiwi, Museum, Folder, Pendant.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "sample 139 / 512\n",
      "2025-09-15 00:19:18 src.selection.data DEBUG    Options: Giraffe, Hairdryer, Zebra, Razor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:19:19 src.selection.data DEBUG    Options: Bathtub, Towel, Monkey, Eagle.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Eagle\n",
      "2025-09-15 00:19:19 src.selection.data DEBUG    Options: Bathtub, Towel, Monkey, Eagle.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tow\n",
      "sample 140 / 512\n",
      "2025-09-15 00:19:22 src.selection.data DEBUG    Options: Orchid, Food processor, Piano, Peony, Microphone, Socks, Pants.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:19:23 src.selection.data DEBUG    Options: Suit, Sunflower, Lily, Jeans, Rice cooker, Drum, Tablet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Lily\n",
      "2025-09-15 00:19:23 src.selection.data DEBUG    Options: Suit, Sunflower, Lily, Jeans, Rice cooker, Drum, Tablet.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "sample 141 / 512\n",
      "2025-09-15 00:19:26 src.selection.data DEBUG    Options: Redwood, Laptop, Monitor, Hickory.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "2025-09-15 00:19:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Red', prob=0.34375, logit=17.875, token_id=3816, metadata=None))[\" Red\"] != 79028[\" Hick\"]\n",
      "2025-09-15 00:19:26 src.selection.data DEBUG    Options: Bamboo, Eucalyptus, Monitor, Television.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:19:27 src.selection.data DEBUG    Options: Palm, Redwood, Microphone, Smartwatch.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "2025-09-15 00:19:27 src.selection.data DEBUG    Options: Palm, Redwood, Microphone, Smartwatch.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "sample 142 / 512\n",
      "2025-09-15 00:19:30 src.selection.data DEBUG    Options: Ash, Drum, Hickory, Trumpet.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "2025-09-15 00:19:31 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Trump', prob=0.58984375, logit=18.625, token_id=3420, metadata=None))[\" Trump\"] != 79028[\" Hick\"]\n",
      "2025-09-15 00:19:31 src.selection.data DEBUG    Options: Trombone, Willow, Cedar, Saxophone.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "2025-09-15 00:19:31 src.selection.data DEBUG    Options: Harp, Bamboo, Trumpet, Magnolia.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trump\n",
      "2025-09-15 00:19:31 src.selection.data DEBUG    Options: Harp, Bamboo, Trumpet, Magnolia.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "sample 143 / 512\n",
      "2025-09-15 00:19:34 src.selection.data DEBUG    Options: Library, Television, Temple, Laptop.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:19:35 src.selection.data DEBUG    Options: Warehouse, Keyboard, Camera, Mosque.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Camera\n",
      "2025-09-15 00:19:35 src.selection.data DEBUG    Options: Warehouse, Keyboard, Camera, Mosque.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "sample 144 / 512\n",
      "2025-09-15 00:19:38 src.selection.data DEBUG    Options: Baseball, Basketball, Lavender, Marigold.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "2025-09-15 00:19:38 src.selection.data DEBUG    Options: Sunflower, Dumbbell, Daffodil, Football.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:19:39 src.selection.data DEBUG    Options: Sunflower, Dumbbell, Daffodil, Football.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  D\n",
      "sample 145 / 512\n",
      "2025-09-15 00:19:42 src.selection.data DEBUG    Options: Iris, Peony, Palm, Elm, Theater.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Pe\n",
      "2025-09-15 00:19:43 src.selection.data DEBUG    Options: Hickory, Hospital, Spruce, Carnation, Violet.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:19:43 src.selection.data DEBUG    Options: Hickory, Hospital, Spruce, Carnation, Violet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "sample 146 / 512\n",
      "2025-09-15 00:19:46 src.selection.data DEBUG    Options: Blender, Onion, Cauliflower, Bookshelf, Chair.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "2025-09-15 00:19:46 src.selection.data DEBUG    Options: Spinach, Tomato, Coffee table, Oven, Stool.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:19:47 src.selection.data DEBUG    Options: Spinach, Tomato, Coffee table, Oven, Stool.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:19:47 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Spin', prob=0.3203125, logit=18.375, token_id=41785, metadata=None))[\" Spin\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:19:47 src.selection.data DEBUG    Options: Sofa, Cucumber, Bookshelf, Eagle, Tomato.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:19:47 src.selection.data DEBUG    Options: Cabinet, Zucchini, Potato, Ottoman, Bear.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "2025-09-15 00:19:47 src.selection.data DEBUG    Options: Cabinet, Zucchini, Potato, Ottoman, Bear.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Potato\n",
      "sample 147 / 512\n",
      "2025-09-15 00:19:51 src.selection.data DEBUG    Options: Clarinet, Accordion, Watermelon, Pear, Ambulance.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "2025-09-15 00:19:51 src.selection.data DEBUG    Options: Flute, Truck, Kiwi, Ukulele, Pineapple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:19:51 src.selection.data DEBUG    Options: Flute, Truck, Kiwi, Ukulele, Pineapple.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "sample 148 / 512\n",
      "2025-09-15 00:19:54 src.selection.data DEBUG    Options: Bangle, Pen, Pants, Warehouse, Oak, Coat, Palm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Palm\n",
      "2025-09-15 00:19:55 src.selection.data DEBUG    Options: Elm, Skirt, Gloves, Scissors, Ring, Pine, Apartment.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:19:55 src.selection.data DEBUG    Options: Elm, Skirt, Gloves, Scissors, Ring, Pine, Apartment.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "sample 149 / 512\n",
      "2025-09-15 00:19:58 src.selection.data DEBUG    Options: Comb, Willow, Skis, Warehouse, Hospital, Pine, Sweater.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "2025-09-15 00:19:59 src.selection.data DEBUG    Options: Factory, Socks, Library, Baseball, Razor, Eucalyptus, Magnolia.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "2025-09-15 00:19:59 src.selection.data DEBUG    Options: Factory, Socks, Library, Baseball, Razor, Eucalyptus, Magnolia.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "sample 150 / 512\n",
      "2025-09-15 00:20:02 src.selection.data DEBUG    Options: School, Cow, Dog, Suit, Projector, Shirt.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:20:02 src.selection.data DEBUG    Options: Lion, Dress, Keyboard, Elephant, Jeans, Factory.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "2025-09-15 00:20:03 src.selection.data DEBUG    Options: Lion, Dress, Keyboard, Elephant, Jeans, Factory.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Elephant\n",
      "sample 151 / 512\n",
      "2025-09-15 00:20:06 src.selection.data DEBUG    Options: Tractor, Monitor, Stool, Recliner, Speaker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 00:20:06 src.selection.data DEBUG    Options: Headphones, Sofa, Bed, Smartwatch, Helicopter.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:20:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Sofa', prob=0.64453125, logit=20.0, token_id=61948, metadata=None))[\" Sofa\"] != 13394[\" Bed\"]\n",
      "2025-09-15 00:20:06 src.selection.data DEBUG    Options: Bat, Television, Laptop, Coffee table, Bench.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "2025-09-15 00:20:07 src.selection.data DEBUG    Options: Surfboard, Microphone, Nightstand, Stool, Router.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:20:07 src.selection.data DEBUG    Options: Surfboard, Microphone, Nightstand, Stool, Router.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "sample 152 / 512\n",
      "2025-09-15 00:20:10 src.selection.data DEBUG    Options: Factory, Kiwi, Bed, Chair, Tape, Apple.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Chair\n",
      "2025-09-15 00:20:10 src.selection.data DEBUG    Options: Banana, Stool, Dresser, Mosque, Folder, Watermelon.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:20:11 src.selection.data DEBUG    Options: Banana, Stool, Dresser, Mosque, Folder, Watermelon.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Dress\n",
      "sample 153 / 512\n",
      "2025-09-15 00:20:14 src.selection.data DEBUG    Options: Racket, Strawberry, Kiwi, Maple, Pine.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:20:14 src.selection.data DEBUG    Options: Raspberry, Apple, Eucalyptus, Tennis ball, Ash.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "2025-09-15 00:20:15 src.selection.data DEBUG    Options: Raspberry, Apple, Eucalyptus, Tennis ball, Ash.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "sample 154 / 512\n",
      "2025-09-15 00:20:18 src.selection.data DEBUG    Options: Skyscraper, Router, Camera, Elm, Toilet, Coffee maker, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:20:18 src.selection.data DEBUG    Options: Soap, Dishwasher, Pine, Library, Slow cooker, Tablet, Microphone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Micro\n",
      "2025-09-15 00:20:18 src.selection.data DEBUG    Options: Soap, Dishwasher, Pine, Library, Slow cooker, Tablet, Microphone.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "sample 155 / 512\n",
      "2025-09-15 00:20:22 src.selection.data DEBUG    Options: Wardrobe, Tomato, Pepper, Trumpet, Factory, Museum, Microphone.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Pepper\n",
      "2025-09-15 00:20:22 src.selection.data DEBUG    Options: Asparagus, School, Stool, Accordion, Cucumber, Projector, House.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:20:22 src.selection.data DEBUG    Options: Asparagus, School, Stool, Accordion, Cucumber, Projector, House.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "sample 156 / 512\n",
      "2025-09-15 00:20:26 src.selection.data DEBUG    Options: Mango, Towel, Hockey stick, Toothbrush, Table, Cherry, Trumpet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:20:26 src.selection.data DEBUG    Options: Apple, Wardrobe, Toothpaste, Skis, Piano, Bathtub, Pear.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:20:26 src.selection.data DEBUG    Options: Apple, Wardrobe, Toothpaste, Skis, Piano, Bathtub, Pear.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "sample 157 / 512\n",
      "2025-09-15 00:20:30 src.selection.data DEBUG    Options: Violin, Dolphin, Ukulele, Zebra.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:20:30 src.selection.data DEBUG    Options: Monkey, Guitar, Bear, Harmonica.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Harmon\n",
      "2025-09-15 00:20:30 src.selection.data DEBUG    Options: Monkey, Guitar, Bear, Harmonica.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "sample 158 / 512\n",
      "2025-09-15 00:20:33 src.selection.data DEBUG    Options: Bamboo, Suit, Pendant, Surfboard, Earring, Hat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "2025-09-15 00:20:34 src.selection.data DEBUG    Options: Bangle, Coat, Socks, Golf ball, Spruce, Bracelet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "2025-09-15 00:20:34 src.selection.data DEBUG    Options: Bangle, Coat, Socks, Golf ball, Spruce, Bracelet.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "sample 159 / 512\n",
      "2025-09-15 00:20:37 src.selection.data DEBUG    Options: Microwave, Headphones, Microphone, Slow cooker, Surfboard.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "2025-09-15 00:20:38 src.selection.data DEBUG    Options: Juicer, Tennis ball, Smartwatch, Television, Air fryer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "2025-09-15 00:20:38 src.selection.data DEBUG    Options: Juicer, Tennis ball, Smartwatch, Television, Air fryer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "sample 160 / 512\n",
      "2025-09-15 00:20:42 src.selection.data DEBUG    Options: Theater, Projector, Juicer, Shampoo, Warehouse, Hockey stick, Television.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "2025-09-15 00:20:42 src.selection.data DEBUG    Options: Skyscraper, Helmet, Temple, Toaster, Mouse, Monitor, Shower.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:20:42 src.selection.data DEBUG    Options: Skyscraper, Helmet, Temple, Toaster, Mouse, Monitor, Shower.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "sample 161 / 512\n",
      "2025-09-15 00:20:45 src.selection.data DEBUG    Options: Nightstand, Bed, Towel, Shampoo.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:20:46 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Tow', prob=0.34765625, logit=17.875, token_id=41493, metadata=None))[\" Sh\"] != 13394[\" Bed\"]\n",
      "2025-09-15 00:20:46 src.selection.data DEBUG    Options: Toilet paper, Comb, Sofa, Recliner.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Re\n",
      "2025-09-15 00:20:46 src.selection.data DEBUG    Options: Towel, Bathtub, Bed, Dresser.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:20:46 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tow', prob=0.486328125, logit=20.375, token_id=41493, metadata=None))[\" Tow\"] != 16488[\" Bat\"]\n",
      "2025-09-15 00:20:46 src.selection.data DEBUG    Options: Comb, Toothbrush, Sofa, Dresser.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:20:46 src.selection.data DEBUG    Options: Lotion, Soap, Recliner, Cabinet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Soap\n",
      "2025-09-15 00:20:46 src.selection.data DEBUG    Options: Lotion, Soap, Recliner, Cabinet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "sample 162 / 512\n",
      "2025-09-15 00:20:50 src.selection.data DEBUG    Options: Museum, Pants, Suit, Ambulance, Potato, Car, Dresser.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:20:50 src.selection.data DEBUG    Options: Dress, House, Helicopter, Submarine, Cauliflower, Bookshelf, Skirt.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:20:51 src.selection.data DEBUG    Options: Dress, House, Helicopter, Submarine, Cauliflower, Bookshelf, Skirt.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "sample 163 / 512\n",
      "2025-09-15 00:20:54 src.selection.data DEBUG    Options: Raspberry, Blueberry, Football, Helmet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "2025-09-15 00:20:54 src.selection.data DEBUG    Options: Racket, Dumbbell, Apple, Strawberry.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:20:55 src.selection.data DEBUG    Options: Racket, Dumbbell, Apple, Strawberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "sample 164 / 512\n",
      "2025-09-15 00:20:58 src.selection.data DEBUG    Options: Skirt, Mall, Jeans, Kettle, Factory.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "2025-09-15 00:20:58 src.selection.data DEBUG    Options: Coat, Microwave, Museum, Shorts, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:20:58 src.selection.data DEBUG    Options: Coat, Microwave, Museum, Shorts, Church.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shorts\n",
      "sample 165 / 512\n",
      "2025-09-15 00:21:02 src.selection.data DEBUG    Options: Towel, Mango, Peach, Toilet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:21:02 src.selection.data DEBUG    Options: Watermelon, Strawberry, Mirror, Sink.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:21:02 src.selection.data DEBUG    Options: Watermelon, Strawberry, Mirror, Sink.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 166 / 512\n",
      "2025-09-15 00:21:06 src.selection.data DEBUG    Options: Lotion, Ambulance, Skyscraper, Oak, Celery, Shampoo, Cucumber.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "2025-09-15 00:21:06 src.selection.data DEBUG    Options: Helicopter, Apartment, Shower, Carrot, Soap, Broccoli, Eucalyptus.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:21:06 src.selection.data DEBUG    Options: Helicopter, Apartment, Shower, Carrot, Soap, Broccoli, Eucalyptus.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Soap\n",
      "sample 167 / 512\n",
      "2025-09-15 00:21:10 src.selection.data DEBUG    Options: Mirror, Redwood, Mall, Temple, Pine.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:21:10 src.selection.data DEBUG    Options: Willow, Warehouse, Cedar, Toothbrush, Stadium.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "2025-09-15 00:21:10 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Willow', prob=0.423828125, logit=18.875, token_id=65449, metadata=None))[\" Willow\"] != 57748[\" Cedar\"]\n",
      "2025-09-15 00:21:10 src.selection.data DEBUG    Options: School, Museum, Ottoman, Palm, Pine.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "2025-09-15 00:21:10 src.selection.data DEBUG    Options: Elm, Church, Theater, Redwood, Sofa.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:21:10 src.selection.data DEBUG    Options: Elm, Church, Theater, Redwood, Sofa.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "sample 168 / 512\n",
      "2025-09-15 00:21:14 src.selection.data DEBUG    Options: Boxing gloves, Football, Drum, Saxophone.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:21:14 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boxing', prob=0.4296875, logit=19.375, token_id=72683, metadata=None))[\" Boxing\"] != 21424[\" Football\"]\n",
      "2025-09-15 00:21:14 src.selection.data DEBUG    Options: Helmet, Piano, Violin, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:21:14 src.selection.data DEBUG    Options: Yoga mat, Guitar, Bat, Cello.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:21:14 src.selection.data DEBUG    Options: Yoga mat, Guitar, Bat, Cello.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Bat\n",
      "sample 169 / 512\n",
      "2025-09-15 00:21:18 src.selection.data DEBUG    Options: Cedar, Redwood, Horse, Paperclip, Tape.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:21:18 src.selection.data DEBUG    Options: Scissors, Bamboo, Calculator, Elm, Monkey.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "2025-09-15 00:21:18 src.selection.data DEBUG    Options: Scissors, Bamboo, Calculator, Elm, Monkey.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "sample 170 / 512\n",
      "2025-09-15 00:21:22 src.selection.data DEBUG    Options: Smartwatch, Microwave, Pin, Rice cooker, Pen, Binder, Trumpet.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:21:22 src.selection.data DEBUG    Options: Mixer, Toaster, Harmonica, Headphones, Chain, Highlighter, Notebook.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  To\n",
      "2025-09-15 00:21:22 src.selection.data DEBUG    Options: Mixer, Toaster, Harmonica, Headphones, Chain, Highlighter, Notebook.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Notebook\n",
      "2025-09-15 00:21:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Highlight', prob=0.421875, logit=19.5, token_id=57094, metadata=None))[\" Highlight\"] != 69755[\" Notebook\"]\n",
      "2025-09-15 00:21:22 src.selection.data DEBUG    Options: Temple, Cedar, Marker, Binder, Car, Microwave, Toaster.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:21:23 src.selection.data DEBUG    Options: Stapler, Pine, Paperclip, Apartment, Truck, Juicer, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:21:23 src.selection.data DEBUG    Options: Stapler, Pine, Paperclip, Apartment, Truck, Juicer, Pressure cooker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:21:23 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.50390625, logit=19.25, token_id=63606, metadata=None))[\" Stap\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:21:23 src.selection.data DEBUG    Options: Notebook, Scissors, Mixer, Piano, Watch, Slow cooker, Lotion.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:21:23 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Notebook', prob=0.76953125, logit=20.125, token_id=69755, metadata=None))[\" Notebook\"] != 2522[\" Sc\"]\n",
      "2025-09-15 00:21:23 src.selection.data DEBUG    Options: Violin, Elephant, Eraser, Toaster, Juicer, Pencil, Cucumber.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:21:23 src.selection.data DEBUG    Options: Paper, Cello, Paperclip, Slow cooker, Refrigerator, Potato, Horse.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "2025-09-15 00:21:24 src.selection.data DEBUG    Options: Paper, Cello, Paperclip, Slow cooker, Refrigerator, Potato, Horse.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 171 / 512\n",
      "2025-09-15 00:21:27 src.selection.data DEBUG    Options: Scissors, Highlighter, Dishwasher, Hat, Bamboo, Wardrobe, Food processor.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 00:21:27 src.selection.data DEBUG    Options: Ruler, Cedar, Skirt, Coffee maker, Marker, Blender, Bed.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:21:28 src.selection.data DEBUG    Options: Ruler, Cedar, Skirt, Coffee maker, Marker, Blender, Bed.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "sample 172 / 512\n",
      "2025-09-15 00:21:31 src.selection.data DEBUG    Options: Drum, Toothpaste, Zebra, Mango, Cat, Pencil, Pen.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:21:32 src.selection.data DEBUG    Options: Sheep, Plum, Flute, Dog, Toilet paper, Tape, Scissors.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:21:32 src.selection.data DEBUG    Options: Sheep, Plum, Flute, Dog, Toilet paper, Tape, Scissors.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "sample 173 / 512\n",
      "2025-09-15 00:21:35 src.selection.data DEBUG    Options: Raspberry, Mushroom, Anklet, Baseball, Locket, Grape, Suit.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "2025-09-15 00:21:35 src.selection.data DEBUG    Options: Bangle, Orange, Jeans, Cucumber, Hockey stick, Earring, Blueberry.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:21:36 src.selection.data DEBUG    Options: Bangle, Orange, Jeans, Cucumber, Hockey stick, Earring, Blueberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "sample 174 / 512\n",
      "2025-09-15 00:21:39 src.selection.data DEBUG    Options: Saxophone, Rice cooker, Monitor, Accordion, Carrot, Pressure cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:21:39 src.selection.data DEBUG    Options: Blender, Dishwasher, Piano, Smartwatch, Mushroom, Ukulele.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "2025-09-15 00:21:40 src.selection.data DEBUG    Options: Blender, Dishwasher, Piano, Smartwatch, Mushroom, Ukulele.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "sample 175 / 512\n",
      "2025-09-15 00:21:43 src.selection.data DEBUG    Options: Eagle, Tiger, Microphone, Camera, Cauliflower.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Camera\n",
      "2025-09-15 00:21:43 src.selection.data DEBUG    Options: Phone, Bear, Dog, Lettuce, Printer.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:21:44 src.selection.data DEBUG    Options: Phone, Bear, Dog, Lettuce, Printer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "sample 176 / 512\n",
      "2025-09-15 00:21:47 src.selection.data DEBUG    Options: Tomato, Asparagus, Nightstand, Coffee table, Bathtub.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:21:47 src.selection.data DEBUG    Options: Bookshelf, Lettuce, Cabinet, Toilet paper, Celery.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "2025-09-15 00:21:48 src.selection.data DEBUG    Options: Bookshelf, Lettuce, Cabinet, Toilet paper, Celery.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "sample 177 / 512\n",
      "2025-09-15 00:21:51 src.selection.data DEBUG    Options: Brooch, Lotion, Helicopter, Sunflower, Cufflink, Tape, Train.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:21:51 src.selection.data DEBUG    Options: Tractor, Folder, Car, Soap, Tiara, Iris, Locket.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:21:52 src.selection.data DEBUG    Options: Tractor, Folder, Car, Soap, Tiara, Iris, Locket.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "sample 178 / 512\n",
      "2025-09-15 00:21:55 src.selection.data DEBUG    Options: Rabbit, Shirt, Bat, Headphones, Eraser, Cat, Jeans.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:21:56 src.selection.data DEBUG    Options: Shorts, Projector, Lion, Racket, Scarf, Stapler, Zebra.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:21:56 src.selection.data DEBUG    Options: Shorts, Projector, Lion, Racket, Scarf, Stapler, Zebra.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "sample 179 / 512\n",
      "2025-09-15 00:21:59 src.selection.data DEBUG    Options: Plum, Lavender, Skyscraper, Church, Ruler, Eraser.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:22:00 src.selection.data DEBUG    Options: Grape, Temple, Lily, Binder, Apartment, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:22:00 src.selection.data DEBUG    Options: Grape, Temple, Lily, Binder, Apartment, Pencil.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "sample 180 / 512\n",
      "2025-09-15 00:22:03 src.selection.data DEBUG    Options: Mirror, Toothpaste, House, Saxophone, Drum, Recliner.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "2025-09-15 00:22:04 src.selection.data DEBUG    Options: Hairdryer, Clarinet, Cello, Sofa, Temple, Toothbrush.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:22:04 src.selection.data DEBUG    Options: Hairdryer, Clarinet, Cello, Sofa, Temple, Toothbrush.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "sample 181 / 512\n",
      "2025-09-15 00:22:07 src.selection.data DEBUG    Options: Ring, Spruce, Necklace, Bench, Pen, Scissors.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "2025-09-15 00:22:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ring', prob=0.53125, logit=20.0, token_id=22249, metadata=None))[\" Ring\"] != 86460[\" Necklace\"]\n",
      "2025-09-15 00:22:08 src.selection.data DEBUG    Options: Iris, Paperclip, Anklet, Calculator, Watch, Orange.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:22:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ank', prob=0.5859375, logit=20.125, token_id=57915, metadata=None))[\" Ank\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:22:08 src.selection.data DEBUG    Options: Cufflink, Camera, Ruler, Pin, Coffee table, Tape.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:22:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' C', prob=0.59765625, logit=19.125, token_id=356, metadata=None))[\" C\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:22:08 src.selection.data DEBUG    Options: Air fryer, Pencil, Pin, Tape, Sofa, Cufflink.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:22:08 src.selection.data DEBUG    Options: Necklace, Earring, Calculator, Binder, Blender, Stool.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:22:09 src.selection.data DEBUG    Options: Necklace, Earring, Calculator, Binder, Blender, Stool.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "sample 182 / 512\n",
      "2025-09-15 00:22:12 src.selection.data DEBUG    Options: Bracelet, Spruce, Shirt, Gloves, Tennis ball, Eucalyptus.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:22:12 src.selection.data DEBUG    Options: Boxing gloves, Magnolia, Scarf, Birch, Tie, Brooch.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:22:13 src.selection.data DEBUG    Options: Boxing gloves, Magnolia, Scarf, Birch, Tie, Brooch.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Tie\n",
      "2025-09-15 00:22:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bro', prob=0.62890625, logit=19.625, token_id=6031, metadata=None))[\" Bro\"] != 59825[\" Tie\"]\n",
      "2025-09-15 00:22:13 src.selection.data DEBUG    Options: Elm, Redwood, Cufflink, Dress, Scarf, Skateboard.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:22:13 src.selection.data DEBUG    Options: Pants, Sweater, Bamboo, Birch, Golf ball, Chain.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:22:13 src.selection.data DEBUG    Options: Pants, Sweater, Bamboo, Birch, Golf ball, Chain.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "sample 183 / 512\n",
      "2025-09-15 00:22:17 src.selection.data DEBUG    Options: Rabbit, Dolphin, Violet, Orchid.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:22:17 src.selection.data DEBUG    Options: Sunflower, Zebra, Bear, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:22:17 src.selection.data DEBUG    Options: Sunflower, Zebra, Bear, Iris.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "sample 184 / 512\n",
      "2025-09-15 00:22:21 src.selection.data DEBUG    Options: Kettle, Monkey, Golf ball, Dishwasher, Coffee table, Helmet, Ash.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "2025-09-15 00:22:21 src.selection.data DEBUG    Options: Hockey stick, Dog, Racket, Food processor, Cedar, Stool, Refrigerator.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:22:21 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Hockey', prob=0.345703125, logit=19.25, token_id=41342, metadata=None))[\" R\"] != 432[\" R\"]\n",
      "2025-09-15 00:22:21 src.selection.data DEBUG    Options: Skateboard, School, Elephant, Sunflower, Football, Rice cooker, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:22:21 src.selection.data DEBUG    Options: Mixer, Refrigerator, Bat, Church, Dumbbell, Dog, Marigold.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:22:21 src.selection.data DEBUG    Options: Mixer, Refrigerator, Bat, Church, Dumbbell, Dog, Marigold.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "2025-09-15 00:22:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Mixer', prob=0.3671875, logit=19.75, token_id=72392, metadata=None))[\" Mixer\"] != 75258[\" Refriger\"]\n",
      "2025-09-15 00:22:22 src.selection.data DEBUG    Options: Toaster, Brooch, Chrysanthemum, Food processor, Projector, Helmet, Yoga mat.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:22:22 src.selection.data DEBUG    Options: Pin, Sunflower, Pressure cooker, Football, Rice cooker, Phone, Bat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:22:22 src.selection.data DEBUG    Options: Pin, Sunflower, Pressure cooker, Football, Rice cooker, Phone, Bat.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Rice\n",
      "sample 185 / 512\n",
      "2025-09-15 00:22:26 src.selection.data DEBUG    Options: Asparagus, Bus, Zucchini, Bike.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:22:26 src.selection.data DEBUG    Options: Potato, Yacht, Tomato, Scooter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:22:26 src.selection.data DEBUG    Options: Potato, Yacht, Tomato, Scooter.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "sample 186 / 512\n",
      "2025-09-15 00:22:29 src.selection.data DEBUG    Options: Mouse, Locket, Pin, Eraser, Television.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "2025-09-15 00:22:30 src.selection.data DEBUG    Options: Earring, Tiara, Printer, Headphones, Folder.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:22:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' E', prob=0.396484375, logit=19.375, token_id=469, metadata=None))[\" E\"] != 23126[\" Ti\"]\n",
      "2025-09-15 00:22:30 src.selection.data DEBUG    Options: Speaker, Hickory, Charm, Monitor, Watch.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:22:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Watch', prob=0.5546875, logit=18.625, token_id=10573, metadata=None))[\" Watch\"] != 24423[\" Monitor\"]\n",
      "2025-09-15 00:22:30 src.selection.data DEBUG    Options: Printer, Charm, Headphones, Locket, Drum.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "2025-09-15 00:22:30 src.selection.data DEBUG    Options: Bracelet, Ring, Trumpet, Keyboard, Microphone.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "2025-09-15 00:22:30 src.selection.data DEBUG    Options: Bracelet, Ring, Trumpet, Keyboard, Microphone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Micro\n",
      "sample 187 / 512\n",
      "2025-09-15 00:22:34 src.selection.data DEBUG    Options: Tablet, Lettuce, Tennis ball, Broccoli, Phone.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:22:34 src.selection.data DEBUG    Options: Microphone, Pepper, Celery, Surfboard, Printer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "2025-09-15 00:22:34 src.selection.data DEBUG    Options: Microphone, Pepper, Celery, Surfboard, Printer.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "sample 188 / 512\n",
      "2025-09-15 00:22:38 src.selection.data DEBUG    Options: Football, Pen, Trumpet, Racket, Ukulele.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "2025-09-15 00:22:38 src.selection.data DEBUG    Options: Violin, Tennis ball, Guitar, Highlighter, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:22:38 src.selection.data DEBUG    Options: Violin, Tennis ball, Guitar, Highlighter, Baseball.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "sample 189 / 512\n",
      "2025-09-15 00:22:42 src.selection.data DEBUG    Options: Projector, Eraser, Willow, Carnation, Monitor, Marker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:22:42 src.selection.data DEBUG    Options: Mouse, Calculator, Stapler, Smartwatch, Cedar, Orchid.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "2025-09-15 00:22:42 src.selection.data DEBUG    Options: Mouse, Calculator, Stapler, Smartwatch, Cedar, Orchid.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "sample 190 / 512\n",
      "2025-09-15 00:22:45 src.selection.data DEBUG    Options: Mall, Toothpaste, Headphones, Accordion, Library, Comb, Yacht.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:22:46 src.selection.data DEBUG    Options: Guitar, Razor, Car, Hospital, Phone, School, Hairdryer.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "2025-09-15 00:22:46 src.selection.data DEBUG    Options: Guitar, Razor, Car, Hospital, Phone, School, Hairdryer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Hair\n",
      "sample 191 / 512\n",
      "2025-09-15 00:22:49 src.selection.data DEBUG    Options: Zucchini, Bus, Daisy, Carrot, Bike.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:22:50 src.selection.data DEBUG    Options: Cucumber, Asparagus, Van, Lavender, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:22:50 src.selection.data DEBUG    Options: Cucumber, Asparagus, Van, Lavender, Ambulance.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "sample 192 / 512\n",
      "2025-09-15 00:22:53 src.selection.data DEBUG    Options: Keyboard, Skirt, Watch, Bracelet, Coat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Coat\n",
      "2025-09-15 00:22:54 src.selection.data DEBUG    Options: Suit, Earring, Gloves, Printer, Tiara.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:22:54 src.selection.data DEBUG    Options: Suit, Earring, Gloves, Printer, Tiara.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "sample 193 / 512\n",
      "2025-09-15 00:22:57 src.selection.data DEBUG    Options: Tulip, Sunflower, Van, Recliner, Racket, Helicopter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:22:58 src.selection.data DEBUG    Options: Train, Lily, Scooter, Violet, Hockey stick, Ottoman.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:22:58 src.selection.data DEBUG    Options: Train, Lily, Scooter, Violet, Hockey stick, Ottoman.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "sample 194 / 512\n",
      "2025-09-15 00:23:01 src.selection.data DEBUG    Options: Bus, Harp, Scooter, Xylophone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "2025-09-15 00:23:01 src.selection.data DEBUG    Options: Bike, Motorcycle, Drum, Ukulele.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:23:02 src.selection.data DEBUG    Options: Bike, Motorcycle, Drum, Ukulele.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "sample 195 / 512\n",
      "2025-09-15 00:23:05 src.selection.data DEBUG    Options: Wardrobe, Bat, Chair, Cow, Horse.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:23:05 src.selection.data DEBUG    Options: Bookshelf, Bear, Recliner, Eagle, Skis.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Re\n",
      "2025-09-15 00:23:06 src.selection.data DEBUG    Options: Bookshelf, Bear, Recliner, Eagle, Skis.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Eagle\n",
      "sample 196 / 512\n",
      "2025-09-15 00:23:09 src.selection.data DEBUG    Options: Motorcycle, Rose, Giraffe, Bear, Anklet, Cherry, Kiwi.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:23:09 src.selection.data DEBUG    Options: Pineapple, Rabbit, Tiger, Raspberry, Daisy, Watch, Tractor.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "2025-09-15 00:23:10 src.selection.data DEBUG    Options: Pineapple, Rabbit, Tiger, Raspberry, Daisy, Watch, Tractor.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Raspberry\n",
      "sample 197 / 512\n",
      "2025-09-15 00:23:13 src.selection.data DEBUG    Options: Cherry, Coffee maker, Air fryer, Kiwi.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:23:13 src.selection.data DEBUG    Options: Plum, Rice cooker, Dishwasher, Grape.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "2025-09-15 00:23:13 src.selection.data DEBUG    Options: Plum, Rice cooker, Dishwasher, Grape.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "sample 198 / 512\n",
      "2025-09-15 00:23:17 src.selection.data DEBUG    Options: Paperclip, Truck, Library, Pencil, Submarine.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "2025-09-15 00:23:17 src.selection.data DEBUG    Options: Museum, Car, Bike, Tape, Notebook.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Notebook\n",
      "2025-09-15 00:23:17 src.selection.data DEBUG    Options: Museum, Car, Bike, Tape, Notebook.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "sample 199 / 512\n",
      "2025-09-15 00:23:21 src.selection.data DEBUG    Options: Pencil, Drum, Stapler, Harmonica.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "2025-09-15 00:23:21 src.selection.data DEBUG    Options: Ruler, Scissors, Xylophone, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:23:21 src.selection.data DEBUG    Options: Ruler, Scissors, Xylophone, Clarinet.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "sample 200 / 512\n",
      "2025-09-15 00:23:25 src.selection.data DEBUG    Options: Recliner, Stool, Notebook, Stapler.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:23:25 src.selection.data DEBUG    Options: Paper, Dresser, Wardrobe, Calculator.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:23:25 src.selection.data DEBUG    Options: Paper, Dresser, Wardrobe, Calculator.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "sample 201 / 512\n",
      "2025-09-15 00:23:29 src.selection.data DEBUG    Options: Drum, Toothpaste, Bear, Toothbrush, Boxing gloves, Binder, Harmonica.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:23:29 src.selection.data DEBUG    Options: Mirror, Saxophone, Zebra, Harp, Notebook, Surfboard, Hairdryer.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "2025-09-15 00:23:29 src.selection.data DEBUG    Options: Mirror, Saxophone, Zebra, Harp, Notebook, Surfboard, Hairdryer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Hair\n",
      "sample 202 / 512\n",
      "2025-09-15 00:23:32 src.selection.data DEBUG    Options: Chair, Tractor, Bench, Car.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bench\n",
      "2025-09-15 00:23:33 src.selection.data DEBUG    Options: Van, Bookshelf, Yacht, Bed.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "2025-09-15 00:23:33 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Van', prob=0.55859375, logit=19.25, token_id=13000, metadata=None))[\" Van\"] != 816[\" Y\"]\n",
      "2025-09-15 00:23:33 src.selection.data DEBUG    Options: Sofa, Tractor, Train, Wardrobe.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "2025-09-15 00:23:33 src.selection.data DEBUG    Options: Ottoman, Cabinet, Ambulance, Helicopter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:23:33 src.selection.data DEBUG    Options: Ottoman, Cabinet, Ambulance, Helicopter.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "sample 203 / 512\n",
      "2025-09-15 00:23:37 src.selection.data DEBUG    Options: Piano, Asparagus, Pepper, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:23:37 src.selection.data DEBUG    Options: Broccoli, Tomato, Ukulele, Harp.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:23:37 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bro', prob=0.640625, logit=20.0, token_id=6031, metadata=None))[\" Bro\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:23:37 src.selection.data DEBUG    Options: Celery, Potato, Violin, Trombone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trom\n",
      "2025-09-15 00:23:37 src.selection.data DEBUG    Options: Broccoli, Saxophone, Accordion, Lettuce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:23:38 src.selection.data DEBUG    Options: Broccoli, Saxophone, Accordion, Lettuce.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "sample 204 / 512\n",
      "2025-09-15 00:23:41 src.selection.data DEBUG    Options: Watermelon, Watch, Ring, Plum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:23:41 src.selection.data DEBUG    Options: Peach, Earring, Charm, Apple.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:23:42 src.selection.data DEBUG    Options: Peach, Earring, Charm, Apple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "sample 205 / 512\n",
      "2025-09-15 00:23:45 src.selection.data DEBUG    Options: Oak, Car, Elm, Tractor, Mirror.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "2025-09-15 00:23:46 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Car', prob=0.6015625, logit=19.125, token_id=3341, metadata=None))[\" Car\"] != 1183[\" Tr\"]\n",
      "2025-09-15 00:23:46 src.selection.data DEBUG    Options: Bike, Nightstand, Magnolia, Helicopter, Oak.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:23:46 src.selection.data DEBUG    Options: Cedar, Bus, Car, Sofa, Spruce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:23:46 src.selection.data DEBUG    Options: Cedar, Bus, Car, Sofa, Spruce.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "sample 206 / 512\n",
      "2025-09-15 00:23:50 src.selection.data DEBUG    Options: Stadium, School, Coffee maker, Paperclip, Pressure cooker, Monkey.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "2025-09-15 00:23:50 src.selection.data DEBUG    Options: Theater, Refrigerator, Library, Food processor, Dog, Pencil.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "2025-09-15 00:23:50 src.selection.data DEBUG    Options: Theater, Refrigerator, Library, Food processor, Dog, Pencil.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "sample 207 / 512\n",
      "2025-09-15 00:23:54 src.selection.data DEBUG    Options: Skirt, Drum, Shorts, Soap, Toothpaste.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:23:54 src.selection.data DEBUG    Options: Guitar, Shampoo, Bathtub, Tie, Shirt.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:23:54 src.selection.data DEBUG    Options: Guitar, Shampoo, Bathtub, Tie, Shirt.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "sample 208 / 512\n",
      "2025-09-15 00:23:58 src.selection.data DEBUG    Options: Pressure cooker, Toothpaste, Shower, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "2025-09-15 00:23:58 src.selection.data DEBUG    Options: Comb, Bathtub, Rice cooker, Blender.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:23:58 src.selection.data DEBUG    Options: Comb, Bathtub, Rice cooker, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "sample 209 / 512\n",
      "2025-09-15 00:24:02 src.selection.data DEBUG    Options: Lion, Slow cooker, Tie, Dolphin, Tomato, Cucumber, Microphone.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:24:02 src.selection.data DEBUG    Options: Giraffe, Pepper, Dishwasher, Mouse, Scarf, Broccoli, Elephant.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:24:02 src.selection.data DEBUG    Options: Giraffe, Pepper, Dishwasher, Mouse, Scarf, Broccoli, Elephant.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Elephant\n",
      "sample 210 / 512\n",
      "2025-09-15 00:24:05 src.selection.data DEBUG    Options: Maple, House, Car, Surfboard, Socks, Jeans, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:24:06 src.selection.data DEBUG    Options: Apartment, School, Jacket, Basketball, Scarf, Airplane, Redwood.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:24:06 src.selection.data DEBUG    Options: Apartment, School, Jacket, Basketball, Scarf, Airplane, Redwood.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "sample 211 / 512\n",
      "2025-09-15 00:24:10 src.selection.data DEBUG    Options: Peach, Theater, Library, Basketball, Paperclip, Mirror, Pen.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:24:10 src.selection.data DEBUG    Options: Apple, Binder, Shampoo, Hockey stick, School, Marker, House.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:24:10 src.selection.data DEBUG    Options: Apple, Binder, Shampoo, Hockey stick, School, Marker, House.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "sample 212 / 512\n",
      "2025-09-15 00:24:13 src.selection.data DEBUG    Options: Scissors, Monkey, Palm, Violin, Potato, Dog, Trombone.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:24:14 src.selection.data DEBUG    Options: Guitar, Dolphin, Cedar, Tiger, Piano, Pen, Cucumber.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Piano\n",
      "2025-09-15 00:24:14 src.selection.data DEBUG    Options: Guitar, Dolphin, Cedar, Tiger, Piano, Pen, Cucumber.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "sample 213 / 512\n",
      "2025-09-15 00:24:17 src.selection.data DEBUG    Options: Rabbit, Asparagus, Sink, Carrot, Horse.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:24:17 src.selection.data DEBUG    Options: Zucchini, Onion, Cat, Tiger, Shower.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "2025-09-15 00:24:18 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Z', prob=0.345703125, logit=19.5, token_id=1901, metadata=None))[\" Z\"] != 87035[\" Onion\"]\n",
      "2025-09-15 00:24:18 src.selection.data DEBUG    Options: Magnolia, Lion, Onion, Cucumber, Cow.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "2025-09-15 00:24:18 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Lion', prob=0.609375, logit=19.75, token_id=33199, metadata=None))[\" Lion\"] != 22607[\" Cow\"]\n",
      "2025-09-15 00:24:18 src.selection.data DEBUG    Options: Giraffe, Tennis ball, Potato, Spinach, Lion.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:24:18 src.selection.data DEBUG    Options: Onion, Horse, Bear, Hockey stick, Zucchini.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:24:18 src.selection.data DEBUG    Options: Onion, Horse, Bear, Hockey stick, Zucchini.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "sample 214 / 512\n",
      "2025-09-15 00:24:22 src.selection.data DEBUG    Options: Bench, Necklace, Tulip, Chrysanthemum, Camera, Redwood, Cabinet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "2025-09-15 00:24:22 src.selection.data DEBUG    Options: Desk, Lavender, Jasmine, Brooch, Bookshelf, Monitor, Ash.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Book\n",
      "2025-09-15 00:24:22 src.selection.data DEBUG    Options: Desk, Lavender, Jasmine, Brooch, Bookshelf, Monitor, Ash.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Jasmine\n",
      "sample 215 / 512\n",
      "2025-09-15 00:24:25 src.selection.data DEBUG    Options: Towel, Chair, Helicopter, Printer, Violet, Daffodil, Car.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:24:26 src.selection.data DEBUG    Options: Motorcycle, Jasmine, Tractor, Keyboard, Lavender, Mirror, Bookshelf.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Lav\n",
      "2025-09-15 00:24:26 src.selection.data DEBUG    Options: Motorcycle, Jasmine, Tractor, Keyboard, Lavender, Mirror, Bookshelf.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "2025-09-15 00:24:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Motorcycle', prob=0.6640625, logit=21.125, token_id=70762, metadata=None))[\" Motorcycle\"] != 1183[\" Tr\"]\n",
      "2025-09-15 00:24:26 src.selection.data DEBUG    Options: Peony, Van, Daffodil, Trombone, Cow, Yacht, Headphones.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "2025-09-15 00:24:26 src.selection.data DEBUG    Options: Tractor, Motorcycle, Jasmine, Piano, Violet, Television, Elephant.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:24:26 src.selection.data DEBUG    Options: Tractor, Motorcycle, Jasmine, Piano, Violet, Television, Elephant.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "sample 216 / 512\n",
      "2025-09-15 00:24:30 src.selection.data DEBUG    Options: Temple, Mosque, Ambulance, Helicopter.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "2025-09-15 00:24:30 src.selection.data DEBUG    Options: Skyscraper, Library, Train, Bike.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "2025-09-15 00:24:30 src.selection.data DEBUG    Options: Skyscraper, Library, Train, Bike.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "sample 217 / 512\n",
      "2025-09-15 00:24:34 src.selection.data DEBUG    Options: Willow, Palm, Pendant, Jasmine, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:24:34 src.selection.data DEBUG    Options: Tulip, Eucalyptus, Oak, Carnation, Locket.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:24:34 src.selection.data DEBUG    Options: Tulip, Eucalyptus, Oak, Carnation, Locket.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "sample 218 / 512\n",
      "2025-09-15 00:24:38 src.selection.data DEBUG    Options: Scooter, Tractor, Shower, Surfboard, Razor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:24:38 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Shower', prob=0.84765625, logit=20.5, token_id=48471, metadata=None))[\" Shower\"] != 74968[\" Razor\"]\n",
      "2025-09-15 00:24:38 src.selection.data DEBUG    Options: Bus, Hat, Soap, Scooter, Toilet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:24:38 src.selection.data DEBUG    Options: Bike, Shower, Truck, Sink, Scarf.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:24:38 src.selection.data DEBUG    Options: Bike, Shower, Truck, Sink, Scarf.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 219 / 512\n",
      "2025-09-15 00:24:42 src.selection.data DEBUG    Options: Spinach, Raspberry, Golf ball, Apple, Camera, Boxing gloves.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "2025-09-15 00:24:42 src.selection.data DEBUG    Options: Skis, Tennis ball, Pineapple, Zucchini, Kiwi, Monitor.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Tennis\n",
      "2025-09-15 00:24:42 src.selection.data DEBUG    Options: Skis, Tennis ball, Pineapple, Zucchini, Kiwi, Monitor.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "sample 220 / 512\n",
      "2025-09-15 00:24:46 src.selection.data DEBUG    Options: Tape, Yoga mat, Boxing gloves, Paper.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:24:46 src.selection.data DEBUG    Options: Marker, Skateboard, Baseball, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:24:46 src.selection.data DEBUG    Options: Marker, Skateboard, Baseball, Pencil.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "sample 221 / 512\n",
      "2025-09-15 00:24:50 src.selection.data DEBUG    Options: Carrot, Cat, Rice cooker, Asparagus, Shampoo, Refrigerator, Library.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:24:50 src.selection.data DEBUG    Options: Coffee maker, Cucumber, Celery, School, Monkey, Toothpaste, Microwave.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Microwave\n",
      "2025-09-15 00:24:50 src.selection.data DEBUG    Options: Coffee maker, Cucumber, Celery, School, Monkey, Toothpaste, Microwave.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "sample 222 / 512\n",
      "2025-09-15 00:24:53 src.selection.data DEBUG    Options: Giraffe, Truck, Helicopter, Ash, Marker, Museum, Willow.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:24:54 src.selection.data DEBUG    Options: Cow, Elm, House, Tractor, Train, Cedar, Ruler.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "2025-09-15 00:24:54 src.selection.data DEBUG    Options: Cow, Elm, House, Tractor, Train, Cedar, Ruler.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "sample 223 / 512\n",
      "2025-09-15 00:24:57 src.selection.data DEBUG    Options: Truck, Boxing gloves, Ukulele, Helmet, Scooter.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:24:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boxing', prob=0.828125, logit=20.625, token_id=72683, metadata=None))[\" Boxing\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:24:58 src.selection.data DEBUG    Options: Football, Piano, Van, Golf ball, Bike.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:24:58 src.selection.data DEBUG    Options: Truck, Car, Drum, Dumbbell, Skateboard.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:24:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Skate', prob=0.609375, logit=19.375, token_id=97796, metadata=None))[\" Skate\"] != 3341[\" Car\"]\n",
      "2025-09-15 00:24:58 src.selection.data DEBUG    Options: Mouse, Helmet, Surfboard, Bus, Scooter.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:24:58 src.selection.data DEBUG    Options: Bat, Smartwatch, Airplane, Yoga mat, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:24:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Air', prob=0.408203125, logit=19.75, token_id=6690, metadata=None))[\" Air\"] != 20423[\" Amb\"]\n",
      "2025-09-15 00:24:58 src.selection.data DEBUG    Options: Bus, Airplane, Skis, Basketball, Dress.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Basketball\n",
      "2025-09-15 00:24:58 src.selection.data DEBUG    Options: Tennis ball, Train, Dumbbell, Shorts, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:24:59 src.selection.data DEBUG    Options: Tennis ball, Train, Dumbbell, Shorts, Ambulance.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "sample 224 / 512\n",
      "2025-09-15 00:25:02 src.selection.data DEBUG    Options: Mouse, Microphone, Notebook, Paperclip, House.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:25:02 src.selection.data DEBUG    Options: Tape, Monitor, Folder, Hospital, Printer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "2025-09-15 00:25:02 src.selection.data DEBUG    Options: Tape, Monitor, Folder, Hospital, Printer.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:25:03 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Printer', prob=0.7421875, logit=19.625, token_id=47033, metadata=None))[\" Printer\"] != 36943[\" Folder\"]\n",
      "2025-09-15 00:25:03 src.selection.data DEBUG    Options: Bike, Monitor, Paper, Keyboard, Scissors.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:25:03 src.selection.data DEBUG    Options: Marker, Tractor, Paperclip, Mouse, Microphone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Micro\n",
      "2025-09-15 00:25:03 src.selection.data DEBUG    Options: Marker, Tractor, Paperclip, Mouse, Microphone.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:25:03 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Micro', prob=0.443359375, logit=18.625, token_id=18654, metadata=None))[\" Micro\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:25:03 src.selection.data DEBUG    Options: Folder, Router, Headphones, Raspberry, Notebook.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Notebook\n",
      "2025-09-15 00:25:04 src.selection.data DEBUG    Options: Calculator, Keyboard, Phone, Pencil, Grape.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:25:04 src.selection.data DEBUG    Options: Calculator, Keyboard, Phone, Pencil, Grape.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "sample 225 / 512\n",
      "2025-09-15 00:25:07 src.selection.data DEBUG    Options: Suit, Scarf, Chain, Ring, Rabbit, Ambulance, Raspberry.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:25:07 src.selection.data DEBUG    Options: Cat, Gloves, Charm, Banana, Tractor, Pants, Earring.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:25:08 src.selection.data DEBUG    Options: Cat, Gloves, Charm, Banana, Tractor, Pants, Earring.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "sample 226 / 512\n",
      "2025-09-15 00:25:11 src.selection.data DEBUG    Options: Ukulele, Saxophone, Bus, Shower, Blueberry, Chair, Orange.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "2025-09-15 00:25:11 src.selection.data DEBUG    Options: Clarinet, Boat, Cherry, Drum, Hairdryer, Stool, Plum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:25:11 src.selection.data DEBUG    Options: Clarinet, Boat, Cherry, Drum, Hairdryer, Stool, Plum.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "sample 227 / 512\n",
      "2025-09-15 00:25:15 src.selection.data DEBUG    Options: Chain, Toilet, Locket, Lavender, Sunflower.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:25:15 src.selection.data DEBUG    Options: Jasmine, Cufflink, Mirror, Bangle, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:25:15 src.selection.data DEBUG    Options: Jasmine, Cufflink, Mirror, Bangle, Iris.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:25:16 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Iris', prob=0.494140625, logit=19.25, token_id=66821, metadata=None))[\" Iris\"] != 426[\" B\"]\n",
      "2025-09-15 00:25:16 src.selection.data DEBUG    Options: Charm, Helicopter, Chrysanthemum, Violet, Anklet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "2025-09-15 00:25:16 src.selection.data DEBUG    Options: Cufflink, Submarine, Tiara, Tulip, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:25:17 src.selection.data DEBUG    Options: Cufflink, Submarine, Tiara, Tulip, Iris.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "sample 228 / 512\n",
      "2025-09-15 00:25:20 src.selection.data DEBUG    Options: Coffee maker, Oven, Dress, Pants.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:25:20 src.selection.data DEBUG    Options: Pressure cooker, Juicer, Coat, Gloves.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Ju\n",
      "2025-09-15 00:25:21 src.selection.data DEBUG    Options: Pressure cooker, Juicer, Coat, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "sample 229 / 512\n",
      "2025-09-15 00:25:24 src.selection.data DEBUG    Options: Broccoli, Bracelet, Binder, Folder, Bamboo, Tiara.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:25:24 src.selection.data DEBUG    Options: Pin, Ring, Tape, Spruce, Paperclip, Tomato.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:25:24 src.selection.data DEBUG    Options: Pin, Ring, Tape, Spruce, Paperclip, Tomato.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "sample 230 / 512\n",
      "2025-09-15 00:25:28 src.selection.data DEBUG    Options: Tiara, Calculator, Eraser, Charm.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:25:28 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ti', prob=0.55859375, logit=19.125, token_id=23126, metadata=None))[\" Ti\"] != 58600[\" Charm\"]\n",
      "2025-09-15 00:25:28 src.selection.data DEBUG    Options: Ruler, Earring, Marker, Pin.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:25:28 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' E', prob=0.74609375, logit=19.75, token_id=469, metadata=None))[\" E\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:25:28 src.selection.data DEBUG    Options: Tape, Bracelet, Cufflink, Paper.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:25:28 src.selection.data DEBUG    Options: Binder, Chain, Tiara, Eraser.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:25:29 src.selection.data DEBUG    Options: Binder, Chain, Tiara, Eraser.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "sample 231 / 512\n",
      "2025-09-15 00:25:32 src.selection.data DEBUG    Options: Cat, Toilet, Shampoo, Magnolia, Pressure cooker, Router, Tablet.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:25:32 src.selection.data DEBUG    Options: Microphone, Cedar, Blender, Printer, Eagle, Toothpaste, Toothbrush.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:25:32 src.selection.data DEBUG    Options: Microphone, Cedar, Blender, Printer, Eagle, Toothpaste, Toothbrush.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "sample 232 / 512\n",
      "2025-09-15 00:25:36 src.selection.data DEBUG    Options: Keyboard, Folder, Television, Ottoman, Sink, Hairdryer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "2025-09-15 00:25:36 src.selection.data DEBUG    Options: Phone, Camera, Shampoo, Pen, Recliner, Bathtub.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:25:36 src.selection.data DEBUG    Options: Phone, Camera, Shampoo, Pen, Recliner, Bathtub.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Camera\n",
      "2025-09-15 00:25:36 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Phone', prob=0.326171875, logit=19.0, token_id=14642, metadata=None))[\" Phone\"] != 14669[\" Camera\"]\n",
      "2025-09-15 00:25:36 src.selection.data DEBUG    Options: Recliner, Cufflink, Router, Bathtub, Laptop, Towel.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "2025-09-15 00:25:37 src.selection.data DEBUG    Options: Shampoo, Printer, Ring, Tablet, Sofa, Razor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:25:37 src.selection.data DEBUG    Options: Shampoo, Printer, Ring, Tablet, Sofa, Razor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "sample 233 / 512\n",
      "2025-09-15 00:25:40 src.selection.data DEBUG    Options: Watch, Zebra, Boat, Tiger, Car.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:25:41 src.selection.data DEBUG    Options: Bear, Dolphin, Yacht, Train, Locket.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:25:41 src.selection.data DEBUG    Options: Bear, Dolphin, Yacht, Train, Locket.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "sample 234 / 512\n",
      "2025-09-15 00:25:44 src.selection.data DEBUG    Options: Saxophone, Coat, Piano, Socks, Toilet.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "2025-09-15 00:25:44 src.selection.data DEBUG    Options: Guitar, Suit, Dress, Shampoo, Xylophone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "2025-09-15 00:25:45 src.selection.data DEBUG    Options: Guitar, Suit, Dress, Shampoo, Xylophone.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "sample 235 / 512\n",
      "2025-09-15 00:25:48 src.selection.data DEBUG    Options: Hat, Printer, Toilet, Toothpaste, Guitar, Drum.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "2025-09-15 00:25:48 src.selection.data DEBUG    Options: Monitor, Hairdryer, Saxophone, Toilet paper, Harp, Scarf.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:25:48 src.selection.data DEBUG    Options: Monitor, Hairdryer, Saxophone, Toilet paper, Harp, Scarf.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "sample 236 / 512\n",
      "2025-09-15 00:25:52 src.selection.data DEBUG    Options: Earring, Mouse, Camera, Ring.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Camera\n",
      "2025-09-15 00:25:52 src.selection.data DEBUG    Options: Smartwatch, Pin, Laptop, Locket.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:25:52 src.selection.data DEBUG    Options: Smartwatch, Pin, Laptop, Locket.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "sample 237 / 512\n",
      "2025-09-15 00:25:56 src.selection.data DEBUG    Options: Skirt, Spinach, Redwood, Tomato, Ruler, Spruce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:25:56 src.selection.data DEBUG    Options: Pepper, Willow, Bamboo, Celery, Folder, Coat.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "2025-09-15 00:25:56 src.selection.data DEBUG    Options: Pepper, Willow, Bamboo, Celery, Folder, Coat.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "2025-09-15 00:25:56 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Willow', prob=0.640625, logit=19.0, token_id=65449, metadata=None))[\" Willow\"] != 98028[\" Bamboo\"]\n",
      "2025-09-15 00:25:56 src.selection.data DEBUG    Options: Cedar, Eucalyptus, Lettuce, Ambulance, Stadium, Cauliflower.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:25:57 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Cedar', prob=0.51953125, logit=19.0, token_id=57748, metadata=None))[\" Cedar\"] != 469[\" E\"]\n",
      "2025-09-15 00:25:57 src.selection.data DEBUG    Options: Asparagus, Magnolia, Mushroom, Mouse, Pen, Eucalyptus.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:25:57 src.selection.data DEBUG    Options: Hickory, Bamboo, Cucumber, Monitor, Broccoli, Stapler.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:25:57 src.selection.data DEBUG    Options: Hickory, Bamboo, Cucumber, Monitor, Broccoli, Stapler.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "sample 238 / 512\n",
      "2025-09-15 00:26:00 src.selection.data DEBUG    Options: Violet, Carnation, Anklet, Locket, Table.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "2025-09-15 00:26:01 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Violet', prob=0.5390625, logit=18.375, token_id=74574, metadata=None))[\" Violet\"] != 32749[\" Carn\"]\n",
      "2025-09-15 00:26:01 src.selection.data DEBUG    Options: Chain, Carnation, Locket, Daisy, Mirror.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:26:01 src.selection.data DEBUG    Options: Sunflower, Bangle, Rose, Anklet, Toilet paper.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "2025-09-15 00:26:01 src.selection.data DEBUG    Options: Sunflower, Bangle, Rose, Anklet, Toilet paper.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Rose\n",
      "sample 239 / 512\n",
      "2025-09-15 00:26:05 src.selection.data DEBUG    Options: Accordion, Air fryer, Food processor, Trumpet.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:26:05 src.selection.data DEBUG    Options: Violin, Oven, Drum, Refrigerator.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "2025-09-15 00:26:05 src.selection.data DEBUG    Options: Violin, Oven, Drum, Refrigerator.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "sample 240 / 512\n",
      "2025-09-15 00:26:08 src.selection.data DEBUG    Options: Bangle, Palm, Eucalyptus, School, Charm.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:26:09 src.selection.data DEBUG    Options: Brooch, Elm, Ring, House, Ash.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "2025-09-15 00:26:09 src.selection.data DEBUG    Options: Brooch, Elm, Ring, House, Ash.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "sample 241 / 512\n",
      "2025-09-15 00:26:12 src.selection.data DEBUG    Options: Warehouse, Theater, Birch, Oak.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:26:12 src.selection.data DEBUG    Options: Pine, School, Eucalyptus, Mall.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:26:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' School', prob=0.609375, logit=19.0, token_id=6150, metadata=None))[\" School\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:26:13 src.selection.data DEBUG    Options: House, Maple, Mosque, Eucalyptus.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:26:13 src.selection.data DEBUG    Options: Apartment, Oak, Ash, Theater.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "2025-09-15 00:26:13 src.selection.data DEBUG    Options: Apartment, Oak, Ash, Theater.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "sample 242 / 512\n",
      "2025-09-15 00:26:16 src.selection.data DEBUG    Options: Keyboard, Chair, Tablet, Carnation, Toilet paper, School, Comb.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:26:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Toilet', prob=0.80859375, logit=19.875, token_id=82994, metadata=None))[\" Toilet\"] != 23262[\" Comb\"]\n",
      "2025-09-15 00:26:17 src.selection.data DEBUG    Options: Soap, Toilet, Projector, Jacket, Mouse, Bat, Hospital.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:26:17 src.selection.data DEBUG    Options: Router, Mirror, Factory, Headphones, Jeans, Toilet paper, Hockey stick.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "2025-09-15 00:26:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Router', prob=0.46484375, logit=19.0, token_id=10777, metadata=None))[\" Router\"] != 11452[\" Head\"]\n",
      "2025-09-15 00:26:17 src.selection.data DEBUG    Options: Laptop, Comb, Bike, Warehouse, Mirror, Kiwi, Tablet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:26:17 src.selection.data DEBUG    Options: Camera, Yacht, Stadium, Toilet paper, Pear, Shower, Mouse.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Mouse\n",
      "2025-09-15 00:26:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Camera', prob=0.419921875, logit=19.0, token_id=14669, metadata=None))[\" Camera\"] != 18191[\" Mouse\"]\n",
      "2025-09-15 00:26:17 src.selection.data DEBUG    Options: Towel, Bamboo, Grape, Headphones, Projector, Dumbbell, Lotion.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:26:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tow', prob=0.494140625, logit=19.875, token_id=41493, metadata=None))[\" Tow\"] != 445[\" L\"]\n",
      "2025-09-15 00:26:17 src.selection.data DEBUG    Options: Toothbrush, Phone, Xylophone, Yoga mat, Toilet, Temple, Television.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:26:18 src.selection.data DEBUG    Options: Hairdryer, Smartwatch, Sink, Accordion, Dumbbell, Warehouse, Monitor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:26:18 src.selection.data DEBUG    Options: Hairdryer, Smartwatch, Sink, Accordion, Dumbbell, Warehouse, Monitor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 243 / 512\n",
      "2025-09-15 00:26:21 src.selection.data DEBUG    Options: Chrysanthemum, Towel, Ambulance, Daffodil, Slow cooker, Bike.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:26:22 src.selection.data DEBUG    Options: Oven, Marigold, Violet, Tractor, Car, Razor.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:26:22 src.selection.data DEBUG    Options: Oven, Marigold, Violet, Tractor, Car, Razor.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "sample 244 / 512\n",
      "2025-09-15 00:26:25 src.selection.data DEBUG    Options: Hockey stick, Maple, Soap, Chain, Onion, Redwood, Asparagus.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:26:26 src.selection.data DEBUG    Options: Hickory, Lotion, Carrot, Spinach, Willow, Yoga mat, Pin.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:26:26 src.selection.data DEBUG    Options: Hickory, Lotion, Carrot, Spinach, Willow, Yoga mat, Pin.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Spin\n",
      "sample 245 / 512\n",
      "2025-09-15 00:26:29 src.selection.data DEBUG    Options: Slow cooker, Daffodil, Microwave, Jasmine.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Jasmine\n",
      "2025-09-15 00:26:30 src.selection.data DEBUG    Options: Lily, Kettle, Sunflower, Dishwasher.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "2025-09-15 00:26:30 src.selection.data DEBUG    Options: Lily, Kettle, Sunflower, Dishwasher.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Sun\n",
      "sample 246 / 512\n",
      "2025-09-15 00:26:33 src.selection.data DEBUG    Options: Paperclip, Sheep, Jasmine, Rabbit, Tape, Oven, Zucchini.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:26:33 src.selection.data DEBUG    Options: Lion, Binder, Slow cooker, Highlighter, Celery, Tulip, Cow.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "2025-09-15 00:26:34 src.selection.data DEBUG    Options: Lion, Binder, Slow cooker, Highlighter, Celery, Tulip, Cow.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "sample 247 / 512\n",
      "2025-09-15 00:26:37 src.selection.data DEBUG    Options: Soap, Willow, Bamboo, Toothbrush.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:26:37 src.selection.data DEBUG    Options: Toothpaste, Birch, Toilet paper, Pine.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:26:37 src.selection.data DEBUG    Options: Toothpaste, Birch, Toilet paper, Pine.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "sample 248 / 512\n",
      "2025-09-15 00:26:41 src.selection.data DEBUG    Options: Rice cooker, Bus, Desk, Yacht, Refrigerator.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "2025-09-15 00:26:41 src.selection.data DEBUG    Options: Scooter, Dishwasher, Air fryer, Truck, Wardrobe.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:26:41 src.selection.data DEBUG    Options: Scooter, Dishwasher, Air fryer, Truck, Wardrobe.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "sample 249 / 512\n",
      "2025-09-15 00:26:45 src.selection.data DEBUG    Options: Camera, Broccoli, Tie, Suit, Monkey, Tablet, Recliner.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:26:45 src.selection.data DEBUG    Options: Monitor, Eagle, Keyboard, Scarf, Zucchini, Coffee table, Hat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "2025-09-15 00:26:45 src.selection.data DEBUG    Options: Monitor, Eagle, Keyboard, Scarf, Zucchini, Coffee table, Hat.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:26:45 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Monitor', prob=0.466796875, logit=19.375, token_id=24423, metadata=None))[\" Monitor\"] != 26698[\" Keyboard\"]\n",
      "2025-09-15 00:26:45 src.selection.data DEBUG    Options: Towel, Ruler, Hat, Router, Monitor, Gloves, Pin.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:26:46 src.selection.data DEBUG    Options: Smartwatch, Dress, Tiara, Marker, Shirt, Hairdryer, Projector.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:26:46 src.selection.data DEBUG    Options: Smartwatch, Dress, Tiara, Marker, Shirt, Hairdryer, Projector.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "sample 250 / 512\n",
      "2025-09-15 00:26:49 src.selection.data DEBUG    Options: Food processor, Blender, Palm, Bracelet, Earring.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:26:49 src.selection.data DEBUG    Options: Toaster, Tiara, Anklet, Bamboo, Dishwasher.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "2025-09-15 00:26:50 src.selection.data DEBUG    Options: Toaster, Tiara, Anklet, Bamboo, Dishwasher.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "sample 251 / 512\n",
      "2025-09-15 00:26:53 src.selection.data DEBUG    Options: Eraser, Bus, Scooter, Spruce, Redwood.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:26:53 src.selection.data DEBUG    Options: Truck, Scissors, Magnolia, Maple, Tractor.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "2025-09-15 00:26:53 src.selection.data DEBUG    Options: Truck, Scissors, Magnolia, Maple, Tractor.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "sample 252 / 512\n",
      "2025-09-15 00:26:57 src.selection.data DEBUG    Options: Train, Peony, Violet, Sofa, Tractor, Bracelet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:26:57 src.selection.data DEBUG    Options: Lavender, Rose, Necklace, Bus, Airplane, Recliner.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:26:57 src.selection.data DEBUG    Options: Lavender, Rose, Necklace, Bus, Airplane, Recliner.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Rose\n",
      "sample 253 / 512\n",
      "2025-09-15 00:27:01 src.selection.data DEBUG    Options: Pressure cooker, Food processor, Onion, Tomato.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:27:01 src.selection.data DEBUG    Options: Rice cooker, Pepper, Air fryer, Cucumber.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:27:01 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pepper', prob=0.466796875, logit=19.875, token_id=52882, metadata=None))[\" Pepper\"] != 356[\" C\"]\n",
      "2025-09-15 00:27:01 src.selection.data DEBUG    Options: Mushroom, Dishwasher, Toaster, Onion.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  To\n",
      "2025-09-15 00:27:01 src.selection.data DEBUG    Options: Spinach, Refrigerator, Oven, Asparagus.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:27:02 src.selection.data DEBUG    Options: Spinach, Refrigerator, Oven, Asparagus.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Oven\n",
      "sample 254 / 512\n",
      "2025-09-15 00:27:05 src.selection.data DEBUG    Options: Chair, Bed, Ruler, Folder, Hickory, Broccoli, Airplane.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:27:05 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Chair', prob=0.478515625, logit=19.625, token_id=16478, metadata=None))[\" Chair\"] != 13394[\" Bed\"]\n",
      "2025-09-15 00:27:05 src.selection.data DEBUG    Options: Table, Calculator, Toothpaste, Shirt, Pencil, Refrigerator, Bench.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bench\n",
      "2025-09-15 00:27:05 src.selection.data DEBUG    Options: Chair, Binder, Skirt, Highlighter, Mixer, Recliner, Toilet paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 00:27:06 src.selection.data DEBUG    Options: Chair, Binder, Skirt, Highlighter, Mixer, Recliner, Toilet paper.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Re\n",
      "sample 255 / 512\n",
      "2025-09-15 00:27:09 src.selection.data DEBUG    Options: Blender, Van, Watch, Daisy, Tractor, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:27:09 src.selection.data DEBUG    Options: Pendant, Carnation, Necklace, Rice cooker, Bus, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:27:09 src.selection.data DEBUG    Options: Pendant, Carnation, Necklace, Rice cooker, Bus, Ambulance.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "sample 256 / 512\n",
      "2025-09-15 00:27:13 src.selection.data DEBUG    Options: Factory, Hat, Laptop, Maple, Tomato, Speaker, Pants.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:27:13 src.selection.data DEBUG    Options: Sweater, Camera, Redwood, Mushroom, Suit, Smartwatch, Temple.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "2025-09-15 00:27:14 src.selection.data DEBUG    Options: Sweater, Camera, Redwood, Mushroom, Suit, Smartwatch, Temple.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "sample 257 / 512\n",
      "2025-09-15 00:27:17 src.selection.data DEBUG    Options: Necklace, Car, Ambulance, Pendant.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:27:17 src.selection.data DEBUG    Options: Bus, Train, Earring, Bracelet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "2025-09-15 00:27:18 src.selection.data DEBUG    Options: Bus, Train, Earring, Bracelet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "sample 258 / 512\n",
      "2025-09-15 00:27:21 src.selection.data DEBUG    Options: Ring, Potato, House, Flute, Factory, Spinach, Phone.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Factory\n",
      "2025-09-15 00:27:21 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' House', prob=0.4765625, logit=19.5, token_id=4783, metadata=None))[\" House\"] != 17367[\" Factory\"]\n",
      "2025-09-15 00:27:21 src.selection.data DEBUG    Options: Binder, Church, Warehouse, Lettuce, Potato, Bangle, Coffee table.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:27:21 src.selection.data DEBUG    Options: Tomato, Notebook, Broccoli, School, Table, Watch, Library.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:27:22 src.selection.data DEBUG    Options: Tomato, Notebook, Broccoli, School, Table, Watch, Library.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "sample 259 / 512\n",
      "2025-09-15 00:27:25 src.selection.data DEBUG    Options: Microwave, Toothbrush, Air fryer, Bathtub.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:27:25 src.selection.data DEBUG    Options: Dishwasher, Razor, Toaster, Hairdryer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  To\n",
      "2025-09-15 00:27:25 src.selection.data DEBUG    Options: Dishwasher, Razor, Toaster, Hairdryer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Hair\n",
      "2025-09-15 00:27:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Razor', prob=0.51953125, logit=20.25, token_id=74968, metadata=None))[\" Razor\"] != 26781[\" Hair\"]\n",
      "2025-09-15 00:27:26 src.selection.data DEBUG    Options: Oven, Soap, Toothpaste, Mixer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:27:26 src.selection.data DEBUG    Options: Shampoo, Blender, Sink, Coffee maker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:27:26 src.selection.data DEBUG    Options: Shampoo, Blender, Sink, Coffee maker.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 260 / 512\n",
      "2025-09-15 00:27:29 src.selection.data DEBUG    Options: Xylophone, Ruler, Desk, Keyboard, Marker, Bat, Trombone.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "2025-09-15 00:27:30 src.selection.data DEBUG    Options: Football, Bookshelf, Violin, Harp, Tape, Scissors, Microphone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "2025-09-15 00:27:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Micro', prob=0.640625, logit=19.625, token_id=18654, metadata=None))[\" Micro\"] != 5340[\" Har\"]\n",
      "2025-09-15 00:27:30 src.selection.data DEBUG    Options: Drum, Violin, Mushroom, Marker, Paper, Towel, Baseball.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:27:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Marker', prob=0.6875, logit=20.5, token_id=40975, metadata=None))[\" Marker\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:27:30 src.selection.data DEBUG    Options: Headphones, Football, Notebook, Pen, Guitar, Jasmine, Violin.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:27:31 src.selection.data DEBUG    Options: Scissors, Eraser, Piano, Router, Ukulele, Marigold, Surfboard.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "2025-09-15 00:27:31 src.selection.data DEBUG    Options: Scissors, Eraser, Piano, Router, Ukulele, Marigold, Surfboard.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "sample 261 / 512\n",
      "2025-09-15 00:27:34 src.selection.data DEBUG    Options: Peach, Violet, Iris, Sweater, Raspberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Raspberry\n",
      "2025-09-15 00:27:34 src.selection.data DEBUG    Options: Sunflower, Mango, Daisy, Kiwi, Dress.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:27:35 src.selection.data DEBUG    Options: Sunflower, Mango, Daisy, Kiwi, Dress.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "sample 262 / 512\n",
      "2025-09-15 00:27:38 src.selection.data DEBUG    Options: Dress, Socks, Elm, Cufflink, Magnolia.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "2025-09-15 00:27:38 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Elm', prob=0.6796875, logit=19.875, token_id=65329, metadata=None))[\" Elm\"] != 20918[\" Magn\"]\n",
      "2025-09-15 00:27:38 src.selection.data DEBUG    Options: Scarf, Ash, Scissors, Willow, Shorts.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Pencil, Shirt, Jacket, Bamboo, Cedar.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jacket\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Pencil, Shirt, Jacket, Bamboo, Cedar.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "2025-09-15 00:27:39 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Bamboo', prob=0.41015625, logit=19.375, token_id=98028, metadata=None))[\" Cedar\"] != 57748[\" Cedar\"]\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Charm, Redwood, Jacket, Gloves, Bamboo.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Hickory, Cedar, Dress, Suit, Necklace.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:27:39 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Necklace', prob=0.80078125, logit=20.625, token_id=86460, metadata=None))[\" Necklace\"] != 33711[\" Suit\"]\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Jeans, Oak, Jacket, Willow, Locket.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Eucalyptus, Maple, Bracelet, Hat, Pants.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:27:39 src.selection.data DEBUG    Options: Eucalyptus, Maple, Bracelet, Hat, Pants.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "sample 263 / 512\n",
      "2025-09-15 00:27:43 src.selection.data DEBUG    Options: Hickory, Potato, Tomato, Jeans, Juicer, Flute, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "2025-09-15 00:27:43 src.selection.data DEBUG    Options: Cucumber, Saxophone, Asparagus, Jacket, Kettle, Air fryer, Spruce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:27:43 src.selection.data DEBUG    Options: Cucumber, Saxophone, Asparagus, Jacket, Kettle, Air fryer, Spruce.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "sample 264 / 512\n",
      "2025-09-15 00:27:47 src.selection.data DEBUG    Options: Refrigerator, Watch, Temple, Bangle, Factory.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:27:47 src.selection.data DEBUG    Options: School, Chain, Bracelet, Skyscraper, Mixer.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:27:47 src.selection.data DEBUG    Options: School, Chain, Bracelet, Skyscraper, Mixer.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "sample 265 / 512\n",
      "2025-09-15 00:27:51 src.selection.data DEBUG    Options: Toaster, Spruce, Tape, Ukulele, Skis, Ash, Dumbbell.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:27:51 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Sk', prob=0.54296875, logit=19.625, token_id=4923, metadata=None))[\" Sk\"] != 423[\" D\"]\n",
      "2025-09-15 00:27:51 src.selection.data DEBUG    Options: Bamboo, Charm, Drum, Surfboard, Football, Oak, Laptop.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:27:51 src.selection.data DEBUG    Options: Yoga mat, Camera, Harp, Willow, Birch, Pin, Skateboard.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:27:51 src.selection.data DEBUG    Options: Yoga mat, Camera, Harp, Willow, Birch, Pin, Skateboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "sample 266 / 512\n",
      "2025-09-15 00:27:55 src.selection.data DEBUG    Options: Strawberry, Trombone, Trumpet, Cherry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:27:55 src.selection.data DEBUG    Options: Piano, Blueberry, Banana, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:27:55 src.selection.data DEBUG    Options: Piano, Blueberry, Banana, Violin.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n",
      "sample 267 / 512\n",
      "2025-09-15 00:27:59 src.selection.data DEBUG    Options: Harmonica, Brooch, Rice cooker, Cello, Coffee maker, Mirror.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:27:59 src.selection.data DEBUG    Options: Accordion, Hairdryer, Cufflink, Xylophone, Blender, Slow cooker.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "2025-09-15 00:27:59 src.selection.data DEBUG    Options: Accordion, Hairdryer, Cufflink, Xylophone, Blender, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "sample 268 / 512\n",
      "2025-09-15 00:28:03 src.selection.data DEBUG    Options: Ukulele, Cello, Recliner, Surfboard, Sofa.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Sofa\n",
      "2025-09-15 00:28:03 src.selection.data DEBUG    Options: Yoga mat, Stool, Clarinet, Nightstand, Harmonica.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Harmon\n",
      "2025-09-15 00:28:03 src.selection.data DEBUG    Options: Yoga mat, Stool, Clarinet, Nightstand, Harmonica.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "sample 269 / 512\n",
      "2025-09-15 00:28:07 src.selection.data DEBUG    Options: Daisy, Racket, Peony, Baseball.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Pe\n",
      "2025-09-15 00:28:07 src.selection.data DEBUG    Options: Marigold, Surfboard, Boxing gloves, Orchid.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:28:07 src.selection.data DEBUG    Options: Marigold, Surfboard, Boxing gloves, Orchid.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Orch\n",
      "sample 270 / 512\n",
      "2025-09-15 00:28:11 src.selection.data DEBUG    Options: Theater, Shower, Dumbbell, Warehouse, Lotion.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:28:11 src.selection.data DEBUG    Options: Soap, Comb, Helmet, Hospital, Skyscraper.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:28:11 src.selection.data DEBUG    Options: Soap, Comb, Helmet, Hospital, Skyscraper.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:28:11 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hospital', prob=0.63671875, logit=20.0, token_id=15429, metadata=None))[\" Hospital\"] != 4923[\" Sk\"]\n",
      "2025-09-15 00:28:11 src.selection.data DEBUG    Options: Apartment, Temple, Marigold, Soap, Hairdryer.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:28:11 src.selection.data DEBUG    Options: Toothpaste, Lotion, Mall, Theater, Lily.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:28:11 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tooth', prob=0.6015625, logit=20.375, token_id=83499, metadata=None))[\" Tooth\"] != 445[\" L\"]\n",
      "2025-09-15 00:28:11 src.selection.data DEBUG    Options: Shower, Museum, Cherry, Lotion, House.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:28:12 src.selection.data DEBUG    Options: Toothbrush, Temple, School, Razor, Plum.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:28:12 src.selection.data DEBUG    Options: Toothbrush, Temple, School, Razor, Plum.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "sample 271 / 512\n",
      "2025-09-15 00:28:15 src.selection.data DEBUG    Options: Brooch, Carnation, Onion, Iris, Cow, Surfboard, Pepper.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Pepper\n",
      "2025-09-15 00:28:16 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Onion', prob=0.35546875, logit=19.25, token_id=87035, metadata=None))[\" Onion\"] != 52882[\" Pepper\"]\n",
      "2025-09-15 00:28:16 src.selection.data DEBUG    Options: Celery, Daffodil, Chrysanthemum, Cabinet, Lettuce, Sink, Blender.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:28:16 src.selection.data DEBUG    Options: Pepper, Mushroom, Toaster, Chair, Jasmine, Marigold, Toilet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "2025-09-15 00:28:16 src.selection.data DEBUG    Options: Pepper, Mushroom, Toaster, Chair, Jasmine, Marigold, Toilet.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "sample 272 / 512\n",
      "2025-09-15 00:28:19 src.selection.data DEBUG    Options: Sweater, Paperclip, Monitor, Iris, Tape, Tulip.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Tul\n",
      "2025-09-15 00:28:20 src.selection.data DEBUG    Options: Jeans, Rose, Sunflower, Keyboard, Folder, Pen.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:28:20 src.selection.data DEBUG    Options: Jeans, Rose, Sunflower, Keyboard, Folder, Pen.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Sun\n",
      "sample 273 / 512\n",
      "2025-09-15 00:28:23 src.selection.data DEBUG    Options: Stadium, Wardrobe, House, Sofa.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:28:23 src.selection.data DEBUG    Options: Skyscraper, Table, Ottoman, Hospital.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "2025-09-15 00:28:24 src.selection.data DEBUG    Options: Skyscraper, Table, Ottoman, Hospital.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "sample 274 / 512\n",
      "2025-09-15 00:28:27 src.selection.data DEBUG    Options: Horse, Scissors, Paper, Cat.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:28:27 src.selection.data DEBUG    Options: Elephant, Marker, Tiger, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:28:28 src.selection.data DEBUG    Options: Elephant, Marker, Tiger, Pencil.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "sample 275 / 512\n",
      "2025-09-15 00:28:31 src.selection.data DEBUG    Options: Brooch, Jeans, Charm, Orange, Hockey stick, Tablet, Phone.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:28:32 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bro', prob=0.5546875, logit=19.875, token_id=6031, metadata=None))[\" Bro\"] != 58600[\" Charm\"]\n",
      "2025-09-15 00:28:32 src.selection.data DEBUG    Options: Chain, Rose, Microphone, Router, Ambulance, Pendant, Raspberry.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:28:32 src.selection.data DEBUG    Options: Bangle, Iris, Tractor, Smartwatch, Brooch, Plum, Speaker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 00:28:32 src.selection.data DEBUG    Options: Bangle, Iris, Tractor, Smartwatch, Brooch, Plum, Speaker.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "sample 276 / 512\n",
      "2025-09-15 00:28:35 src.selection.data DEBUG    Options: Bear, Air fryer, Giraffe, Flute, Maple, Willow, Bike.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Gir\n",
      "2025-09-15 00:28:36 src.selection.data DEBUG    Options: Saxophone, Birch, Cow, Boat, Spruce, Dog, Juicer.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:28:36 src.selection.data DEBUG    Options: Saxophone, Birch, Cow, Boat, Spruce, Dog, Juicer.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "sample 277 / 512\n",
      "2025-09-15 00:28:39 src.selection.data DEBUG    Options: Oak, Razor, Highlighter, Tractor, Jeans, Tape, Hickory.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:28:40 src.selection.data DEBUG    Options: Gloves, Submarine, Eraser, Redwood, Paper, Elm, Shower.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "2025-09-15 00:28:40 src.selection.data DEBUG    Options: Gloves, Submarine, Eraser, Redwood, Paper, Elm, Shower.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 278 / 512\n",
      "2025-09-15 00:28:43 src.selection.data DEBUG    Options: Marker, Pen, Apartment, Stadium.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Stadium\n",
      "2025-09-15 00:28:44 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Apartment', prob=0.416015625, logit=18.75, token_id=53889, metadata=None))[\" Apartment\"] != 23462[\" Stadium\"]\n",
      "2025-09-15 00:28:44 src.selection.data DEBUG    Options: Folder, Ruler, Hospital, Mall.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:28:44 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hospital', prob=0.55078125, logit=18.75, token_id=15429, metadata=None))[\" Hospital\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:28:44 src.selection.data DEBUG    Options: Folder, Skyscraper, Temple, Pen.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:28:44 src.selection.data DEBUG    Options: Apartment, Tape, Highlighter, Theater.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 00:28:44 src.selection.data DEBUG    Options: Apartment, Tape, Highlighter, Theater.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "sample 279 / 512\n",
      "2025-09-15 00:28:48 src.selection.data DEBUG    Options: Shorts, Tie, Soap, Towel.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Tie\n",
      "2025-09-15 00:28:48 src.selection.data DEBUG    Options: Toilet paper, Toilet, Gloves, Sweater.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:28:49 src.selection.data DEBUG    Options: Toilet paper, Toilet, Gloves, Sweater.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "sample 280 / 512\n",
      "2025-09-15 00:28:52 src.selection.data DEBUG    Options: Shorts, Pear, Monkey, Truck, Sweater, Watermelon, Toothbrush.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:28:52 src.selection.data DEBUG    Options: Orange, Shampoo, Apple, Dress, Yacht, Scarf, Elephant.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "2025-09-15 00:28:52 src.selection.data DEBUG    Options: Orange, Shampoo, Apple, Dress, Yacht, Scarf, Elephant.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:28:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Dress', prob=0.427734375, logit=19.75, token_id=29318, metadata=None))[\" Dress\"] != 30760[\" Scar\"]\n",
      "2025-09-15 00:28:53 src.selection.data DEBUG    Options: Mango, Pants, Watch, Church, Skis, Skirt, Cherry.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:28:53 src.selection.data DEBUG    Options: Scarf, Strawberry, Surfboard, Library, Tie, Kiwi, Anklet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:28:53 src.selection.data DEBUG    Options: Scarf, Strawberry, Surfboard, Library, Tie, Kiwi, Anklet.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Tie\n",
      "2025-09-15 00:28:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ank', prob=0.76171875, logit=20.0, token_id=57915, metadata=None))[\" Ank\"] != 59825[\" Tie\"]\n",
      "2025-09-15 00:28:53 src.selection.data DEBUG    Options: Tie, Jeans, Kiwi, Plum, Harmonica, Laptop, Motorcycle.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "2025-09-15 00:28:53 src.selection.data DEBUG    Options: Watermelon, Headphones, Ukulele, Shirt, Gloves, Submarine, Pineapple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:28:53 src.selection.data DEBUG    Options: Watermelon, Headphones, Ukulele, Shirt, Gloves, Submarine, Pineapple.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "sample 281 / 512\n",
      "2025-09-15 00:28:57 src.selection.data DEBUG    Options: Dolphin, Locket, Earring, Cow, Pine.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:28:57 src.selection.data DEBUG    Options: Brooch, Spruce, Sheep, Zebra, Tiara.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:28:57 src.selection.data DEBUG    Options: Brooch, Spruce, Sheep, Zebra, Tiara.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "sample 282 / 512\n",
      "2025-09-15 00:29:01 src.selection.data DEBUG    Options: Gloves, Cucumber, Cufflink, Sweater, Cauliflower.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "2025-09-15 00:29:01 src.selection.data DEBUG    Options: Asparagus, Scarf, Lettuce, Shirt, Anklet.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:29:01 src.selection.data DEBUG    Options: Asparagus, Scarf, Lettuce, Shirt, Anklet.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "sample 283 / 512\n",
      "2025-09-15 00:29:05 src.selection.data DEBUG    Options: Orchid, Oven, Blueberry, Grape, Temple, Iris, Desk.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:29:05 src.selection.data DEBUG    Options: Daffodil, Mall, Apple, Kiwi, Marigold, Bench, Toaster.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:29:05 src.selection.data DEBUG    Options: Daffodil, Mall, Apple, Kiwi, Marigold, Bench, Toaster.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "sample 284 / 512\n",
      "2025-09-15 00:29:09 src.selection.data DEBUG    Options: Cufflink, Orchid, Rose, Tiara.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:29:09 src.selection.data DEBUG    Options: Watch, Daisy, Pendant, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:29:09 src.selection.data DEBUG    Options: Watch, Daisy, Pendant, Iris.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:29:09 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Iris', prob=0.62109375, logit=19.5, token_id=66821, metadata=None))[\" Iris\"] != 81501[\" Pendant\"]\n",
      "2025-09-15 00:29:09 src.selection.data DEBUG    Options: Sunflower, Iris, Pendant, Bangle.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:29:10 src.selection.data DEBUG    Options: Tiara, Orchid, Ring, Daisy.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:29:10 src.selection.data DEBUG    Options: Tiara, Orchid, Ring, Daisy.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "sample 285 / 512\n",
      "2025-09-15 00:29:13 src.selection.data DEBUG    Options: Oak, Kettle, Binder, Willow, Bat, Dumbbell.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:29:13 src.selection.data DEBUG    Options: Boxing gloves, Cedar, Magnolia, Rice cooker, Basketball, Pencil.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Basketball\n",
      "2025-09-15 00:29:14 src.selection.data DEBUG    Options: Boxing gloves, Cedar, Magnolia, Rice cooker, Basketball, Pencil.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "sample 286 / 512\n",
      "2025-09-15 00:29:17 src.selection.data DEBUG    Options: Cherry, Dumbbell, Hockey stick, Blueberry.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "2025-09-15 00:29:17 src.selection.data DEBUG    Options: Strawberry, Golf ball, Plum, Boxing gloves.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:29:17 src.selection.data DEBUG    Options: Strawberry, Golf ball, Plum, Boxing gloves.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "sample 287 / 512\n",
      "2025-09-15 00:29:21 src.selection.data DEBUG    Options: Dress, Marker, Lily, Sweater, Calculator.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:29:21 src.selection.data DEBUG    Options: Suit, Paper, Jasmine, Scissors, Gloves.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:29:21 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Paper', prob=0.4453125, logit=19.125, token_id=18343, metadata=None))[\" Paper\"] != 2522[\" Sc\"]\n",
      "2025-09-15 00:29:21 src.selection.data DEBUG    Options: Folder, Tie, Towel, Scarf, Calculator.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:29:21 src.selection.data DEBUG    Options: Tape, Shirt, Binder, Toothpaste, Gloves.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:29:21 src.selection.data DEBUG    Options: Tape, Shirt, Binder, Toothpaste, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:29:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Shirt', prob=0.51953125, logit=19.75, token_id=55807, metadata=None))[\" Shirt\"] != 68554[\" Gloves\"]\n",
      "2025-09-15 00:29:22 src.selection.data DEBUG    Options: Pen, Suit, Gloves, Elephant, Pencil.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:29:22 src.selection.data DEBUG    Options: Marker, Folder, Pants, Coat, Horse.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:29:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Marker', prob=0.88671875, logit=21.125, token_id=40975, metadata=None))[\" Marker\"] != 36943[\" Folder\"]\n",
      "2025-09-15 00:29:22 src.selection.data DEBUG    Options: Binder, Van, Dress, Calculator, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:29:22 src.selection.data DEBUG    Options: Pants, Highlighter, Pencil, Socks, Train.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:29:22 src.selection.data DEBUG    Options: Pants, Highlighter, Pencil, Socks, Train.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "sample 288 / 512\n",
      "2025-09-15 00:29:26 src.selection.data DEBUG    Options: Train, Chain, Cufflink, Bike.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "2025-09-15 00:29:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Train', prob=0.384765625, logit=18.75, token_id=27217, metadata=None))[\" Train\"] != 38930[\" Bike\"]\n",
      "2025-09-15 00:29:26 src.selection.data DEBUG    Options: Bangle, Car, Bracelet, Boat.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:29:26 src.selection.data DEBUG    Options: Anklet, Cufflink, Submarine, Tractor.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:29:26 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ank', prob=0.6796875, logit=20.5, token_id=57915, metadata=None))[\" Ank\"] != 356[\" C\"]\n",
      "2025-09-15 00:29:26 src.selection.data DEBUG    Options: Yacht, Bangle, Chain, Truck.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:29:26 src.selection.data DEBUG    Options: Locket, Train, Car, Cufflink.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:29:27 src.selection.data DEBUG    Options: Locket, Train, Car, Cufflink.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "sample 289 / 512\n",
      "2025-09-15 00:29:30 src.selection.data DEBUG    Options: Potato, Factory, Helmet, Hockey stick, Paper, Clarinet, Binder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:29:30 src.selection.data DEBUG    Options: Carrot, Basketball, Highlighter, Saxophone, Stapler, Boxing gloves, Church.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:29:30 src.selection.data DEBUG    Options: Carrot, Basketball, Highlighter, Saxophone, Stapler, Boxing gloves, Church.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "sample 290 / 512\n",
      "2025-09-15 00:29:34 src.selection.data DEBUG    Options: Tennis ball, Necklace, Golf ball, Submarine, Orange, Helicopter.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:29:34 src.selection.data DEBUG    Options: Truck, Scooter, Skis, Peach, Brooch, Helmet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:29:34 src.selection.data DEBUG    Options: Truck, Scooter, Skis, Peach, Brooch, Helmet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "sample 291 / 512\n",
      "2025-09-15 00:29:38 src.selection.data DEBUG    Options: Projector, Air fryer, Printer, Eagle, Toaster.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  To\n",
      "2025-09-15 00:29:38 src.selection.data DEBUG    Options: Pressure cooker, Camera, Router, Coffee maker, Dog.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "2025-09-15 00:29:38 src.selection.data DEBUG    Options: Pressure cooker, Camera, Router, Coffee maker, Dog.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Coffee\n",
      "sample 292 / 512\n",
      "2025-09-15 00:29:41 src.selection.data DEBUG    Options: Printer, Hospital, Headphones, School.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "2025-09-15 00:29:42 src.selection.data DEBUG    Options: Projector, Tablet, Factory, House.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:29:42 src.selection.data DEBUG    Options: Projector, Tablet, Factory, House.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "sample 293 / 512\n",
      "2025-09-15 00:29:46 src.selection.data DEBUG    Options: Strawberry, Tape, Elephant, Banana, Zebra.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n",
      "2025-09-15 00:29:46 src.selection.data DEBUG    Options: Mango, Orange, Cat, Dolphin, Highlighter.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:29:46 src.selection.data DEBUG    Options: Mango, Orange, Cat, Dolphin, Highlighter.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "sample 294 / 512\n",
      "2025-09-15 00:29:50 src.selection.data DEBUG    Options: Horse, Camera, Speaker, Stapler, Notebook.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 00:29:50 src.selection.data DEBUG    Options: Paper, Keyboard, Elephant, Smartwatch, Paperclip.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:29:50 src.selection.data DEBUG    Options: Paper, Keyboard, Elephant, Smartwatch, Paperclip.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "sample 295 / 512\n",
      "2025-09-15 00:29:53 src.selection.data DEBUG    Options: Helmet, Hockey stick, Stadium, Library, Maple, Orchid.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "2025-09-15 00:29:54 src.selection.data DEBUG    Options: Marigold, Factory, Redwood, Yoga mat, Mall, Surfboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:29:54 src.selection.data DEBUG    Options: Marigold, Factory, Redwood, Yoga mat, Mall, Surfboard.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:29:54 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Factory', prob=0.419921875, logit=19.25, token_id=17367, metadata=None))[\" Factory\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:29:54 src.selection.data DEBUG    Options: Skateboard, Dolphin, Skyscraper, Spinach, Boxing gloves, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:29:54 src.selection.data DEBUG    Options: Bat, Warehouse, Dog, Helmet, Theater, Lettuce.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:29:55 src.selection.data DEBUG    Options: Bat, Warehouse, Dog, Helmet, Theater, Lettuce.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "sample 296 / 512\n",
      "2025-09-15 00:29:58 src.selection.data DEBUG    Options: Palm, Shirt, Elm, Scarf, Toaster.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Scar\n",
      "2025-09-15 00:29:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Shirt', prob=0.498046875, logit=20.125, token_id=55807, metadata=None))[\" Shirt\"] != 30760[\" Scar\"]\n",
      "2025-09-15 00:29:58 src.selection.data DEBUG    Options: Shower, Magnolia, Shirt, Skirt, Palm.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:29:58 src.selection.data DEBUG    Options: Oak, Spruce, Socks, Toothbrush, Gloves.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:29:59 src.selection.data DEBUG    Options: Oak, Spruce, Socks, Toothbrush, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "sample 297 / 512\n",
      "2025-09-15 00:30:02 src.selection.data DEBUG    Options: Redwood, Onion, Locket, Bracelet, Pepper, Folder.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Pepper\n",
      "2025-09-15 00:30:02 src.selection.data DEBUG    Options: Spinach, Cauliflower, Charm, Chain, Highlighter, Spruce.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:30:03 src.selection.data DEBUG    Options: Spinach, Cauliflower, Charm, Chain, Highlighter, Spruce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "sample 298 / 512\n",
      "2025-09-15 00:30:06 src.selection.data DEBUG    Options: Razor, Speaker, Peony, Orchid, Printer, Monkey, Theater.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Orch\n",
      "2025-09-15 00:30:07 src.selection.data DEBUG    Options: Temple, Sunflower, Sink, Television, Router, Tulip, Giraffe.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "2025-09-15 00:30:07 src.selection.data DEBUG    Options: Temple, Sunflower, Sink, Television, Router, Tulip, Giraffe.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Tul\n",
      "sample 299 / 512\n",
      "2025-09-15 00:30:10 src.selection.data DEBUG    Options: Car, Projector, Bus, Speaker.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 00:30:11 src.selection.data DEBUG    Options: Microphone, Train, Laptop, Ambulance.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "2025-09-15 00:30:11 src.selection.data DEBUG    Options: Microphone, Train, Laptop, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "sample 300 / 512\n",
      "2025-09-15 00:30:14 src.selection.data DEBUG    Options: Mixer, Notebook, Desk, Ash, Elm, Ottoman.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "2025-09-15 00:30:15 src.selection.data DEBUG    Options: Spruce, Nightstand, Highlighter, Oak, Wardrobe, Food processor.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:30:15 src.selection.data DEBUG    Options: Spruce, Nightstand, Highlighter, Oak, Wardrobe, Food processor.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "sample 301 / 512\n",
      "2025-09-15 00:30:19 src.selection.data DEBUG    Options: Sofa, Mosque, Plum, Bathtub, Locket, Temple, Chain.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:30:19 src.selection.data DEBUG    Options: Hospital, Blueberry, Charm, Table, Apartment, Mirror, Bracelet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "2025-09-15 00:30:19 src.selection.data DEBUG    Options: Hospital, Blueberry, Charm, Table, Apartment, Mirror, Bracelet.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "sample 302 / 512\n",
      "2025-09-15 00:30:23 src.selection.data DEBUG    Options: Accordion, Harp, Bookshelf, Basketball, Dog, Lotion, Tennis ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Tennis\n",
      "2025-09-15 00:30:23 src.selection.data DEBUG    Options: Soap, Saxophone, Nightstand, Yoga mat, Giraffe, Surfboard, Flute.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:30:23 src.selection.data DEBUG    Options: Soap, Saxophone, Nightstand, Yoga mat, Giraffe, Surfboard, Flute.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "sample 303 / 512\n",
      "2025-09-15 00:30:27 src.selection.data DEBUG    Options: Router, Brooch, Camera, Earring.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:30:27 src.selection.data DEBUG    Options: Television, Locket, Watch, Speaker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 00:30:27 src.selection.data DEBUG    Options: Television, Locket, Watch, Speaker.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:30:27 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' L', prob=0.609375, logit=19.625, token_id=445, metadata=None))[\" L\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:30:27 src.selection.data DEBUG    Options: Router, Pendant, Bracelet, Keyboard.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Brace\n",
      "2025-09-15 00:30:28 src.selection.data DEBUG    Options: Watch, Projector, Necklace, Monitor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:30:28 src.selection.data DEBUG    Options: Watch, Projector, Necklace, Monitor.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "sample 304 / 512\n",
      "2025-09-15 00:30:32 src.selection.data DEBUG    Options: Museum, Scooter, Yacht, Warehouse, Earring.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "2025-09-15 00:30:32 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Sco', prob=0.470703125, logit=19.25, token_id=50159, metadata=None))[\" Sco\"] != 816[\" Y\"]\n",
      "2025-09-15 00:30:32 src.selection.data DEBUG    Options: Train, Mall, Hospital, Scooter, Cow.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:30:32 src.selection.data DEBUG    Options: Factory, Monkey, Tractor, Theater, Car.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "2025-09-15 00:30:33 src.selection.data DEBUG    Options: Factory, Monkey, Tractor, Theater, Car.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "sample 305 / 512\n",
      "2025-09-15 00:30:37 src.selection.data DEBUG    Options: Shorts, Shirt, Elm, Palm, Toaster, Zebra.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:30:37 src.selection.data DEBUG    Options: Air fryer, Skirt, Oak, Birch, Jacket, Cow.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:30:37 src.selection.data DEBUG    Options: Air fryer, Skirt, Oak, Birch, Jacket, Cow.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jacket\n",
      "sample 306 / 512\n",
      "2025-09-15 00:30:41 src.selection.data DEBUG    Options: Pear, Zebra, Mango, Bear.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Mango\n",
      "2025-09-15 00:30:41 src.selection.data DEBUG    Options: Cow, Horse, Cherry, Strawberry.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:30:41 src.selection.data DEBUG    Options: Cow, Horse, Cherry, Strawberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "sample 307 / 512\n",
      "2025-09-15 00:30:45 src.selection.data DEBUG    Options: Bus, Pineapple, Grape, Toilet, Towel.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tow\n",
      "2025-09-15 00:30:45 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Toilet', prob=0.4921875, logit=20.0, token_id=82994, metadata=None))[\" Toilet\"] != 41493[\" Tow\"]\n",
      "2025-09-15 00:30:45 src.selection.data DEBUG    Options: Shampoo, Pineapple, Toothbrush, Pear, Hat.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:30:46 src.selection.data DEBUG    Options: Skirt, Cherry, Toilet, Toilet paper, Mango.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Mango\n",
      "2025-09-15 00:30:46 src.selection.data DEBUG    Options: Skirt, Cherry, Toilet, Toilet paper, Mango.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "sample 308 / 512\n",
      "2025-09-15 00:30:50 src.selection.data DEBUG    Options: Museum, Train, Anklet, Earring, Desk, Chair.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Chair\n",
      "2025-09-15 00:30:50 src.selection.data DEBUG    Options: Pendant, Locket, Cabinet, Wardrobe, Bus, House.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:30:50 src.selection.data DEBUG    Options: Pendant, Locket, Cabinet, Wardrobe, Bus, House.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "sample 309 / 512\n",
      "2025-09-15 00:30:54 src.selection.data DEBUG    Options: Ambulance, Monkey, Magnolia, Microwave, Cedar, Bus.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 00:30:54 src.selection.data DEBUG    Options: Boat, Helicopter, Hickory, Horse, Oak, Mixer.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:30:54 src.selection.data DEBUG    Options: Boat, Helicopter, Hickory, Horse, Oak, Mixer.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:30:54 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Boat', prob=0.33203125, logit=19.0, token_id=45332, metadata=None))[\" Hel\"] != 16183[\" Hel\"]\n",
      "2025-09-15 00:30:54 src.selection.data DEBUG    Options: Birch, Palm, Boat, Cow, Motorcycle, Broccoli.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:30:55 src.selection.data DEBUG    Options: Tractor, Magnolia, Horse, Pepper, Oak, Bike.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:30:55 src.selection.data DEBUG    Options: Tractor, Magnolia, Horse, Pepper, Oak, Bike.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "sample 310 / 512\n",
      "2025-09-15 00:30:59 src.selection.data DEBUG    Options: Comb, Willow, Monkey, Router, Shower, Cow, Celery.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:30:59 src.selection.data DEBUG    Options: Cauliflower, Bathtub, Sink, Keyboard, Elephant, Cat, Maple.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:31:00 src.selection.data DEBUG    Options: Cauliflower, Bathtub, Sink, Keyboard, Elephant, Cat, Maple.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 311 / 512\n",
      "2025-09-15 00:31:05 src.selection.data DEBUG    Options: Palm, Submarine, Car, Pine, Necklace.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:31:05 src.selection.data DEBUG    Options: Bamboo, Bus, Redwood, Tiara, Van.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "2025-09-15 00:31:05 src.selection.data DEBUG    Options: Bamboo, Bus, Redwood, Tiara, Van.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "sample 312 / 512\n",
      "2025-09-15 00:31:10 src.selection.data DEBUG    Options: Apartment, Mosque, Hairdryer, Cufflink, Jasmine, Comb.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:31:11 src.selection.data DEBUG    Options: Theater, Marigold, Towel, Razor, Temple, Necklace.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:31:11 src.selection.data DEBUG    Options: Theater, Marigold, Towel, Razor, Temple, Necklace.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "sample 313 / 512\n",
      "2025-09-15 00:31:16 src.selection.data DEBUG    Options: Ring, Toaster, Sofa, Blender, Carnation, Hat, Recliner.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:31:16 src.selection.data DEBUG    Options: Stool, Sunflower, Watch, Bed, Socks, Coffee maker, Mixer.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:31:16 src.selection.data DEBUG    Options: Stool, Sunflower, Watch, Bed, Socks, Coffee maker, Mixer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "sample 314 / 512\n",
      "2025-09-15 00:31:20 src.selection.data DEBUG    Options: Charm, Cufflink, Coat, Dress, Sheep.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:31:20 src.selection.data DEBUG    Options: Dolphin, Bracelet, Tiara, Socks, Shirt.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "2025-09-15 00:31:21 src.selection.data DEBUG    Options: Dolphin, Bracelet, Tiara, Socks, Shirt.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "sample 315 / 512\n",
      "2025-09-15 00:31:26 src.selection.data DEBUG    Options: Scooter, Mosque, House, Motorcycle.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:31:26 src.selection.data DEBUG    Options: Apartment, Car, Museum, Bike.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "2025-09-15 00:31:26 src.selection.data DEBUG    Options: Apartment, Car, Museum, Bike.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "sample 316 / 512\n",
      "2025-09-15 00:31:31 src.selection.data DEBUG    Options: Iris, Table, Saxophone, Cabinet, Ukulele.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "2025-09-15 00:31:32 src.selection.data DEBUG    Options: Guitar, Violet, Trombone, Wardrobe, Ottoman.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trom\n",
      "2025-09-15 00:31:32 src.selection.data DEBUG    Options: Guitar, Violet, Trombone, Wardrobe, Ottoman.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "sample 317 / 512\n",
      "2025-09-15 00:31:37 src.selection.data DEBUG    Options: Mango, Pear, Harp, Drum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "2025-09-15 00:31:37 src.selection.data DEBUG    Options: Apple, Guitar, Grape, Harmonica.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Harmon\n",
      "2025-09-15 00:31:37 src.selection.data DEBUG    Options: Apple, Guitar, Grape, Harmonica.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "sample 318 / 512\n",
      "2025-09-15 00:31:41 src.selection.data DEBUG    Options: Oven, Bathtub, Necklace, Refrigerator, Sink.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "2025-09-15 00:31:41 src.selection.data DEBUG    Options: Bangle, Toaster, Towel, Mirror, Air fryer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:31:42 src.selection.data DEBUG    Options: Bangle, Toaster, Towel, Mirror, Air fryer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "sample 319 / 512\n",
      "2025-09-15 00:31:47 src.selection.data DEBUG    Options: Birch, Yoga mat, Toothbrush, Anklet, Eucalyptus, Tape, Skateboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:31:47 src.selection.data DEBUG    Options: Helmet, Tiara, Dumbbell, Willow, Stapler, Redwood, Hairdryer.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:31:47 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Willow', prob=0.671875, logit=19.375, token_id=65449, metadata=None))[\" Willow\"] != 3816[\" Red\"]\n",
      "2025-09-15 00:31:47 src.selection.data DEBUG    Options: Basketball, Pine, Helmet, Bench, Oven, Notebook, Ash.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:31:47 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Basketball', prob=0.40625, logit=18.75, token_id=47589, metadata=None))[\" Basketball\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:31:47 src.selection.data DEBUG    Options: Magnolia, Football, Palm, Hairdryer, Cow, Skateboard, Oven.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:31:48 src.selection.data DEBUG    Options: Giraffe, Oak, Boxing gloves, Soap, Helmet, Maple, Dishwasher.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "2025-09-15 00:31:48 src.selection.data DEBUG    Options: Giraffe, Oak, Boxing gloves, Soap, Helmet, Maple, Dishwasher.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:31:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boxing', prob=0.7734375, logit=21.0, token_id=72683, metadata=None))[\" Boxing\"] != 67629[\" Helmet\"]\n",
      "2025-09-15 00:31:48 src.selection.data DEBUG    Options: Oak, Trumpet, Maple, Tablet, Dumbbell, Zebra, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:31:48 src.selection.data DEBUG    Options: Router, Skateboard, Bamboo, Cello, Horse, Surfboard, Redwood.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:31:48 src.selection.data DEBUG    Options: Router, Skateboard, Bamboo, Cello, Horse, Surfboard, Redwood.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "sample 320 / 512\n",
      "2025-09-15 00:31:52 src.selection.data DEBUG    Options: Skateboard, Boxing gloves, Cherry, Orange.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:31:52 src.selection.data DEBUG    Options: Pineapple, Racket, Apple, Football.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "2025-09-15 00:31:52 src.selection.data DEBUG    Options: Pineapple, Racket, Apple, Football.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:31:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' R', prob=0.45703125, logit=19.75, token_id=432, metadata=None))[\" R\"] != 21424[\" Football\"]\n",
      "2025-09-15 00:31:53 src.selection.data DEBUG    Options: Plum, Racket, Bat, Mango.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:31:53 src.selection.data DEBUG    Options: Kiwi, Basketball, Surfboard, Orange.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "2025-09-15 00:31:53 src.selection.data DEBUG    Options: Kiwi, Basketball, Surfboard, Orange.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "sample 321 / 512\n",
      "2025-09-15 00:31:57 src.selection.data DEBUG    Options: Tractor, Notebook, Ambulance, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:31:57 src.selection.data DEBUG    Options: Motorcycle, Ruler, Paper, Train.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "2025-09-15 00:31:58 src.selection.data DEBUG    Options: Motorcycle, Ruler, Paper, Train.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 322 / 512\n",
      "2025-09-15 00:32:01 src.selection.data DEBUG    Options: Magnolia, Toilet, Mirror, Willow.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:32:01 src.selection.data DEBUG    Options: Elm, Spruce, Bathtub, Hairdryer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Hair\n",
      "2025-09-15 00:32:02 src.selection.data DEBUG    Options: Elm, Spruce, Bathtub, Hairdryer.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "sample 323 / 512\n",
      "2025-09-15 00:32:06 src.selection.data DEBUG    Options: Mango, Violin, Saxophone, Banana, Basketball.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "2025-09-15 00:32:06 src.selection.data DEBUG    Options: Harmonica, Clarinet, Golf ball, Cherry, Watermelon.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:32:06 src.selection.data DEBUG    Options: Harmonica, Clarinet, Golf ball, Cherry, Watermelon.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "sample 324 / 512\n",
      "2025-09-15 00:32:09 src.selection.data DEBUG    Options: Projector, Gloves, Ukulele, Harp, Shorts.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shorts\n",
      "2025-09-15 00:32:10 src.selection.data DEBUG    Options: Printer, Jacket, Guitar, Dress, Drum.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "2025-09-15 00:32:10 src.selection.data DEBUG    Options: Printer, Jacket, Guitar, Dress, Drum.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "sample 325 / 512\n",
      "2025-09-15 00:32:14 src.selection.data DEBUG    Options: Hickory, Soap, Basketball, Pendant, Recliner, Birch, Razor.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:32:14 src.selection.data DEBUG    Options: Cedar, Surfboard, Ring, Toilet paper, Bamboo, Bench, Toilet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:32:14 src.selection.data DEBUG    Options: Cedar, Surfboard, Ring, Toilet paper, Bamboo, Bench, Toilet.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "sample 326 / 512\n",
      "2025-09-15 00:32:18 src.selection.data DEBUG    Options: Zebra, Lion, Charm, Anklet, Jeans, Zucchini.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:32:18 src.selection.data DEBUG    Options: Monkey, Cufflink, Dress, Eagle, Necklace, Asparagus.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "2025-09-15 00:32:18 src.selection.data DEBUG    Options: Monkey, Cufflink, Dress, Eagle, Necklace, Asparagus.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Eagle\n",
      "sample 327 / 512\n",
      "2025-09-15 00:32:22 src.selection.data DEBUG    Options: Nightstand, Anklet, Watch, Bench.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:32:23 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ank', prob=0.55078125, logit=19.125, token_id=57915, metadata=None))[\" Ank\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:32:23 src.selection.data DEBUG    Options: Locket, Table, Tiara, Nightstand.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:32:23 src.selection.data DEBUG    Options: Cufflink, Earring, Coffee table, Cabinet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "2025-09-15 00:32:23 src.selection.data DEBUG    Options: Cufflink, Earring, Coffee table, Cabinet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "sample 328 / 512\n",
      "2025-09-15 00:32:27 src.selection.data DEBUG    Options: Ruler, Paper, Stadium, Cow, Chain, Temple.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:32:27 src.selection.data DEBUG    Options: Marker, Binder, Library, Hospital, Sheep, Bangle.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:32:27 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Marker', prob=0.453125, logit=19.875, token_id=40975, metadata=None))[\" Marker\"] != 91263[\" Binder\"]\n",
      "2025-09-15 00:32:27 src.selection.data DEBUG    Options: Highlighter, Accordion, Temple, Paper, Scarf, Theater.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Theater\n",
      "2025-09-15 00:32:27 src.selection.data DEBUG    Options: Scissors, Museum, Jacket, Paperclip, Library, Guitar.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:32:27 src.selection.data DEBUG    Options: Scissors, Museum, Jacket, Paperclip, Library, Guitar.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "sample 329 / 512\n",
      "2025-09-15 00:32:31 src.selection.data DEBUG    Options: Harmonica, Willow, Palm, Cello.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Palm\n",
      "2025-09-15 00:32:31 src.selection.data DEBUG    Options: Accordion, Violin, Oak, Elm.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:32:31 src.selection.data DEBUG    Options: Accordion, Violin, Oak, Elm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "sample 330 / 512\n",
      "2025-09-15 00:32:35 src.selection.data DEBUG    Options: Cucumber, Harp, Library, Tractor, Sheep, Cat, Scooter.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:32:35 src.selection.data DEBUG    Options: Motorcycle, Elephant, Ambulance, Zebra, Accordion, School, Asparagus.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:32:35 src.selection.data DEBUG    Options: Motorcycle, Elephant, Ambulance, Zebra, Accordion, School, Asparagus.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "sample 331 / 512\n",
      "2025-09-15 00:32:39 src.selection.data DEBUG    Options: Daisy, Shampoo, Chrysanthemum, Hairdryer.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "2025-09-15 00:32:39 src.selection.data DEBUG    Options: Carnation, Towel, Marigold, Mirror.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:32:39 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tow', prob=0.53125, logit=19.75, token_id=41493, metadata=None))[\" Tow\"] != 34954[\" Mirror\"]\n",
      "2025-09-15 00:32:39 src.selection.data DEBUG    Options: Chrysanthemum, Mirror, Razor, Rose.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Rose\n",
      "2025-09-15 00:32:39 src.selection.data DEBUG    Options: Shower, Tulip, Marigold, Toilet paper.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:32:40 src.selection.data DEBUG    Options: Shower, Tulip, Marigold, Toilet paper.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "sample 332 / 512\n",
      "2025-09-15 00:32:43 src.selection.data DEBUG    Options: Projector, Notebook, Toothbrush, Mango, Raspberry, Toothpaste, Bat.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:32:43 src.selection.data DEBUG    Options: Football, Shampoo, Toilet paper, Ruler, Grape, Keyboard, Plum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:32:44 src.selection.data DEBUG    Options: Football, Shampoo, Toilet paper, Ruler, Grape, Keyboard, Plum.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "sample 333 / 512\n",
      "2025-09-15 00:32:47 src.selection.data DEBUG    Options: Football, Bathtub, Soap, Basketball.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Soap\n",
      "2025-09-15 00:32:47 src.selection.data DEBUG    Options: Skateboard, Surfboard, Shampoo, Toothpaste.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:32:48 src.selection.data DEBUG    Options: Skateboard, Surfboard, Shampoo, Toothpaste.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "sample 334 / 512\n",
      "2025-09-15 00:32:51 src.selection.data DEBUG    Options: Mushroom, Saxophone, Scooter, Flute, Shirt, Tomato, Binder.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:32:51 src.selection.data DEBUG    Options: Celery, Ukulele, Eraser, Yacht, Scarf, Violin, Cucumber.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:32:51 src.selection.data DEBUG    Options: Celery, Ukulele, Eraser, Yacht, Scarf, Violin, Cucumber.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "sample 335 / 512\n",
      "2025-09-15 00:32:55 src.selection.data DEBUG    Options: Submarine, Earring, Eucalyptus, Pineapple, Bat, Birch, Cherry.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:32:55 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Cherry', prob=0.423828125, logit=18.625, token_id=45805, metadata=None))[\" Cherry\"] != 88088[\" Birch\"]\n",
      "2025-09-15 00:32:55 src.selection.data DEBUG    Options: Bus, Pear, Bamboo, Raspberry, Smartwatch, Cedar, Shorts.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Cedar\n",
      "2025-09-15 00:32:55 src.selection.data DEBUG    Options: Shirt, Hickory, Speaker, Cherry, Elm, Boat, Kiwi.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:32:55 src.selection.data DEBUG    Options: Shirt, Hickory, Speaker, Cherry, Elm, Boat, Kiwi.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "sample 336 / 512\n",
      "2025-09-15 00:32:59 src.selection.data DEBUG    Options: Toothbrush, Brooch, Monkey, Locket, Spruce, Toothpaste, Peony.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:32:59 src.selection.data DEBUG    Options: Pine, Chain, Zebra, Sink, Tiara, Sunflower, Shower.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:32:59 src.selection.data DEBUG    Options: Pine, Chain, Zebra, Sink, Tiara, Sunflower, Shower.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "sample 337 / 512\n",
      "2025-09-15 00:33:03 src.selection.data DEBUG    Options: Air fryer, Phone, Tablet, Scooter, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:33:03 src.selection.data DEBUG    Options: Refrigerator, Mouse, Headphones, Food processor, Truck.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "2025-09-15 00:33:03 src.selection.data DEBUG    Options: Refrigerator, Mouse, Headphones, Food processor, Truck.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "sample 338 / 512\n",
      "2025-09-15 00:33:06 src.selection.data DEBUG    Options: Car, Orange, Boat, Banana.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:33:07 src.selection.data DEBUG    Options: Motorcycle, Plum, Watermelon, Tractor.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:33:07 src.selection.data DEBUG    Options: Motorcycle, Plum, Watermelon, Tractor.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "sample 339 / 512\n",
      "2025-09-15 00:33:10 src.selection.data DEBUG    Options: Watch, Cat, Highlighter, Locket, Cabinet, Recliner.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:33:10 src.selection.data DEBUG    Options: Tiara, Ring, Bench, Sofa, Calculator, Tiger.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Sofa\n",
      "2025-09-15 00:33:11 src.selection.data DEBUG    Options: Tiara, Ring, Bench, Sofa, Calculator, Tiger.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "sample 340 / 512\n",
      "2025-09-15 00:33:14 src.selection.data DEBUG    Options: Pen, Tape, Coffee table, Wardrobe, Car, Guitar.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "2025-09-15 00:33:14 src.selection.data DEBUG    Options: Clarinet, Dresser, Van, Eraser, Bed, Binder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:33:15 src.selection.data DEBUG    Options: Clarinet, Dresser, Van, Eraser, Bed, Binder.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "sample 341 / 512\n",
      "2025-09-15 00:33:18 src.selection.data DEBUG    Options: Jasmine, Asparagus, Yoga mat, Plum, Racket, Mushroom.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:33:18 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' As', prob=0.41796875, logit=19.5, token_id=1666, metadata=None))[\" As\"] != 91297[\" Mushroom\"]\n",
      "2025-09-15 00:33:18 src.selection.data DEBUG    Options: Towel, Spinach, Shorts, Surfboard, Football, Zucchini.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:33:19 src.selection.data DEBUG    Options: Suit, Carrot, Yoga mat, Dumbbell, Cauliflower, Soap.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:33:19 src.selection.data DEBUG    Options: Suit, Carrot, Yoga mat, Dumbbell, Cauliflower, Soap.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "sample 342 / 512\n",
      "2025-09-15 00:33:22 src.selection.data DEBUG    Options: Rabbit, Skirt, Tennis ball, Yoga mat, Ring, Maple, Redwood.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:33:22 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Maple', prob=0.482421875, logit=19.375, token_id=44570, metadata=None))[\" Maple\"] != 3816[\" Red\"]\n",
      "2025-09-15 00:33:22 src.selection.data DEBUG    Options: Eucalyptus, Hickory, Oven, Orchid, Racket, Helmet, Projector.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "2025-09-15 00:33:23 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' E', prob=0.263671875, logit=17.25, token_id=469, metadata=None))[\" E\"] != 79028[\" Hick\"]\n",
      "2025-09-15 00:33:23 src.selection.data DEBUG    Options: Oak, Mixer, Helmet, Strawberry, Redwood, Golf ball, Tiger.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:33:23 src.selection.data DEBUG    Options: Watermelon, Dolphin, Ash, Basketball, Yoga mat, Bamboo, Kettle.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:33:23 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Basketball', prob=0.89453125, logit=21.25, token_id=47589, metadata=None))[\" Basketball\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:33:23 src.selection.data DEBUG    Options: Yoga mat, Scarf, Bamboo, Golf ball, Elm, Motorcycle, Broccoli.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "2025-09-15 00:33:23 src.selection.data DEBUG    Options: Celery, Football, Eucalyptus, Willow, Baseball, Airplane, Sweater.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:33:23 src.selection.data DEBUG    Options: Celery, Football, Eucalyptus, Willow, Baseball, Airplane, Sweater.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "sample 343 / 512\n",
      "2025-09-15 00:33:27 src.selection.data DEBUG    Options: Raspberry, Lion, Sheep, Suit, Lavender, Jacket.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jacket\n",
      "2025-09-15 00:33:27 src.selection.data DEBUG    Options: Tiger, Horse, Shirt, Dress, Violet, Cherry.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:33:27 src.selection.data DEBUG    Options: Tiger, Horse, Shirt, Dress, Violet, Cherry.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "sample 344 / 512\n",
      "2025-09-15 00:33:31 src.selection.data DEBUG    Options: Accordion, Stapler, Bangle, Lion, Zebra, Tiara.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:33:31 src.selection.data DEBUG    Options: Elephant, Locket, Anklet, Tiger, Scissors, Xylophone.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "2025-09-15 00:33:31 src.selection.data DEBUG    Options: Elephant, Locket, Anklet, Tiger, Scissors, Xylophone.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "sample 345 / 512\n",
      "2025-09-15 00:33:35 src.selection.data DEBUG    Options: Hairdryer, Towel, Cello, Flute.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:33:35 src.selection.data DEBUG    Options: Xylophone, Shower, Lotion, Accordion.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:33:35 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Shower', prob=0.50390625, logit=20.0, token_id=48471, metadata=None))[\" Shower\"] != 445[\" L\"]\n",
      "2025-09-15 00:33:35 src.selection.data DEBUG    Options: Lotion, Shampoo, Piano, Flute.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:33:35 src.selection.data DEBUG    Options: Trombone, Toilet paper, Ukulele, Toilet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:33:35 src.selection.data DEBUG    Options: Trombone, Toilet paper, Ukulele, Toilet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "sample 346 / 512\n",
      "2025-09-15 00:33:39 src.selection.data DEBUG    Options: Necklace, Microphone, Church, Pendant, Palm, Mosque.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "2025-09-15 00:33:39 src.selection.data DEBUG    Options: Watch, Printer, Apartment, Museum, Earring, Birch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:33:39 src.selection.data DEBUG    Options: Watch, Printer, Apartment, Museum, Earring, Birch.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "sample 347 / 512\n",
      "2025-09-15 00:33:43 src.selection.data DEBUG    Options: Temple, Surfboard, Yacht, Coffee maker, Camera, Boxing gloves, Juicer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Ju\n",
      "2025-09-15 00:33:43 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Coffee', prob=0.357421875, logit=18.875, token_id=27171, metadata=None))[\" Coffee\"] != 22410[\" Ju\"]\n",
      "2025-09-15 00:33:43 src.selection.data DEBUG    Options: Wardrobe, Juicer, Surfboard, Tennis ball, Mango, Willow, Mixer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-15 00:33:44 src.selection.data DEBUG    Options: Basketball, Elm, Golf ball, Coffee maker, Plum, Food processor, Table.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:33:44 src.selection.data DEBUG    Options: Basketball, Elm, Golf ball, Coffee maker, Plum, Food processor, Table.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "sample 348 / 512\n",
      "2025-09-15 00:33:47 src.selection.data DEBUG    Options: Mosque, Temple, Oven, Rice cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Rice\n",
      "2025-09-15 00:33:48 src.selection.data DEBUG    Options: Toaster, Church, Hospital, Coffee maker.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "2025-09-15 00:33:48 src.selection.data DEBUG    Options: Toaster, Church, Hospital, Coffee maker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Coffee\n",
      "sample 349 / 512\n",
      "2025-09-15 00:33:51 src.selection.data DEBUG    Options: Kettle, Horse, Dolphin, Mixer.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dolphin\n",
      "2025-09-15 00:33:52 src.selection.data DEBUG    Options: Air fryer, Dishwasher, Giraffe, Cow.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "2025-09-15 00:33:52 src.selection.data DEBUG    Options: Air fryer, Dishwasher, Giraffe, Cow.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "sample 350 / 512\n",
      "2025-09-15 00:33:55 src.selection.data DEBUG    Options: Plum, Laptop, Skateboard, Smartwatch, Grape.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "2025-09-15 00:33:56 src.selection.data DEBUG    Options: Strawberry, Peach, Basketball, Printer, Monitor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:33:56 src.selection.data DEBUG    Options: Strawberry, Peach, Basketball, Printer, Monitor.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "sample 351 / 512\n",
      "2025-09-15 00:34:00 src.selection.data DEBUG    Options: Ottoman, Banana, Ambulance, Magnolia, Ring, Chain, Airplane.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:34:00 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ring', prob=0.494140625, logit=19.875, token_id=22249, metadata=None))[\" Ring\"] != 29625[\" Chain\"]\n",
      "2025-09-15 00:34:00 src.selection.data DEBUG    Options: Boat, Zebra, Submarine, Bangle, Broccoli, Pineapple, Pendant.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:34:00 src.selection.data DEBUG    Options: Mango, Elephant, Brooch, Ambulance, Van, Pin, Asparagus.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "2025-09-15 00:34:00 src.selection.data DEBUG    Options: Mango, Elephant, Brooch, Ambulance, Van, Pin, Asparagus.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:34:00 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bro', prob=0.431640625, logit=20.0, token_id=6031, metadata=None))[\" Bro\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:34:00 src.selection.data DEBUG    Options: Bus, Dolphin, Spinach, Pendant, Pineapple, Car, Watch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:34:01 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pendant', prob=0.8828125, logit=21.875, token_id=81501, metadata=None))[\" Pendant\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:34:01 src.selection.data DEBUG    Options: Anklet, Ukulele, Ambulance, Calculator, Dog, Airplane, Charm.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:34:01 src.selection.data DEBUG    Options: Bangle, Pendant, Boat, Scooter, Guitar, Monkey, Eraser.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:34:01 src.selection.data DEBUG    Options: Bangle, Pendant, Boat, Scooter, Guitar, Monkey, Eraser.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "sample 352 / 512\n",
      "2025-09-15 00:34:05 src.selection.data DEBUG    Options: Trumpet, Church, Bracelet, Piano, Stadium, Mango, Pepper.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Stadium\n",
      "2025-09-15 00:34:05 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Church', prob=0.466796875, logit=19.5, token_id=9441, metadata=None))[\" Church\"] != 23462[\" Stadium\"]\n",
      "2025-09-15 00:34:05 src.selection.data DEBUG    Options: Stool, Drum, Scarf, Orchid, Church, Flute, Temple.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:34:05 src.selection.data DEBUG    Options: Violin, Sweater, Apartment, Lavender, Bench, School, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:34:05 src.selection.data DEBUG    Options: Violin, Sweater, Apartment, Lavender, Bench, School, Clarinet.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "sample 353 / 512\n",
      "2025-09-15 00:34:09 src.selection.data DEBUG    Options: Speaker, Horse, Keyboard, Cow, Shirt.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:34:09 src.selection.data DEBUG    Options: Tablet, Zebra, Eagle, Dress, Headphones.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Eagle\n",
      "2025-09-15 00:34:09 src.selection.data DEBUG    Options: Tablet, Zebra, Eagle, Dress, Headphones.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "sample 354 / 512\n",
      "2025-09-15 00:34:13 src.selection.data DEBUG    Options: Mall, Saxophone, Clarinet, Pine, Hickory.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:34:13 src.selection.data DEBUG    Options: Willow, Maple, Cello, Skyscraper, Harp.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "2025-09-15 00:34:13 src.selection.data DEBUG    Options: Willow, Maple, Cello, Skyscraper, Harp.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "sample 355 / 512\n",
      "2025-09-15 00:34:17 src.selection.data DEBUG    Options: Cello, Orange, Violin, Lion, Horse.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:34:17 src.selection.data DEBUG    Options: Apple, Sheep, Monkey, Ukulele, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:34:18 src.selection.data DEBUG    Options: Apple, Sheep, Monkey, Ukulele, Clarinet.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "sample 356 / 512\n",
      "2025-09-15 00:34:21 src.selection.data DEBUG    Options: Submarine, Projector, Tablet, Bookshelf, Car, Coat, Soap.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:34:21 src.selection.data DEBUG    Options: Phone, Shampoo, Ambulance, Chair, Skirt, Tractor, Television.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "2025-09-15 00:34:21 src.selection.data DEBUG    Options: Phone, Shampoo, Ambulance, Chair, Skirt, Tractor, Television.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "sample 357 / 512\n",
      "2025-09-15 00:34:25 src.selection.data DEBUG    Options: Museum, Marker, Cow, Factory, Sheep.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Factory\n",
      "2025-09-15 00:34:25 src.selection.data DEBUG    Options: Pencil, Theater, Monkey, Cat, House.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:34:25 src.selection.data DEBUG    Options: Pencil, Theater, Monkey, Cat, House.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "sample 358 / 512\n",
      "2025-09-15 00:34:29 src.selection.data DEBUG    Options: Comb, Keyboard, Toothbrush, Birch, Mosque, Scissors, Willow.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:34:29 src.selection.data DEBUG    Options: Speaker, Towel, Pen, Maple, Hairdryer, Redwood, Mall.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:34:29 src.selection.data DEBUG    Options: Speaker, Towel, Pen, Maple, Hairdryer, Redwood, Mall.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Hair\n",
      "sample 359 / 512\n",
      "2025-09-15 00:34:33 src.selection.data DEBUG    Options: Harp, Kettle, Monkey, Broccoli, Toilet, Tiger, Piano.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "2025-09-15 00:34:33 src.selection.data DEBUG    Options: Carrot, Rabbit, Razor, Bear, Trombone, Harmonica, Slow cooker.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Harmon\n",
      "2025-09-15 00:34:33 src.selection.data DEBUG    Options: Carrot, Rabbit, Razor, Bear, Trombone, Harmonica, Slow cooker.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "sample 360 / 512\n",
      "2025-09-15 00:34:37 src.selection.data DEBUG    Options: Keyboard, Celery, Shirt, Pine, Anklet, Bamboo, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:34:37 src.selection.data DEBUG    Options: Cufflink, Pants, Magnolia, Maple, Lettuce, Necklace, Headphones.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "2025-09-15 00:34:37 src.selection.data DEBUG    Options: Cufflink, Pants, Magnolia, Maple, Lettuce, Necklace, Headphones.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "sample 361 / 512\n",
      "2025-09-15 00:34:41 src.selection.data DEBUG    Options: Piano, Yoga mat, Scissors, Ukulele, School, Scooter, Stapler.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "2025-09-15 00:34:41 src.selection.data DEBUG    Options: Xylophone, Pencil, Ruler, Bike, Trumpet, Helmet, Warehouse.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:34:41 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' P', prob=0.55859375, logit=20.0, token_id=393, metadata=None))[\" P\"] != 432[\" R\"]\n",
      "2025-09-15 00:34:41 src.selection.data DEBUG    Options: Saxophone, Paperclip, Ruler, Tablet, Car, Cauliflower, Accordion.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "2025-09-15 00:34:41 src.selection.data DEBUG    Options: Clarinet, Scissors, Drum, Submarine, Stapler, Potato, Laptop.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "2025-09-15 00:34:41 src.selection.data DEBUG    Options: Clarinet, Scissors, Drum, Submarine, Stapler, Potato, Laptop.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Drum\n",
      "sample 362 / 512\n",
      "2025-09-15 00:34:45 src.selection.data DEBUG    Options: Rose, Food processor, Theater, House, Car, Bus.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 00:34:45 src.selection.data DEBUG    Options: Boat, Skyscraper, Truck, Blender, Museum, Lily.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "2025-09-15 00:34:45 src.selection.data DEBUG    Options: Boat, Skyscraper, Truck, Blender, Museum, Lily.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "sample 363 / 512\n",
      "2025-09-15 00:34:49 src.selection.data DEBUG    Options: Piano, Bamboo, Speaker, Spinach, Asparagus, Microphone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Micro\n",
      "2025-09-15 00:34:49 src.selection.data DEBUG    Options: Clarinet, Tomato, Headphones, Eucalyptus, Tablet, Celery.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "2025-09-15 00:34:49 src.selection.data DEBUG    Options: Clarinet, Tomato, Headphones, Eucalyptus, Tablet, Celery.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "sample 364 / 512\n",
      "2025-09-15 00:34:53 src.selection.data DEBUG    Options: Hockey stick, Tulip, Stadium, Warehouse, Pants, Boxing gloves.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:34:53 src.selection.data DEBUG    Options: Iris, Baseball, Tie, Apartment, Skis, Mall.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:34:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Apartment', prob=0.58984375, logit=19.625, token_id=53889, metadata=None))[\" Apartment\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:34:53 src.selection.data DEBUG    Options: Church, Dumbbell, Skateboard, Sweater, Violin, Theater.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:34:53 src.selection.data DEBUG    Options: Temple, Yoga mat, Trombone, Warehouse, Basketball, Dress.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:34:54 src.selection.data DEBUG    Options: Temple, Yoga mat, Trombone, Warehouse, Basketball, Dress.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Basketball\n",
      "sample 365 / 512\n",
      "2025-09-15 00:34:57 src.selection.data DEBUG    Options: Tennis ball, Dumbbell, Nightstand, Sweater, Jeans, Slow cooker, Oak.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "2025-09-15 00:34:58 src.selection.data DEBUG    Options: Football, Surfboard, Tie, Blender, Birch, Suit, Coffee table.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:34:58 src.selection.data DEBUG    Options: Football, Surfboard, Tie, Blender, Birch, Suit, Coffee table.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "sample 366 / 512\n",
      "2025-09-15 00:35:01 src.selection.data DEBUG    Options: Dresser, Coffee table, Dress, Shorts, Smartwatch.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:35:02 src.selection.data DEBUG    Options: Monitor, Table, Ottoman, Coat, Jacket.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jacket\n",
      "2025-09-15 00:35:02 src.selection.data DEBUG    Options: Monitor, Table, Ottoman, Coat, Jacket.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "sample 367 / 512\n",
      "2025-09-15 00:35:05 src.selection.data DEBUG    Options: Grape, Toilet paper, Jacket, Pants, Shampoo.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:35:05 src.selection.data DEBUG    Options: Scarf, Shower, Jeans, Comb, Strawberry.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 00:35:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Shower', prob=0.53515625, logit=19.875, token_id=48471, metadata=None))[\" Shower\"] != 23262[\" Comb\"]\n",
      "2025-09-15 00:35:06 src.selection.data DEBUG    Options: Locket, Pants, Gloves, Soap, Toilet paper.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:35:06 src.selection.data DEBUG    Options: Scarf, Shorts, Shampoo, Necklace, Razor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:35:06 src.selection.data DEBUG    Options: Scarf, Shorts, Shampoo, Necklace, Razor.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shorts\n",
      "sample 368 / 512\n",
      "2025-09-15 00:35:10 src.selection.data DEBUG    Options: Flute, Rice cooker, Lily, Violet, Pendant, Cello, Sink.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:35:10 src.selection.data DEBUG    Options: Guitar, Toilet, Bracelet, Ukulele, Orchid, Food processor, Chrysanthemum.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "2025-09-15 00:35:10 src.selection.data DEBUG    Options: Guitar, Toilet, Bracelet, Ukulele, Orchid, Food processor, Chrysanthemum.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "sample 369 / 512\n",
      "2025-09-15 00:35:14 src.selection.data DEBUG    Options: Soap, Boxing gloves, Toilet paper, Eraser, Ruler.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:35:14 src.selection.data DEBUG    Options: Football, Marker, Razor, Pencil, Lotion.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:35:14 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Razor', prob=0.80078125, logit=20.875, token_id=74968, metadata=None))[\" Razor\"] != 445[\" L\"]\n",
      "2025-09-15 00:35:14 src.selection.data DEBUG    Options: Toothbrush, Pencil, Hairdryer, Strawberry, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:35:14 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' P', prob=0.65625, logit=20.625, token_id=393, metadata=None))[\" P\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:35:14 src.selection.data DEBUG    Options: Soap, Racket, Marker, Mirror, Ruler.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:35:15 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Marker', prob=0.484375, logit=18.875, token_id=40975, metadata=None))[\" Marker\"] != 432[\" R\"]\n",
      "2025-09-15 00:35:15 src.selection.data DEBUG    Options: Comb, Magnolia, Notebook, Lotion, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:35:15 src.selection.data DEBUG    Options: Folder, Scissors, Hairdryer, Elm, Mirror.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:35:15 src.selection.data DEBUG    Options: Folder, Scissors, Hairdryer, Elm, Mirror.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:35:15 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Folder', prob=0.283203125, logit=18.0, token_id=36943, metadata=None))[\" Folder\"] != 2522[\" Sc\"]\n",
      "2025-09-15 00:35:15 src.selection.data DEBUG    Options: Hairdryer, Microphone, Lotion, Pen, Tape.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:35:15 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pen', prob=0.73046875, logit=20.375, token_id=13597, metadata=None))[\" Pen\"] != 58586[\" Tape\"]\n",
      "2025-09-15 00:35:15 src.selection.data DEBUG    Options: Mirror, Toothpaste, Eagle, Paperclip, Binder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:35:15 src.selection.data DEBUG    Options: Notebook, Comb, Razor, Ruler, Rabbit.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:35:16 src.selection.data DEBUG    Options: Notebook, Comb, Razor, Ruler, Rabbit.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "sample 370 / 512\n",
      "2025-09-15 00:35:19 src.selection.data DEBUG    Options: Ukulele, Sheep, Nightstand, Oven, Piano, Strawberry, Mango.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Piano\n",
      "2025-09-15 00:35:19 src.selection.data DEBUG    Options: Saxophone, Coffee table, Orange, Harp, Food processor, Kiwi, Eagle.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:35:19 src.selection.data DEBUG    Options: Saxophone, Coffee table, Orange, Harp, Food processor, Kiwi, Eagle.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "sample 371 / 512\n",
      "2025-09-15 00:35:23 src.selection.data DEBUG    Options: Bat, Truck, Shorts, Tractor, Mango, Strawberry, Factory.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Tr\n",
      "2025-09-15 00:35:23 src.selection.data DEBUG    Options: Raspberry, Surfboard, Train, Socks, Motorcycle, Cherry, Temple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:35:23 src.selection.data DEBUG    Options: Raspberry, Surfboard, Train, Socks, Motorcycle, Cherry, Temple.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "sample 372 / 512\n",
      "2025-09-15 00:35:27 src.selection.data DEBUG    Options: Redwood, Apartment, Daffodil, Willow, Library.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:35:27 src.selection.data DEBUG    Options: Magnolia, Violet, Ash, Mosque, Museum.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "2025-09-15 00:35:27 src.selection.data DEBUG    Options: Magnolia, Violet, Ash, Mosque, Museum.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "sample 373 / 512\n",
      "2025-09-15 00:35:31 src.selection.data DEBUG    Options: Apartment, Kettle, Accordion, House, Pin, Bangle, Cow.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:35:31 src.selection.data DEBUG    Options: Temple, Chain, Elephant, Pendant, Hospital, Coffee maker, Flute.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:35:31 src.selection.data DEBUG    Options: Temple, Chain, Elephant, Pendant, Hospital, Coffee maker, Flute.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "sample 374 / 512\n",
      "2025-09-15 00:35:35 src.selection.data DEBUG    Options: Dishwasher, Mixer, Xylophone, Trumpet.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-15 00:35:35 src.selection.data DEBUG    Options: Toaster, Drum, Accordion, Slow cooker.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "2025-09-15 00:35:35 src.selection.data DEBUG    Options: Toaster, Drum, Accordion, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "sample 375 / 512\n",
      "2025-09-15 00:35:39 src.selection.data DEBUG    Options: Marigold, Eagle, Dog, Daffodil.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:35:39 src.selection.data DEBUG    Options: Rose, Elephant, Lion, Carnation.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:35:39 src.selection.data DEBUG    Options: Rose, Elephant, Lion, Carnation.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "sample 376 / 512\n",
      "2025-09-15 00:35:43 src.selection.data DEBUG    Options: Jasmine, Recliner, Chair, Basketball, Dolphin, Dumbbell, Kettle.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:35:43 src.selection.data DEBUG    Options: Table, Desk, Helmet, Yoga mat, Horse, Lavender, Refrigerator.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Desk\n",
      "2025-09-15 00:35:43 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Refriger', prob=0.41015625, logit=18.75, token_id=75258, metadata=None))[\" Refriger\"] != 39794[\" Desk\"]\n",
      "2025-09-15 00:35:43 src.selection.data DEBUG    Options: Boxing gloves, Socks, Bookshelf, Baseball, Factory, Asparagus, Recliner.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:35:43 src.selection.data DEBUG    Options: Mall, Jacket, Cabinet, Table, Dumbbell, Cucumber, Hockey stick.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Table\n",
      "2025-09-15 00:35:44 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Cabinet', prob=0.54296875, logit=20.0, token_id=34046, metadata=None))[\" Cabinet\"] != 6771[\" Table\"]\n",
      "2025-09-15 00:35:44 src.selection.data DEBUG    Options: Blender, Bed, Skis, Cello, Boxing gloves, Dresser, Coat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "2025-09-15 00:35:44 src.selection.data DEBUG    Options: Bench, Oven, Hat, Sofa, Football, Clarinet, Yoga mat.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Sofa\n",
      "2025-09-15 00:35:44 src.selection.data DEBUG    Options: Bench, Oven, Hat, Sofa, Football, Clarinet, Yoga mat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:35:44 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Football', prob=0.80859375, logit=20.75, token_id=21424, metadata=None))[\" Football\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:35:44 src.selection.data DEBUG    Options: Skateboard, Pendant, Yoga mat, Rabbit, Sunflower, Chair, Wardrobe.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:35:44 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Skate', prob=0.484375, logit=19.375, token_id=97796, metadata=None))[\" Skate\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:35:44 src.selection.data DEBUG    Options: Oven, Jeans, Stool, Bat, Bench, Baseball, Toothbrush.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:35:44 src.selection.data DEBUG    Options: Table, Basketball, Tennis ball, Hairdryer, Dishwasher, Hat, Coffee table.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:35:45 src.selection.data DEBUG    Options: Table, Basketball, Tennis ball, Hairdryer, Dishwasher, Hat, Coffee table.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Tennis\n",
      "sample 377 / 512\n",
      "2025-09-15 00:35:48 src.selection.data DEBUG    Options: Juicer, Kettle, Notebook, Cauliflower, Paper, Toilet.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  K\n",
      "2025-09-15 00:35:48 src.selection.data DEBUG    Options: Marker, Asparagus, Blender, Eraser, Hairdryer, Slow cooker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:35:49 src.selection.data DEBUG    Options: Marker, Asparagus, Blender, Eraser, Hairdryer, Slow cooker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Slow\n",
      "sample 378 / 512\n",
      "2025-09-15 00:35:52 src.selection.data DEBUG    Options: Mouse, Factory, Bamboo, Laptop, Folder, Warehouse, Harmonica.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "2025-09-15 00:35:53 src.selection.data DEBUG    Options: Skyscraper, Monitor, Temple, Eraser, Trombone, Redwood, Router.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:35:53 src.selection.data DEBUG    Options: Skyscraper, Monitor, Temple, Eraser, Trombone, Redwood, Router.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "sample 379 / 512\n",
      "2025-09-15 00:35:57 src.selection.data DEBUG    Options: Trumpet, Monkey, Truck, Stapler, Towel, Ruler, Scooter.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:35:57 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.80859375, logit=20.375, token_id=63606, metadata=None))[\" Stap\"] != 432[\" R\"]\n",
      "2025-09-15 00:35:57 src.selection.data DEBUG    Options: Toaster, Ambulance, Notebook, Desk, Tractor, Paper, Library.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:35:57 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Notebook', prob=0.484375, logit=19.75, token_id=69755, metadata=None))[\" Notebook\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:35:57 src.selection.data DEBUG    Options: Motorcycle, Nightstand, Folder, Paperclip, Charm, Yacht, Clarinet.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:35:57 src.selection.data DEBUG    Options: Tape, Tractor, Scooter, Watch, Calculator, Recliner, Piano.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:35:57 src.selection.data DEBUG    Options: Tape, Tractor, Scooter, Watch, Calculator, Recliner, Piano.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:35:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tape', prob=0.625, logit=19.75, token_id=58586, metadata=None))[\" Tape\"] != 37128[\" Calculator\"]\n",
      "2025-09-15 00:35:58 src.selection.data DEBUG    Options: Stapler, Broccoli, Truck, Bangle, Phone, Car, Highlighter.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 00:35:58 src.selection.data DEBUG    Options: Binder, Submarine, Bike, Pencil, Router, Anklet, Carrot.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "2025-09-15 00:35:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Car', prob=0.39453125, logit=19.625, token_id=3341, metadata=None))[\" Car\"] != 38930[\" Bike\"]\n",
      "2025-09-15 00:35:58 src.selection.data DEBUG    Options: Notebook, Van, Bamboo, Accordion, Ambulance, Bear, Eraser.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:35:58 src.selection.data DEBUG    Options: Calculator, Boat, Truck, Spruce, Zebra, Pencil, Guitar.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:35:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boat', prob=0.349609375, logit=19.625, token_id=45332, metadata=None))[\" Boat\"] != 34785[\" Truck\"]\n",
      "2025-09-15 00:35:58 src.selection.data DEBUG    Options: Lion, Eraser, Hat, Calculator, Helicopter, Cucumber, Airplane.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:35:58 src.selection.data DEBUG    Options: Van, Skirt, Stapler, Onion, Paper, Scooter, Bear.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:35:59 src.selection.data DEBUG    Options: Van, Skirt, Stapler, Onion, Paper, Scooter, Bear.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:35:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.734375, logit=21.0, token_id=63606, metadata=None))[\" Stap\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:35:59 src.selection.data DEBUG    Options: Calculator, Van, Headphones, Bear, Bike, Museum, Scissors.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:35:59 src.selection.data DEBUG    Options: Horse, Speaker, Stapler, Eraser, Theater, Truck, Airplane.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:35:59 src.selection.data DEBUG    Options: Horse, Speaker, Stapler, Eraser, Theater, Truck, Airplane.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:35:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.46875, logit=19.5, token_id=63606, metadata=None))[\" Stap\"] != 9939[\" Er\"]\n",
      "2025-09-15 00:35:59 src.selection.data DEBUG    Options: Raspberry, Clarinet, Marker, Binder, Motorcycle, Golf ball, Bike.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:35:59 src.selection.data DEBUG    Options: Highlighter, Apple, Yoga mat, Train, Paper, Cello, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:36:00 src.selection.data DEBUG    Options: Highlighter, Apple, Yoga mat, Train, Paper, Cello, Ambulance.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 380 / 512\n",
      "2025-09-15 00:36:03 src.selection.data DEBUG    Options: Sofa, Shampoo, Dresser, Towel, Dog, Magnolia.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tow\n",
      "2025-09-15 00:36:03 src.selection.data DEBUG    Options: Lotion, Cow, Razor, Chair, Wardrobe, Redwood.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "2025-09-15 00:36:03 src.selection.data DEBUG    Options: Lotion, Cow, Razor, Chair, Wardrobe, Redwood.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "sample 381 / 512\n",
      "2025-09-15 00:36:07 src.selection.data DEBUG    Options: Cherry, Kiwi, Hospital, Tennis ball, Pants, Baseball.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:36:07 src.selection.data DEBUG    Options: Orange, Skis, Peach, Library, Skateboard, Shorts.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:36:07 src.selection.data DEBUG    Options: Orange, Skis, Peach, Library, Skateboard, Shorts.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "sample 382 / 512\n",
      "2025-09-15 00:36:11 src.selection.data DEBUG    Options: Library, Accordion, Necklace, Pin, Submarine, Ambulance.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pin\n",
      "2025-09-15 00:36:11 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Necklace', prob=0.392578125, logit=19.5, token_id=86460, metadata=None))[\" Pin\"] != 17929[\" Pin\"]\n",
      "2025-09-15 00:36:11 src.selection.data DEBUG    Options: Watch, Yacht, Chair, Ring, Factory, Car.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "2025-09-15 00:36:11 src.selection.data DEBUG    Options: Necklace, Mall, Scooter, Sofa, Locket, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:36:11 src.selection.data DEBUG    Options: Necklace, Mall, Scooter, Sofa, Locket, Ambulance.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "sample 383 / 512\n",
      "2025-09-15 00:36:15 src.selection.data DEBUG    Options: Bike, Pepper, Yacht, Tomato.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:36:15 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pepper', prob=0.44140625, logit=19.125, token_id=52882, metadata=None))[\" Pepper\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:36:15 src.selection.data DEBUG    Options: Tractor, Car, Carrot, Lettuce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:36:15 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Car', prob=0.408203125, logit=19.125, token_id=3341, metadata=None))[\" Car\"] != 6914[\" Let\"]\n",
      "2025-09-15 00:36:15 src.selection.data DEBUG    Options: Boat, Cucumber, Lettuce, Motorcycle.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:36:15 src.selection.data DEBUG    Options: Tomato, Onion, Car, Submarine.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "2025-09-15 00:36:16 src.selection.data DEBUG    Options: Tomato, Onion, Car, Submarine.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "sample 384 / 512\n",
      "2025-09-15 00:36:19 src.selection.data DEBUG    Options: Food processor, Iris, Peony, Helicopter, Motorcycle.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:36:19 src.selection.data DEBUG    Options: Rose, Truck, Airplane, Carnation, Toaster.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "2025-09-15 00:36:20 src.selection.data DEBUG    Options: Rose, Truck, Airplane, Carnation, Toaster.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "sample 385 / 512\n",
      "2025-09-15 00:36:23 src.selection.data DEBUG    Options: Paper, Onion, Scissors, Tomato, Tractor.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:36:24 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Onion', prob=0.259765625, logit=18.375, token_id=87035, metadata=None))[\" There\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:36:24 src.selection.data DEBUG    Options: Pen, Paper, Onion, Mushroom, Jacket.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:36:24 src.selection.data DEBUG    Options: Eraser, Celery, Scissors, Scarf, Carrot.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:36:24 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Er', prob=0.455078125, logit=19.5, token_id=9939, metadata=None))[\" Er\"] != 2522[\" Sc\"]\n",
      "2025-09-15 00:36:24 src.selection.data DEBUG    Options: Marker, Banana, Paperclip, Tomato, Spinach.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Spin\n",
      "2025-09-15 00:36:24 src.selection.data DEBUG    Options: Broccoli, Pen, Eraser, Cauliflower, Raspberry.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:36:24 src.selection.data DEBUG    Options: Broccoli, Pen, Eraser, Cauliflower, Raspberry.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "sample 386 / 512\n",
      "2025-09-15 00:36:28 src.selection.data DEBUG    Options: Sheep, Hospital, Tomato, Hickory, Bear, Carrot.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "2025-09-15 00:36:28 src.selection.data DEBUG    Options: Broccoli, House, Elephant, Lion, Maple, Zucchini.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:36:28 src.selection.data DEBUG    Options: Broccoli, House, Elephant, Lion, Maple, Zucchini.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "sample 387 / 512\n",
      "2025-09-15 00:36:32 src.selection.data DEBUG    Options: Drum, Trumpet, Birch, Elm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "2025-09-15 00:36:32 src.selection.data DEBUG    Options: Trombone, Flute, Spruce, Ash.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:36:32 src.selection.data DEBUG    Options: Trombone, Flute, Spruce, Ash.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "sample 388 / 512\n",
      "2025-09-15 00:36:36 src.selection.data DEBUG    Options: Elephant, Sink, Toothbrush, Bear.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:36:36 src.selection.data DEBUG    Options: Cow, Comb, Shampoo, Dog.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Dog\n",
      "2025-09-15 00:36:36 src.selection.data DEBUG    Options: Cow, Comb, Shampoo, Dog.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "sample 389 / 512\n",
      "2025-09-15 00:36:40 src.selection.data DEBUG    Options: Suit, Toothbrush, Brooch, Flute, Violet, Shower, Peony.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:36:40 src.selection.data DEBUG    Options: Shampoo, Gloves, Lavender, Earring, Sink, Saxophone, Daisy.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:36:40 src.selection.data DEBUG    Options: Shampoo, Gloves, Lavender, Earring, Sink, Saxophone, Daisy.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "sample 390 / 512\n",
      "2025-09-15 00:36:44 src.selection.data DEBUG    Options: House, Spruce, Football, Palm, Mouse, Smartwatch, Drum.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "2025-09-15 00:36:44 src.selection.data DEBUG    Options: Speaker, Ukulele, Skis, Phone, Elm, Church, Pine.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:36:44 src.selection.data DEBUG    Options: Speaker, Ukulele, Skis, Phone, Elm, Church, Pine.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "sample 391 / 512\n",
      "2025-09-15 00:36:48 src.selection.data DEBUG    Options: House, Mosque, Asparagus, Yoga mat, Kiwi, Skateboard.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "2025-09-15 00:36:48 src.selection.data DEBUG    Options: Golf ball, Mango, Basketball, Carrot, Church, Apartment.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Basketball\n",
      "2025-09-15 00:36:48 src.selection.data DEBUG    Options: Golf ball, Mango, Basketball, Carrot, Church, Apartment.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "2025-09-15 00:36:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Church', prob=0.625, logit=20.875, token_id=9441, metadata=None))[\" Church\"] != 53889[\" Apartment\"]\n",
      "2025-09-15 00:36:48 src.selection.data DEBUG    Options: Hospital, School, Skateboard, Recliner, Golf ball, Anklet.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "2025-09-15 00:36:48 src.selection.data DEBUG    Options: Skis, House, Desk, Earring, Stadium, Surfboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:36:48 src.selection.data DEBUG    Options: Skis, House, Desk, Earring, Stadium, Surfboard.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Stadium\n",
      "2025-09-15 00:36:49 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' House', prob=0.4765625, logit=18.875, token_id=4783, metadata=None))[\" House\"] != 23462[\" Stadium\"]\n",
      "2025-09-15 00:36:49 src.selection.data DEBUG    Options: Skis, Apartment, Scooter, Bench, Dumbbell, Library.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "2025-09-15 00:36:49 src.selection.data DEBUG    Options: Helicopter, Helmet, Wardrobe, School, Museum, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:36:49 src.selection.data DEBUG    Options: Helicopter, Helmet, Wardrobe, School, Museum, Baseball.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Museum\n",
      "sample 392 / 512\n",
      "2025-09-15 00:36:53 src.selection.data DEBUG    Options: Razor, Cherry, Tennis ball, Watch, Dumbbell, Hairdryer.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Hair\n",
      "2025-09-15 00:36:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Razor', prob=0.41015625, logit=19.0, token_id=74968, metadata=None))[\" Razor\"] != 26781[\" Hair\"]\n",
      "2025-09-15 00:36:53 src.selection.data DEBUG    Options: Bus, Toothbrush, Racket, Toilet, Yoga mat, Cherry.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:36:53 src.selection.data DEBUG    Options: Hairdryer, Bat, Baseball, Helicopter, Mirror, Blueberry.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:36:54 src.selection.data DEBUG    Options: Hairdryer, Bat, Baseball, Helicopter, Mirror, Blueberry.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Mirror\n",
      "2025-09-15 00:36:54 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Hair', prob=0.427734375, logit=19.75, token_id=26781, metadata=None))[\" Hair\"] != 34954[\" Mirror\"]\n",
      "2025-09-15 00:36:54 src.selection.data DEBUG    Options: Toilet, Shampoo, Phone, Boxing gloves, Football, Mall.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "2025-09-15 00:36:54 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Toilet', prob=0.5546875, logit=19.25, token_id=82994, metadata=None))[\" Toilet\"] != 1443[\" Sh\"]\n",
      "2025-09-15 00:36:54 src.selection.data DEBUG    Options: Surfboard, Hairdryer, Van, Toilet paper, Hat, Football.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:36:54 src.selection.data DEBUG    Options: Sink, Baseball, Hockey stick, Bike, Tie, Razor.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "2025-09-15 00:36:55 src.selection.data DEBUG    Options: Sink, Baseball, Hockey stick, Bike, Tie, Razor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "sample 393 / 512\n",
      "2025-09-15 00:36:58 src.selection.data DEBUG    Options: Monkey, Calculator, Mall, Cat, Socks, Shirt.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cat\n",
      "2025-09-15 00:36:58 src.selection.data DEBUG    Options: Sheep, Lion, Jacket, Stadium, Sweater, Highlighter.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:36:59 src.selection.data DEBUG    Options: Sheep, Lion, Jacket, Stadium, Sweater, Highlighter.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "sample 394 / 512\n",
      "2025-09-15 00:37:02 src.selection.data DEBUG    Options: Toothpaste, Chrysanthemum, Iris, Shampoo.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "2025-09-15 00:37:02 src.selection.data DEBUG    Options: Lily, Towel, Toothbrush, Daisy.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:37:02 src.selection.data DEBUG    Options: Lily, Towel, Toothbrush, Daisy.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "sample 395 / 512\n",
      "2025-09-15 00:37:06 src.selection.data DEBUG    Options: Mouse, Watermelon, Apple, Sofa, Table, Piano.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Table\n",
      "2025-09-15 00:37:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Piano', prob=0.376953125, logit=19.25, token_id=56491, metadata=None))[\" Piano\"] != 6771[\" Table\"]\n",
      "2025-09-15 00:37:06 src.selection.data DEBUG    Options: Blueberry, Toilet paper, Mango, Bed, Shorts, Chair.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Chair\n",
      "2025-09-15 00:37:06 src.selection.data DEBUG    Options: Table, Watermelon, Ottoman, Kiwi, Tie, Bathtub.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:37:07 src.selection.data DEBUG    Options: Table, Watermelon, Ottoman, Kiwi, Tie, Bathtub.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "sample 396 / 512\n",
      "2025-09-15 00:37:10 src.selection.data DEBUG    Options: Eagle, Projector, Sheep, Phone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:37:10 src.selection.data DEBUG    Options: Router, Monitor, Elephant, Monkey.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "2025-09-15 00:37:11 src.selection.data DEBUG    Options: Router, Monitor, Elephant, Monkey.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "sample 397 / 512\n",
      "2025-09-15 00:37:14 src.selection.data DEBUG    Options: Broccoli, Rose, Bat, Blueberry, Basketball, Smartwatch, Watermelon.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:37:14 src.selection.data DEBUG    Options: Pear, Carnation, Hockey stick, Surfboard, Peach, Potato, Tablet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:37:15 src.selection.data DEBUG    Options: Pear, Carnation, Hockey stick, Surfboard, Peach, Potato, Tablet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "sample 398 / 512\n",
      "2025-09-15 00:37:18 src.selection.data DEBUG    Options: Zebra, Monkey, Shampoo, Mirror.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "2025-09-15 00:37:19 src.selection.data DEBUG    Options: Hairdryer, Shower, Dolphin, Sheep.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:37:19 src.selection.data DEBUG    Options: Hairdryer, Shower, Dolphin, Sheep.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "sample 399 / 512\n",
      "2025-09-15 00:37:22 src.selection.data DEBUG    Options: Apartment, Skirt, Marigold, Daisy, Recliner, Dolphin, Sweater.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:37:23 src.selection.data DEBUG    Options: Suit, Temple, Bookshelf, Pants, Orchid, Bear, Jasmine.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:37:23 src.selection.data DEBUG    Options: Suit, Temple, Bookshelf, Pants, Orchid, Bear, Jasmine.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Jasmine\n",
      "sample 400 / 512\n",
      "2025-09-15 00:37:26 src.selection.data DEBUG    Options: Binder, Ring, Cherry, Cufflink, Kiwi.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:37:27 src.selection.data DEBUG    Options: Paperclip, Grape, Bangle, Watermelon, Tiara.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "2025-09-15 00:37:27 src.selection.data DEBUG    Options: Paperclip, Grape, Bangle, Watermelon, Tiara.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "sample 401 / 512\n",
      "2025-09-15 00:37:30 src.selection.data DEBUG    Options: Truck, Bed, Bench, Chain, Jasmine, Brooch.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:37:31 src.selection.data DEBUG    Options: Airplane, Coffee table, Earring, Charm, Dresser, Lily.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:37:31 src.selection.data DEBUG    Options: Airplane, Coffee table, Earring, Charm, Dresser, Lily.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:37:31 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' E', prob=0.3984375, logit=19.125, token_id=469, metadata=None))[\" E\"] != 58600[\" Charm\"]\n",
      "2025-09-15 00:37:31 src.selection.data DEBUG    Options: Anklet, Cabinet, Pendant, Yacht, Bookshelf, Palm.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 00:37:31 src.selection.data DEBUG    Options: Necklace, Tiara, Bamboo, Helicopter, Bench, Stool.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:37:31 src.selection.data DEBUG    Options: Necklace, Tiara, Bamboo, Helicopter, Bench, Stool.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:37:32 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Necklace', prob=0.64453125, logit=20.0, token_id=86460, metadata=None))[\" Necklace\"] != 23126[\" Ti\"]\n",
      "2025-09-15 00:37:32 src.selection.data DEBUG    Options: Charm, Towel, Ring, Sofa, Coffee table, Palm.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "2025-09-15 00:37:32 src.selection.data DEBUG    Options: Cufflink, Locket, Maple, Toilet paper, Cabinet, Nightstand.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "2025-09-15 00:37:32 src.selection.data DEBUG    Options: Cufflink, Locket, Maple, Toilet paper, Cabinet, Nightstand.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "sample 402 / 512\n",
      "2025-09-15 00:37:36 src.selection.data DEBUG    Options: Pendant, Tiara, Tablet, Suit, Sweater.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Swe\n",
      "2025-09-15 00:37:36 src.selection.data DEBUG    Options: Shirt, Television, Skirt, Necklace, Chain.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:37:36 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Necklace', prob=0.71875, logit=21.0, token_id=86460, metadata=None))[\" Necklace\"] != 29625[\" Chain\"]\n",
      "2025-09-15 00:37:36 src.selection.data DEBUG    Options: Tiara, Suit, Gloves, Cedar, Cufflink.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:37:36 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' C', prob=0.73828125, logit=19.375, token_id=356, metadata=None))[\" C\"] != 68554[\" Gloves\"]\n",
      "2025-09-15 00:37:36 src.selection.data DEBUG    Options: Necklace, Hat, Cufflink, Hickory, Suit.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:37:36 src.selection.data DEBUG    Options: Pendant, Charm, Shirt, Coat, Oak.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:37:37 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pendant', prob=0.38671875, logit=17.875, token_id=81501, metadata=None))[\" Pendant\"] != 58600[\" Charm\"]\n",
      "2025-09-15 00:37:37 src.selection.data DEBUG    Options: Necklace, Jacket, Tiara, Toothbrush, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:37:37 src.selection.data DEBUG    Options: Earring, Pants, Bangle, Coat, Soap.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:37:37 src.selection.data DEBUG    Options: Earring, Pants, Bangle, Coat, Soap.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Coat\n",
      "sample 403 / 512\n",
      "2025-09-15 00:37:41 src.selection.data DEBUG    Options: Dolphin, Boxing gloves, Dumbbell, Palm, Harp, Redwood, Lotion.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  D\n",
      "2025-09-15 00:37:41 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Boxing', prob=0.5625, logit=19.875, token_id=72683, metadata=None))[\" Boxing\"] != 423[\" D\"]\n",
      "2025-09-15 00:37:41 src.selection.data DEBUG    Options: Pepper, Skateboard, Cedar, Skyscraper, Pin, Palm, Surfboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:37:41 src.selection.data DEBUG    Options: Golf ball, Earring, Magnolia, Maple, Cucumber, Baseball, Library.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "2025-09-15 00:37:41 src.selection.data DEBUG    Options: Golf ball, Earring, Magnolia, Maple, Cucumber, Baseball, Library.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "sample 404 / 512\n",
      "2025-09-15 00:37:45 src.selection.data DEBUG    Options: Bike, Rose, Tomato, Spinach, Daisy, Comb.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:37:45 src.selection.data DEBUG    Options: Onion, Cucumber, Chrysanthemum, Orchid, Sink, Tractor.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:37:45 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Onion', prob=0.36328125, logit=18.75, token_id=87035, metadata=None))[\" Onion\"] != 356[\" C\"]\n",
      "2025-09-15 00:37:45 src.selection.data DEBUG    Options: Iris, Piano, Football, Onion, Spinach, Tulip.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Tul\n",
      "2025-09-15 00:37:46 src.selection.data DEBUG    Options: Potato, Cucumber, Orchid, Marigold, Violin, Basketball.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:37:46 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Potato', prob=0.55078125, logit=19.5, token_id=78703, metadata=None))[\" Potato\"] != 356[\" C\"]\n",
      "2025-09-15 00:37:46 src.selection.data DEBUG    Options: Tiara, Cauliflower, Chrysanthemum, Iris, Factory, Cucumber.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:37:46 src.selection.data DEBUG    Options: Lily, Carnation, Bracelet, Mushroom, Museum, Spinach.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Spin\n",
      "2025-09-15 00:37:46 src.selection.data DEBUG    Options: Lily, Carnation, Bracelet, Mushroom, Museum, Spinach.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "sample 405 / 512\n",
      "2025-09-15 00:37:50 src.selection.data DEBUG    Options: Nightstand, Watermelon, Mouse, Projector, Watch, Pineapple.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "2025-09-15 00:37:50 src.selection.data DEBUG    Options: Earring, Peach, Orange, Smartwatch, Laptop, Desk.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "2025-09-15 00:37:50 src.selection.data DEBUG    Options: Earring, Peach, Orange, Smartwatch, Laptop, Desk.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "sample 406 / 512\n",
      "2025-09-15 00:37:54 src.selection.data DEBUG    Options: Banana, Notebook, Grape, Highlighter.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Grape\n",
      "2025-09-15 00:37:54 src.selection.data DEBUG    Options: Watermelon, Marker, Blueberry, Eraser.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:37:55 src.selection.data DEBUG    Options: Watermelon, Marker, Blueberry, Eraser.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "sample 407 / 512\n",
      "2025-09-15 00:37:58 src.selection.data DEBUG    Options: Skateboard, Saxophone, Necklace, Highlighter, Binder, Wardrobe, Stool.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Binder\n",
      "2025-09-15 00:37:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Highlight', prob=0.404296875, logit=19.625, token_id=57094, metadata=None))[\" Highlight\"] != 91263[\" Binder\"]\n",
      "2025-09-15 00:37:59 src.selection.data DEBUG    Options: Coffee table, Highlighter, Eraser, Cabinet, Clarinet, Razor, Blueberry.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:37:59 src.selection.data DEBUG    Options: Bookshelf, Tape, Piano, Pineapple, Sink, Ottoman, Paper.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "2025-09-15 00:37:59 src.selection.data DEBUG    Options: Bookshelf, Tape, Piano, Pineapple, Sink, Ottoman, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 408 / 512\n",
      "2025-09-15 00:38:03 src.selection.data DEBUG    Options: Lily, Socks, Museum, Trumpet, Sweater, Golf ball, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:38:03 src.selection.data DEBUG    Options: Dress, Cello, Tie, Peony, Guitar, Racket, Mall.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Tie\n",
      "2025-09-15 00:38:03 src.selection.data DEBUG    Options: Dress, Cello, Tie, Peony, Guitar, Racket, Mall.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "sample 409 / 512\n",
      "2025-09-15 00:38:07 src.selection.data DEBUG    Options: Rose, Helicopter, Toothpaste, Tulip, Airplane.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:38:07 src.selection.data DEBUG    Options: Lavender, Tractor, Scooter, Sunflower, Shower.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Sun\n",
      "2025-09-15 00:38:07 src.selection.data DEBUG    Options: Lavender, Tractor, Scooter, Sunflower, Shower.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "sample 410 / 512\n",
      "2025-09-15 00:38:11 src.selection.data DEBUG    Options: Saxophone, Projector, Ukulele, Keyboard.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:38:11 src.selection.data DEBUG    Options: Clarinet, Harp, Headphones, Printer.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "2025-09-15 00:38:11 src.selection.data DEBUG    Options: Clarinet, Harp, Headphones, Printer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "sample 411 / 512\n",
      "2025-09-15 00:38:15 src.selection.data DEBUG    Options: Bike, Banana, Pin, Cherry, Brooch, Desk.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:38:15 src.selection.data DEBUG    Options: Kiwi, Bangle, Peach, Anklet, Tractor, Stool.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "2025-09-15 00:38:15 src.selection.data DEBUG    Options: Kiwi, Bangle, Peach, Anklet, Tractor, Stool.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "sample 412 / 512\n",
      "2025-09-15 00:38:19 src.selection.data DEBUG    Options: Jacket, Socks, Submarine, Van.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "2025-09-15 00:38:19 src.selection.data DEBUG    Options: Ambulance, Shorts, Boat, Jeans.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Boat\n",
      "2025-09-15 00:38:19 src.selection.data DEBUG    Options: Ambulance, Shorts, Boat, Jeans.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "sample 413 / 512\n",
      "2025-09-15 00:38:23 src.selection.data DEBUG    Options: Binder, Magnolia, Coat, Strawberry, Notebook, Helicopter, Van.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "2025-09-15 00:38:23 src.selection.data DEBUG    Options: Paper, Truck, Redwood, Skirt, Calculator, Airplane, Kiwi.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:38:23 src.selection.data DEBUG    Options: Paper, Truck, Redwood, Skirt, Calculator, Airplane, Kiwi.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "sample 414 / 512\n",
      "2025-09-15 00:38:27 src.selection.data DEBUG    Options: Boat, Projector, Train, Headphones.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "2025-09-15 00:38:27 src.selection.data DEBUG    Options: Helicopter, Submarine, Television, Monitor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:38:28 src.selection.data DEBUG    Options: Helicopter, Submarine, Television, Monitor.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "sample 415 / 512\n",
      "2025-09-15 00:38:31 src.selection.data DEBUG    Options: Zucchini, Jacket, Kiwi, Asparagus, Orange.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:38:31 src.selection.data DEBUG    Options: Suit, Grape, Mango, Broccoli, Pepper.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Mango\n",
      "2025-09-15 00:38:32 src.selection.data DEBUG    Options: Suit, Grape, Mango, Broccoli, Pepper.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Pepper\n",
      "sample 416 / 512\n",
      "2025-09-15 00:38:35 src.selection.data DEBUG    Options: Router, Horse, Laptop, Suit, Lettuce, Cauliflower.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Laptop\n",
      "2025-09-15 00:38:36 src.selection.data DEBUG    Options: Camera, Dog, Spinach, Tablet, Tie, Carrot.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:38:36 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Spin', prob=0.52734375, logit=21.0, token_id=41785, metadata=None))[\" Spin\"] != 3341[\" Car\"]\n",
      "2025-09-15 00:38:36 src.selection.data DEBUG    Options: Pen, Carrot, Football, Headphones, Celery, Phone.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:38:36 src.selection.data DEBUG    Options: Television, Laptop, Cauliflower, Marker, Tomato, Basketball.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:38:36 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Caul', prob=0.76171875, logit=21.0, token_id=90538, metadata=None))[\" Caul\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:38:36 src.selection.data DEBUG    Options: Spinach, Gloves, Highlighter, Celery, Smartwatch, Printer.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Printer\n",
      "2025-09-15 00:38:37 src.selection.data DEBUG    Options: Scissors, Potato, Laptop, Router, Skirt, Carrot.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:38:37 src.selection.data DEBUG    Options: Scissors, Potato, Laptop, Router, Skirt, Carrot.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "sample 417 / 512\n",
      "2025-09-15 00:38:41 src.selection.data DEBUG    Options: Blender, Jeans, Juicer, Skirt.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Sk\n",
      "2025-09-15 00:38:41 src.selection.data DEBUG    Options: Suit, Oven, Refrigerator, Gloves.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "2025-09-15 00:38:41 src.selection.data DEBUG    Options: Suit, Oven, Refrigerator, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "sample 418 / 512\n",
      "2025-09-15 00:38:45 src.selection.data DEBUG    Options: Sunflower, Marker, Brooch, Theater, House, Pin.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  House\n",
      "2025-09-15 00:38:45 src.selection.data DEBUG    Options: Lily, Chain, Scissors, Warehouse, Charm, Library.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "2025-09-15 00:38:45 src.selection.data DEBUG    Options: Lily, Chain, Scissors, Warehouse, Charm, Library.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Library\n",
      "sample 419 / 512\n",
      "2025-09-15 00:38:49 src.selection.data DEBUG    Options: Locket, Ukulele, Surfboard, Lotion, Chrysanthemum, Chain, Jasmine.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Chain\n",
      "2025-09-15 00:38:49 src.selection.data DEBUG    Options: Pin, Rose, Flute, Cufflink, Basketball, Iris, Toilet.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:38:49 src.selection.data DEBUG    Options: Pin, Rose, Flute, Cufflink, Basketball, Iris, Toilet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "sample 420 / 512\n",
      "2025-09-15 00:38:53 src.selection.data DEBUG    Options: Ukulele, Scissors, Palm, Mouse, Maple, Eraser, Iris.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "2025-09-15 00:38:53 src.selection.data DEBUG    Options: Pencil, Magnolia, Hickory, Flute, Pen, Sunflower, Smartwatch.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:38:54 src.selection.data DEBUG    Options: Pencil, Magnolia, Hickory, Flute, Pen, Sunflower, Smartwatch.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "sample 421 / 512\n",
      "2025-09-15 00:38:57 src.selection.data DEBUG    Options: Desk, Baseball, Sofa, Surfboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:38:58 src.selection.data DEBUG    Options: Recliner, Nightstand, Dumbbell, Helmet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "2025-09-15 00:38:58 src.selection.data DEBUG    Options: Recliner, Nightstand, Dumbbell, Helmet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "sample 422 / 512\n",
      "2025-09-15 00:39:02 src.selection.data DEBUG    Options: Redwood, Dress, Potato, Pine, Cat, Soap, Asparagus.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:39:02 src.selection.data DEBUG    Options: Cucumber, Birch, Comb, Jacket, Zucchini, Sheep, Hickory.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "2025-09-15 00:39:02 src.selection.data DEBUG    Options: Cucumber, Birch, Comb, Jacket, Zucchini, Sheep, Hickory.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "sample 423 / 512\n",
      "2025-09-15 00:39:06 src.selection.data DEBUG    Options: Piano, Paper, Bear, Mouse, Clarinet, Zebra, Lily.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:39:06 src.selection.data DEBUG    Options: Eraser, Drum, Sheep, Cello, Carnation, Monitor, Tiger.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:39:06 src.selection.data DEBUG    Options: Eraser, Drum, Sheep, Cello, Carnation, Monitor, Tiger.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "sample 424 / 512\n",
      "2025-09-15 00:39:10 src.selection.data DEBUG    Options: Eagle, Golf ball, Basketball, Monkey.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "2025-09-15 00:39:10 src.selection.data DEBUG    Options: Elephant, Boxing gloves, Sheep, Bat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:39:10 src.selection.data DEBUG    Options: Elephant, Boxing gloves, Sheep, Bat.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:39:10 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bat', prob=0.466796875, logit=18.875, token_id=16488, metadata=None))[\" Bat\"] != 84008[\" Sheep\"]\n",
      "2025-09-15 00:39:10 src.selection.data DEBUG    Options: Rabbit, Helmet, Baseball, Sheep.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:39:11 src.selection.data DEBUG    Options: Skis, Monkey, Skateboard, Tiger.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:39:11 src.selection.data DEBUG    Options: Skis, Monkey, Skateboard, Tiger.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "sample 425 / 512\n",
      "2025-09-15 00:39:15 src.selection.data DEBUG    Options: Bamboo, Toaster, Pineapple, Strawberry, Air fryer.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:39:15 src.selection.data DEBUG    Options: Watermelon, Elm, Pear, Blender, Food processor.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:39:15 src.selection.data DEBUG    Options: Watermelon, Elm, Pear, Blender, Food processor.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Pear\n",
      "sample 426 / 512\n",
      "2025-09-15 00:39:19 src.selection.data DEBUG    Options: Temple, Dress, Yacht, Submarine, Spinach, Tomato, Ash.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "2025-09-15 00:39:19 src.selection.data DEBUG    Options: Truck, Mosque, Mushroom, Onion, Pine, Coat, Ambulance.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "2025-09-15 00:39:19 src.selection.data DEBUG    Options: Truck, Mosque, Mushroom, Onion, Pine, Coat, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "sample 427 / 512\n",
      "2025-09-15 00:39:23 src.selection.data DEBUG    Options: Pressure cooker, Ring, Towel, Oven, Pin.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Oven\n",
      "2025-09-15 00:39:23 src.selection.data DEBUG    Options: Brooch, Toothbrush, Kettle, Watch, Dishwasher.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:39:23 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bro', prob=0.68359375, logit=20.25, token_id=6031, metadata=None))[\" Bro\"] != 10573[\" Watch\"]\n",
      "2025-09-15 00:39:23 src.selection.data DEBUG    Options: Bangle, Van, Tiara, Juicer, Mixer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-15 00:39:24 src.selection.data DEBUG    Options: Necklace, Ring, Coffee maker, Pressure cooker, Bike.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ring\n",
      "2025-09-15 00:39:24 src.selection.data DEBUG    Options: Necklace, Ring, Coffee maker, Pressure cooker, Bike.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Pressure\n",
      "sample 428 / 512\n",
      "2025-09-15 00:39:27 src.selection.data DEBUG    Options: Boat, Drum, Hockey stick, Chain, Refrigerator, Baseball, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:39:27 src.selection.data DEBUG    Options: Flute, Blender, Tennis ball, Scooter, Piano, Charm, Racket.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:39:28 src.selection.data DEBUG    Options: Flute, Blender, Tennis ball, Scooter, Piano, Charm, Racket.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Piano\n",
      "sample 429 / 512\n",
      "2025-09-15 00:39:31 src.selection.data DEBUG    Options: Dress, Watermelon, Toaster, Food processor, Broccoli, Oak, Cauliflower.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "2025-09-15 00:39:31 src.selection.data DEBUG    Options: Potato, Rice cooker, Pine, Socks, Blender, Cucumber, Grape.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:39:32 src.selection.data DEBUG    Options: Potato, Rice cooker, Pine, Socks, Blender, Cucumber, Grape.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "sample 430 / 512\n",
      "2025-09-15 00:39:35 src.selection.data DEBUG    Options: Cufflink, Dress, Harmonica, Trumpet, Pin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trump\n",
      "2025-09-15 00:39:35 src.selection.data DEBUG    Options: Clarinet, Necklace, Cello, Tie, Locket.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  L\n",
      "2025-09-15 00:39:36 src.selection.data DEBUG    Options: Clarinet, Necklace, Cello, Tie, Locket.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  C\n",
      "sample 431 / 512\n",
      "2025-09-15 00:39:39 src.selection.data DEBUG    Options: Mosque, Yoga mat, Racket, Theater, Charm.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:39:40 src.selection.data DEBUG    Options: School, Golf ball, Hospital, Cufflink, Football.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "2025-09-15 00:39:40 src.selection.data DEBUG    Options: School, Golf ball, Hospital, Cufflink, Football.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "sample 432 / 512\n",
      "2025-09-15 00:39:44 src.selection.data DEBUG    Options: Desk, Kiwi, Skirt, Apple, Pendant, Stadium, Hat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "2025-09-15 00:39:44 src.selection.data DEBUG    Options: Necklace, Banana, Nightstand, Pants, Raspberry, Socks, Mosque.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Raspberry\n",
      "2025-09-15 00:39:44 src.selection.data DEBUG    Options: Necklace, Banana, Nightstand, Pants, Raspberry, Socks, Mosque.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "sample 433 / 512\n",
      "2025-09-15 00:39:48 src.selection.data DEBUG    Options: Skis, Rose, Sheep, Jasmine, Helmet, Socks.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Helmet\n",
      "2025-09-15 00:39:48 src.selection.data DEBUG    Options: Surfboard, Tie, Bear, Boxing gloves, Violet, Carnation.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Carn\n",
      "2025-09-15 00:39:48 src.selection.data DEBUG    Options: Surfboard, Tie, Bear, Boxing gloves, Violet, Carnation.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Boxing\n",
      "sample 434 / 512\n",
      "2025-09-15 00:39:52 src.selection.data DEBUG    Options: Eagle, Cello, Ukulele, Lion.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:39:52 src.selection.data DEBUG    Options: Piano, Bear, Rabbit, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:39:52 src.selection.data DEBUG    Options: Piano, Bear, Rabbit, Violin.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Rabbit\n",
      "sample 435 / 512\n",
      "2025-09-15 00:39:56 src.selection.data DEBUG    Options: Truck, School, Mosque, Baseball, Pin, Golf ball.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "2025-09-15 00:39:56 src.selection.data DEBUG    Options: Museum, Hospital, Charm, Bat, Submarine, Skateboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:39:56 src.selection.data DEBUG    Options: Museum, Hospital, Charm, Bat, Submarine, Skateboard.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "sample 436 / 512\n",
      "2025-09-15 00:40:00 src.selection.data DEBUG    Options: Charm, Pendant, Sink, Willow, Cello, Oak, Food processor.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Oak\n",
      "2025-09-15 00:40:00 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Willow', prob=0.609375, logit=19.875, token_id=65449, metadata=None))[\" Willow\"] != 18787[\" Oak\"]\n",
      "2025-09-15 00:40:00 src.selection.data DEBUG    Options: Cauliflower, Earring, Pendant, Elephant, Shirt, Elm, Eucalyptus.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:40:00 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Elm', prob=0.4375, logit=20.25, token_id=65329, metadata=None))[\" Elm\"] != 469[\" E\"]\n",
      "2025-09-15 00:40:00 src.selection.data DEBUG    Options: Laptop, Desk, Pine, Church, Spruce, Locket, Bracelet.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:40:01 src.selection.data DEBUG    Options: Watch, Cedar, Willow, Tablet, Bangle, Library, Dresser.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  B\n",
      "2025-09-15 00:40:01 src.selection.data DEBUG    Options: Watch, Cedar, Willow, Tablet, Bangle, Library, Dresser.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "sample 437 / 512\n",
      "2025-09-15 00:40:05 src.selection.data DEBUG    Options: Guitar, Temple, Locket, Truck, Peach, Bus, Anklet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "2025-09-15 00:40:05 src.selection.data DEBUG    Options: Ukulele, Yacht, Charm, Tiara, Warehouse, Kiwi, Submarine.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "2025-09-15 00:40:05 src.selection.data DEBUG    Options: Ukulele, Yacht, Charm, Tiara, Warehouse, Kiwi, Submarine.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "sample 438 / 512\n",
      "2025-09-15 00:40:09 src.selection.data DEBUG    Options: Earring, Tablet, Television, Shampoo, Blueberry, Tennis ball, Peach.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Television\n",
      "2025-09-15 00:40:09 src.selection.data DEBUG    Options: Grape, Speaker, Surfboard, Hairdryer, Banana, Headphones, Anklet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n",
      "2025-09-15 00:40:09 src.selection.data DEBUG    Options: Grape, Speaker, Surfboard, Hairdryer, Banana, Headphones, Anklet.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Head\n",
      "sample 439 / 512\n",
      "2025-09-15 00:40:13 src.selection.data DEBUG    Options: Clarinet, Yacht, Piano, Van, Mango.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Piano\n",
      "2025-09-15 00:40:13 src.selection.data DEBUG    Options: Ambulance, Harp, Submarine, Apple, Saxophone.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sub\n",
      "2025-09-15 00:40:13 src.selection.data DEBUG    Options: Ambulance, Harp, Submarine, Apple, Saxophone.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "sample 440 / 512\n",
      "2025-09-15 00:40:17 src.selection.data DEBUG    Options: Dolphin, Food processor, Violet, Giraffe, Xylophone, Toaster, School.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Gir\n",
      "2025-09-15 00:40:17 src.selection.data DEBUG    Options: Bear, Elephant, Pressure cooker, Saxophone, Dishwasher, Skyscraper, Jasmine.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Dish\n",
      "2025-09-15 00:40:17 src.selection.data DEBUG    Options: Bear, Elephant, Pressure cooker, Saxophone, Dishwasher, Skyscraper, Jasmine.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Elephant\n",
      "sample 441 / 512\n",
      "2025-09-15 00:40:21 src.selection.data DEBUG    Options: Coat, Warehouse, Bus, Pressure cooker, Hospital, Clarinet, Coffee maker.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:40:21 src.selection.data DEBUG    Options: Tractor, Temple, Dress, Mixer, Ukulele, Rice cooker, Mall.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:40:21 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Temple', prob=0.53125, logit=19.625, token_id=19176, metadata=None))[\" Temple\"] != 32498[\" Mall\"]\n",
      "2025-09-15 00:40:21 src.selection.data DEBUG    Options: Iris, Rice cooker, Shampoo, Factory, Basketball, Mall, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:40:22 src.selection.data DEBUG    Options: Tulip, Tennis ball, School, Kettle, Toaster, Hospital, Comb.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "2025-09-15 00:40:22 src.selection.data DEBUG    Options: Tulip, Tennis ball, School, Kettle, Toaster, Hospital, Comb.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  To\n",
      "sample 442 / 512\n",
      "2025-09-15 00:40:26 src.selection.data DEBUG    Options: Ash, Hickory, Sweater, Suit.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:40:26 src.selection.data DEBUG    Options: Jacket, Bamboo, Eucalyptus, Hat.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:40:26 src.selection.data DEBUG    Options: Jacket, Bamboo, Eucalyptus, Hat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "sample 443 / 512\n",
      "2025-09-15 00:40:30 src.selection.data DEBUG    Options: Asparagus, Library, Palm, Ash, Mushroom.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:40:30 src.selection.data DEBUG    Options: Skyscraper, Zucchini, Maple, Carrot, Bamboo.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Bamboo\n",
      "2025-09-15 00:40:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Maple', prob=0.71484375, logit=21.0, token_id=44570, metadata=None))[\" Maple\"] != 98028[\" Bamboo\"]\n",
      "2025-09-15 00:40:30 src.selection.data DEBUG    Options: Cucumber, Cufflink, Bamboo, Hickory, Pepper.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Pepper\n",
      "2025-09-15 00:40:30 src.selection.data DEBUG    Options: Birch, Mushroom, Celery, Spruce, Chain.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:40:30 src.selection.data DEBUG    Options: Birch, Mushroom, Celery, Spruce, Chain.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "sample 444 / 512\n",
      "2025-09-15 00:40:34 src.selection.data DEBUG    Options: Pants, Cauliflower, Giraffe, Temple, Rabbit, Suit, Dumbbell.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Suit\n",
      "2025-09-15 00:40:34 src.selection.data DEBUG    Options: Dress, School, Hockey stick, Jeans, Celery, Horse, Zebra.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:40:34 src.selection.data DEBUG    Options: Dress, School, Hockey stick, Jeans, Celery, Horse, Zebra.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "sample 445 / 512\n",
      "2025-09-15 00:40:38 src.selection.data DEBUG    Options: Tulip, Orchid, Tennis ball, Folder, Notebook, Printer.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Orch\n",
      "2025-09-15 00:40:38 src.selection.data DEBUG    Options: Calculator, Lily, Chrysanthemum, Paper, Dumbbell, Smartwatch.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:40:38 src.selection.data DEBUG    Options: Calculator, Lily, Chrysanthemum, Paper, Dumbbell, Smartwatch.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "sample 446 / 512\n",
      "2025-09-15 00:40:42 src.selection.data DEBUG    Options: Library, Bear, Pen, Hospital, Elephant.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Elephant\n",
      "2025-09-15 00:40:42 src.selection.data DEBUG    Options: Factory, Tiger, Marker, Sheep, Warehouse.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:40:42 src.selection.data DEBUG    Options: Factory, Tiger, Marker, Sheep, Warehouse.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "sample 447 / 512\n",
      "2025-09-15 00:40:46 src.selection.data DEBUG    Options: Toaster, Bike, Toothbrush, Truck, Temple, Oven.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Oven\n",
      "2025-09-15 00:40:46 src.selection.data DEBUG    Options: Pressure cooker, Hospital, Blender, Shampoo, Boat, Ambulance.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Amb\n",
      "2025-09-15 00:40:47 src.selection.data ERROR    Prediction mismatch: (2, PredictedToken(token=' Boat', prob=0.341796875, logit=19.25, token_id=45332, metadata=None))[\" Amb\"] != 20423[\" Amb\"]\n",
      "2025-09-15 00:40:47 src.selection.data DEBUG    Options: Highlighter, Pressure cooker, Willow, Train, Submarine, Microwave.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Microwave\n",
      "2025-09-15 00:40:47 src.selection.data DEBUG    Options: Blender, Airplane, Kettle, Scissors, Truck, Elm.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Truck\n",
      "2025-09-15 00:40:47 src.selection.data DEBUG    Options: Blender, Airplane, Kettle, Scissors, Truck, Elm.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  K\n",
      "sample 448 / 512\n",
      "2025-09-15 00:40:51 src.selection.data DEBUG    Options: Hospital, Trombone, Juicer, Birch, Library, Toilet, Toothpaste.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:40:51 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Toilet', prob=0.486328125, logit=19.25, token_id=82994, metadata=None))[\" Toilet\"] != 83499[\" Tooth\"]\n",
      "2025-09-15 00:40:51 src.selection.data DEBUG    Options: Shirt, School, Towel, Stadium, Iris, Toothpaste, Sheep.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:40:51 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tow', prob=0.65234375, logit=20.625, token_id=41493, metadata=None))[\" Tow\"] != 83499[\" Tooth\"]\n",
      "2025-09-15 00:40:51 src.selection.data DEBUG    Options: Sink, Elm, Mall, Violin, Toilet, House, Elephant.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 00:40:51 src.selection.data DEBUG    Options: Willow, Factory, Razor, Horse, Ukulele, School, Toothpaste.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  School\n",
      "2025-09-15 00:40:51 src.selection.data DEBUG    Options: Willow, Factory, Razor, Horse, Ukulele, School, Toothpaste.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "sample 449 / 512\n",
      "2025-09-15 00:40:55 src.selection.data DEBUG    Options: Dolphin, Trumpet, Cow, Violin.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "2025-09-15 00:40:55 src.selection.data DEBUG    Options: Dog, Zebra, Drum, Accordion.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:40:56 src.selection.data DEBUG    Options: Dog, Zebra, Drum, Accordion.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "sample 450 / 512\n",
      "2025-09-15 00:40:59 src.selection.data DEBUG    Options: Marigold, Brooch, Refrigerator, Jeans, Toilet, Pin, Shorts.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shorts\n",
      "2025-09-15 00:40:59 src.selection.data DEBUG    Options: Ring, Tiara, Lotion, Lavender, Pants, Dress, Kettle.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ti\n",
      "2025-09-15 00:41:00 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ring', prob=0.49609375, logit=19.875, token_id=22249, metadata=None))[\" Ring\"] != 23126[\" Ti\"]\n",
      "2025-09-15 00:41:00 src.selection.data DEBUG    Options: Necklace, Tape, Scarf, Gloves, Ring, Slow cooker, Sheep.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:41:00 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ring', prob=0.451171875, logit=18.625, token_id=22249, metadata=None))[\" Ring\"] != 68554[\" Gloves\"]\n",
      "2025-09-15 00:41:00 src.selection.data DEBUG    Options: Bangle, Ring, Jacket, Socks, Trombone, Camera, Blender.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "2025-09-15 00:41:00 src.selection.data DEBUG    Options: Chain, Jeans, Juicer, Tablet, Watch, Violin, Shorts.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Watch\n",
      "2025-09-15 00:41:00 src.selection.data DEBUG    Options: Chain, Jeans, Juicer, Tablet, Watch, Violin, Shorts.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shorts\n",
      "sample 451 / 512\n",
      "2025-09-15 00:41:04 src.selection.data DEBUG    Options: Sweater, Lily, Iris, Jeans.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 00:41:04 src.selection.data DEBUG    Options: Daffodil, Carnation, Dress, Hat.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "2025-09-15 00:41:04 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Dress', prob=0.55078125, logit=19.375, token_id=29318, metadata=None))[\" Dress\"] != 22050[\" Hat\"]\n",
      "2025-09-15 00:41:04 src.selection.data DEBUG    Options: Daffodil, Lily, Scarf, Suit.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Lily\n",
      "2025-09-15 00:41:04 src.selection.data DEBUG    Options: Tie, Rose, Pants, Tulip.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:41:05 src.selection.data DEBUG    Options: Tie, Rose, Pants, Tulip.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Tul\n",
      "sample 452 / 512\n",
      "2025-09-15 00:41:08 src.selection.data DEBUG    Options: Camera, Marker, Smartwatch, Folder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:41:08 src.selection.data DEBUG    Options: Headphones, Highlighter, Calculator, Speaker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 00:41:09 src.selection.data DEBUG    Options: Headphones, Highlighter, Calculator, Speaker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 00:41:09 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Highlight', prob=0.50390625, logit=19.125, token_id=57094, metadata=None))[\" Highlight\"] != 37128[\" Calculator\"]\n",
      "2025-09-15 00:41:09 src.selection.data DEBUG    Options: Paper, Router, Printer, Folder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:41:09 src.selection.data DEBUG    Options: Notebook, Tablet, Scissors, Projector.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "2025-09-15 00:41:09 src.selection.data DEBUG    Options: Notebook, Tablet, Scissors, Projector.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 00:41:09 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Project', prob=0.5, logit=18.375, token_id=5907, metadata=None))[\" Project\"] != 2522[\" Sc\"]\n",
      "2025-09-15 00:41:09 src.selection.data DEBUG    Options: Keyboard, Tape, Mouse, Pen.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:41:09 src.selection.data DEBUG    Options: Binder, Laptop, Camera, Paper.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Camera\n",
      "2025-09-15 00:41:10 src.selection.data DEBUG    Options: Binder, Laptop, Camera, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 453 / 512\n",
      "2025-09-15 00:41:13 src.selection.data DEBUG    Options: Pen, Motorcycle, Warehouse, Accordion, Drum, Yacht.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "2025-09-15 00:41:14 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Motorcycle', prob=0.78125, logit=21.25, token_id=70762, metadata=None))[\" Motorcycle\"] != 816[\" Y\"]\n",
      "2025-09-15 00:41:14 src.selection.data DEBUG    Options: Guitar, Helicopter, Motorcycle, Rose, Router, Piano.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:41:14 src.selection.data DEBUG    Options: Ukulele, Clarinet, Iris, Bike, Van, Smartwatch.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "2025-09-15 00:41:14 src.selection.data DEBUG    Options: Ukulele, Clarinet, Iris, Bike, Van, Smartwatch.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Van\n",
      "sample 454 / 512\n",
      "2025-09-15 00:41:18 src.selection.data DEBUG    Options: Tiara, Cow, Grape, Peony, Car, Blueberry, Cufflink.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "2025-09-15 00:41:18 src.selection.data DEBUG    Options: Bracelet, Pineapple, Watermelon, Carnation, Monkey, Truck, Anklet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "2025-09-15 00:41:18 src.selection.data DEBUG    Options: Bracelet, Pineapple, Watermelon, Carnation, Monkey, Truck, Anklet.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n",
      "sample 455 / 512\n",
      "2025-09-15 00:41:22 src.selection.data DEBUG    Options: Jeans, Kiwi, Cherry, Coat.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Cherry\n",
      "2025-09-15 00:41:22 src.selection.data DEBUG    Options: Grape, Pants, Socks, Apple.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  S\n",
      "2025-09-15 00:41:22 src.selection.data DEBUG    Options: Grape, Pants, Socks, Apple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "sample 456 / 512\n",
      "2025-09-15 00:41:26 src.selection.data DEBUG    Options: Yoga mat, Racket, Pear, Cherry.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 00:41:26 src.selection.data DEBUG    Options: Apple, Surfboard, Banana, Baseball.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n",
      "2025-09-15 00:41:26 src.selection.data DEBUG    Options: Apple, Surfboard, Banana, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "sample 457 / 512\n",
      "2025-09-15 00:41:30 src.selection.data DEBUG    Options: Bike, Helicopter, Socks, Scarf.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:41:30 src.selection.data DEBUG    Options: Yacht, Train, Pants, Dress.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Dress\n",
      "2025-09-15 00:41:31 src.selection.data DEBUG    Options: Yacht, Train, Pants, Dress.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "sample 458 / 512\n",
      "2025-09-15 00:41:34 src.selection.data DEBUG    Options: Calculator, Orchid, Zucchini, Lettuce, Highlighter.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:41:34 src.selection.data DEBUG    Options: Spinach, Onion, Pencil, Jasmine, Eraser.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "2025-09-15 00:41:35 src.selection.data DEBUG    Options: Spinach, Onion, Pencil, Jasmine, Eraser.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "sample 459 / 512\n",
      "2025-09-15 00:41:38 src.selection.data DEBUG    Options: Cufflink, Horse, Orchid, Tiger, Bathtub, Baseball, Sunflower.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Tiger\n",
      "2025-09-15 00:41:39 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bat', prob=0.53515625, logit=19.75, token_id=16488, metadata=None))[\" Bat\"] != 36845[\" Tiger\"]\n",
      "2025-09-15 00:41:39 src.selection.data DEBUG    Options: Chrysanthemum, House, Cat, Golf ball, Horse, Daisy, Pin.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:41:39 src.selection.data DEBUG    Options: Lily, Dolphin, Lion, Brooch, Factory, Jasmine, Surfboard.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Jasmine\n",
      "2025-09-15 00:41:39 src.selection.data DEBUG    Options: Lily, Dolphin, Lion, Brooch, Factory, Jasmine, Surfboard.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "2025-09-15 00:41:39 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Dolphin', prob=0.76953125, logit=20.875, token_id=96096, metadata=None))[\" Dolphin\"] != 33199[\" Lion\"]\n",
      "2025-09-15 00:41:39 src.selection.data DEBUG    Options: Tiger, Bear, Refrigerator, Truck, Peony, Chrysanthemum, Tiara.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Bear\n",
      "2025-09-15 00:41:39 src.selection.data DEBUG    Options: Tulip, Food processor, Anklet, Dog, Violet, Helicopter, Horse.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:41:39 src.selection.data DEBUG    Options: Tulip, Food processor, Anklet, Dog, Violet, Helicopter, Horse.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "sample 460 / 512\n",
      "2025-09-15 00:41:43 src.selection.data DEBUG    Options: Tape, Bench, Pen, Cabinet.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:41:43 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Cabinet', prob=0.6953125, logit=19.0, token_id=34046, metadata=None))[\" Cabinet\"] != 13597[\" Pen\"]\n",
      "2025-09-15 00:41:43 src.selection.data DEBUG    Options: Folder, Ottoman, Bench, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:41:43 src.selection.data DEBUG    Options: Desk, Marker, Nightstand, Paperclip.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Night\n",
      "2025-09-15 00:41:44 src.selection.data DEBUG    Options: Desk, Marker, Nightstand, Paperclip.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 461 / 512\n",
      "2025-09-15 00:41:47 src.selection.data DEBUG    Options: Stool, Phone, Desk, Harmonica, Brooch, Harp, Basketball.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Har\n",
      "2025-09-15 00:41:48 src.selection.data DEBUG    Options: Trombone, Tennis ball, Ottoman, Bangle, Chair, Printer, Clarinet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Chair\n",
      "2025-09-15 00:41:48 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Ottoman', prob=0.5546875, logit=19.375, token_id=70110, metadata=None))[\" Ottoman\"] != 16478[\" Chair\"]\n",
      "2025-09-15 00:41:48 src.selection.data DEBUG    Options: Violet, Violin, Ukulele, Ottoman, Cabinet, Hospital, Folder.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Uk\n",
      "2025-09-15 00:41:48 src.selection.data DEBUG    Options: Church, Wardrobe, Tape, Trumpet, Accordion, Sofa, Chrysanthemum.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Sofa\n",
      "2025-09-15 00:41:48 src.selection.data DEBUG    Options: Church, Wardrobe, Tape, Trumpet, Accordion, Sofa, Chrysanthemum.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "sample 462 / 512\n",
      "2025-09-15 00:41:52 src.selection.data DEBUG    Options: Toothbrush, Hickory, Watch, Willow, Shampoo.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "2025-09-15 00:41:53 src.selection.data DEBUG    Options: Shower, Toothpaste, Spruce, Eucalyptus, Chain.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  E\n",
      "2025-09-15 00:41:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Spr', prob=0.8359375, logit=20.375, token_id=15883, metadata=None))[\" Spr\"] != 469[\" E\"]\n",
      "2025-09-15 00:41:53 src.selection.data DEBUG    Options: Hickory, Ash, Soap, Razor, Cow.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "2025-09-15 00:41:53 src.selection.data DEBUG    Options: Toothbrush, Magnolia, Bathtub, Rabbit, Spruce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "2025-09-15 00:41:54 src.selection.data DEBUG    Options: Toothbrush, Magnolia, Bathtub, Rabbit, Spruce.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Bat\n",
      "sample 463 / 512\n",
      "2025-09-15 00:41:57 src.selection.data DEBUG    Options: Bamboo, Baseball, Hockey stick, Lavender, Temple, Lion, Hospital.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n",
      "2025-09-15 00:41:58 src.selection.data DEBUG    Options: Apartment, Racket, Spruce, Marigold, Stadium, Giraffe, Surfboard.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:41:58 src.selection.data DEBUG    Options: Apartment, Racket, Spruce, Marigold, Stadium, Giraffe, Surfboard.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Stadium\n",
      "2025-09-15 00:41:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Apartment', prob=0.51171875, logit=19.125, token_id=53889, metadata=None))[\" Apartment\"] != 23462[\" Stadium\"]\n",
      "2025-09-15 00:41:58 src.selection.data DEBUG    Options: Surfboard, Skyscraper, Boxing gloves, Redwood, Church, Kettle, Elephant.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:41:58 src.selection.data DEBUG    Options: Yoga mat, Food processor, Maple, Mosque, Tiger, Warehouse, Baseball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Baseball\n",
      "2025-09-15 00:41:58 src.selection.data DEBUG    Options: Yoga mat, Food processor, Maple, Mosque, Tiger, Warehouse, Baseball.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:41:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Mosque', prob=0.4375, logit=19.75, token_id=100031, metadata=None))[\" Mosque\"] != 52466[\" Warehouse\"]\n",
      "2025-09-15 00:41:59 src.selection.data DEBUG    Options: Skyscraper, Surfboard, Raspberry, Dishwasher, Warehouse, Skateboard, Violet.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:41:59 src.selection.data DEBUG    Options: Temple, Air fryer, Chrysanthemum, Watermelon, Golf ball, Church, Yoga mat.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:41:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Golf', prob=0.71484375, logit=20.25, token_id=28131, metadata=None))[\" Golf\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:41:59 src.selection.data DEBUG    Options: Skyscraper, Temple, Socks, Spinach, Tennis ball, Bamboo, Skis.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:41:59 src.selection.data DEBUG    Options: Cauliflower, Bat, Basketball, Ash, Warehouse, Gloves, Mosque.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Basketball\n",
      "2025-09-15 00:41:59 src.selection.data DEBUG    Options: Cauliflower, Bat, Basketball, Ash, Warehouse, Gloves, Mosque.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mosque\n",
      "sample 464 / 512\n",
      "2025-09-15 00:42:03 src.selection.data DEBUG    Options: Banana, Strawberry, Train, Shirt, Sweater.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:42:03 src.selection.data DEBUG    Options: Socks, Pineapple, Blueberry, Yacht, Jeans.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "2025-09-15 00:42:04 src.selection.data DEBUG    Options: Socks, Pineapple, Blueberry, Yacht, Jeans.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Blue\n",
      "sample 465 / 512\n",
      "2025-09-15 00:42:07 src.selection.data DEBUG    Options: Chair, Orange, Plum, Ottoman.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ottoman\n",
      "2025-09-15 00:42:07 src.selection.data DEBUG    Options: Blueberry, Strawberry, Nightstand, Bed.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:42:08 src.selection.data DEBUG    Options: Blueberry, Strawberry, Nightstand, Bed.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "sample 466 / 512\n",
      "2025-09-15 00:42:11 src.selection.data DEBUG    Options: Mouse, Basketball, Phone, Football.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:42:12 src.selection.data DEBUG    Options: Yoga mat, Speaker, Keyboard, Tennis ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Tennis\n",
      "2025-09-15 00:42:12 src.selection.data DEBUG    Options: Yoga mat, Speaker, Keyboard, Tennis ball.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:42:12 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Speaker', prob=0.49609375, logit=19.0, token_id=30173, metadata=None))[\" Speaker\"] != 26698[\" Keyboard\"]\n",
      "2025-09-15 00:42:12 src.selection.data DEBUG    Options: Headphones, Dumbbell, Monitor, Basketball.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:42:12 src.selection.data DEBUG    Options: Golf ball, Router, Bat, Smartwatch.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Bat\n",
      "2025-09-15 00:42:12 src.selection.data DEBUG    Options: Golf ball, Router, Bat, Smartwatch.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "sample 467 / 512\n",
      "2025-09-15 00:42:16 src.selection.data DEBUG    Options: Anklet, Sweater, Kiwi, Piano, Watermelon, Pants, Slow cooker.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Pants\n",
      "2025-09-15 00:42:16 src.selection.data DEBUG    Options: Peach, Blender, Cello, Chain, Mango, Gloves, Jacket.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Mango\n",
      "2025-09-15 00:42:16 src.selection.data DEBUG    Options: Peach, Blender, Cello, Chain, Mango, Gloves, Jacket.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jacket\n",
      "sample 468 / 512\n",
      "2025-09-15 00:42:20 src.selection.data DEBUG    Options: Sunflower, Boxing gloves, Pepper, Carrot, Hockey stick.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:42:20 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pepper', prob=0.416015625, logit=20.0, token_id=52882, metadata=None))[\" Pepper\"] != 3341[\" Car\"]\n",
      "2025-09-15 00:42:20 src.selection.data DEBUG    Options: Guitar, Skis, Broccoli, Asparagus, Tennis ball.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "2025-09-15 00:42:20 src.selection.data DEBUG    Options: Boxing gloves, Surfboard, Cauliflower, Piano, Lettuce.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Surf\n",
      "2025-09-15 00:42:21 src.selection.data DEBUG    Options: Boxing gloves, Surfboard, Cauliflower, Piano, Lettuce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:42:21 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Caul', prob=0.58203125, logit=20.75, token_id=90538, metadata=None))[\" Caul\"] != 6914[\" Let\"]\n",
      "2025-09-15 00:42:21 src.selection.data DEBUG    Options: Pepper, Tennis ball, Celery, Surfboard, Charm.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Cel\n",
      "2025-09-15 00:42:21 src.selection.data DEBUG    Options: Onion, Baseball, Pendant, Football, Potato.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Football\n",
      "2025-09-15 00:42:21 src.selection.data DEBUG    Options: Onion, Baseball, Pendant, Football, Potato.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Potato\n",
      "sample 469 / 512\n",
      "2025-09-15 00:42:25 src.selection.data DEBUG    Options: Boxing gloves, Baseball, Drum, Accordion, Mirror.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "2025-09-15 00:42:25 src.selection.data DEBUG    Options: Xylophone, Skis, Golf ball, Bathtub, Clarinet.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:42:25 src.selection.data DEBUG    Options: Xylophone, Skis, Golf ball, Bathtub, Clarinet.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Clar\n",
      "sample 470 / 512\n",
      "2025-09-15 00:42:29 src.selection.data DEBUG    Options: Skyscraper, Sheep, Monkey, Bracelet, Watch.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Monkey\n",
      "2025-09-15 00:42:29 src.selection.data DEBUG    Options: Bear, Anklet, Cufflink, Lion, Temple.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:42:29 src.selection.data DEBUG    Options: Bear, Anklet, Cufflink, Lion, Temple.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Lion\n",
      "sample 471 / 512\n",
      "2025-09-15 00:42:33 src.selection.data DEBUG    Options: Zucchini, Cauliflower, Van, Motorcycle, Hat.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Caul\n",
      "2025-09-15 00:42:33 src.selection.data DEBUG    Options: Socks, Broccoli, Submarine, Helicopter, Asparagus.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Hel\n",
      "2025-09-15 00:42:34 src.selection.data DEBUG    Options: Socks, Broccoli, Submarine, Helicopter, Asparagus.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "sample 472 / 512\n",
      "2025-09-15 00:42:37 src.selection.data DEBUG    Options: Skirt, Shirt, Asparagus, Apple, Violet, Chrysanthemum, Headphones.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "2025-09-15 00:42:37 src.selection.data DEBUG    Options: Microphone, Iris, Pants, Tomato, Pear, Gloves, Lavender.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "2025-09-15 00:42:37 src.selection.data DEBUG    Options: Microphone, Iris, Pants, Tomato, Pear, Gloves, Lavender.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Lav\n",
      "sample 473 / 512\n",
      "2025-09-15 00:42:41 src.selection.data DEBUG    Options: Lily, Cow, Headphones, Socks, Mouse, Violet.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Mouse\n",
      "2025-09-15 00:42:41 src.selection.data DEBUG    Options: Smartwatch, Sweater, Lion, Microphone, Jasmine, Sunflower.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Sun\n",
      "2025-09-15 00:42:42 src.selection.data DEBUG    Options: Smartwatch, Sweater, Lion, Microphone, Jasmine, Sunflower.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Micro\n",
      "sample 474 / 512\n",
      "2025-09-15 00:42:45 src.selection.data DEBUG    Options: Sweater, Tiger, Oven, Air fryer, Elephant.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Elephant\n",
      "2025-09-15 00:42:45 src.selection.data DEBUG    Options: Food processor, Horse, Kettle, Zebra, Skirt.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  K\n",
      "2025-09-15 00:42:46 src.selection.data DEBUG    Options: Food processor, Horse, Kettle, Zebra, Skirt.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "sample 475 / 512\n",
      "2025-09-15 00:42:49 src.selection.data DEBUG    Options: Ruler, Pencil, Coffee maker, Lily, Chain, Cufflink, Dress.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:42:50 src.selection.data DEBUG    Options: Tape, Sweater, Brooch, Rose, Microwave, Necklace, Paperclip.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Necklace\n",
      "2025-09-15 00:42:50 src.selection.data DEBUG    Options: Tape, Sweater, Brooch, Rose, Microwave, Necklace, Paperclip.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "sample 476 / 512\n",
      "2025-09-15 00:42:53 src.selection.data DEBUG    Options: Yoga mat, Refrigerator, Celery, Shirt, Hat, Maple, Cauliflower.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Hat\n",
      "2025-09-15 00:42:54 src.selection.data DEBUG    Options: Oak, Dress, Food processor, Surfboard, Carrot, Mushroom, Gloves.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:42:54 src.selection.data DEBUG    Options: Oak, Dress, Food processor, Surfboard, Carrot, Mushroom, Gloves.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Gloves\n",
      "sample 477 / 512\n",
      "2025-09-15 00:42:58 src.selection.data DEBUG    Options: Monitor, Cat, Temple, Cedar, Shirt, Sheep, Smartwatch.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "2025-09-15 00:42:58 src.selection.data DEBUG    Options: Lion, Skirt, Microphone, Zebra, Pine, Mall, Keyboard.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Keyboard\n",
      "2025-09-15 00:42:58 src.selection.data DEBUG    Options: Lion, Skirt, Microphone, Zebra, Pine, Mall, Keyboard.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Z\n",
      "sample 478 / 512\n",
      "2025-09-15 00:43:02 src.selection.data DEBUG    Options: Peach, Church, Plum, Stadium, Iris, Earring.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:43:02 src.selection.data DEBUG    Options: Hospital, Tulip, Pendant, Banana, Temple, Strawberry.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-15 00:43:03 src.selection.data DEBUG    Options: Hospital, Tulip, Pendant, Banana, Temple, Strawberry.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "sample 479 / 512\n",
      "2025-09-15 00:43:07 src.selection.data DEBUG    Options: Spinach, Iris, Orchid, Mushroom.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:43:07 src.selection.data DEBUG    Options: Pepper, Rose, Lavender, Cauliflower.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Lav\n",
      "2025-09-15 00:43:07 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Caul', prob=0.65234375, logit=19.375, token_id=90538, metadata=None))[\" Caul\"] != 43950[\" Lav\"]\n",
      "2025-09-15 00:43:07 src.selection.data DEBUG    Options: Carnation, Tomato, Lavender, Zucchini.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:43:07 src.selection.data DEBUG    Options: Broccoli, Cucumber, Sunflower, Peony.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Pe\n",
      "2025-09-15 00:43:07 src.selection.data DEBUG    Options: Broccoli, Cucumber, Sunflower, Peony.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:43:07 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Bro', prob=0.515625, logit=18.875, token_id=6031, metadata=None))[\" Bro\"] != 356[\" C\"]\n",
      "2025-09-15 00:43:07 src.selection.data DEBUG    Options: Celery, Tomato, Chrysanthemum, Lily.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:43:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Cel', prob=0.359375, logit=19.0, token_id=47643, metadata=None))[\" Cel\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:43:08 src.selection.data DEBUG    Options: Cauliflower, Sunflower, Zucchini, Daisy.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:43:08 src.selection.data DEBUG    Options: Potato, Tomato, Iris, Tulip.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Tul\n",
      "2025-09-15 00:43:08 src.selection.data DEBUG    Options: Potato, Tomato, Iris, Tulip.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:43:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Potato', prob=0.51953125, logit=19.5, token_id=78703, metadata=None))[\" Potato\"] != 94091[\" Tomato\"]\n",
      "2025-09-15 00:43:08 src.selection.data DEBUG    Options: Carrot, Lettuce, Daffodil, Iris.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:43:09 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Car', prob=0.64453125, logit=20.5, token_id=3341, metadata=None))[\" Car\"] != 6914[\" Let\"]\n",
      "2025-09-15 00:43:09 src.selection.data DEBUG    Options: Spinach, Carnation, Zucchini, Lavender.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Z\n",
      "2025-09-15 00:43:09 src.selection.data DEBUG    Options: Celery, Daffodil, Mushroom, Sunflower.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Sun\n",
      "2025-09-15 00:43:09 src.selection.data DEBUG    Options: Celery, Daffodil, Mushroom, Sunflower.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "sample 480 / 512\n",
      "2025-09-15 00:43:13 src.selection.data DEBUG    Options: Ash, Scooter, Palm, Airplane, Zucchini.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:43:13 src.selection.data DEBUG    Options: Spruce, Train, Yacht, Redwood, Potato.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n",
      "2025-09-15 00:43:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Spr', prob=0.46875, logit=18.875, token_id=15883, metadata=None))[\" Spr\"] != 3816[\" Red\"]\n",
      "2025-09-15 00:43:13 src.selection.data DEBUG    Options: Spruce, Cello, Tractor, Bus, Hickory.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bus\n",
      "2025-09-15 00:43:13 src.selection.data DEBUG    Options: Boat, Willow, Train, Accordion, Magnolia.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "2025-09-15 00:43:13 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Willow', prob=0.435546875, logit=18.75, token_id=65449, metadata=None))[\" Willow\"] != 20918[\" Magn\"]\n",
      "2025-09-15 00:43:13 src.selection.data DEBUG    Options: Truck, Car, Printer, Bamboo, Pine.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:43:14 src.selection.data DEBUG    Options: Maple, Mouse, Willow, Van, Airplane.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Willow\n",
      "2025-09-15 00:43:14 src.selection.data DEBUG    Options: Maple, Mouse, Willow, Van, Airplane.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Air\n",
      "sample 481 / 512\n",
      "2025-09-15 00:43:17 src.selection.data DEBUG    Options: Toilet paper, Projector, Shower, Speaker.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Shower\n",
      "2025-09-15 00:43:18 src.selection.data DEBUG    Options: Phone, Tablet, Soap, Razor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:43:18 src.selection.data DEBUG    Options: Phone, Tablet, Soap, Razor.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Razor\n",
      "sample 482 / 512\n",
      "2025-09-15 00:43:22 src.selection.data DEBUG    Options: Tie, Horse, Drum, Xylophone, Iris, Rose, Recliner.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "2025-09-15 00:43:22 src.selection.data DEBUG    Options: Harp, Lavender, Dresser, Eagle, Saxophone, Chrysanthemum, Jacket.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "2025-09-15 00:43:22 src.selection.data DEBUG    Options: Harp, Lavender, Dresser, Eagle, Saxophone, Chrysanthemum, Jacket.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "sample 483 / 512\n",
      "2025-09-15 00:43:26 src.selection.data DEBUG    Options: Ash, Stadium, Dresser, Pen, Tomato, Cedar, Coffee table.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-15 00:43:26 src.selection.data DEBUG    Options: Nightstand, Wardrobe, School, Mushroom, Birch, Magnolia, Pencil.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "2025-09-15 00:43:26 src.selection.data DEBUG    Options: Nightstand, Wardrobe, School, Mushroom, Birch, Magnolia, Pencil.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "sample 484 / 512\n",
      "2025-09-15 00:43:30 src.selection.data DEBUG    Options: Cucumber, Peony, Tomato, Marigold.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:43:30 src.selection.data DEBUG    Options: Violet, Daisy, Celery, Onion.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Daisy\n",
      "2025-09-15 00:43:31 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Violet', prob=0.5, logit=18.875, token_id=74574, metadata=None))[\" Violet\"] != 71264[\" Daisy\"]\n",
      "2025-09-15 00:43:31 src.selection.data DEBUG    Options: Iris, Potato, Daffodil, Lettuce.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Let\n",
      "2025-09-15 00:43:31 src.selection.data DEBUG    Options: Asparagus, Daisy, Marigold, Onion.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "2025-09-15 00:43:31 src.selection.data DEBUG    Options: Asparagus, Daisy, Marigold, Onion.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "sample 485 / 512\n",
      "2025-09-15 00:43:35 src.selection.data DEBUG    Options: Paper, Dresser, Folder, Cabinet.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Cabinet\n",
      "2025-09-15 00:43:35 src.selection.data DEBUG    Options: Highlighter, Tape, Coffee table, Wardrobe.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Tape\n",
      "2025-09-15 00:43:35 src.selection.data DEBUG    Options: Highlighter, Tape, Coffee table, Wardrobe.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "sample 486 / 512\n",
      "2025-09-15 00:43:38 src.selection.data DEBUG    Options: Redwood, Tape, Skis, Palm, Bed, Watermelon, Bat.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Palm\n",
      "2025-09-15 00:43:39 src.selection.data DEBUG    Options: Pineapple, Baseball, Paper, Yoga mat, Elm, Magnolia, Dresser.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Yoga\n",
      "2025-09-15 00:43:39 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Baseball', prob=0.59765625, logit=19.75, token_id=38258, metadata=None))[\" Baseball\"] != 38673[\" Yoga\"]\n",
      "2025-09-15 00:43:39 src.selection.data DEBUG    Options: Plum, Gloves, Spruce, Pine, Carrot, Boxing gloves, Baseball.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Pine\n",
      "2025-09-15 00:43:39 src.selection.data DEBUG    Options: Suit, Skis, Skateboard, Mango, Mushroom, Birch, Maple.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Skate\n",
      "2025-09-15 00:43:39 src.selection.data DEBUG    Options: Suit, Skis, Skateboard, Mango, Mushroom, Birch, Maple.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Maple\n",
      "sample 487 / 512\n",
      "2025-09-15 00:43:43 src.selection.data DEBUG    Options: Zucchini, Potato, Projector, Mouse.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Potato\n",
      "2025-09-15 00:43:43 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Z', prob=0.37890625, logit=19.375, token_id=1901, metadata=None))[\" Z\"] != 78703[\" Potato\"]\n",
      "2025-09-15 00:43:43 src.selection.data DEBUG    Options: Carrot, Speaker, Potato, Keyboard.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Potato\n",
      "2025-09-15 00:43:43 src.selection.data DEBUG    Options: Cauliflower, Broccoli, Mouse, Projector.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "2025-09-15 00:43:43 src.selection.data DEBUG    Options: Cauliflower, Broccoli, Mouse, Projector.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "sample 488 / 512\n",
      "2025-09-15 00:43:47 src.selection.data DEBUG    Options: Elephant, Piano, Strawberry, Xylophone, Giraffe.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  X\n",
      "2025-09-15 00:43:47 src.selection.data DEBUG    Options: Eagle, Plum, Horse, Clarinet, Accordion.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Horse\n",
      "2025-09-15 00:43:47 src.selection.data DEBUG    Options: Eagle, Plum, Horse, Clarinet, Accordion.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Acc\n",
      "sample 489 / 512\n",
      "2025-09-15 00:43:51 src.selection.data DEBUG    Options: Pine, Bookshelf, Anklet, Ash, Cherry, Cat, Desk.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "2025-09-15 00:43:51 src.selection.data DEBUG    Options: Bangle, Raspberry, Giraffe, Dresser, Oak, Stool, Hickory.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "2025-09-15 00:43:51 src.selection.data DEBUG    Options: Bangle, Raspberry, Giraffe, Dresser, Oak, Stool, Hickory.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "sample 490 / 512\n",
      "2025-09-15 00:43:55 src.selection.data DEBUG    Options: Yoga mat, Pear, Table, Bed, Orange.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bed\n",
      "2025-09-15 00:43:55 src.selection.data DEBUG    Options: Kiwi, Racket, Mango, Cabinet, Bench.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Mango\n",
      "2025-09-15 00:43:55 src.selection.data DEBUG    Options: Kiwi, Racket, Mango, Cabinet, Bench.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bench\n",
      "sample 491 / 512\n",
      "2025-09-15 00:43:59 src.selection.data DEBUG    Options: Pressure cooker, Rice cooker, Elm, Bangle, Birch.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "2025-09-15 00:43:59 src.selection.data DEBUG    Options: Redwood, Kettle, Ash, Mixer, Cufflink.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-15 00:43:59 src.selection.data DEBUG    Options: Redwood, Kettle, Ash, Mixer, Cufflink.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "sample 492 / 512\n",
      "2025-09-15 00:44:03 src.selection.data DEBUG    Options: Elephant, Pendant, Rabbit, Printer, Banana, Pineapple.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Rabbit\n",
      "2025-09-15 00:44:03 src.selection.data DEBUG    Options: Orange, Router, Necklace, Plum, Zebra, Cow.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:44:04 src.selection.data DEBUG    Options: Orange, Router, Necklace, Plum, Zebra, Cow.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "sample 493 / 512\n",
      "2025-09-15 00:44:08 src.selection.data DEBUG    Options: Bike, Boat, Stapler, Paper, Shower.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:44:08 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.640625, logit=20.125, token_id=63606, metadata=None))[\" Stap\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:44:08 src.selection.data DEBUG    Options: Folder, Mouse, Paperclip, Bike, Yacht.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:44:08 src.selection.data DEBUG    Options: Tape, Pencil, Laptop, Helicopter, Scooter.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-15 00:44:08 src.selection.data DEBUG    Options: Tape, Pencil, Laptop, Helicopter, Scooter.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "sample 494 / 512\n",
      "2025-09-15 00:44:12 src.selection.data DEBUG    Options: Hat, Watermelon, Bench, Eraser, Banana, Hockey stick, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:44:12 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Er', prob=0.73828125, logit=20.375, token_id=9939, metadata=None))[\" Er\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:44:12 src.selection.data DEBUG    Options: Cherry, Binder, Marker, Accordion, Banana, Submarine, Basketball.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "2025-09-15 00:44:12 src.selection.data DEBUG    Options: Kiwi, Skis, Harmonica, Stapler, Pen, Bus, Plum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "2025-09-15 00:44:12 src.selection.data DEBUG    Options: Kiwi, Skis, Harmonica, Stapler, Pen, Bus, Plum.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:44:12 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.50390625, logit=20.125, token_id=63606, metadata=None))[\" Stap\"] != 13597[\" Pen\"]\n",
      "2025-09-15 00:44:12 src.selection.data DEBUG    Options: Folder, Bookshelf, Eagle, Pen, Pineapple, Shower, Pear.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:44:13 src.selection.data DEBUG    Options: Peach, Eraser, Marker, Cabinet, Toothpaste, Banana, Bear.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Banana\n",
      "2025-09-15 00:44:13 src.selection.data DEBUG    Options: Peach, Eraser, Marker, Cabinet, Toothpaste, Banana, Bear.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "sample 495 / 512\n",
      "2025-09-15 00:44:16 src.selection.data DEBUG    Options: Laptop, Cow, Lavender, Asparagus, Sofa, Smartwatch, Carrot.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Car\n",
      "2025-09-15 00:44:16 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' As', prob=0.5078125, logit=20.5, token_id=1666, metadata=None))[\" As\"] != 3341[\" Car\"]\n",
      "2025-09-15 00:44:16 src.selection.data DEBUG    Options: Sunflower, Cauliflower, Harmonica, Television, Factory, Smartwatch, Onion.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Onion\n",
      "2025-09-15 00:44:17 src.selection.data DEBUG    Options: Chrysanthemum, Library, Asparagus, Mushroom, Headphones, Ukulele, Monitor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 00:44:17 src.selection.data DEBUG    Options: Chrysanthemum, Library, Asparagus, Mushroom, Headphones, Ukulele, Monitor.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Mushroom\n",
      "2025-09-15 00:44:17 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' As', prob=0.68359375, logit=20.0, token_id=1666, metadata=None))[\" As\"] != 91297[\" Mushroom\"]\n",
      "2025-09-15 00:44:17 src.selection.data DEBUG    Options: Table, Camera, Mirror, Tomato, Speaker, Broccoli, Sheep.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Bro\n",
      "2025-09-15 00:44:18 src.selection.data DEBUG    Options: Dolphin, Desk, Projector, Onion, Asparagus, Tablet, Towel.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "2025-09-15 00:44:18 src.selection.data DEBUG    Options: Dolphin, Desk, Projector, Onion, Asparagus, Tablet, Towel.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  As\n",
      "sample 496 / 512\n",
      "2025-09-15 00:44:22 src.selection.data DEBUG    Options: Helmet, Sweater, Golf ball, Jacket.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jacket\n",
      "2025-09-15 00:44:22 src.selection.data DEBUG    Options: Tie, Jeans, Dumbbell, Hockey stick.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Hockey\n",
      "2025-09-15 00:44:22 src.selection.data DEBUG    Options: Tie, Jeans, Dumbbell, Hockey stick.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Jeans\n",
      "sample 497 / 512\n",
      "2025-09-15 00:44:26 src.selection.data DEBUG    Options: Sink, Jasmine, Chrysanthemum, Towel, Bike.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Ch\n",
      "2025-09-15 00:44:26 src.selection.data DEBUG    Options: Hairdryer, Peony, Airplane, Toothbrush, Iris.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "2025-09-15 00:44:26 src.selection.data DEBUG    Options: Hairdryer, Peony, Airplane, Toothbrush, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "sample 498 / 512\n",
      "2025-09-15 00:44:30 src.selection.data DEBUG    Options: Nightstand, Pen, Recliner, Plum, Paper.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 00:44:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Pen', prob=0.73828125, logit=20.5, token_id=13597, metadata=None))[\" Pen\"] != 18343[\" Paper\"]\n",
      "2025-09-15 00:44:30 src.selection.data DEBUG    Options: Stapler, Nightstand, Temple, Stool, Pencil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 00:44:30 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.6796875, logit=20.375, token_id=63606, metadata=None))[\" Stap\"] != 393[\" P\"]\n",
      "2025-09-15 00:44:30 src.selection.data DEBUG    Options: Van, Sofa, Table, Highlighter, Stapler.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "2025-09-15 00:44:30 src.selection.data DEBUG    Options: Scissors, Cabinet, Marker, Wardrobe, Train.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Ward\n",
      "2025-09-15 00:44:30 src.selection.data DEBUG    Options: Scissors, Cabinet, Marker, Wardrobe, Train.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "sample 499 / 512\n",
      "2025-09-15 00:44:34 src.selection.data DEBUG    Options: Skirt, Tie, Trumpet, Flute.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Fl\n",
      "2025-09-15 00:44:34 src.selection.data DEBUG    Options: Accordion, Gloves, Saxophone, Shorts.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shorts\n",
      "2025-09-15 00:44:35 src.selection.data DEBUG    Options: Accordion, Gloves, Saxophone, Shorts.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Sax\n",
      "sample 500 / 512\n",
      "2025-09-15 00:44:38 src.selection.data DEBUG    Options: Blueberry, Peony, Kiwi, Daffodil.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Ki\n",
      "2025-09-15 00:44:39 src.selection.data DEBUG    Options: Daisy, Violet, Watermelon, Apple.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:44:39 src.selection.data DEBUG    Options: Daisy, Violet, Watermelon, Apple.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Apple\n",
      "sample 501 / 512\n",
      "2025-09-15 00:44:42 src.selection.data DEBUG    Options: Baseball, Stool, Bench, Yoga mat, Camera.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bench\n",
      "2025-09-15 00:44:43 src.selection.data DEBUG    Options: Ottoman, Laptop, Dumbbell, Dresser, Golf ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "2025-09-15 00:44:43 src.selection.data DEBUG    Options: Ottoman, Laptop, Dumbbell, Dresser, Golf ball.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Dress\n",
      "sample 502 / 512\n",
      "2025-09-15 00:44:47 src.selection.data DEBUG    Options: Broccoli, Pine, Dumbbell, Asparagus, Elm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Elm\n",
      "2025-09-15 00:44:47 src.selection.data DEBUG    Options: Cucumber, Bamboo, Magnolia, Tomato, Football.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-15 00:44:47 src.selection.data DEBUG    Options: Cucumber, Bamboo, Magnolia, Tomato, Football.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Magn\n",
      "sample 503 / 512\n",
      "2025-09-15 00:44:51 src.selection.data DEBUG    Options: Air fryer, Drum, Food processor, Trumpet.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Food\n",
      "2025-09-15 00:44:51 src.selection.data DEBUG    Options: Toaster, Refrigerator, Saxophone, Guitar.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Guitar\n",
      "2025-09-15 00:44:51 src.selection.data DEBUG    Options: Toaster, Refrigerator, Saxophone, Guitar.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Refriger\n",
      "sample 504 / 512\n",
      "2025-09-15 00:44:55 src.selection.data DEBUG    Options: Calculator, Scissors, Stadium, Mall.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-15 00:44:55 src.selection.data DEBUG    Options: Binder, House, Church, Pen.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-15 00:44:55 src.selection.data DEBUG    Options: Binder, House, Church, Pen.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "sample 505 / 512\n",
      "2025-09-15 00:44:59 src.selection.data DEBUG    Options: Food processor, Bamboo, Hickory, Pressure cooker.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Hick\n",
      "2025-09-15 00:44:59 src.selection.data DEBUG    Options: Eucalyptus, Birch, Coffee maker, Air fryer.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Air\n",
      "2025-09-15 00:44:59 src.selection.data DEBUG    Options: Eucalyptus, Birch, Coffee maker, Air fryer.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Birch\n",
      "sample 506 / 512\n",
      "2025-09-15 00:45:03 src.selection.data DEBUG    Options: Car, Sunflower, Zebra, Carnation, Coat, Motorcycle.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Motorcycle\n",
      "2025-09-15 00:45:04 src.selection.data DEBUG    Options: Boat, Marigold, Yacht, Violet, Suit, Cat.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 00:45:04 src.selection.data DEBUG    Options: Boat, Marigold, Yacht, Violet, Suit, Cat.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Y\n",
      "sample 507 / 512\n",
      "2025-09-15 00:45:07 src.selection.data DEBUG    Options: Banana, Juicer, Strawberry, Coffee maker.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Strawberry\n",
      "2025-09-15 00:45:08 src.selection.data DEBUG    Options: Apple, Dishwasher, Oven, Plum.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Oven\n",
      "2025-09-15 00:45:08 src.selection.data DEBUG    Options: Apple, Dishwasher, Oven, Plum.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Plum\n",
      "sample 508 / 512\n",
      "2025-09-15 00:45:11 src.selection.data DEBUG    Options: Trombone, Bamboo, Ash, Harmonica, Stool, Pants.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Ash\n",
      "2025-09-15 00:45:12 src.selection.data DEBUG    Options: Bench, Eucalyptus, Cello, Gloves, Trumpet, Spruce.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trump\n",
      "2025-09-15 00:45:12 src.selection.data DEBUG    Options: Bench, Eucalyptus, Cello, Gloves, Trumpet, Spruce.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Spr\n",
      "sample 509 / 512\n",
      "2025-09-15 00:45:15 src.selection.data DEBUG    Options: Hickory, Monitor, Lion, Birch, Projector.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Project\n",
      "2025-09-15 00:45:16 src.selection.data DEBUG    Options: Eucalyptus, Cow, Mouse, Smartwatch, Palm.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Palm\n",
      "2025-09-15 00:45:16 src.selection.data DEBUG    Options: Eucalyptus, Cow, Mouse, Smartwatch, Palm.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Smart\n",
      "sample 510 / 512\n",
      "2025-09-15 00:45:19 src.selection.data DEBUG    Options: Bed, Ruler, Ottoman, Folder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 00:45:20 src.selection.data DEBUG    Options: Table, Bench, Notebook, Eraser.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Bench\n",
      "2025-09-15 00:45:20 src.selection.data DEBUG    Options: Table, Bench, Notebook, Eraser.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Er\n",
      "sample 511 / 512\n",
      "2025-09-15 00:45:23 src.selection.data DEBUG    Options: Bracelet, Cufflink, Air fryer, Pressure cooker.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  C\n",
      "2025-09-15 00:45:24 src.selection.data DEBUG    Options: Toaster, Chain, Earring, Blender.\n",
      "What is the last kitchen appliance in this list above?\n",
      "Answer: >>  Blender\n",
      "2025-09-15 00:45:24 src.selection.data DEBUG    Options: Toaster, Chain, Earring, Blender.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  E\n",
      "sample 512 / 512\n",
      "2025-09-15 00:45:28 src.selection.data DEBUG    Options: Microphone, Stadium, Printer, Church.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Church\n",
      "2025-09-15 00:45:28 src.selection.data DEBUG    Options: Museum, Warehouse, Monitor, Router.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n",
      "2025-09-15 00:45:28 src.selection.data DEBUG    Options: Museum, Warehouse, Monitor, Router.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:45:28 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Router', prob=0.65625, logit=18.25, token_id=10777, metadata=None))[\" Router\"] != 52466[\" Warehouse\"]\n",
      "2025-09-15 00:45:28 src.selection.data DEBUG    Options: Laptop, Microphone, Stadium, Warehouse.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Warehouse\n",
      "2025-09-15 00:45:28 src.selection.data DEBUG    Options: Camera, Temple, Phone, Hospital.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "2025-09-15 00:45:29 src.selection.data DEBUG    Options: Camera, Temple, Phone, Hospital.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Hospital\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "from src.selection.data import CounterFactualSamplePair\n",
    "\n",
    "\n",
    "train_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"train\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "os.makedirs(train_samples_save_path, exist_ok=True)\n",
    "\n",
    "train_set = []\n",
    "while len(train_set) < train_limit:\n",
    "    print(f\"sample {len(train_set)+1} / {train_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=prompt_template_idx,\n",
    "        option_style=OPTION_STYLE,\n",
    "        # distinct_options=True,\n",
    "        # # n_distractors=N_DISTRACTORS,\n",
    "        # patch_n_distractors=N_DISTRACTORS,\n",
    "        # clean_n_distractors=N_DISTRACTORS\n",
    "        n_options = random.choice([4, 5, 6, 7])\n",
    "    )\n",
    "    train_set.append((clean, patch))\n",
    "\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(os.path.join(train_samples_save_path, f\"{len(train_set):05d}.json\"), \"w\") as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b32f8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 00:46:26 __main__ INFO     Found 512 sample files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "\n",
    "train_set = []\n",
    "train_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"train\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(train_samples_load_path, f)\n",
    "    for f in os.listdir(train_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:train_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    train_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1f36fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Comb, Keyboard, Toothbrush, Birch, Mosque, Scissors, Willow.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Tooth\n",
      "Options: Speaker, Towel, Pen, Maple, Hairdryer, Redwood, Mall.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Red\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26781, ' Hair')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean, patch = train_set[5]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5eb0b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt._model.zero_grad()\n",
    "free_gpu_cache()\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d636fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 00:49:26 src.selection.optimization DEBUG    Training with hparams: {'learning_rate': 0.01, 'n_epochs': 10, 'lamb': 0.02, 'batch_size': 16}\n",
      "2025-09-15 00:49:26 src.selection.optimization INFO     Starting training...\n",
      "2025-09-15 00:49:30 src.selection.optimization DEBUG    Epoch=1 | batch_idx=0 |>> -16.6250 + 15.3750 + 102.5000 = 101.0000\n",
      "2025-09-15 00:49:38 src.selection.optimization DEBUG    Epoch=1 | batch_idx=1 |>> -16.6250 + 15.3125 + 101.0000 = 99.5000\n",
      "2025-09-15 00:49:46 src.selection.optimization DEBUG    Epoch=1 | batch_idx=2 |>> -17.5000 + 15.0625 + 100.0000 = 97.5000\n",
      "2025-09-15 00:49:53 src.selection.optimization DEBUG    Epoch=1 | batch_idx=3 |>> -17.2500 + 15.4375 + 99.0000 = 97.0000\n",
      "2025-09-15 00:50:01 src.selection.optimization DEBUG    Epoch=1 | batch_idx=4 |>> -16.8750 + 15.0625 + 98.0000 = 96.0000\n",
      "2025-09-15 00:50:10 src.selection.optimization DEBUG    Epoch=1 | batch_idx=5 |>> -17.1250 + 15.1875 + 96.5000 = 94.5000\n",
      "2025-09-15 00:50:17 src.selection.optimization DEBUG    Epoch=1 | batch_idx=6 |>> -17.2500 + 14.9375 + 95.5000 = 93.0000\n",
      "2025-09-15 00:50:25 src.selection.optimization DEBUG    Epoch=1 | batch_idx=7 |>> -17.1250 + 15.4375 + 94.0000 = 92.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 00:50:33 src.selection.optimization DEBUG    Epoch=1 | batch_idx=8 |>> -17.0000 + 14.8125 + 93.5000 = 91.5000\n",
      "2025-09-15 00:50:40 src.selection.optimization DEBUG    Epoch=1 | batch_idx=9 |>> -18.2500 + 15.4375 + 92.0000 = 89.0000\n",
      "2025-09-15 00:50:48 src.selection.optimization DEBUG    Epoch=1 | batch_idx=10 |>> -17.5000 + 15.4375 + 91.0000 = 89.0000\n",
      "2025-09-15 00:50:56 src.selection.optimization DEBUG    Epoch=1 | batch_idx=11 |>> -17.3750 + 15.5000 + 89.5000 = 87.5000\n",
      "2025-09-15 00:51:04 src.selection.optimization DEBUG    Epoch=1 | batch_idx=12 |>> -17.6250 + 15.8125 + 89.0000 = 87.0000\n",
      "2025-09-15 00:51:12 src.selection.optimization DEBUG    Epoch=1 | batch_idx=13 |>> -18.2500 + 15.0625 + 87.5000 = 84.5000\n",
      "2025-09-15 00:51:20 src.selection.optimization DEBUG    Epoch=1 | batch_idx=14 |>> -17.8750 + 15.5000 + 86.5000 = 84.0000\n",
      "2025-09-15 00:51:27 src.selection.optimization DEBUG    Epoch=1 | batch_idx=15 |>> -18.2500 + 15.0625 + 85.0000 = 82.0000\n",
      "2025-09-15 00:51:35 src.selection.optimization DEBUG    Epoch=1 | batch_idx=16 |>> -18.5000 + 15.3750 + 84.0000 = 81.0000\n",
      "2025-09-15 00:51:43 src.selection.optimization DEBUG    Epoch=1 | batch_idx=17 |>> -18.3750 + 15.8750 + 83.0000 = 80.5000\n",
      "2025-09-15 00:51:51 src.selection.optimization DEBUG    Epoch=1 | batch_idx=18 |>> -18.0000 + 15.5625 + 82.0000 = 79.5000\n",
      "2025-09-15 00:51:59 src.selection.optimization DEBUG    Epoch=1 | batch_idx=19 |>> -17.6250 + 15.8750 + 80.5000 = 79.0000\n",
      "2025-09-15 00:52:07 src.selection.optimization DEBUG    Epoch=1 | batch_idx=20 |>> -18.2500 + 15.6875 + 79.5000 = 77.0000\n",
      "2025-09-15 00:52:14 src.selection.optimization DEBUG    Epoch=1 | batch_idx=21 |>> -17.3750 + 15.6875 + 78.5000 = 77.0000\n",
      "2025-09-15 00:52:22 src.selection.optimization DEBUG    Epoch=1 | batch_idx=22 |>> -18.5000 + 15.2500 + 77.5000 = 74.0000\n",
      "2025-09-15 00:52:30 src.selection.optimization DEBUG    Epoch=1 | batch_idx=23 |>> -18.6250 + 15.5000 + 76.0000 = 73.0000\n",
      "2025-09-15 00:52:38 src.selection.optimization DEBUG    Epoch=1 | batch_idx=24 |>> -18.8750 + 15.1875 + 75.0000 = 71.5000\n",
      "2025-09-15 00:52:45 src.selection.optimization DEBUG    Epoch=1 | batch_idx=25 |>> -19.0000 + 15.8750 + 74.0000 = 71.0000\n",
      "2025-09-15 00:52:53 src.selection.optimization DEBUG    Epoch=1 | batch_idx=26 |>> -18.7500 + 15.7500 + 73.0000 = 70.0000\n",
      "2025-09-15 00:53:01 src.selection.optimization DEBUG    Epoch=1 | batch_idx=27 |>> -18.8750 + 16.1250 + 71.5000 = 69.0000\n",
      "2025-09-15 00:53:08 src.selection.optimization DEBUG    Epoch=1 | batch_idx=28 |>> -19.0000 + 15.2500 + 70.5000 = 67.0000\n",
      "2025-09-15 00:53:16 src.selection.optimization DEBUG    Epoch=1 | batch_idx=29 |>> -19.0000 + 15.5625 + 69.5000 = 66.0000\n",
      "2025-09-15 00:53:25 src.selection.optimization DEBUG    Epoch=1 | batch_idx=30 |>> -19.0000 + 15.4375 + 68.5000 = 65.0000\n",
      "2025-09-15 00:53:32 src.selection.optimization DEBUG    Epoch=1 | batch_idx=31 |>> -18.7500 + 15.0000 + 67.0000 = 63.2500\n",
      "2025-09-15 00:53:37 src.selection.optimization INFO     Epoch 1/10 completed. Avg Loss: 82.1641\n",
      "2025-09-15 00:53:41 src.selection.optimization DEBUG    Epoch=2 | batch_idx=0 |>> -18.7500 + 15.5625 + 66.0000 = 62.7500\n",
      "2025-09-15 00:53:49 src.selection.optimization DEBUG    Epoch=2 | batch_idx=1 |>> -18.8750 + 15.6875 + 65.0000 = 61.7500\n",
      "2025-09-15 00:53:57 src.selection.optimization DEBUG    Epoch=2 | batch_idx=2 |>> -19.5000 + 15.2500 + 64.0000 = 59.7500\n",
      "2025-09-15 00:54:05 src.selection.optimization DEBUG    Epoch=2 | batch_idx=3 |>> -19.0000 + 15.3750 + 62.7500 = 59.0000\n",
      "2025-09-15 00:54:12 src.selection.optimization DEBUG    Epoch=2 | batch_idx=4 |>> -18.7500 + 15.0625 + 61.7500 = 58.0000\n",
      "2025-09-15 00:54:21 src.selection.optimization DEBUG    Epoch=2 | batch_idx=5 |>> -18.7500 + 15.0000 + 60.5000 = 56.7500\n",
      "2025-09-15 00:54:28 src.selection.optimization DEBUG    Epoch=2 | batch_idx=6 |>> -19.3750 + 15.1875 + 59.5000 = 55.2500\n",
      "2025-09-15 00:54:36 src.selection.optimization DEBUG    Epoch=2 | batch_idx=7 |>> -19.6250 + 15.5000 + 58.2500 = 54.0000\n",
      "2025-09-15 00:54:44 src.selection.optimization DEBUG    Epoch=2 | batch_idx=8 |>> -19.2500 + 14.8125 + 57.2500 = 52.7500\n",
      "2025-09-15 00:54:52 src.selection.optimization DEBUG    Epoch=2 | batch_idx=9 |>> -20.0000 + 15.1875 + 56.0000 = 51.2500\n",
      "2025-09-15 00:55:01 src.selection.optimization DEBUG    Epoch=2 | batch_idx=10 |>> -19.5000 + 15.4375 + 55.0000 = 51.0000\n",
      "2025-09-15 00:55:09 src.selection.optimization DEBUG    Epoch=2 | batch_idx=11 |>> -19.1250 + 15.6250 + 54.0000 = 50.5000\n",
      "2025-09-15 00:55:18 src.selection.optimization DEBUG    Epoch=2 | batch_idx=12 |>> -19.1250 + 15.7500 + 53.0000 = 49.5000\n",
      "2025-09-15 00:55:26 src.selection.optimization DEBUG    Epoch=2 | batch_idx=13 |>> -19.8750 + 14.7500 + 52.2500 = 47.0000\n",
      "2025-09-15 00:55:35 src.selection.optimization DEBUG    Epoch=2 | batch_idx=14 |>> -19.7500 + 15.2500 + 51.2500 = 46.7500\n",
      "2025-09-15 00:55:43 src.selection.optimization DEBUG    Epoch=2 | batch_idx=15 |>> -20.1250 + 14.8750 + 50.2500 = 45.0000\n",
      "2025-09-15 00:55:52 src.selection.optimization DEBUG    Epoch=2 | batch_idx=16 |>> -20.2500 + 15.0000 + 49.2500 = 44.0000\n",
      "2025-09-15 00:56:01 src.selection.optimization DEBUG    Epoch=2 | batch_idx=17 |>> -20.3750 + 15.6250 + 48.2500 = 43.5000\n",
      "2025-09-15 00:56:09 src.selection.optimization DEBUG    Epoch=2 | batch_idx=18 |>> -19.7500 + 15.1875 + 47.2500 = 42.7500\n",
      "2025-09-15 00:56:17 src.selection.optimization DEBUG    Epoch=2 | batch_idx=19 |>> -19.6250 + 15.5000 + 46.5000 = 42.5000\n",
      "2025-09-15 00:56:25 src.selection.optimization DEBUG    Epoch=2 | batch_idx=20 |>> -19.6250 + 15.1875 + 45.5000 = 41.0000\n",
      "2025-09-15 00:56:33 src.selection.optimization DEBUG    Epoch=2 | batch_idx=21 |>> -18.7500 + 15.7500 + 44.5000 = 41.5000\n",
      "2025-09-15 00:56:41 src.selection.optimization DEBUG    Epoch=2 | batch_idx=22 |>> -20.1250 + 14.9375 + 43.5000 = 38.2500\n",
      "2025-09-15 00:56:49 src.selection.optimization DEBUG    Epoch=2 | batch_idx=23 |>> -19.8750 + 14.9375 + 42.5000 = 37.5000\n",
      "2025-09-15 00:56:58 src.selection.optimization DEBUG    Epoch=2 | batch_idx=24 |>> -20.6250 + 14.6250 + 41.5000 = 35.5000\n",
      "2025-09-15 00:57:05 src.selection.optimization DEBUG    Epoch=2 | batch_idx=25 |>> -20.3750 + 15.1875 + 40.7500 = 35.5000\n",
      "2025-09-15 00:57:13 src.selection.optimization DEBUG    Epoch=2 | batch_idx=26 |>> -20.3750 + 15.3750 + 39.7500 = 34.7500\n",
      "2025-09-15 00:57:21 src.selection.optimization DEBUG    Epoch=2 | batch_idx=27 |>> -20.2500 + 15.3125 + 38.7500 = 33.7500\n",
      "2025-09-15 00:57:30 src.selection.optimization DEBUG    Epoch=2 | batch_idx=28 |>> -20.2500 + 14.8125 + 37.7500 = 32.2500\n",
      "2025-09-15 00:57:38 src.selection.optimization DEBUG    Epoch=2 | batch_idx=29 |>> -20.2500 + 14.8125 + 36.7500 = 31.2500\n",
      "2025-09-15 00:57:47 src.selection.optimization DEBUG    Epoch=2 | batch_idx=30 |>> -20.2500 + 14.6250 + 35.7500 = 30.1250\n",
      "2025-09-15 00:57:55 src.selection.optimization DEBUG    Epoch=2 | batch_idx=31 |>> -20.2500 + 14.3125 + 35.0000 = 29.0000\n",
      "2025-09-15 00:57:59 src.selection.optimization INFO     Epoch 2/10 completed. Avg Loss: 45.4414\n",
      "2025-09-15 00:58:04 src.selection.optimization DEBUG    Epoch=3 | batch_idx=0 |>> -20.1250 + 14.6875 + 34.0000 = 28.5000\n",
      "2025-09-15 00:58:12 src.selection.optimization DEBUG    Epoch=3 | batch_idx=1 |>> -20.3750 + 14.9375 + 33.0000 = 27.5000\n",
      "2025-09-15 00:58:21 src.selection.optimization DEBUG    Epoch=3 | batch_idx=2 |>> -20.6250 + 14.6875 + 32.0000 = 26.0000\n",
      "2025-09-15 00:58:30 src.selection.optimization DEBUG    Epoch=3 | batch_idx=3 |>> -19.8750 + 14.5000 + 31.0000 = 25.6250\n",
      "2025-09-15 00:58:37 src.selection.optimization DEBUG    Epoch=3 | batch_idx=4 |>> -19.8750 + 14.2500 + 30.1250 = 24.5000\n",
      "2025-09-15 00:58:47 src.selection.optimization DEBUG    Epoch=3 | batch_idx=5 |>> -19.3750 + 14.0625 + 29.1250 = 23.7500\n",
      "2025-09-15 00:58:55 src.selection.optimization DEBUG    Epoch=3 | batch_idx=6 |>> -20.6250 + 14.2500 + 28.1250 = 21.7500\n",
      "2025-09-15 00:59:03 src.selection.optimization DEBUG    Epoch=3 | batch_idx=7 |>> -20.7500 + 14.3750 + 27.2500 = 20.8750\n",
      "2025-09-15 00:59:10 src.selection.optimization DEBUG    Epoch=3 | batch_idx=8 |>> -20.2500 + 13.8750 + 26.2500 = 19.8750\n",
      "2025-09-15 00:59:18 src.selection.optimization DEBUG    Epoch=3 | batch_idx=9 |>> -21.0000 + 14.3125 + 25.2500 = 18.5000\n",
      "2025-09-15 00:59:26 src.selection.optimization DEBUG    Epoch=3 | batch_idx=10 |>> -20.0000 + 14.5000 + 24.3750 = 18.8750\n",
      "2025-09-15 00:59:34 src.selection.optimization DEBUG    Epoch=3 | batch_idx=11 |>> -19.7500 + 14.8125 + 23.3750 = 18.5000\n",
      "2025-09-15 00:59:42 src.selection.optimization DEBUG    Epoch=3 | batch_idx=12 |>> -19.7500 + 14.7500 + 22.3750 = 17.3750\n",
      "2025-09-15 00:59:49 src.selection.optimization DEBUG    Epoch=3 | batch_idx=13 |>> -20.7500 + 13.7500 + 21.5000 = 14.5000\n",
      "2025-09-15 00:59:57 src.selection.optimization DEBUG    Epoch=3 | batch_idx=14 |>> -20.6250 + 14.3125 + 20.5000 = 14.1875\n",
      "2025-09-15 01:00:05 src.selection.optimization DEBUG    Epoch=3 | batch_idx=15 |>> -21.0000 + 13.6875 + 19.6250 = 12.3125\n",
      "2025-09-15 01:00:13 src.selection.optimization DEBUG    Epoch=3 | batch_idx=16 |>> -21.0000 + 13.8125 + 18.6250 = 11.4375\n",
      "2025-09-15 01:00:20 src.selection.optimization DEBUG    Epoch=3 | batch_idx=17 |>> -21.0000 + 14.3125 + 17.6250 = 10.9375\n",
      "2025-09-15 01:00:28 src.selection.optimization DEBUG    Epoch=3 | batch_idx=18 |>> -20.3750 + 13.9375 + 16.7500 = 10.3125\n",
      "2025-09-15 01:00:36 src.selection.optimization DEBUG    Epoch=3 | batch_idx=19 |>> -20.0000 + 14.0625 + 15.7500 = 9.8125\n",
      "2025-09-15 01:00:44 src.selection.optimization DEBUG    Epoch=3 | batch_idx=20 |>> -20.2500 + 14.1250 + 14.8125 = 8.6875\n",
      "2025-09-15 01:00:52 src.selection.optimization DEBUG    Epoch=3 | batch_idx=21 |>> -18.8750 + 14.9375 + 13.8125 = 9.8750\n",
      "2025-09-15 01:01:00 src.selection.optimization DEBUG    Epoch=3 | batch_idx=22 |>> -21.1250 + 13.8125 + 12.8750 = 5.5625\n",
      "2025-09-15 01:01:07 src.selection.optimization DEBUG    Epoch=3 | batch_idx=23 |>> -20.5000 + 13.7500 + 11.9375 = 5.1875\n",
      "2025-09-15 01:01:15 src.selection.optimization DEBUG    Epoch=3 | batch_idx=24 |>> -21.1250 + 13.0625 + 10.9375 = 2.8750\n",
      "2025-09-15 01:01:23 src.selection.optimization DEBUG    Epoch=3 | batch_idx=25 |>> -20.8750 + 13.8125 + 10.0625 = 3.0000\n",
      "2025-09-15 01:01:30 src.selection.optimization DEBUG    Epoch=3 | batch_idx=26 |>> -20.8750 + 14.1250 + 9.1250 = 2.3750\n",
      "2025-09-15 01:01:38 src.selection.optimization DEBUG    Epoch=3 | batch_idx=27 |>> -20.5000 + 13.7500 + 8.1875 = 1.4375\n",
      "2025-09-15 01:01:46 src.selection.optimization DEBUG    Epoch=3 | batch_idx=28 |>> -20.7500 + 13.6250 + 7.2500 = 0.1250\n",
      "2025-09-15 01:01:53 src.selection.optimization DEBUG    Epoch=3 | batch_idx=29 |>> -20.8750 + 13.1250 + 6.3125 = -1.4375\n",
      "2025-09-15 01:02:01 src.selection.optimization DEBUG    Epoch=3 | batch_idx=30 |>> -20.7500 + 12.9375 + 5.4375 = -2.3750\n",
      "2025-09-15 01:02:09 src.selection.optimization DEBUG    Epoch=3 | batch_idx=31 |>> -20.8750 + 13.0000 + 5.1250 = -2.7500\n",
      "2025-09-15 01:02:13 src.selection.optimization INFO     Epoch 3/10 completed. Avg Loss: 12.7402\n",
      "2025-09-15 01:02:18 src.selection.optimization DEBUG    Epoch=4 | batch_idx=0 |>> -21.0000 + 13.2500 + 4.9375 = -2.8125\n",
      "2025-09-15 01:02:25 src.selection.optimization DEBUG    Epoch=4 | batch_idx=1 |>> -21.1250 + 13.3125 + 4.8125 = -3.0000\n",
      "2025-09-15 01:02:33 src.selection.optimization DEBUG    Epoch=4 | batch_idx=2 |>> -21.2500 + 13.5000 + 4.6875 = -3.0625\n",
      "2025-09-15 01:02:41 src.selection.optimization DEBUG    Epoch=4 | batch_idx=3 |>> -20.0000 + 13.0000 + 4.5938 = -2.4062\n",
      "2025-09-15 01:02:49 src.selection.optimization DEBUG    Epoch=4 | batch_idx=4 |>> -20.3750 + 13.1250 + 4.5000 = -2.7500\n",
      "2025-09-15 01:02:57 src.selection.optimization DEBUG    Epoch=4 | batch_idx=5 |>> -19.3750 + 12.6250 + 4.4062 = -2.3438\n",
      "2025-09-15 01:03:05 src.selection.optimization DEBUG    Epoch=4 | batch_idx=6 |>> -21.1250 + 12.5000 + 4.3438 = -4.2812\n",
      "2025-09-15 01:03:13 src.selection.optimization DEBUG    Epoch=4 | batch_idx=7 |>> -21.3750 + 12.5625 + 4.2500 = -4.5625\n",
      "2025-09-15 01:03:20 src.selection.optimization DEBUG    Epoch=4 | batch_idx=8 |>> -20.6250 + 12.4375 + 4.1875 = -4.0000\n",
      "2025-09-15 01:03:28 src.selection.optimization DEBUG    Epoch=4 | batch_idx=9 |>> -21.3750 + 12.9375 + 4.1250 = -4.3125\n",
      "2025-09-15 01:03:36 src.selection.optimization DEBUG    Epoch=4 | batch_idx=10 |>> -20.3750 + 13.2500 + 4.0625 = -3.0625\n",
      "2025-09-15 01:03:43 src.selection.optimization DEBUG    Epoch=4 | batch_idx=11 |>> -19.8750 + 13.5625 + 4.0000 = -2.3125\n",
      "2025-09-15 01:03:51 src.selection.optimization DEBUG    Epoch=4 | batch_idx=12 |>> -20.0000 + 13.5625 + 3.9375 = -2.5000\n",
      "2025-09-15 01:03:59 src.selection.optimization DEBUG    Epoch=4 | batch_idx=13 |>> -21.0000 + 12.4375 + 3.9062 = -4.6562\n",
      "2025-09-15 01:04:07 src.selection.optimization DEBUG    Epoch=4 | batch_idx=14 |>> -21.0000 + 13.3125 + 3.8438 = -3.8438\n",
      "2025-09-15 01:04:15 src.selection.optimization DEBUG    Epoch=4 | batch_idx=15 |>> -21.1250 + 12.3750 + 3.7969 = -4.9375\n",
      "2025-09-15 01:04:23 src.selection.optimization DEBUG    Epoch=4 | batch_idx=16 |>> -21.1250 + 12.2500 + 3.7656 = -5.1250\n",
      "2025-09-15 01:04:32 src.selection.optimization DEBUG    Epoch=4 | batch_idx=17 |>> -21.0000 + 13.0625 + 3.7188 = -4.2188\n",
      "2025-09-15 01:04:40 src.selection.optimization DEBUG    Epoch=4 | batch_idx=18 |>> -20.5000 + 12.5625 + 3.6875 = -4.2500\n",
      "2025-09-15 01:04:48 src.selection.optimization DEBUG    Epoch=4 | batch_idx=19 |>> -20.1250 + 12.5625 + 3.6406 = -3.9219\n",
      "2025-09-15 01:04:56 src.selection.optimization DEBUG    Epoch=4 | batch_idx=20 |>> -20.3750 + 12.9375 + 3.5938 = -3.8438\n",
      "2025-09-15 01:05:04 src.selection.optimization DEBUG    Epoch=4 | batch_idx=21 |>> -19.0000 + 13.9375 + 3.5625 = -1.5000\n",
      "2025-09-15 01:05:12 src.selection.optimization DEBUG    Epoch=4 | batch_idx=22 |>> -21.2500 + 12.8750 + 3.5156 = -4.8750\n",
      "2025-09-15 01:05:19 src.selection.optimization DEBUG    Epoch=4 | batch_idx=23 |>> -20.6250 + 12.5000 + 3.5000 = -4.6250\n",
      "2025-09-15 01:05:28 src.selection.optimization DEBUG    Epoch=4 | batch_idx=24 |>> -21.0000 + 11.8125 + 3.4531 = -5.7500\n",
      "2025-09-15 01:05:35 src.selection.optimization DEBUG    Epoch=4 | batch_idx=25 |>> -21.0000 + 12.7500 + 3.4375 = -4.8125\n",
      "2025-09-15 01:05:43 src.selection.optimization DEBUG    Epoch=4 | batch_idx=26 |>> -21.0000 + 13.0000 + 3.4219 = -4.5625\n",
      "2025-09-15 01:05:51 src.selection.optimization DEBUG    Epoch=4 | batch_idx=27 |>> -20.3750 + 12.5625 + 3.3750 = -4.4375\n",
      "2025-09-15 01:05:58 src.selection.optimization DEBUG    Epoch=4 | batch_idx=28 |>> -20.7500 + 12.6875 + 3.3594 = -4.6875\n",
      "2025-09-15 01:06:06 src.selection.optimization DEBUG    Epoch=4 | batch_idx=29 |>> -20.8750 + 11.8125 + 3.3438 = -5.7188\n",
      "2025-09-15 01:06:14 src.selection.optimization DEBUG    Epoch=4 | batch_idx=30 |>> -20.7500 + 12.0000 + 3.3125 = -5.4375\n",
      "2025-09-15 01:06:22 src.selection.optimization DEBUG    Epoch=4 | batch_idx=31 |>> -20.7500 + 12.0625 + 3.2969 = -5.3750\n",
      "2025-09-15 01:06:27 src.selection.optimization INFO     Epoch 4/10 completed. Avg Loss: -3.9995\n",
      "2025-09-15 01:06:31 src.selection.optimization DEBUG    Epoch=5 | batch_idx=0 |>> -21.0000 + 12.4375 + 3.2656 = -5.3125\n",
      "2025-09-15 01:06:39 src.selection.optimization DEBUG    Epoch=5 | batch_idx=1 |>> -21.2500 + 12.1875 + 3.2344 = -5.8125\n",
      "2025-09-15 01:06:47 src.selection.optimization DEBUG    Epoch=5 | batch_idx=2 |>> -21.2500 + 12.6250 + 3.2188 = -5.4062\n",
      "2025-09-15 01:06:55 src.selection.optimization DEBUG    Epoch=5 | batch_idx=3 |>> -19.7500 + 11.8750 + 3.2031 = -4.6875\n",
      "2025-09-15 01:07:03 src.selection.optimization DEBUG    Epoch=5 | batch_idx=4 |>> -20.3750 + 12.3125 + 3.1875 = -4.8750\n",
      "2025-09-15 01:07:11 src.selection.optimization DEBUG    Epoch=5 | batch_idx=5 |>> -19.2500 + 11.6875 + 3.1875 = -4.3750\n",
      "2025-09-15 01:07:19 src.selection.optimization DEBUG    Epoch=5 | batch_idx=6 |>> -21.0000 + 11.2500 + 3.1562 = -6.5938\n",
      "2025-09-15 01:07:27 src.selection.optimization DEBUG    Epoch=5 | batch_idx=7 |>> -21.3750 + 11.3125 + 3.1406 = -6.9375\n",
      "2025-09-15 01:07:35 src.selection.optimization DEBUG    Epoch=5 | batch_idx=8 |>> -20.6250 + 11.4375 + 3.1250 = -6.0625\n",
      "2025-09-15 01:07:43 src.selection.optimization DEBUG    Epoch=5 | batch_idx=9 |>> -21.3750 + 12.0000 + 3.0938 = -6.2812\n",
      "2025-09-15 01:07:50 src.selection.optimization DEBUG    Epoch=5 | batch_idx=10 |>> -20.2500 + 12.1875 + 3.0781 = -5.0000\n",
      "2025-09-15 01:07:58 src.selection.optimization DEBUG    Epoch=5 | batch_idx=11 |>> -19.6250 + 12.6250 + 3.0625 = -3.9375\n",
      "2025-09-15 01:08:06 src.selection.optimization DEBUG    Epoch=5 | batch_idx=12 |>> -19.8750 + 12.8750 + 3.0625 = -3.9375\n",
      "2025-09-15 01:08:14 src.selection.optimization DEBUG    Epoch=5 | batch_idx=13 |>> -21.0000 + 11.6875 + 3.0469 = -6.2500\n",
      "2025-09-15 01:08:22 src.selection.optimization DEBUG    Epoch=5 | batch_idx=14 |>> -20.8750 + 12.4375 + 3.0156 = -5.4375\n",
      "2025-09-15 01:08:30 src.selection.optimization DEBUG    Epoch=5 | batch_idx=15 |>> -21.0000 + 11.4375 + 3.0156 = -6.5625\n",
      "2025-09-15 01:08:38 src.selection.optimization DEBUG    Epoch=5 | batch_idx=16 |>> -21.0000 + 11.0625 + 3.0000 = -6.9375\n",
      "2025-09-15 01:08:46 src.selection.optimization DEBUG    Epoch=5 | batch_idx=17 |>> -21.0000 + 12.0000 + 2.9844 = -6.0000\n",
      "2025-09-15 01:08:54 src.selection.optimization DEBUG    Epoch=5 | batch_idx=18 |>> -20.0000 + 11.7500 + 2.9844 = -5.2500\n",
      "2025-09-15 01:09:02 src.selection.optimization DEBUG    Epoch=5 | batch_idx=19 |>> -20.1250 + 11.8125 + 2.9531 = -5.3750\n",
      "2025-09-15 01:09:09 src.selection.optimization DEBUG    Epoch=5 | batch_idx=20 |>> -20.2500 + 12.2500 + 2.9531 = -5.0625\n",
      "2025-09-15 01:09:17 src.selection.optimization DEBUG    Epoch=5 | batch_idx=21 |>> -19.0000 + 13.3125 + 2.9375 = -2.7500\n",
      "2025-09-15 01:09:25 src.selection.optimization DEBUG    Epoch=5 | batch_idx=22 |>> -21.2500 + 12.1875 + 2.9219 = -6.1250\n",
      "2025-09-15 01:09:32 src.selection.optimization DEBUG    Epoch=5 | batch_idx=23 |>> -20.7500 + 11.7500 + 2.9219 = -6.0625\n",
      "2025-09-15 01:09:40 src.selection.optimization DEBUG    Epoch=5 | batch_idx=24 |>> -20.8750 + 11.1250 + 2.9219 = -6.8125\n",
      "2025-09-15 01:09:48 src.selection.optimization DEBUG    Epoch=5 | batch_idx=25 |>> -21.1250 + 12.0625 + 2.9062 = -6.1562\n",
      "2025-09-15 01:09:55 src.selection.optimization DEBUG    Epoch=5 | batch_idx=26 |>> -20.8750 + 12.3125 + 2.9062 = -5.6562\n",
      "2025-09-15 01:10:03 src.selection.optimization DEBUG    Epoch=5 | batch_idx=27 |>> -20.3750 + 11.8750 + 2.8750 = -5.6250\n",
      "2025-09-15 01:10:11 src.selection.optimization DEBUG    Epoch=5 | batch_idx=28 |>> -20.8750 + 12.0625 + 2.8750 = -5.9375\n",
      "2025-09-15 01:10:19 src.selection.optimization DEBUG    Epoch=5 | batch_idx=29 |>> -20.8750 + 11.0625 + 2.8750 = -6.9375\n",
      "2025-09-15 01:10:27 src.selection.optimization DEBUG    Epoch=5 | batch_idx=30 |>> -20.8750 + 11.4375 + 2.8594 = -6.5625\n",
      "2025-09-15 01:10:36 src.selection.optimization DEBUG    Epoch=5 | batch_idx=31 |>> -20.8750 + 11.4375 + 2.8594 = -6.5625\n",
      "2025-09-15 01:10:40 src.selection.optimization INFO     Epoch 5/10 completed. Avg Loss: -5.6650\n",
      "2025-09-15 01:10:45 src.selection.optimization DEBUG    Epoch=6 | batch_idx=0 |>> -21.1250 + 12.0000 + 2.8438 = -6.2812\n",
      "2025-09-15 01:10:52 src.selection.optimization DEBUG    Epoch=6 | batch_idx=1 |>> -21.3750 + 11.7500 + 2.8438 = -6.7812\n",
      "2025-09-15 01:11:00 src.selection.optimization DEBUG    Epoch=6 | batch_idx=2 |>> -21.2500 + 12.0000 + 2.8438 = -6.4062\n",
      "2025-09-15 01:11:08 src.selection.optimization DEBUG    Epoch=6 | batch_idx=3 |>> -19.7500 + 11.2500 + 2.8438 = -5.6562\n",
      "2025-09-15 01:11:15 src.selection.optimization DEBUG    Epoch=6 | batch_idx=4 |>> -20.3750 + 11.9375 + 2.8125 = -5.6250\n",
      "2025-09-15 01:11:24 src.selection.optimization DEBUG    Epoch=6 | batch_idx=5 |>> -19.2500 + 11.1250 + 2.8125 = -5.3125\n",
      "2025-09-15 01:11:32 src.selection.optimization DEBUG    Epoch=6 | batch_idx=6 |>> -21.0000 + 10.6875 + 2.8125 = -7.5000\n",
      "2025-09-15 01:11:40 src.selection.optimization DEBUG    Epoch=6 | batch_idx=7 |>> -21.3750 + 10.6250 + 2.7969 = -7.9375\n",
      "2025-09-15 01:11:47 src.selection.optimization DEBUG    Epoch=6 | batch_idx=8 |>> -20.7500 + 10.8750 + 2.7969 = -7.0625\n",
      "2025-09-15 01:11:55 src.selection.optimization DEBUG    Epoch=6 | batch_idx=9 |>> -21.5000 + 11.4375 + 2.7969 = -7.2500\n",
      "2025-09-15 01:12:03 src.selection.optimization DEBUG    Epoch=6 | batch_idx=10 |>> -20.2500 + 11.6875 + 2.7812 = -5.7812\n",
      "2025-09-15 01:12:11 src.selection.optimization DEBUG    Epoch=6 | batch_idx=11 |>> -19.6250 + 12.1250 + 2.7812 = -4.7188\n",
      "2025-09-15 01:12:19 src.selection.optimization DEBUG    Epoch=6 | batch_idx=12 |>> -19.7500 + 12.5000 + 2.7812 = -4.4688\n",
      "2025-09-15 01:12:26 src.selection.optimization DEBUG    Epoch=6 | batch_idx=13 |>> -21.1250 + 11.3125 + 2.7812 = -7.0312\n",
      "2025-09-15 01:12:34 src.selection.optimization DEBUG    Epoch=6 | batch_idx=14 |>> -21.0000 + 12.0000 + 2.7656 = -6.2500\n",
      "2025-09-15 01:12:42 src.selection.optimization DEBUG    Epoch=6 | batch_idx=15 |>> -21.0000 + 10.9375 + 2.7656 = -7.3125\n",
      "2025-09-15 01:12:50 src.selection.optimization DEBUG    Epoch=6 | batch_idx=16 |>> -21.1250 + 10.5625 + 2.7656 = -7.8125\n",
      "2025-09-15 01:12:58 src.selection.optimization DEBUG    Epoch=6 | batch_idx=17 |>> -21.1250 + 11.5625 + 2.7656 = -6.8125\n",
      "2025-09-15 01:13:06 src.selection.optimization DEBUG    Epoch=6 | batch_idx=18 |>> -20.1250 + 11.3750 + 2.7656 = -6.0000\n",
      "2025-09-15 01:13:14 src.selection.optimization DEBUG    Epoch=6 | batch_idx=19 |>> -20.2500 + 11.4375 + 2.7656 = -6.0625\n",
      "2025-09-15 01:13:22 src.selection.optimization DEBUG    Epoch=6 | batch_idx=20 |>> -20.2500 + 11.8750 + 2.7344 = -5.6250\n",
      "2025-09-15 01:13:29 src.selection.optimization DEBUG    Epoch=6 | batch_idx=21 |>> -19.2500 + 13.0000 + 2.7344 = -3.5156\n",
      "2025-09-15 01:13:37 src.selection.optimization DEBUG    Epoch=6 | batch_idx=22 |>> -21.1250 + 11.8125 + 2.7344 = -6.5625\n",
      "2025-09-15 01:13:45 src.selection.optimization DEBUG    Epoch=6 | batch_idx=23 |>> -20.7500 + 11.3125 + 2.7344 = -6.6875\n",
      "2025-09-15 01:13:53 src.selection.optimization DEBUG    Epoch=6 | batch_idx=24 |>> -20.8750 + 10.7500 + 2.7344 = -7.3750\n",
      "2025-09-15 01:14:00 src.selection.optimization DEBUG    Epoch=6 | batch_idx=25 |>> -21.2500 + 11.6875 + 2.7344 = -6.8125\n",
      "2025-09-15 01:14:08 src.selection.optimization DEBUG    Epoch=6 | batch_idx=26 |>> -21.0000 + 11.9375 + 2.7344 = -6.3125\n",
      "2025-09-15 01:14:16 src.selection.optimization DEBUG    Epoch=6 | batch_idx=27 |>> -20.3750 + 11.4375 + 2.7344 = -6.1875\n",
      "2025-09-15 01:14:23 src.selection.optimization DEBUG    Epoch=6 | batch_idx=28 |>> -21.0000 + 11.6250 + 2.7344 = -6.6250\n",
      "2025-09-15 01:14:31 src.selection.optimization DEBUG    Epoch=6 | batch_idx=29 |>> -21.0000 + 10.5625 + 2.7344 = -7.6875\n",
      "2025-09-15 01:14:39 src.selection.optimization DEBUG    Epoch=6 | batch_idx=30 |>> -20.8750 + 11.1250 + 2.7188 = -7.0312\n",
      "2025-09-15 01:14:47 src.selection.optimization DEBUG    Epoch=6 | batch_idx=31 |>> -21.0000 + 11.1250 + 2.7188 = -7.1562\n",
      "2025-09-15 01:14:51 src.selection.optimization INFO     Epoch 6/10 completed. Avg Loss: -6.4263\n",
      "2025-09-15 01:14:56 src.selection.optimization DEBUG    Epoch=7 | batch_idx=0 |>> -21.1250 + 11.7500 + 2.7188 = -6.6562\n",
      "2025-09-15 01:15:04 src.selection.optimization DEBUG    Epoch=7 | batch_idx=1 |>> -21.5000 + 11.4375 + 2.7188 = -7.3438\n",
      "2025-09-15 01:15:11 src.selection.optimization DEBUG    Epoch=7 | batch_idx=2 |>> -21.2500 + 11.6250 + 2.7188 = -6.9062\n",
      "2025-09-15 01:15:19 src.selection.optimization DEBUG    Epoch=7 | batch_idx=3 |>> -19.7500 + 10.8750 + 2.7188 = -6.1562\n",
      "2025-09-15 01:15:27 src.selection.optimization DEBUG    Epoch=7 | batch_idx=4 |>> -20.3750 + 11.6250 + 2.7188 = -6.0312\n",
      "2025-09-15 01:15:35 src.selection.optimization DEBUG    Epoch=7 | batch_idx=5 |>> -19.3750 + 10.8125 + 2.7188 = -5.8438\n",
      "2025-09-15 01:15:43 src.selection.optimization DEBUG    Epoch=7 | batch_idx=6 |>> -21.0000 + 10.3125 + 2.7188 = -7.9688\n",
      "2025-09-15 01:15:51 src.selection.optimization DEBUG    Epoch=7 | batch_idx=7 |>> -21.5000 + 10.2500 + 2.7188 = -8.5000\n",
      "2025-09-15 01:15:59 src.selection.optimization DEBUG    Epoch=7 | batch_idx=8 |>> -20.8750 + 10.5000 + 2.7188 = -7.6562\n",
      "2025-09-15 01:16:06 src.selection.optimization DEBUG    Epoch=7 | batch_idx=9 |>> -21.5000 + 11.1250 + 2.7188 = -7.6562\n",
      "2025-09-15 01:16:14 src.selection.optimization DEBUG    Epoch=7 | batch_idx=10 |>> -20.1250 + 11.3750 + 2.7188 = -6.0312\n",
      "2025-09-15 01:16:22 src.selection.optimization DEBUG    Epoch=7 | batch_idx=11 |>> -19.7500 + 11.8125 + 2.7188 = -5.2188\n",
      "2025-09-15 01:16:30 src.selection.optimization DEBUG    Epoch=7 | batch_idx=12 |>> -19.7500 + 12.3125 + 2.7188 = -4.7188\n",
      "2025-09-15 01:16:38 src.selection.optimization DEBUG    Epoch=7 | batch_idx=13 |>> -21.2500 + 11.0625 + 2.7188 = -7.4688\n",
      "2025-09-15 01:16:45 src.selection.optimization DEBUG    Epoch=7 | batch_idx=14 |>> -21.0000 + 11.6250 + 2.7188 = -6.6562\n",
      "2025-09-15 01:16:53 src.selection.optimization DEBUG    Epoch=7 | batch_idx=15 |>> -21.0000 + 10.5625 + 2.7188 = -7.7188\n",
      "2025-09-15 01:17:02 src.selection.optimization DEBUG    Epoch=7 | batch_idx=16 |>> -21.1250 + 10.3125 + 2.7188 = -8.1250\n",
      "2025-09-15 01:17:10 src.selection.optimization DEBUG    Epoch=7 | batch_idx=17 |>> -21.2500 + 11.2500 + 2.7188 = -7.2812\n",
      "2025-09-15 01:17:19 src.selection.optimization DEBUG    Epoch=7 | batch_idx=18 |>> -20.0000 + 11.1875 + 2.7188 = -6.0938\n",
      "2025-09-15 01:17:28 src.selection.optimization DEBUG    Epoch=7 | batch_idx=19 |>> -20.3750 + 11.3125 + 2.7188 = -6.3438\n",
      "2025-09-15 01:17:36 src.selection.optimization DEBUG    Epoch=7 | batch_idx=20 |>> -20.3750 + 11.5625 + 2.7188 = -6.0938\n",
      "2025-09-15 01:17:45 src.selection.optimization DEBUG    Epoch=7 | batch_idx=21 |>> -19.5000 + 12.8750 + 2.7188 = -3.9062\n",
      "2025-09-15 01:17:53 src.selection.optimization DEBUG    Epoch=7 | batch_idx=22 |>> -21.2500 + 11.6250 + 2.7344 = -6.8750\n",
      "2025-09-15 01:18:02 src.selection.optimization DEBUG    Epoch=7 | batch_idx=23 |>> -20.8750 + 11.1250 + 2.7344 = -7.0000\n",
      "2025-09-15 01:18:10 src.selection.optimization DEBUG    Epoch=7 | batch_idx=24 |>> -20.8750 + 10.4375 + 2.7344 = -7.6875\n",
      "2025-09-15 01:18:18 src.selection.optimization DEBUG    Epoch=7 | batch_idx=25 |>> -21.2500 + 11.4375 + 2.7344 = -7.0625\n",
      "2025-09-15 01:18:25 src.selection.optimization DEBUG    Epoch=7 | batch_idx=26 |>> -21.0000 + 11.6875 + 2.7344 = -6.5625\n",
      "2025-09-15 01:18:33 src.selection.optimization DEBUG    Epoch=7 | batch_idx=27 |>> -20.5000 + 11.0625 + 2.7344 = -6.6875\n",
      "2025-09-15 01:18:41 src.selection.optimization DEBUG    Epoch=7 | batch_idx=28 |>> -21.1250 + 11.2500 + 2.7344 = -7.1250\n",
      "2025-09-15 01:18:49 src.selection.optimization DEBUG    Epoch=7 | batch_idx=29 |>> -21.1250 + 10.2500 + 2.7344 = -8.1250\n",
      "2025-09-15 01:18:57 src.selection.optimization DEBUG    Epoch=7 | batch_idx=30 |>> -20.8750 + 10.8750 + 2.7344 = -7.2500\n",
      "2025-09-15 01:19:05 src.selection.optimization DEBUG    Epoch=7 | batch_idx=31 |>> -21.0000 + 11.0000 + 2.7344 = -7.2500\n",
      "2025-09-15 01:19:09 src.selection.optimization INFO     Epoch 7/10 completed. Avg Loss: -6.8125\n",
      "2025-09-15 01:19:14 src.selection.optimization DEBUG    Epoch=8 | batch_idx=0 |>> -21.1250 + 11.6250 + 2.7344 = -6.7500\n",
      "2025-09-15 01:19:22 src.selection.optimization DEBUG    Epoch=8 | batch_idx=1 |>> -21.5000 + 11.2500 + 2.7656 = -7.5000\n",
      "2025-09-15 01:19:30 src.selection.optimization DEBUG    Epoch=8 | batch_idx=2 |>> -21.2500 + 11.3750 + 2.7656 = -7.1250\n",
      "2025-09-15 01:19:37 src.selection.optimization DEBUG    Epoch=8 | batch_idx=3 |>> -19.7500 + 10.6250 + 2.7656 = -6.3750\n",
      "2025-09-15 01:19:45 src.selection.optimization DEBUG    Epoch=8 | batch_idx=4 |>> -20.3750 + 11.4375 + 2.7656 = -6.1875\n",
      "2025-09-15 01:19:53 src.selection.optimization DEBUG    Epoch=8 | batch_idx=5 |>> -19.2500 + 10.5625 + 2.7656 = -5.9375\n",
      "2025-09-15 01:20:01 src.selection.optimization DEBUG    Epoch=8 | batch_idx=6 |>> -21.1250 + 10.0000 + 2.7656 = -8.3750\n",
      "2025-09-15 01:20:09 src.selection.optimization DEBUG    Epoch=8 | batch_idx=7 |>> -21.5000 + 9.9375 + 2.7656 = -8.8125\n",
      "2025-09-15 01:20:16 src.selection.optimization DEBUG    Epoch=8 | batch_idx=8 |>> -21.0000 + 10.3125 + 2.7656 = -7.9375\n",
      "2025-09-15 01:20:24 src.selection.optimization DEBUG    Epoch=8 | batch_idx=9 |>> -21.5000 + 10.8125 + 2.7656 = -7.9375\n",
      "2025-09-15 01:20:32 src.selection.optimization DEBUG    Epoch=8 | batch_idx=10 |>> -20.1250 + 11.1250 + 2.7656 = -6.2500\n",
      "2025-09-15 01:20:39 src.selection.optimization DEBUG    Epoch=8 | batch_idx=11 |>> -19.8750 + 11.4375 + 2.7656 = -5.6875\n",
      "2025-09-15 01:20:47 src.selection.optimization DEBUG    Epoch=8 | batch_idx=12 |>> -19.5000 + 12.1250 + 2.7656 = -4.6250\n",
      "2025-09-15 01:20:55 src.selection.optimization DEBUG    Epoch=8 | batch_idx=13 |>> -21.2500 + 10.8125 + 2.7656 = -7.6875\n",
      "2025-09-15 01:21:03 src.selection.optimization DEBUG    Epoch=8 | batch_idx=14 |>> -21.0000 + 11.3125 + 2.7656 = -6.9375\n",
      "2025-09-15 01:21:10 src.selection.optimization DEBUG    Epoch=8 | batch_idx=15 |>> -20.8750 + 10.1875 + 2.7812 = -7.9062\n",
      "2025-09-15 01:21:18 src.selection.optimization DEBUG    Epoch=8 | batch_idx=16 |>> -21.1250 + 10.1250 + 2.7812 = -8.2500\n",
      "2025-09-15 01:21:25 src.selection.optimization DEBUG    Epoch=8 | batch_idx=17 |>> -21.2500 + 10.8750 + 2.7812 = -7.5938\n",
      "2025-09-15 01:21:33 src.selection.optimization DEBUG    Epoch=8 | batch_idx=18 |>> -19.8750 + 11.0000 + 2.7812 = -6.0938\n",
      "2025-09-15 01:21:41 src.selection.optimization DEBUG    Epoch=8 | batch_idx=19 |>> -20.5000 + 11.1250 + 2.7812 = -6.5938\n",
      "2025-09-15 01:21:49 src.selection.optimization DEBUG    Epoch=8 | batch_idx=20 |>> -20.3750 + 11.3750 + 2.7812 = -6.2188\n",
      "2025-09-15 01:21:57 src.selection.optimization DEBUG    Epoch=8 | batch_idx=21 |>> -19.6250 + 12.6875 + 2.7812 = -4.1562\n",
      "2025-09-15 01:22:04 src.selection.optimization DEBUG    Epoch=8 | batch_idx=22 |>> -21.1250 + 11.4375 + 2.7812 = -6.9062\n",
      "2025-09-15 01:22:12 src.selection.optimization DEBUG    Epoch=8 | batch_idx=23 |>> -20.8750 + 11.0000 + 2.7812 = -7.0938\n",
      "2025-09-15 01:22:20 src.selection.optimization DEBUG    Epoch=8 | batch_idx=24 |>> -20.7500 + 10.1875 + 2.7969 = -7.7500\n",
      "2025-09-15 01:22:28 src.selection.optimization DEBUG    Epoch=8 | batch_idx=25 |>> -21.2500 + 11.1875 + 2.7969 = -7.2500\n",
      "2025-09-15 01:22:35 src.selection.optimization DEBUG    Epoch=8 | batch_idx=26 |>> -21.0000 + 11.4375 + 2.7969 = -6.7500\n",
      "2025-09-15 01:22:43 src.selection.optimization DEBUG    Epoch=8 | batch_idx=27 |>> -20.6250 + 10.8125 + 2.7969 = -7.0000\n",
      "2025-09-15 01:22:51 src.selection.optimization DEBUG    Epoch=8 | batch_idx=28 |>> -21.1250 + 10.9375 + 2.7969 = -7.3750\n",
      "2025-09-15 01:22:58 src.selection.optimization DEBUG    Epoch=8 | batch_idx=29 |>> -21.2500 + 9.9375 + 2.7969 = -8.5000\n",
      "2025-09-15 01:23:07 src.selection.optimization DEBUG    Epoch=8 | batch_idx=30 |>> -20.8750 + 10.6250 + 2.7969 = -7.4375\n",
      "2025-09-15 01:23:15 src.selection.optimization DEBUG    Epoch=8 | batch_idx=31 |>> -21.1250 + 10.8125 + 2.7969 = -7.5000\n",
      "2025-09-15 01:23:19 src.selection.optimization INFO     Epoch 8/10 completed. Avg Loss: -7.0156\n",
      "2025-09-15 01:23:23 src.selection.optimization DEBUG    Epoch=9 | batch_idx=0 |>> -21.2500 + 11.5000 + 2.7969 = -6.9375\n",
      "2025-09-15 01:23:31 src.selection.optimization DEBUG    Epoch=9 | batch_idx=1 |>> -21.5000 + 10.8750 + 2.8125 = -7.8125\n",
      "2025-09-15 01:23:39 src.selection.optimization DEBUG    Epoch=9 | batch_idx=2 |>> -21.2500 + 11.1250 + 2.8125 = -7.3125\n",
      "2025-09-15 01:23:46 src.selection.optimization DEBUG    Epoch=9 | batch_idx=3 |>> -19.8750 + 10.3125 + 2.8125 = -6.7500\n",
      "2025-09-15 01:23:54 src.selection.optimization DEBUG    Epoch=9 | batch_idx=4 |>> -20.3750 + 11.2500 + 2.8125 = -6.3125\n",
      "2025-09-15 01:24:02 src.selection.optimization DEBUG    Epoch=9 | batch_idx=5 |>> -19.1250 + 10.3750 + 2.8125 = -5.9375\n",
      "2025-09-15 01:24:10 src.selection.optimization DEBUG    Epoch=9 | batch_idx=6 |>> -21.1250 + 9.7500 + 2.8125 = -8.5625\n",
      "2025-09-15 01:24:17 src.selection.optimization DEBUG    Epoch=9 | batch_idx=7 |>> -21.3750 + 9.7500 + 2.8125 = -8.8125\n",
      "2025-09-15 01:24:25 src.selection.optimization DEBUG    Epoch=9 | batch_idx=8 |>> -21.0000 + 10.1250 + 2.8125 = -8.0625\n",
      "2025-09-15 01:24:33 src.selection.optimization DEBUG    Epoch=9 | batch_idx=9 |>> -21.5000 + 10.6250 + 2.8125 = -8.0625\n",
      "2025-09-15 01:24:40 src.selection.optimization DEBUG    Epoch=9 | batch_idx=10 |>> -20.1250 + 10.8750 + 2.8125 = -6.4375\n",
      "2025-09-15 01:24:48 src.selection.optimization DEBUG    Epoch=9 | batch_idx=11 |>> -19.8750 + 11.1875 + 2.8125 = -5.8750\n",
      "2025-09-15 01:24:56 src.selection.optimization DEBUG    Epoch=9 | batch_idx=12 |>> -19.3750 + 11.9375 + 2.8125 = -4.6250\n",
      "2025-09-15 01:25:03 src.selection.optimization DEBUG    Epoch=9 | batch_idx=13 |>> -21.3750 + 10.6250 + 2.8125 = -7.9375\n",
      "2025-09-15 01:25:11 src.selection.optimization DEBUG    Epoch=9 | batch_idx=14 |>> -21.0000 + 11.0625 + 2.8125 = -7.1250\n",
      "2025-09-15 01:25:19 src.selection.optimization DEBUG    Epoch=9 | batch_idx=15 |>> -20.8750 + 9.8750 + 2.8125 = -8.1875\n",
      "2025-09-15 01:25:27 src.selection.optimization DEBUG    Epoch=9 | batch_idx=16 |>> -21.2500 + 9.9375 + 2.8125 = -8.5000\n",
      "2025-09-15 01:25:35 src.selection.optimization DEBUG    Epoch=9 | batch_idx=17 |>> -21.3750 + 10.6250 + 2.8438 = -7.9062\n",
      "2025-09-15 01:25:43 src.selection.optimization DEBUG    Epoch=9 | batch_idx=18 |>> -19.7500 + 10.8750 + 2.8438 = -6.0312\n",
      "2025-09-15 01:25:51 src.selection.optimization DEBUG    Epoch=9 | batch_idx=19 |>> -20.6250 + 11.0625 + 2.8438 = -6.7188\n",
      "2025-09-15 01:25:59 src.selection.optimization DEBUG    Epoch=9 | batch_idx=20 |>> -20.3750 + 11.1875 + 2.8438 = -6.3438\n",
      "2025-09-15 01:26:06 src.selection.optimization DEBUG    Epoch=9 | batch_idx=21 |>> -19.7500 + 12.5000 + 2.8438 = -4.4062\n",
      "2025-09-15 01:26:14 src.selection.optimization DEBUG    Epoch=9 | batch_idx=22 |>> -21.1250 + 11.2500 + 2.8438 = -7.0312\n",
      "2025-09-15 01:26:22 src.selection.optimization DEBUG    Epoch=9 | batch_idx=23 |>> -20.8750 + 10.9375 + 2.8438 = -7.0938\n",
      "2025-09-15 01:26:30 src.selection.optimization DEBUG    Epoch=9 | batch_idx=24 |>> -20.7500 + 10.0000 + 2.8438 = -7.9062\n",
      "2025-09-15 01:26:38 src.selection.optimization DEBUG    Epoch=9 | batch_idx=25 |>> -21.2500 + 11.0000 + 2.8438 = -7.4062\n",
      "2025-09-15 01:26:45 src.selection.optimization DEBUG    Epoch=9 | batch_idx=26 |>> -21.0000 + 11.2500 + 2.8438 = -6.9062\n",
      "2025-09-15 01:26:53 src.selection.optimization DEBUG    Epoch=9 | batch_idx=27 |>> -20.6250 + 10.5625 + 2.8438 = -7.2188\n",
      "2025-09-15 01:27:01 src.selection.optimization DEBUG    Epoch=9 | batch_idx=28 |>> -21.2500 + 10.7500 + 2.8438 = -7.6562\n",
      "2025-09-15 01:27:09 src.selection.optimization DEBUG    Epoch=9 | batch_idx=29 |>> -21.2500 + 9.7500 + 2.8594 = -8.6250\n",
      "2025-09-15 01:27:17 src.selection.optimization DEBUG    Epoch=9 | batch_idx=30 |>> -20.8750 + 10.4375 + 2.8594 = -7.5625\n",
      "2025-09-15 01:27:25 src.selection.optimization DEBUG    Epoch=9 | batch_idx=31 |>> -21.2500 + 10.6875 + 2.8594 = -7.6875\n",
      "2025-09-15 01:27:29 src.selection.optimization INFO     Epoch 9/10 completed. Avg Loss: -7.1797\n",
      "2025-09-15 01:27:34 src.selection.optimization DEBUG    Epoch=10 | batch_idx=0 |>> -21.3750 + 11.3750 + 2.8594 = -7.1250\n",
      "2025-09-15 01:27:42 src.selection.optimization DEBUG    Epoch=10 | batch_idx=1 |>> -21.5000 + 10.7500 + 2.8594 = -7.8750\n",
      "2025-09-15 01:27:50 src.selection.optimization DEBUG    Epoch=10 | batch_idx=2 |>> -21.2500 + 11.0000 + 2.8594 = -7.3750\n",
      "2025-09-15 01:27:57 src.selection.optimization DEBUG    Epoch=10 | batch_idx=3 |>> -19.8750 + 10.1875 + 2.8594 = -6.8125\n",
      "2025-09-15 01:28:05 src.selection.optimization DEBUG    Epoch=10 | batch_idx=4 |>> -20.3750 + 11.1875 + 2.8594 = -6.3125\n",
      "2025-09-15 01:28:14 src.selection.optimization DEBUG    Epoch=10 | batch_idx=5 |>> -19.1250 + 10.2500 + 2.8594 = -6.0000\n",
      "2025-09-15 01:28:21 src.selection.optimization DEBUG    Epoch=10 | batch_idx=6 |>> -21.2500 + 9.5625 + 2.8594 = -8.8125\n",
      "2025-09-15 01:28:29 src.selection.optimization DEBUG    Epoch=10 | batch_idx=7 |>> -21.2500 + 9.6250 + 2.8594 = -8.7500\n",
      "2025-09-15 01:28:37 src.selection.optimization DEBUG    Epoch=10 | batch_idx=8 |>> -21.1250 + 10.0000 + 2.8594 = -8.2500\n",
      "2025-09-15 01:28:45 src.selection.optimization DEBUG    Epoch=10 | batch_idx=9 |>> -21.6250 + 10.5000 + 2.8594 = -8.2500\n",
      "2025-09-15 01:28:53 src.selection.optimization DEBUG    Epoch=10 | batch_idx=10 |>> -20.0000 + 10.7500 + 2.8594 = -6.3750\n",
      "2025-09-15 01:29:00 src.selection.optimization DEBUG    Epoch=10 | batch_idx=11 |>> -20.0000 + 11.0000 + 2.8750 = -6.1250\n",
      "2025-09-15 01:29:08 src.selection.optimization DEBUG    Epoch=10 | batch_idx=12 |>> -19.3750 + 11.8750 + 2.8750 = -4.6250\n",
      "2025-09-15 01:29:16 src.selection.optimization DEBUG    Epoch=10 | batch_idx=13 |>> -21.3750 + 10.4375 + 2.8750 = -8.0625\n",
      "2025-09-15 01:29:24 src.selection.optimization DEBUG    Epoch=10 | batch_idx=14 |>> -21.1250 + 10.8750 + 2.8750 = -7.3750\n",
      "2025-09-15 01:29:32 src.selection.optimization DEBUG    Epoch=10 | batch_idx=15 |>> -20.8750 + 9.6875 + 2.8750 = -8.3125\n",
      "2025-09-15 01:29:40 src.selection.optimization DEBUG    Epoch=10 | batch_idx=16 |>> -21.2500 + 9.8750 + 2.8750 = -8.5000\n",
      "2025-09-15 01:29:47 src.selection.optimization DEBUG    Epoch=10 | batch_idx=17 |>> -21.5000 + 10.4375 + 2.8750 = -8.1875\n",
      "2025-09-15 01:29:55 src.selection.optimization DEBUG    Epoch=10 | batch_idx=18 |>> -19.7500 + 10.8125 + 2.8750 = -6.0625\n",
      "2025-09-15 01:30:03 src.selection.optimization DEBUG    Epoch=10 | batch_idx=19 |>> -20.6250 + 11.0000 + 2.8750 = -6.7500\n",
      "2025-09-15 01:30:11 src.selection.optimization DEBUG    Epoch=10 | batch_idx=20 |>> -20.3750 + 11.0625 + 2.8750 = -6.4375\n",
      "2025-09-15 01:30:18 src.selection.optimization DEBUG    Epoch=10 | batch_idx=21 |>> -19.8750 + 12.4375 + 2.8750 = -4.5625\n",
      "2025-09-15 01:30:26 src.selection.optimization DEBUG    Epoch=10 | batch_idx=22 |>> -21.1250 + 11.0625 + 2.8750 = -7.1875\n",
      "2025-09-15 01:30:34 src.selection.optimization DEBUG    Epoch=10 | batch_idx=23 |>> -20.8750 + 10.8125 + 2.8750 = -7.1875\n",
      "2025-09-15 01:30:42 src.selection.optimization DEBUG    Epoch=10 | batch_idx=24 |>> -20.7500 + 9.8750 + 2.9062 = -7.9688\n",
      "2025-09-15 01:30:50 src.selection.optimization DEBUG    Epoch=10 | batch_idx=25 |>> -21.3750 + 10.8750 + 2.9062 = -7.5938\n",
      "2025-09-15 01:30:58 src.selection.optimization DEBUG    Epoch=10 | batch_idx=26 |>> -21.0000 + 11.1250 + 2.9062 = -6.9688\n",
      "2025-09-15 01:31:06 src.selection.optimization DEBUG    Epoch=10 | batch_idx=27 |>> -20.6250 + 10.4375 + 2.9062 = -7.2812\n",
      "2025-09-15 01:31:13 src.selection.optimization DEBUG    Epoch=10 | batch_idx=28 |>> -21.2500 + 10.6250 + 2.9062 = -7.7188\n",
      "2025-09-15 01:31:21 src.selection.optimization DEBUG    Epoch=10 | batch_idx=29 |>> -21.2500 + 9.6250 + 2.9062 = -8.7500\n",
      "2025-09-15 01:31:30 src.selection.optimization DEBUG    Epoch=10 | batch_idx=30 |>> -20.8750 + 10.3125 + 2.9062 = -7.6562\n",
      "2025-09-15 01:31:37 src.selection.optimization DEBUG    Epoch=10 | batch_idx=31 |>> -21.2500 + 10.5625 + 2.9062 = -7.7812\n",
      "2025-09-15 01:31:42 src.selection.optimization INFO     Epoch 10/10 completed. Avg Loss: -7.2822\n"
     ]
    }
   ],
   "source": [
    "from src.selection.optimization import get_optimal_head_mask_optimized, get_optimal_head_mask_prev\n",
    "import numpy as np\n",
    "\n",
    "free_gpu_cache()\n",
    "\n",
    "optimization_interface = {\n",
    "    \"legacy\": get_optimal_head_mask_prev,\n",
    "    \"updated\": get_optimal_head_mask_optimized,\n",
    "}\n",
    "\n",
    "#############################\n",
    "intface = \"legacy\"\n",
    "#############################\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/test_localization_code\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    f\"{TASK_CLS.task_name}\",\n",
    ")\n",
    "\n",
    "optimization_func = optimization_interface[intface]\n",
    "\n",
    "indices_kwargs = {\"query_indices\": [-2, -1]}\n",
    "if intface == \"legacy\":\n",
    "    optimized_path = os.path.join(optimized_path, \"legacy\")\n",
    "    # indices_kwargs[\"query_indices\"] = [-3, -2, -1]\n",
    "    indices_kwargs[\"query_indices\"] = [-1]\n",
    "elif intface == \"updated\":\n",
    "    indices_kwargs[\"add_ques_pos_to_query_indices\"] = True\n",
    "\n",
    "optimal_mask, losses = optimization_func(\n",
    "    mt=mt,\n",
    "    train_set=train_set,\n",
    "    learning_rate=1e-2,\n",
    "    n_epochs=10,\n",
    "    lamb=2e-2,\n",
    "    batch_size=16,\n",
    "    save_step=2,\n",
    "    save_path=optimized_path,\n",
    "    # black_list_heads=optimized_heads\n",
    "    **indices_kwargs\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(optimized_path), exist_ok=True)\n",
    "\n",
    "np.savez_compressed(\n",
    "    optimized_path,\n",
    "    **dict(\n",
    "        optimal_mask=optimal_mask.to(torch.float32).numpy(),\n",
    "        losses=np.array(losses, dtype=np.float32),\n",
    "    ),\n",
    "    allow_pickle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04fa7b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6eb40e6a10>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/test_localization_code\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    f\"{TASK_CLS.task_name}\",\n",
    "    \"legacy\",\n",
    "    \"epoch_10.npz\",\n",
    ")\n",
    "\n",
    "optimization_results = np.load(optimized_path, allow_pickle=True)\n",
    "plt.plot(optimization_results[\"losses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66e217f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(torch.float32)\n",
    "optimal_head_mask[50:, :] = 0.0\n",
    "# optimal_head_mask[75:, :] = 0.0\n",
    "# optimal_head_mask[37:, :] = 0.0\n",
    "\n",
    "plt.imshow(\n",
    "    optimal_head_mask.T.numpy(),\n",
    "    cmap=\"Blues\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "optimized_heads = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).to(dtype=torch.int).tolist()\n",
    "optimized_heads = [\n",
    "    (layer_idx, head_idx) for layer_idx, head_idx in optimized_heads\n",
    "]\n",
    "print(len(optimized_heads))\n",
    "\n",
    "HEADS = optimized_heads\n",
    "\n",
    "(35, 19) in HEADS, (35, 19) in optimized_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414b376",
   "metadata": {},
   "source": [
    "## Validation of the patching effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c310a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1 / 257\n",
      "2025-09-14 20:07:57 src.selection.data DEBUG    Options: Microwave, Oven, Jasmine, Tie, Apartment, School.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Apartment\n",
      "2025-09-14 20:07:58 src.selection.data DEBUG    Options: Dress, Mall, Library, Daisy, Kettle, Slow cooker.\n",
      "What is the first kitchen appliance from the list above?\n",
      "Answer: >>  K\n",
      "2025-09-14 20:07:58 src.selection.data DEBUG    Options: Dress, Mall, Library, Daisy, Kettle, Slow cooker.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-14 20:07:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Library', prob=0.376953125, logit=20.625, token_id=11896, metadata=None))[\" Library\"] != 32498[\" Mall\"]\n",
      "2025-09-14 20:07:58 src.selection.data DEBUG    Options: Temple, Air fryer, Tie, Soap, Slow cooker, Skyscraper.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Temple\n",
      "2025-09-14 20:07:58 src.selection.data DEBUG    Options: Oven, Warehouse, Hat, Hairdryer, Factory, Microwave.\n",
      "What is the first kitchen appliance from the list above?\n",
      "Answer: >>  Oven\n",
      "2025-09-14 20:07:58 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Microwave', prob=0.546875, logit=20.75, token_id=98641, metadata=None))[\" Microwave\"] != 87213[\" Oven\"]\n",
      "2025-09-14 20:07:58 src.selection.data DEBUG    Options: Juicer, Church, Speaker, Food processor, Apartment, Trombone.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Church\n",
      "2025-09-14 20:07:58 src.selection.data DEBUG    Options: Piano, Coffee maker, Headphones, Mall, School, Air fryer.\n",
      "What is the first kitchen appliance from the list above?\n",
      "Answer: >>  Coffee\n",
      "2025-09-14 20:07:59 src.selection.data DEBUG    Options: Piano, Coffee maker, Headphones, Mall, School, Air fryer.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Mall\n",
      "2025-09-14 20:07:59 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' School', prob=0.447265625, logit=20.25, token_id=6150, metadata=None))[\" School\"] != 32498[\" Mall\"]\n",
      "2025-09-14 20:07:59 src.selection.data DEBUG    Options: Church, Scarf, Pendant, Slow cooker, Pressure cooker, Temple.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Church\n",
      "2025-09-14 20:07:59 src.selection.data DEBUG    Options: Food processor, Refrigerator, Warehouse, Pin, School, Skirt.\n",
      "What is the first kitchen appliance from the list above?\n",
      "Answer: >>  Food\n",
      "2025-09-14 20:07:59 src.selection.data DEBUG    Options: Food processor, Refrigerator, Warehouse, Pin, School, Skirt.\n",
      "What is the first building from the list above?\n",
      "Answer: >>  Warehouse\n",
      "sample 2 / 257\n",
      "2025-09-14 20:08:03 src.selection.data DEBUG    Options: Potato, Apartment, Notebook, Spinach, Towel, Folder.\n",
      "What is the first vegetable from the list above?\n",
      "Answer: >>  Potato\n",
      "2025-09-14 20:08:03 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Spin', prob=0.7890625, logit=21.75, token_id=41785, metadata=None))[\" Spin\"] != 78703[\" Potato\"]\n",
      "2025-09-14 20:08:03 src.selection.data DEBUG    Options: Spinach, Comb, Notebook, Onion, Binder, Maple.\n",
      "What is the first vegetable from the list above?\n",
      "Answer: >>  Spin\n",
      "2025-09-14 20:08:03 src.selection.data DEBUG    Options: Soap, Mushroom, Zucchini, Ruler, Pencil, Oak.\n",
      "What is the first office supply from the list above?\n",
      "Answer: >>  R\n",
      "2025-09-14 20:08:04 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' P', prob=0.68359375, logit=21.375, token_id=393, metadata=None))[\" P\"] != 432[\" R\"]\n",
      "2025-09-14 20:08:04 src.selection.data DEBUG    Options: Baseball, Binder, Tomato, Ruler, Mushroom, Banana.\n",
      "What is the first vegetable from the list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-14 20:08:04 src.selection.data DEBUG    Options: Pineapple, Pepper, Paper, Tennis ball, Notebook, Celery.\n",
      "What is the first office supply from the list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-14 20:08:04 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Notebook', prob=0.50390625, logit=20.25, token_id=69755, metadata=None))[\" Notebook\"] != 18343[\" Paper\"]\n",
      "2025-09-14 20:08:04 src.selection.data DEBUG    Options: Tomato, Ring, Ottoman, Notebook, Paperclip, Cucumber.\n",
      "What is the first vegetable from the list above?\n",
      "Answer: >>  Tomato\n",
      "2025-09-14 20:08:04 src.selection.data DEBUG    Options: Desk, Broccoli, Pen, Lettuce, Binder, Anklet.\n",
      "What is the first office supply from the list above?\n",
      "Answer: >>  Pen\n",
      "2025-09-14 20:08:04 src.selection.data DEBUG    Options: Desk, Broccoli, Pen, Lettuce, Binder, Anklet.\n",
      "What is the first vegetable from the list above?\n",
      "Answer: >>  Bro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f6e8f72d990>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 3 / 257\n",
      "2025-09-14 20:08:08 src.selection.data DEBUG    Options: Car, Motorcycle, Dolphin, Tablet, Iris, Lotion, Tulip.\n",
      "What is the first vehicle from the list above?\n",
      "Answer: >>  Car\n",
      "2025-09-14 20:08:09 src.selection.data DEBUG    Options: Toothpaste, Scooter, Keyboard, Bus, Tiger, Rose, Orchid.\n",
      "What is the first flower from the list above?\n",
      "Answer: >>  Rose\n",
      "2025-09-14 20:08:09 src.selection.data DEBUG    Options: Toothpaste, Scooter, Keyboard, Bus, Tiger, Rose, Orchid.\n",
      "What is the first vehicle from the list above?\n",
      "Answer: >>  Sco\n",
      "sample 4 / 257\n",
      "2025-09-14 20:08:13 src.selection.data DEBUG    Options: Daffodil, Refrigerator, Microwave, Scooter, Coffee table, Car.\n",
      "What is the first vehicle from the list above?\n",
      "Answer: >>  Sco\n",
      "2025-09-14 20:08:13 src.selection.data DEBUG    Options: Chair, Submarine, Mixer, Boat, Chrysanthemum, Food processor.\n",
      "What is the first kitchen appliance from the list above?\n",
      "Answer: >>  Mixer\n",
      "2025-09-14 20:08:13 src.selection.data DEBUG    Options: Chair, Submarine, Mixer, Boat, Chrysanthemum, Food processor.\n",
      "What is the first vehicle from the list above?\n",
      "Answer: >>  Sub\n",
      "sample 5 / 257\n",
      "2025-09-14 20:08:17 src.selection.data DEBUG    Options: Golf ball, Factory, Bracelet, Charm, Rose, Microwave, Pressure cooker.\n",
      "What is the first kitchen appliance from the list above?\n",
      "Answer: >>  Microwave\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import CounterFactualSamplePair, get_counterfactual_samples_interface\n",
    "from src.functional import free_gpu_cache\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 255\n",
    "start_number = 1\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=prompt_template_idx,\n",
    "        option_style=OPTION_STYLE,\n",
    "        distinct_options=True,\n",
    "        # # n_distractors=N_DISTRACTORS,\n",
    "        # patch_n_distractors=N_DISTRACTORS,\n",
    "        # clean_n_distractors=N_DISTRACTORS\n",
    "        n_options = random.choice([4, 5, 6, 7])\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set) + start_number - 1:05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037d82da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1 / 1024\n",
      "2025-09-15 09:32:52 src.selection.data DEBUG    Options: Toothbrush, Basketball, Smartwatch, Hairdryer, Speaker.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Speaker\n",
      "2025-09-15 09:32:53 src.selection.data DEBUG    Options: Monitor, Phone, Sink, Comb, Racket.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Comb\n",
      "2025-09-15 09:32:53 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Sink', prob=0.765625, logit=20.25, token_id=57551, metadata=None))[\" Sink\"] != 23262[\" Comb\"]\n",
      "2025-09-15 09:32:53 src.selection.data DEBUG    Options: Sink, Calculator, Bathtub, Microphone, Monitor.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Monitor\n",
      "2025-09-15 09:32:53 src.selection.data DEBUG    Options: Laptop, Toilet paper, Phone, Paper, Toilet.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Toilet\n",
      "2025-09-15 09:32:53 src.selection.data DEBUG    Options: Laptop, Toilet paper, Phone, Paper, Toilet.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Phone\n",
      "sample 2 / 1024\n",
      "2025-09-15 09:32:57 src.selection.data DEBUG    Options: Lavender, Skateboard, Surfboard, Plum, Peach.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Peach\n",
      "2025-09-15 09:32:57 src.selection.data DEBUG    Options: Grape, Golf ball, Watermelon, Racket, Jasmine.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  R\n",
      "2025-09-15 09:32:57 src.selection.data DEBUG    Options: Grape, Golf ball, Watermelon, Racket, Jasmine.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Water\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f71c08e5b10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 3 / 1024\n",
      "2025-09-15 09:33:01 src.selection.data DEBUG    Options: Horse, Anklet, Golf ball, Necklace, Cow.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Cow\n",
      "2025-09-15 09:33:01 src.selection.data DEBUG    Options: Monkey, Sheep, Charm, Pendant, Tennis ball.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Pendant\n",
      "2025-09-15 09:33:01 src.selection.data DEBUG    Options: Monkey, Sheep, Charm, Pendant, Tennis ball.\n",
      "What is the last animal in this list above?\n",
      "Answer: >>  Sheep\n",
      "sample 4 / 1024\n",
      "2025-09-15 09:33:04 src.selection.data DEBUG    Options: Lavender, Tulip, Gloves, Paperclip, Highlighter.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Highlight\n",
      "2025-09-15 09:33:05 src.selection.data DEBUG    Options: Folder, Tie, Calculator, Orchid, Iris.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Iris\n",
      "2025-09-15 09:33:05 src.selection.data DEBUG    Options: Folder, Tie, Calculator, Orchid, Iris.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Calculator\n",
      "2025-09-15 09:33:05 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tie', prob=0.28515625, logit=18.5, token_id=59825, metadata=None))[\" Tie\"] != 37128[\" Calculator\"]\n",
      "2025-09-15 09:33:05 src.selection.data DEBUG    Options: Marigold, Ruler, Scissors, Daffodil, Dresser.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Sc\n",
      "2025-09-15 09:33:05 src.selection.data DEBUG    Options: Tulip, Jasmine, Highlighter, Pen, Chair.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Jasmine\n",
      "2025-09-15 09:33:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Tul', prob=0.6171875, logit=19.625, token_id=43316, metadata=None))[\" Tul\"] != 82452[\" Jasmine\"]\n",
      "2025-09-15 09:33:06 src.selection.data DEBUG    Options: Peony, Tulip, House, Notebook, Folder.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Folder\n",
      "2025-09-15 09:33:06 src.selection.data DEBUG    Options: Sunflower, Stapler, Paperclip, Marigold, Mosque.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Mar\n",
      "2025-09-15 09:33:06 src.selection.data DEBUG    Options: Sunflower, Stapler, Paperclip, Marigold, Mosque.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Paper\n",
      "2025-09-15 09:33:06 src.selection.data ERROR    Prediction mismatch: (1, PredictedToken(token=' Stap', prob=0.447265625, logit=19.875, token_id=63606, metadata=None))[\" Stap\"] != 18343[\" Paper\"]\n",
      "2025-09-15 09:33:06 src.selection.data DEBUG    Options: Folder, Cow, Pencil, Chrysanthemum, Daffodil.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  P\n",
      "2025-09-15 09:33:06 src.selection.data DEBUG    Options: Paper, Iris, Eagle, Violet, Marker.\n",
      "What is the last flower in this list above?\n",
      "Answer: >>  Violet\n",
      "2025-09-15 09:33:06 src.selection.data DEBUG    Options: Paper, Iris, Eagle, Violet, Marker.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 1024\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(2, 6)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set):05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f6996a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select_one'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_task.task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f0bbe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:15 __main__ INFO     Found 511 sample files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 1024\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcc99542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Monitor, Keyboard, Notebook, Dog, Stapler.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Stap\n",
      "Options: Pencil, Eraser, Eagle, Headphones, Router.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Router\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9939, ' Er')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4077a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "from src.utils.typing import TokenizerOutput\n",
    "from src.functional import get_module_nnsight, PatchSpec, patch_with_baukit\n",
    "import baukit\n",
    "import types\n",
    "from src.hooking.llama_attention import LlamaAttentionPatcher\n",
    "from src.attention import visualize_attn_matrix\n",
    "from src.selection.data import SelectionSample, CountingSample\n",
    "from src.selection.data import get_options_for_answer\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def cache_q_projections(\n",
    "    mt: ModelandTokenizer,\n",
    "    input: TokenizerOutput,\n",
    "    heads: list[tuple[int, int]],  # (layer_idx, head_idx)\n",
    "    token_indices: list[list[int]],\n",
    "    return_output: bool = False,\n",
    "    projection_signature: str = \".q_proj\",\n",
    "):\n",
    "    batch_size = input.input_ids.shape[0]\n",
    "    assert len(token_indices) == batch_size, f\"{len(token_indices)=} != {batch_size=}\"\n",
    "    layer_to_head = {}\n",
    "    for layer_idx, head_idx in heads:\n",
    "        if layer_idx not in layer_to_head:\n",
    "            layer_to_head[layer_idx] = []\n",
    "        layer_to_head[layer_idx].append(head_idx)\n",
    "\n",
    "    seq_len = input.input_ids.shape[1]\n",
    "    n_heads = mt.config.num_attention_heads\n",
    "    # head_dim = mt.n_embd // n_heads\n",
    "    head_dim = get_module_nnsight(\n",
    "        mt._model, mt.attn_module_name_format.format(0)\n",
    "    ).head_dim\n",
    "    group_size = n_heads // mt.config.num_key_value_heads\n",
    "    q_module_projections_per_layer = {}\n",
    "    with mt.trace(input) as tracer:  # noqa\n",
    "        for layer_idx, head_indices in layer_to_head.items():\n",
    "            q_proj_name = (\n",
    "                mt.attn_module_name_format.format(layer_idx) + projection_signature\n",
    "            )\n",
    "            q_proj_module = get_module_nnsight(mt, q_proj_name)\n",
    "            q_module_projections_per_layer[q_proj_name] = q_proj_module.output.save()\n",
    "\n",
    "        if return_output:\n",
    "            output = mt.output.save()\n",
    "\n",
    "    q_projections = [{} for _ in range(batch_size)]\n",
    "    for layer_idx, head_indices in layer_to_head.items():\n",
    "        q_proj_name = (\n",
    "            mt.attn_module_name_format.format(layer_idx) + projection_signature\n",
    "        )\n",
    "        # print(q_proj_name)\n",
    "        q_proj_out = (\n",
    "            q_module_projections_per_layer[q_proj_name]\n",
    "            .view(batch_size, seq_len, -1, head_dim)\n",
    "            .transpose(1, 2)\n",
    "        )\n",
    "        if projection_signature in [\".k_proj\", \".v_proj\"] and group_size != 1:\n",
    "            q_proj_out = repeat_kv(q_proj_out, n_rep=group_size)\n",
    "        # print(q_proj_out.shape, q_proj_out.norm())\n",
    "        for prompt_idx in range(batch_size):\n",
    "            for head_idx in head_indices:\n",
    "                for token_idx in token_indices[prompt_idx]:\n",
    "                    q_projections[prompt_idx][(layer_idx, head_idx, token_idx)] = (\n",
    "                        q_proj_out[prompt_idx, head_idx, token_idx]\n",
    "                    )\n",
    "\n",
    "    if return_output:\n",
    "        return q_projections, output\n",
    "    return q_projections\n",
    "\n",
    "\n",
    "def locate_with_delim(prompt, option):\n",
    "    st = prompt.index(option)\n",
    "    return prompt[st : st + len(option) + 1]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_q_proj_ie_on_sample_pair(\n",
    "    mt: ModelandTokenizer,\n",
    "    clean_sample: SelectionSample | CountingSample,\n",
    "    patch_sample: SelectionSample | CountingSample,\n",
    "    heads: list[tuple[int, int]],\n",
    "    query_indices: dict[int, int] = {-1: -1},  # patch_idx -> clean_idx\n",
    "    verify_head_behavior_on: Optional[int] = None,\n",
    "    ablate_possible_ans_info_from_options: bool = False,\n",
    "    amplification_scale: float = 1.0,\n",
    "    must_track_tokens: list[int] = [],\n",
    "    patch_args: dict[str, Any] = {},\n",
    "):\n",
    "    clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "    patch_tokenized = prepare_input(prompts=patch_sample.prompt(), tokenizer=mt)\n",
    "    if patch_args.get(\"batch_size\", 1) > 1:\n",
    "        patch_samples = []\n",
    "        task = patch_args[\"task\"]\n",
    "        logger.debug(f\"Sampling {patch_args.get('batch_size', 1)} patch samples...\")\n",
    "        while len(patch_samples) < patch_args.get(\"batch_size\", 1):\n",
    "            obj_idx = len(patch_samples) % len(patch_sample.options)\n",
    "            if patch_args[\"distinct_options\"] is True:\n",
    "                sample = task.get_random_sample(\n",
    "                    mt=mt,\n",
    "                    category=patch_sample.category,\n",
    "                    prompt_template_idx=patch_args[\"prompt_template_idx\"],\n",
    "                    option_style=patch_args[\"option_style\"],\n",
    "                    filter_by_lm_prediction=True,\n",
    "                    # exclude_objs=[clean_sample.obj, patch_sample.obj],\n",
    "                    n_distractors=patch_args[\"n_distractors\"],\n",
    "                    obj_idx=obj_idx,\n",
    "                )\n",
    "            else:\n",
    "                sample = copy.deepcopy(patch_sample)\n",
    "                sample.options[obj_idx], sample.options[sample.obj_idx] = (\n",
    "                    sample.options[sample.obj_idx],\n",
    "                    sample.options[obj_idx],\n",
    "                )\n",
    "                sample.obj_idx = obj_idx\n",
    "                # random.shuffle(sample.options)\n",
    "            patch_samples.append(sample)\n",
    "        patch_tokenized_batch = prepare_input(\n",
    "            prompts=[sample.prompt() for sample in patch_samples], tokenizer=mt\n",
    "        )\n",
    "        logger.debug(f\"{patch_tokenized_batch.input_ids.shape}\")\n",
    "\n",
    "    if verify_head_behavior_on is not None:\n",
    "        logger.info(\"Verifying head behavior...\")\n",
    "\n",
    "        logger.info(f\"Clean Sample >> Ans: {mt.tokenizer.decode(clean_sample.ans_token_id)}\")\n",
    "        clean_attn_pattern = verify_head_patterns(  # noqa\n",
    "            prompt=clean_sample.prompt(),\n",
    "            tokenized_prompt=clean_tokenized,\n",
    "            options=(\n",
    "                [\n",
    "                    locate_with_delim(clean_sample.prompt(), opt)\n",
    "                    for opt in clean_sample.options\n",
    "                ]\n",
    "                if ablate_possible_ans_info_from_options\n",
    "                else clean_sample.options\n",
    "            ),\n",
    "            mt=mt,\n",
    "            heads=heads,\n",
    "            generate_full_answer=False,\n",
    "            query_index=verify_head_behavior_on,\n",
    "            ablate_possible_ans_info_from_options=ablate_possible_ans_info_from_options,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Patch Sample >> Ans: {mt.tokenizer.decode(patch_sample.ans_token_id)}\")\n",
    "        patch_attn_pattern = verify_head_patterns(  # noqa\n",
    "            prompt=patch_sample.prompt(),\n",
    "            tokenized_prompt=patch_tokenized,\n",
    "            options=(\n",
    "                [\n",
    "                    locate_with_delim(patch_sample.prompt(), opt)\n",
    "                    for opt in patch_sample.options\n",
    "                ]\n",
    "                if ablate_possible_ans_info_from_options\n",
    "                else patch_sample.options\n",
    "            ),\n",
    "            mt=mt,\n",
    "            heads=heads,\n",
    "            generate_full_answer=False,\n",
    "            query_index=verify_head_behavior_on,\n",
    "            ablate_possible_ans_info_from_options=ablate_possible_ans_info_from_options,\n",
    "        )\n",
    "\n",
    "    logger.info(f\"Caching the query states for the {len(heads)} heads\")\n",
    "\n",
    "    cached_q_states, patch_output = cache_q_projections(\n",
    "        mt=mt,\n",
    "        input=patch_tokenized,\n",
    "        heads=heads,\n",
    "        token_indices=[list(query_indices.keys())],\n",
    "        return_output=True,\n",
    "    )\n",
    "    if patch_args.get(\"batch_size\", 1) > 1:\n",
    "        cached_q_states = cache_q_projections(\n",
    "            mt=mt,\n",
    "            input=patch_tokenized_batch,\n",
    "            heads=heads,\n",
    "            token_indices=[list(query_indices.keys())]\n",
    "            * patch_args.get(\"batch_size\", 1),\n",
    "            return_output=False,\n",
    "        )\n",
    "        mean_q_states = {}\n",
    "        for prompt_idx in range(patch_args.get(\"batch_size\", 1)):\n",
    "            for key, value in cached_q_states[prompt_idx].items():\n",
    "                if key not in mean_q_states:\n",
    "                    mean_q_states[key] = []\n",
    "                mean_q_states[key].append(value)\n",
    "        for key, value in mean_q_states.items():\n",
    "            mean_q_states[key] = torch.mean(torch.stack(value), dim=0)\n",
    "        cached_q_states = [mean_q_states]\n",
    "\n",
    "    q_proj_patches = []\n",
    "    for (layer_idx, head_idx, patch_query_idx), q_proj in cached_q_states[0].items():\n",
    "        q_proj_patches.append(\n",
    "            PatchSpec(\n",
    "                location=(\n",
    "                    mt.attn_module_name_format.format(layer_idx) + \".q_proj\",\n",
    "                    head_idx,\n",
    "                    query_indices[patch_query_idx],\n",
    "                ),\n",
    "                patch=q_proj,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    patch_logits = patch_output.logits[:, -1, :].squeeze()\n",
    "    patch_predictions = interpret_logits(\n",
    "        tokenizer=mt,\n",
    "        logits=patch_logits,\n",
    "    )\n",
    "    logger.info(f\"patch_prediction={[str(pred) for pred in patch_predictions]}\")\n",
    "\n",
    "    # interested_tokens = [\n",
    "    #     patch_sample.ans_token_id,\n",
    "    #     clean_sample.ans_token_id,\n",
    "    #     clean_sample.metadata[\"track_type_obj_token_id\"],\n",
    "    # ]\n",
    "    interested_tokens = get_options_for_answer(sample=clean_sample)\n",
    "    interested_tokens = [\n",
    "        get_first_token_id(name=opt, tokenizer=mt.tokenizer, prefix=\" \")\n",
    "        for opt in interested_tokens\n",
    "    ]\n",
    "    # interested_tokens += [patch_sample.ans_token_id]\n",
    "    # interested_tokens = list(set(interested_tokens))  # remove duplicates #! don't need to, made sure during sampling\n",
    "\n",
    "    logger.info(\"clean run\")\n",
    "    clean_output = patch_with_baukit(\n",
    "        mt=mt,\n",
    "        inputs=clean_tokenized,\n",
    "        patches=[],\n",
    "    )\n",
    "    clean_logits = clean_output.logits[:, -1, :].squeeze()\n",
    "    clean_predictions, clean_track = interpret_logits(\n",
    "        tokenizer=mt,\n",
    "        logits=clean_logits,\n",
    "        interested_tokens=interested_tokens + must_track_tokens,\n",
    "    )\n",
    "    logger.info(f\"clean_prediction={[str(pred) for pred in clean_predictions]}\")\n",
    "    logger.info(f\"clean_track={clean_track}\")\n",
    "\n",
    "    logger.info(\"patching the q_proj states\")\n",
    "\n",
    "    if verify_head_behavior_on is not None and amplification_scale == 1.0:\n",
    "        int_attn_pattern = verify_head_patterns(\n",
    "            prompt=clean_sample.prompt(),\n",
    "            tokenized_prompt=clean_tokenized,\n",
    "            options=(\n",
    "                [\n",
    "                    locate_with_delim(clean_sample.prompt(), opt)\n",
    "                    for opt in clean_sample.options\n",
    "                ]\n",
    "                if ablate_possible_ans_info_from_options\n",
    "                else clean_sample.options   \n",
    "            ),\n",
    "            mt=mt,\n",
    "            heads=heads,\n",
    "            query_patches=q_proj_patches,\n",
    "            generate_full_answer=False,\n",
    "            query_index=verify_head_behavior_on,\n",
    "            ablate_possible_ans_info_from_options=ablate_possible_ans_info_from_options,\n",
    "        )\n",
    "        int_logits = int_attn_pattern[\"logits\"].squeeze()\n",
    "\n",
    "    else:\n",
    "        default_attn_implementation = mt.config._attn_implementation\n",
    "        if amplification_scale != 1.0:\n",
    "            mt.reset_forward()\n",
    "            mt.set_attn_implementation(\"sdpa\")\n",
    "\n",
    "            layers_to_heads = {}\n",
    "            for layer_idx, head_idx in heads:\n",
    "                if layer_idx not in layers_to_heads:\n",
    "                    layers_to_heads[layer_idx] = []\n",
    "                layers_to_heads[layer_idx].append(head_idx)\n",
    "\n",
    "            layers_to_q_patches = {}\n",
    "            for (\n",
    "                layer_idx,\n",
    "                head_idx,\n",
    "                patch_query_idx,\n",
    "            ), patch in cached_q_states[0].items():\n",
    "                if layer_idx not in layers_to_q_patches:\n",
    "                    layers_to_q_patches[layer_idx] = []\n",
    "                layers_to_q_patches[layer_idx].append(\n",
    "                    (head_idx, query_indices[patch_query_idx], patch)\n",
    "                )\n",
    "\n",
    "            attention_patterns = {}\n",
    "            head_contributions = {}\n",
    "            for layer_idx, head_indices in layers_to_heads.items():\n",
    "                attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "                attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "\n",
    "                attention_patterns[layer_idx] = {}\n",
    "                head_contributions[layer_idx] = {}\n",
    "\n",
    "                attn_block.forward = types.MethodType(\n",
    "                    LlamaAttentionPatcher(\n",
    "                        block_name=attn_block_name,\n",
    "                        save_attn_for=head_indices,\n",
    "                        store_attn_matrices=attention_patterns[layer_idx],\n",
    "                        store_head_contributions=head_contributions[layer_idx],\n",
    "                        query_patches=layers_to_q_patches[layer_idx],\n",
    "                        amplify_contributions=[\n",
    "                            (head_idx, q_idx, amplification_scale)\n",
    "                            for head_idx in head_indices\n",
    "                            for q_idx in query_indices.values()\n",
    "                        ],\n",
    "                        # value_weighted=True,\n",
    "                    ),\n",
    "                    attn_block,\n",
    "                )\n",
    "            patches = []  # already handled by hooking the default forward pass\n",
    "\n",
    "        else:\n",
    "            patches = q_proj_patches\n",
    "\n",
    "        if ablate_possible_ans_info_from_options:\n",
    "            patches.extend(\n",
    "                get_patches_to_verify_independent_enrichment(\n",
    "                    prompt=clean_sample.prompt(),\n",
    "                    options=clean_sample.options,\n",
    "                    pivot=clean_sample.subj,\n",
    "                    mt=mt,\n",
    "                    tokenized_prompt=clean_tokenized,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        int_out = patch_with_baukit(\n",
    "            mt=mt,\n",
    "            inputs=clean_tokenized,\n",
    "            patches=patches,\n",
    "        )\n",
    "        int_logits = int_out.logits[:, -1, :].squeeze()\n",
    "\n",
    "        if amplification_scale != 1.0:\n",
    "            mt.reset_forward()\n",
    "            mt.set_attn_implementation(default_attn_implementation)\n",
    "\n",
    "            if verify_head_behavior_on is not None:\n",
    "                attn_matrix = []\n",
    "                for layer_idx in attention_patterns:\n",
    "                    for head_idx in attention_patterns[layer_idx]:\n",
    "                        attn_matrix.append(\n",
    "                            attention_patterns[layer_idx][head_idx].cpu()\n",
    "                        )\n",
    "\n",
    "                attn_matrix = torch.stack(attn_matrix).squeeze()\n",
    "                if attn_matrix.dim() == 3:\n",
    "                    attn_matrix = attn_matrix.mean(dim=0)\n",
    "\n",
    "                visualize_attn_matrix(\n",
    "                    attn_matrix=attn_matrix,\n",
    "                    tokens=[\n",
    "                        mt.tokenizer.decode(t) for t in clean_tokenized[\"input_ids\"][0]\n",
    "                    ],\n",
    "                )\n",
    "\n",
    "    int_predictions, int_track = interpret_logits(\n",
    "        tokenizer=mt,\n",
    "        logits=int_logits,\n",
    "        interested_tokens=interested_tokens + must_track_tokens,\n",
    "    )\n",
    "    logger.info(f\"int_prediction={[str(pred) for pred in int_predictions]}\")\n",
    "    logger.info(f\"int_track={int_track}\")\n",
    "\n",
    "    return {\n",
    "        \"clean_sample\": clean_sample,\n",
    "        \"patch_sample\": patch_sample,\n",
    "        \"clean_predictions\": clean_predictions,\n",
    "        \"patch_predictions\": patch_predictions,\n",
    "        \"int_predictions\": int_predictions,\n",
    "        \"clean_track\": clean_track,\n",
    "        \"int_track\": int_track,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efb29ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_attn = set(optimized_heads) - set(heads_max_ie)\n",
    "# no_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d041d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Cedar, Wardrobe, Cufflink, Hickory, Anklet.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Ank\n",
      "Options: Elm, Palm, Pendant, Locket, Sofa.\n",
      "What is the last tree in this list above?\n",
      "Answer: >>  Palm\n",
      "2025-09-15 09:35:40 src.selection.optimization INFO     Verifying head behavior...\n",
      "2025-09-15 09:35:40 src.selection.optimization INFO     Clean Sample >> Ans:  Ank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:46 src.selection.functional DEBUG    Generated full answer: \" Anklet.\n",
      "Explanation: The last jewelry in the list above is an Anklet. An anklet is a type of jewelry that is worn around the\"\n",
      "2025-09-15 09:35:46 src.selection.functional DEBUG    Predictions: ['\" Ank\"[57915] (p=0.762, logit=19.250)', '\" The\"[578] (p=0.055, logit=16.625)', '\" C\"[356] (p=0.043, logit=16.375)', '\" ank\"[71572] (p=0.017, logit=15.438)', '\" An\"[1556] (p=0.017, logit=15.438)']\n",
      "2025-09-15 09:35:46 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-0aa9bce2-96ee\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-0aa9bce2-96ee\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Cedar\", \",\", \" Ward\", \"robe\", \",\", \" C\", \"uff\", \"link\", \",\", \" Hick\", \"ory\", \",\", \" Ank\", \"let\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" jewelry\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.02052355371415615, 0.0031737193930894136, 0.0037704540882259607, 0.004170176573097706, 0.0032184456940740347, 0.004792237654328346, 0.010228748433291912, 0.0037531559355556965, 0.013445673510432243, 0.0282120518386364, 0.03138646110892296, 0.005124792456626892, 0.008699417114257812, 0.012344191782176495, 0.025163432583212852, 0.12292108684778214, 0.022792913019657135, 0.009730713441967964, 0.005091315601021051, 0.012033679522573948, 0.015233896672725677, 0.0706203281879425, 0.04123967885971069, 0.003722989000380039, 0.01755600981414318, 0.008653040044009686, 0.040611617267131805, 0.015523497015237808, 0.06908619403839111]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa671688bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:46 src.selection.optimization INFO     Patch Sample >> Ans:  Palm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:52 src.selection.functional DEBUG    Generated full answer: \" Palm.\n",
      "The last tree in the list is the Palm tree. The other options are not trees: Elm is a type of tree, but it's\"\n",
      "2025-09-15 09:35:52 src.selection.functional DEBUG    Predictions: ['\" Palm\"[33578] (p=0.730, logit=19.375)', '\" Elm\"[65329] (p=0.053, logit=16.750)', '\" The\"[578] (p=0.047, logit=16.625)', '\" Pendant\"[81501] (p=0.022, logit=15.875)', '\" L\"[445] (p=0.021, logit=15.812)']\n",
      "2025-09-15 09:35:52 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-69199b71-cd02\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-69199b71-cd02\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Elm\", \",\", \" Palm\", \",\", \" Pendant\", \",\", \" L\", \"ocket\", \",\", \" Sofa\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" tree\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.02382712997496128, 0.004284424241632223, 0.02139805629849434, 0.03085264377295971, 0.050616685301065445, 0.024256307631731033, 0.02583351545035839, 0.02000473067164421, 0.0223916694521904, 0.01987721025943756, 0.014998472295701504, 0.030062904581427574, 0.02183465100824833, 0.006253773812204599, 0.00457355659455061, 0.015192683786153793, 0.014784414321184158, 0.08953548222780228, 0.01869814842939377, 0.006696996744722128, 0.022464090958237648, 0.013211308047175407, 0.045611899346113205, 0.011758273467421532, 0.06791011244058609]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa659920f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:35:53 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.730, logit=19.375)', '\" Elm\"[65329] (p=0.053, logit=16.750)', '\" The\"[578] (p=0.047, logit=16.625)', '\" Pendant\"[81501] (p=0.022, logit=15.875)', '\" L\"[445] (p=0.021, logit=15.812)']\n",
      "2025-09-15 09:35:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:35:53 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.762, logit=19.250)', '\" The\"[578] (p=0.055, logit=16.625)', '\" C\"[356] (p=0.043, logit=16.375)', '\" ank\"[71572] (p=0.017, logit=15.438)', '\" An\"[1556] (p=0.017, logit=15.438)']\n",
      "2025-09-15 09:35:53 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.76171875, logit=19.25, token_id=57915, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.04296875, logit=16.375, token_id=356, metadata=None))), (79028, (7, PredictedToken(token=' Hick', prob=0.00848388671875, logit=14.75, token_id=79028, metadata=None))), (27738, (25, PredictedToken(token=' Ward', prob=0.00078582763671875, logit=12.375, token_id=27738, metadata=None))), (57748, (29, PredictedToken(token=' Cedar', prob=0.000614166259765625, logit=12.125, token_id=57748, metadata=None)))])\n",
      "2025-09-15 09:35:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:35:53 src.selection.functional DEBUG    Predictions: ['\" Hick\"[79028] (p=0.586, logit=18.250)', '\" The\"[578] (p=0.070, logit=16.125)', '\" Ank\"[57915] (p=0.058, logit=15.938)', '\" C\"[356] (p=0.045, logit=15.688)', '\" None\"[2290] (p=0.033, logit=15.375)']\n",
      "2025-09-15 09:35:53 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cd1538bc-5939\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cd1538bc-5939\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Cedar\", \",\", \" Ward\", \"robe\", \",\", \" C\", \"uff\", \"link\", \",\", \" Hick\", \"ory\", \",\", \" Ank\", \"let\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" jewelry\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.025051793083548546, 0.004262392874807119, 0.017865151166915894, 0.01448411587625742, 0.012872155755758286, 0.011631832458078861, 0.03179439157247543, 0.014126330614089966, 0.012260605581104755, 0.012218439020216465, 0.027318350970745087, 0.024927429854869843, 0.05006640404462814, 0.03360728919506073, 0.013618928380310535, 0.01851353980600834, 0.0219044741243124, 0.011492089368402958, 0.004877862986177206, 0.017978861927986145, 0.01861712336540222, 0.03850599378347397, 0.03206639364361763, 0.006084541790187359, 0.02084110677242279, 0.011873305775225163, 0.03228069096803665, 0.010193063877522945, 0.04563796520233154]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa7491a4890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:35:53 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.586, logit=18.250)', '\" The\"[578] (p=0.070, logit=16.125)', '\" Ank\"[57915] (p=0.058, logit=15.938)', '\" C\"[356] (p=0.045, logit=15.688)', '\" None\"[2290] (p=0.033, logit=15.375)']\n",
      "2025-09-15 09:35:53 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.5859375, logit=18.25, token_id=79028, metadata=None))), (57915, (3, PredictedToken(token=' Ank', prob=0.05810546875, logit=15.9375, token_id=57915, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.045166015625, logit=15.6875, token_id=356, metadata=None))), (27738, (6, PredictedToken(token=' Ward', prob=0.0291748046875, logit=15.25, token_id=27738, metadata=None))), (57748, (7, PredictedToken(token=' Cedar', prob=0.0274658203125, logit=15.1875, token_id=57748, metadata=None)))])\n",
      "2025-09-15 09:35:53 __main__ DEBUG    clean obj:  Ank\n",
      "2025-09-15 09:35:53 __main__ DEBUG    target obj:  Hick\n",
      "2025-09-15 09:35:53 __main__ INFO     Clean Prediction Rank Change: 1 -> 3 | Delta: 2 \n",
      "2025-09-15 09:35:53 __main__ INFO     Target Prediction Rank Change: 7 -> 1 | Delta: -6 \n",
      "2025-09-15 09:35:53 __main__ INFO     Clean Prediction Logit Change: 19.2500 -> 15.9375 | Delta: -3.3125 \n",
      "2025-09-15 09:35:53 __main__ INFO     Target Prediction Logit Change: 14.7500 -> 18.2500 | Delta: 3.5000 \n"
     ]
    }
   ],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = copy.deepcopy(validation_set[15])\n",
    "# clean.default_option_style=\"numbered\"\n",
    "# patch.default_option_style=\"numbered\"\n",
    "# clean, patch = train_set[18]\n",
    "\n",
    "# clean, patch = copy.deepcopy(clean_sample), copy.deepcopy(patch_sample)\n",
    "\n",
    "# failed_case = failed_cases[27]\n",
    "# clean = failed_case[\"clean_sample\"]\n",
    "# patch = failed_case[\"patch_sample\"]\n",
    "\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "\n",
    "mt.set_attn_implementation(\"eager\")\n",
    "mt.reset_forward()\n",
    "\n",
    "validation_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    # heads=sorted(heads_max_ie),\n",
    "    # heads=sorted(list(no_attn)),\n",
    "    # heads=sorted(qwen_32_heads, key=lambda x: (x[0], x[1])),\n",
    "    # heads=sorted(heads_attn_behavior, key=lambda x: (x[0], x[1])),\n",
    "    # heads=[(35, 19)],\n",
    "    # query_indices={\n",
    "    #     patch.metadata[\"ques_pos\"]: clean.metadata[\"ques_pos\"],\n",
    "    #     -2: -2,\n",
    "    #     -1: -1,\n",
    "    # },\n",
    "    query_indices={tok_idx: tok_idx for tok_idx in range(-10, 0)},\n",
    "    # verify_head_behavior_on=clean.metadata[\"ques_pos\"]\n",
    "    verify_head_behavior_on=-1,\n",
    "    # ablate_possible_ans_info_from_options=True,\n",
    "    # amplification_scale=2.0\n",
    "    # patch_args={\n",
    "    #     \"batch_size\": N_DISTRACTORS + 1,\n",
    "    #     \"task\": select_task,\n",
    "    #     \"prompt_template_idx\": prompt_template_idx,\n",
    "    #     \"option_style\": patch.default_option_style,\n",
    "    #     \"distinct_options\": False,\n",
    "    #     \"n_distractors\": N_DISTRACTORS,\n",
    "    # },\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": validation_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": validation_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": validation_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": validation_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": validation_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": validation_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": validation_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": validation_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80bf8527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boat', 'Watermelon', 'Blueberry', 'Bus', 'Helmet']\n",
      "Options: Boat, Watermelon, Blueberry, Bus, Helmet.\n",
      "What is the last vehicle in this list above?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(clean_sample.options)\n",
    "print(clean_sample.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "053091bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.selection.functional import cache_q_projections, verify_head_patterns\n",
    "# from typing import Literal\n",
    "# from src.functional import PatchSpec, interpret_logits\n",
    "# from src.hooking.llama_attention import LlamaAttentionPatcher\n",
    "# import baukit\n",
    "# import types\n",
    "\n",
    "\n",
    "# def set_attn_implementation(mt, attn_implementation: Literal[\"sdpa\", \"eager\"]):\n",
    "#     mt.config._attn_implementation = attn_implementation\n",
    "#     for layer_idx in range(mt.config.num_hidden_layers):\n",
    "#         attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "#         attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "#         attn_block.config._attn_implementation = attn_implementation\n",
    "\n",
    "\n",
    "# ##########################################################\n",
    "# query_indices = [-3, -2, -1]\n",
    "# heads = optimized_heads\n",
    "# ##########################################################\n",
    "\n",
    "# mt.reset_forward()\n",
    "# set_attn_implementation(mt, \"eager\")\n",
    "\n",
    "# clean_sample = failed_case[\"clean_sample\"]\n",
    "# patch_sample = failed_case[\"patch_sample\"]\n",
    "\n",
    "# clean_tokenized = prepare_input(prompts=clean_sample.prompt(), tokenizer=mt)\n",
    "# patch_tokenized = prepare_input(prompts=patch_sample.prompt(), tokenizer=mt)\n",
    "\n",
    "# verify_head_patterns(\n",
    "#     prompt=patch_sample.prompt(),\n",
    "#     tokenized_prompt=patch_tokenized,\n",
    "#     pivot=patch_sample.subj,\n",
    "#     options=patch_sample.options,\n",
    "#     mt=mt,\n",
    "#     heads=heads,\n",
    "#     query_index=-1,\n",
    "# )\n",
    "\n",
    "# verify_head_patterns(\n",
    "#     prompt=clean_sample.prompt(),\n",
    "#     tokenized_prompt=clean_tokenized,\n",
    "#     pivot=clean_sample.subj,\n",
    "#     options=clean_sample.options,\n",
    "#     mt=mt,\n",
    "#     heads=heads,\n",
    "#     query_index=-1,\n",
    "# )\n",
    "\n",
    "# query_locations = [\n",
    "#     (layer_idx, head_idx, query_idx)\n",
    "#     for layer_idx, head_idx in heads\n",
    "#     for query_idx in query_indices\n",
    "# ]\n",
    "\n",
    "# cached_q_states, patch_output = cache_q_projections(\n",
    "#     mt=mt,\n",
    "#     input=patch_tokenized,\n",
    "#     query_locations=query_locations,\n",
    "#     return_output=True,\n",
    "# )\n",
    "# q_proj_patches = []\n",
    "# for (layer_idx, head_idx, query_idx), q_proj in cached_q_states.items():\n",
    "#     q_proj_patches.append(\n",
    "#         PatchSpec(\n",
    "#             location=(\n",
    "#                 mt.attn_module_name_format.format(layer_idx) + \".q_proj\",\n",
    "#                 head_idx,\n",
    "#                 query_idx,\n",
    "#             ),\n",
    "#             patch=q_proj,\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# patch_logits = patch_output.logits[:, -1, :].squeeze()\n",
    "# patch_predictions = interpret_logits(\n",
    "#     tokenizer=mt,\n",
    "#     logits=patch_logits,\n",
    "# )\n",
    "# logger.info(f\"patch_prediction={[str(pred) for pred in patch_predictions]}\")\n",
    "\n",
    "\n",
    "# mt.reset_forward()\n",
    "# set_attn_implementation(mt, \"sdpa\")\n",
    "\n",
    "# layers_to_heads = {}\n",
    "# for layer_idx, head_idx in heads:\n",
    "#     if layer_idx not in layers_to_heads:\n",
    "#         layers_to_heads[layer_idx] = []\n",
    "#     layers_to_heads[layer_idx].append(head_idx)\n",
    "\n",
    "# layers_to_q_patches = {}\n",
    "# for (layer_idx, head_idx, query_idx), patch in cached_q_states.items():\n",
    "#     if layer_idx not in layers_to_q_patches:\n",
    "#         layers_to_q_patches[layer_idx] = []\n",
    "#     layers_to_q_patches[layer_idx].append((head_idx, query_idx, patch))\n",
    "\n",
    "# attention_patterns = {}\n",
    "# head_contributions = {}\n",
    "# for layer_idx, head_indices in layers_to_heads.items():\n",
    "#     attn_block_name = mt.attn_module_name_format.format(layer_idx)\n",
    "#     attn_block = baukit.get_module(mt._model, attn_block_name)\n",
    "\n",
    "#     attention_patterns[layer_idx] = {}\n",
    "#     head_contributions[layer_idx] = {}\n",
    "\n",
    "#     attn_block.forward = types.MethodType(\n",
    "#         LlamaAttentionPatcher(\n",
    "#             block_name=attn_block_name,\n",
    "#             save_attn_for=head_indices,\n",
    "#             store_attn_matrices=attention_patterns[layer_idx],\n",
    "#             store_head_contributions=head_contributions[layer_idx],\n",
    "#             query_patches=layers_to_q_patches[layer_idx],\n",
    "#             amplify_contributions=[\n",
    "#                 (head_idx, q_idx, 2.0)\n",
    "#                 for head_idx in head_indices\n",
    "#                 for q_idx in query_indices\n",
    "#             ],\n",
    "#             # value_weighted=True,\n",
    "#         ),\n",
    "#         attn_block,\n",
    "#     )\n",
    "\n",
    "\n",
    "# output = mt._model(**clean_tokenized)\n",
    "# int_logits = output.logits[:, -1, :].squeeze()\n",
    "# int_pred = interpret_logits(\n",
    "#     tokenizer=mt,\n",
    "#     logits=int_logits,\n",
    "# )\n",
    "\n",
    "# logger.info(f\"int_prediction={[str(pred) for pred in int_pred]}\")\n",
    "\n",
    "# mt.reset_forward()\n",
    "# set_attn_implementation(mt, \"eager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c8e8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.selection.functional import visualize_attn_matrix\n",
    "\n",
    "# attn_matrix = []\n",
    "# for layer_idx in attention_patterns:\n",
    "#     for head_idx in attention_patterns[layer_idx]:\n",
    "#         attn_matrix.append(attention_patterns[layer_idx][head_idx].cpu())\n",
    "# attn_matrix = torch.stack(attn_matrix).squeeze().mean(dim=0)\n",
    "\n",
    "# visualize_attn_matrix(\n",
    "#     attn_matrix = attn_matrix,\n",
    "#     tokens = [mt.tokenizer.decode(t) for t in clean_tokenized[\"input_ids\"][0]]\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45c65ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_per_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# heads_attn_behavior\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# for layer_idx, head_idx, score in scores_per_head[:79]:\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     print(f\"Layer {layer_idx}, Head {head_idx}: {score:.4f}\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#     for layer_idx, head_idx, score in scores_per_head[:79]\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[32m     10\u001b[39m heads_max_ie = []\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, head_idx, score \u001b[38;5;129;01min\u001b[39;00m \u001b[43mscores_per_head\u001b[49m:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m layer_idx < \u001b[32m55\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m layer_idx > \u001b[32m25\u001b[39m:\n\u001b[32m     13\u001b[39m         heads_max_ie.append((layer_idx, head_idx))\n",
      "\u001b[31mNameError\u001b[39m: name 'scores_per_head' is not defined"
     ]
    }
   ],
   "source": [
    "# heads_attn_behavior\n",
    "# for layer_idx, head_idx, score in scores_per_head[:79]:\n",
    "#     print(f\"Layer {layer_idx}, Head {head_idx}: {score:.4f}\")\n",
    "\n",
    "# heads_max_ie = [\n",
    "#     (layer_idx, head_idx)\n",
    "#     for layer_idx, head_idx, score in scores_per_head[:79]\n",
    "# ]\n",
    "\n",
    "heads_max_ie = []\n",
    "for layer_idx, head_idx, score in scores_per_head:\n",
    "    if layer_idx < 55 and layer_idx > 25:\n",
    "        heads_max_ie.append((layer_idx, head_idx))\n",
    "    if len(heads_max_ie) >= 80:\n",
    "        break\n",
    "\n",
    "heads_max_ie = sorted(heads_max_ie, key=lambda x: (x[0], x[1]))\n",
    "len(heads_max_ie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65931db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f33d8bb59d4baf974fc7f5cd6d4c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/511 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:36:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-15 09:36:45 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:36:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.828, logit=20.125)', '\" The\"[578] (p=0.041, logit=17.125)', '\" Boxing\"[72683] (p=0.025, logit=16.625)', '\" Basketball\"[47589] (p=0.015, logit=16.125)', '\" SOCK\"[35651] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.773, logit=19.875)', '\" The\"[578] (p=0.092, logit=17.750)', '\" Tennis\"[58251] (p=0.049, logit=17.125)', '\" A\"[362] (p=0.014, logit=15.875)', '\" It\"[1102] (p=0.009, logit=15.438)']\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.7734375, logit=19.875, token_id=432, metadata=None))), (58251, (3, PredictedToken(token=' Tennis', prob=0.04931640625, logit=17.125, token_id=58251, metadata=None))), (67553, (17, PredictedToken(token=' Pants', prob=0.0012359619140625, logit=13.4375, token_id=67553, metadata=None))), (33711, (20, PredictedToken(token=' Suit', prob=0.0010223388671875, logit=13.25, token_id=33711, metadata=None)))])\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.758, logit=19.250)', '\" The\"[578] (p=0.055, logit=16.625)', '\" R\"[432] (p=0.049, logit=16.500)', '\" Tennis\"[58251] (p=0.029, logit=16.000)', '\" None\"[2290] (p=0.023, logit=15.750)']\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.7578125, logit=19.25, token_id=67553, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.048583984375, logit=16.5, token_id=432, metadata=None))), (58251, (4, PredictedToken(token=' Tennis', prob=0.0294189453125, logit=16.0, token_id=58251, metadata=None))), (33711, (6, PredictedToken(token=' Suit', prob=0.0074462890625, logit=14.625, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:46 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:36:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.660, logit=20.500)', '\" E\"[469] (p=0.214, logit=19.375)', '\" The\"[578] (p=0.054, logit=18.000)', '\" Tooth\"[83499] (p=0.008, logit=16.125)', '\" A\"[362] (p=0.007, logit=16.000)']\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.699, logit=20.125)', '\" Let\"[6914] (p=0.095, logit=18.125)', '\" The\"[578] (p=0.095, logit=18.125)', '\" There\"[2684] (p=0.024, logit=16.750)', '\" None\"[2290] (p=0.013, logit=16.125)']\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.69921875, logit=20.125, token_id=356, metadata=None))), (6914, (3, PredictedToken(token=' Let', prob=0.0947265625, logit=18.125, token_id=6914, metadata=None))), (23126, (6, PredictedToken(token=' Ti', prob=0.00933837890625, logit=15.8125, token_id=23126, metadata=None))), (57915, (12, PredictedToken(token=' Ank', prob=0.002227783203125, logit=14.375, token_id=57915, metadata=None))), (82994, (20, PredictedToken(token=' Toilet', prob=0.000926971435546875, logit=13.5, token_id=82994, metadata=None)))])\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     int_prediction=['\" Ank\"[57915] (p=0.488, logit=19.250)', '\" Ti\"[23126] (p=0.297, logit=18.750)', '\" The\"[578] (p=0.075, logit=17.375)', '\" Let\"[6914] (p=0.019, logit=16.000)', '\" C\"[356] (p=0.018, logit=15.938)']\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     int_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.48828125, logit=19.25, token_id=57915, metadata=None))), (23126, (2, PredictedToken(token=' Ti', prob=0.296875, logit=18.75, token_id=23126, metadata=None))), (6914, (4, PredictedToken(token=' Let', prob=0.0189208984375, logit=16.0, token_id=6914, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.017822265625, logit=15.9375, token_id=356, metadata=None))), (82994, (17, PredictedToken(token=' Toilet', prob=0.00146484375, logit=13.4375, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:47 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:36:47 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.711, logit=20.625)', '\" The\"[578] (p=0.204, logit=19.375)', '\" A\"[362] (p=0.010, logit=16.375)', '\" There\"[2684] (p=0.009, logit=16.250)', '\" xy\"[31884] (p=0.007, logit=15.938)']\n",
      "2025-09-15 09:36:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.467, logit=19.625)', '\" Skate\"[97796] (p=0.220, logit=18.875)', '\" The\"[578] (p=0.172, logit=18.625)', '\" There\"[2684] (p=0.023, logit=16.625)', '\" A\"[362] (p=0.016, logit=16.250)']\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.466796875, logit=19.625, token_id=67629, metadata=None))), (97796, (2, PredictedToken(token=' Skate', prob=0.2197265625, logit=18.875, token_id=97796, metadata=None))), (90538, (55, PredictedToken(token=' Caul', prob=0.0002918243408203125, logit=12.25, token_id=90538, metadata=None))), (46506, (57, PredictedToken(token=' Drum', prob=0.000274658203125, logit=12.1875, token_id=46506, metadata=None))), (56491, (81, PredictedToken(token=' Piano', prob=0.0001468658447265625, logit=11.5625, token_id=56491, metadata=None))), (66821, (131, PredictedToken(token=' Iris', prob=5.745887756347656e-05, logit=10.625, token_id=66821, metadata=None)))])\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.361, logit=18.750)', '\" Drum\"[46506] (p=0.171, logit=18.000)', '\" The\"[578] (p=0.171, logit=18.000)', '\" There\"[2684] (p=0.055, logit=16.875)', '\" None\"[2290] (p=0.049, logit=16.750)']\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.361328125, logit=18.75, token_id=56491, metadata=None))), (46506, (3, PredictedToken(token=' Drum', prob=0.1708984375, logit=18.0, token_id=46506, metadata=None))), (97796, (6, PredictedToken(token=' Skate', prob=0.043212890625, logit=16.625, token_id=97796, metadata=None))), (67629, (8, PredictedToken(token=' Helmet', prob=0.0115966796875, logit=15.3125, token_id=67629, metadata=None))), (66821, (12, PredictedToken(token=' Iris', prob=0.005157470703125, logit=14.5, token_id=66821, metadata=None))), (90538, (21, PredictedToken(token=' Caul', prob=0.00244140625, logit=13.75, token_id=90538, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:48 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.773, logit=20.125)', '\" The\"[578] (p=0.092, logit=18.000)', '\" A\"[362] (p=0.030, logit=16.875)', '\" Monitor\"[24423] (p=0.023, logit=16.625)', '\" ST\"[4015] (p=0.014, logit=16.125)']\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     clean_prediction=['\" Router\"[10777] (p=0.668, logit=19.750)', '\" Head\"[11452] (p=0.116, logit=18.000)', '\" The\"[578] (p=0.102, logit=17.875)', '\" There\"[2684] (p=0.010, logit=15.562)', '\" ROUT\"[54281] (p=0.010, logit=15.500)']\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     clean_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.66796875, logit=19.75, token_id=10777, metadata=None))), (11452, (2, PredictedToken(token=' Head', prob=0.11572265625, logit=18.0, token_id=11452, metadata=None))), (393, (14, PredictedToken(token=' P', prob=0.0025634765625, logit=14.1875, token_id=393, metadata=None))), (36895, (27, PredictedToken(token=' Eagle', prob=0.00083160400390625, logit=13.0625, token_id=36895, metadata=None))), (9939, (86, PredictedToken(token=' Er', prob=0.00011968612670898438, logit=11.125, token_id=9939, metadata=None)))])\n",
      "2025-09-15 09:36:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:49 src.selection.optimization INFO     int_prediction=['\" Er\"[9939] (p=0.629, logit=19.500)', '\" Router\"[10777] (p=0.124, logit=17.875)', '\" P\"[393] (p=0.085, logit=17.500)', '\" The\"[578] (p=0.052, logit=17.000)', '\" ER\"[27590] (p=0.013, logit=15.625)']\n",
      "2025-09-15 09:36:49 src.selection.optimization INFO     int_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.62890625, logit=19.5, token_id=9939, metadata=None))), (10777, (2, PredictedToken(token=' Router', prob=0.1240234375, logit=17.875, token_id=10777, metadata=None))), (393, (3, PredictedToken(token=' P', prob=0.08544921875, logit=17.5, token_id=393, metadata=None))), (36895, (20, PredictedToken(token=' Eagle', prob=0.00138092041015625, logit=13.375, token_id=36895, metadata=None))), (11452, (24, PredictedToken(token=' Head', prob=0.00121307373046875, logit=13.25, token_id=11452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:36:49 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:36:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:49 src.selection.optimization INFO     patch_prediction=['\" Raspberry\"[48665] (p=0.863, logit=20.500)', '\" Water\"[10164] (p=0.026, logit=17.000)', '\" R\"[432] (p=0.023, logit=16.875)', '\" The\"[578] (p=0.020, logit=16.750)', '\" There\"[2684] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:36:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:50 src.selection.optimization INFO     clean_prediction=['\" Har\"[5340] (p=0.707, logit=20.375)', '\" The\"[578] (p=0.123, logit=18.625)', '\" Uk\"[60413] (p=0.084, logit=18.250)', '\" HAR\"[87588] (p=0.011, logit=16.250)', '\" H\"[473] (p=0.007, logit=15.812)']\n",
      "2025-09-15 09:36:50 src.selection.optimization INFO     clean_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.70703125, logit=20.375, token_id=5340, metadata=None))), (60413, (3, PredictedToken(token=' Uk', prob=0.08447265625, logit=18.25, token_id=60413, metadata=None))), (32498, (12, PredictedToken(token=' Mall', prob=0.002716064453125, logit=14.8125, token_id=32498, metadata=None))), (76924, (120, PredictedToken(token=' Banana', prob=3.886222839355469e-05, logit=10.5625, token_id=76924, metadata=None))), (65329, (249, PredictedToken(token=' Elm', prob=9.775161743164062e-06, logit=9.1875, token_id=65329, metadata=None))), (64695, (423, PredictedToken(token=' Peach', prob=4.351139068603516e-06, logit=8.375, token_id=64695, metadata=None)))])\n",
      "2025-09-15 09:36:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:50 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.742, logit=20.875)', '\" Banana\"[76924] (p=0.114, logit=19.000)', '\" Uk\"[60413] (p=0.078, logit=18.625)', '\" The\"[578] (p=0.029, logit=17.625)', '\" PE\"[22557] (p=0.005, logit=15.938)']\n",
      "2025-09-15 09:36:50 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.7421875, logit=20.875, token_id=64695, metadata=None))), (76924, (2, PredictedToken(token=' Banana', prob=0.11376953125, logit=19.0, token_id=76924, metadata=None))), (60413, (3, PredictedToken(token=' Uk', prob=0.078125, logit=18.625, token_id=60413, metadata=None))), (32498, (42, PredictedToken(token=' Mall', prob=0.00011730194091796875, logit=12.125, token_id=32498, metadata=None))), (65329, (61, PredictedToken(token=' Elm', prob=5.91278076171875e-05, logit=11.4375, token_id=65329, metadata=None))), (5340, (71, PredictedToken(token=' Har', prob=4.601478576660156e-05, logit=11.1875, token_id=5340, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:50 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:36:50 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:36:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.672, logit=20.750)', '\" Monkey\"[58937] (p=0.218, logit=19.625)', '\" The\"[578] (p=0.055, logit=18.250)', '\" There\"[2684] (p=0.008, logit=16.375)', '\" MON\"[29637] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     clean_prediction=['\" Orange\"[22725] (p=0.871, logit=21.625)', '\" The\"[578] (p=0.056, logit=18.875)', '\" OR\"[2794] (p=0.018, logit=17.750)', '\" There\"[2684] (p=0.010, logit=17.125)', '\" Blue\"[8868] (p=0.008, logit=16.875)']\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     clean_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.87109375, logit=21.625, token_id=22725, metadata=None))), (8868, (5, PredictedToken(token=' Blue', prob=0.007537841796875, logit=16.875, token_id=8868, metadata=None))), (1630, (13, PredictedToken(token=' X', prob=0.0012359619140625, logit=15.0625, token_id=1630, metadata=None))), (15429, (20, PredictedToken(token=' Hospital', prob=0.0004825592041015625, logit=14.125, token_id=15429, metadata=None))), (24941, (30, PredictedToken(token=' Bear', prob=0.00022792816162109375, logit=13.375, token_id=24941, metadata=None))), (14588, (54, PredictedToken(token=' Dog', prob=8.916854858398438e-05, logit=12.4375, token_id=14588, metadata=None)))])\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.605, logit=20.750)', '\" Dog\"[14588] (p=0.254, logit=19.875)', '\" The\"[578] (p=0.072, logit=18.625)', '\" A\"[362] (p=0.011, logit=16.750)', '\" There\"[2684] (p=0.010, logit=16.625)']\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.60546875, logit=20.75, token_id=24941, metadata=None))), (14588, (2, PredictedToken(token=' Dog', prob=0.25390625, logit=19.875, token_id=14588, metadata=None))), (22725, (20, PredictedToken(token=' Orange', prob=0.000553131103515625, logit=13.75, token_id=22725, metadata=None))), (8868, (23, PredictedToken(token=' Blue', prob=0.000431060791015625, logit=13.5, token_id=8868, metadata=None))), (1630, (42, PredictedToken(token=' X', prob=0.00019168853759765625, logit=12.6875, token_id=1630, metadata=None))), (15429, (47, PredictedToken(token=' Hospital', prob=0.0001583099365234375, logit=12.5, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:36:51 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:36:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.887, logit=21.375)', '\" Sc\"[2522] (p=0.039, logit=18.250)', '\" The\"[578] (p=0.039, logit=18.250)', '\" There\"[2684] (p=0.005, logit=16.250)', '\" None\"[2290] (p=0.005, logit=16.125)']\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.805, logit=20.875)', '\" The\"[578] (p=0.096, logit=18.750)', '\" PL\"[10528] (p=0.045, logit=18.000)', '\" There\"[2684] (p=0.010, logit=16.500)', '\" Grape\"[80629] (p=0.009, logit=16.375)']\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.8046875, logit=20.875, token_id=84409, metadata=None))), (80629, (5, PredictedToken(token=' Grape', prob=0.0089111328125, logit=16.375, token_id=80629, metadata=None))), (65197, (22, PredictedToken(token=' Surf', prob=0.0003681182861328125, logit=13.1875, token_id=65197, metadata=None))), (100031, (89, PredictedToken(token=' Mosque', prob=4.982948303222656e-05, logit=11.1875, token_id=100031, metadata=None))), (18343, (102, PredictedToken(token=' Paper', prob=3.647804260253906e-05, logit=10.875, token_id=18343, metadata=None))), (63606, (141, PredictedToken(token=' Stap', prob=2.2172927856445312e-05, logit=10.375, token_id=63606, metadata=None)))])\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.824, logit=20.750)', '\" The\"[578] (p=0.068, logit=18.250)', '\" Stap\"[63606] (p=0.028, logit=17.375)', '\" A\"[362] (p=0.022, logit=17.125)', '\" Surf\"[65197] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.82421875, logit=20.75, token_id=18343, metadata=None))), (63606, (3, PredictedToken(token=' Stap', prob=0.0281982421875, logit=17.375, token_id=63606, metadata=None))), (65197, (5, PredictedToken(token=' Surf', prob=0.0103759765625, logit=16.375, token_id=65197, metadata=None))), (84409, (6, PredictedToken(token=' Plum', prob=0.0067138671875, logit=15.9375, token_id=84409, metadata=None))), (80629, (20, PredictedToken(token=' Grape', prob=0.000621795654296875, logit=13.5625, token_id=80629, metadata=None))), (100031, (86, PredictedToken(token=' Mosque', prob=4.8160552978515625e-05, logit=11.0, token_id=100031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:52 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:36:52 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:36:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.816, logit=20.750)', '\" A\"[362] (p=0.076, logit=18.375)', '\" The\"[578] (p=0.052, logit=18.000)', '\" Calculator\"[37128] (p=0.019, logit=17.000)', '\" None\"[2290] (p=0.004, logit=15.438)']\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.617, logit=20.250)', '\" Bat\"[16488] (p=0.177, logit=19.000)', '\" The\"[578] (p=0.107, logit=18.500)', '\" A\"[362] (p=0.016, logit=16.625)', '\" Tennis\"[58251] (p=0.013, logit=16.375)']\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.6171875, logit=20.25, token_id=432, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.1767578125, logit=19.0, token_id=16488, metadata=None))), (40975, (45, PredictedToken(token=' Marker', prob=0.00026702880859375, logit=12.5, token_id=40975, metadata=None))), (13597, (84, PredictedToken(token=' Pen', prob=9.202957153320312e-05, logit=11.4375, token_id=13597, metadata=None))), (17367, (200, PredictedToken(token=' Factory', prob=1.811981201171875e-05, logit=9.8125, token_id=17367, metadata=None))), (75258, (482, PredictedToken(token=' Refriger', prob=4.291534423828125e-06, logit=8.375, token_id=75258, metadata=None)))])\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.879, logit=21.125)', '\" The\"[578] (p=0.030, logit=17.750)', '\" R\"[432] (p=0.030, logit=17.750)', '\" Pen\"[13597] (p=0.010, logit=16.625)', '\" A\"[362] (p=0.008, logit=16.375)']\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.87890625, logit=21.125, token_id=40975, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.0301513671875, logit=17.75, token_id=432, metadata=None))), (13597, (4, PredictedToken(token=' Pen', prob=0.009765625, logit=16.625, token_id=13597, metadata=None))), (16488, (6, PredictedToken(token=' Bat', prob=0.0052490234375, logit=16.0, token_id=16488, metadata=None))), (75258, (21, PredictedToken(token=' Refriger', prob=0.0004863739013671875, logit=13.625, token_id=75258, metadata=None))), (17367, (120, PredictedToken(token=' Factory', prob=2.1338462829589844e-05, logit=10.5, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:53 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:36:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.867, logit=20.625)', '\" The\"[578] (p=0.055, logit=17.875)', '\" Jacket\"[55870] (p=0.018, logit=16.750)', '\" A\"[362] (p=0.010, logit=16.125)', '\" None\"[2290] (p=0.004, logit=15.250)']\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.875, logit=21.000)', '\" The\"[578] (p=0.049, logit=18.125)', '\" Cow\"[22607] (p=0.021, logit=17.250)', '\" A\"[362] (p=0.013, logit=16.750)', '\" H\"[473] (p=0.007, logit=16.125)']\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.875, logit=21.0, token_id=34392, metadata=None))), (22607, (3, PredictedToken(token=' Cow', prob=0.0206298828125, logit=17.25, token_id=22607, metadata=None))), (47589, (33, PredictedToken(token=' Basketball', prob=0.00018978118896484375, logit=12.5625, token_id=47589, metadata=None))), (38258, (74, PredictedToken(token=' Baseball', prob=4.792213439941406e-05, logit=11.1875, token_id=38258, metadata=None))), (29318, (104, PredictedToken(token=' Dress', prob=2.9087066650390625e-05, logit=10.6875, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.848, logit=20.500)', '\" Dress\"[29318] (p=0.042, logit=17.500)', '\" Horse\"[34392] (p=0.037, logit=17.375)', '\" The\"[578] (p=0.023, logit=16.875)', '\" Baseball\"[38258] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.84765625, logit=20.5, token_id=47589, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.042236328125, logit=17.5, token_id=29318, metadata=None))), (34392, (3, PredictedToken(token=' Horse', prob=0.037109375, logit=17.375, token_id=34392, metadata=None))), (38258, (5, PredictedToken(token=' Baseball', prob=0.006072998046875, logit=15.5625, token_id=38258, metadata=None))), (22607, (17, PredictedToken(token=' Cow', prob=0.000682830810546875, logit=13.375, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:54 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:36:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     patch_prediction=['\" Watch\"[10573] (p=0.531, logit=19.000)', '\" Ank\"[57915] (p=0.221, logit=18.125)', '\" WATCH\"[48507] (p=0.056, logit=16.750)', '\" The\"[578] (p=0.043, logit=16.500)', '\" An\"[1556] (p=0.026, logit=16.000)']\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.812, logit=20.500)', '\" The\"[578] (p=0.141, logit=18.750)', '\" W\"[468] (p=0.007, logit=15.688)', '\" It\"[1102] (p=0.005, logit=15.438)', '\" A\"[362] (p=0.005, logit=15.438)']\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.8125, logit=20.5, token_id=27738, metadata=None))), (42609, (20, PredictedToken(token=' Pine', prob=0.000576019287109375, logit=13.25, token_id=42609, metadata=None))), (13120, (42, PredictedToken(token=' Night', prob=0.00014591217041015625, logit=11.875, token_id=13120, metadata=None))), (58600, (114, PredictedToken(token=' Charm', prob=3.0517578125e-05, logit=10.3125, token_id=58600, metadata=None))), (23126, (143, PredictedToken(token=' Ti', prob=2.2292137145996094e-05, logit=10.0, token_id=23126, metadata=None)))])\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     int_prediction=['\" Ti\"[23126] (p=0.426, logit=18.500)', '\" Ward\"[27738] (p=0.178, logit=17.625)', '\" The\"[578] (p=0.178, logit=17.625)', '\" Charm\"[58600] (p=0.108, logit=17.125)', '\" TI\"[39237] (p=0.016, logit=15.188)']\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     int_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.42578125, logit=18.5, token_id=23126, metadata=None))), (27738, (3, PredictedToken(token=' Ward', prob=0.177734375, logit=17.625, token_id=27738, metadata=None))), (58600, (4, PredictedToken(token=' Charm', prob=0.10791015625, logit=17.125, token_id=58600, metadata=None))), (42609, (27, PredictedToken(token=' Pine', prob=0.000682830810546875, logit=12.0625, token_id=42609, metadata=None))), (13120, (58, PredictedToken(token=' Night', prob=0.00025177001953125, logit=11.0625, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:55 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.314, logit=18.625)', '\" Potato\"[78703] (p=0.277, logit=18.500)', '\" The\"[578] (p=0.090, logit=17.375)', '\" Watch\"[10573] (p=0.062, logit=17.000)', '\" There\"[2684] (p=0.062, logit=17.000)']\n",
      "2025-09-15 09:36:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.812, logit=20.750)', '\" The\"[578] (p=0.052, logit=18.000)', '\" There\"[2684] (p=0.028, logit=17.375)', '\" E\"[469] (p=0.025, logit=17.250)', '\" Bamboo\"[98028] (p=0.017, logit=16.875)']\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.8125, logit=20.75, token_id=44570, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.0245361328125, logit=17.25, token_id=469, metadata=None))), (98028, (5, PredictedToken(token=' Bamboo', prob=0.016845703125, logit=16.875, token_id=98028, metadata=None))), (1666, (6, PredictedToken(token=' As', prob=0.0115966796875, logit=16.5, token_id=1666, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.004547119140625, logit=15.5625, token_id=3341, metadata=None)))])\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.586, logit=20.250)', '\" Bamboo\"[98028] (p=0.070, logit=18.125)', '\" Maple\"[44570] (p=0.062, logit=18.000)', '\" The\"[578] (p=0.062, logit=18.000)', '\" There\"[2684] (p=0.054, logit=17.875)']\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.5859375, logit=20.25, token_id=3341, metadata=None))), (98028, (2, PredictedToken(token=' Bamboo', prob=0.06982421875, logit=18.125, token_id=98028, metadata=None))), (44570, (4, PredictedToken(token=' Maple', prob=0.061767578125, logit=18.0, token_id=44570, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.04248046875, logit=17.625, token_id=469, metadata=None))), (1666, (7, PredictedToken(token=' As', prob=0.033203125, logit=17.375, token_id=1666, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:56 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.648, logit=20.250)', '\" Microwave\"[98641] (p=0.164, logit=18.875)', '\" The\"[578] (p=0.077, logit=18.125)', '\" A\"[362] (p=0.022, logit=16.875)', '\" R\"[432] (p=0.017, logit=16.625)']\n",
      "2025-09-15 09:36:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     clean_prediction=['\" Marker\"[40975] (p=0.863, logit=20.750)', '\" The\"[578] (p=0.043, logit=17.750)', '\" A\"[362] (p=0.026, logit=17.250)', '\" Notebook\"[69755] (p=0.014, logit=16.625)', '\" MARK\"[18505] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     clean_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.86328125, logit=20.75, token_id=40975, metadata=None))), (69755, (4, PredictedToken(token=' Notebook', prob=0.01397705078125, logit=16.625, token_id=69755, metadata=None))), (57915, (13, PredictedToken(token=' Ank', prob=0.000949859619140625, logit=13.9375, token_id=57915, metadata=None))), (39247, (49, PredictedToken(token=' Slow', prob=0.0001068115234375, logit=11.75, token_id=39247, metadata=None))), (49268, (440, PredictedToken(token=' Dish', prob=3.6507844924926758e-06, logit=8.375, token_id=49268, metadata=None)))])\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.691, logit=18.500)', '\" The\"[578] (p=0.073, logit=16.250)', '\" None\"[2290] (p=0.057, logit=16.000)', '\" Dish\"[49268] (p=0.032, logit=15.438)', '\" There\"[2684] (p=0.030, logit=15.375)']\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.69140625, logit=18.5, token_id=39247, metadata=None))), (49268, (4, PredictedToken(token=' Dish', prob=0.0322265625, logit=15.4375, token_id=49268, metadata=None))), (69755, (11, PredictedToken(token=' Notebook', prob=0.003204345703125, logit=13.125, token_id=69755, metadata=None))), (57915, (14, PredictedToken(token=' Ank', prob=0.002197265625, logit=12.75, token_id=57915, metadata=None))), (40975, (181, PredictedToken(token=' Marker', prob=4.57763671875e-05, logit=8.875, token_id=40975, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:36:57 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.844, logit=20.875)', '\" PEN\"[81770] (p=0.037, logit=17.750)', '\" The\"[578] (p=0.029, logit=17.500)', '\" Highlight\"[57094] (p=0.026, logit=17.375)', '\" A\"[362] (p=0.026, logit=17.375)']\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     clean_prediction=['\" Water\"[10164] (p=0.871, logit=21.250)', '\" The\"[578] (p=0.071, logit=18.750)', '\" WATER\"[76347] (p=0.016, logit=17.250)', '\" Grape\"[80629] (p=0.007, logit=16.375)', '\" There\"[2684] (p=0.003, logit=15.688)']\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     clean_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.87109375, logit=21.25, token_id=10164, metadata=None))), (80629, (4, PredictedToken(token=' Grape', prob=0.00665283203125, logit=16.375, token_id=80629, metadata=None))), (23126, (10, PredictedToken(token=' Ti', prob=0.001678466796875, logit=15.0, token_id=23126, metadata=None))), (94467, (169, PredictedToken(token=' Trom', prob=1.4543533325195312e-05, logit=10.25, token_id=94467, metadata=None))), (40975, (724, PredictedToken(token=' Marker', prob=1.2293457984924316e-06, logit=7.78125, token_id=40975, metadata=None))), (69755, (2078, PredictedToken(token=' Notebook', prob=2.738088369369507e-07, logit=6.28125, token_id=69755, metadata=None)))])\n",
      "2025-09-15 09:36:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     int_prediction=['\" Notebook\"[69755] (p=0.266, logit=18.125)', '\" The\"[578] (p=0.234, logit=18.000)', '\" Trom\"[94467] (p=0.183, logit=17.750)', '\" Marker\"[40975] (p=0.142, logit=17.500)', '\" A\"[362] (p=0.026, logit=15.812)']\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     int_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.265625, logit=18.125, token_id=69755, metadata=None))), (94467, (3, PredictedToken(token=' Trom', prob=0.1826171875, logit=17.75, token_id=94467, metadata=None))), (40975, (4, PredictedToken(token=' Marker', prob=0.1416015625, logit=17.5, token_id=40975, metadata=None))), (23126, (13, PredictedToken(token=' Ti', prob=0.0035552978515625, logit=13.8125, token_id=23126, metadata=None))), (80629, (34, PredictedToken(token=' Grape', prob=0.000743865966796875, logit=12.25, token_id=80629, metadata=None))), (10164, (191, PredictedToken(token=' Water', prob=5.3882598876953125e-05, logit=9.625, token_id=10164, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:58 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.801, logit=21.500)', '\" The\"[578] (p=0.096, logit=19.375)', '\" Orange\"[22725] (p=0.031, logit=18.250)', '\" An\"[1556] (p=0.027, logit=18.125)', '\" Slow\"[39247] (p=0.009, logit=17.000)']\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     clean_prediction=['\" Banana\"[76924] (p=0.809, logit=21.125)', '\" The\"[578] (p=0.097, logit=19.000)', '\" B\"[426] (p=0.040, logit=18.125)', '\" A\"[362] (p=0.010, logit=16.750)', '\" Water\"[10164] (p=0.004, logit=15.875)']\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     clean_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.80859375, logit=21.125, token_id=76924, metadata=None))), (10164, (5, PredictedToken(token=' Water', prob=0.004241943359375, logit=15.875, token_id=10164, metadata=None))), (2057, (6, PredictedToken(token=' To', prob=0.0032958984375, logit=15.625, token_id=2057, metadata=None))), (40759, (23, PredictedToken(token=' Harmon', prob=0.00041961669921875, logit=13.5625, token_id=40759, metadata=None))), (87213, (347, PredictedToken(token=' Oven', prob=4.649162292480469e-06, logit=9.0625, token_id=87213, metadata=None)))])\n",
      "2025-09-15 09:36:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     int_prediction=['\" To\"[2057] (p=0.758, logit=20.375)', '\" The\"[578] (p=0.090, logit=18.250)', '\" TO\"[5257] (p=0.055, logit=17.750)', '\" Banana\"[76924] (p=0.029, logit=17.125)', '\" A\"[362] (p=0.014, logit=16.375)']\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     int_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.7578125, logit=20.375, token_id=2057, metadata=None))), (76924, (4, PredictedToken(token=' Banana', prob=0.029296875, logit=17.125, token_id=76924, metadata=None))), (10164, (6, PredictedToken(token=' Water', prob=0.004791259765625, logit=15.3125, token_id=10164, metadata=None))), (40759, (8, PredictedToken(token=' Harmon', prob=0.0032958984375, logit=14.9375, token_id=40759, metadata=None))), (87213, (20, PredictedToken(token=' Oven', prob=0.000942230224609375, logit=13.6875, token_id=87213, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:59 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:36:59 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.816, logit=20.625)', '\" The\"[578] (p=0.110, logit=18.625)', '\" A\"[362] (p=0.015, logit=16.625)', '\" There\"[2684] (p=0.006, logit=15.688)', '\" J\"[622] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.762, logit=20.125)', '\" The\"[578] (p=0.103, logit=18.125)', '\" Speaker\"[30173] (p=0.049, logit=17.375)', '\" PROJECT\"[40992] (p=0.010, logit=15.750)', '\" A\"[362] (p=0.008, logit=15.562)']\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.76171875, logit=20.125, token_id=5907, metadata=None))), (30173, (3, PredictedToken(token=' Speaker', prob=0.048583984375, logit=17.375, token_id=30173, metadata=None))), (31181, (6, PredictedToken(token=' Clar', prob=0.00701904296875, logit=15.4375, token_id=31181, metadata=None))), (30760, (51, PredictedToken(token=' Scar', prob=0.000270843505859375, logit=12.1875, token_id=30760, metadata=None))), (14937, (50, PredictedToken(token=' Ash', prob=0.000270843505859375, logit=12.1875, token_id=14937, metadata=None))), (55807, (108, PredictedToken(token=' Shirt', prob=7.295608520507812e-05, logit=10.875, token_id=55807, metadata=None))), (32498, (239, PredictedToken(token=' Mall', prob=1.633167266845703e-05, logit=9.375, token_id=32498, metadata=None)))])\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.895, logit=20.750)', '\" The\"[578] (p=0.035, logit=17.500)', '\" SH\"[6570] (p=0.024, logit=17.125)', '\" A\"[362] (p=0.008, logit=16.000)', '\" \"\"[330] (p=0.003, logit=15.125)']\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.89453125, logit=20.75, token_id=55807, metadata=None))), (30760, (7, PredictedToken(token=' Scar', prob=0.0025177001953125, logit=14.875, token_id=30760, metadata=None))), (30173, (14, PredictedToken(token=' Speaker', prob=0.00081634521484375, logit=13.75, token_id=30173, metadata=None))), (14937, (55, PredictedToken(token=' Ash', prob=0.00011014938354492188, logit=11.75, token_id=14937, metadata=None))), (31181, (83, PredictedToken(token=' Clar', prob=5.91278076171875e-05, logit=11.125, token_id=31181, metadata=None))), (32498, (161, PredictedToken(token=' Mall', prob=1.800060272216797e-05, logit=9.9375, token_id=32498, metadata=None))), (5907, (612, PredictedToken(token=' Project', prob=2.4437904357910156e-06, logit=7.9375, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:36:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:36:59 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:36:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.730, logit=19.375)', '\" Elm\"[65329] (p=0.053, logit=16.750)', '\" The\"[578] (p=0.047, logit=16.625)', '\" Pendant\"[81501] (p=0.022, logit=15.875)', '\" L\"[445] (p=0.021, logit=15.812)']\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.762, logit=19.250)', '\" The\"[578] (p=0.055, logit=16.625)', '\" C\"[356] (p=0.043, logit=16.375)', '\" ank\"[71572] (p=0.017, logit=15.438)', '\" An\"[1556] (p=0.017, logit=15.438)']\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.76171875, logit=19.25, token_id=57915, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.04296875, logit=16.375, token_id=356, metadata=None))), (79028, (7, PredictedToken(token=' Hick', prob=0.00848388671875, logit=14.75, token_id=79028, metadata=None))), (27738, (25, PredictedToken(token=' Ward', prob=0.00078582763671875, logit=12.375, token_id=27738, metadata=None))), (57748, (29, PredictedToken(token=' Cedar', prob=0.000614166259765625, logit=12.125, token_id=57748, metadata=None)))])\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.871, logit=19.750)', '\" The\"[578] (p=0.038, logit=16.625)', '\" Cedar\"[57748] (p=0.011, logit=15.375)', '\" Ward\"[27738] (p=0.010, logit=15.312)', '\" C\"[356] (p=0.009, logit=15.188)']\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.87109375, logit=19.75, token_id=79028, metadata=None))), (57748, (3, PredictedToken(token=' Cedar', prob=0.010986328125, logit=15.375, token_id=57748, metadata=None))), (27738, (4, PredictedToken(token=' Ward', prob=0.01031494140625, logit=15.3125, token_id=27738, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.00909423828125, logit=15.1875, token_id=356, metadata=None))), (57915, (21, PredictedToken(token=' Ank', prob=0.000545501708984375, logit=12.375, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:00 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:00 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:37:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:01 src.selection.optimization INFO     patch_prediction=['\" Basketball\"[47589] (p=0.832, logit=20.750)', '\" The\"[578] (p=0.068, logit=18.250)', '\" A\"[362] (p=0.020, logit=17.000)', '\" Baseball\"[38258] (p=0.013, logit=16.625)', '\" Bat\"[16488] (p=0.013, logit=16.625)']\n",
      "2025-09-15 09:37:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:01 src.selection.optimization INFO     clean_prediction=['\" Ju\"[22410] (p=0.436, logit=19.125)', '\" Food\"[12369] (p=0.182, logit=18.250)', '\" The\"[578] (p=0.182, logit=18.250)', '\" A\"[362] (p=0.052, logit=17.000)', '\" R\"[432] (p=0.025, logit=16.250)']\n",
      "2025-09-15 09:37:01 src.selection.optimization INFO     clean_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.435546875, logit=19.125, token_id=22410, metadata=None))), (12369, (3, PredictedToken(token=' Food', prob=0.181640625, logit=18.25, token_id=12369, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.0245361328125, logit=16.25, token_id=432, metadata=None))), (13000, (13, PredictedToken(token=' Van', prob=0.0054931640625, logit=14.75, token_id=13000, metadata=None))), (11896, (17, PredictedToken(token=' Library', prob=0.0021514892578125, logit=13.8125, token_id=11896, metadata=None))), (65197, (277, PredictedToken(token=' Surf', prob=1.7523765563964844e-05, logit=9.0, token_id=65197, metadata=None)))])\n",
      "2025-09-15 09:37:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.785, logit=20.375)', '\" The\"[578] (p=0.120, logit=18.500)', '\" A\"[362] (p=0.034, logit=17.250)', '\" There\"[2684] (p=0.011, logit=16.125)', '\" Van\"[13000] (p=0.004, logit=15.188)']\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.78515625, logit=20.375, token_id=432, metadata=None))), (13000, (5, PredictedToken(token=' Van', prob=0.00439453125, logit=15.1875, token_id=13000, metadata=None))), (11896, (7, PredictedToken(token=' Library', prob=0.003204345703125, logit=14.875, token_id=11896, metadata=None))), (22410, (27, PredictedToken(token=' Ju', prob=0.000492095947265625, logit=13.0, token_id=22410, metadata=None))), (65197, (81, PredictedToken(token=' Surf', prob=6.67572021484375e-05, logit=11.0, token_id=65197, metadata=None))), (12369, (106, PredictedToken(token=' Food', prob=4.029273986816406e-05, logit=10.5, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:02 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:02 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     patch_prediction=['\" Van\"[13000] (p=0.730, logit=20.625)', '\" The\"[578] (p=0.144, logit=19.000)', '\" VAN\"[97753] (p=0.036, logit=17.625)', '\" A\"[362] (p=0.028, logit=17.375)', '\" Train\"[27217] (p=0.019, logit=17.000)']\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.512, logit=19.125)', '\" The\"[578] (p=0.130, logit=17.750)', '\" Chair\"[16478] (p=0.079, logit=17.250)', '\" Sk\"[4923] (p=0.054, logit=16.875)', '\" A\"[362] (p=0.042, logit=16.625)']\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.51171875, logit=19.125, token_id=23462, metadata=None))), (16478, (3, PredictedToken(token=' Chair', prob=0.07861328125, logit=17.25, token_id=16478, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.05419921875, logit=16.875, token_id=4923, metadata=None))), (3341, (6, PredictedToken(token=' Car', prob=0.0289306640625, logit=16.25, token_id=3341, metadata=None))), (1183, (7, PredictedToken(token=' Tr', prob=0.0255126953125, logit=16.125, token_id=1183, metadata=None))), (23262, (8, PredictedToken(token=' Comb', prob=0.0164794921875, logit=15.6875, token_id=23262, metadata=None))), (84409, (10, PredictedToken(token=' Plum', prob=0.01458740234375, logit=15.5625, token_id=84409, metadata=None)))])\n",
      "2025-09-15 09:37:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.730, logit=20.375)', '\" The\"[578] (p=0.099, logit=18.375)', '\" Tr\"[1183] (p=0.041, logit=17.500)', '\" A\"[362] (p=0.036, logit=17.375)', '\" CAR\"[28876] (p=0.017, logit=16.625)']\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.73046875, logit=20.375, token_id=3341, metadata=None))), (1183, (3, PredictedToken(token=' Tr', prob=0.041259765625, logit=17.5, token_id=1183, metadata=None))), (4923, (7, PredictedToken(token=' Sk', prob=0.0067138671875, logit=15.6875, token_id=4923, metadata=None))), (16478, (11, PredictedToken(token=' Chair', prob=0.0038299560546875, logit=15.125, token_id=16478, metadata=None))), (23462, (14, PredictedToken(token=' Stadium', prob=0.002471923828125, logit=14.6875, token_id=23462, metadata=None))), (84409, (20, PredictedToken(token=' Plum', prob=0.000804901123046875, logit=13.5625, token_id=84409, metadata=None))), (23262, (29, PredictedToken(token=' Comb', prob=0.000518798828125, logit=13.125, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:03 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.703, logit=20.125)', '\" The\"[578] (p=0.122, logit=18.375)', '\" Football\"[21424] (p=0.074, logit=17.875)', '\" A\"[362] (p=0.027, logit=16.875)', '\" There\"[2684] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     clean_prediction=['\" St\"[800] (p=0.582, logit=19.750)', '\" Dress\"[29318] (p=0.188, logit=18.625)', '\" The\"[578] (p=0.079, logit=17.750)', '\" A\"[362] (p=0.061, logit=17.500)', '\" R\"[432] (p=0.023, logit=16.500)']\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     clean_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.58203125, logit=19.75, token_id=800, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.1884765625, logit=18.625, token_id=29318, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.0225830078125, logit=16.5, token_id=432, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.0036773681640625, logit=14.6875, token_id=4923, metadata=None))), (58251, (63, PredictedToken(token=' Tennis', prob=0.000125885009765625, logit=11.3125, token_id=58251, metadata=None)))])\n",
      "2025-09-15 09:37:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.416, logit=19.000)', '\" Tennis\"[58251] (p=0.223, logit=18.375)', '\" St\"[800] (p=0.196, logit=18.250)', '\" The\"[578] (p=0.039, logit=16.625)', '\" Sk\"[4923] (p=0.027, logit=16.250)']\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.416015625, logit=19.0, token_id=432, metadata=None))), (58251, (2, PredictedToken(token=' Tennis', prob=0.22265625, logit=18.375, token_id=58251, metadata=None))), (800, (3, PredictedToken(token=' St', prob=0.1962890625, logit=18.25, token_id=800, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.026611328125, logit=16.25, token_id=4923, metadata=None))), (29318, (40, PredictedToken(token=' Dress', prob=0.0003795623779296875, logit=12.0, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:04 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:04 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.443, logit=19.375)', '\" The\"[578] (p=0.236, logit=18.750)', '\" Microwave\"[98641] (p=0.112, logit=18.000)', '\" Bro\"[6031] (p=0.047, logit=17.125)', '\" A\"[362] (p=0.041, logit=17.000)']\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.621, logit=19.125)', '\" The\"[578] (p=0.122, logit=17.500)', '\" Ti\"[23126] (p=0.065, logit=16.875)', '\" A\"[362] (p=0.051, logit=16.625)', '\" CH\"[6969] (p=0.027, logit=16.000)']\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.62109375, logit=19.125, token_id=58600, metadata=None))), (23126, (3, PredictedToken(token=' Ti', prob=0.0654296875, logit=16.875, token_id=23126, metadata=None))), (60413, (9, PredictedToken(token=' Uk', prob=0.003936767578125, logit=14.0625, token_id=60413, metadata=None))), (16183, (11, PredictedToken(token=' Hel', prob=0.0034637451171875, logit=13.9375, token_id=16183, metadata=None))), (328, (12, PredictedToken(token=' S', prob=0.0032501220703125, logit=13.875, token_id=328, metadata=None))), (27171, (504, PredictedToken(token=' Coffee', prob=9.119510650634766e-06, logit=8.0, token_id=27171, metadata=None))), (72392, (1925, PredictedToken(token=' Mixer', prob=1.5422701835632324e-06, logit=6.21875, token_id=72392, metadata=None)))])\n",
      "2025-09-15 09:37:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.664, logit=19.250)', '\" The\"[578] (p=0.102, logit=17.375)', '\" CO\"[7432] (p=0.048, logit=16.625)', '\" A\"[362] (p=0.042, logit=16.500)', '\" Maker\"[41628] (p=0.029, logit=16.125)']\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6640625, logit=19.25, token_id=27171, metadata=None))), (72392, (7, PredictedToken(token=' Mixer', prob=0.0089111328125, logit=14.9375, token_id=72392, metadata=None))), (328, (21, PredictedToken(token=' S', prob=0.001129150390625, logit=12.875, token_id=328, metadata=None))), (23126, (30, PredictedToken(token=' Ti', prob=0.000728607177734375, logit=12.4375, token_id=23126, metadata=None))), (60413, (181, PredictedToken(token=' Uk', prob=4.124641418457031e-05, logit=9.5625, token_id=60413, metadata=None))), (16183, (266, PredictedToken(token=' Hel', prob=2.0742416381835938e-05, logit=8.875, token_id=16183, metadata=None))), (58600, (635, PredictedToken(token=' Charm', prob=5.3942203521728516e-06, logit=7.53125, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:05 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:05 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     patch_prediction=['\" Tennis\"[58251] (p=0.479, logit=18.875)', '\" Helmet\"[67629] (p=0.199, logit=18.000)', '\" The\"[578] (p=0.107, logit=17.375)', '\" A\"[362] (p=0.022, logit=15.812)', '\" Shorts\"[91782] (p=0.021, logit=15.750)']\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     clean_prediction=['\" Train\"[27217] (p=0.531, logit=20.125)', '\" Boat\"[45332] (p=0.195, logit=19.125)', '\" The\"[578] (p=0.152, logit=18.875)', '\" A\"[362] (p=0.026, logit=17.125)', '\" There\"[2684] (p=0.016, logit=16.625)']\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     clean_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.53125, logit=20.125, token_id=27217, metadata=None))), (45332, (2, PredictedToken(token=' Boat', prob=0.1953125, logit=19.125, token_id=45332, metadata=None))), (65197, (6, PredictedToken(token=' Surf', prob=0.01611328125, logit=16.625, token_id=65197, metadata=None))), (3816, (7, PredictedToken(token=' Red', prob=0.00860595703125, logit=16.0, token_id=3816, metadata=None))), (2522, (18, PredictedToken(token=' Sc', prob=0.00115966796875, logit=14.0, token_id=2522, metadata=None))), (41342, (37, PredictedToken(token=' Hockey', prob=0.000377655029296875, logit=12.875, token_id=41342, metadata=None))), (29318, (61, PredictedToken(token=' Dress', prob=0.00013065338134765625, logit=11.8125, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:37:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.498, logit=19.375)', '\" Sc\"[2522] (p=0.161, logit=18.250)', '\" The\"[578] (p=0.086, logit=17.625)', '\" Boat\"[45332] (p=0.059, logit=17.250)', '\" Surf\"[65197] (p=0.032, logit=16.625)']\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.498046875, logit=19.375, token_id=41342, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.1611328125, logit=18.25, token_id=2522, metadata=None))), (45332, (4, PredictedToken(token=' Boat', prob=0.059326171875, logit=17.25, token_id=45332, metadata=None))), (65197, (5, PredictedToken(token=' Surf', prob=0.03173828125, logit=16.625, token_id=65197, metadata=None))), (3816, (8, PredictedToken(token=' Red', prob=0.0218505859375, logit=16.25, token_id=3816, metadata=None))), (27217, (9, PredictedToken(token=' Train', prob=0.01409912109375, logit=15.8125, token_id=27217, metadata=None))), (29318, (16, PredictedToken(token=' Dress', prob=0.0023040771484375, logit=14.0, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:06 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.684, logit=18.875)', '\" Bear\"[24941] (p=0.119, logit=17.125)', '\" The\"[578] (p=0.063, logit=16.500)', '\" R\"[432] (p=0.018, logit=15.250)', '\" An\"[1556] (p=0.013, logit=14.875)']\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.672, logit=19.875)', '\" The\"[578] (p=0.132, logit=18.250)', '\" Baseball\"[38258] (p=0.103, logit=18.000)', '\" A\"[362] (p=0.023, logit=16.500)', '\" None\"[2290] (p=0.007, logit=15.312)']\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.671875, logit=19.875, token_id=423, metadata=None))), (38258, (3, PredictedToken(token=' Baseball', prob=0.10302734375, logit=18.0, token_id=38258, metadata=None))), (48035, (28, PredictedToken(token=' Gir', prob=0.00069427490234375, logit=13.0, token_id=48035, metadata=None))), (14588, (67, PredictedToken(token=' Dog', prob=0.0001277923583984375, logit=11.3125, token_id=14588, metadata=None)))])\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.695, logit=19.250)', '\" The\"[578] (p=0.083, logit=17.125)', '\" Baseball\"[38258] (p=0.065, logit=16.875)', '\" Gir\"[48035] (p=0.020, logit=15.688)', '\" None\"[2290] (p=0.020, logit=15.688)']\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.6953125, logit=19.25, token_id=14588, metadata=None))), (38258, (3, PredictedToken(token=' Baseball', prob=0.06494140625, logit=16.875, token_id=38258, metadata=None))), (48035, (5, PredictedToken(token=' Gir', prob=0.019775390625, logit=15.6875, token_id=48035, metadata=None))), (423, (9, PredictedToken(token=' D', prob=0.0087890625, logit=14.875, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:06 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.812, logit=20.625)', '\" The\"[578] (p=0.125, logit=18.750)', '\" Bench\"[36358] (p=0.007, logit=15.875)', '\" It\"[1102] (p=0.005, logit=15.625)', '\" An\"[1556] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     clean_prediction=['\" Rose\"[16344] (p=0.420, logit=19.500)', '\" Daisy\"[71264] (p=0.226, logit=18.875)', '\" The\"[578] (p=0.199, logit=18.750)', '\" There\"[2684] (p=0.034, logit=17.000)', '\" A\"[362] (p=0.024, logit=16.625)']\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     clean_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.419921875, logit=19.5, token_id=16344, metadata=None))), (71264, (2, PredictedToken(token=' Daisy', prob=0.2255859375, logit=18.875, token_id=71264, metadata=None))), (27738, (69, PredictedToken(token=' Ward', prob=0.00016021728515625, logit=11.625, token_id=27738, metadata=None))), (6017, (112, PredictedToken(token=' Book', prob=5.888938903808594e-05, logit=10.625, token_id=6017, metadata=None))), (38930, (1343, PredictedToken(token=' Bike', prob=1.385807991027832e-06, logit=6.875, token_id=38930, metadata=None)))])\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     int_prediction=['\" Book\"[6017] (p=0.746, logit=20.375)', '\" The\"[578] (p=0.089, logit=18.250)', '\" Daisy\"[71264] (p=0.054, logit=17.750)', '\" Rose\"[16344] (p=0.020, logit=16.750)', '\" There\"[2684] (p=0.016, logit=16.500)']\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     int_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.74609375, logit=20.375, token_id=6017, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.05419921875, logit=17.75, token_id=71264, metadata=None))), (16344, (4, PredictedToken(token=' Rose', prob=0.0198974609375, logit=16.75, token_id=16344, metadata=None))), (27738, (28, PredictedToken(token=' Ward', prob=0.000499725341796875, logit=13.0625, token_id=27738, metadata=None))), (38930, (157, PredictedToken(token=' Bike', prob=2.0503997802734375e-05, logit=9.875, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:07 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.836, logit=20.250)', '\" The\"[578] (p=0.061, logit=17.625)', '\" Y\"[816] (p=0.029, logit=16.875)', '\" Cabinet\"[34046] (p=0.008, logit=15.562)', '\" C\"[356] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.965, logit=22.125)', '\" The\"[578] (p=0.012, logit=17.750)', '\" B\"[426] (p=0.005, logit=16.875)', '\" P\"[393] (p=0.002, logit=16.000)', '\" A\"[362] (p=0.002, logit=15.875)']\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.96484375, logit=22.125, token_id=81501, metadata=None))), (426, (3, PredictedToken(token=' B', prob=0.00506591796875, logit=16.875, token_id=426, metadata=None))), (16183, (6, PredictedToken(token=' Hel', prob=0.00136566162109375, logit=15.5625, token_id=16183, metadata=None))), (27738, (32, PredictedToken(token=' Ward', prob=8.726119995117188e-05, logit=12.8125, token_id=27738, metadata=None))), (61948, (67, PredictedToken(token=' Sofa', prob=2.491474151611328e-05, logit=11.5625, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     int_prediction=['\" Sofa\"[61948] (p=0.832, logit=20.250)', '\" Ward\"[27738] (p=0.037, logit=17.125)', '\" The\"[578] (p=0.037, logit=17.125)', '\" SO\"[5745] (p=0.015, logit=16.250)', '\" sofa\"[32169] (p=0.008, logit=15.625)']\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     int_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.83203125, logit=20.25, token_id=61948, metadata=None))), (27738, (3, PredictedToken(token=' Ward', prob=0.03662109375, logit=17.125, token_id=27738, metadata=None))), (16183, (6, PredictedToken(token=' Hel', prob=0.007659912109375, logit=15.5625, token_id=16183, metadata=None))), (81501, (10, PredictedToken(token=' Pendant', prob=0.004638671875, logit=15.0625, token_id=81501, metadata=None))), (426, (24, PredictedToken(token=' B', prob=0.000629425048828125, logit=13.0625, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:08 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     patch_prediction=['\" Tablet\"[58403] (p=0.482, logit=19.250)', '\" The\"[578] (p=0.228, logit=18.500)', '\" Project\"[5907] (p=0.065, logit=17.250)', '\" TABLE\"[14700] (p=0.045, logit=16.875)', '\" A\"[362] (p=0.040, logit=16.750)']\n",
      "2025-09-15 09:37:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.443, logit=19.750)', '\" Pendant\"[81501] (p=0.391, logit=19.625)', '\" The\"[578] (p=0.047, logit=17.500)', '\" LO\"[5125] (p=0.025, logit=16.875)', '\" A\"[362] (p=0.017, logit=16.500)']\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.443359375, logit=19.75, token_id=445, metadata=None))), (81501, (2, PredictedToken(token=' Pendant', prob=0.390625, logit=19.625, token_id=81501, metadata=None))), (356, (15, PredictedToken(token=' C', prob=0.00150299072265625, logit=14.0625, token_id=356, metadata=None))), (24423, (20, PredictedToken(token=' Monitor', prob=0.00096893310546875, logit=13.625, token_id=24423, metadata=None))), (16730, (44, PredictedToken(token=' Museum', prob=0.0002460479736328125, logit=12.25, token_id=16730, metadata=None))), (14669, (322, PredictedToken(token=' Camera', prob=8.940696716308594e-06, logit=8.9375, token_id=14669, metadata=None)))])\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.824, logit=20.125)', '\" Camera\"[14669] (p=0.041, logit=17.125)', '\" The\"[578] (p=0.032, logit=16.875)', '\" MON\"[29637] (p=0.017, logit=16.250)', '\" Museum\"[16730] (p=0.017, logit=16.250)']\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.82421875, logit=20.125, token_id=24423, metadata=None))), (14669, (2, PredictedToken(token=' Camera', prob=0.041015625, logit=17.125, token_id=14669, metadata=None))), (16730, (4, PredictedToken(token=' Museum', prob=0.01708984375, logit=16.25, token_id=16730, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.00970458984375, logit=15.6875, token_id=356, metadata=None))), (81501, (15, PredictedToken(token=' Pendant', prob=0.002044677734375, logit=14.125, token_id=81501, metadata=None))), (445, (20, PredictedToken(token=' L', prob=0.000751495361328125, logit=13.125, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:09 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.855, logit=21.375)', '\" The\"[578] (p=0.070, logit=18.875)', '\" MON\"[29637] (p=0.023, logit=17.750)', '\" A\"[362] (p=0.012, logit=17.125)', '\" Dog\"[14588] (p=0.010, logit=16.875)']\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.812, logit=20.625)', '\" The\"[578] (p=0.066, logit=18.125)', '\" Television\"[41445] (p=0.052, logit=17.875)', '\" LAP\"[72428] (p=0.012, logit=16.375)', '\" There\"[2684] (p=0.006, logit=15.688)']\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.8125, logit=20.625, token_id=57225, metadata=None))), (41445, (3, PredictedToken(token=' Television', prob=0.0517578125, logit=17.875, token_id=41445, metadata=None))), (34392, (6, PredictedToken(token=' Horse', prob=0.005126953125, logit=15.5625, token_id=34392, metadata=None))), (56491, (26, PredictedToken(token=' Piano', prob=0.000476837158203125, logit=13.1875, token_id=56491, metadata=None))), (33199, (222, PredictedToken(token=' Lion', prob=1.055002212524414e-05, logit=9.375, token_id=33199, metadata=None)))])\n",
      "2025-09-15 09:37:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:10 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.848, logit=20.250)', '\" The\"[578] (p=0.062, logit=17.625)', '\" Lion\"[33199] (p=0.011, logit=15.938)', '\" Laptop\"[57225] (p=0.010, logit=15.812)', '\" H\"[473] (p=0.009, logit=15.688)']\n",
      "2025-09-15 09:37:10 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.84765625, logit=20.25, token_id=34392, metadata=None))), (33199, (3, PredictedToken(token=' Lion', prob=0.0113525390625, logit=15.9375, token_id=33199, metadata=None))), (57225, (4, PredictedToken(token=' Laptop', prob=0.010009765625, logit=15.8125, token_id=57225, metadata=None))), (41445, (15, PredictedToken(token=' Television', prob=0.00144195556640625, logit=13.875, token_id=41445, metadata=None))), (56491, (26, PredictedToken(token=' Piano', prob=0.000530242919921875, logit=12.875, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:10 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:10 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:37:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:10 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.715, logit=19.750)', '\" The\"[578] (p=0.125, logit=18.000)', '\" Ward\"[27738] (p=0.059, logit=17.250)', '\" A\"[362] (p=0.012, logit=15.625)', '\" There\"[2684] (p=0.011, logit=15.562)']\n",
      "2025-09-15 09:37:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.855, logit=21.000)', '\" The\"[578] (p=0.080, logit=18.625)', '\" M\"[386] (p=0.026, logit=17.500)', '\" Peach\"[64695] (p=0.007, logit=16.125)', '\" There\"[2684] (p=0.004, logit=15.562)']\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.85546875, logit=21.0, token_id=91963, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.00653076171875, logit=16.125, token_id=64695, metadata=None))), (426, (31, PredictedToken(token=' B', prob=0.000209808349609375, logit=12.6875, token_id=426, metadata=None))), (13394, (358, PredictedToken(token=' Bed', prob=4.082918167114258e-06, logit=8.75, token_id=13394, metadata=None))), (91782, (518, PredictedToken(token=' Shorts', prob=2.4884939193725586e-06, logit=8.25, token_id=91782, metadata=None))), (94467, (730, PredictedToken(token=' Trom', prob=1.5050172805786133e-06, logit=7.75, token_id=94467, metadata=None))), (70110, (4582, PredictedToken(token=' Ottoman', prob=1.1594966053962708e-07, logit=5.1875, token_id=70110, metadata=None)))])\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     int_prediction=['\" Bed\"[13394] (p=0.365, logit=18.500)', '\" Ottoman\"[70110] (p=0.250, logit=18.125)', '\" The\"[578] (p=0.092, logit=17.125)', '\" B\"[426] (p=0.063, logit=16.750)', '\" BED\"[83364] (p=0.034, logit=16.125)']\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     int_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.365234375, logit=18.5, token_id=13394, metadata=None))), (70110, (2, PredictedToken(token=' Ottoman', prob=0.25, logit=18.125, token_id=70110, metadata=None))), (426, (4, PredictedToken(token=' B', prob=0.0634765625, logit=16.75, token_id=426, metadata=None))), (91782, (6, PredictedToken(token=' Shorts', prob=0.033935546875, logit=16.125, token_id=91782, metadata=None))), (94467, (7, PredictedToken(token=' Trom', prob=0.0233154296875, logit=15.75, token_id=94467, metadata=None))), (64695, (175, PredictedToken(token=' Peach', prob=4.792213439941406e-05, logit=9.5625, token_id=64695, metadata=None))), (91963, (183, PredictedToken(token=' Mango', prob=4.506111145019531e-05, logit=9.5, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:11 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:11 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.676, logit=20.625)', '\" Rice\"[30616] (p=0.133, logit=19.000)', '\" The\"[578] (p=0.118, logit=18.875)', '\" A\"[362] (p=0.018, logit=17.000)', '\" It\"[1102] (p=0.006, logit=15.938)']\n",
      "2025-09-15 09:37:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.551, logit=19.875)', '\" Dress\"[29318] (p=0.179, logit=18.750)', '\" The\"[578] (p=0.123, logit=18.375)', '\" A\"[362] (p=0.096, logit=18.125)', '\" Sk\"[4923] (p=0.007, logit=15.438)']\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.55078125, logit=19.875, token_id=59825, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.1787109375, logit=18.75, token_id=29318, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.006500244140625, logit=15.4375, token_id=4923, metadata=None))), (40090, (84, PredictedToken(token=' Pressure', prob=5.626678466796875e-05, logit=10.6875, token_id=40090, metadata=None))), (12369, (759, PredictedToken(token=' Food', prob=2.250075340270996e-06, logit=7.46875, token_id=12369, metadata=None)))])\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     int_prediction=['\" Food\"[12369] (p=0.367, logit=19.875)', '\" Pressure\"[40090] (p=0.367, logit=19.875)', '\" Dress\"[29318] (p=0.072, logit=18.250)', '\" The\"[578] (p=0.064, logit=18.125)', '\" Tie\"[59825] (p=0.044, logit=17.750)']\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     int_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.3671875, logit=19.875, token_id=12369, metadata=None))), (40090, (2, PredictedToken(token=' Pressure', prob=0.3671875, logit=19.875, token_id=40090, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.072265625, logit=18.25, token_id=29318, metadata=None))), (59825, (5, PredictedToken(token=' Tie', prob=0.0439453125, logit=17.75, token_id=59825, metadata=None))), (4923, (16, PredictedToken(token=' Sk', prob=0.00096893310546875, logit=13.9375, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:12 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.738, logit=19.500)', '\" The\"[578] (p=0.078, logit=17.250)', '\" Pendant\"[81501] (p=0.047, logit=16.750)', '\" Iris\"[66821] (p=0.016, logit=15.688)', '\" A\"[362] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:37:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     clean_prediction=['\" Lily\"[48390] (p=0.617, logit=18.750)', '\" The\"[578] (p=0.122, logit=17.125)', '\" Violet\"[74574] (p=0.065, logit=16.500)', '\" L\"[445] (p=0.037, logit=15.938)', '\" There\"[2684] (p=0.020, logit=15.312)']\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     clean_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.6171875, logit=18.75, token_id=48390, metadata=None))), (74574, (3, PredictedToken(token=' Violet', prob=0.0654296875, logit=16.5, token_id=74574, metadata=None))), (58600, (13, PredictedToken(token=' Charm', prob=0.00537109375, logit=14.0, token_id=58600, metadata=None))), (29625, (18, PredictedToken(token=' Chain', prob=0.00185394287109375, logit=12.9375, token_id=29625, metadata=None))), (37326, (19, PredictedToken(token=' Swe', prob=0.001739501953125, logit=12.875, token_id=37326, metadata=None)))])\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     int_prediction=['\" Charm\"[58600] (p=0.684, logit=18.375)', '\" Chain\"[29625] (p=0.056, logit=15.875)', '\" CH\"[6969] (p=0.039, logit=15.500)', '\" The\"[578] (p=0.030, logit=15.250)', '\" Violet\"[74574] (p=0.028, logit=15.188)']\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     int_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.68359375, logit=18.375, token_id=58600, metadata=None))), (29625, (2, PredictedToken(token=' Chain', prob=0.05615234375, logit=15.875, token_id=29625, metadata=None))), (74574, (5, PredictedToken(token=' Violet', prob=0.0281982421875, logit=15.1875, token_id=74574, metadata=None))), (37326, (12, PredictedToken(token=' Swe', prob=0.00433349609375, logit=13.3125, token_id=37326, metadata=None))), (48390, (16, PredictedToken(token=' Lily', prob=0.002166748046875, logit=12.625, token_id=48390, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:13 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     patch_prediction=['\" Bench\"[36358] (p=0.793, logit=20.625)', '\" The\"[578] (p=0.074, logit=18.250)', '\" Chair\"[16478] (p=0.051, logit=17.875)', '\" A\"[362] (p=0.015, logit=16.625)', '\" It\"[1102] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:37:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:14 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.762, logit=20.125)', '\" The\"[578] (p=0.103, logit=18.125)', '\" Har\"[5340] (p=0.038, logit=17.125)', '\" TR\"[5091] (p=0.029, logit=16.875)', '\" There\"[2684] (p=0.008, logit=15.562)']\n",
      "2025-09-15 09:37:14 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.76171875, logit=20.125, token_id=3420, metadata=None))), (5340, (3, PredictedToken(token=' Har', prob=0.037841796875, logit=17.125, token_id=5340, metadata=None))), (13394, (100, PredictedToken(token=' Bed', prob=6.0558319091796875e-05, logit=10.6875, token_id=13394, metadata=None))), (68867, (149, PredictedToken(token=' Coat', prob=3.039836883544922e-05, logit=10.0, token_id=68867, metadata=None))), (39794, (545, PredictedToken(token=' Desk', prob=3.3080577850341797e-06, logit=7.78125, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:37:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:14 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.750, logit=19.500)', '\" Desk\"[39794] (p=0.070, logit=17.125)', '\" The\"[578] (p=0.048, logit=16.750)', '\" None\"[2290] (p=0.016, logit=15.625)', '\" HAR\"[87588] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:37:14 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.75, logit=19.5, token_id=5340, metadata=None))), (39794, (2, PredictedToken(token=' Desk', prob=0.06982421875, logit=17.125, token_id=39794, metadata=None))), (13394, (7, PredictedToken(token=' Bed', prob=0.01068115234375, logit=15.25, token_id=13394, metadata=None))), (68867, (16, PredictedToken(token=' Coat', prob=0.0022430419921875, logit=13.6875, token_id=68867, metadata=None))), (3420, (28, PredictedToken(token=' Trump', prob=0.00087738037109375, logit=12.75, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:14 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:37:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     patch_prediction=['\" Orange\"[22725] (p=0.785, logit=21.125)', '\" The\"[578] (p=0.073, logit=18.750)', '\" Strawberry\"[89077] (p=0.057, logit=18.500)', '\" There\"[2684] (p=0.027, logit=17.750)', '\" OR\"[2794] (p=0.014, logit=17.125)']\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     clean_prediction=['\" Mouse\"[18191] (p=0.691, logit=19.750)', '\" Micro\"[18654] (p=0.175, logit=18.375)', '\" The\"[578] (p=0.050, logit=17.125)', '\" None\"[2290] (p=0.011, logit=15.625)', '\" A\"[362] (p=0.011, logit=15.625)']\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     clean_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.69140625, logit=19.75, token_id=18191, metadata=None))), (18654, (2, PredictedToken(token=' Micro', prob=0.1748046875, logit=18.375, token_id=18654, metadata=None))), (36845, (13, PredictedToken(token=' Tiger', prob=0.0018310546875, logit=13.8125, token_id=36845, metadata=None))), (10164, (54, PredictedToken(token=' Water', prob=0.0001926422119140625, logit=11.5625, token_id=10164, metadata=None))), (45805, (394, PredictedToken(token=' Cherry', prob=7.0035457611083984e-06, logit=8.25, token_id=45805, metadata=None)))])\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.789, logit=19.625)', '\" Cherry\"[45805] (p=0.057, logit=17.000)', '\" WATER\"[76347] (p=0.044, logit=16.750)', '\" The\"[578] (p=0.039, logit=16.625)', '\" Tiger\"[36845] (p=0.009, logit=15.188)']\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.7890625, logit=19.625, token_id=10164, metadata=None))), (45805, (2, PredictedToken(token=' Cherry', prob=0.05712890625, logit=17.0, token_id=45805, metadata=None))), (36845, (5, PredictedToken(token=' Tiger', prob=0.00933837890625, logit=15.1875, token_id=36845, metadata=None))), (18191, (7, PredictedToken(token=' Mouse', prob=0.004974365234375, logit=14.5625, token_id=18191, metadata=None))), (18654, (22, PredictedToken(token=' Micro', prob=0.000762939453125, logit=12.6875, token_id=18654, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:15 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.875, logit=21.125)', '\" The\"[578] (p=0.056, logit=18.375)', '\" A\"[362] (p=0.023, logit=17.500)', '\" Yoga\"[38673] (p=0.006, logit=16.125)', '\" FOOT\"[81137] (p=0.005, logit=15.938)']\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     clean_prediction=['\" Lion\"[33199] (p=0.816, logit=20.500)', '\" The\"[578] (p=0.059, logit=17.875)', '\" Z\"[1901] (p=0.036, logit=17.375)', '\" Bat\"[16488] (p=0.025, logit=17.000)', '\" A\"[362] (p=0.013, logit=16.375)']\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     clean_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.81640625, logit=20.5, token_id=33199, metadata=None))), (1901, (3, PredictedToken(token=' Z', prob=0.035888671875, logit=17.375, token_id=1901, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.024658203125, logit=17.0, token_id=16488, metadata=None))), (57748, (51, PredictedToken(token=' Cedar', prob=0.00011396408081054688, logit=11.625, token_id=57748, metadata=None))), (41342, (111, PredictedToken(token=' Hockey', prob=3.933906555175781e-05, logit=10.5625, token_id=41342, metadata=None)))])\n",
      "2025-09-15 09:37:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.668, logit=19.750)', '\" Bat\"[16488] (p=0.116, logit=18.000)', '\" The\"[578] (p=0.091, logit=17.750)', '\" A\"[362] (p=0.026, logit=16.500)', '\" Z\"[1901] (p=0.020, logit=16.250)']\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.66796875, logit=19.75, token_id=41342, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.1162109375, logit=18.0, token_id=16488, metadata=None))), (1901, (5, PredictedToken(token=' Z', prob=0.020263671875, logit=16.25, token_id=1901, metadata=None))), (33199, (12, PredictedToken(token=' Lion', prob=0.0030975341796875, logit=14.375, token_id=33199, metadata=None))), (57748, (51, PredictedToken(token=' Cedar', prob=0.0001983642578125, logit=11.625, token_id=57748, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:16 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     patch_prediction=['\" Mango\"[91963] (p=0.844, logit=21.125)', '\" The\"[578] (p=0.114, logit=19.125)', '\" M\"[386] (p=0.007, logit=16.375)', '\" Pine\"[42609] (p=0.003, logit=15.500)', '\" It\"[1102] (p=0.003, logit=15.438)']\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.707, logit=20.250)', '\" Monitor\"[24423] (p=0.108, logit=18.375)', '\" The\"[578] (p=0.096, logit=18.250)', '\" HEAD\"[34180] (p=0.015, logit=16.375)', '\" None\"[2290] (p=0.007, logit=15.562)']\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.70703125, logit=20.25, token_id=11452, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.1083984375, logit=18.375, token_id=24423, metadata=None))), (61948, (46, PredictedToken(token=' Sofa', prob=0.00023651123046875, logit=12.25, token_id=61948, metadata=None))), (89077, (47, PredictedToken(token=' Strawberry', prob=0.00022220611572265625, logit=12.1875, token_id=89077, metadata=None))), (10164, (216, PredictedToken(token=' Water', prob=1.609325408935547e-05, logit=9.5625, token_id=10164, metadata=None)))])\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.918, logit=21.000)', '\" Strawberry\"[89077] (p=0.019, logit=17.125)', '\" WATER\"[76347] (p=0.019, logit=17.125)', '\" The\"[578] (p=0.013, logit=16.750)', '\" water\"[3090] (p=0.003, logit=15.312)']\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.91796875, logit=21.0, token_id=10164, metadata=None))), (89077, (3, PredictedToken(token=' Strawberry', prob=0.01904296875, logit=17.125, token_id=89077, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.0022735595703125, logit=15.0, token_id=24423, metadata=None))), (11452, (26, PredictedToken(token=' Head', prob=0.00032806396484375, logit=13.0625, token_id=11452, metadata=None))), (61948, (45, PredictedToken(token=' Sofa', prob=0.0001277923583984375, logit=12.125, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:16 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.664, logit=20.000)', '\" Hel\"[16183] (p=0.168, logit=18.625)', '\" The\"[578] (p=0.080, logit=17.875)', '\" There\"[2684] (p=0.014, logit=16.125)', '\" An\"[1556] (p=0.012, logit=16.000)']\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.754, logit=20.125)', '\" The\"[578] (p=0.102, logit=18.125)', '\" Factory\"[17367] (p=0.029, logit=16.875)', '\" A\"[362] (p=0.029, logit=16.875)', '\" CH\"[6969] (p=0.020, logit=16.500)']\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.75390625, logit=20.125, token_id=9441, metadata=None))), (17367, (4, PredictedToken(token=' Factory', prob=0.0291748046875, logit=16.875, token_id=17367, metadata=None))), (34785, (6, PredictedToken(token=' Truck', prob=0.006927490234375, logit=15.4375, token_id=34785, metadata=None))), (1183, (8, PredictedToken(token=' Tr', prob=0.00506591796875, logit=15.125, token_id=1183, metadata=None))), (39794, (98, PredictedToken(token=' Desk', prob=5.2928924560546875e-05, logit=10.5625, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     int_prediction=['\" Truck\"[34785] (p=0.361, logit=17.500)', '\" Tr\"[1183] (p=0.220, logit=17.000)', '\" The\"[578] (p=0.091, logit=16.125)', '\" TR\"[5091] (p=0.046, logit=15.438)', '\" A\"[362] (p=0.034, logit=15.125)']\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     int_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.361328125, logit=17.5, token_id=34785, metadata=None))), (1183, (2, PredictedToken(token=' Tr', prob=0.2197265625, logit=17.0, token_id=1183, metadata=None))), (17367, (6, PredictedToken(token=' Factory', prob=0.0296630859375, logit=15.0, token_id=17367, metadata=None))), (9441, (8, PredictedToken(token=' Church', prob=0.0262451171875, logit=14.875, token_id=9441, metadata=None))), (39794, (11, PredictedToken(token=' Desk', prob=0.0096435546875, logit=13.875, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:17 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:17 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:37:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     patch_prediction=['\" Tennis\"[58251] (p=0.637, logit=19.625)', '\" Boxing\"[72683] (p=0.110, logit=17.875)', '\" A\"[362] (p=0.097, logit=17.750)', '\" The\"[578] (p=0.067, logit=17.375)', '\" TEN\"[75366] (p=0.015, logit=15.875)']\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.621, logit=20.125)', '\" Pressure\"[40090] (p=0.178, logit=18.875)', '\" The\"[578] (p=0.108, logit=18.375)', '\" R\"[432] (p=0.013, logit=16.250)', '\" O\"[507] (p=0.009, logit=15.875)']\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.62109375, logit=20.125, token_id=87213, metadata=None))), (40090, (2, PredictedToken(token=' Pressure', prob=0.177734375, logit=18.875, token_id=40090, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.01287841796875, logit=16.25, token_id=432, metadata=None))), (423, (12, PredictedToken(token=' D', prob=0.002105712890625, logit=14.4375, token_id=423, metadata=None))), (97796, (40, PredictedToken(token=' Skate', prob=0.00034332275390625, logit=12.625, token_id=97796, metadata=None))), (16478, (579, PredictedToken(token=' Chair', prob=3.3676624298095703e-06, logit=8.0, token_id=16478, metadata=None))), (15429, (1023, PredictedToken(token=' Hospital', prob=1.5422701835632324e-06, logit=7.21875, token_id=15429, metadata=None)))])\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.441, logit=19.375)', '\" D\"[423] (p=0.268, logit=18.875)', '\" R\"[432] (p=0.099, logit=17.875)', '\" The\"[578] (p=0.087, logit=17.750)', '\" A\"[362] (p=0.036, logit=16.875)']\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.44140625, logit=19.375, token_id=97796, metadata=None))), (423, (2, PredictedToken(token=' D', prob=0.267578125, logit=18.875, token_id=423, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.0986328125, logit=17.875, token_id=432, metadata=None))), (40090, (6, PredictedToken(token=' Pressure', prob=0.01513671875, logit=16.0, token_id=40090, metadata=None))), (16478, (9, PredictedToken(token=' Chair', prob=0.0029754638671875, logit=14.375, token_id=16478, metadata=None))), (87213, (20, PredictedToken(token=' Oven', prob=0.00075531005859375, logit=13.0, token_id=87213, metadata=None))), (15429, (106, PredictedToken(token=' Hospital', prob=5.459785461425781e-05, logit=10.375, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:18 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:18 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:37:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:19 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.688, logit=20.500)', '\" Z\"[1901] (p=0.105, logit=18.625)', '\" The\"[578] (p=0.105, logit=18.625)', '\" BE\"[7354] (p=0.044, logit=17.750)', '\" A\"[362] (p=0.013, logit=16.500)']\n",
      "2025-09-15 09:37:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     clean_prediction=['\" St\"[800] (p=0.727, logit=20.125)', '\" The\"[578] (p=0.087, logit=18.000)', '\" Coffee\"[27171] (p=0.060, logit=17.625)', '\" A\"[362] (p=0.041, logit=17.250)', '\" ST\"[4015] (p=0.010, logit=15.812)']\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     clean_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.7265625, logit=20.125, token_id=800, metadata=None))), (27171, (3, PredictedToken(token=' Coffee', prob=0.0595703125, logit=17.625, token_id=27171, metadata=None))), (65197, (7, PredictedToken(token=' Surf', prob=0.007568359375, logit=15.5625, token_id=65197, metadata=None))), (83499, (22, PredictedToken(token=' Tooth', prob=0.00109100341796875, logit=13.625, token_id=83499, metadata=None))), (14588, (58, PredictedToken(token=' Dog', prob=0.00021457672119140625, logit=12.0, token_id=14588, metadata=None))), (22725, (62, PredictedToken(token=' Orange', prob=0.0001678466796875, logit=11.75, token_id=22725, metadata=None))), (84008, (259, PredictedToken(token=' Sheep', prob=1.138448715209961e-05, logit=9.0625, token_id=84008, metadata=None)))])\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.711, logit=20.125)', '\" The\"[578] (p=0.085, logit=18.000)', '\" St\"[800] (p=0.066, logit=17.750)', '\" A\"[362] (p=0.028, logit=16.875)', '\" DO\"[9503] (p=0.024, logit=16.750)']\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.7109375, logit=20.125, token_id=14588, metadata=None))), (800, (3, PredictedToken(token=' St', prob=0.06591796875, logit=17.75, token_id=800, metadata=None))), (84008, (6, PredictedToken(token=' Sheep', prob=0.0167236328125, logit=16.375, token_id=84008, metadata=None))), (65197, (8, PredictedToken(token=' Surf', prob=0.0045166015625, logit=15.0625, token_id=65197, metadata=None))), (22725, (21, PredictedToken(token=' Orange', prob=0.00121307373046875, logit=13.75, token_id=22725, metadata=None))), (83499, (35, PredictedToken(token=' Tooth', prob=0.0005035400390625, logit=12.875, token_id=83499, metadata=None))), (27171, (79, PredictedToken(token=' Coffee', prob=9.34600830078125e-05, logit=11.1875, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:20 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:20 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.520, logit=18.500)', '\" The\"[578] (p=0.149, logit=17.250)', '\" Mall\"[32498] (p=0.062, logit=16.375)', '\" A\"[362] (p=0.062, logit=16.375)', '\" None\"[2290] (p=0.031, logit=15.688)']\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     clean_prediction=['\" Dish\"[49268] (p=0.617, logit=20.250)', '\" Food\"[12369] (p=0.177, logit=19.000)', '\" The\"[578] (p=0.121, logit=18.625)', '\" A\"[362] (p=0.027, logit=17.125)', '\" DIS\"[12244] (p=0.006, logit=15.625)']\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     clean_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.6171875, logit=20.25, token_id=49268, metadata=None))), (12369, (2, PredictedToken(token=' Food', prob=0.1767578125, logit=19.0, token_id=12369, metadata=None))), (17367, (21, PredictedToken(token=' Factory', prob=0.000637054443359375, logit=13.375, token_id=17367, metadata=None))), (68027, (40, PredictedToken(token=' Sax', prob=0.00028228759765625, logit=12.5625, token_id=68027, metadata=None))), (16730, (1588, PredictedToken(token=' Museum', prob=8.195638656616211e-07, logit=6.71875, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:37:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:21 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.338, logit=18.500)', '\" Sax\"[68027] (p=0.232, logit=18.125)', '\" The\"[578] (p=0.160, logit=17.750)', '\" Factory\"[17367] (p=0.110, logit=17.375)', '\" A\"[362] (p=0.041, logit=16.375)']\n",
      "2025-09-15 09:37:21 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.337890625, logit=18.5, token_id=16730, metadata=None))), (68027, (2, PredictedToken(token=' Sax', prob=0.232421875, logit=18.125, token_id=68027, metadata=None))), (17367, (4, PredictedToken(token=' Factory', prob=0.10986328125, logit=17.375, token_id=17367, metadata=None))), (49268, (22, PredictedToken(token=' Dish', prob=0.0011444091796875, logit=12.8125, token_id=49268, metadata=None))), (12369, (74, PredictedToken(token=' Food', prob=0.00017547607421875, logit=10.9375, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:21 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:37:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:21 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.543, logit=19.250)', '\" Hospital\"[15429] (p=0.177, logit=18.125)', '\" The\"[578] (p=0.121, logit=17.750)', '\" A\"[362] (p=0.039, logit=16.625)', '\" Toilet\"[82994] (p=0.017, logit=15.812)']\n",
      "2025-09-15 09:37:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.852, logit=22.000)', '\" Bat\"[16488] (p=0.102, logit=19.875)', '\" The\"[578] (p=0.018, logit=18.125)', '\" Tub\"[40640] (p=0.006, logit=17.000)', '\" A\"[362] (p=0.005, logit=16.875)']\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.8515625, logit=22.0, token_id=57551, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.10205078125, logit=19.875, token_id=16488, metadata=None))), (41785, (13, PredictedToken(token=' Spin', prob=0.0004711151123046875, logit=14.5, token_id=41785, metadata=None))), (17367, (70, PredictedToken(token=' Factory', prob=3.218650817871094e-05, logit=11.8125, token_id=17367, metadata=None))), (52466, (227, PredictedToken(token=' Warehouse', prob=3.382563591003418e-06, logit=9.5625, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     int_prediction=['\" Factory\"[17367] (p=0.598, logit=20.625)', '\" Sink\"[57551] (p=0.250, logit=19.750)', '\" The\"[578] (p=0.043, logit=18.000)', '\" Bat\"[16488] (p=0.038, logit=17.875)', '\" FACT\"[59643] (p=0.011, logit=16.625)']\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     int_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.59765625, logit=20.625, token_id=17367, metadata=None))), (57551, (2, PredictedToken(token=' Sink', prob=0.25, logit=19.75, token_id=57551, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.038330078125, logit=17.875, token_id=16488, metadata=None))), (41785, (9, PredictedToken(token=' Spin', prob=0.002166748046875, logit=15.0, token_id=41785, metadata=None))), (52466, (10, PredictedToken(token=' Warehouse', prob=0.0020294189453125, logit=14.9375, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:22 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.785, logit=20.250)', '\" The\"[578] (p=0.106, logit=18.250)', '\" OR\"[2794] (p=0.024, logit=16.750)', '\" An\"[1556] (p=0.013, logit=16.125)', '\" orch\"[41245] (p=0.009, logit=15.812)']\n",
      "2025-09-15 09:37:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     clean_prediction=['\" Microwave\"[98641] (p=0.664, logit=20.750)', '\" To\"[2057] (p=0.131, logit=19.125)', '\" The\"[578] (p=0.102, logit=18.875)', '\" A\"[362] (p=0.026, logit=17.500)', '\" None\"[2290] (p=0.018, logit=17.125)']\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     clean_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.6640625, logit=20.75, token_id=98641, metadata=None))), (2057, (2, PredictedToken(token=' To', prob=0.130859375, logit=19.125, token_id=2057, metadata=None))), (2947, (139, PredictedToken(token=' Mar', prob=2.6702880859375e-05, logit=10.625, token_id=2947, metadata=None))), (47643, (555, PredictedToken(token=' Cel', prob=2.995133399963379e-06, logit=8.4375, token_id=47643, metadata=None))), (32749, (830, PredictedToken(token=' Carn', prob=1.6540288925170898e-06, logit=7.84375, token_id=32749, metadata=None)))])\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.738, logit=20.000)', '\" The\"[578] (p=0.061, logit=17.500)', '\" MAR\"[38599] (p=0.037, logit=17.000)', '\" Microwave\"[98641] (p=0.037, logit=17.000)', '\" Carn\"[32749] (p=0.029, logit=16.750)']\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.73828125, logit=20.0, token_id=2947, metadata=None))), (98641, (4, PredictedToken(token=' Microwave', prob=0.03662109375, logit=17.0, token_id=98641, metadata=None))), (32749, (5, PredictedToken(token=' Carn', prob=0.028564453125, logit=16.75, token_id=32749, metadata=None))), (2057, (13, PredictedToken(token=' To', prob=0.002349853515625, logit=14.25, token_id=2057, metadata=None))), (47643, (18, PredictedToken(token=' Cel', prob=0.0014190673828125, logit=13.75, token_id=47643, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:23 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     patch_prediction=['\" Charm\"[58600] (p=0.605, logit=19.000)', '\" Chain\"[29625] (p=0.223, logit=18.000)', '\" The\"[578] (p=0.050, logit=16.500)', '\" A\"[362] (p=0.018, logit=15.500)', '\" CH\"[6969] (p=0.016, logit=15.375)']\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.828, logit=20.750)', '\" The\"[578] (p=0.068, logit=18.250)', '\" BE\"[7354] (p=0.047, logit=17.875)', '\" A\"[362] (p=0.015, logit=16.750)', '\" Monkey\"[58937] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.828125, logit=20.75, token_id=24941, metadata=None))), (58937, (5, PredictedToken(token=' Monkey', prob=0.00921630859375, logit=16.25, token_id=58937, metadata=None))), (469, (10, PredictedToken(token=' E', prob=0.0010986328125, logit=14.125, token_id=469, metadata=None))), (800, (11, PredictedToken(token=' St', prob=0.0010986328125, logit=14.125, token_id=800, metadata=None))), (81501, (393, PredictedToken(token=' Pendant', prob=4.76837158203125e-06, logit=8.6875, token_id=81501, metadata=None)))])\n",
      "2025-09-15 09:37:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.648, logit=19.875)', '\" Monkey\"[58937] (p=0.128, logit=18.250)', '\" Bear\"[24941] (p=0.088, logit=17.875)', '\" The\"[578] (p=0.037, logit=17.000)', '\" MON\"[29637] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.6484375, logit=19.875, token_id=469, metadata=None))), (58937, (2, PredictedToken(token=' Monkey', prob=0.1279296875, logit=18.25, token_id=58937, metadata=None))), (24941, (3, PredictedToken(token=' Bear', prob=0.087890625, logit=17.875, token_id=24941, metadata=None))), (800, (7, PredictedToken(token=' St', prob=0.0086669921875, logit=15.5625, token_id=800, metadata=None))), (81501, (40, PredictedToken(token=' Pendant', prob=0.00029754638671875, logit=12.1875, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:24 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     patch_prediction=['\" Mall\"[32498] (p=0.391, logit=19.125)', '\" Church\"[9441] (p=0.344, logit=19.000)', '\" The\"[578] (p=0.127, logit=18.000)', '\" A\"[362] (p=0.028, logit=16.500)', '\" Jeans\"[82507] (p=0.013, logit=15.750)']\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.863, logit=20.375)', '\" Pants\"[67553] (p=0.033, logit=17.125)', '\" The\"[578] (p=0.033, logit=17.125)', '\" SH\"[6570] (p=0.011, logit=16.000)', '\" A\"[362] (p=0.005, logit=15.312)']\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.86328125, logit=20.375, token_id=55807, metadata=None))), (67553, (3, PredictedToken(token=' Pants', prob=0.033447265625, logit=17.125, token_id=67553, metadata=None))), (14937, (20, PredictedToken(token=' Ash', prob=0.000652313232421875, logit=13.1875, token_id=14937, metadata=None))), (4783, (61, PredictedToken(token=' House', prob=0.0001373291015625, logit=11.625, token_id=4783, metadata=None))), (38571, (95, PredictedToken(token=' Theater', prob=6.4849853515625e-05, logit=10.875, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.512, logit=19.125)', '\" House\"[4783] (p=0.146, logit=17.875)', '\" Shirt\"[55807] (p=0.101, logit=17.500)', '\" The\"[578] (p=0.079, logit=17.250)', '\" Pants\"[67553] (p=0.026, logit=16.125)']\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.51171875, logit=19.125, token_id=38571, metadata=None))), (4783, (2, PredictedToken(token=' House', prob=0.146484375, logit=17.875, token_id=4783, metadata=None))), (55807, (3, PredictedToken(token=' Shirt', prob=0.1005859375, logit=17.5, token_id=55807, metadata=None))), (67553, (5, PredictedToken(token=' Pants', prob=0.0255126953125, logit=16.125, token_id=67553, metadata=None))), (14937, (47, PredictedToken(token=' Ash', prob=0.0004119873046875, logit=12.0, token_id=14937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:24 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:24 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-15 09:37:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.859, logit=20.875)', '\" The\"[578] (p=0.071, logit=18.375)', '\" Fl\"[3061] (p=0.016, logit=16.875)', '\" violin\"[63137] (p=0.008, logit=16.250)', '\" There\"[2684] (p=0.004, logit=15.562)']\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.404, logit=18.750)', '\" The\"[578] (p=0.190, logit=18.000)', '\" Smart\"[16147] (p=0.168, logit=17.875)', '\" A\"[362] (p=0.033, logit=16.250)', '\" TABLE\"[14700] (p=0.024, logit=15.938)']\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.404296875, logit=18.75, token_id=58403, metadata=None))), (16147, (3, PredictedToken(token=' Smart', prob=0.16796875, logit=17.875, token_id=16147, metadata=None))), (19111, (6, PredictedToken(token=' Bus', prob=0.015625, logit=15.5, token_id=19111, metadata=None))), (40759, (9, PredictedToken(token=' Harmon', prob=0.009521484375, logit=15.0, token_id=40759, metadata=None))), (52466, (10, PredictedToken(token=' Warehouse', prob=0.009521484375, logit=15.0, token_id=52466, metadata=None))), (3420, (36, PredictedToken(token=' Trump', prob=0.000885009765625, logit=12.625, token_id=3420, metadata=None)))])\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.676, logit=19.875)', '\" Trump\"[3420] (p=0.193, logit=18.625)', '\" The\"[578] (p=0.055, logit=17.375)', '\" Bus\"[19111] (p=0.008, logit=15.500)', '\" TR\"[5091] (p=0.007, logit=15.250)']\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.67578125, logit=19.875, token_id=40759, metadata=None))), (3420, (2, PredictedToken(token=' Trump', prob=0.193359375, logit=18.625, token_id=3420, metadata=None))), (19111, (4, PredictedToken(token=' Bus', prob=0.00848388671875, logit=15.5, token_id=19111, metadata=None))), (16147, (15, PredictedToken(token=' Smart', prob=0.001678466796875, logit=13.875, token_id=16147, metadata=None))), (58403, (34, PredictedToken(token=' Tablet', prob=0.00037384033203125, logit=12.375, token_id=58403, metadata=None))), (52466, (47, PredictedToken(token=' Warehouse', prob=0.0002002716064453125, logit=11.75, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:25 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:25 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:37:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.816, logit=20.875)', '\" The\"[578] (p=0.110, logit=18.875)', '\" P\"[393] (p=0.017, logit=17.000)', '\" It\"[1102] (p=0.005, logit=15.812)', '\" Uk\"[60413] (p=0.004, logit=15.438)']\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.758, logit=20.125)', '\" The\"[578] (p=0.116, logit=18.250)', '\" Dog\"[14588] (p=0.029, logit=16.875)', '\" A\"[362] (p=0.020, logit=16.500)', '\" There\"[2684] (p=0.012, logit=16.000)']\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.7578125, logit=20.125, token_id=48035, metadata=None))), (14588, (3, PredictedToken(token=' Dog', prob=0.029296875, logit=16.875, token_id=14588, metadata=None))), (356, (12, PredictedToken(token=' C', prob=0.0021209716796875, logit=14.25, token_id=356, metadata=None))), (1630, (22, PredictedToken(token=' X', prob=0.00083160400390625, logit=13.3125, token_id=1630, metadata=None)))])\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.836, logit=21.000)', '\" The\"[578] (p=0.100, logit=18.875)', '\" Gir\"[48035] (p=0.012, logit=16.750)', '\" X\"[1630] (p=0.006, logit=16.000)', '\" There\"[2684] (p=0.005, logit=15.938)']\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.8359375, logit=21.0, token_id=356, metadata=None))), (48035, (3, PredictedToken(token=' Gir', prob=0.01190185546875, logit=16.75, token_id=48035, metadata=None))), (1630, (4, PredictedToken(token=' X', prob=0.005615234375, logit=16.0, token_id=1630, metadata=None))), (14588, (8, PredictedToken(token=' Dog', prob=0.003204345703125, logit=15.4375, token_id=14588, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:26 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:26 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:37:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.656, logit=19.625)', '\" The\"[578] (p=0.129, logit=18.000)', '\" A\"[362] (p=0.061, logit=17.250)', '\" Surf\"[65197] (p=0.054, logit=17.125)', '\" SUR\"[53083] (p=0.014, logit=15.812)']\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.719, logit=19.875)', '\" The\"[578] (p=0.142, logit=18.250)', '\" Mouse\"[18191] (p=0.036, logit=16.875)', '\" TR\"[5091] (p=0.028, logit=16.625)', '\" A\"[362] (p=0.010, logit=15.562)']\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.71875, logit=19.875, token_id=3420, metadata=None))), (18191, (3, PredictedToken(token=' Mouse', prob=0.035888671875, logit=16.875, token_id=18191, metadata=None))), (47759, (6, PredictedToken(token=' Guitar', prob=0.005859375, logit=15.0625, token_id=47759, metadata=None))), (423, (12, PredictedToken(token=' D', prob=0.002288818359375, logit=14.125, token_id=423, metadata=None))), (16488, (42, PredictedToken(token=' Bat', prob=0.000274658203125, logit=12.0, token_id=16488, metadata=None))), (83499, (68, PredictedToken(token=' Tooth', prob=0.0001373291015625, logit=11.3125, token_id=83499, metadata=None))), (100031, (71, PredictedToken(token=' Mosque', prob=0.00012969970703125, logit=11.25, token_id=100031, metadata=None)))])\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.715, logit=19.875)', '\" The\"[578] (p=0.076, logit=17.625)', '\" Mouse\"[18191] (p=0.046, logit=17.125)', '\" A\"[362] (p=0.046, logit=17.125)', '\" BAT\"[79081] (p=0.041, logit=17.000)']\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.71484375, logit=19.875, token_id=16488, metadata=None))), (18191, (4, PredictedToken(token=' Mouse', prob=0.0458984375, logit=17.125, token_id=18191, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.0115966796875, logit=15.75, token_id=423, metadata=None))), (100031, (12, PredictedToken(token=' Mosque', prob=0.0022735595703125, logit=14.125, token_id=100031, metadata=None))), (47759, (20, PredictedToken(token=' Guitar', prob=0.00107574462890625, logit=13.375, token_id=47759, metadata=None))), (3420, (210, PredictedToken(token=' Trump', prob=1.7404556274414062e-05, logit=9.25, token_id=3420, metadata=None))), (83499, (276, PredictedToken(token=' Tooth', prob=1.1265277862548828e-05, logit=8.8125, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:27 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:37:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.602, logit=20.375)', '\" Chair\"[16478] (p=0.152, logit=19.000)', '\" The\"[578] (p=0.152, logit=19.000)', '\" A\"[362] (p=0.021, logit=17.000)', '\" There\"[2684] (p=0.014, logit=16.625)']\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     clean_prediction=['\" Cherry\"[45805] (p=0.484, logit=18.625)', '\" Mango\"[91963] (p=0.179, logit=17.625)', '\" The\"[578] (p=0.096, logit=17.000)', '\" There\"[2684] (p=0.084, logit=16.875)', '\" CH\"[6969] (p=0.023, logit=15.562)']\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     clean_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.484375, logit=18.625, token_id=45805, metadata=None))), (91963, (2, PredictedToken(token=' Mango', prob=0.1787109375, logit=17.625, token_id=91963, metadata=None))), (6771, (9, PredictedToken(token=' Table', prob=0.007354736328125, logit=14.4375, token_id=6771, metadata=None))), (27171, (13, PredictedToken(token=' Coffee', prob=0.003265380859375, logit=13.625, token_id=27171, metadata=None))), (2522, (25, PredictedToken(token=' Sc', prob=0.0012054443359375, logit=12.625, token_id=2522, metadata=None)))])\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.582, logit=19.000)', '\" Table\"[6771] (p=0.089, logit=17.125)', '\" The\"[578] (p=0.048, logit=16.500)', '\" Mango\"[91963] (p=0.042, logit=16.375)', '\" There\"[2684] (p=0.042, logit=16.375)']\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.58203125, logit=19.0, token_id=27171, metadata=None))), (6771, (2, PredictedToken(token=' Table', prob=0.08935546875, logit=17.125, token_id=6771, metadata=None))), (91963, (5, PredictedToken(token=' Mango', prob=0.042236328125, logit=16.375, token_id=91963, metadata=None))), (45805, (6, PredictedToken(token=' Cherry', prob=0.037353515625, logit=16.25, token_id=45805, metadata=None))), (2522, (9, PredictedToken(token=' Sc', prob=0.01287841796875, logit=15.1875, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:28 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:37:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.453, logit=18.375)', '\" Toilet\"[82994] (p=0.188, logit=17.500)', '\" The\"[578] (p=0.146, logit=17.250)', '\" A\"[362] (p=0.033, logit=15.750)', '\" Harmon\"[40759] (p=0.027, logit=15.562)']\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.406, logit=20.000)', '\" Microwave\"[98641] (p=0.359, logit=19.875)', '\" The\"[578] (p=0.132, logit=18.875)', '\" A\"[362] (p=0.023, logit=17.125)', '\" Tow\"[41493] (p=0.016, logit=16.750)']\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.40625, logit=20.0, token_id=39247, metadata=None))), (98641, (2, PredictedToken(token=' Microwave', prob=0.359375, logit=19.875, token_id=98641, metadata=None))), (41493, (5, PredictedToken(token=' Tow', prob=0.0157470703125, logit=16.75, token_id=41493, metadata=None))), (74968, (19, PredictedToken(token=' Razor', prob=0.00078582763671875, logit=13.75, token_id=74968, metadata=None))), (47759, (350, PredictedToken(token=' Guitar', prob=5.632638931274414e-06, logit=8.8125, token_id=47759, metadata=None)))])\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     int_prediction=['\" Razor\"[74968] (p=0.645, logit=20.000)', '\" Tow\"[41493] (p=0.112, logit=18.250)', '\" The\"[578] (p=0.087, logit=18.000)', '\" Microwave\"[98641] (p=0.047, logit=17.375)', '\" A\"[362] (p=0.041, logit=17.250)']\n",
      "2025-09-15 09:37:29 src.selection.optimization INFO     int_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.64453125, logit=20.0, token_id=74968, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.11181640625, logit=18.25, token_id=41493, metadata=None))), (98641, (4, PredictedToken(token=' Microwave', prob=0.046630859375, logit=17.375, token_id=98641, metadata=None))), (47759, (14, PredictedToken(token=' Guitar', prob=0.00150299072265625, logit=13.9375, token_id=47759, metadata=None))), (39247, (392, PredictedToken(token=' Slow', prob=7.3909759521484375e-06, logit=8.625, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:30 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:30 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:37:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:30 src.selection.optimization INFO     patch_prediction=['\" Tie\"[59825] (p=0.385, logit=18.375)', '\" Ank\"[57915] (p=0.233, logit=17.875)', '\" Watch\"[10573] (p=0.097, logit=17.000)', '\" Dress\"[29318] (p=0.076, logit=16.750)', '\" The\"[578] (p=0.052, logit=16.375)']\n",
      "2025-09-15 09:37:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:30 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.680, logit=20.000)', '\" The\"[578] (p=0.134, logit=18.375)', '\" Ti\"[23126] (p=0.038, logit=17.125)', '\" A\"[362] (p=0.034, logit=17.000)', '\" LO\"[5125] (p=0.021, logit=16.500)']\n",
      "2025-09-15 09:37:30 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.6796875, logit=20.0, token_id=445, metadata=None))), (23126, (3, PredictedToken(token=' Ti', prob=0.038330078125, logit=17.125, token_id=23126, metadata=None))), (13597, (9, PredictedToken(token=' Pen', prob=0.004302978515625, logit=14.9375, token_id=13597, metadata=None))), (37326, (56, PredictedToken(token=' Swe', prob=0.0002765655517578125, logit=12.1875, token_id=37326, metadata=None))), (79189, (85, PredictedToken(token=' Elephant', prob=0.00011491775512695312, logit=11.3125, token_id=79189, metadata=None))), (22050, (88, PredictedToken(token=' Hat', prob=0.00010156631469726562, logit=11.1875, token_id=22050, metadata=None))), (48665, (274, PredictedToken(token=' Raspberry', prob=1.3709068298339844e-05, logit=9.1875, token_id=48665, metadata=None)))])\n",
      "2025-09-15 09:37:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.883, logit=20.750)', '\" The\"[578] (p=0.039, logit=17.625)', '\" Pen\"[13597] (p=0.018, logit=16.875)', '\" A\"[362] (p=0.013, logit=16.500)', '\" There\"[2684] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.8828125, logit=20.75, token_id=37326, metadata=None))), (13597, (3, PredictedToken(token=' Pen', prob=0.018310546875, logit=16.875, token_id=13597, metadata=None))), (22050, (7, PredictedToken(token=' Hat', prob=0.0026397705078125, logit=14.9375, token_id=22050, metadata=None))), (79189, (24, PredictedToken(token=' Elephant', prob=0.000457763671875, logit=13.1875, token_id=79189, metadata=None))), (23126, (32, PredictedToken(token=' Ti', prob=0.0003795623779296875, logit=13.0, token_id=23126, metadata=None))), (445, (55, PredictedToken(token=' L', prob=0.00016880035400390625, logit=12.1875, token_id=445, metadata=None))), (48665, (76, PredictedToken(token=' Raspberry', prob=9.012222290039062e-05, logit=11.5625, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:31 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.875, logit=20.125)', '\" The\"[578] (p=0.039, logit=17.000)', '\" None\"[2290] (p=0.009, logit=15.500)', '\" There\"[2684] (p=0.009, logit=15.500)', '\" Rose\"[16344] (p=0.008, logit=15.438)']\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.641, logit=21.250)', '\" The\"[578] (p=0.162, logit=19.875)', '\" Car\"[3341] (p=0.098, logit=19.375)', '\" A\"[362] (p=0.032, logit=18.250)', '\" There\"[2684] (p=0.015, logit=17.500)']\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.640625, logit=21.25, token_id=45332, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.09814453125, logit=19.375, token_id=3341, metadata=None))), (423, (12, PredictedToken(token=' D', prob=0.00139617919921875, logit=15.125, token_id=423, metadata=None))), (445, (21, PredictedToken(token=' L', prob=0.000701904296875, logit=14.4375, token_id=445, metadata=None))), (43950, (147, PredictedToken(token=' Lav', prob=1.990795135498047e-05, logit=10.875, token_id=43950, metadata=None)))])\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     int_prediction=['\" Lav\"[43950] (p=0.590, logit=20.500)', '\" L\"[445] (p=0.170, logit=19.250)', '\" The\"[578] (p=0.117, logit=18.875)', '\" D\"[423] (p=0.026, logit=17.375)', '\" There\"[2684] (p=0.020, logit=17.125)']\n",
      "2025-09-15 09:37:31 src.selection.optimization INFO     int_track=OrderedDict([(43950, (1, PredictedToken(token=' Lav', prob=0.58984375, logit=20.5, token_id=43950, metadata=None))), (445, (2, PredictedToken(token=' L', prob=0.169921875, logit=19.25, token_id=445, metadata=None))), (423, (4, PredictedToken(token=' D', prob=0.0260009765625, logit=17.375, token_id=423, metadata=None))), (45332, (6, PredictedToken(token=' Boat', prob=0.0157470703125, logit=16.875, token_id=45332, metadata=None))), (3341, (9, PredictedToken(token=' Car', prob=0.0035247802734375, logit=15.375, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:31 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:32 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:37:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:32 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.871, logit=20.750)', '\" The\"[578] (p=0.063, logit=18.125)', '\" A\"[362] (p=0.009, logit=16.125)', '\" Coat\"[68867] (p=0.007, logit=15.938)', '\" dress\"[8679] (p=0.005, logit=15.688)']\n",
      "2025-09-15 09:37:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:32 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.609, logit=20.125)', '\" The\"[578] (p=0.175, logit=18.875)', '\" Viol\"[30555] (p=0.136, logit=18.625)', '\" A\"[362] (p=0.009, logit=15.938)', '\" There\"[2684] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:37:32 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.609375, logit=20.125, token_id=1630, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.1357421875, logit=18.625, token_id=30555, metadata=None))), (21424, (51, PredictedToken(token=' Football', prob=0.00014972686767578125, logit=11.8125, token_id=21424, metadata=None))), (34954, (60, PredictedToken(token=' Mirror', prob=0.0001239776611328125, logit=11.625, token_id=34954, metadata=None))), (33711, (162, PredictedToken(token=' Suit', prob=2.4437904357910156e-05, logit=10.0, token_id=33711, metadata=None))), (91782, (1342, PredictedToken(token=' Shorts', prob=8.121132850646973e-07, logit=6.59375, token_id=91782, metadata=None)))])\n",
      "2025-09-15 09:37:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.605, logit=19.000)', '\" Shorts\"[91782] (p=0.153, logit=17.625)', '\" The\"[578] (p=0.072, logit=16.875)', '\" SU\"[15857] (p=0.030, logit=16.000)', '\" A\"[362] (p=0.013, logit=15.188)']\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.60546875, logit=19.0, token_id=33711, metadata=None))), (91782, (2, PredictedToken(token=' Shorts', prob=0.1533203125, logit=17.625, token_id=91782, metadata=None))), (21424, (7, PredictedToken(token=' Football', prob=0.009765625, logit=14.875, token_id=21424, metadata=None))), (34954, (28, PredictedToken(token=' Mirror', prob=0.000911712646484375, logit=12.5, token_id=34954, metadata=None))), (30555, (33, PredictedToken(token=' Viol', prob=0.000553131103515625, logit=12.0, token_id=30555, metadata=None))), (1630, (197, PredictedToken(token=' X', prob=3.7670135498046875e-05, logit=9.3125, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:33 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:33 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.586, logit=19.375)', '\" The\"[578] (p=0.168, logit=18.125)', '\" Plum\"[84409] (p=0.070, logit=17.250)', '\" A\"[362] (p=0.023, logit=16.125)', '\" None\"[2290] (p=0.017, logit=15.812)']\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.914, logit=21.125)', '\" The\"[578] (p=0.046, logit=18.125)', '\" Orange\"[22725] (p=0.009, logit=16.500)', '\" PE\"[22557] (p=0.005, logit=15.812)', '\" There\"[2684] (p=0.002, logit=15.125)']\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.9140625, logit=21.125, token_id=64695, metadata=None))), (22725, (3, PredictedToken(token=' Orange', prob=0.00897216796875, logit=16.5, token_id=22725, metadata=None))), (30616, (25, PredictedToken(token=' Rice', prob=0.0002536773681640625, logit=12.9375, token_id=30616, metadata=None))), (98641, (380, PredictedToken(token=' Microwave', prob=3.4123659133911133e-06, logit=8.625, token_id=98641, metadata=None)))])\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.863, logit=19.625)', '\" The\"[578] (p=0.043, logit=16.625)', '\" Cook\"[12797] (p=0.012, logit=15.375)', '\" Peach\"[64695] (p=0.008, logit=15.000)', '\" Apple\"[8325] (p=0.005, logit=14.375)']\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.86328125, logit=19.625, token_id=30616, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.00848388671875, logit=15.0, token_id=64695, metadata=None))), (22725, (10, PredictedToken(token=' Orange', prob=0.00311279296875, logit=14.0, token_id=22725, metadata=None))), (98641, (176, PredictedToken(token=' Microwave', prob=3.266334533691406e-05, logit=9.4375, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:33 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:33 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:37:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     patch_prediction=['\" Boat\"[45332] (p=0.492, logit=19.625)', '\" The\"[578] (p=0.181, logit=18.625)', '\" Elephant\"[79189] (p=0.159, logit=18.500)', '\" BO\"[7967] (p=0.031, logit=16.875)', '\" A\"[362] (p=0.028, logit=16.750)']\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.609, logit=20.000)', '\" Mirror\"[34954] (p=0.254, logit=19.125)', '\" The\"[578] (p=0.050, logit=17.500)', '\" Soap\"[61731] (p=0.010, logit=15.875)', '\" A\"[362] (p=0.007, logit=15.562)']\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.609375, logit=20.0, token_id=445, metadata=None))), (34954, (2, PredictedToken(token=' Mirror', prob=0.25390625, logit=19.125, token_id=34954, metadata=None))), (5340, (8, PredictedToken(token=' Har', prob=0.004638671875, logit=15.125, token_id=5340, metadata=None))), (3804, (15, PredictedToken(token=' Sub', prob=0.0018157958984375, logit=14.1875, token_id=3804, metadata=None))), (17810, (28, PredictedToken(token=' Cat', prob=0.000553131103515625, logit=13.0, token_id=17810, metadata=None))), (67553, (42, PredictedToken(token=' Pants', prob=0.00035858154296875, logit=12.5625, token_id=67553, metadata=None))), (27217, (56, PredictedToken(token=' Train', prob=0.000217437744140625, logit=12.0625, token_id=27217, metadata=None)))])\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.766, logit=20.625)', '\" Sub\"[3804] (p=0.117, logit=18.750)', '\" The\"[578] (p=0.034, logit=17.500)', '\" Pants\"[67553] (p=0.014, logit=16.625)', '\" TRAIN\"[68609] (p=0.011, logit=16.375)']\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.765625, logit=20.625, token_id=27217, metadata=None))), (3804, (2, PredictedToken(token=' Sub', prob=0.1171875, logit=18.75, token_id=3804, metadata=None))), (67553, (4, PredictedToken(token=' Pants', prob=0.0140380859375, logit=16.625, token_id=67553, metadata=None))), (17810, (9, PredictedToken(token=' Cat', prob=0.0027618408203125, logit=15.0, token_id=17810, metadata=None))), (5340, (12, PredictedToken(token=' Har', prob=0.00167083740234375, logit=14.5, token_id=5340, metadata=None))), (445, (25, PredictedToken(token=' L', prob=0.00048065185546875, logit=13.25, token_id=445, metadata=None))), (34954, (40, PredictedToken(token=' Mirror', prob=0.0002918243408203125, logit=12.75, token_id=34954, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:34 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:37:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     patch_prediction=['\" Dolphin\"[96096] (p=0.883, logit=20.875)', '\" The\"[578] (p=0.064, logit=18.250)', '\" Lion\"[33199] (p=0.011, logit=16.500)', '\" D\"[423] (p=0.006, logit=15.938)', '\" A\"[362] (p=0.003, logit=15.250)']\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.777, logit=19.750)', '\" The\"[578] (p=0.072, logit=17.375)', '\" A\"[362] (p=0.034, logit=16.625)', '\" There\"[2684] (p=0.023, logit=16.250)', '\" None\"[2290] (p=0.013, logit=15.625)']\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.77734375, logit=19.75, token_id=16183, metadata=None))), (38930, (13, PredictedToken(token=' Bike', prob=0.0023193359375, logit=13.9375, token_id=38930, metadata=None))), (22607, (17, PredictedToken(token=' Cow', prob=0.00180816650390625, logit=13.6875, token_id=22607, metadata=None))), (49431, (23, PredictedToken(token=' Rabbit', prob=0.000965118408203125, logit=13.0625, token_id=49431, metadata=None)))])\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.520, logit=18.625)', '\" The\"[578] (p=0.116, logit=17.125)', '\" Rabbit\"[49431] (p=0.090, logit=16.875)', '\" There\"[2684] (p=0.038, logit=16.000)', '\" A\"[362] (p=0.038, logit=16.000)']\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.51953125, logit=18.625, token_id=22607, metadata=None))), (49431, (3, PredictedToken(token=' Rabbit', prob=0.09033203125, logit=16.875, token_id=49431, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.029296875, logit=15.75, token_id=38930, metadata=None))), (16183, (9, PredictedToken(token=' Hel', prob=0.006134033203125, logit=14.1875, token_id=16183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:35 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:35 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.910, logit=22.375)', '\" The\"[578] (p=0.058, logit=19.625)', '\" A\"[362] (p=0.011, logit=18.000)', '\" P\"[393] (p=0.004, logit=16.875)', '\" pear\"[38790] (p=0.003, logit=16.500)']\n",
      "2025-09-15 09:37:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.613, logit=20.750)', '\" The\"[578] (p=0.199, logit=19.625)', '\" There\"[2684] (p=0.073, logit=18.625)', '\" Pepper\"[52882] (p=0.031, logit=17.750)', '\" None\"[2290] (p=0.014, logit=17.000)']\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.61328125, logit=20.75, token_id=3341, metadata=None))), (52882, (4, PredictedToken(token=' Pepper', prob=0.030517578125, logit=17.75, token_id=52882, metadata=None))), (84409, (7, PredictedToken(token=' Plum', prob=0.00872802734375, logit=16.5, token_id=84409, metadata=None))), (16183, (9, PredictedToken(token=' Hel', prob=0.006011962890625, logit=16.125, token_id=16183, metadata=None))), (64695, (47, PredictedToken(token=' Peach', prob=0.00017070770263671875, logit=12.5625, token_id=64695, metadata=None))), (38673, (440, PredictedToken(token=' Yoga', prob=3.546476364135742e-06, logit=8.6875, token_id=38673, metadata=None)))])\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     int_prediction=['\" The\"[578] (p=0.273, logit=19.500)', '\" Peach\"[64695] (p=0.273, logit=19.500)', '\" Plum\"[84409] (p=0.241, logit=19.375)', '\" There\"[2684] (p=0.101, logit=18.500)', '\" None\"[2290] (p=0.020, logit=16.875)']\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     int_track=OrderedDict([(64695, (2, PredictedToken(token=' Peach', prob=0.2734375, logit=19.5, token_id=64695, metadata=None))), (84409, (3, PredictedToken(token=' Plum', prob=0.2412109375, logit=19.375, token_id=84409, metadata=None))), (52882, (7, PredictedToken(token=' Pepper', prob=0.01361083984375, logit=16.5, token_id=52882, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.00726318359375, logit=15.875, token_id=3341, metadata=None))), (16183, (15, PredictedToken(token=' Hel', prob=0.0013427734375, logit=14.1875, token_id=16183, metadata=None))), (38673, (71, PredictedToken(token=' Yoga', prob=0.00011730194091796875, logit=11.75, token_id=38673, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:36 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.781, logit=20.125)', '\" The\"[578] (p=0.105, logit=18.125)', '\" An\"[1556] (p=0.030, logit=16.875)', '\" It\"[1102] (p=0.009, logit=15.688)', '\" OT\"[8775] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.773, logit=19.750)', '\" The\"[578] (p=0.049, logit=17.000)', '\" Pepper\"[52882] (p=0.043, logit=16.875)', '\" St\"[800] (p=0.026, logit=16.375)', '\" There\"[2684] (p=0.023, logit=16.250)']\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.7734375, logit=19.75, token_id=1666, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.04345703125, logit=16.875, token_id=52882, metadata=None))), (800, (4, PredictedToken(token=' St', prob=0.0264892578125, logit=16.375, token_id=800, metadata=None))), (39794, (24, PredictedToken(token=' Desk', prob=0.0009613037109375, logit=13.0625, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:37:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     int_prediction=['\" Desk\"[39794] (p=0.400, logit=19.125)', '\" St\"[800] (p=0.312, logit=18.875)', '\" Pepper\"[52882] (p=0.070, logit=17.375)', '\" The\"[578] (p=0.062, logit=17.250)', '\" As\"[1666] (p=0.037, logit=16.750)']\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     int_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.400390625, logit=19.125, token_id=39794, metadata=None))), (800, (2, PredictedToken(token=' St', prob=0.3125, logit=18.875, token_id=800, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.06982421875, logit=17.375, token_id=52882, metadata=None))), (1666, (5, PredictedToken(token=' As', prob=0.037353515625, logit=16.75, token_id=1666, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:37 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.758, logit=20.375)', '\" The\"[578] (p=0.080, logit=18.125)', '\" Potato\"[78703] (p=0.062, logit=17.875)', '\" There\"[2684] (p=0.033, logit=17.250)', '\" None\"[2290] (p=0.007, logit=15.750)']\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.648, logit=19.250)', '\" Hel\"[16183] (p=0.087, logit=17.250)', '\" The\"[578] (p=0.087, logit=17.250)', '\" There\"[2684] (p=0.024, logit=15.938)', '\" A\"[362] (p=0.024, logit=15.938)']\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.6484375, logit=19.25, token_id=38930, metadata=None))), (16183, (3, PredictedToken(token=' Hel', prob=0.08740234375, logit=17.25, token_id=16183, metadata=None))), (91297, (35, PredictedToken(token=' Mushroom', prob=0.000591278076171875, logit=12.25, token_id=91297, metadata=None))), (87035, (60, PredictedToken(token=' Onion', prob=0.00021648406982421875, logit=11.25, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:37:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.672, logit=18.875)', '\" The\"[578] (p=0.080, logit=16.750)', '\" There\"[2684] (p=0.036, logit=15.938)', '\" An\"[1556] (p=0.028, logit=15.688)', '\" Hel\"[16183] (p=0.017, logit=15.188)']\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.671875, logit=18.875, token_id=87035, metadata=None))), (16183, (5, PredictedToken(token=' Hel', prob=0.016845703125, logit=15.1875, token_id=16183, metadata=None))), (91297, (7, PredictedToken(token=' Mushroom', prob=0.0157470703125, logit=15.125, token_id=91297, metadata=None))), (38930, (10, PredictedToken(token=' Bike', prob=0.00848388671875, logit=14.5, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:38 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.887, logit=21.250)', '\" The\"[578] (p=0.064, logit=18.625)', '\" VI\"[30768] (p=0.008, logit=16.500)', '\" violin\"[63137] (p=0.005, logit=16.000)', '\" Har\"[5340] (p=0.004, logit=15.938)']\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.766, logit=20.250)', '\" Hair\"[26781] (p=0.071, logit=17.875)', '\" The\"[578] (p=0.071, logit=17.875)', '\" A\"[362] (p=0.030, logit=17.000)', '\" Y\"[816] (p=0.008, logit=15.625)']\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.765625, logit=20.25, token_id=74968, metadata=None))), (26781, (3, PredictedToken(token=' Hair', prob=0.0712890625, logit=17.875, token_id=26781, metadata=None))), (816, (5, PredictedToken(token=' Y', prob=0.00750732421875, logit=15.625, token_id=816, metadata=None))), (27171, (21, PredictedToken(token=' Coffee', prob=0.0006561279296875, logit=13.1875, token_id=27171, metadata=None))), (31181, (78, PredictedToken(token=' Clar', prob=7.82012939453125e-05, logit=11.0625, token_id=31181, metadata=None))), (68027, (127, PredictedToken(token=' Sax', prob=3.933906555175781e-05, logit=10.375, token_id=68027, metadata=None)))])\n",
      "2025-09-15 09:37:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:39 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.535, logit=19.125)', '\" The\"[578] (p=0.223, logit=18.250)', '\" Razor\"[74968] (p=0.119, logit=17.625)', '\" A\"[362] (p=0.012, logit=15.312)', '\" There\"[2684] (p=0.010, logit=15.188)']\n",
      "2025-09-15 09:37:39 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.53515625, logit=19.125, token_id=68027, metadata=None))), (74968, (3, PredictedToken(token=' Razor', prob=0.119140625, logit=17.625, token_id=74968, metadata=None))), (816, (6, PredictedToken(token=' Y', prob=0.009765625, logit=15.125, token_id=816, metadata=None))), (26781, (14, PredictedToken(token=' Hair', prob=0.00262451171875, logit=13.8125, token_id=26781, metadata=None))), (27171, (17, PredictedToken(token=' Coffee', prob=0.001922607421875, logit=13.5, token_id=27171, metadata=None))), (31181, (21, PredictedToken(token=' Clar', prob=0.00141143798828125, logit=13.1875, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:39 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:39 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:37:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:39 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.918, logit=22.000)', '\" The\"[578] (p=0.046, logit=19.000)', '\" A\"[362] (p=0.010, logit=17.500)', '\" PE\"[22557] (p=0.008, logit=17.250)', '\" Grape\"[80629] (p=0.004, logit=16.500)']\n",
      "2025-09-15 09:37:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.848, logit=21.000)', '\" The\"[578] (p=0.079, logit=18.625)', '\" A\"[362] (p=0.018, logit=17.125)', '\" CO\"[7432] (p=0.011, logit=16.625)', '\" Swe\"[37326] (p=0.008, logit=16.375)']\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.84765625, logit=21.0, token_id=68867, metadata=None))), (37326, (5, PredictedToken(token=' Swe', prob=0.00830078125, logit=16.375, token_id=37326, metadata=None))), (40975, (35, PredictedToken(token=' Marker', prob=0.0002841949462890625, logit=13.0, token_id=40975, metadata=None))), (30558, (53, PredictedToken(token=' Ki', prob=0.000125885009765625, logit=12.1875, token_id=30558, metadata=None))), (67629, (94, PredictedToken(token=' Helmet', prob=4.363059997558594e-05, logit=11.125, token_id=67629, metadata=None))), (89077, (208, PredictedToken(token=' Strawberry', prob=1.329183578491211e-05, logit=9.9375, token_id=89077, metadata=None)))])\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     int_prediction=['\" Ki\"[30558] (p=0.918, logit=21.250)', '\" The\"[578] (p=0.046, logit=18.250)', '\" Strawberry\"[89077] (p=0.004, logit=15.875)', '\" A\"[362] (p=0.004, logit=15.875)', '\" K\"[735] (p=0.003, logit=15.625)']\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     int_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.91796875, logit=21.25, token_id=30558, metadata=None))), (89077, (4, PredictedToken(token=' Strawberry', prob=0.004241943359375, logit=15.875, token_id=89077, metadata=None))), (37326, (8, PredictedToken(token=' Swe', prob=0.00146484375, logit=14.8125, token_id=37326, metadata=None))), (67629, (18, PredictedToken(token=' Helmet', prob=0.000507354736328125, logit=13.75, token_id=67629, metadata=None))), (68867, (23, PredictedToken(token=' Coat', prob=0.000370025634765625, logit=13.4375, token_id=68867, metadata=None))), (40975, (41, PredictedToken(token=' Marker', prob=0.00012063980102539062, logit=12.3125, token_id=40975, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:40 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.906, logit=21.625)', '\" The\"[578] (p=0.058, logit=18.875)', '\" Raspberry\"[48665] (p=0.007, logit=16.750)', '\" Uk\"[60413] (p=0.003, logit=16.000)', '\" There\"[2684] (p=0.003, logit=15.812)']\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     clean_prediction=['\" Drum\"[46506] (p=0.459, logit=19.250)', '\" Sax\"[68027] (p=0.217, logit=18.500)', '\" The\"[578] (p=0.191, logit=18.375)', '\" DR\"[14644] (p=0.020, logit=16.125)', '\" There\"[2684] (p=0.020, logit=16.125)']\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     clean_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.458984375, logit=19.25, token_id=46506, metadata=None))), (68027, (2, PredictedToken(token=' Sax', prob=0.216796875, logit=18.5, token_id=68027, metadata=None))), (91782, (46, PredictedToken(token=' Shorts', prob=0.000347137451171875, logit=12.0625, token_id=91782, metadata=None))), (42609, (384, PredictedToken(token=' Pine', prob=9.238719940185547e-06, logit=8.4375, token_id=42609, metadata=None))), (80629, (468, PredictedToken(token=' Grape', prob=6.765127182006836e-06, logit=8.125, token_id=80629, metadata=None)))])\n",
      "2025-09-15 09:37:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.738, logit=19.750)', '\" Sax\"[68027] (p=0.061, logit=17.250)', '\" GRA\"[65120] (p=0.053, logit=17.125)', '\" The\"[578] (p=0.047, logit=17.000)', '\" There\"[2684] (p=0.016, logit=15.938)']\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.73828125, logit=19.75, token_id=80629, metadata=None))), (68027, (2, PredictedToken(token=' Sax', prob=0.060546875, logit=17.25, token_id=68027, metadata=None))), (46506, (10, PredictedToken(token=' Drum', prob=0.00341796875, logit=14.375, token_id=46506, metadata=None))), (42609, (12, PredictedToken(token=' Pine', prob=0.003204345703125, logit=14.3125, token_id=42609, metadata=None))), (91782, (75, PredictedToken(token=' Shorts', prob=0.00011682510375976562, logit=11.0, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:41 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:41 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.840, logit=20.625)', '\" The\"[578] (p=0.078, logit=18.250)', '\" E\"[469] (p=0.017, logit=16.750)', '\" Gir\"[48035] (p=0.012, logit=16.375)', '\" An\"[1556] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     clean_prediction=['\" Chair\"[16478] (p=0.668, logit=20.000)', '\" The\"[578] (p=0.132, logit=18.375)', '\" Ward\"[27738] (p=0.080, logit=17.875)', '\" CH\"[6969] (p=0.023, logit=16.625)', '\" A\"[362] (p=0.018, logit=16.375)']\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     clean_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.66796875, logit=20.0, token_id=16478, metadata=None))), (27738, (3, PredictedToken(token=' Ward', prob=0.080078125, logit=17.875, token_id=27738, metadata=None))), (17810, (29, PredictedToken(token=' Cat', prob=0.000537872314453125, logit=12.875, token_id=17810, metadata=None))), (96096, (31, PredictedToken(token=' Dolphin', prob=0.000507354736328125, logit=12.8125, token_id=96096, metadata=None)))])\n",
      "2025-09-15 09:37:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     int_prediction=['\" Cat\"[17810] (p=0.793, logit=19.375)', '\" The\"[578] (p=0.074, logit=17.000)', '\" CAT\"[45081] (p=0.040, logit=16.375)', '\" Chair\"[16478] (p=0.013, logit=15.250)', '\" Dolphin\"[96096] (p=0.008, logit=14.812)']\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     int_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.79296875, logit=19.375, token_id=17810, metadata=None))), (16478, (4, PredictedToken(token=' Chair', prob=0.0128173828125, logit=15.25, token_id=16478, metadata=None))), (96096, (5, PredictedToken(token=' Dolphin', prob=0.00830078125, logit=14.8125, token_id=96096, metadata=None))), (27738, (12, PredictedToken(token=' Ward', prob=0.002532958984375, logit=13.625, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:42 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.574, logit=18.750)', '\" Elm\"[65329] (p=0.164, logit=17.500)', '\" Stap\"[63606] (p=0.060, logit=16.500)', '\" The\"[578] (p=0.060, logit=16.500)', '\" None\"[2290] (p=0.021, logit=15.438)']\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.902, logit=19.625)', '\" The\"[578] (p=0.014, logit=15.438)', '\" PEN\"[81770] (p=0.012, logit=15.312)', '\" None\"[2290] (p=0.007, logit=14.812)', '\" Willow\"[65449] (p=0.007, logit=14.750)']\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.90234375, logit=19.625, token_id=13597, metadata=None))), (65449, (5, PredictedToken(token=' Willow', prob=0.00689697265625, logit=14.75, token_id=65449, metadata=None))), (18787, (7, PredictedToken(token=' Oak', prob=0.0034637451171875, logit=14.0625, token_id=18787, metadata=None))), (2522, (9, PredictedToken(token=' Sc', prob=0.002532958984375, logit=13.75, token_id=2522, metadata=None)))])\n",
      "2025-09-15 09:37:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.797, logit=19.500)', '\" Oak\"[18787] (p=0.084, logit=17.250)', '\" None\"[2290] (p=0.024, logit=16.000)', '\" Willow\"[65449] (p=0.013, logit=15.375)', '\" PEN\"[81770] (p=0.012, logit=15.312)']\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.796875, logit=19.5, token_id=13597, metadata=None))), (18787, (2, PredictedToken(token=' Oak', prob=0.083984375, logit=17.25, token_id=18787, metadata=None))), (65449, (4, PredictedToken(token=' Willow', prob=0.01287841796875, logit=15.375, token_id=65449, metadata=None))), (2522, (7, PredictedToken(token=' Sc', prob=0.00946044921875, logit=15.0625, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:43 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.680, logit=19.375)', '\" Baseball\"[38258] (p=0.104, logit=17.500)', '\" The\"[578] (p=0.063, logit=17.000)', '\" HEL\"[38757] (p=0.034, logit=16.375)', '\" A\"[362] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     clean_prediction=['\" Train\"[27217] (p=0.828, logit=20.375)', '\" The\"[578] (p=0.060, logit=17.750)', '\" Tr\"[1183] (p=0.019, logit=16.625)', '\" A\"[362] (p=0.017, logit=16.500)', '\" D\"[423] (p=0.015, logit=16.375)']\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     clean_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.828125, logit=20.375, token_id=27217, metadata=None))), (1183, (3, PredictedToken(token=' Tr', prob=0.0194091796875, logit=16.625, token_id=1183, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.01513671875, logit=16.375, token_id=423, metadata=None))), (21424, (7, PredictedToken(token=' Football', prob=0.00860595703125, logit=15.8125, token_id=21424, metadata=None))), (17367, (11, PredictedToken(token=' Factory', prob=0.003173828125, logit=14.8125, token_id=17367, metadata=None)))])\n",
      "2025-09-15 09:37:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.479, logit=20.375)', '\" Football\"[21424] (p=0.328, logit=20.000)', '\" D\"[423] (p=0.057, logit=18.250)', '\" The\"[578] (p=0.050, logit=18.125)', '\" A\"[362] (p=0.021, logit=17.250)']\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.478515625, logit=20.375, token_id=27217, metadata=None))), (21424, (2, PredictedToken(token=' Football', prob=0.328125, logit=20.0, token_id=21424, metadata=None))), (423, (3, PredictedToken(token=' D', prob=0.05712890625, logit=18.25, token_id=423, metadata=None))), (1183, (6, PredictedToken(token=' Tr', prob=0.02099609375, logit=17.25, token_id=1183, metadata=None))), (17367, (12, PredictedToken(token=' Factory', prob=0.00125885009765625, logit=14.4375, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:44 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     patch_prediction=['\" Shirt\"[55807] (p=0.785, logit=21.000)', '\" The\"[578] (p=0.121, logit=19.125)', '\" A\"[362] (p=0.021, logit=17.375)', '\" SH\"[6570] (p=0.016, logit=17.125)', '\" Dress\"[29318] (p=0.008, logit=16.375)']\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.582, logit=19.750)', '\" Hockey\"[41342] (p=0.147, logit=18.375)', '\" The\"[578] (p=0.130, logit=18.250)', '\" A\"[362] (p=0.029, logit=16.750)', '\" BASE\"[22984] (p=0.026, logit=16.625)']\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.58203125, logit=19.75, token_id=38258, metadata=None))), (41342, (2, PredictedToken(token=' Hockey', prob=0.1474609375, logit=18.375, token_id=41342, metadata=None))), (4923, (19, PredictedToken(token=' Sk', prob=0.0014495849609375, logit=13.75, token_id=4923, metadata=None))), (328, (27, PredictedToken(token=' S', prob=0.000774383544921875, logit=13.125, token_id=328, metadata=None))), (1901, (53, PredictedToken(token=' Z', prob=0.0002841949462890625, logit=12.125, token_id=1901, metadata=None)))])\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.797, logit=20.125)', '\" The\"[578] (p=0.058, logit=17.500)', '\" Sk\"[4923] (p=0.031, logit=16.875)', '\" Z\"[1901] (p=0.027, logit=16.750)', '\" Hockey\"[41342] (p=0.017, logit=16.250)']\n",
      "2025-09-15 09:37:44 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.796875, logit=20.125, token_id=328, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.031005859375, logit=16.875, token_id=4923, metadata=None))), (1901, (4, PredictedToken(token=' Z', prob=0.02734375, logit=16.75, token_id=1901, metadata=None))), (41342, (5, PredictedToken(token=' Hockey', prob=0.0166015625, logit=16.25, token_id=41342, metadata=None))), (38258, (9, PredictedToken(token=' Baseball', prob=0.003936767578125, logit=14.8125, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:45 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     patch_prediction=['\" Tie\"[59825] (p=0.652, logit=19.750)', '\" Gloves\"[68554] (p=0.211, logit=18.625)', '\" The\"[578] (p=0.047, logit=17.125)', '\" D\"[423] (p=0.009, logit=15.500)', '\" None\"[2290] (p=0.008, logit=15.312)']\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     clean_prediction=['\" Oak\"[18787] (p=0.887, logit=20.625)', '\" Tow\"[41493] (p=0.024, logit=17.000)', '\" The\"[578] (p=0.024, logit=17.000)', '\" Hick\"[79028] (p=0.021, logit=16.875)', '\" None\"[2290] (p=0.006, logit=15.625)']\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     clean_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.88671875, logit=20.625, token_id=18787, metadata=None))), (41493, (3, PredictedToken(token=' Tow', prob=0.0235595703125, logit=17.0, token_id=41493, metadata=None))), (79028, (4, PredictedToken(token=' Hick', prob=0.0208740234375, logit=16.875, token_id=79028, metadata=None))), (38258, (8, PredictedToken(token=' Baseball', prob=0.0023345947265625, logit=14.6875, token_id=38258, metadata=None))), (4923, (15, PredictedToken(token=' Sk', prob=0.000972747802734375, logit=13.8125, token_id=4923, metadata=None))), (29318, (18, PredictedToken(token=' Dress', prob=0.000713348388671875, logit=13.5, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.385, logit=19.125)', '\" Hick\"[79028] (p=0.206, logit=18.500)', '\" Baseball\"[38258] (p=0.125, logit=18.000)', '\" Tow\"[41493] (p=0.097, logit=17.750)', '\" Oak\"[18787] (p=0.052, logit=17.125)']\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.384765625, logit=19.125, token_id=29318, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.2060546875, logit=18.5, token_id=79028, metadata=None))), (38258, (3, PredictedToken(token=' Baseball', prob=0.125, logit=18.0, token_id=38258, metadata=None))), (41493, (4, PredictedToken(token=' Tow', prob=0.09716796875, logit=17.75, token_id=41493, metadata=None))), (18787, (5, PredictedToken(token=' Oak', prob=0.052001953125, logit=17.125, token_id=18787, metadata=None))), (4923, (7, PredictedToken(token=' Sk', prob=0.02783203125, logit=16.5, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:45 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.590, logit=19.125)', '\" Sk\"[4923] (p=0.116, logit=17.500)', '\" The\"[578] (p=0.103, logit=17.375)', '\" SHORT\"[66024] (p=0.023, logit=15.875)', '\" Short\"[10928] (p=0.012, logit=15.250)']\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.602, logit=18.750)', '\" The\"[578] (p=0.119, logit=17.125)', '\" Ottoman\"[70110] (p=0.072, logit=16.625)', '\" CO\"[7432] (p=0.039, logit=16.000)', '\" It\"[1102] (p=0.013, logit=14.938)']\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6015625, logit=18.75, token_id=27171, metadata=None))), (70110, (3, PredictedToken(token=' Ottoman', prob=0.07177734375, logit=16.625, token_id=70110, metadata=None))), (328, (9, PredictedToken(token=' S', prob=0.00628662109375, logit=14.1875, token_id=328, metadata=None))), (83499, (50, PredictedToken(token=' Tooth', prob=0.00054931640625, logit=11.75, token_id=83499, metadata=None))), (68867, (74, PredictedToken(token=' Coat', prob=0.000293731689453125, logit=11.125, token_id=68867, metadata=None)))])\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.688, logit=18.750)', '\" The\"[578] (p=0.082, logit=16.625)', '\" S\"[328] (p=0.056, logit=16.250)', '\" TO\"[5257] (p=0.022, logit=15.312)', '\" SO\"[5745] (p=0.010, logit=14.500)']\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.6875, logit=18.75, token_id=70110, metadata=None))), (328, (3, PredictedToken(token=' S', prob=0.056396484375, logit=16.25, token_id=328, metadata=None))), (83499, (7, PredictedToken(token=' Tooth', prob=0.00921630859375, logit=14.4375, token_id=83499, metadata=None))), (68867, (96, PredictedToken(token=' Coat', prob=0.00018024444580078125, logit=10.5, token_id=68867, metadata=None))), (27171, (294, PredictedToken(token=' Coffee', prob=2.586841583251953e-05, logit=8.5625, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:46 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.754, logit=19.875)', '\" The\"[578] (p=0.070, logit=17.500)', '\" C\"[356] (p=0.038, logit=16.875)', '\" St\"[800] (p=0.029, logit=16.625)', '\" A\"[362] (p=0.015, logit=15.938)']\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.613, logit=19.875)', '\" The\"[578] (p=0.154, logit=18.500)', '\" Car\"[3341] (p=0.073, logit=17.750)', '\" X\"[1630] (p=0.050, logit=17.375)', '\" A\"[362] (p=0.024, logit=16.625)']\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.61328125, logit=19.875, token_id=38930, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.0732421875, logit=17.75, token_id=3341, metadata=None))), (1630, (4, PredictedToken(token=' X', prob=0.05029296875, logit=17.375, token_id=1630, metadata=None))), (13394, (57, PredictedToken(token=' Bed', prob=0.0001926422119140625, logit=11.8125, token_id=13394, metadata=None))), (6771, (78, PredictedToken(token=' Table', prob=0.00011014938354492188, logit=11.25, token_id=6771, metadata=None)))])\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.365, logit=19.250)', '\" Table\"[6771] (p=0.283, logit=19.000)', '\" The\"[578] (p=0.104, logit=18.000)', '\" Bed\"[13394] (p=0.063, logit=17.500)', '\" X\"[1630] (p=0.038, logit=17.000)']\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.365234375, logit=19.25, token_id=38930, metadata=None))), (6771, (2, PredictedToken(token=' Table', prob=0.283203125, logit=19.0, token_id=6771, metadata=None))), (13394, (4, PredictedToken(token=' Bed', prob=0.0634765625, logit=17.5, token_id=13394, metadata=None))), (1630, (5, PredictedToken(token=' X', prob=0.038330078125, logit=17.0, token_id=1630, metadata=None))), (3341, (6, PredictedToken(token=' Car', prob=0.0233154296875, logit=16.5, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:47 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.617, logit=20.250)', '\" Suit\"[33711] (p=0.228, logit=19.250)', '\" The\"[578] (p=0.074, logit=18.125)', '\" JE\"[71430] (p=0.015, logit=16.500)', '\" A\"[362] (p=0.011, logit=16.250)']\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.742, logit=20.875)', '\" The\"[578] (p=0.166, logit=19.375)', '\" Viol\"[30555] (p=0.029, logit=17.625)', '\" T\"[350] (p=0.017, logit=17.125)', '\" A\"[362] (p=0.006, logit=16.125)']\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.7421875, logit=20.875, token_id=94467, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.02880859375, logit=17.625, token_id=30555, metadata=None))), (356, (10, PredictedToken(token=' C', prob=0.0018463134765625, logit=14.875, token_id=356, metadata=None))), (55870, (377, PredictedToken(token=' Jacket', prob=3.7848949432373047e-06, logit=8.6875, token_id=55870, metadata=None))), (68554, (558, PredictedToken(token=' Gloves', prob=2.16066837310791e-06, logit=8.125, token_id=68554, metadata=None)))])\n",
      "2025-09-15 09:37:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.416, logit=19.250)', '\" Jacket\"[55870] (p=0.287, logit=18.875)', '\" The\"[578] (p=0.153, logit=18.250)', '\" Viol\"[30555] (p=0.023, logit=16.375)', '\" G\"[480] (p=0.015, logit=15.938)']\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.416015625, logit=19.25, token_id=68554, metadata=None))), (55870, (2, PredictedToken(token=' Jacket', prob=0.287109375, logit=18.875, token_id=55870, metadata=None))), (30555, (4, PredictedToken(token=' Viol', prob=0.0234375, logit=16.375, token_id=30555, metadata=None))), (356, (15, PredictedToken(token=' C', prob=0.0026397705078125, logit=14.1875, token_id=356, metadata=None))), (94467, (93, PredictedToken(token=' Trom', prob=9.012222290039062e-05, logit=10.8125, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:48 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:48 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     patch_prediction=['\" Onion\"[87035] (p=0.684, logit=20.625)', '\" Bro\"[6031] (p=0.119, logit=18.875)', '\" The\"[578] (p=0.105, logit=18.750)', '\" There\"[2684] (p=0.018, logit=17.000)', '\" ON\"[6328] (p=0.011, logit=16.500)']\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     clean_prediction=['\" Carn\"[32749] (p=0.715, logit=19.875)', '\" The\"[578] (p=0.141, logit=18.250)', '\" C\"[356] (p=0.036, logit=16.875)', '\" Lav\"[43950] (p=0.028, logit=16.625)', '\" A\"[362] (p=0.013, logit=15.875)']\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     clean_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.71484375, logit=19.875, token_id=32749, metadata=None))), (43950, (4, PredictedToken(token=' Lav', prob=0.0277099609375, logit=16.625, token_id=43950, metadata=None))), (58600, (9, PredictedToken(token=' Charm', prob=0.0033111572265625, logit=14.5, token_id=58600, metadata=None))), (91297, (25, PredictedToken(token=' Mushroom', prob=0.00074005126953125, logit=13.0, token_id=91297, metadata=None))), (6771, (24, PredictedToken(token=' Table', prob=0.00074005126953125, logit=13.0, token_id=6771, metadata=None))), (78703, (96, PredictedToken(token=' Potato', prob=8.296966552734375e-05, logit=10.8125, token_id=78703, metadata=None)))])\n",
      "2025-09-15 09:37:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     int_prediction=['\" Potato\"[78703] (p=0.633, logit=19.375)', '\" Mushroom\"[91297] (p=0.142, logit=17.875)', '\" The\"[578] (p=0.086, logit=17.375)', '\" POT\"[62602] (p=0.031, logit=16.375)', '\" There\"[2684] (p=0.009, logit=15.125)']\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     int_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.6328125, logit=19.375, token_id=78703, metadata=None))), (91297, (2, PredictedToken(token=' Mushroom', prob=0.1416015625, logit=17.875, token_id=91297, metadata=None))), (43950, (7, PredictedToken(token=' Lav', prob=0.00848388671875, logit=15.0625, token_id=43950, metadata=None))), (6771, (8, PredictedToken(token=' Table', prob=0.00750732421875, logit=14.9375, token_id=6771, metadata=None))), (32749, (12, PredictedToken(token=' Carn', prob=0.0037689208984375, logit=14.25, token_id=32749, metadata=None))), (58600, (114, PredictedToken(token=' Charm', prob=6.103515625e-05, logit=10.125, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:49 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:49 src.selection.optimization DEBUG    torch.Size([7, 36])\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.617, logit=19.875)', '\" The\"[578] (p=0.156, logit=18.500)', '\" Rice\"[30616] (p=0.095, logit=18.000)', '\" Re\"[1050] (p=0.027, logit=16.750)', '\" A\"[362] (p=0.027, logit=16.750)']\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     clean_prediction=['\" Night\"[13120] (p=0.754, logit=21.000)', '\" The\"[578] (p=0.115, logit=19.125)', '\" A\"[362] (p=0.048, logit=18.250)', '\" Chair\"[16478] (p=0.037, logit=18.000)', '\" NIGHT\"[76131] (p=0.014, logit=17.000)']\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     clean_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.75390625, logit=21.0, token_id=13120, metadata=None))), (16478, (4, PredictedToken(token=' Chair', prob=0.037353515625, logit=18.0, token_id=16478, metadata=None))), (75258, (13, PredictedToken(token=' Refriger', prob=0.00099945068359375, logit=14.375, token_id=75258, metadata=None))), (18343, (20, PredictedToken(token=' Paper', prob=0.000606536865234375, logit=13.875, token_id=18343, metadata=None))), (30558, (21, PredictedToken(token=' Ki', prob=0.000606536865234375, logit=13.875, token_id=30558, metadata=None))), (6031, (26, PredictedToken(token=' Bro', prob=0.0004425048828125, logit=13.5625, token_id=6031, metadata=None))), (6690, (76, PredictedToken(token=' Air', prob=4.673004150390625e-05, logit=11.3125, token_id=6690, metadata=None)))])\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.848, logit=21.500)', '\" The\"[578] (p=0.079, logit=19.125)', '\" An\"[1556] (p=0.026, logit=18.000)', '\" Bro\"[6031] (p=0.009, logit=17.000)', '\" AIR\"[46994] (p=0.008, logit=16.875)']\n",
      "2025-09-15 09:37:49 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.84765625, logit=21.5, token_id=6690, metadata=None))), (6031, (4, PredictedToken(token=' Bro', prob=0.0093994140625, logit=17.0, token_id=6031, metadata=None))), (30558, (6, PredictedToken(token=' Ki', prob=0.00390625, logit=16.125, token_id=30558, metadata=None))), (18343, (17, PredictedToken(token=' Paper', prob=0.000820159912109375, logit=14.5625, token_id=18343, metadata=None))), (75258, (21, PredictedToken(token=' Refriger', prob=0.00060272216796875, logit=14.25, token_id=75258, metadata=None))), (16478, (26, PredictedToken(token=' Chair', prob=0.0003871917724609375, logit=13.8125, token_id=16478, metadata=None))), (13120, (786, PredictedToken(token=' Night', prob=6.817281246185303e-07, logit=7.46875, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:49 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:50 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.730, logit=19.000)', '\" The\"[578] (p=0.077, logit=16.750)', '\" Tow\"[41493] (p=0.047, logit=16.250)', '\" A\"[362] (p=0.036, logit=16.000)', '\" Theater\"[38571] (p=0.026, logit=15.688)']\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.789, logit=20.750)', '\" Hair\"[26781] (p=0.137, logit=19.000)', '\" The\"[578] (p=0.021, logit=17.125)', '\" TO\"[5257] (p=0.011, logit=16.500)', '\" A\"[362] (p=0.006, logit=15.812)']\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.7890625, logit=20.75, token_id=83499, metadata=None))), (26781, (2, PredictedToken(token=' Hair', prob=0.13671875, logit=19.0, token_id=26781, metadata=None))), (32498, (20, PredictedToken(token=' Mall', prob=0.00049591064453125, logit=13.375, token_id=32498, metadata=None))), (52466, (30, PredictedToken(token=' Warehouse', prob=0.000247955322265625, logit=12.6875, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     int_prediction=['\" Warehouse\"[52466] (p=0.652, logit=19.500)', '\" Mall\"[32498] (p=0.146, logit=18.000)', '\" The\"[578] (p=0.047, logit=16.875)', '\" Hair\"[26781] (p=0.025, logit=16.250)', '\" A\"[362] (p=0.020, logit=16.000)']\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     int_track=OrderedDict([(52466, (1, PredictedToken(token=' Warehouse', prob=0.65234375, logit=19.5, token_id=52466, metadata=None))), (32498, (2, PredictedToken(token=' Mall', prob=0.1455078125, logit=18.0, token_id=32498, metadata=None))), (26781, (4, PredictedToken(token=' Hair', prob=0.025390625, logit=16.25, token_id=26781, metadata=None))), (83499, (7, PredictedToken(token=' Tooth', prob=0.00933837890625, logit=15.25, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:50 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:50 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:37:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.465, logit=18.750)', '\" The\"[578] (p=0.281, logit=18.250)', '\" Swe\"[37326] (p=0.038, logit=16.250)', '\" SHORT\"[66024] (p=0.025, logit=15.812)', '\" Short\"[10928] (p=0.015, logit=15.312)']\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     clean_prediction=['\" Raspberry\"[48665] (p=0.773, logit=20.250)', '\" The\"[578] (p=0.072, logit=17.875)', '\" Peach\"[64695] (p=0.063, logit=17.750)', '\" There\"[2684] (p=0.016, logit=16.375)', '\" R\"[432] (p=0.012, logit=16.125)']\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     clean_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.7734375, logit=20.25, token_id=48665, metadata=None))), (64695, (3, PredictedToken(token=' Peach', prob=0.0634765625, logit=17.75, token_id=64695, metadata=None))), (15429, (15, PredictedToken(token=' Hospital', prob=0.0015869140625, logit=14.0625, token_id=15429, metadata=None))), (40090, (58, PredictedToken(token=' Pressure', prob=0.00016689300537109375, logit=11.8125, token_id=40090, metadata=None))), (29318, (312, PredictedToken(token=' Dress', prob=1.0669231414794922e-05, logit=9.0625, token_id=29318, metadata=None))), (55807, (408, PredictedToken(token=' Shirt', prob=6.884336471557617e-06, logit=8.625, token_id=55807, metadata=None)))])\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.871, logit=20.875)', '\" The\"[578] (p=0.056, logit=18.125)', '\" Dress\"[29318] (p=0.009, logit=16.250)', '\" There\"[2684] (p=0.009, logit=16.250)', '\" A\"[362] (p=0.005, logit=15.688)']\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.87109375, logit=20.875, token_id=55807, metadata=None))), (29318, (4, PredictedToken(token=' Dress', prob=0.008544921875, logit=16.25, token_id=29318, metadata=None))), (64695, (7, PredictedToken(token=' Peach', prob=0.0037994384765625, logit=15.4375, token_id=64695, metadata=None))), (15429, (10, PredictedToken(token=' Hospital', prob=0.002777099609375, logit=15.125, token_id=15429, metadata=None))), (40090, (15, PredictedToken(token=' Pressure', prob=0.0015869140625, logit=14.5625, token_id=40090, metadata=None))), (48665, (47, PredictedToken(token=' Raspberry', prob=0.00012969970703125, logit=12.0625, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:37:51 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:37:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     patch_prediction=['\" Har\"[5340] (p=0.766, logit=19.875)', '\" The\"[578] (p=0.104, logit=17.875)', '\" Drum\"[46506] (p=0.018, logit=16.125)', '\" HAR\"[87588] (p=0.018, logit=16.125)', '\" A\"[362] (p=0.007, logit=15.188)']\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     clean_prediction=['\" Elm\"[65329] (p=0.664, logit=19.250)', '\" The\"[578] (p=0.115, logit=17.500)', '\" There\"[2684] (p=0.024, logit=15.938)', '\" Birch\"[88088] (p=0.023, logit=15.875)', '\" None\"[2290] (p=0.019, logit=15.688)']\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     clean_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.6640625, logit=19.25, token_id=65329, metadata=None))), (88088, (4, PredictedToken(token=' Birch', prob=0.022705078125, logit=15.875, token_id=88088, metadata=None))), (29625, (7, PredictedToken(token=' Chain', prob=0.01556396484375, logit=15.5, token_id=29625, metadata=None))), (356, (12, PredictedToken(token=' C', prob=0.00506591796875, logit=14.375, token_id=356, metadata=None))), (40759, (25, PredictedToken(token=' Harmon', prob=0.00128173828125, logit=13.0, token_id=40759, metadata=None))), (39794, (557, PredictedToken(token=' Desk', prob=9.179115295410156e-06, logit=8.0625, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.812, logit=19.750)', '\" The\"[578] (p=0.066, logit=17.250)', '\" Birch\"[88088] (p=0.013, logit=15.625)', '\" There\"[2684] (p=0.013, logit=15.625)', '\" C\"[356] (p=0.012, logit=15.500)']\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8125, logit=19.75, token_id=40759, metadata=None))), (88088, (4, PredictedToken(token=' Birch', prob=0.01312255859375, logit=15.625, token_id=88088, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.0115966796875, logit=15.5, token_id=356, metadata=None))), (29625, (8, PredictedToken(token=' Chain', prob=0.00848388671875, logit=15.1875, token_id=29625, metadata=None))), (65329, (13, PredictedToken(token=' Elm', prob=0.00213623046875, logit=13.8125, token_id=65329, metadata=None))), (39794, (14, PredictedToken(token=' Desk', prob=0.00201416015625, logit=13.75, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:52 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:52 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:37:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.512, logit=19.125)', '\" The\"[578] (p=0.188, logit=18.125)', '\" Scar\"[30760] (p=0.101, logit=17.500)', '\" A\"[362] (p=0.101, logit=17.500)', '\" H\"[473] (p=0.008, logit=15.000)']\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.598, logit=19.750)', '\" The\"[578] (p=0.133, logit=18.250)', '\" Tennis\"[58251] (p=0.117, logit=18.125)', '\" A\"[362] (p=0.038, logit=17.000)', '\" HEL\"[38757] (p=0.016, logit=16.125)']\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.59765625, logit=19.75, token_id=67629, metadata=None))), (58251, (3, PredictedToken(token=' Tennis', prob=0.1171875, logit=18.125, token_id=58251, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.004852294921875, logit=14.9375, token_id=4923, metadata=None))), (14642, (21, PredictedToken(token=' Phone', prob=0.0015716552734375, logit=13.8125, token_id=14642, metadata=None))), (42609, (83, PredictedToken(token=' Pine', prob=0.00014591217041015625, logit=11.4375, token_id=42609, metadata=None))), (29318, (347, PredictedToken(token=' Dress', prob=9.953975677490234e-06, logit=8.75, token_id=29318, metadata=None))), (49268, (1162, PredictedToken(token=' Dish', prob=1.7881393432617188e-06, logit=7.03125, token_id=49268, metadata=None)))])\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.793, logit=20.500)', '\" The\"[578] (p=0.065, logit=18.000)', '\" Tennis\"[58251] (p=0.031, logit=17.250)', '\" Helmet\"[67629] (p=0.016, logit=16.625)', '\" A\"[362] (p=0.016, logit=16.625)']\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.79296875, logit=20.5, token_id=29318, metadata=None))), (58251, (3, PredictedToken(token=' Tennis', prob=0.03076171875, logit=17.25, token_id=58251, metadata=None))), (67629, (5, PredictedToken(token=' Helmet', prob=0.0164794921875, logit=16.625, token_id=67629, metadata=None))), (4923, (7, PredictedToken(token=' Sk', prob=0.007781982421875, logit=15.875, token_id=4923, metadata=None))), (14642, (13, PredictedToken(token=' Phone', prob=0.0034637451171875, logit=15.0625, token_id=14642, metadata=None))), (49268, (43, PredictedToken(token=' Dish', prob=0.00026702880859375, logit=12.5, token_id=49268, metadata=None))), (42609, (62, PredictedToken(token=' Pine', prob=0.00015163421630859375, logit=11.9375, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:53 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.953, logit=22.250)', '\" The\"[578] (p=0.022, logit=18.500)', '\" There\"[2684] (p=0.004, logit=16.875)', '\" Bro\"[6031] (p=0.003, logit=16.500)', '\" CA\"[9362] (p=0.003, logit=16.375)']\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.432, logit=19.500)', '\" Toilet\"[82994] (p=0.336, logit=19.250)', '\" The\"[578] (p=0.075, logit=17.750)', '\" TO\"[5257] (p=0.035, logit=17.000)', '\" R\"[432] (p=0.031, logit=16.875)']\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.431640625, logit=19.5, token_id=83499, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.3359375, logit=19.25, token_id=82994, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.03125, logit=16.875, token_id=432, metadata=None))), (6914, (6, PredictedToken(token=' Let', prob=0.01226806640625, logit=15.9375, token_id=6914, metadata=None))), (87035, (123, PredictedToken(token=' Onion', prob=6.437301635742188e-05, logit=10.6875, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.680, logit=20.000)', '\" Toilet\"[82994] (p=0.072, logit=17.750)', '\" Let\"[6914] (p=0.049, logit=17.375)', '\" The\"[578] (p=0.038, logit=17.125)', '\" R\"[432] (p=0.038, logit=17.125)']\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.6796875, logit=20.0, token_id=87035, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.07177734375, logit=17.75, token_id=82994, metadata=None))), (6914, (3, PredictedToken(token=' Let', prob=0.049072265625, logit=17.375, token_id=6914, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.038330078125, logit=17.125, token_id=432, metadata=None))), (83499, (6, PredictedToken(token=' Tooth', prob=0.023193359375, logit=16.625, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:54 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.789, logit=20.875)', '\" Pepper\"[52882] (p=0.073, logit=18.500)', '\" The\"[578] (p=0.073, logit=18.500)', '\" There\"[2684] (p=0.014, logit=16.875)', '\" None\"[2290] (p=0.005, logit=15.812)']\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.832, logit=21.250)', '\" The\"[578] (p=0.100, logit=19.125)', '\" Guitar\"[47759] (p=0.020, logit=17.500)', '\" VI\"[30768] (p=0.006, logit=16.250)', '\" There\"[2684] (p=0.006, logit=16.250)']\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.83203125, logit=21.25, token_id=30555, metadata=None))), (47759, (3, PredictedToken(token=' Guitar', prob=0.0196533203125, logit=17.5, token_id=47759, metadata=None))), (17810, (32, PredictedToken(token=' Cat', prob=0.0001926422119140625, logit=12.875, token_id=17810, metadata=None))), (3341, (39, PredictedToken(token=' Car', prob=0.0001239776611328125, logit=12.4375, token_id=3341, metadata=None))), (94091, (116, PredictedToken(token=' Tomato', prob=2.5987625122070312e-05, logit=10.875, token_id=94091, metadata=None)))])\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.490, logit=20.250)', '\" Car\"[3341] (p=0.336, logit=19.875)', '\" The\"[578] (p=0.066, logit=18.250)', '\" Tomato\"[94091] (p=0.031, logit=17.500)', '\" None\"[2290] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.490234375, logit=20.25, token_id=30555, metadata=None))), (3341, (2, PredictedToken(token=' Car', prob=0.3359375, logit=19.875, token_id=3341, metadata=None))), (94091, (4, PredictedToken(token=' Tomato', prob=0.03125, logit=17.5, token_id=94091, metadata=None))), (47759, (7, PredictedToken(token=' Guitar', prob=0.006988525390625, logit=16.0, token_id=47759, metadata=None))), (17810, (8, PredictedToken(token=' Cat', prob=0.00543212890625, logit=15.75, token_id=17810, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:55 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:37:55 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:37:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     patch_prediction=['\" Violet\"[74574] (p=0.934, logit=20.500)', '\" The\"[578] (p=0.013, logit=16.250)', '\" Rose\"[16344] (p=0.008, logit=15.750)', '\" C\"[356] (p=0.004, logit=15.125)', '\" V\"[650] (p=0.004, logit=15.062)']\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.754, logit=20.125)', '\" e\"[384] (p=0.080, logit=17.875)', '\" The\"[578] (p=0.042, logit=17.250)', '\" S\"[328] (p=0.029, logit=16.875)', '\" An\"[1556] (p=0.023, logit=16.625)']\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.75390625, logit=20.125, token_id=469, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.0291748046875, logit=16.875, token_id=328, metadata=None))), (57915, (6, PredictedToken(token=' Ank', prob=0.02001953125, logit=16.5, token_id=57915, metadata=None))), (40759, (8, PredictedToken(token=' Harmon', prob=0.0028839111328125, logit=14.5625, token_id=40759, metadata=None))), (423, (12, PredictedToken(token=' D', prob=0.00164794921875, logit=14.0, token_id=423, metadata=None))), (921, (24, PredictedToken(token=' Ch', prob=0.00093841552734375, logit=13.4375, token_id=921, metadata=None))), (27171, (176, PredictedToken(token=' Coffee', prob=2.3484230041503906e-05, logit=9.75, token_id=27171, metadata=None)))])\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     int_prediction=['\" Ch\"[921] (p=0.758, logit=20.000)', '\" S\"[328] (p=0.080, logit=17.750)', '\" The\"[578] (p=0.048, logit=17.250)', '\" D\"[423] (p=0.043, logit=17.125)', '\" ch\"[523] (p=0.008, logit=15.438)']\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     int_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.7578125, logit=20.0, token_id=921, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.080078125, logit=17.75, token_id=328, metadata=None))), (423, (4, PredictedToken(token=' D', prob=0.042724609375, logit=17.125, token_id=423, metadata=None))), (57915, (6, PredictedToken(token=' Ank', prob=0.00579833984375, logit=15.125, token_id=57915, metadata=None))), (40759, (9, PredictedToken(token=' Harmon', prob=0.0030975341796875, logit=14.5, token_id=40759, metadata=None))), (469, (12, PredictedToken(token=' E', prob=0.0021209716796875, logit=14.125, token_id=469, metadata=None))), (27171, (20, PredictedToken(token=' Coffee', prob=0.001068115234375, logit=13.4375, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:56 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:37:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     patch_prediction=['\" Bed\"[13394] (p=0.680, logit=19.375)', '\" The\"[578] (p=0.118, logit=17.625)', '\" Ward\"[27738] (p=0.056, logit=16.875)', '\" Lav\"[43950] (p=0.026, logit=16.125)', '\" BED\"[83364] (p=0.018, logit=15.750)']\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.754, logit=20.375)', '\" The\"[578] (p=0.102, logit=18.375)', '\" Mouse\"[18191] (p=0.054, logit=17.750)', '\" There\"[2684] (p=0.018, logit=16.625)', '\" A\"[362] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.75390625, logit=20.375, token_id=47033, metadata=None))), (18191, (3, PredictedToken(token=' Mouse', prob=0.054443359375, logit=17.75, token_id=18191, metadata=None))), (423, (24, PredictedToken(token=' D', prob=0.0007781982421875, logit=13.5, token_id=423, metadata=None))), (61948, (189, PredictedToken(token=' Sofa', prob=1.9431114196777344e-05, logit=9.8125, token_id=61948, metadata=None))), (29318, (318, PredictedToken(token=' Dress', prob=8.64267349243164e-06, logit=9.0, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.777, logit=20.250)', '\" The\"[578] (p=0.064, logit=17.750)', '\" There\"[2684] (p=0.039, logit=17.250)', '\" None\"[2290] (p=0.030, logit=17.000)', '\" Printer\"[47033] (p=0.023, logit=16.750)']\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.77734375, logit=20.25, token_id=29318, metadata=None))), (47033, (5, PredictedToken(token=' Printer', prob=0.0234375, logit=16.75, token_id=47033, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.00714111328125, logit=15.5625, token_id=423, metadata=None))), (61948, (7, PredictedToken(token=' Sofa', prob=0.006317138671875, logit=15.4375, token_id=61948, metadata=None))), (18191, (21, PredictedToken(token=' Mouse', prob=0.00080108642578125, logit=13.375, token_id=18191, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:57 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:37:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.715, logit=20.250)', '\" The\"[578] (p=0.181, logit=18.875)', '\" Harmon\"[40759] (p=0.028, logit=17.000)', '\" Stap\"[63606] (p=0.012, logit=16.125)', '\" T\"[350] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.660, logit=19.250)', '\" Lion\"[33199] (p=0.115, logit=17.500)', '\" The\"[578] (p=0.089, logit=17.250)', '\" There\"[2684] (p=0.018, logit=15.625)', '\" None\"[2290] (p=0.018, logit=15.625)']\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.66015625, logit=19.25, token_id=48035, metadata=None))), (33199, (2, PredictedToken(token=' Lion', prob=0.11474609375, logit=17.5, token_id=33199, metadata=None))), (432, (8, PredictedToken(token=' R', prob=0.005035400390625, logit=14.375, token_id=432, metadata=None))), (5340, (9, PredictedToken(token=' Har', prob=0.003692626953125, logit=14.0625, token_id=5340, metadata=None))), (60413, (50, PredictedToken(token=' Uk', prob=0.00034332275390625, logit=11.6875, token_id=60413, metadata=None)))])\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.477, logit=19.625)', '\" Uk\"[60413] (p=0.254, logit=19.000)', '\" The\"[578] (p=0.120, logit=18.250)', '\" HAR\"[87588] (p=0.021, logit=16.500)', '\" There\"[2684] (p=0.016, logit=16.250)']\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.4765625, logit=19.625, token_id=5340, metadata=None))), (60413, (2, PredictedToken(token=' Uk', prob=0.25390625, logit=19.0, token_id=60413, metadata=None))), (48035, (6, PredictedToken(token=' Gir', prob=0.0162353515625, logit=16.25, token_id=48035, metadata=None))), (432, (11, PredictedToken(token=' R', prob=0.004669189453125, logit=15.0, token_id=432, metadata=None))), (33199, (13, PredictedToken(token=' Lion', prob=0.0028228759765625, logit=14.5, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:37:58 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:37:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.629, logit=19.375)', '\" Lion\"[33199] (p=0.141, logit=17.875)', '\" The\"[578] (p=0.109, logit=17.625)', '\" There\"[2684] (p=0.014, logit=15.562)', '\" A\"[362] (p=0.014, logit=15.562)']\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.527, logit=18.125)', '\" Ward\"[27738] (p=0.172, logit=17.000)', '\" Pendant\"[81501] (p=0.081, logit=16.250)', '\" The\"[578] (p=0.043, logit=15.625)', '\" A\"[362] (p=0.021, logit=14.875)']\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.52734375, logit=18.125, token_id=58600, metadata=None))), (27738, (2, PredictedToken(token=' Ward', prob=0.171875, logit=17.0, token_id=27738, metadata=None))), (81501, (3, PredictedToken(token=' Pendant', prob=0.0810546875, logit=16.25, token_id=81501, metadata=None))), (49431, (7, PredictedToken(token=' Rabbit', prob=0.01409912109375, logit=14.5, token_id=49431, metadata=None))), (24941, (9, PredictedToken(token=' Bear', prob=0.008544921875, logit=14.0, token_id=24941, metadata=None)))])\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.625, logit=18.250)', '\" Ward\"[27738] (p=0.180, logit=17.000)', '\" Charm\"[58600] (p=0.029, logit=15.188)', '\" The\"[578] (p=0.029, logit=15.188)', '\" Bear\"[24941] (p=0.021, logit=14.875)']\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.625, logit=18.25, token_id=49431, metadata=None))), (27738, (2, PredictedToken(token=' Ward', prob=0.1796875, logit=17.0, token_id=27738, metadata=None))), (58600, (4, PredictedToken(token=' Charm', prob=0.029296875, logit=15.1875, token_id=58600, metadata=None))), (24941, (5, PredictedToken(token=' Bear', prob=0.0213623046875, logit=14.875, token_id=24941, metadata=None))), (81501, (10, PredictedToken(token=' Pendant', prob=0.0069580078125, logit=13.75, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:37:59 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:37:59 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.781, logit=20.625)', '\" Tooth\"[83499] (p=0.136, logit=18.875)', '\" The\"[578] (p=0.030, logit=17.375)', '\" A\"[362] (p=0.016, logit=16.750)', '\" TO\"[5257] (p=0.006, logit=15.688)']\n",
      "2025-09-15 09:37:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.797, logit=20.375)', '\" The\"[578] (p=0.122, logit=18.500)', '\" CL\"[7121] (p=0.017, logit=16.500)', '\" A\"[362] (p=0.007, logit=15.688)', '\" It\"[1102] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.796875, logit=20.375, token_id=31181, metadata=None))), (94467, (6, PredictedToken(token=' Trom', prob=0.005035400390625, logit=15.3125, token_id=94467, metadata=None))), (74968, (66, PredictedToken(token=' Razor', prob=0.00011157989501953125, logit=11.5, token_id=74968, metadata=None))), (48471, (489, PredictedToken(token=' Shower', prob=3.5762786865234375e-06, logit=8.0625, token_id=48471, metadata=None)))])\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     int_prediction=['\" Razor\"[74968] (p=0.523, logit=19.375)', '\" Trom\"[94467] (p=0.248, logit=18.625)', '\" The\"[578] (p=0.104, logit=17.750)', '\" A\"[362] (p=0.020, logit=16.125)', '\" R\"[432] (p=0.016, logit=15.875)']\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     int_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.5234375, logit=19.375, token_id=74968, metadata=None))), (94467, (2, PredictedToken(token=' Trom', prob=0.248046875, logit=18.625, token_id=94467, metadata=None))), (48471, (9, PredictedToken(token=' Shower', prob=0.004547119140625, logit=14.625, token_id=48471, metadata=None))), (31181, (68, PredictedToken(token=' Clar', prob=0.00015544891357421875, logit=11.25, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:00 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.598, logit=19.625)', '\" Sh\"[1443] (p=0.250, logit=18.750)', '\" The\"[578] (p=0.026, logit=16.500)', '\" SH\"[6570] (p=0.021, logit=16.250)', '\" Shower\"[48471] (p=0.013, logit=15.812)']\n",
      "2025-09-15 09:38:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     clean_prediction=['\" Orange\"[22725] (p=0.879, logit=21.250)', '\" The\"[578] (p=0.044, logit=18.250)', '\" Peach\"[64695] (p=0.023, logit=17.625)', '\" OR\"[2794] (p=0.010, logit=16.750)', '\" orange\"[19087] (p=0.008, logit=16.500)']\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     clean_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.87890625, logit=21.25, token_id=22725, metadata=None))), (64695, (3, PredictedToken(token=' Peach', prob=0.0234375, logit=17.625, token_id=64695, metadata=None))), (83499, (180, PredictedToken(token=' Tooth', prob=1.2934207916259766e-05, logit=10.125, token_id=83499, metadata=None))), (57551, (204, PredictedToken(token=' Sink', prob=1.1444091796875e-05, logit=10.0, token_id=57551, metadata=None)))])\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     int_prediction=['\" Orange\"[22725] (p=0.559, logit=19.000)', '\" Sink\"[57551] (p=0.160, logit=17.750)', '\" Peach\"[64695] (p=0.075, logit=17.000)', '\" The\"[578] (p=0.075, logit=17.000)', '\" There\"[2684] (p=0.017, logit=15.500)']\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     int_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.55859375, logit=19.0, token_id=22725, metadata=None))), (57551, (2, PredictedToken(token=' Sink', prob=0.16015625, logit=17.75, token_id=57551, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.0751953125, logit=17.0, token_id=64695, metadata=None))), (83499, (7, PredictedToken(token=' Tooth', prob=0.01397705078125, logit=15.3125, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:01 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.516, logit=19.125)', '\" Toilet\"[82994] (p=0.243, logit=18.375)', '\" The\"[578] (p=0.102, logit=17.500)', '\" Football\"[21424] (p=0.020, logit=15.875)', '\" A\"[362] (p=0.018, logit=15.750)']\n",
      "2025-09-15 09:38:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:02 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.648, logit=20.625)', '\" The\"[578] (p=0.211, logit=19.500)', '\" Microwave\"[98641] (p=0.053, logit=18.125)', '\" A\"[362] (p=0.017, logit=17.000)', '\" BLE\"[52818] (p=0.009, logit=16.375)']\n",
      "2025-09-15 09:38:02 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.6484375, logit=20.625, token_id=88668, metadata=None))), (98641, (3, PredictedToken(token=' Microwave', prob=0.053466796875, logit=18.125, token_id=98641, metadata=None))), (16488, (7, PredictedToken(token=' Bat', prob=0.003631591796875, logit=15.4375, token_id=16488, metadata=None))), (61731, (25, PredictedToken(token=' Soap', prob=0.000713348388671875, logit=13.8125, token_id=61731, metadata=None))), (38258, (109, PredictedToken(token=' Baseball', prob=4.57763671875e-05, logit=11.0625, token_id=38258, metadata=None)))])\n",
      "2025-09-15 09:38:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:02 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.598, logit=20.375)', '\" The\"[578] (p=0.091, logit=18.500)', '\" Blender\"[88668] (p=0.071, logit=18.250)', '\" Microwave\"[98641] (p=0.071, logit=18.250)', '\" Bat\"[16488] (p=0.063, logit=18.125)']\n",
      "2025-09-15 09:38:02 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.59765625, logit=20.375, token_id=61731, metadata=None))), (98641, (4, PredictedToken(token=' Microwave', prob=0.0712890625, logit=18.25, token_id=98641, metadata=None))), (88668, (3, PredictedToken(token=' Blender', prob=0.0712890625, logit=18.25, token_id=88668, metadata=None))), (16488, (5, PredictedToken(token=' Bat', prob=0.06298828125, logit=18.125, token_id=16488, metadata=None))), (38258, (14, PredictedToken(token=' Baseball', prob=0.0014801025390625, logit=14.375, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:02 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     patch_prediction=['\" Folder\"[36943] (p=0.703, logit=19.875)', '\" Binder\"[91263] (p=0.138, logit=18.250)', '\" The\"[578] (p=0.031, logit=16.750)', '\" F\"[435] (p=0.027, logit=16.625)', '\" A\"[362] (p=0.021, logit=16.375)']\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.672, logit=20.375)', '\" The\"[578] (p=0.132, logit=18.750)', '\" A\"[362] (p=0.071, logit=18.125)', '\" Sk\"[4923] (p=0.062, logit=18.000)', '\" P\"[393] (p=0.007, logit=15.812)']\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.671875, logit=20.375, token_id=29318, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.062255859375, logit=18.0, token_id=4923, metadata=None))), (393, (5, PredictedToken(token=' P', prob=0.006988525390625, logit=15.8125, token_id=393, metadata=None))), (1901, (23, PredictedToken(token=' Z', prob=0.00057220458984375, logit=13.3125, token_id=1901, metadata=None))), (57094, (100, PredictedToken(token=' Highlight', prob=5.0067901611328125e-05, logit=10.875, token_id=57094, metadata=None)))])\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.812, logit=21.125)', '\" The\"[578] (p=0.067, logit=18.625)', '\" A\"[362] (p=0.046, logit=18.250)', '\" Highlight\"[57094] (p=0.022, logit=17.500)', '\" Dress\"[29318] (p=0.015, logit=17.125)']\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.8125, logit=21.125, token_id=393, metadata=None))), (57094, (4, PredictedToken(token=' Highlight', prob=0.021728515625, logit=17.5, token_id=57094, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.014892578125, logit=17.125, token_id=29318, metadata=None))), (4923, (13, PredictedToken(token=' Sk', prob=0.00107574462890625, logit=14.5, token_id=4923, metadata=None))), (1901, (23, PredictedToken(token=' Z', prob=0.0004787445068359375, logit=13.6875, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:03 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.887, logit=20.625)', '\" Bear\"[24941] (p=0.034, logit=17.375)', '\" The\"[578] (p=0.018, logit=16.750)', '\" None\"[2290] (p=0.007, logit=15.750)', '\" There\"[2684] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:38:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.668, logit=20.625)', '\" The\"[578] (p=0.217, logit=19.500)', '\" Harmon\"[40759] (p=0.023, logit=17.250)', '\" U\"[549] (p=0.016, logit=16.875)', '\" A\"[362] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.66796875, logit=20.625, token_id=60413, metadata=None))), (40759, (3, PredictedToken(token=' Harmon', prob=0.0228271484375, logit=17.25, token_id=40759, metadata=None))), (393, (29, PredictedToken(token=' P', prob=0.0004749298095703125, logit=13.375, token_id=393, metadata=None))), (14588, (186, PredictedToken(token=' Dog', prob=1.621246337890625e-05, logit=10.0, token_id=14588, metadata=None))), (49431, (295, PredictedToken(token=' Rabbit', prob=7.212162017822266e-06, logit=9.1875, token_id=49431, metadata=None)))])\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.625, logit=19.750)', '\" The\"[578] (p=0.123, logit=18.125)', '\" Harmon\"[40759] (p=0.075, logit=17.625)', '\" Dog\"[14588] (p=0.051, logit=17.250)', '\" A\"[362] (p=0.017, logit=16.125)']\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.625, logit=19.75, token_id=49431, metadata=None))), (40759, (3, PredictedToken(token=' Harmon', prob=0.07470703125, logit=17.625, token_id=40759, metadata=None))), (14588, (4, PredictedToken(token=' Dog', prob=0.05126953125, logit=17.25, token_id=14588, metadata=None))), (393, (6, PredictedToken(token=' P', prob=0.0101318359375, logit=15.625, token_id=393, metadata=None))), (60413, (19, PredictedToken(token=' Uk', prob=0.00225830078125, logit=14.125, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:04 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.688, logit=19.625)', '\" Ward\"[27738] (p=0.105, logit=17.750)', '\" The\"[578] (p=0.093, logit=17.625)', '\" A\"[362] (p=0.027, logit=16.375)', '\" NIGHT\"[76131] (p=0.013, logit=15.688)']\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.586, logit=19.625)', '\" B\"[426] (p=0.216, logit=18.625)', '\" The\"[578] (p=0.080, logit=17.625)', '\" b\"[293] (p=0.023, logit=16.375)', '\" A\"[362] (p=0.013, logit=15.812)']\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.5859375, logit=19.625, token_id=58600, metadata=None))), (426, (2, PredictedToken(token=' B', prob=0.2158203125, logit=18.625, token_id=426, metadata=None))), (29318, (56, PredictedToken(token=' Dress', prob=0.00023746490478515625, logit=11.8125, token_id=29318, metadata=None))), (49431, (93, PredictedToken(token=' Rabbit', prob=9.918212890625e-05, logit=10.9375, token_id=49431, metadata=None))), (6017, (190, PredictedToken(token=' Book', prob=2.3484230041503906e-05, logit=9.5, token_id=6017, metadata=None)))])\n",
      "2025-09-15 09:38:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.840, logit=20.250)', '\" The\"[578] (p=0.061, logit=17.625)', '\" Book\"[6017] (p=0.037, logit=17.125)', '\" A\"[362] (p=0.008, logit=15.562)', '\" dress\"[8679] (p=0.005, logit=15.125)']\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.83984375, logit=20.25, token_id=29318, metadata=None))), (6017, (3, PredictedToken(token=' Book', prob=0.036865234375, logit=17.125, token_id=6017, metadata=None))), (426, (20, PredictedToken(token=' B', prob=0.000675201416015625, logit=13.125, token_id=426, metadata=None))), (58600, (56, PredictedToken(token=' Charm', prob=0.000141143798828125, logit=11.5625, token_id=58600, metadata=None))), (49431, (98, PredictedToken(token=' Rabbit', prob=5.888938903808594e-05, logit=10.6875, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:05 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.871, logit=20.625)', '\" The\"[578] (p=0.049, logit=17.750)', '\" L\"[445] (p=0.023, logit=17.000)', '\" An\"[1556] (p=0.009, logit=16.000)', '\" AN\"[2147] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     clean_prediction=['\" Let\"[6914] (p=0.551, logit=20.625)', '\" Z\"[1901] (p=0.295, logit=20.000)', '\" The\"[578] (p=0.074, logit=18.625)', '\" There\"[2684] (p=0.017, logit=17.125)', '\" None\"[2290] (p=0.011, logit=16.750)']\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     clean_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.55078125, logit=20.625, token_id=6914, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.294921875, logit=20.0, token_id=1901, metadata=None))), (29625, (7, PredictedToken(token=' Chain', prob=0.0078125, logit=16.375, token_id=29625, metadata=None))), (75258, (53, PredictedToken(token=' Refriger', prob=0.000152587890625, logit=12.4375, token_id=75258, metadata=None))), (70306, (222, PredictedToken(token=' Brace', prob=1.2576580047607422e-05, logit=9.9375, token_id=70306, metadata=None)))])\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     int_prediction=['\" Brace\"[70306] (p=0.570, logit=19.625)', '\" Chain\"[29625] (p=0.127, logit=18.125)', '\" The\"[578] (p=0.099, logit=17.875)', '\" Z\"[1901] (p=0.041, logit=17.000)', '\" A\"[362] (p=0.036, logit=16.875)']\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     int_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.5703125, logit=19.625, token_id=70306, metadata=None))), (29625, (2, PredictedToken(token=' Chain', prob=0.126953125, logit=18.125, token_id=29625, metadata=None))), (1901, (4, PredictedToken(token=' Z', prob=0.041259765625, logit=17.0, token_id=1901, metadata=None))), (6914, (12, PredictedToken(token=' Let', prob=0.00384521484375, logit=14.625, token_id=6914, metadata=None))), (75258, (14, PredictedToken(token=' Refriger', prob=0.00299072265625, logit=14.375, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:05 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.891, logit=20.125)', '\" The\"[578] (p=0.044, logit=17.125)', '\" cabinet\"[22685] (p=0.006, logit=15.188)', '\" CAB\"[81217] (p=0.006, logit=15.062)', '\" It\"[1102] (p=0.005, logit=15.000)']\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     clean_prediction=['\" Library\"[11896] (p=0.684, logit=19.125)', '\" Apartment\"[53889] (p=0.082, logit=17.000)', '\" The\"[578] (p=0.063, logit=16.750)', '\" Printer\"[47033] (p=0.044, logit=16.375)', '\" St\"[800] (p=0.023, logit=15.750)']\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     clean_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.68359375, logit=19.125, token_id=11896, metadata=None))), (53889, (2, PredictedToken(token=' Apartment', prob=0.08154296875, logit=17.0, token_id=53889, metadata=None))), (47033, (4, PredictedToken(token=' Printer', prob=0.043701171875, logit=16.375, token_id=47033, metadata=None))), (800, (5, PredictedToken(token=' St', prob=0.0234375, logit=15.75, token_id=800, metadata=None))), (29318, (6, PredictedToken(token=' Dress', prob=0.01611328125, logit=15.375, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     int_prediction=['\" St\"[800] (p=0.672, logit=18.750)', '\" The\"[578] (p=0.055, logit=16.250)', '\" Dress\"[29318] (p=0.049, logit=16.125)', '\" Library\"[11896] (p=0.043, logit=16.000)', '\" Printer\"[47033] (p=0.030, logit=15.625)']\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     int_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.671875, logit=18.75, token_id=800, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.048583984375, logit=16.125, token_id=29318, metadata=None))), (11896, (4, PredictedToken(token=' Library', prob=0.04296875, logit=16.0, token_id=11896, metadata=None))), (47033, (5, PredictedToken(token=' Printer', prob=0.029541015625, logit=15.625, token_id=47033, metadata=None))), (53889, (7, PredictedToken(token=' Apartment', prob=0.02294921875, logit=15.375, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:06 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:38:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.498, logit=19.375)', '\" Caul\"[90538] (p=0.389, logit=19.125)', '\" The\"[578] (p=0.028, logit=16.500)', '\" There\"[2684] (p=0.022, logit=16.250)', '\" Dolphin\"[96096] (p=0.010, logit=15.438)']\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     clean_prediction=['\" Rabbit\"[49431] (p=0.586, logit=18.375)', '\" The\"[578] (p=0.131, logit=16.875)', '\" Eagle\"[36895] (p=0.070, logit=16.250)', '\" R\"[432] (p=0.029, logit=15.375)', '\" There\"[2684] (p=0.019, logit=14.938)']\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     clean_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.5859375, logit=18.375, token_id=49431, metadata=None))), (36895, (3, PredictedToken(token=' Eagle', prob=0.0703125, logit=16.25, token_id=36895, metadata=None))), (1901, (10, PredictedToken(token=' Z', prob=0.0069580078125, logit=13.9375, token_id=1901, metadata=None))), (41785, (33, PredictedToken(token=' Spin', prob=0.00113677978515625, logit=12.125, token_id=41785, metadata=None)))])\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.715, logit=19.250)', '\" Z\"[1901] (p=0.110, logit=17.375)', '\" The\"[578] (p=0.040, logit=16.375)', '\" Rabbit\"[49431] (p=0.031, logit=16.125)', '\" SP\"[9440] (p=0.017, logit=15.500)']\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.71484375, logit=19.25, token_id=41785, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.10986328125, logit=17.375, token_id=1901, metadata=None))), (49431, (4, PredictedToken(token=' Rabbit', prob=0.031494140625, logit=16.125, token_id=49431, metadata=None))), (36895, (8, PredictedToken(token=' Eagle', prob=0.0033111572265625, logit=13.875, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:07 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:07 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     patch_prediction=['\" Folder\"[36943] (p=0.742, logit=19.250)', '\" Paper\"[18343] (p=0.054, logit=16.625)', '\" C\"[356] (p=0.029, logit=16.000)', '\" The\"[578] (p=0.027, logit=15.938)', '\" F\"[435] (p=0.017, logit=15.500)']\n",
      "2025-09-15 09:38:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:08 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.684, logit=20.500)', '\" The\"[578] (p=0.223, logit=19.375)', '\" A\"[362] (p=0.018, logit=16.875)', '\" It\"[1102] (p=0.014, logit=16.625)', '\" CL\"[7121] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:38:08 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.68359375, logit=20.5, token_id=31181, metadata=None))), (1630, (7, PredictedToken(token=' X', prob=0.00555419921875, logit=15.6875, token_id=1630, metadata=None))), (40975, (86, PredictedToken(token=' Marker', prob=6.198883056640625e-05, logit=11.1875, token_id=40975, metadata=None))), (13597, (96, PredictedToken(token=' Pen', prob=5.125999450683594e-05, logit=11.0, token_id=13597, metadata=None)))])\n",
      "2025-09-15 09:38:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:08 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.531, logit=19.375)', '\" The\"[578] (p=0.152, logit=18.125)', '\" Marker\"[40975] (p=0.135, logit=18.000)', '\" Clar\"[31181] (p=0.044, logit=16.875)', '\" PEN\"[81770] (p=0.026, logit=16.375)']\n",
      "2025-09-15 09:38:08 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.53125, logit=19.375, token_id=13597, metadata=None))), (40975, (3, PredictedToken(token=' Marker', prob=0.134765625, logit=18.0, token_id=40975, metadata=None))), (31181, (4, PredictedToken(token=' Clar', prob=0.043701171875, logit=16.875, token_id=31181, metadata=None))), (1630, (8, PredictedToken(token=' X', prob=0.005218505859375, logit=14.75, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:38:08 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:38:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     patch_prediction=['\" Mango\"[91963] (p=0.812, logit=20.750)', '\" The\"[578] (p=0.110, logit=18.750)', '\" There\"[2684] (p=0.019, logit=17.000)', '\" M\"[386] (p=0.012, logit=16.500)', '\" Apple\"[8325] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.703, logit=20.125)', '\" The\"[578] (p=0.095, logit=18.125)', '\" Tennis\"[58251] (p=0.065, logit=17.750)', '\" A\"[362] (p=0.040, logit=17.250)', '\" BASE\"[22984] (p=0.021, logit=16.625)']\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.703125, logit=20.125, token_id=38258, metadata=None))), (58251, (3, PredictedToken(token=' Tennis', prob=0.0654296875, logit=17.75, token_id=58251, metadata=None))), (800, (6, PredictedToken(token=' St', prob=0.00689697265625, logit=15.5, token_id=800, metadata=None))), (46506, (17, PredictedToken(token=' Drum', prob=0.0015411376953125, logit=14.0, token_id=46506, metadata=None))), (30558, (176, PredictedToken(token=' Ki', prob=2.3365020751953125e-05, logit=9.8125, token_id=30558, metadata=None))), (8868, (594, PredictedToken(token=' Blue', prob=3.3676624298095703e-06, logit=7.875, token_id=8868, metadata=None)))])\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.691, logit=20.125)', '\" Ki\"[30558] (p=0.083, logit=18.000)', '\" The\"[578] (p=0.083, logit=18.000)', '\" Baseball\"[38258] (p=0.039, logit=17.250)', '\" A\"[362] (p=0.024, logit=16.750)']\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.69140625, logit=20.125, token_id=8868, metadata=None))), (30558, (3, PredictedToken(token=' Ki', prob=0.08251953125, logit=18.0, token_id=30558, metadata=None))), (38258, (4, PredictedToken(token=' Baseball', prob=0.0390625, logit=17.25, token_id=38258, metadata=None))), (58251, (7, PredictedToken(token=' Tennis', prob=0.01116943359375, logit=16.0, token_id=58251, metadata=None))), (800, (8, PredictedToken(token=' St', prob=0.0038604736328125, logit=14.9375, token_id=800, metadata=None))), (46506, (24, PredictedToken(token=' Drum', prob=0.000713348388671875, logit=13.25, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:09 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:09 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:38:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.498, logit=20.125)', '\" Apartment\"[53889] (p=0.235, logit=19.375)', '\" The\"[578] (p=0.162, logit=19.000)', '\" A\"[362] (p=0.022, logit=17.000)', '\" There\"[2684] (p=0.017, logit=16.750)']\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.797, logit=20.750)', '\" Hick\"[79028] (p=0.074, logit=18.375)', '\" The\"[578] (p=0.065, logit=18.250)', '\" There\"[2684] (p=0.011, logit=16.500)', '\" C\"[356] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.796875, logit=20.75, token_id=42609, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.07421875, logit=18.375, token_id=79028, metadata=None))), (393, (6, PredictedToken(token=' P', prob=0.00885009765625, logit=16.25, token_id=393, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.00885009765625, logit=16.25, token_id=356, metadata=None))), (11896, (8, PredictedToken(token=' Library', prob=0.004180908203125, logit=15.5, token_id=11896, metadata=None))), (4783, (27, PredictedToken(token=' House', prob=0.0002841949462890625, logit=12.8125, token_id=4783, metadata=None))), (6690, (30, PredictedToken(token=' Air', prob=0.0002079010009765625, logit=12.5, token_id=6690, metadata=None)))])\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.871, logit=22.000)', '\" The\"[578] (p=0.063, logit=19.375)', '\" Hick\"[79028] (p=0.016, logit=18.000)', '\" Pine\"[42609] (p=0.011, logit=17.625)', '\" A\"[362] (p=0.011, logit=17.625)']\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.87109375, logit=22.0, token_id=11896, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.0159912109375, logit=18.0, token_id=79028, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.010986328125, logit=17.625, token_id=42609, metadata=None))), (4783, (9, PredictedToken(token=' House', prob=0.00244140625, logit=16.125, token_id=4783, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.00244140625, logit=16.125, token_id=356, metadata=None))), (393, (11, PredictedToken(token=' P', prob=0.001312255859375, logit=15.5, token_id=393, metadata=None))), (6690, (40, PredictedToken(token=' Air', prob=6.532669067382812e-05, logit=12.5, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:10 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:10 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:38:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.605, logit=18.250)', '\" Chain\"[29625] (p=0.120, logit=16.625)', '\" The\"[578] (p=0.050, logit=15.750)', '\" Blue\"[8868] (p=0.047, logit=15.688)', '\" Ti\"[23126] (p=0.013, logit=14.438)']\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.809, logit=20.250)', '\" The\"[578] (p=0.085, logit=18.000)', '\" An\"[1556] (p=0.028, logit=16.875)', '\" ank\"[71572] (p=0.009, logit=15.750)', '\" AN\"[2147] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.80859375, logit=20.25, token_id=57915, metadata=None))), (23910, (6, PredictedToken(token=' Pear', prob=0.00579833984375, logit=15.3125, token_id=23910, metadata=None))), (6031, (7, PredictedToken(token=' Bro', prob=0.005126953125, logit=15.1875, token_id=6031, metadata=None))), (18787, (14, PredictedToken(token=' Oak', prob=0.00156402587890625, logit=14.0, token_id=18787, metadata=None))), (89077, (34, PredictedToken(token=' Strawberry', prob=0.00032806396484375, logit=12.4375, token_id=89077, metadata=None)))])\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     int_prediction=['\" Pear\"[23910] (p=0.949, logit=21.500)', '\" The\"[578] (p=0.022, logit=17.750)', '\" pear\"[38790] (p=0.004, logit=16.125)', '\" P\"[393] (p=0.003, logit=15.562)', '\" A\"[362] (p=0.002, logit=15.250)']\n",
      "2025-09-15 09:38:11 src.selection.optimization INFO     int_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.94921875, logit=21.5, token_id=23910, metadata=None))), (89077, (6, PredictedToken(token=' Strawberry', prob=0.001617431640625, logit=15.125, token_id=89077, metadata=None))), (18787, (8, PredictedToken(token=' Oak', prob=0.00125885009765625, logit=14.875, token_id=18787, metadata=None))), (6031, (9, PredictedToken(token=' Bro', prob=0.0011138916015625, logit=14.75, token_id=6031, metadata=None))), (57915, (160, PredictedToken(token=' Ank', prob=9.59634780883789e-06, logit=10.0, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:12 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     patch_prediction=['\" Printer\"[47033] (p=0.703, logit=20.125)', '\" The\"[578] (p=0.138, logit=18.500)', '\" Camera\"[14669] (p=0.051, logit=17.500)', '\" Binder\"[91263] (p=0.016, logit=16.375)', '\" A\"[362] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.625, logit=19.375)', '\" Toilet\"[82994] (p=0.179, logit=18.125)', '\" The\"[578] (p=0.074, logit=17.250)', '\" A\"[362] (p=0.031, logit=16.375)', '\" R\"[432] (p=0.014, logit=15.562)']\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.625, logit=19.375, token_id=57551, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.1787109375, logit=18.125, token_id=82994, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.0137939453125, logit=15.5625, token_id=432, metadata=None))), (18191, (11, PredictedToken(token=' Mouse', prob=0.0023956298828125, logit=13.8125, token_id=18191, metadata=None))), (30173, (16, PredictedToken(token=' Speaker', prob=0.00164794921875, logit=13.4375, token_id=30173, metadata=None)))])\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.648, logit=19.500)', '\" Mouse\"[18191] (p=0.100, logit=17.625)', '\" The\"[578] (p=0.053, logit=17.000)', '\" R\"[432] (p=0.032, logit=16.500)', '\" A\"[362] (p=0.032, logit=16.500)']\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.6484375, logit=19.5, token_id=30173, metadata=None))), (18191, (2, PredictedToken(token=' Mouse', prob=0.099609375, logit=17.625, token_id=18191, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.032470703125, logit=16.5, token_id=432, metadata=None))), (57551, (6, PredictedToken(token=' Sink', prob=0.028564453125, logit=16.375, token_id=57551, metadata=None))), (82994, (8, PredictedToken(token=' Toilet', prob=0.01190185546875, logit=15.5, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:12 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:12 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:38:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     patch_prediction=['\" Harmon\"[40759] (p=0.754, logit=20.250)', '\" The\"[578] (p=0.148, logit=18.625)', '\" Piano\"[56491] (p=0.026, logit=16.875)', '\" A\"[362] (p=0.020, logit=16.625)', '\" It\"[1102] (p=0.004, logit=15.125)']\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.945, logit=21.875)', '\" The\"[578] (p=0.029, logit=18.375)', '\" V\"[650] (p=0.004, logit=16.375)', '\" violet\"[80836] (p=0.003, logit=16.125)', '\" There\"[2684] (p=0.003, logit=16.125)']\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.9453125, logit=21.875, token_id=74574, metadata=None))), (5250, (6, PredictedToken(token=' Pe', prob=0.00194549560546875, logit=15.6875, token_id=5250, metadata=None))), (356, (14, PredictedToken(token=' C', prob=0.000263214111328125, logit=13.6875, token_id=356, metadata=None))), (4923, (31, PredictedToken(token=' Sk', prob=0.000102996826171875, logit=12.75, token_id=4923, metadata=None))), (16147, (42, PredictedToken(token=' Smart', prob=6.67572021484375e-05, logit=12.3125, token_id=16147, metadata=None))), (5340, (64, PredictedToken(token=' Har', prob=3.552436828613281e-05, logit=11.6875, token_id=5340, metadata=None))), (98641, (101, PredictedToken(token=' Microwave', prob=1.7881393432617188e-05, logit=11.0, token_id=98641, metadata=None)))])\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.781, logit=20.625)', '\" The\"[578] (p=0.120, logit=18.750)', '\" Smart\"[16147] (p=0.024, logit=17.125)', '\" A\"[362] (p=0.013, logit=16.500)', '\" There\"[2684] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.78125, logit=20.625, token_id=356, metadata=None))), (16147, (3, PredictedToken(token=' Smart', prob=0.0235595703125, logit=17.125, token_id=16147, metadata=None))), (74574, (6, PredictedToken(token=' Violet', prob=0.006744384765625, logit=15.875, token_id=74574, metadata=None))), (4923, (9, PredictedToken(token=' Sk', prob=0.00299072265625, logit=15.0625, token_id=4923, metadata=None))), (5340, (12, PredictedToken(token=' Har', prob=0.002197265625, logit=14.75, token_id=5340, metadata=None))), (98641, (17, PredictedToken(token=' Microwave', prob=0.0010986328125, logit=14.0625, token_id=98641, metadata=None))), (5250, (27, PredictedToken(token=' Pe', prob=0.00040435791015625, logit=13.0625, token_id=5250, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:13 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:38:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     patch_prediction=['\" Necklace\"[86460] (p=0.840, logit=20.375)', '\" The\"[578] (p=0.069, logit=17.875)', '\" A\"[362] (p=0.015, logit=16.375)', '\" NE\"[8014] (p=0.006, logit=15.438)', '\" Pin\"[17929] (p=0.005, logit=15.312)']\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.625, logit=19.250)', '\" Maple\"[44570] (p=0.158, logit=17.875)', '\" The\"[578] (p=0.066, logit=17.000)', '\" There\"[2684] (p=0.028, logit=16.125)', '\" None\"[2290] (p=0.024, logit=16.000)']\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.625, logit=19.25, token_id=79028, metadata=None))), (44570, (2, PredictedToken(token=' Maple', prob=0.158203125, logit=17.875, token_id=44570, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.005767822265625, logit=14.5625, token_id=6031, metadata=None))), (57915, (14, PredictedToken(token=' Ank', prob=0.002899169921875, logit=13.875, token_id=57915, metadata=None))), (81501, (21, PredictedToken(token=' Pendant', prob=0.00165557861328125, logit=13.3125, token_id=81501, metadata=None)))])\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     int_prediction=['\" Ank\"[57915] (p=0.785, logit=20.125)', '\" Pendant\"[81501] (p=0.106, logit=18.125)', '\" An\"[1556] (p=0.016, logit=16.250)', '\" The\"[578] (p=0.013, logit=16.000)', '\" AN\"[2147] (p=0.007, logit=15.438)']\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     int_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.78515625, logit=20.125, token_id=57915, metadata=None))), (81501, (2, PredictedToken(token=' Pendant', prob=0.10595703125, logit=18.125, token_id=81501, metadata=None))), (44570, (6, PredictedToken(token=' Maple', prob=0.007232666015625, logit=15.4375, token_id=44570, metadata=None))), (6031, (9, PredictedToken(token=' Bro', prob=0.006378173828125, logit=15.3125, token_id=6031, metadata=None))), (79028, (12, PredictedToken(token=' Hick', prob=0.002655029296875, logit=14.4375, token_id=79028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:14 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:38:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.688, logit=20.000)', '\" Jacket\"[55870] (p=0.136, logit=18.375)', '\" The\"[578] (p=0.082, logit=17.875)', '\" A\"[362] (p=0.024, logit=16.625)', '\" dress\"[8679] (p=0.007, logit=15.438)']\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     clean_prediction=['\" Ottoman\"[70110] (p=0.531, logit=19.125)', '\" The\"[578] (p=0.221, logit=18.250)', '\" An\"[1556] (p=0.049, logit=16.750)', '\" Coffee\"[27171] (p=0.043, logit=16.625)', '\" It\"[1102] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     clean_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.53125, logit=19.125, token_id=70110, metadata=None))), (27171, (4, PredictedToken(token=' Coffee', prob=0.04345703125, logit=16.625, token_id=27171, metadata=None))), (30760, (17, PredictedToken(token=' Scar', prob=0.002960205078125, logit=13.9375, token_id=30760, metadata=None))), (68554, (107, PredictedToken(token=' Gloves', prob=0.00014781951904296875, logit=10.9375, token_id=68554, metadata=None))), (64695, (228, PredictedToken(token=' Peach', prob=3.719329833984375e-05, logit=9.5625, token_id=64695, metadata=None)))])\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.559, logit=18.375)', '\" The\"[578] (p=0.182, logit=17.250)', '\" Ottoman\"[70110] (p=0.036, logit=15.625)', '\" Glo\"[25372] (p=0.017, logit=14.875)', '\" Scar\"[30760] (p=0.016, logit=14.812)']\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.55859375, logit=18.375, token_id=68554, metadata=None))), (70110, (3, PredictedToken(token=' Ottoman', prob=0.035888671875, logit=15.625, token_id=70110, metadata=None))), (30760, (5, PredictedToken(token=' Scar', prob=0.015869140625, logit=14.8125, token_id=30760, metadata=None))), (64695, (41, PredictedToken(token=' Peach', prob=0.000743865966796875, logit=11.75, token_id=64695, metadata=None))), (27171, (54, PredictedToken(token=' Coffee', prob=0.00051116943359375, logit=11.375, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:15 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:15 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:38:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     patch_prediction=['\" Raspberry\"[48665] (p=0.840, logit=20.875)', '\" The\"[578] (p=0.078, logit=18.500)', '\" R\"[432] (p=0.020, logit=17.125)', '\" Orange\"[22725] (p=0.014, logit=16.750)', '\" There\"[2684] (p=0.006, logit=16.000)']\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.625, logit=19.625)', '\" Tow\"[41493] (p=0.260, logit=18.750)', '\" The\"[578] (p=0.031, logit=16.625)', '\" TO\"[5257] (p=0.011, logit=15.625)', '\" None\"[2290] (p=0.008, logit=15.250)']\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.625, logit=19.625, token_id=82994, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.259765625, logit=18.75, token_id=41493, metadata=None))), (80629, (8, PredictedToken(token=' Grape', prob=0.003936767578125, logit=14.5625, token_id=80629, metadata=None))), (8325, (31, PredictedToken(token=' Apple', prob=0.000568389892578125, logit=12.625, token_id=8325, metadata=None)))])\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.559, logit=19.000)', '\" Tow\"[41493] (p=0.232, logit=18.125)', '\" Grape\"[80629] (p=0.046, logit=16.500)', '\" APPLE\"[91436] (p=0.031, logit=16.125)', '\" The\"[578] (p=0.028, logit=16.000)']\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.55859375, logit=19.0, token_id=8325, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.232421875, logit=18.125, token_id=41493, metadata=None))), (80629, (3, PredictedToken(token=' Grape', prob=0.0458984375, logit=16.5, token_id=80629, metadata=None))), (82994, (6, PredictedToken(token=' Toilet', prob=0.014892578125, logit=15.375, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:16 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.527, logit=20.000)', '\" Soap\"[61731] (p=0.320, logit=19.500)', '\" Bench\"[36358] (p=0.038, logit=17.375)', '\" The\"[578] (p=0.034, logit=17.250)', '\" SOAP\"[64332] (p=0.010, logit=16.000)']\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.656, logit=19.625)', '\" The\"[578] (p=0.130, logit=18.000)', '\" Golf\"[28131] (p=0.079, logit=17.500)', '\" A\"[362] (p=0.048, logit=17.000)', '\" Tennis\"[58251] (p=0.018, logit=16.000)']\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.65625, logit=19.625, token_id=432, metadata=None))), (28131, (3, PredictedToken(token=' Golf', prob=0.07861328125, logit=17.5, token_id=28131, metadata=None))), (48471, (29, PredictedToken(token=' Shower', prob=0.000530242919921875, logit=12.5, token_id=48471, metadata=None))), (27738, (52, PredictedToken(token=' Ward', prob=0.00022029876708984375, logit=11.625, token_id=27738, metadata=None))), (83499, (55, PredictedToken(token=' Tooth', prob=0.00020694732666015625, logit=11.5625, token_id=83499, metadata=None)))])\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     int_prediction=['\" Tooth\"[83499] (p=0.762, logit=19.500)', '\" The\"[578] (p=0.049, logit=16.750)', '\" Golf\"[28131] (p=0.043, logit=16.625)', '\" Shower\"[48471] (p=0.026, logit=16.125)', '\" TO\"[5257] (p=0.026, logit=16.125)']\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     int_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.76171875, logit=19.5, token_id=83499, metadata=None))), (28131, (3, PredictedToken(token=' Golf', prob=0.04296875, logit=16.625, token_id=28131, metadata=None))), (48471, (5, PredictedToken(token=' Shower', prob=0.026123046875, logit=16.125, token_id=48471, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.00848388671875, logit=15.0, token_id=432, metadata=None))), (27738, (7, PredictedToken(token=' Ward', prob=0.007476806640625, logit=14.875, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:17 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:17 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.719, logit=19.125)', '\" The\"[578] (p=0.098, logit=17.125)', '\" Tennis\"[58251] (p=0.059, logit=16.625)', '\" A\"[362] (p=0.032, logit=16.000)', '\" H\"[473] (p=0.007, logit=14.500)']\n",
      "2025-09-15 09:38:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:18 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.746, logit=20.125)', '\" Brace\"[70306] (p=0.130, logit=18.375)', '\" The\"[578] (p=0.037, logit=17.125)', '\" A\"[362] (p=0.012, logit=16.000)', '\" NE\"[8014] (p=0.008, logit=15.625)']\n",
      "2025-09-15 09:38:18 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.74609375, logit=20.125, token_id=86460, metadata=None))), (70306, (2, PredictedToken(token=' Brace', prob=0.1298828125, logit=18.375, token_id=70306, metadata=None))), (21424, (6, PredictedToken(token=' Football', prob=0.006072998046875, logit=15.3125, token_id=21424, metadata=None))), (4923, (25, PredictedToken(token=' Sk', prob=0.000873565673828125, logit=13.375, token_id=4923, metadata=None)))])\n",
      "2025-09-15 09:38:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:18 src.selection.optimization INFO     int_prediction=['\" Football\"[21424] (p=0.934, logit=21.125)', '\" The\"[578] (p=0.012, logit=16.750)', '\" A\"[362] (p=0.012, logit=16.750)', '\" FOOT\"[81137] (p=0.010, logit=16.625)', '\" Brace\"[70306] (p=0.004, logit=15.625)']\n",
      "2025-09-15 09:38:18 src.selection.optimization INFO     int_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.93359375, logit=21.125, token_id=21424, metadata=None))), (70306, (5, PredictedToken(token=' Brace', prob=0.003814697265625, logit=15.625, token_id=70306, metadata=None))), (86460, (8, PredictedToken(token=' Necklace', prob=0.00191497802734375, logit=14.9375, token_id=86460, metadata=None))), (4923, (11, PredictedToken(token=' Sk', prob=0.00131988525390625, logit=14.5625, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:18 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:38:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     patch_prediction=['\" Y\"[816] (p=0.469, logit=18.500)', '\" Sub\"[3804] (p=0.285, logit=18.000)', '\" The\"[578] (p=0.119, logit=17.125)', '\" A\"[362] (p=0.039, logit=16.000)', '\" SUB\"[16532] (p=0.007, logit=14.250)']\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     clean_prediction=['\" St\"[800] (p=0.734, logit=19.500)', '\" The\"[578] (p=0.088, logit=17.375)', '\" Sofa\"[61948] (p=0.060, logit=17.000)', '\" A\"[362] (p=0.015, logit=15.625)', '\" ST\"[4015] (p=0.010, logit=15.188)']\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     clean_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.734375, logit=19.5, token_id=800, metadata=None))), (61948, (3, PredictedToken(token=' Sofa', prob=0.060302734375, logit=17.0, token_id=61948, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.005615234375, logit=14.625, token_id=3341, metadata=None))), (20423, (15, PredictedToken(token=' Amb', prob=0.0023345947265625, logit=13.75, token_id=20423, metadata=None)))])\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.762, logit=19.125)', '\" The\"[578] (p=0.071, logit=16.750)', '\" Sofa\"[61948] (p=0.033, logit=16.000)', '\" St\"[800] (p=0.015, logit=15.188)', '\" CAR\"[28876] (p=0.013, logit=15.062)']\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.76171875, logit=19.125, token_id=3341, metadata=None))), (61948, (3, PredictedToken(token=' Sofa', prob=0.033447265625, logit=16.0, token_id=61948, metadata=None))), (800, (4, PredictedToken(token=' St', prob=0.01483154296875, logit=15.1875, token_id=800, metadata=None))), (20423, (6, PredictedToken(token=' Amb', prob=0.0123291015625, logit=15.0, token_id=20423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:19 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:19 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:38:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     patch_prediction=['\" Rose\"[16344] (p=0.562, logit=19.875)', '\" The\"[578] (p=0.207, logit=18.875)', '\" A\"[362] (p=0.059, logit=17.625)', '\" Lily\"[48390] (p=0.046, logit=17.375)', '\" RO\"[12076] (p=0.046, logit=17.375)']\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.840, logit=20.500)', '\" Shower\"[48471] (p=0.089, logit=18.250)', '\" Gloves\"[68554] (p=0.015, logit=16.500)', '\" The\"[578] (p=0.012, logit=16.250)', '\" A\"[362] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.83984375, logit=20.5, token_id=41493, metadata=None))), (48471, (2, PredictedToken(token=' Shower', prob=0.0888671875, logit=18.25, token_id=48471, metadata=None))), (68554, (3, PredictedToken(token=' Gloves', prob=0.015380859375, logit=16.5, token_id=68554, metadata=None))), (55405, (11, PredictedToken(token=' Orch', prob=0.0013427734375, logit=14.0625, token_id=55405, metadata=None))), (47033, (13, PredictedToken(token=' Printer', prob=0.0008697509765625, logit=13.625, token_id=47033, metadata=None))), (74574, (21, PredictedToken(token=' Violet', prob=0.000385284423828125, logit=12.8125, token_id=74574, metadata=None))), (87213, (35, PredictedToken(token=' Oven', prob=0.00017070770263671875, logit=12.0, token_id=87213, metadata=None)))])\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.926, logit=21.375)', '\" Tow\"[41493] (p=0.028, logit=17.875)', '\" Orch\"[55405] (p=0.009, logit=16.750)', '\" Shower\"[48471] (p=0.009, logit=16.750)', '\" The\"[578] (p=0.007, logit=16.500)']\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.92578125, logit=21.375, token_id=74574, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.0279541015625, logit=17.875, token_id=41493, metadata=None))), (48471, (3, PredictedToken(token=' Shower', prob=0.00909423828125, logit=16.75, token_id=48471, metadata=None))), (55405, (4, PredictedToken(token=' Orch', prob=0.00909423828125, logit=16.75, token_id=55405, metadata=None))), (47033, (9, PredictedToken(token=' Printer', prob=0.0015716552734375, logit=15.0, token_id=47033, metadata=None))), (68554, (10, PredictedToken(token=' Gloves', prob=0.0015716552734375, logit=15.0, token_id=68554, metadata=None))), (87213, (37, PredictedToken(token=' Oven', prob=7.390975952148438e-05, logit=11.9375, token_id=87213, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:20 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.480, logit=19.000)', '\" Air\"[6690] (p=0.227, logit=18.250)', '\" The\"[578] (p=0.094, logit=17.375)', '\" A\"[362] (p=0.024, logit=16.000)', '\" There\"[2684] (p=0.019, logit=15.750)']\n",
      "2025-09-15 09:38:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     clean_prediction=['\" Sh\"[1443] (p=0.594, logit=20.000)', '\" Toilet\"[82994] (p=0.279, logit=19.250)', '\" The\"[578] (p=0.033, logit=17.125)', '\" Hel\"[16183] (p=0.014, logit=16.250)', '\" None\"[2290] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     clean_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.59375, logit=20.0, token_id=1443, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.279296875, logit=19.25, token_id=82994, metadata=None))), (16183, (4, PredictedToken(token=' Hel', prob=0.01397705078125, logit=16.25, token_id=16183, metadata=None))), (19111, (37, PredictedToken(token=' Bus', prob=0.0003490447998046875, logit=12.5625, token_id=19111, metadata=None)))])\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.684, logit=19.500)', '\" Hel\"[16183] (p=0.135, logit=17.875)', '\" Toilet\"[82994] (p=0.056, logit=17.000)', '\" The\"[578] (p=0.030, logit=16.375)', '\" None\"[2290] (p=0.023, logit=16.125)']\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.68359375, logit=19.5, token_id=19111, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.134765625, logit=17.875, token_id=16183, metadata=None))), (82994, (3, PredictedToken(token=' Toilet', prob=0.05615234375, logit=17.0, token_id=82994, metadata=None))), (1443, (9, PredictedToken(token=' Sh', prob=0.004058837890625, logit=14.375, token_id=1443, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:21 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     patch_prediction=['\" Willow\"[65449] (p=0.863, logit=20.375)', '\" The\"[578] (p=0.055, logit=17.625)', '\" Magn\"[20918] (p=0.018, logit=16.500)', '\" There\"[2684] (p=0.007, logit=15.500)', '\" W\"[468] (p=0.005, logit=15.125)']\n",
      "2025-09-15 09:38:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:22 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.852, logit=20.375)', '\" Museum\"[16730] (p=0.048, logit=17.500)', '\" The\"[578] (p=0.048, logit=17.500)', '\" E\"[469] (p=0.007, logit=15.625)', '\" An\"[1556] (p=0.006, logit=15.438)']\n",
      "2025-09-15 09:38:22 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.8515625, logit=20.375, token_id=53889, metadata=None))), (16730, (3, PredictedToken(token=' Museum', prob=0.0478515625, logit=17.5, token_id=16730, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.007354736328125, logit=15.625, token_id=469, metadata=None))), (18787, (6, PredictedToken(token=' Oak', prob=0.0030670166015625, logit=14.75, token_id=18787, metadata=None)))])\n",
      "2025-09-15 09:38:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:22 src.selection.optimization INFO     int_prediction=['\" Apartment\"[53889] (p=0.471, logit=18.250)', '\" Museum\"[16730] (p=0.196, logit=17.375)', '\" E\"[469] (p=0.119, logit=16.875)', '\" Oak\"[18787] (p=0.082, logit=16.500)', '\" The\"[578] (p=0.041, logit=15.812)']\n",
      "2025-09-15 09:38:22 src.selection.optimization INFO     int_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.470703125, logit=18.25, token_id=53889, metadata=None))), (16730, (2, PredictedToken(token=' Museum', prob=0.1962890625, logit=17.375, token_id=16730, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.119140625, logit=16.875, token_id=469, metadata=None))), (18787, (4, PredictedToken(token=' Oak', prob=0.08203125, logit=16.5, token_id=18787, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:22 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:22 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:38:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.465, logit=18.375)', '\" The\"[578] (p=0.171, logit=17.375)', '\" Spr\"[15883] (p=0.133, logit=17.125)', '\" Stadium\"[23462] (p=0.063, logit=16.375)', '\" A\"[362] (p=0.028, logit=15.562)']\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.535, logit=19.000)', '\" Tennis\"[58251] (p=0.196, logit=18.000)', '\" The\"[578] (p=0.093, logit=17.250)', '\" A\"[362] (p=0.039, logit=16.375)', '\" Horse\"[34392] (p=0.030, logit=16.125)']\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.53515625, logit=19.0, token_id=28131, metadata=None))), (58251, (2, PredictedToken(token=' Tennis', prob=0.1962890625, logit=18.0, token_id=58251, metadata=None))), (34392, (5, PredictedToken(token=' Horse', prob=0.0301513671875, logit=16.125, token_id=34392, metadata=None))), (57551, (72, PredictedToken(token=' Sink', prob=0.00022983551025390625, logit=11.25, token_id=57551, metadata=None))), (20918, (119, PredictedToken(token=' Magn', prob=9.584426879882812e-05, logit=10.375, token_id=20918, metadata=None))), (32498, (125, PredictedToken(token=' Mall', prob=8.487701416015625e-05, logit=10.25, token_id=32498, metadata=None))), (6150, (308, PredictedToken(token=' School', prob=1.5616416931152344e-05, logit=8.5625, token_id=6150, metadata=None)))])\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     int_prediction=['\" Sink\"[57551] (p=0.879, logit=20.500)', '\" The\"[578] (p=0.044, logit=17.500)', '\" A\"[362] (p=0.011, logit=16.125)', '\" School\"[6150] (p=0.008, logit=15.750)', '\" Magn\"[20918] (p=0.007, logit=15.625)']\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     int_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.87890625, logit=20.5, token_id=57551, metadata=None))), (6150, (4, PredictedToken(token=' School', prob=0.007598876953125, logit=15.75, token_id=6150, metadata=None))), (20918, (5, PredictedToken(token=' Magn', prob=0.0067138671875, logit=15.625, token_id=20918, metadata=None))), (32498, (8, PredictedToken(token=' Mall', prob=0.003173828125, logit=14.875, token_id=32498, metadata=None))), (34392, (10, PredictedToken(token=' Horse', prob=0.00262451171875, logit=14.6875, token_id=34392, metadata=None))), (58251, (12, PredictedToken(token=' Tennis', prob=0.0023193359375, logit=14.5625, token_id=58251, metadata=None))), (28131, (13, PredictedToken(token=' Golf', prob=0.0021820068359375, logit=14.5, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:38:23 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.914, logit=21.500)', '\" The\"[578] (p=0.052, logit=18.625)', '\" P\"[393] (p=0.005, logit=16.250)', '\" A\"[362] (p=0.004, logit=16.125)', '\" There\"[2684] (p=0.002, logit=15.562)']\n",
      "2025-09-15 09:38:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     clean_prediction=['\" Sofa\"[61948] (p=0.730, logit=20.500)', '\" Chair\"[16478] (p=0.099, logit=18.500)', '\" The\"[578] (p=0.099, logit=18.500)', '\" A\"[362] (p=0.010, logit=16.250)', '\" SO\"[5745] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     clean_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.73046875, logit=20.5, token_id=61948, metadata=None))), (16478, (3, PredictedToken(token=' Chair', prob=0.09912109375, logit=18.5, token_id=16478, metadata=None))), (40090, (17, PredictedToken(token=' Pressure', prob=0.0010986328125, logit=14.0, token_id=40090, metadata=None))), (17367, (41, PredictedToken(token=' Factory', prob=0.000179290771484375, logit=12.1875, token_id=17367, metadata=None))), (8325, (74, PredictedToken(token=' Apple', prob=7.009506225585938e-05, logit=11.25, token_id=8325, metadata=None))), (89077, (78, PredictedToken(token=' Strawberry', prob=6.580352783203125e-05, logit=11.1875, token_id=89077, metadata=None)))])\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.750, logit=20.250)', '\" Strawberry\"[89077] (p=0.147, logit=18.625)', '\" The\"[578] (p=0.037, logit=17.250)', '\" There\"[2684] (p=0.008, logit=15.688)', '\" APPLE\"[91436] (p=0.007, logit=15.625)']\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.75, logit=20.25, token_id=8325, metadata=None))), (89077, (2, PredictedToken(token=' Strawberry', prob=0.1474609375, logit=18.625, token_id=89077, metadata=None))), (61948, (6, PredictedToken(token=' Sofa', prob=0.003692626953125, logit=14.9375, token_id=61948, metadata=None))), (17367, (17, PredictedToken(token=' Factory', prob=0.001129150390625, logit=13.75, token_id=17367, metadata=None))), (40090, (25, PredictedToken(token=' Pressure', prob=0.000728607177734375, logit=13.3125, token_id=40090, metadata=None))), (16478, (24, PredictedToken(token=' Chair', prob=0.000728607177734375, logit=13.3125, token_id=16478, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:24 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.863, logit=21.125)', '\" The\"[578] (p=0.071, logit=18.625)', '\" E\"[469] (p=0.016, logit=17.125)', '\" Tiger\"[36845] (p=0.014, logit=17.000)', '\" An\"[1556] (p=0.005, logit=16.000)']\n",
      "2025-09-15 09:38:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     clean_prediction=['\" Bench\"[36358] (p=0.844, logit=20.000)', '\" The\"[578] (p=0.048, logit=17.125)', '\" Table\"[6771] (p=0.029, logit=16.625)', '\" B\"[426] (p=0.011, logit=15.625)', '\" There\"[2684] (p=0.005, logit=14.938)']\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     clean_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.84375, logit=20.0, token_id=36358, metadata=None))), (6771, (3, PredictedToken(token=' Table', prob=0.02880859375, logit=16.625, token_id=6771, metadata=None))), (24941, (13, PredictedToken(token=' Bear', prob=0.0019683837890625, logit=13.9375, token_id=24941, metadata=None))), (36895, (18, PredictedToken(token=' Eagle', prob=0.001190185546875, logit=13.4375, token_id=36895, metadata=None))), (32498, (152, PredictedToken(token=' Mall', prob=2.8014183044433594e-05, logit=9.6875, token_id=32498, metadata=None)))])\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     int_prediction=['\" Eagle\"[36895] (p=0.684, logit=19.375)', '\" Bear\"[24941] (p=0.152, logit=17.875)', '\" The\"[578] (p=0.056, logit=16.875)', '\" E\"[469] (p=0.019, logit=15.812)', '\" Bench\"[36358] (p=0.012, logit=15.312)']\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     int_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.68359375, logit=19.375, token_id=36895, metadata=None))), (24941, (2, PredictedToken(token=' Bear', prob=0.15234375, logit=17.875, token_id=24941, metadata=None))), (36358, (5, PredictedToken(token=' Bench', prob=0.01177978515625, logit=15.3125, token_id=36358, metadata=None))), (6771, (9, PredictedToken(token=' Table', prob=0.0033721923828125, logit=14.0625, token_id=6771, metadata=None))), (32498, (46, PredictedToken(token=' Mall', prob=0.0002288818359375, logit=11.375, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:25 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:25 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     patch_prediction=['\" Book\"[6017] (p=0.742, logit=20.000)', '\" The\"[578] (p=0.069, logit=17.625)', '\" Bed\"[13394] (p=0.047, logit=17.250)', '\" A\"[362] (p=0.033, logit=16.875)', '\" E\"[469] (p=0.020, logit=16.375)']\n",
      "2025-09-15 09:38:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     clean_prediction=['\" Van\"[13000] (p=0.691, logit=20.000)', '\" Bench\"[36358] (p=0.106, logit=18.125)', '\" The\"[578] (p=0.083, logit=17.875)', '\" VAN\"[97753] (p=0.030, logit=16.875)', '\" A\"[362] (p=0.027, logit=16.750)']\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     clean_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.69140625, logit=20.0, token_id=13000, metadata=None))), (36358, (2, PredictedToken(token=' Bench', prob=0.10595703125, logit=18.125, token_id=36358, metadata=None))), (34785, (6, PredictedToken(token=' Truck', prob=0.01434326171875, logit=16.125, token_id=34785, metadata=None))), (6771, (10, PredictedToken(token=' Table', prob=0.002197265625, logit=14.25, token_id=6771, metadata=None))), (39247, (13, PredictedToken(token=' Slow', prob=0.0011749267578125, logit=13.625, token_id=39247, metadata=None))), (57915, (24, PredictedToken(token=' Ank', prob=0.000713348388671875, logit=13.125, token_id=57915, metadata=None))), (24423, (113, PredictedToken(token=' Monitor', prob=4.291534423828125e-05, logit=10.3125, token_id=24423, metadata=None)))])\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.715, logit=20.250)', '\" Table\"[6771] (p=0.075, logit=18.000)', '\" The\"[578] (p=0.059, logit=17.750)', '\" Truck\"[34785] (p=0.040, logit=17.375)', '\" Slow\"[39247] (p=0.028, logit=17.000)']\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.71484375, logit=20.25, token_id=36358, metadata=None))), (6771, (2, PredictedToken(token=' Table', prob=0.0751953125, logit=18.0, token_id=6771, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.040283203125, logit=17.375, token_id=34785, metadata=None))), (39247, (5, PredictedToken(token=' Slow', prob=0.0277099609375, logit=17.0, token_id=39247, metadata=None))), (13000, (7, PredictedToken(token=' Van', prob=0.01019287109375, logit=16.0, token_id=13000, metadata=None))), (57915, (67, PredictedToken(token=' Ank', prob=0.00012874603271484375, logit=11.625, token_id=57915, metadata=None))), (24423, (115, PredictedToken(token=' Monitor', prob=4.172325134277344e-05, logit=10.5, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:26 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:26 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     patch_prediction=['\" Potato\"[78703] (p=0.715, logit=20.250)', '\" The\"[578] (p=0.110, logit=18.375)', '\" Z\"[1901] (p=0.052, logit=17.625)', '\" There\"[2684] (p=0.019, logit=16.625)', '\" S\"[328] (p=0.017, logit=16.500)']\n",
      "2025-09-15 09:38:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     clean_prediction=['\" Swe\"[37326] (p=0.613, logit=19.750)', '\" The\"[578] (p=0.176, logit=18.500)', '\" A\"[362] (p=0.039, logit=17.000)', '\" Coat\"[68867] (p=0.031, logit=16.750)', '\" Pepper\"[52882] (p=0.027, logit=16.625)']\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     clean_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.61328125, logit=19.75, token_id=37326, metadata=None))), (68867, (4, PredictedToken(token=' Coat', prob=0.030517578125, logit=16.75, token_id=68867, metadata=None))), (52882, (5, PredictedToken(token=' Pepper', prob=0.0269775390625, logit=16.625, token_id=52882, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.01055908203125, logit=15.6875, token_id=3341, metadata=None))), (17810, (11, PredictedToken(token=' Cat', prob=0.00341796875, logit=14.5625, token_id=17810, metadata=None))), (43950, (39, PredictedToken(token=' Lav', prob=0.00052642822265625, logit=12.6875, token_id=43950, metadata=None))), (11896, (56, PredictedToken(token=' Library', prob=0.0003185272216796875, logit=12.1875, token_id=11896, metadata=None)))])\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.797, logit=20.875)', '\" The\"[578] (p=0.095, logit=18.750)', '\" Car\"[3341] (p=0.035, logit=17.750)', '\" PE\"[22557] (p=0.011, logit=16.625)', '\" Cat\"[17810] (p=0.009, logit=16.375)']\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.796875, logit=20.875, token_id=52882, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.034912109375, logit=17.75, token_id=3341, metadata=None))), (17810, (5, PredictedToken(token=' Cat', prob=0.00885009765625, logit=16.375, token_id=17810, metadata=None))), (11896, (14, PredictedToken(token=' Library', prob=0.0010528564453125, logit=14.25, token_id=11896, metadata=None))), (43950, (19, PredictedToken(token=' Lav', prob=0.000873565673828125, logit=14.0625, token_id=43950, metadata=None))), (68867, (26, PredictedToken(token=' Coat', prob=0.000530242919921875, logit=13.5625, token_id=68867, metadata=None))), (37326, (85, PredictedToken(token=' Swe', prob=6.341934204101562e-05, logit=11.4375, token_id=37326, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:27 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.836, logit=21.250)', '\" Shower\"[48471] (p=0.061, logit=18.625)', '\" The\"[578] (p=0.032, logit=18.000)', '\" St\"[800] (p=0.025, logit=17.750)', '\" A\"[362] (p=0.009, logit=16.750)']\n",
      "2025-09-15 09:38:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.898, logit=21.000)', '\" The\"[578] (p=0.024, logit=17.375)', '\" As\"[1666] (p=0.015, logit=16.875)', '\" There\"[2684] (p=0.013, logit=16.750)', '\" Bed\"[13394] (p=0.011, logit=16.625)']\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.8984375, logit=21.0, token_id=41785, metadata=None))), (1666, (3, PredictedToken(token=' As', prob=0.0145263671875, logit=16.875, token_id=1666, metadata=None))), (13394, (5, PredictedToken(token=' Bed', prob=0.0113525390625, logit=16.625, token_id=13394, metadata=None))), (445, (15, PredictedToken(token=' L', prob=0.00067901611328125, logit=13.8125, token_id=445, metadata=None))), (26781, (114, PredictedToken(token=' Hair', prob=3.3855438232421875e-05, logit=10.8125, token_id=26781, metadata=None)))])\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     int_prediction=['\" Hair\"[26781] (p=0.586, logit=20.125)', '\" Bed\"[13394] (p=0.116, logit=18.500)', '\" The\"[578] (p=0.102, logit=18.375)', '\" As\"[1666] (p=0.055, logit=17.750)', '\" L\"[445] (p=0.048, logit=17.625)']\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     int_track=OrderedDict([(26781, (1, PredictedToken(token=' Hair', prob=0.5859375, logit=20.125, token_id=26781, metadata=None))), (13394, (2, PredictedToken(token=' Bed', prob=0.11572265625, logit=18.5, token_id=13394, metadata=None))), (1666, (4, PredictedToken(token=' As', prob=0.0546875, logit=17.75, token_id=1666, metadata=None))), (445, (5, PredictedToken(token=' L', prob=0.04833984375, logit=17.625, token_id=445, metadata=None))), (41785, (57, PredictedToken(token=' Spin', prob=0.000209808349609375, logit=12.1875, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:28 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     patch_prediction=['\" Re\"[1050] (p=0.715, logit=19.625)', '\" The\"[578] (p=0.181, logit=18.250)', '\" A\"[362] (p=0.036, logit=16.625)', '\" RE\"[3680] (p=0.009, logit=15.250)', '\" Onion\"[87035] (p=0.007, logit=14.938)']\n",
      "2025-09-15 09:38:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     clean_prediction=['\" Oak\"[18787] (p=0.641, logit=19.875)', '\" Maple\"[44570] (p=0.184, logit=18.625)', '\" There\"[2684] (p=0.046, logit=17.250)', '\" The\"[578] (p=0.046, logit=17.250)', '\" Elm\"[65329] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     clean_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.640625, logit=19.875, token_id=18787, metadata=None))), (44570, (2, PredictedToken(token=' Maple', prob=0.18359375, logit=18.625, token_id=44570, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.004302978515625, logit=14.875, token_id=6031, metadata=None))), (36358, (19, PredictedToken(token=' Bench', prob=0.0009613037109375, logit=13.375, token_id=36358, metadata=None))), (16478, (43, PredictedToken(token=' Chair', prob=0.00031280517578125, logit=12.25, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.160, logit=17.125)', '\" The\"[578] (p=0.142, logit=17.000)', '\" Bench\"[36358] (p=0.110, logit=16.750)', '\" Pine\"[42609] (p=0.110, logit=16.750)', '\" There\"[2684] (p=0.097, logit=16.625)']\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.16015625, logit=17.125, token_id=16478, metadata=None))), (36358, (3, PredictedToken(token=' Bench', prob=0.1103515625, logit=16.75, token_id=36358, metadata=None))), (6031, (6, PredictedToken(token=' Bro', prob=0.05908203125, logit=16.125, token_id=6031, metadata=None))), (18787, (9, PredictedToken(token=' Oak', prob=0.021728515625, logit=15.125, token_id=18787, metadata=None))), (44570, (14, PredictedToken(token=' Maple', prob=0.00848388671875, logit=14.1875, token_id=44570, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:29 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:29 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.746, logit=20.250)', '\" The\"[578] (p=0.130, logit=18.500)', '\" JE\"[71430] (p=0.048, logit=17.500)', '\" Scar\"[30760] (p=0.016, logit=16.375)', '\" A\"[362] (p=0.004, logit=14.938)']\n",
      "2025-09-15 09:38:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.828, logit=20.625)', '\" The\"[578] (p=0.068, logit=18.125)', '\" M\"[386] (p=0.022, logit=17.000)', '\" Apple\"[8325] (p=0.017, logit=16.750)', '\" There\"[2684] (p=0.017, logit=16.750)']\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.828125, logit=20.625, token_id=91963, metadata=None))), (8325, (5, PredictedToken(token=' Apple', prob=0.0172119140625, logit=16.75, token_id=8325, metadata=None))), (328, (6, PredictedToken(token=' S', prob=0.00408935546875, logit=15.3125, token_id=328, metadata=None))), (33711, (20, PredictedToken(token=' Suit', prob=0.000518798828125, logit=13.25, token_id=33711, metadata=None))), (61731, (39, PredictedToken(token=' Soap', prob=0.0002613067626953125, logit=12.5625, token_id=61731, metadata=None)))])\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.730, logit=19.875)', '\" The\"[578] (p=0.087, logit=17.750)', '\" Soap\"[61731] (p=0.032, logit=16.750)', '\" There\"[2684] (p=0.028, logit=16.625)', '\" S\"[328] (p=0.025, logit=16.500)']\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.73046875, logit=19.875, token_id=33711, metadata=None))), (61731, (3, PredictedToken(token=' Soap', prob=0.031982421875, logit=16.75, token_id=61731, metadata=None))), (328, (5, PredictedToken(token=' S', prob=0.02490234375, logit=16.5, token_id=328, metadata=None))), (8325, (7, PredictedToken(token=' Apple', prob=0.01177978515625, logit=15.75, token_id=8325, metadata=None))), (91963, (12, PredictedToken(token=' Mango', prob=0.0033721923828125, logit=14.5, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:30 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     patch_prediction=['\" Re\"[1050] (p=0.789, logit=20.750)', '\" The\"[578] (p=0.107, logit=18.750)', '\" A\"[362] (p=0.024, logit=17.250)', '\" RE\"[3680] (p=0.019, logit=17.000)', '\" Bench\"[36358] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:38:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     clean_prediction=['\" Train\"[27217] (p=0.412, logit=19.125)', '\" Sco\"[50159] (p=0.250, logit=18.625)', '\" The\"[578] (p=0.194, logit=18.375)', '\" A\"[362] (p=0.026, logit=16.375)', '\" There\"[2684] (p=0.023, logit=16.250)']\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     clean_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.412109375, logit=19.125, token_id=27217, metadata=None))), (50159, (2, PredictedToken(token=' Sco', prob=0.25, logit=18.625, token_id=50159, metadata=None))), (78703, (29, PredictedToken(token=' Potato', prob=0.000579833984375, logit=12.5625, token_id=78703, metadata=None))), (29318, (102, PredictedToken(token=' Dress', prob=8.392333984375e-05, logit=10.625, token_id=29318, metadata=None))), (70110, (239, PredictedToken(token=' Ottoman', prob=1.990795135498047e-05, logit=9.1875, token_id=70110, metadata=None)))])\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     int_prediction=['\" The\"[578] (p=0.268, logit=18.375)', '\" Ottoman\"[70110] (p=0.268, logit=18.375)', '\" Train\"[27217] (p=0.185, logit=18.000)', '\" Dress\"[29318] (p=0.032, logit=16.250)', '\" There\"[2684] (p=0.032, logit=16.250)']\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     int_track=OrderedDict([(70110, (2, PredictedToken(token=' Ottoman', prob=0.267578125, logit=18.375, token_id=70110, metadata=None))), (27217, (3, PredictedToken(token=' Train', prob=0.1845703125, logit=18.0, token_id=27217, metadata=None))), (50159, (6, PredictedToken(token=' Sco', prob=0.031982421875, logit=16.25, token_id=50159, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.031982421875, logit=16.25, token_id=29318, metadata=None))), (78703, (11, PredictedToken(token=' Potato', prob=0.006317138671875, logit=14.625, token_id=78703, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:31 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.354, logit=18.125)', '\" Elm\"[65329] (p=0.189, logit=17.500)', '\" The\"[578] (p=0.115, logit=17.000)', '\" Watch\"[10573] (p=0.089, logit=16.750)', '\" Ring\"[22249] (p=0.042, logit=16.000)']\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.945, logit=21.250)', '\" The\"[578] (p=0.013, logit=17.000)', '\" Router\"[10777] (p=0.007, logit=16.375)', '\" L\"[445] (p=0.004, logit=15.812)', '\" P\"[393] (p=0.004, logit=15.750)']\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.9453125, logit=21.25, token_id=81501, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.0072021484375, logit=16.375, token_id=10777, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.004119873046875, logit=15.8125, token_id=445, metadata=None))), (20918, (9, PredictedToken(token=' Magn', prob=0.0011749267578125, logit=14.5625, token_id=20918, metadata=None))), (42609, (12, PredictedToken(token=' Pine', prob=0.0009765625, logit=14.375, token_id=42609, metadata=None)))])\n",
      "2025-09-15 09:38:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:32 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.535, logit=18.750)', '\" Pendant\"[81501] (p=0.197, logit=17.750)', '\" Router\"[10777] (p=0.064, logit=16.625)', '\" The\"[578] (p=0.050, logit=16.375)', '\" P\"[393] (p=0.016, logit=15.250)']\n",
      "2025-09-15 09:38:32 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.53515625, logit=18.75, token_id=42609, metadata=None))), (81501, (2, PredictedToken(token=' Pendant', prob=0.197265625, logit=17.75, token_id=81501, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.06396484375, logit=16.625, token_id=10777, metadata=None))), (20918, (8, PredictedToken(token=' Magn', prob=0.0086669921875, logit=14.625, token_id=20918, metadata=None))), (445, (10, PredictedToken(token=' L', prob=0.005615234375, logit=14.1875, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:32 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:38:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:32 src.selection.optimization INFO     patch_prediction=['\" Shirt\"[55807] (p=0.727, logit=20.375)', '\" The\"[578] (p=0.126, logit=18.625)', '\" B\"[426] (p=0.032, logit=17.250)', '\" A\"[362] (p=0.022, logit=16.875)', '\" SH\"[6570] (p=0.015, logit=16.500)']\n",
      "2025-09-15 09:38:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.471, logit=18.875)', '\" Brace\"[70306] (p=0.223, logit=18.125)', '\" The\"[578] (p=0.063, logit=16.875)', '\" WATCH\"[48507] (p=0.050, logit=16.625)', '\" Scar\"[30760] (p=0.039, logit=16.375)']\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.470703125, logit=18.875, token_id=10573, metadata=None))), (70306, (2, PredictedToken(token=' Brace', prob=0.22265625, logit=18.125, token_id=70306, metadata=None))), (30760, (5, PredictedToken(token=' Scar', prob=0.03857421875, logit=16.375, token_id=30760, metadata=None))), (55870, (28, PredictedToken(token=' Jacket', prob=0.00124359130859375, logit=12.9375, token_id=55870, metadata=None)))])\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     int_prediction=['\" Jacket\"[55870] (p=0.316, logit=18.625)', '\" Scar\"[30760] (p=0.169, logit=18.000)', '\" Brace\"[70306] (p=0.132, logit=17.750)', '\" Watch\"[10573] (p=0.116, logit=17.625)', '\" The\"[578] (p=0.071, logit=17.125)']\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     int_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.31640625, logit=18.625, token_id=55870, metadata=None))), (30760, (2, PredictedToken(token=' Scar', prob=0.1689453125, logit=18.0, token_id=30760, metadata=None))), (70306, (3, PredictedToken(token=' Brace', prob=0.1318359375, logit=17.75, token_id=70306, metadata=None))), (10573, (4, PredictedToken(token=' Watch', prob=0.1162109375, logit=17.625, token_id=10573, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:33 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     patch_prediction=['\" Apartment\"[53889] (p=0.559, logit=18.000)', '\" Library\"[11896] (p=0.141, logit=16.625)', '\" The\"[578] (p=0.085, logit=16.125)', '\" Watch\"[10573] (p=0.046, logit=15.500)', '\" There\"[2684] (p=0.020, logit=14.688)']\n",
      "2025-09-15 09:38:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     clean_prediction=['\" Brace\"[70306] (p=0.707, logit=20.000)', '\" The\"[578] (p=0.139, logit=18.375)', '\" Bro\"[6031] (p=0.040, logit=17.125)', '\" A\"[362] (p=0.021, logit=16.500)', '\" BR\"[19333] (p=0.011, logit=15.875)']\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     clean_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.70703125, logit=20.0, token_id=70306, metadata=None))), (6031, (3, PredictedToken(token=' Bro', prob=0.039794921875, logit=17.125, token_id=6031, metadata=None))), (48390, (31, PredictedToken(token=' Lily', prob=0.0005340576171875, logit=12.8125, token_id=48390, metadata=None))), (6150, (234, PredictedToken(token=' School', prob=1.609325408935547e-05, logit=9.3125, token_id=6150, metadata=None))), (100031, (305, PredictedToken(token=' Mosque', prob=1.1086463928222656e-05, logit=8.9375, token_id=100031, metadata=None)))])\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     int_prediction=['\" Mosque\"[100031] (p=0.426, logit=19.250)', '\" School\"[6150] (p=0.377, logit=19.125)', '\" The\"[578] (p=0.095, logit=17.750)', '\" SCHOOL\"[71501] (p=0.016, logit=15.938)', '\" A\"[362] (p=0.007, logit=15.125)']\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     int_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.42578125, logit=19.25, token_id=100031, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.376953125, logit=19.125, token_id=6150, metadata=None))), (6031, (16, PredictedToken(token=' Bro', prob=0.001739501953125, logit=13.75, token_id=6031, metadata=None))), (48390, (17, PredictedToken(token=' Lily', prob=0.001739501953125, logit=13.75, token_id=48390, metadata=None))), (70306, (70, PredictedToken(token=' Brace', prob=0.0001621246337890625, logit=11.375, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:34 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:34 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     patch_prediction=['\" Laptop\"[57225] (p=0.801, logit=20.500)', '\" The\"[578] (p=0.075, logit=18.125)', '\" Television\"[41445] (p=0.040, logit=17.500)', '\" E\"[469] (p=0.011, logit=16.250)', '\" LAP\"[72428] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:38:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     clean_prediction=['\" Surf\"[65197] (p=0.633, logit=19.375)', '\" The\"[578] (p=0.125, logit=17.750)', '\" R\"[432] (p=0.059, logit=17.000)', '\" SUR\"[53083] (p=0.036, logit=16.500)', '\" A\"[362] (p=0.020, logit=15.938)']\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     clean_track=OrderedDict([(65197, (1, PredictedToken(token=' Surf', prob=0.6328125, logit=19.375, token_id=65197, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.05908203125, logit=17.0, token_id=432, metadata=None))), (29625, (6, PredictedToken(token=' Chain', prob=0.0191650390625, logit=15.875, token_id=29625, metadata=None))), (55405, (21, PredictedToken(token=' Orch', prob=0.002288818359375, logit=13.75, token_id=55405, metadata=None))), (5907, (29, PredictedToken(token=' Project', prob=0.000843048095703125, logit=12.75, token_id=5907, metadata=None))), (2057, (39, PredictedToken(token=' To', prob=0.000545501708984375, logit=12.3125, token_id=2057, metadata=None))), (18654, (74, PredictedToken(token=' Micro', prob=0.00015544891357421875, logit=11.0625, token_id=18654, metadata=None)))])\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     int_prediction=['\" Project\"[5907] (p=0.488, logit=19.250)', '\" Micro\"[18654] (p=0.180, logit=18.250)', '\" Chain\"[29625] (p=0.158, logit=18.125)', '\" The\"[578] (p=0.058, logit=17.125)', '\" None\"[2290] (p=0.015, logit=15.750)']\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     int_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.48828125, logit=19.25, token_id=5907, metadata=None))), (18654, (2, PredictedToken(token=' Micro', prob=0.1796875, logit=18.25, token_id=18654, metadata=None))), (29625, (3, PredictedToken(token=' Chain', prob=0.158203125, logit=18.125, token_id=29625, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.01300048828125, logit=15.625, token_id=432, metadata=None))), (2057, (27, PredictedToken(token=' To', prob=0.00064849853515625, logit=12.625, token_id=2057, metadata=None))), (65197, (64, PredictedToken(token=' Surf', prob=0.00021076202392578125, logit=11.5, token_id=65197, metadata=None))), (55405, (1221, PredictedToken(token=' Orch', prob=1.9371509552001953e-06, logit=6.8125, token_id=55405, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:35 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:38:35 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     patch_prediction=['\" P\"[393] (p=0.467, logit=19.750)', '\" Highlight\"[57094] (p=0.283, logit=19.250)', '\" The\"[578] (p=0.134, logit=18.500)', '\" A\"[362] (p=0.030, logit=17.000)', '\" There\"[2684] (p=0.014, logit=16.250)']\n",
      "2025-09-15 09:38:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     clean_prediction=['\" Sh\"[1443] (p=0.699, logit=20.250)', '\" Hair\"[26781] (p=0.083, logit=18.125)', '\" The\"[578] (p=0.065, logit=17.875)', '\" S\"[328] (p=0.045, logit=17.500)', '\" SH\"[6570] (p=0.019, logit=16.625)']\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     clean_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.69921875, logit=20.25, token_id=1443, metadata=None))), (26781, (2, PredictedToken(token=' Hair', prob=0.08349609375, logit=18.125, token_id=26781, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.044677734375, logit=17.5, token_id=328, metadata=None))), (18343, (7, PredictedToken(token=' Paper', prob=0.007781982421875, logit=15.75, token_id=18343, metadata=None))), (36943, (12, PredictedToken(token=' Folder', prob=0.0028533935546875, logit=14.75, token_id=36943, metadata=None))), (97796, (205, PredictedToken(token=' Skate', prob=1.704692840576172e-05, logit=9.625, token_id=97796, metadata=None)))])\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.676, logit=20.750)', '\" Sh\"[1443] (p=0.081, logit=18.625)', '\" Folder\"[36943] (p=0.071, logit=18.500)', '\" The\"[578] (p=0.049, logit=18.125)', '\" A\"[362] (p=0.049, logit=18.125)']\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.67578125, logit=20.75, token_id=18343, metadata=None))), (1443, (2, PredictedToken(token=' Sh', prob=0.08056640625, logit=18.625, token_id=1443, metadata=None))), (36943, (3, PredictedToken(token=' Folder', prob=0.0712890625, logit=18.5, token_id=36943, metadata=None))), (328, (6, PredictedToken(token=' S', prob=0.026123046875, logit=17.5, token_id=328, metadata=None))), (26781, (8, PredictedToken(token=' Hair', prob=0.00750732421875, logit=16.25, token_id=26781, metadata=None))), (97796, (107, PredictedToken(token=' Skate', prob=3.933906555175781e-05, logit=11.0, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:36 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:38:36 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.797, logit=20.625)', '\" The\"[578] (p=0.139, logit=18.875)', '\" Lav\"[43950] (p=0.009, logit=16.125)', '\" There\"[2684] (p=0.009, logit=16.125)', '\" C\"[356] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:38:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     clean_prediction=['\" Sax\"[68027] (p=0.719, logit=20.500)', '\" The\"[578] (p=0.206, logit=19.250)', '\" There\"[2684] (p=0.017, logit=16.750)', '\" Viol\"[30555] (p=0.007, logit=15.812)', '\" It\"[1102] (p=0.007, logit=15.812)']\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     clean_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.71875, logit=20.5, token_id=68027, metadata=None))), (30555, (5, PredictedToken(token=' Viol', prob=0.006622314453125, logit=15.8125, token_id=30555, metadata=None))), (1901, (32, PredictedToken(token=' Z', prob=0.00024127960205078125, logit=12.5, token_id=1901, metadata=None))), (55405, (53, PredictedToken(token=' Orch', prob=0.00012874603271484375, logit=11.875, token_id=55405, metadata=None))), (39247, (61, PredictedToken(token=' Slow', prob=0.00011396408081054688, logit=11.75, token_id=39247, metadata=None))), (48390, (179, PredictedToken(token=' Lily', prob=1.8596649169921875e-05, logit=9.9375, token_id=48390, metadata=None)))])\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     int_prediction=['\" Lily\"[48390] (p=0.426, logit=19.000)', '\" Viol\"[30555] (p=0.201, logit=18.250)', '\" The\"[578] (p=0.138, logit=17.875)', '\" Orch\"[55405] (p=0.107, logit=17.625)', '\" There\"[2684] (p=0.019, logit=15.875)']\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     int_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.42578125, logit=19.0, token_id=48390, metadata=None))), (30555, (2, PredictedToken(token=' Viol', prob=0.201171875, logit=18.25, token_id=30555, metadata=None))), (55405, (4, PredictedToken(token=' Orch', prob=0.107421875, logit=17.625, token_id=55405, metadata=None))), (1901, (41, PredictedToken(token=' Z', prob=0.0004119873046875, logit=12.0625, token_id=1901, metadata=None))), (39247, (139, PredictedToken(token=' Slow', prob=6.341934204101562e-05, logit=10.1875, token_id=39247, metadata=None))), (68027, (164, PredictedToken(token=' Sax', prob=4.6253204345703125e-05, logit=9.875, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:37 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:37 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.746, logit=21.500)', '\" The\"[578] (p=0.146, logit=19.875)', '\" Viol\"[30555] (p=0.048, logit=18.750)', '\" P\"[393] (p=0.022, logit=18.000)', '\" There\"[2684] (p=0.006, logit=16.750)']\n",
      "2025-09-15 09:38:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.914, logit=20.750)', '\" As\"[1666] (p=0.021, logit=17.000)', '\" The\"[578] (p=0.021, logit=17.000)', '\" There\"[2684] (p=0.006, logit=15.688)', '\" SP\"[9440] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.9140625, logit=20.75, token_id=41785, metadata=None))), (1666, (3, PredictedToken(token=' As', prob=0.021484375, logit=17.0, token_id=1666, metadata=None))), (29318, (11, PredictedToken(token=' Dress', prob=0.000888824462890625, logit=13.8125, token_id=29318, metadata=None))), (5340, (15, PredictedToken(token=' Har', prob=0.000736236572265625, logit=13.625, token_id=5340, metadata=None))), (68027, (222, PredictedToken(token=' Sax', prob=1.1920928955078125e-05, logit=9.5, token_id=68027, metadata=None)))])\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.867, logit=21.375)', '\" The\"[578] (p=0.071, logit=18.875)', '\" Sax\"[68027] (p=0.010, logit=16.875)', '\" HAR\"[87588] (p=0.010, logit=16.875)', '\" H\"[473] (p=0.007, logit=16.500)']\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.8671875, logit=21.375, token_id=5340, metadata=None))), (68027, (3, PredictedToken(token=' Sax', prob=0.0096435546875, logit=16.875, token_id=68027, metadata=None))), (1666, (6, PredictedToken(token=' As', prob=0.005157470703125, logit=16.25, token_id=1666, metadata=None))), (29318, (28, PredictedToken(token=' Dress', prob=0.0002269744873046875, logit=13.125, token_id=29318, metadata=None))), (41785, (97, PredictedToken(token=' Spin', prob=2.396106719970703e-05, logit=10.875, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:38 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.605, logit=19.625)', '\" Laptop\"[57225] (p=0.287, logit=18.875)', '\" The\"[578] (p=0.030, logit=16.625)', '\" MON\"[29637] (p=0.011, logit=15.625)', '\" monitor\"[8891] (p=0.006, logit=15.062)']\n",
      "2025-09-15 09:38:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     clean_prediction=['\" Amb\"[20423] (p=0.500, logit=18.375)', '\" An\"[1556] (p=0.099, logit=16.750)', '\" Mouse\"[18191] (p=0.087, logit=16.625)', '\" Air\"[6690] (p=0.077, logit=16.500)', '\" The\"[578] (p=0.077, logit=16.500)']\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     clean_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.5, logit=18.375, token_id=20423, metadata=None))), (18191, (3, PredictedToken(token=' Mouse', prob=0.0869140625, logit=16.625, token_id=18191, metadata=None))), (6690, (5, PredictedToken(token=' Air', prob=0.07666015625, logit=16.5, token_id=6690, metadata=None))), (30173, (8, PredictedToken(token=' Speaker', prob=0.0103759765625, logit=14.5, token_id=30173, metadata=None)))])\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.551, logit=19.375)', '\" Mouse\"[18191] (p=0.179, logit=18.250)', '\" The\"[578] (p=0.065, logit=17.250)', '\" An\"[1556] (p=0.031, logit=16.500)', '\" A\"[362] (p=0.021, logit=16.125)']\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.55078125, logit=19.375, token_id=30173, metadata=None))), (18191, (2, PredictedToken(token=' Mouse', prob=0.1787109375, logit=18.25, token_id=18191, metadata=None))), (6690, (6, PredictedToken(token=' Air', prob=0.018798828125, logit=16.0, token_id=6690, metadata=None))), (20423, (10, PredictedToken(token=' Amb', prob=0.01007080078125, logit=15.375, token_id=20423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:39 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:39 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.863, logit=19.875)', '\" C\"[356] (p=0.033, logit=16.625)', '\" The\"[578] (p=0.023, logit=16.250)', '\" There\"[2684] (p=0.018, logit=16.000)', '\" None\"[2290] (p=0.008, logit=15.188)']\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.559, logit=18.375)', '\" The\"[578] (p=0.160, logit=17.125)', '\" Bro\"[6031] (p=0.036, logit=15.625)', '\" A\"[362] (p=0.031, logit=15.500)', '\" ST\"[4015] (p=0.030, logit=15.438)']\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.55859375, logit=18.375, token_id=23462, metadata=None))), (6031, (3, PredictedToken(token=' Bro', prob=0.03564453125, logit=15.625, token_id=6031, metadata=None))), (94091, (6, PredictedToken(token=' Tomato', prob=0.026123046875, logit=15.3125, token_id=94091, metadata=None))), (52466, (7, PredictedToken(token=' Warehouse', prob=0.0230712890625, logit=15.1875, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:38:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.508, logit=18.125)', '\" Warehouse\"[52466] (p=0.113, logit=16.625)', '\" Stadium\"[23462] (p=0.088, logit=16.375)', '\" Tomato\"[94091] (p=0.069, logit=16.125)', '\" The\"[578] (p=0.061, logit=16.000)']\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.5078125, logit=18.125, token_id=6031, metadata=None))), (52466, (2, PredictedToken(token=' Warehouse', prob=0.11328125, logit=16.625, token_id=52466, metadata=None))), (23462, (3, PredictedToken(token=' Stadium', prob=0.08837890625, logit=16.375, token_id=23462, metadata=None))), (94091, (4, PredictedToken(token=' Tomato', prob=0.06884765625, logit=16.125, token_id=94091, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:40 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.879, logit=21.250)', '\" The\"[578] (p=0.072, logit=18.750)', '\" There\"[2684] (p=0.007, logit=16.375)', '\" K\"[735] (p=0.006, logit=16.250)', '\" Grape\"[80629] (p=0.004, logit=15.812)']\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.879, logit=21.750)', '\" The\"[578] (p=0.063, logit=19.125)', '\" Amb\"[20423] (p=0.023, logit=18.125)', '\" There\"[2684] (p=0.007, logit=16.875)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.87890625, logit=21.75, token_id=70762, metadata=None))), (20423, (3, PredictedToken(token=' Amb', prob=0.0234375, logit=18.125, token_id=20423, metadata=None))), (16488, (21, PredictedToken(token=' Bat', prob=0.0002288818359375, logit=13.5, token_id=16488, metadata=None))), (89077, (45, PredictedToken(token=' Strawberry', prob=8.440017700195312e-05, logit=12.5, token_id=89077, metadata=None))), (76924, (178, PredictedToken(token=' Banana', prob=8.344650268554688e-06, logit=10.1875, token_id=76924, metadata=None)))])\n",
      "2025-09-15 09:38:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     int_prediction=['\" Banana\"[76924] (p=0.598, logit=20.375)', '\" Motorcycle\"[70762] (p=0.220, logit=19.375)', '\" The\"[578] (p=0.063, logit=18.125)', '\" Strawberry\"[89077] (p=0.030, logit=17.375)', '\" A\"[362] (p=0.014, logit=16.625)']\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     int_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.59765625, logit=20.375, token_id=76924, metadata=None))), (70762, (2, PredictedToken(token=' Motorcycle', prob=0.2197265625, logit=19.375, token_id=70762, metadata=None))), (89077, (4, PredictedToken(token=' Strawberry', prob=0.02978515625, logit=17.375, token_id=89077, metadata=None))), (20423, (8, PredictedToken(token=' Amb', prob=0.008544921875, logit=16.125, token_id=20423, metadata=None))), (16488, (14, PredictedToken(token=' Bat', prob=0.0021514892578125, logit=14.75, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:38:41 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.668, logit=20.000)', '\" Sh\"[1443] (p=0.191, logit=18.750)', '\" The\"[578] (p=0.043, logit=17.250)', '\" SH\"[6570] (p=0.020, logit=16.500)', '\" LOT\"[54460] (p=0.008, logit=15.562)']\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.898, logit=21.500)', '\" The\"[578] (p=0.051, logit=18.625)', '\" Ch\"[921] (p=0.019, logit=17.625)', '\" There\"[2684] (p=0.004, logit=16.125)', '\" V\"[650] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.8984375, logit=21.5, token_id=74574, metadata=None))), (921, (3, PredictedToken(token=' Ch', prob=0.0186767578125, logit=17.625, token_id=921, metadata=None))), (82994, (35, PredictedToken(token=' Toilet', prob=0.000133514404296875, logit=12.6875, token_id=82994, metadata=None))), (48471, (36, PredictedToken(token=' Shower', prob=0.000125885009765625, logit=12.625, token_id=48471, metadata=None))), (40759, (62, PredictedToken(token=' Harmon', prob=5.936622619628906e-05, logit=11.875, token_id=40759, metadata=None))), (23462, (632, PredictedToken(token=' Stadium', prob=1.1622905731201172e-06, logit=7.9375, token_id=23462, metadata=None)))])\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.660, logit=18.875)', '\" The\"[578] (p=0.115, logit=17.125)', '\" Violet\"[74574] (p=0.048, logit=16.250)', '\" Shower\"[48471] (p=0.027, logit=15.688)', '\" TO\"[5257] (p=0.019, logit=15.312)']\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.66015625, logit=18.875, token_id=82994, metadata=None))), (74574, (3, PredictedToken(token=' Violet', prob=0.0478515625, logit=16.25, token_id=74574, metadata=None))), (48471, (4, PredictedToken(token=' Shower', prob=0.02734375, logit=15.6875, token_id=48471, metadata=None))), (40759, (13, PredictedToken(token=' Harmon', prob=0.0034637451171875, logit=13.625, token_id=40759, metadata=None))), (921, (14, PredictedToken(token=' Ch', prob=0.003265380859375, logit=13.5625, token_id=921, metadata=None))), (23462, (220, PredictedToken(token=' Stadium', prob=3.8623809814453125e-05, logit=9.125, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:41 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:38:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.645, logit=19.875)', '\" Brace\"[70306] (p=0.163, logit=18.500)', '\" The\"[578] (p=0.077, logit=17.750)', '\" A\"[362] (p=0.028, logit=16.750)', '\" Stap\"[63606] (p=0.007, logit=15.375)']\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.668, logit=20.750)', '\" Pen\"[13597] (p=0.169, logit=19.375)', '\" The\"[578] (p=0.055, logit=18.250)', '\" A\"[362] (p=0.038, logit=17.875)', '\" C\"[356] (p=0.012, logit=16.750)']\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.66796875, logit=20.75, token_id=18343, metadata=None))), (13597, (2, PredictedToken(token=' Pen', prob=0.1689453125, logit=19.375, token_id=13597, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.01226806640625, logit=16.75, token_id=356, metadata=None))), (426, (8, PredictedToken(token=' B', prob=0.00579833984375, logit=16.0, token_id=426, metadata=None))), (57915, (162, PredictedToken(token=' Ank', prob=1.728534698486328e-05, logit=10.1875, token_id=57915, metadata=None)))])\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.852, logit=21.250)', '\" The\"[578] (p=0.042, logit=18.250)', '\" Ank\"[57915] (p=0.023, logit=17.625)', '\" A\"[362] (p=0.023, logit=17.625)', '\" C\"[356] (p=0.020, logit=17.500)']\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.8515625, logit=21.25, token_id=426, metadata=None))), (57915, (4, PredictedToken(token=' Ank', prob=0.022705078125, logit=17.625, token_id=57915, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.02001953125, logit=17.5, token_id=356, metadata=None))), (13597, (10, PredictedToken(token=' Pen', prob=0.0025482177734375, logit=15.4375, token_id=13597, metadata=None))), (18343, (87, PredictedToken(token=' Paper', prob=3.647804260253906e-05, logit=11.1875, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:42 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:38:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.805, logit=20.500)', '\" The\"[578] (p=0.058, logit=17.875)', '\" A\"[362] (p=0.051, logit=17.750)', '\" Calculator\"[37128] (p=0.040, logit=17.500)', '\" None\"[2290] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.734, logit=19.500)', '\" The\"[578] (p=0.099, logit=17.500)', '\" A\"[362] (p=0.042, logit=16.625)', '\" Jacket\"[55870] (p=0.025, logit=16.125)', '\" R\"[432] (p=0.014, logit=15.562)']\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.734375, logit=19.5, token_id=33711, metadata=None))), (55870, (4, PredictedToken(token=' Jacket', prob=0.025146484375, logit=16.125, token_id=55870, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.0142822265625, logit=15.5625, token_id=432, metadata=None))), (393, (6, PredictedToken(token=' P', prob=0.0111083984375, logit=15.3125, token_id=393, metadata=None)))])\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.574, logit=19.625)', '\" R\"[432] (p=0.271, logit=18.875)', '\" Jacket\"[55870] (p=0.047, logit=17.125)', '\" The\"[578] (p=0.037, logit=16.875)', '\" A\"[362] (p=0.013, logit=15.812)']\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.57421875, logit=19.625, token_id=393, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.271484375, logit=18.875, token_id=432, metadata=None))), (55870, (3, PredictedToken(token=' Jacket', prob=0.047119140625, logit=17.125, token_id=55870, metadata=None))), (33711, (6, PredictedToken(token=' Suit', prob=0.007232666015625, logit=15.25, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:43 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-15 09:38:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.789, logit=19.375)', '\" E\"[469] (p=0.057, logit=16.750)', '\" The\"[578] (p=0.051, logit=16.625)', '\" There\"[2684] (p=0.020, logit=15.688)', '\" None\"[2290] (p=0.013, logit=15.250)']\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     clean_prediction=['\" Lav\"[43950] (p=0.734, logit=19.625)', '\" The\"[578] (p=0.113, logit=17.750)', '\" Orch\"[55405] (p=0.060, logit=17.125)', '\" L\"[445] (p=0.017, logit=15.875)', '\" There\"[2684] (p=0.006, logit=14.750)']\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     clean_track=OrderedDict([(43950, (1, PredictedToken(token=' Lav', prob=0.734375, logit=19.625, token_id=43950, metadata=None))), (55405, (3, PredictedToken(token=' Orch', prob=0.060302734375, logit=17.125, token_id=55405, metadata=None))), (65449, (32, PredictedToken(token=' Willow', prob=0.000591278076171875, logit=12.5, token_id=65449, metadata=None))), (98028, (52, PredictedToken(token=' Bamboo', prob=0.000278472900390625, logit=11.75, token_id=98028, metadata=None))), (39794, (4023, PredictedToken(token=' Desk', prob=3.948807716369629e-07, logit=5.1875, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     int_prediction=['\" Lav\"[43950] (p=0.488, logit=18.375)', '\" The\"[578] (p=0.141, logit=17.125)', '\" Willow\"[65449] (p=0.096, logit=16.750)', '\" Orch\"[55405] (p=0.085, logit=16.625)', '\" There\"[2684] (p=0.021, logit=15.250)']\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     int_track=OrderedDict([(43950, (1, PredictedToken(token=' Lav', prob=0.48828125, logit=18.375, token_id=43950, metadata=None))), (65449, (3, PredictedToken(token=' Willow', prob=0.09619140625, logit=16.75, token_id=65449, metadata=None))), (55405, (4, PredictedToken(token=' Orch', prob=0.0849609375, logit=16.625, token_id=55405, metadata=None))), (98028, (8, PredictedToken(token=' Bamboo', prob=0.0101318359375, logit=14.5, token_id=98028, metadata=None))), (39794, (42, PredictedToken(token=' Desk', prob=0.000782012939453125, logit=11.9375, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:44 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:44 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     patch_prediction=['\" Fl\"[3061] (p=0.691, logit=19.875)', '\" The\"[578] (p=0.175, logit=18.500)', '\" FL\"[13062] (p=0.027, logit=16.625)', '\" R\"[432] (p=0.018, logit=16.250)', '\" Har\"[5340] (p=0.016, logit=16.125)']\n",
      "2025-09-15 09:38:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     clean_prediction=['\" Microwave\"[98641] (p=0.559, logit=19.875)', '\" Pressure\"[40090] (p=0.264, logit=19.125)', '\" The\"[578] (p=0.076, logit=17.875)', '\" A\"[362] (p=0.022, logit=16.625)', '\" Harmon\"[40759] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     clean_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.55859375, logit=19.875, token_id=98641, metadata=None))), (40090, (2, PredictedToken(token=' Pressure', prob=0.263671875, logit=19.125, token_id=40090, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.01019287109375, logit=15.875, token_id=40759, metadata=None))), (63606, (7, PredictedToken(token=' Stap', prob=0.005828857421875, logit=15.3125, token_id=63606, metadata=None))), (1630, (10, PredictedToken(token=' X', prob=0.0022735595703125, logit=14.375, token_id=1630, metadata=None))), (445, (16, PredictedToken(token=' L', prob=0.00138092041015625, logit=13.875, token_id=445, metadata=None))), (38571, (78, PredictedToken(token=' Theater', prob=0.0001068115234375, logit=11.3125, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.777, logit=19.875)', '\" The\"[578] (p=0.082, logit=17.625)', '\" X\"[1630] (p=0.039, logit=16.875)', '\" A\"[362] (p=0.018, logit=16.125)', '\" Theater\"[38571] (p=0.014, logit=15.875)']\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.77734375, logit=19.875, token_id=40759, metadata=None))), (1630, (3, PredictedToken(token=' X', prob=0.038818359375, logit=16.875, token_id=1630, metadata=None))), (38571, (5, PredictedToken(token=' Theater', prob=0.0142822265625, logit=15.875, token_id=38571, metadata=None))), (63606, (6, PredictedToken(token=' Stap', prob=0.0052490234375, logit=14.875, token_id=63606, metadata=None))), (40090, (7, PredictedToken(token=' Pressure', prob=0.00494384765625, logit=14.8125, token_id=40090, metadata=None))), (445, (10, PredictedToken(token=' L', prob=0.0024871826171875, logit=14.125, token_id=445, metadata=None))), (98641, (16, PredictedToken(token=' Microwave', prob=0.00150299072265625, logit=13.625, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:45 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.445, logit=17.000)', '\" Factory\"[17367] (p=0.128, logit=15.750)', '\" Tr\"[1183] (p=0.113, logit=15.625)', '\" Van\"[13000] (p=0.083, logit=15.312)', '\" The\"[578] (p=0.083, logit=15.312)']\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.789, logit=20.375)', '\" The\"[578] (p=0.083, logit=18.125)', '\" An\"[1556] (p=0.035, logit=17.250)', '\" Truck\"[34785] (p=0.019, logit=16.625)', '\" Sk\"[4923] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.7890625, logit=20.375, token_id=6690, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.0185546875, logit=16.625, token_id=34785, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.01275634765625, logit=16.25, token_id=4923, metadata=None))), (23462, (47, PredictedToken(token=' Stadium', prob=0.0002193450927734375, logit=12.1875, token_id=23462, metadata=None)))])\n",
      "2025-09-15 09:38:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.426, logit=18.500)', '\" The\"[578] (p=0.201, logit=17.750)', '\" Air\"[6690] (p=0.065, logit=16.625)', '\" Sk\"[4923] (p=0.065, logit=16.625)', '\" An\"[1556] (p=0.035, logit=16.000)']\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.42578125, logit=18.5, token_id=23462, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.0654296875, logit=16.625, token_id=4923, metadata=None))), (6690, (4, PredictedToken(token=' Air', prob=0.0654296875, logit=16.625, token_id=6690, metadata=None))), (34785, (6, PredictedToken(token=' Truck', prob=0.0272216796875, logit=15.75, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:46 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     patch_prediction=['\" Folder\"[36943] (p=0.523, logit=19.500)', '\" Binder\"[91263] (p=0.279, logit=18.875)', '\" A\"[362] (p=0.038, logit=16.875)', '\" The\"[578] (p=0.033, logit=16.750)', '\" F\"[435] (p=0.026, logit=16.500)']\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     clean_prediction=['\" Sco\"[50159] (p=0.559, logit=19.125)', '\" Van\"[13000] (p=0.205, logit=18.125)', '\" The\"[578] (p=0.097, logit=17.375)', '\" A\"[362] (p=0.028, logit=16.125)', '\" VAN\"[97753] (p=0.023, logit=15.938)']\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     clean_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.55859375, logit=19.125, token_id=50159, metadata=None))), (13000, (2, PredictedToken(token=' Van', prob=0.205078125, logit=18.125, token_id=13000, metadata=None))), (18343, (15, PredictedToken(token=' Paper', prob=0.00201416015625, logit=13.5, token_id=18343, metadata=None))), (57094, (20, PredictedToken(token=' Highlight', prob=0.001220703125, logit=13.0, token_id=57094, metadata=None))), (34046, (22, PredictedToken(token=' Cabinet', prob=0.000949859619140625, logit=12.75, token_id=34046, metadata=None)))])\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.449, logit=19.125)', '\" Highlight\"[57094] (p=0.271, logit=18.625)', '\" Paper\"[18343] (p=0.129, logit=17.875)', '\" The\"[578] (p=0.037, logit=16.625)', '\" A\"[362] (p=0.016, logit=15.812)']\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.44921875, logit=19.125, token_id=13000, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.271484375, logit=18.625, token_id=57094, metadata=None))), (18343, (3, PredictedToken(token=' Paper', prob=0.12890625, logit=17.875, token_id=18343, metadata=None))), (50159, (9, PredictedToken(token=' Sco', prob=0.00640869140625, logit=14.875, token_id=50159, metadata=None))), (34046, (64, PredictedToken(token=' Cabinet', prob=0.00016021728515625, logit=11.1875, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:46 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:38:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     patch_prediction=['\" Oak\"[18787] (p=0.361, logit=18.500)', '\" Van\"[13000] (p=0.361, logit=18.500)', '\" Maple\"[44570] (p=0.055, logit=16.625)', '\" Sun\"[8219] (p=0.043, logit=16.375)', '\" The\"[578] (p=0.043, logit=16.375)']\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.680, logit=19.500)', '\" The\"[578] (p=0.104, logit=17.625)', '\" Lily\"[48390] (p=0.081, logit=17.375)', '\" DA\"[25561] (p=0.018, logit=15.875)', '\" There\"[2684] (p=0.016, logit=15.750)']\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.6796875, logit=19.5, token_id=71264, metadata=None))), (48390, (3, PredictedToken(token=' Lily', prob=0.0810546875, logit=17.375, token_id=48390, metadata=None))), (79028, (7, PredictedToken(token=' Hick', prob=0.0096435546875, logit=15.25, token_id=79028, metadata=None))), (816, (27, PredictedToken(token=' Y', prob=0.00079345703125, logit=12.75, token_id=816, metadata=None))), (98028, (34, PredictedToken(token=' Bamboo', prob=0.00061798095703125, logit=12.5, token_id=98028, metadata=None)))])\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.805, logit=19.750)', '\" Bamboo\"[98028] (p=0.058, logit=17.125)', '\" The\"[578] (p=0.045, logit=16.875)', '\" H\"[473] (p=0.016, logit=15.812)', '\" There\"[2684] (p=0.014, logit=15.688)']\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.8046875, logit=19.75, token_id=79028, metadata=None))), (98028, (2, PredictedToken(token=' Bamboo', prob=0.05810546875, logit=17.125, token_id=98028, metadata=None))), (816, (7, PredictedToken(token=' Y', prob=0.005767822265625, logit=14.8125, token_id=816, metadata=None))), (48390, (8, PredictedToken(token=' Lily', prob=0.0034942626953125, logit=14.3125, token_id=48390, metadata=None))), (71264, (20, PredictedToken(token=' Daisy', prob=0.0006866455078125, logit=12.6875, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:47 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     patch_prediction=['\" Boat\"[45332] (p=0.789, logit=21.125)', '\" The\"[578] (p=0.107, logit=19.125)', '\" Car\"[3341] (p=0.024, logit=17.625)', '\" A\"[362] (p=0.019, logit=17.375)', '\" BO\"[7967] (p=0.016, logit=17.250)']\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.602, logit=20.125)', '\" Folder\"[36943] (p=0.222, logit=19.125)', '\" The\"[578] (p=0.050, logit=17.625)', '\" F\"[435] (p=0.044, logit=17.500)', '\" A\"[362] (p=0.018, logit=16.625)']\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.6015625, logit=20.125, token_id=432, metadata=None))), (36943, (2, PredictedToken(token=' Folder', prob=0.2216796875, logit=19.125, token_id=36943, metadata=None))), (6690, (11, PredictedToken(token=' Air', prob=0.001800537109375, logit=14.3125, token_id=6690, metadata=None))), (50159, (27, PredictedToken(token=' Sco', prob=0.000514984130859375, logit=13.0625, token_id=50159, metadata=None))), (1901, (29, PredictedToken(token=' Z', prob=0.00042724609375, logit=12.875, token_id=1901, metadata=None)))])\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.922, logit=21.000)', '\" The\"[578] (p=0.017, logit=17.000)', '\" AIR\"[46994] (p=0.009, logit=16.375)', '\" None\"[2290] (p=0.009, logit=16.375)', '\" An\"[1556] (p=0.005, logit=15.688)']\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.921875, logit=21.0, token_id=6690, metadata=None))), (432, (7, PredictedToken(token=' R', prob=0.0035400390625, logit=15.4375, token_id=432, metadata=None))), (1901, (8, PredictedToken(token=' Z', prob=0.002593994140625, logit=15.125, token_id=1901, metadata=None))), (50159, (11, PredictedToken(token=' Sco', prob=0.0015716552734375, logit=14.625, token_id=50159, metadata=None))), (36943, (25, PredictedToken(token=' Folder', prob=0.0002899169921875, logit=12.9375, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:48 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.436, logit=18.875)', '\" Calculator\"[37128] (p=0.299, logit=18.500)', '\" Hick\"[79028] (p=0.085, logit=17.250)', '\" The\"[578] (p=0.059, logit=16.875)', '\" A\"[362] (p=0.019, logit=15.750)']\n",
      "2025-09-15 09:38:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.746, logit=18.875)', '\" The\"[578] (p=0.061, logit=16.375)', '\" Printer\"[47033] (p=0.035, logit=15.812)', '\" Monitor\"[24423] (p=0.026, logit=15.500)', '\" P\"[393] (p=0.016, logit=15.062)']\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.74609375, logit=18.875, token_id=18343, metadata=None))), (47033, (3, PredictedToken(token=' Printer', prob=0.034912109375, logit=15.8125, token_id=47033, metadata=None))), (24423, (4, PredictedToken(token=' Monitor', prob=0.0255126953125, logit=15.5, token_id=24423, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.0164794921875, logit=15.0625, token_id=469, metadata=None))), (9939, (7, PredictedToken(token=' Er', prob=0.0164794921875, logit=15.0625, token_id=9939, metadata=None)))])\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.508, logit=19.125)', '\" Monitor\"[24423] (p=0.239, logit=18.375)', '\" Printer\"[47033] (p=0.100, logit=17.500)', '\" The\"[578] (p=0.047, logit=16.750)', '\" Er\"[9939] (p=0.020, logit=15.875)']\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.5078125, logit=19.125, token_id=18343, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.2392578125, logit=18.375, token_id=24423, metadata=None))), (47033, (3, PredictedToken(token=' Printer', prob=0.10009765625, logit=17.5, token_id=47033, metadata=None))), (9939, (5, PredictedToken(token=' Er', prob=0.0196533203125, logit=15.875, token_id=9939, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.0126953125, logit=15.4375, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:49 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:49 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.848, logit=20.375)', '\" A\"[362] (p=0.037, logit=17.250)', '\" R\"[432] (p=0.029, logit=17.000)', '\" The\"[578] (p=0.026, logit=16.875)', '\" S\"[328] (p=0.007, logit=15.625)']\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.711, logit=19.000)', '\" The\"[578] (p=0.096, logit=17.000)', '\" A\"[362] (p=0.040, logit=16.125)', '\" Gloves\"[68554] (p=0.031, logit=15.875)', '\" SU\"[15857] (p=0.015, logit=15.125)']\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.7109375, logit=19.0, token_id=33711, metadata=None))), (68554, (4, PredictedToken(token=' Gloves', prob=0.03125, logit=15.875, token_id=68554, metadata=None))), (58600, (7, PredictedToken(token=' Charm', prob=0.0084228515625, logit=14.5625, token_id=58600, metadata=None))), (36943, (27, PredictedToken(token=' Folder', prob=0.000942230224609375, logit=12.375, token_id=36943, metadata=None))), (57094, (35, PredictedToken(token=' Highlight', prob=0.0006103515625, logit=11.9375, token_id=57094, metadata=None)))])\n",
      "2025-09-15 09:38:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:50 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.844, logit=20.250)', '\" Gloves\"[68554] (p=0.061, logit=17.625)', '\" The\"[578] (p=0.029, logit=16.875)', '\" A\"[362] (p=0.012, logit=16.000)', '\" Charm\"[58600] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:38:50 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.84375, logit=20.25, token_id=57094, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.06103515625, logit=17.625, token_id=68554, metadata=None))), (58600, (5, PredictedToken(token=' Charm', prob=0.006439208984375, logit=15.375, token_id=58600, metadata=None))), (36943, (10, PredictedToken(token=' Folder', prob=0.002227783203125, logit=14.3125, token_id=36943, metadata=None))), (33711, (21, PredictedToken(token=' Suit', prob=0.000560760498046875, logit=12.9375, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:50 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:50 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:38:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     patch_prediction=['\" Binder\"[91263] (p=0.875, logit=20.750)', '\" The\"[578] (p=0.043, logit=17.750)', '\" A\"[362] (p=0.026, logit=17.250)', '\" Tape\"[58586] (p=0.014, logit=16.625)', '\" There\"[2684] (p=0.003, logit=15.125)']\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.781, logit=20.375)', '\" The\"[578] (p=0.057, logit=17.750)', '\" L\"[445] (p=0.034, logit=17.250)', '\" A\"[362] (p=0.034, logit=17.250)', '\" BAT\"[79081] (p=0.030, logit=17.125)']\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.78125, logit=20.375, token_id=16488, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.034423828125, logit=17.25, token_id=445, metadata=None))), (13597, (6, PredictedToken(token=' Pen', prob=0.01116943359375, logit=16.125, token_id=13597, metadata=None))), (36943, (8, PredictedToken(token=' Folder', prob=0.00384521484375, logit=15.0625, token_id=36943, metadata=None))), (47033, (24, PredictedToken(token=' Printer', prob=0.000667572021484375, logit=13.3125, token_id=47033, metadata=None))), (41342, (43, PredictedToken(token=' Hockey', prob=0.0002460479736328125, logit=12.3125, token_id=41342, metadata=None)))])\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.535, logit=19.250)', '\" Printer\"[47033] (p=0.174, logit=18.125)', '\" PEN\"[81770] (p=0.064, logit=17.125)', '\" The\"[578] (p=0.056, logit=17.000)', '\" L\"[445] (p=0.056, logit=17.000)']\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.53515625, logit=19.25, token_id=13597, metadata=None))), (47033, (2, PredictedToken(token=' Printer', prob=0.173828125, logit=18.125, token_id=47033, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.056396484375, logit=17.0, token_id=445, metadata=None))), (36943, (7, PredictedToken(token=' Folder', prob=0.0086669921875, logit=15.125, token_id=36943, metadata=None))), (41342, (195, PredictedToken(token=' Hockey', prob=3.123283386230469e-05, logit=9.5, token_id=41342, metadata=None))), (16488, (263, PredictedToken(token=' Bat', prob=1.895427703857422e-05, logit=9.0, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:51 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:51 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.801, logit=20.625)', '\" Pendant\"[81501] (p=0.096, logit=18.500)', '\" Spr\"[15883] (p=0.031, logit=17.375)', '\" The\"[578] (p=0.027, logit=17.250)', '\" An\"[1556] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:38:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:52 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.727, logit=19.750)', '\" Camera\"[14669] (p=0.077, logit=17.500)', '\" The\"[578] (p=0.077, logit=17.500)', '\" Red\"[3816] (p=0.011, logit=15.562)', '\" There\"[2684] (p=0.008, logit=15.250)']\n",
      "2025-09-15 09:38:52 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.7265625, logit=19.75, token_id=26698, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.07666015625, logit=17.5, token_id=14669, metadata=None))), (3816, (4, PredictedToken(token=' Red', prob=0.01104736328125, logit=15.5625, token_id=3816, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.0029754638671875, logit=14.25, token_id=356, metadata=None))), (23126, (18, PredictedToken(token=' Ti', prob=0.0023193359375, logit=14.0, token_id=23126, metadata=None)))])\n",
      "2025-09-15 09:38:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:52 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.707, logit=20.250)', '\" Ti\"[23126] (p=0.084, logit=18.125)', '\" Camera\"[14669] (p=0.040, logit=17.375)', '\" Keyboard\"[26698] (p=0.035, logit=17.250)', '\" The\"[578] (p=0.035, logit=17.250)']\n",
      "2025-09-15 09:38:52 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.70703125, logit=20.25, token_id=356, metadata=None))), (23126, (2, PredictedToken(token=' Ti', prob=0.08447265625, logit=18.125, token_id=23126, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.0400390625, logit=17.375, token_id=14669, metadata=None))), (26698, (5, PredictedToken(token=' Keyboard', prob=0.03515625, logit=17.25, token_id=26698, metadata=None))), (3816, (6, PredictedToken(token=' Red', prob=0.0311279296875, logit=17.125, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:52 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:38:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     patch_prediction=['\" Bus\"[19111] (p=0.777, logit=21.125)', '\" The\"[578] (p=0.135, logit=19.375)', '\" A\"[362] (p=0.030, logit=17.875)', '\" Car\"[3341] (p=0.014, logit=17.125)', '\" BUS\"[23504] (p=0.013, logit=17.000)']\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.922, logit=21.125)', '\" Sc\"[2522] (p=0.022, logit=17.375)', '\" The\"[578] (p=0.022, logit=17.375)', '\" None\"[2290] (p=0.006, logit=16.125)', '\" Stap\"[63606] (p=0.003, logit=15.250)']\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.921875, logit=21.125, token_id=58586, metadata=None))), (2522, (3, PredictedToken(token=' Sc', prob=0.021728515625, logit=17.375, token_id=2522, metadata=None))), (1183, (6, PredictedToken(token=' Tr', prob=0.002288818359375, logit=15.125, token_id=1183, metadata=None))), (60413, (64, PredictedToken(token=' Uk', prob=6.4849853515625e-05, logit=11.5625, token_id=60413, metadata=None))), (38930, (137, PredictedToken(token=' Bike', prob=1.8596649169921875e-05, logit=10.3125, token_id=38930, metadata=None)))])\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.590, logit=18.500)', '\" Sc\"[2522] (p=0.103, logit=16.750)', '\" None\"[2290] (p=0.080, logit=16.500)', '\" The\"[578] (p=0.055, logit=16.125)', '\" Pen\"[13597] (p=0.028, logit=15.438)']\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.58984375, logit=18.5, token_id=38930, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.1025390625, logit=16.75, token_id=2522, metadata=None))), (1183, (6, PredictedToken(token=' Tr', prob=0.0147705078125, logit=14.8125, token_id=1183, metadata=None))), (60413, (9, PredictedToken(token=' Uk', prob=0.0074462890625, logit=14.125, token_id=60413, metadata=None))), (58586, (23, PredictedToken(token=' Tape', prob=0.00146484375, logit=12.5, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:53 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.746, logit=20.000)', '\" The\"[578] (p=0.130, logit=18.250)', '\" E\"[469] (p=0.037, logit=17.000)', '\" An\"[1556] (p=0.029, logit=16.750)', '\" Lion\"[33199] (p=0.009, logit=15.625)']\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.863, logit=20.750)', '\" The\"[578] (p=0.049, logit=17.875)', '\" There\"[2684] (p=0.018, logit=16.875)', '\" PL\"[10528] (p=0.014, logit=16.625)', '\" Grape\"[80629] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.86328125, logit=20.75, token_id=84409, metadata=None))), (80629, (5, PredictedToken(token=' Grape', prob=0.00958251953125, logit=16.25, token_id=80629, metadata=None))), (58937, (69, PredictedToken(token=' Monkey', prob=7.343292236328125e-05, logit=11.375, token_id=58937, metadata=None))), (24941, (107, PredictedToken(token=' Bear', prob=3.933906555175781e-05, logit=10.75, token_id=24941, metadata=None))), (18191, (121, PredictedToken(token=' Mouse', prob=3.24249267578125e-05, logit=10.5625, token_id=18191, metadata=None)))])\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     int_prediction=['\" Monkey\"[58937] (p=0.742, logit=20.000)', '\" Bear\"[24941] (p=0.078, logit=17.750)', '\" The\"[578] (p=0.054, logit=17.375)', '\" Mouse\"[18191] (p=0.047, logit=17.250)', '\" There\"[2684] (p=0.020, logit=16.375)']\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     int_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.7421875, logit=20.0, token_id=58937, metadata=None))), (24941, (2, PredictedToken(token=' Bear', prob=0.078125, logit=17.75, token_id=24941, metadata=None))), (18191, (4, PredictedToken(token=' Mouse', prob=0.04736328125, logit=17.25, token_id=18191, metadata=None))), (84409, (13, PredictedToken(token=' Plum', prob=0.0013427734375, logit=13.6875, token_id=84409, metadata=None))), (80629, (25, PredictedToken(token=' Grape', prob=0.00052642822265625, logit=12.75, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:54 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:38:54 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.754, logit=20.375)', '\" The\"[578] (p=0.148, logit=18.750)', '\" A\"[362] (p=0.026, logit=17.000)', '\" NIGHT\"[76131] (p=0.014, logit=16.375)', '\" It\"[1102] (p=0.007, logit=15.750)']\n",
      "2025-09-15 09:38:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.836, logit=20.125)', '\" The\"[578] (p=0.069, logit=17.625)', '\" A\"[362] (p=0.017, logit=16.250)', '\" jacket\"[27300] (p=0.012, logit=15.875)', '\" J\"[622] (p=0.010, logit=15.688)']\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.8359375, logit=20.125, token_id=55870, metadata=None))), (68554, (8, PredictedToken(token=' Gloves', prob=0.002838134765625, logit=14.4375, token_id=68554, metadata=None))), (70110, (11, PredictedToken(token=' Ottoman', prob=0.0020751953125, logit=14.125, token_id=70110, metadata=None))), (16478, (113, PredictedToken(token=' Chair', prob=5.1975250244140625e-05, logit=10.4375, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.734, logit=19.125)', '\" The\"[578] (p=0.078, logit=16.875)', '\" CH\"[6969] (p=0.025, logit=15.750)', '\" None\"[2290] (p=0.018, logit=15.438)', '\" Jacket\"[55870] (p=0.016, logit=15.312)']\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.734375, logit=19.125, token_id=16478, metadata=None))), (55870, (5, PredictedToken(token=' Jacket', prob=0.0162353515625, logit=15.3125, token_id=55870, metadata=None))), (68554, (10, PredictedToken(token=' Gloves', prob=0.00677490234375, logit=14.4375, token_id=68554, metadata=None))), (70110, (20, PredictedToken(token=' Ottoman', prob=0.0014190673828125, logit=12.875, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:55 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.707, logit=19.875)', '\" The\"[578] (p=0.108, logit=18.000)', '\" Surf\"[65197] (p=0.035, logit=16.875)', '\" Ski\"[61595] (p=0.027, logit=16.625)', '\" Sur\"[8242] (p=0.015, logit=16.000)']\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.645, logit=20.000)', '\" Tape\"[58586] (p=0.237, logit=19.000)', '\" Pen\"[13597] (p=0.025, logit=16.750)', '\" The\"[578] (p=0.022, logit=16.625)', '\" None\"[2290] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.64453125, logit=20.0, token_id=18343, metadata=None))), (58586, (2, PredictedToken(token=' Tape', prob=0.2373046875, logit=19.0, token_id=58586, metadata=None))), (57551, (10, PredictedToken(token=' Sink', prob=0.0028076171875, logit=14.5625, token_id=57551, metadata=None))), (16488, (17, PredictedToken(token=' Bat', prob=0.0013275146484375, logit=13.8125, token_id=16488, metadata=None))), (97796, (49, PredictedToken(token=' Skate', prob=0.00022983551025390625, logit=12.0625, token_id=97796, metadata=None)))])\n",
      "2025-09-15 09:38:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.695, logit=20.000)', '\" Tape\"[58586] (p=0.121, logit=18.250)', '\" Bat\"[16488] (p=0.094, logit=18.000)', '\" None\"[2290] (p=0.016, logit=16.250)', '\" Pen\"[13597] (p=0.012, logit=15.938)']\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.6953125, logit=20.0, token_id=97796, metadata=None))), (58586, (2, PredictedToken(token=' Tape', prob=0.12060546875, logit=18.25, token_id=58586, metadata=None))), (16488, (3, PredictedToken(token=' Bat', prob=0.09423828125, logit=18.0, token_id=16488, metadata=None))), (18343, (10, PredictedToken(token=' Paper', prob=0.002349853515625, logit=14.3125, token_id=18343, metadata=None))), (57551, (26, PredictedToken(token=' Sink', prob=0.000560760498046875, logit=12.875, token_id=57551, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:56 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     patch_prediction=['\" Router\"[10777] (p=0.672, logit=19.875)', '\" Camera\"[14669] (p=0.150, logit=18.375)', '\" The\"[578] (p=0.081, logit=17.750)', '\" A\"[362] (p=0.012, logit=15.812)', '\" ROUT\"[54281] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.883, logit=20.875)', '\" The\"[578] (p=0.056, logit=18.125)', '\" d\"[294] (p=0.011, logit=16.500)', '\" Jasmine\"[82452] (p=0.007, logit=16.000)', '\" DA\"[25561] (p=0.007, logit=16.000)']\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.8828125, logit=20.875, token_id=423, metadata=None))), (82452, (5, PredictedToken(token=' Jasmine', prob=0.006744384765625, logit=16.0, token_id=82452, metadata=None))), (41342, (85, PredictedToken(token=' Hockey', prob=4.267692565917969e-05, logit=10.9375, token_id=41342, metadata=None))), (14642, (90, PredictedToken(token=' Phone', prob=4.00543212890625e-05, logit=10.875, token_id=14642, metadata=None))), (24423, (181, PredictedToken(token=' Monitor', prob=1.2993812561035156e-05, logit=9.75, token_id=24423, metadata=None)))])\n",
      "2025-09-15 09:38:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.523, logit=19.875)', '\" Monitor\"[24423] (p=0.316, logit=19.375)', '\" The\"[578] (p=0.071, logit=17.875)', '\" A\"[362] (p=0.018, logit=16.500)', '\" PHONE\"[92183] (p=0.008, logit=15.688)']\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.5234375, logit=19.875, token_id=14642, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.31640625, logit=19.375, token_id=24423, metadata=None))), (41342, (59, PredictedToken(token=' Hockey', prob=0.0001277923583984375, logit=11.5625, token_id=41342, metadata=None))), (423, (66, PredictedToken(token=' D', prob=0.00010633468627929688, logit=11.375, token_id=423, metadata=None))), (82452, (477, PredictedToken(token=' Jasmine', prob=3.635883331298828e-06, logit=8.0, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:57 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.836, logit=21.125)', '\" The\"[578] (p=0.053, logit=18.375)', '\" Apartment\"[53889] (p=0.042, logit=18.125)', '\" A\"[362] (p=0.022, logit=17.500)', '\" MOS\"[74174] (p=0.013, logit=17.000)']\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     clean_prediction=['\" Tomato\"[94091] (p=0.377, logit=19.375)', '\" There\"[2684] (p=0.260, logit=19.000)', '\" Onion\"[87035] (p=0.178, logit=18.625)', '\" The\"[578] (p=0.065, logit=17.625)', '\" None\"[2290] (p=0.040, logit=17.125)']\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     clean_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.376953125, logit=19.375, token_id=94091, metadata=None))), (87035, (3, PredictedToken(token=' Onion', prob=0.177734375, logit=18.625, token_id=87035, metadata=None))), (60413, (17, PredictedToken(token=' Uk', prob=0.00164031982421875, logit=13.9375, token_id=60413, metadata=None))), (19176, (220, PredictedToken(token=' Temple', prob=1.9431114196777344e-05, logit=9.5, token_id=19176, metadata=None))), (6150, (277, PredictedToken(token=' School', prob=1.33514404296875e-05, logit=9.125, token_id=6150, metadata=None)))])\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.457, logit=19.000)', '\" There\"[2684] (p=0.190, logit=18.125)', '\" School\"[6150] (p=0.116, logit=17.625)', '\" The\"[578] (p=0.102, logit=17.500)', '\" None\"[2290] (p=0.048, logit=16.750)']\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.45703125, logit=19.0, token_id=19176, metadata=None))), (6150, (3, PredictedToken(token=' School', prob=0.11572265625, logit=17.625, token_id=6150, metadata=None))), (94091, (13, PredictedToken(token=' Tomato', prob=0.0025482177734375, logit=13.8125, token_id=94091, metadata=None))), (87035, (22, PredictedToken(token=' Onion', prob=0.00106048583984375, logit=12.9375, token_id=87035, metadata=None))), (60413, (36, PredictedToken(token=' Uk', prob=0.000606536865234375, logit=12.375, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:57 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:38:57 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:38:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     patch_prediction=['\" Ash\"[14937] (p=0.652, logit=20.000)', '\" The\"[578] (p=0.188, logit=18.750)', '\" Elm\"[65329] (p=0.054, logit=17.500)', '\" AS\"[5871] (p=0.014, logit=16.125)', '\" There\"[2684] (p=0.014, logit=16.125)']\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.762, logit=20.875)', '\" P\"[393] (p=0.103, logit=18.875)', '\" The\"[578] (p=0.043, logit=18.000)', '\" A\"[362] (p=0.038, logit=17.875)', '\" F\"[435] (p=0.011, logit=16.625)']\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.76171875, logit=20.875, token_id=36943, metadata=None))), (393, (2, PredictedToken(token=' P', prob=0.10302734375, logit=18.875, token_id=393, metadata=None))), (469, (8, PredictedToken(token=' E', prob=0.00311279296875, logit=15.375, token_id=469, metadata=None))), (22050, (80, PredictedToken(token=' Hat', prob=7.295608520507812e-05, logit=11.625, token_id=22050, metadata=None))), (79028, (85, PredictedToken(token=' Hick', prob=6.437301635742188e-05, logit=11.5, token_id=79028, metadata=None))), (43950, (155, PredictedToken(token=' Lav', prob=2.09808349609375e-05, logit=10.375, token_id=43950, metadata=None))), (70762, (167, PredictedToken(token=' Motorcycle', prob=1.8477439880371094e-05, logit=10.25, token_id=70762, metadata=None)))])\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.467, logit=19.625)', '\" Hick\"[79028] (p=0.365, logit=19.375)', '\" E\"[469] (p=0.056, logit=17.500)', '\" The\"[578] (p=0.030, logit=16.875)', '\" None\"[2290] (p=0.018, logit=16.375)']\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.466796875, logit=19.625, token_id=393, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.365234375, logit=19.375, token_id=79028, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.055908203125, logit=17.5, token_id=469, metadata=None))), (43950, (7, PredictedToken(token=' Lav', prob=0.005889892578125, logit=15.25, token_id=43950, metadata=None))), (36943, (94, PredictedToken(token=' Folder', prob=7.867813110351562e-05, logit=10.9375, token_id=36943, metadata=None))), (70762, (346, PredictedToken(token=' Motorcycle', prob=1.138448715209961e-05, logit=9.0, token_id=70762, metadata=None))), (22050, (491, PredictedToken(token=' Hat', prob=6.884336471557617e-06, logit=8.5, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:58 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:38:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.828, logit=21.000)', '\" E\"[469] (p=0.053, logit=18.250)', '\" The\"[578] (p=0.047, logit=18.125)', '\" R\"[432] (p=0.007, logit=16.250)', '\" A\"[362] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     clean_prediction=['\" Rice\"[30616] (p=0.586, logit=19.750)', '\" Oven\"[87213] (p=0.189, logit=18.625)', '\" The\"[578] (p=0.115, logit=18.125)', '\" None\"[2290] (p=0.020, logit=16.375)', '\" B\"[426] (p=0.013, logit=15.938)']\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     clean_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.5859375, logit=19.75, token_id=30616, metadata=None))), (87213, (2, PredictedToken(token=' Oven', prob=0.189453125, logit=18.625, token_id=87213, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.01287841796875, logit=15.9375, token_id=426, metadata=None))), (96096, (12, PredictedToken(token=' Dolphin', prob=0.00238037109375, logit=14.25, token_id=96096, metadata=None))), (86460, (52, PredictedToken(token=' Necklace', prob=0.00025177001953125, logit=12.0, token_id=86460, metadata=None)))])\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.844, logit=21.125)', '\" The\"[578] (p=0.101, logit=19.000)', '\" A\"[362] (p=0.009, logit=16.625)', '\" There\"[2684] (p=0.006, logit=16.125)', '\" None\"[2290] (p=0.004, logit=15.875)']\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.84375, logit=21.125, token_id=426, metadata=None))), (86460, (6, PredictedToken(token=' Necklace', prob=0.004425048828125, logit=15.875, token_id=86460, metadata=None))), (96096, (13, PredictedToken(token=' Dolphin', prob=0.0010528564453125, logit=14.4375, token_id=96096, metadata=None))), (87213, (14, PredictedToken(token=' Oven', prob=0.000926971435546875, logit=14.3125, token_id=87213, metadata=None))), (30616, (413, PredictedToken(token=' Rice', prob=3.1441450119018555e-06, logit=8.625, token_id=30616, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:38:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:38:59 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:38:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.766, logit=21.125)', '\" As\"[1666] (p=0.104, logit=19.125)', '\" The\"[578] (p=0.062, logit=18.625)', '\" D\"[423] (p=0.014, logit=17.125)', '\" There\"[2684] (p=0.011, logit=16.875)']\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.797, logit=20.875)', '\" The\"[578] (p=0.108, logit=18.875)', '\" Television\"[41445] (p=0.040, logit=17.875)', '\" It\"[1102] (p=0.006, logit=15.938)', '\" There\"[2684] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.796875, logit=20.875, token_id=57225, metadata=None))), (41445, (3, PredictedToken(token=' Television', prob=0.039794921875, logit=17.875, token_id=41445, metadata=None))), (97796, (15, PredictedToken(token=' Skate', prob=0.00106048583984375, logit=14.25, token_id=97796, metadata=None))), (87035, (573, PredictedToken(token=' Onion', prob=1.9222497940063477e-06, logit=7.9375, token_id=87035, metadata=None))), (94091, (715, PredictedToken(token=' Tomato', prob=1.3187527656555176e-06, logit=7.5625, token_id=94091, metadata=None)))])\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     int_prediction=['\" Tomato\"[94091] (p=0.297, logit=18.125)', '\" Onion\"[87035] (p=0.231, logit=17.875)', '\" The\"[578] (p=0.159, logit=17.500)', '\" Television\"[41445] (p=0.124, logit=17.250)', '\" There\"[2684] (p=0.026, logit=15.688)']\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     int_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.296875, logit=18.125, token_id=94091, metadata=None))), (87035, (2, PredictedToken(token=' Onion', prob=0.2314453125, logit=17.875, token_id=87035, metadata=None))), (41445, (4, PredictedToken(token=' Television', prob=0.1240234375, logit=17.25, token_id=41445, metadata=None))), (97796, (6, PredictedToken(token=' Skate', prob=0.017822265625, logit=15.3125, token_id=97796, metadata=None))), (57225, (20, PredictedToken(token=' Laptop', prob=0.0022735595703125, logit=13.25, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:00 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:39:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.789, logit=19.375)', '\" The\"[578] (p=0.107, logit=17.375)', '\" A\"[362] (p=0.014, logit=15.312)', '\" None\"[2290] (p=0.009, logit=14.938)', '\" Surf\"[65197] (p=0.007, logit=14.625)']\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     clean_prediction=['\" Rabbit\"[49431] (p=0.527, logit=18.500)', '\" The\"[578] (p=0.151, logit=17.250)', '\" R\"[432] (p=0.104, logit=16.875)', '\" Eagle\"[36895] (p=0.056, logit=16.250)', '\" There\"[2684] (p=0.013, logit=14.812)']\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     clean_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.52734375, logit=18.5, token_id=49431, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.10400390625, logit=16.875, token_id=432, metadata=None))), (36895, (4, PredictedToken(token=' Eagle', prob=0.0556640625, logit=16.25, token_id=36895, metadata=None))), (67629, (146, PredictedToken(token=' Helmet', prob=0.0001010894775390625, logit=9.9375, token_id=67629, metadata=None)))])\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.797, logit=19.625)', '\" The\"[578] (p=0.084, logit=17.375)', '\" Rabbit\"[49431] (p=0.035, logit=16.500)', '\" A\"[362] (p=0.014, logit=15.562)', '\" There\"[2684] (p=0.010, logit=15.250)']\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.796875, logit=19.625, token_id=432, metadata=None))), (49431, (3, PredictedToken(token=' Rabbit', prob=0.034912109375, logit=16.5, token_id=49431, metadata=None))), (36895, (7, PredictedToken(token=' Eagle', prob=0.004180908203125, logit=14.375, token_id=36895, metadata=None))), (67629, (34, PredictedToken(token=' Helmet', prob=0.00038909912109375, logit=12.0, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:01 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:39:01 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.797, logit=19.250)', '\" Razor\"[74968] (p=0.040, logit=16.250)', '\" The\"[578] (p=0.035, logit=16.125)', '\" Gloves\"[68554] (p=0.016, logit=15.312)', '\" TO\"[5257] (p=0.016, logit=15.312)']\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.789, logit=19.750)', '\" The\"[578] (p=0.073, logit=17.375)', '\" A\"[362] (p=0.035, logit=16.625)', '\" BAT\"[79081] (p=0.019, logit=16.000)', '\" Tow\"[41493] (p=0.013, logit=15.625)']\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.7890625, logit=19.75, token_id=16488, metadata=None))), (41493, (5, PredictedToken(token=' Tow', prob=0.0126953125, logit=15.625, token_id=41493, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.00872802734375, logit=15.25, token_id=432, metadata=None))), (57551, (57, PredictedToken(token=' Sink', prob=0.00016021728515625, logit=11.25, token_id=57551, metadata=None))), (37326, (97, PredictedToken(token=' Swe', prob=7.581710815429688e-05, logit=10.5, token_id=37326, metadata=None)))])\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.695, logit=19.625)', '\" R\"[432] (p=0.137, logit=18.000)', '\" The\"[578] (p=0.050, logit=17.000)', '\" A\"[362] (p=0.021, logit=16.125)', '\" Sink\"[57551] (p=0.019, logit=16.000)']\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.6953125, logit=19.625, token_id=41493, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.13671875, logit=18.0, token_id=432, metadata=None))), (57551, (5, PredictedToken(token=' Sink', prob=0.0185546875, logit=16.0, token_id=57551, metadata=None))), (16488, (7, PredictedToken(token=' Bat', prob=0.00640869140625, logit=14.9375, token_id=16488, metadata=None))), (37326, (12, PredictedToken(token=' Swe', prob=0.002838134765625, logit=14.125, token_id=37326, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:02 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.711, logit=20.000)', '\" Micro\"[18654] (p=0.109, logit=18.125)', '\" The\"[578] (p=0.058, logit=17.500)', '\" Calculator\"[37128] (p=0.035, logit=17.000)', '\" MON\"[29637] (p=0.015, logit=16.125)']\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.875, logit=19.750)', '\" The\"[578] (p=0.030, logit=16.375)', '\" Paper\"[18343] (p=0.019, logit=15.938)', '\" TO\"[5257] (p=0.013, logit=15.562)', '\" toilet\"[27306] (p=0.006, logit=14.812)']\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.875, logit=19.75, token_id=82994, metadata=None))), (18343, (3, PredictedToken(token=' Paper', prob=0.0194091796875, logit=15.9375, token_id=18343, metadata=None))), (14642, (17, PredictedToken(token=' Phone', prob=0.000850677490234375, logit=12.8125, token_id=14642, metadata=None))), (57225, (49, PredictedToken(token=' Laptop', prob=0.00018978118896484375, logit=11.3125, token_id=57225, metadata=None)))])\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.816, logit=19.500)', '\" The\"[578] (p=0.036, logit=16.375)', '\" Toilet\"[82994] (p=0.022, logit=15.875)', '\" Paper\"[18343] (p=0.021, logit=15.812)', '\" A\"[362] (p=0.011, logit=15.188)']\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.81640625, logit=19.5, token_id=14642, metadata=None))), (82994, (3, PredictedToken(token=' Toilet', prob=0.0218505859375, logit=15.875, token_id=82994, metadata=None))), (18343, (4, PredictedToken(token=' Paper', prob=0.0205078125, logit=15.8125, token_id=18343, metadata=None))), (57225, (6, PredictedToken(token=' Laptop', prob=0.010986328125, logit=15.1875, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:03 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.754, logit=20.125)', '\" The\"[578] (p=0.115, logit=18.250)', '\" Laptop\"[57225] (p=0.029, logit=16.875)', '\" Blue\"[8868] (p=0.020, logit=16.500)', '\" A\"[362] (p=0.020, logit=16.500)']\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.699, logit=20.625)', '\" The\"[578] (p=0.156, logit=19.125)', '\" Boxing\"[72683] (p=0.065, logit=18.250)', '\" A\"[362] (p=0.035, logit=17.625)', '\" H\"[473] (p=0.003, logit=15.250)']\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.69921875, logit=20.625, token_id=41342, metadata=None))), (72683, (3, PredictedToken(token=' Boxing', prob=0.0654296875, logit=18.25, token_id=72683, metadata=None))), (47033, (80, PredictedToken(token=' Printer', prob=5.5789947509765625e-05, logit=11.1875, token_id=47033, metadata=None))), (26698, (110, PredictedToken(token=' Keyboard', prob=3.170967102050781e-05, logit=10.625, token_id=26698, metadata=None))), (22725, (126, PredictedToken(token=' Orange', prob=2.6345252990722656e-05, logit=10.4375, token_id=22725, metadata=None)))])\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.676, logit=20.500)', '\" Keyboard\"[26698] (p=0.194, logit=19.250)', '\" The\"[578] (p=0.081, logit=18.375)', '\" A\"[362] (p=0.009, logit=16.125)', '\" None\"[2290] (p=0.003, logit=15.000)']\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.67578125, logit=20.5, token_id=47033, metadata=None))), (26698, (2, PredictedToken(token=' Keyboard', prob=0.1943359375, logit=19.25, token_id=26698, metadata=None))), (72683, (7, PredictedToken(token=' Boxing', prob=0.002288818359375, logit=14.8125, token_id=72683, metadata=None))), (41342, (33, PredictedToken(token=' Hockey', prob=0.0003108978271484375, logit=12.8125, token_id=41342, metadata=None))), (22725, (76, PredictedToken(token=' Orange', prob=6.103515625e-05, logit=11.1875, token_id=22725, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:04 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     patch_prediction=['\" Van\"[13000] (p=0.551, logit=20.625)', '\" Motorcycle\"[70762] (p=0.293, logit=20.000)', '\" The\"[578] (p=0.065, logit=18.500)', '\" VAN\"[97753] (p=0.031, logit=17.750)', '\" A\"[362] (p=0.015, logit=17.000)']\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.762, logit=20.750)', '\" The\"[578] (p=0.150, logit=19.125)', '\" A\"[362] (p=0.016, logit=16.875)', '\" There\"[2684] (p=0.011, logit=16.500)', '\" It\"[1102] (p=0.005, logit=15.812)']\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.76171875, logit=20.75, token_id=38258, metadata=None))), (38673, (24, PredictedToken(token=' Yoga', prob=0.000576019287109375, logit=13.5625, token_id=38673, metadata=None))), (27217, (51, PredictedToken(token=' Train', prob=0.00016498565673828125, logit=12.3125, token_id=27217, metadata=None))), (19111, (74, PredictedToken(token=' Bus', prob=8.296966552734375e-05, logit=11.625, token_id=19111, metadata=None))), (921, (170, PredictedToken(token=' Ch', prob=1.7404556274414062e-05, logit=10.0625, token_id=921, metadata=None)))])\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.750, logit=20.625)', '\" The\"[578] (p=0.131, logit=18.875)', '\" There\"[2684] (p=0.023, logit=17.125)', '\" None\"[2290] (p=0.018, logit=16.875)', '\" Baseball\"[38258] (p=0.012, logit=16.500)']\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.75, logit=20.625, token_id=27217, metadata=None))), (38258, (5, PredictedToken(token=' Baseball', prob=0.01214599609375, logit=16.5, token_id=38258, metadata=None))), (19111, (16, PredictedToken(token=' Bus', prob=0.00164031982421875, logit=14.5, token_id=19111, metadata=None))), (38673, (62, PredictedToken(token=' Yoga', prob=0.00013446807861328125, logit=12.0, token_id=38673, metadata=None))), (921, (94, PredictedToken(token=' Ch', prob=6.389617919921875e-05, logit=11.25, token_id=921, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:05 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.699, logit=20.500)', '\" The\"[578] (p=0.155, logit=19.000)', '\" A\"[362] (p=0.035, logit=17.500)', '\" Truck\"[34785] (p=0.024, logit=17.125)', '\" There\"[2684] (p=0.013, logit=16.500)']\n",
      "2025-09-15 09:39:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     clean_prediction=['\" Sh\"[1443] (p=0.672, logit=20.500)', '\" Tooth\"[83499] (p=0.219, logit=19.375)', '\" The\"[578] (p=0.030, logit=17.375)', '\" Cabinet\"[34046] (p=0.011, logit=16.375)', '\" SH\"[6570] (p=0.007, logit=15.875)']\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     clean_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.671875, logit=20.5, token_id=1443, metadata=None))), (83499, (2, PredictedToken(token=' Tooth', prob=0.21875, logit=19.375, token_id=83499, metadata=None))), (34046, (4, PredictedToken(token=' Cabinet', prob=0.0108642578125, logit=16.375, token_id=34046, metadata=None))), (16183, (11, PredictedToken(token=' Hel', prob=0.0029296875, logit=15.0625, token_id=16183, metadata=None))), (27217, (50, PredictedToken(token=' Train', prob=0.00017547607421875, logit=12.25, token_id=27217, metadata=None)))])\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.762, logit=20.750)', '\" Hel\"[16183] (p=0.149, logit=19.125)', '\" The\"[578] (p=0.026, logit=17.375)', '\" A\"[362] (p=0.010, logit=16.375)', '\" Cabinet\"[34046] (p=0.008, logit=16.250)']\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.76171875, logit=20.75, token_id=27217, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.1494140625, logit=19.125, token_id=16183, metadata=None))), (34046, (5, PredictedToken(token=' Cabinet', prob=0.0084228515625, logit=16.25, token_id=34046, metadata=None))), (83499, (6, PredictedToken(token=' Tooth', prob=0.0074462890625, logit=16.125, token_id=83499, metadata=None))), (1443, (30, PredictedToken(token=' Sh', prob=0.000270843505859375, logit=12.8125, token_id=1443, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:06 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.887, logit=21.625)', '\" The\"[578] (p=0.044, logit=18.625)', '\" As\"[1666] (p=0.021, logit=17.875)', '\" There\"[2684] (p=0.013, logit=17.375)', '\" Tie\"[59825] (p=0.006, logit=16.625)']\n",
      "2025-09-15 09:39:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.781, logit=20.875)', '\" The\"[578] (p=0.082, logit=18.625)', '\" A\"[362] (p=0.044, logit=18.000)', '\" Jacket\"[55870] (p=0.039, logit=17.875)', '\" D\"[423] (p=0.007, logit=16.125)']\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.78125, logit=20.875, token_id=29318, metadata=None))), (55870, (4, PredictedToken(token=' Jacket', prob=0.038818359375, logit=17.875, token_id=55870, metadata=None))), (3341, (7, PredictedToken(token=' Car', prob=0.00494384765625, logit=15.8125, token_id=3341, metadata=None))), (16478, (89, PredictedToken(token=' Chair', prob=4.839897155761719e-05, logit=11.1875, token_id=16478, metadata=None))), (78703, (114, PredictedToken(token=' Potato', prob=2.9325485229492188e-05, logit=10.6875, token_id=78703, metadata=None)))])\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.832, logit=20.625)', '\" Jacket\"[55870] (p=0.042, logit=17.625)', '\" The\"[578] (p=0.032, logit=17.375)', '\" Potato\"[78703] (p=0.028, logit=17.250)', '\" A\"[362] (p=0.015, logit=16.625)']\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.83203125, logit=20.625, token_id=3341, metadata=None))), (55870, (2, PredictedToken(token=' Jacket', prob=0.04150390625, logit=17.625, token_id=55870, metadata=None))), (78703, (4, PredictedToken(token=' Potato', prob=0.0284423828125, logit=17.25, token_id=78703, metadata=None))), (29318, (39, PredictedToken(token=' Dress', prob=0.000217437744140625, logit=12.375, token_id=29318, metadata=None))), (16478, (58, PredictedToken(token=' Chair', prob=0.00010251998901367188, logit=11.625, token_id=16478, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:07 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:07 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     patch_prediction=['\" Router\"[10777] (p=0.746, logit=19.625)', '\" The\"[578] (p=0.101, logit=17.625)', '\" ROUT\"[54281] (p=0.022, logit=16.125)', '\" A\"[362] (p=0.020, logit=16.000)', '\" It\"[1102] (p=0.014, logit=15.625)']\n",
      "2025-09-15 09:39:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:08 src.selection.optimization INFO     clean_prediction=['\" Ti\"[23126] (p=0.645, logit=19.500)', '\" Ank\"[57915] (p=0.163, logit=18.125)', '\" The\"[578] (p=0.077, logit=17.375)', '\" TI\"[39237] (p=0.019, logit=16.000)', '\" A\"[362] (p=0.015, logit=15.750)']\n",
      "2025-09-15 09:39:08 src.selection.optimization INFO     clean_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.64453125, logit=19.5, token_id=23126, metadata=None))), (57915, (2, PredictedToken(token=' Ank', prob=0.1630859375, logit=18.125, token_id=57915, metadata=None))), (18191, (10, PredictedToken(token=' Mouse', prob=0.003173828125, logit=14.1875, token_id=18191, metadata=None))), (30173, (19, PredictedToken(token=' Speaker', prob=0.00131988525390625, logit=13.3125, token_id=30173, metadata=None)))])\n",
      "2025-09-15 09:39:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:08 src.selection.optimization INFO     int_prediction=['\" Mouse\"[18191] (p=0.871, logit=20.000)', '\" Ank\"[57915] (p=0.034, logit=16.750)', '\" The\"[578] (p=0.018, logit=16.125)', '\" Speaker\"[30173] (p=0.013, logit=15.812)', '\" A\"[362] (p=0.013, logit=15.812)']\n",
      "2025-09-15 09:39:08 src.selection.optimization INFO     int_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.87109375, logit=20.0, token_id=18191, metadata=None))), (57915, (2, PredictedToken(token=' Ank', prob=0.03369140625, logit=16.75, token_id=57915, metadata=None))), (30173, (5, PredictedToken(token=' Speaker', prob=0.01324462890625, logit=15.8125, token_id=30173, metadata=None))), (23126, (65, PredictedToken(token=' Ti', prob=9.489059448242188e-05, logit=10.875, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:08 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:08 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:39:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     patch_prediction=['\" Desk\"[39794] (p=0.523, logit=19.750)', '\" Re\"[1050] (p=0.170, logit=18.625)', '\" R\"[432] (p=0.133, logit=18.375)', '\" The\"[578] (p=0.081, logit=17.875)', '\" A\"[362] (p=0.018, logit=16.375)']\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.840, logit=21.000)', '\" The\"[578] (p=0.088, logit=18.750)', '\" M\"[386] (p=0.025, logit=17.500)', '\" There\"[2684] (p=0.009, logit=16.500)', '\" No\"[2360] (p=0.003, logit=15.188)']\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.83984375, logit=21.0, token_id=91963, metadata=None))), (76924, (6, PredictedToken(token=' Banana', prob=0.0023651123046875, logit=15.125, token_id=76924, metadata=None))), (34392, (10, PredictedToken(token=' Horse', prob=0.00152587890625, logit=14.6875, token_id=34392, metadata=None))), (800, (13, PredictedToken(token=' St', prob=0.00104522705078125, logit=14.3125, token_id=800, metadata=None))), (47033, (241, PredictedToken(token=' Printer', prob=8.52346420288086e-06, logit=9.5, token_id=47033, metadata=None))), (37128, (669, PredictedToken(token=' Calculator', prob=1.6763806343078613e-06, logit=7.875, token_id=37128, metadata=None))), (61948, (836, PredictedToken(token=' Sofa', prob=1.2293457984924316e-06, logit=7.5625, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     int_prediction=['\" St\"[800] (p=0.797, logit=20.500)', '\" The\"[578] (p=0.095, logit=18.375)', '\" A\"[362] (p=0.027, logit=17.125)', '\" Sofa\"[61948] (p=0.019, logit=16.750)', '\" Horse\"[34392] (p=0.015, logit=16.500)']\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     int_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.796875, logit=20.5, token_id=800, metadata=None))), (61948, (4, PredictedToken(token=' Sofa', prob=0.018798828125, logit=16.75, token_id=61948, metadata=None))), (34392, (5, PredictedToken(token=' Horse', prob=0.01458740234375, logit=16.5, token_id=34392, metadata=None))), (47033, (6, PredictedToken(token=' Printer', prob=0.00689697265625, logit=15.75, token_id=47033, metadata=None))), (91963, (13, PredictedToken(token=' Mango', prob=0.00119781494140625, logit=14.0, token_id=91963, metadata=None))), (76924, (29, PredictedToken(token=' Banana', prob=0.0004138946533203125, logit=12.9375, token_id=76924, metadata=None))), (37128, (40, PredictedToken(token=' Calculator', prob=0.00019550323486328125, logit=12.1875, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:09 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:09 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.797, logit=20.375)', '\" The\"[578] (p=0.058, logit=17.750)', '\" Monitor\"[24423] (p=0.045, logit=17.500)', '\" Pen\"[13597] (p=0.024, logit=16.875)', '\" A\"[362] (p=0.019, logit=16.625)']\n",
      "2025-09-15 09:39:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     clean_prediction=['\" Dog\"[14588] (p=0.785, logit=20.875)', '\" The\"[578] (p=0.121, logit=19.000)', '\" DO\"[9503] (p=0.027, logit=17.500)', '\" A\"[362] (p=0.010, logit=16.500)', '\" There\"[2684] (p=0.009, logit=16.375)']\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     clean_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.78515625, logit=20.875, token_id=14588, metadata=None))), (17810, (6, PredictedToken(token=' Cat', prob=0.006805419921875, logit=16.125, token_id=17810, metadata=None))), (432, (18, PredictedToken(token=' R', prob=0.000762939453125, logit=13.9375, token_id=432, metadata=None))), (9939, (107, PredictedToken(token=' Er', prob=4.029273986816406e-05, logit=11.0, token_id=9939, metadata=None))), (18343, (139, PredictedToken(token=' Paper', prob=2.4437904357910156e-05, logit=10.5, token_id=18343, metadata=None))), (26698, (572, PredictedToken(token=' Keyboard', prob=2.428889274597168e-06, logit=8.1875, token_id=26698, metadata=None))), (88668, (657, PredictedToken(token=' Blender', prob=2.0116567611694336e-06, logit=8.0, token_id=88668, metadata=None)))])\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     int_prediction=['\" Er\"[9939] (p=0.377, logit=19.125)', '\" Keyboard\"[26698] (p=0.179, logit=18.375)', '\" The\"[578] (p=0.123, logit=18.000)', '\" R\"[432] (p=0.108, logit=17.875)', '\" Paper\"[18343] (p=0.074, logit=17.500)']\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     int_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.376953125, logit=19.125, token_id=9939, metadata=None))), (26698, (2, PredictedToken(token=' Keyboard', prob=0.1787109375, logit=18.375, token_id=26698, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.10791015625, logit=17.875, token_id=432, metadata=None))), (18343, (5, PredictedToken(token=' Paper', prob=0.07421875, logit=17.5, token_id=18343, metadata=None))), (17810, (6, PredictedToken(token=' Cat', prob=0.024169921875, logit=16.375, token_id=17810, metadata=None))), (88668, (11, PredictedToken(token=' Blender', prob=0.00506591796875, logit=14.8125, token_id=88668, metadata=None))), (14588, (28, PredictedToken(token=' Dog', prob=0.000934600830078125, logit=13.125, token_id=14588, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:10 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:10 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     patch_prediction=['\" Ti\"[23126] (p=0.617, logit=20.125)', '\" B\"[426] (p=0.227, logit=19.125)', '\" The\"[578] (p=0.051, logit=17.625)', '\" b\"[293] (p=0.027, logit=17.000)', '\" A\"[362] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:39:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     clean_prediction=['\" Tiger\"[36845] (p=0.902, logit=20.500)', '\" The\"[578] (p=0.035, logit=17.250)', '\" Lion\"[33199] (p=0.011, logit=16.125)', '\" T\"[350] (p=0.011, logit=16.125)', '\" There\"[2684] (p=0.002, logit=14.562)']\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     clean_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.90234375, logit=20.5, token_id=36845, metadata=None))), (33199, (4, PredictedToken(token=' Lion', prob=0.0113525390625, logit=16.125, token_id=33199, metadata=None))), (29318, (12, PredictedToken(token=' Dress', prob=0.00119781494140625, logit=13.875, token_id=29318, metadata=None))), (23262, (58, PredictedToken(token=' Comb', prob=9.822845458984375e-05, logit=11.375, token_id=23262, metadata=None))), (57915, (165, PredictedToken(token=' Ank', prob=2.0623207092285156e-05, logit=9.8125, token_id=57915, metadata=None))), (81501, (785, PredictedToken(token=' Pendant', prob=1.9818544387817383e-06, logit=7.46875, token_id=81501, metadata=None)))])\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     int_prediction=['\" Pendant\"[81501] (p=0.871, logit=20.375)', '\" The\"[578] (p=0.030, logit=17.000)', '\" P\"[393] (p=0.018, logit=16.500)', '\" Lion\"[33199] (p=0.016, logit=16.375)', '\" Dress\"[29318] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     int_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.87109375, logit=20.375, token_id=81501, metadata=None))), (33199, (4, PredictedToken(token=' Lion', prob=0.0159912109375, logit=16.375, token_id=33199, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.01092529296875, logit=16.0, token_id=29318, metadata=None))), (36845, (6, PredictedToken(token=' Tiger', prob=0.0054931640625, logit=15.3125, token_id=36845, metadata=None))), (57915, (16, PredictedToken(token=' Ank', prob=0.000957489013671875, logit=13.5625, token_id=57915, metadata=None))), (23262, (17, PredictedToken(token=' Comb', prob=0.0009002685546875, logit=13.5, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:11 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     patch_prediction=['\" Van\"[13000] (p=0.754, logit=20.500)', '\" The\"[578] (p=0.131, logit=18.750)', '\" VAN\"[97753] (p=0.026, logit=17.125)', '\" A\"[362] (p=0.023, logit=17.000)', '\" Air\"[6690] (p=0.018, logit=16.750)']\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.781, logit=20.750)', '\" The\"[578] (p=0.082, logit=18.500)', '\" There\"[2684] (p=0.073, logit=18.375)', '\" Mushroom\"[91297] (p=0.013, logit=16.625)', '\" None\"[2290] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.78125, logit=20.75, token_id=1666, metadata=None))), (91297, (4, PredictedToken(token=' Mushroom', prob=0.0125732421875, logit=16.625, token_id=91297, metadata=None))), (13394, (22, PredictedToken(token=' Bed', prob=0.000591278076171875, logit=13.5625, token_id=13394, metadata=None))), (63606, (27, PredictedToken(token=' Stap', prob=0.000431060791015625, logit=13.25, token_id=63606, metadata=None))), (27217, (119, PredictedToken(token=' Train', prob=4.00543212890625e-05, logit=10.875, token_id=27217, metadata=None))), (38930, (388, PredictedToken(token=' Bike', prob=4.798173904418945e-06, logit=8.75, token_id=38930, metadata=None)))])\n",
      "2025-09-15 09:39:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.504, logit=19.875)', '\" The\"[578] (p=0.210, logit=19.000)', '\" There\"[2684] (p=0.112, logit=18.375)', '\" Bike\"[38930] (p=0.060, logit=17.750)', '\" Stap\"[63606] (p=0.041, logit=17.375)']\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.50390625, logit=19.875, token_id=27217, metadata=None))), (38930, (4, PredictedToken(token=' Bike', prob=0.06005859375, logit=17.75, token_id=38930, metadata=None))), (63606, (5, PredictedToken(token=' Stap', prob=0.041259765625, logit=17.375, token_id=63606, metadata=None))), (13394, (7, PredictedToken(token=' Bed', prob=0.005950927734375, logit=15.4375, token_id=13394, metadata=None))), (1666, (22, PredictedToken(token=' As', prob=0.000911712646484375, logit=13.5625, token_id=1666, metadata=None))), (91297, (24, PredictedToken(token=' Mushroom', prob=0.00075531005859375, logit=13.375, token_id=91297, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:12 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:12 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     patch_prediction=['\" Har\"[5340] (p=0.648, logit=19.625)', '\" Fl\"[3061] (p=0.128, logit=18.000)', '\" The\"[578] (p=0.088, logit=17.625)', '\" Bat\"[16488] (p=0.032, logit=16.625)', '\" None\"[2290] (p=0.012, logit=15.625)']\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.475, logit=18.750)', '\" Factory\"[17367] (p=0.198, logit=17.875)', '\" The\"[578] (p=0.120, logit=17.375)', '\" A\"[362] (p=0.050, logit=16.500)', '\" Soap\"[61731] (p=0.034, logit=16.125)']\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.474609375, logit=18.75, token_id=23462, metadata=None))), (17367, (2, PredictedToken(token=' Factory', prob=0.1982421875, logit=17.875, token_id=17367, metadata=None))), (61731, (5, PredictedToken(token=' Soap', prob=0.034423828125, logit=16.125, token_id=61731, metadata=None))), (14937, (8, PredictedToken(token=' Ash', prob=0.0072021484375, logit=14.5625, token_id=14937, metadata=None))), (31181, (16, PredictedToken(token=' Clar', prob=0.00160980224609375, logit=13.0625, token_id=31181, metadata=None))), (40759, (39, PredictedToken(token=' Harmon', prob=0.0004062652587890625, logit=11.6875, token_id=40759, metadata=None)))])\n",
      "2025-09-15 09:39:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.629, logit=19.000)', '\" The\"[578] (p=0.124, logit=17.375)', '\" Stadium\"[23462] (p=0.052, logit=16.500)', '\" Soap\"[61731] (p=0.040, logit=16.250)', '\" Harmon\"[40759] (p=0.024, logit=15.750)']\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.62890625, logit=19.0, token_id=31181, metadata=None))), (23462, (3, PredictedToken(token=' Stadium', prob=0.0517578125, logit=16.5, token_id=23462, metadata=None))), (61731, (4, PredictedToken(token=' Soap', prob=0.040283203125, logit=16.25, token_id=61731, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.0244140625, logit=15.75, token_id=40759, metadata=None))), (17367, (13, PredictedToken(token=' Factory', prob=0.0045166015625, logit=14.0625, token_id=17367, metadata=None))), (14937, (14, PredictedToken(token=' Ash', prob=0.003997802734375, logit=13.9375, token_id=14937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:13 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:13 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.467, logit=19.625)', '\" Hockey\"[41342] (p=0.320, logit=19.250)', '\" The\"[578] (p=0.092, logit=18.000)', '\" A\"[362] (p=0.056, logit=17.500)', '\" None\"[2290] (p=0.005, logit=15.125)']\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.812, logit=20.250)', '\" The\"[578] (p=0.046, logit=17.375)', '\" Brace\"[70306] (p=0.036, logit=17.125)', '\" e\"[384] (p=0.036, logit=17.125)', '\" An\"[1556] (p=0.013, logit=16.125)']\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.8125, logit=20.25, token_id=469, metadata=None))), (70306, (4, PredictedToken(token=' Brace', prob=0.03564453125, logit=17.125, token_id=70306, metadata=None))), (58251, (15, PredictedToken(token=' Tennis', prob=0.00147247314453125, logit=13.9375, token_id=58251, metadata=None))), (2522, (18, PredictedToken(token=' Sc', prob=0.0011444091796875, logit=13.6875, token_id=2522, metadata=None))), (21424, (43, PredictedToken(token=' Football', prob=0.0002727508544921875, logit=12.25, token_id=21424, metadata=None))), (34954, (57, PredictedToken(token=' Mirror', prob=0.0001373291015625, logit=11.5625, token_id=34954, metadata=None)))])\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.805, logit=19.750)', '\" Football\"[21424] (p=0.075, logit=17.375)', '\" The\"[578] (p=0.024, logit=16.250)', '\" Sc\"[2522] (p=0.021, logit=16.125)', '\" A\"[362] (p=0.005, logit=14.688)']\n",
      "2025-09-15 09:39:13 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.8046875, logit=19.75, token_id=58251, metadata=None))), (21424, (2, PredictedToken(token=' Football', prob=0.07470703125, logit=17.375, token_id=21424, metadata=None))), (2522, (4, PredictedToken(token=' Sc', prob=0.021484375, logit=16.125, token_id=2522, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.005096435546875, logit=14.6875, token_id=469, metadata=None))), (34954, (21, PredictedToken(token=' Mirror', prob=0.000942230224609375, logit=13.0, token_id=34954, metadata=None))), (70306, (40, PredictedToken(token=' Brace', prob=0.000392913818359375, logit=12.125, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.766, logit=20.500)', '\" Horse\"[34392] (p=0.133, logit=18.750)', '\" The\"[578] (p=0.034, logit=17.375)', '\" C\"[356] (p=0.016, logit=16.625)', '\" A\"[362] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.809, logit=20.125)', '\" Charm\"[58600] (p=0.066, logit=17.625)', '\" The\"[578] (p=0.046, logit=17.250)', '\" A\"[362] (p=0.019, logit=16.375)', '\" Tennis\"[58251] (p=0.005, logit=14.938)']\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.80859375, logit=20.125, token_id=81501, metadata=None))), (58600, (2, PredictedToken(token=' Charm', prob=0.06640625, logit=17.625, token_id=58600, metadata=None))), (58251, (5, PredictedToken(token=' Tennis', prob=0.0045166015625, logit=14.9375, token_id=58251, metadata=None))), (58937, (7, PredictedToken(token=' Monkey', prob=0.0029144287109375, logit=14.5, token_id=58937, metadata=None))), (84008, (26, PredictedToken(token=' Sheep', prob=0.00057220458984375, logit=12.875, token_id=84008, metadata=None)))])\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     int_prediction=['\" Monkey\"[58937] (p=0.535, logit=19.125)', '\" Sheep\"[84008] (p=0.326, logit=18.625)', '\" The\"[578] (p=0.034, logit=16.375)', '\" MON\"[29637] (p=0.016, logit=15.625)', '\" SHE\"[54695] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     int_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.53515625, logit=19.125, token_id=58937, metadata=None))), (84008, (2, PredictedToken(token=' Sheep', prob=0.326171875, logit=18.625, token_id=84008, metadata=None))), (58251, (7, PredictedToken(token=' Tennis', prob=0.005950927734375, logit=14.625, token_id=58251, metadata=None))), (81501, (19, PredictedToken(token=' Pendant', prob=0.000972747802734375, logit=12.8125, token_id=81501, metadata=None))), (58600, (30, PredictedToken(token=' Charm', prob=0.0004062652587890625, logit=11.9375, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     patch_prediction=['\" Spin\"[41785] (p=0.824, logit=20.000)', '\" As\"[1666] (p=0.060, logit=17.375)', '\" The\"[578] (p=0.032, logit=16.750)', '\" There\"[2684] (p=0.019, logit=16.250)', '\" Pin\"[17929] (p=0.013, logit=15.812)']\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.418, logit=19.375)', '\" Library\"[11896] (p=0.369, logit=19.250)', '\" The\"[578] (p=0.120, logit=18.125)', '\" A\"[362] (p=0.018, logit=16.250)', '\" An\"[1556] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.41796875, logit=19.375, token_id=16730, metadata=None))), (11896, (2, PredictedToken(token=' Library', prob=0.369140625, logit=19.25, token_id=11896, metadata=None))), (57915, (7, PredictedToken(token=' Ank', prob=0.004638671875, logit=14.875, token_id=57915, metadata=None))), (1901, (8, PredictedToken(token=' Z', prob=0.004364013671875, logit=14.8125, token_id=1901, metadata=None))), (87035, (10, PredictedToken(token=' Onion', prob=0.00384521484375, logit=14.6875, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.574, logit=19.625)', '\" Z\"[1901] (p=0.128, logit=18.125)', '\" The\"[578] (p=0.100, logit=17.875)', '\" Ank\"[57915] (p=0.032, logit=16.750)', '\" ON\"[6328] (p=0.029, logit=16.625)']\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.57421875, logit=19.625, token_id=87035, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.1279296875, logit=18.125, token_id=1901, metadata=None))), (57915, (4, PredictedToken(token=' Ank', prob=0.0322265625, logit=16.75, token_id=57915, metadata=None))), (11896, (7, PredictedToken(token=' Library', prob=0.017333984375, logit=16.125, token_id=11896, metadata=None))), (16730, (8, PredictedToken(token=' Museum', prob=0.01434326171875, logit=15.9375, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:15 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:15 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:39:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     patch_prediction=['\" Amb\"[20423] (p=0.473, logit=20.000)', '\" Train\"[27217] (p=0.287, logit=19.500)', '\" The\"[578] (p=0.136, logit=18.750)', '\" An\"[1556] (p=0.034, logit=17.375)', '\" There\"[2684] (p=0.018, logit=16.750)']\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.941, logit=22.500)', '\" The\"[578] (p=0.036, logit=19.250)', '\" PE\"[22557] (p=0.007, logit=17.625)', '\" A\"[362] (p=0.002, logit=16.375)', '\" There\"[2684] (p=0.002, logit=16.250)']\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.94140625, logit=22.5, token_id=64695, metadata=None))), (48665, (6, PredictedToken(token=' Raspberry', prob=0.0010986328125, logit=15.75, token_id=48665, metadata=None))), (70762, (25, PredictedToken(token=' Motorcycle', prob=0.00010251998901367188, logit=13.375, token_id=70762, metadata=None))), (13000, (28, PredictedToken(token=' Van', prob=9.632110595703125e-05, logit=13.3125, token_id=13000, metadata=None))), (22050, (567, PredictedToken(token=' Hat', prob=6.48200511932373e-07, logit=8.3125, token_id=22050, metadata=None))), (16478, (1952, PredictedToken(token=' Chair', prob=1.2014061212539673e-07, logit=6.625, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.441, logit=20.500)', '\" Motorcycle\"[70762] (p=0.441, logit=20.500)', '\" The\"[578] (p=0.053, logit=18.375)', '\" VAN\"[97753] (p=0.017, logit=17.250)', '\" A\"[362] (p=0.010, logit=16.750)']\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.44140625, logit=20.5, token_id=13000, metadata=None))), (70762, (2, PredictedToken(token=' Motorcycle', prob=0.44140625, logit=20.5, token_id=70762, metadata=None))), (48665, (15, PredictedToken(token=' Raspberry', prob=0.0008544921875, logit=14.25, token_id=48665, metadata=None))), (16478, (25, PredictedToken(token=' Chair', prob=0.0003147125244140625, logit=13.25, token_id=16478, metadata=None))), (64695, (52, PredictedToken(token=' Peach', prob=0.00010204315185546875, logit=12.125, token_id=64695, metadata=None))), (22050, (301, PredictedToken(token=' Hat', prob=4.76837158203125e-06, logit=9.0625, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:16 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-15 09:39:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.703, logit=20.125)', '\" The\"[578] (p=0.122, logit=18.375)', '\" X\"[1630] (p=0.074, logit=17.875)', '\" TR\"[5091] (p=0.035, logit=17.125)', '\" There\"[2684] (p=0.007, logit=15.562)']\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.574, logit=19.500)', '\" The\"[578] (p=0.165, logit=18.250)', '\" Football\"[21424] (p=0.146, logit=18.125)', '\" Ski\"[61595] (p=0.020, logit=16.125)', '\" It\"[1102] (p=0.008, logit=15.250)']\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.57421875, logit=19.5, token_id=4923, metadata=None))), (21424, (3, PredictedToken(token=' Football', prob=0.1455078125, logit=18.125, token_id=21424, metadata=None))), (30760, (42, PredictedToken(token=' Scar', prob=0.0003604888916015625, logit=12.125, token_id=30760, metadata=None))), (56491, (109, PredictedToken(token=' Piano', prob=6.67572021484375e-05, logit=10.4375, token_id=56491, metadata=None))), (46506, (163, PredictedToken(token=' Drum', prob=3.361701965332031e-05, logit=9.75, token_id=46506, metadata=None)))])\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.691, logit=19.875)', '\" The\"[578] (p=0.154, logit=18.375)', '\" Football\"[21424] (p=0.050, logit=17.250)', '\" There\"[2684] (p=0.009, logit=15.562)', '\" None\"[2290] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.69140625, logit=19.875, token_id=56491, metadata=None))), (21424, (3, PredictedToken(token=' Football', prob=0.050048828125, logit=17.25, token_id=21424, metadata=None))), (4923, (6, PredictedToken(token=' Sk', prob=0.0072021484375, logit=15.3125, token_id=4923, metadata=None))), (46506, (8, PredictedToken(token=' Drum', prob=0.00634765625, logit=15.1875, token_id=46506, metadata=None))), (30760, (14, PredictedToken(token=' Scar', prob=0.0024871826171875, logit=14.25, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:17 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:39:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.859, logit=21.500)', '\" Plum\"[84409] (p=0.055, logit=18.750)', '\" The\"[578] (p=0.048, logit=18.625)', '\" PE\"[22557] (p=0.010, logit=17.000)', '\" A\"[362] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.789, logit=20.750)', '\" The\"[578] (p=0.106, logit=18.750)', '\" A\"[362] (p=0.027, logit=17.375)', '\" Golf\"[28131] (p=0.013, logit=16.625)', '\" Tennis\"[58251] (p=0.011, logit=16.500)']\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.7890625, logit=20.75, token_id=432, metadata=None))), (28131, (4, PredictedToken(token=' Golf', prob=0.01275634765625, logit=16.625, token_id=28131, metadata=None))), (10164, (40, PredictedToken(token=' Water', prob=0.00018215179443359375, logit=12.375, token_id=10164, metadata=None))), (80629, (97, PredictedToken(token=' Grape', prob=4.601478576660156e-05, logit=11.0, token_id=80629, metadata=None))), (82452, (373, PredictedToken(token=' Jasmine', prob=4.559755325317383e-06, logit=8.6875, token_id=82452, metadata=None)))])\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.848, logit=20.125)', '\" Golf\"[28131] (p=0.048, logit=17.250)', '\" The\"[578] (p=0.023, logit=16.500)', '\" Grape\"[80629] (p=0.016, logit=16.125)', '\" WATER\"[76347] (p=0.008, logit=15.438)']\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.84765625, logit=20.125, token_id=10164, metadata=None))), (28131, (2, PredictedToken(token=' Golf', prob=0.0478515625, logit=17.25, token_id=28131, metadata=None))), (80629, (4, PredictedToken(token=' Grape', prob=0.0155029296875, logit=16.125, token_id=80629, metadata=None))), (432, (14, PredictedToken(token=' R', prob=0.0016326904296875, logit=13.875, token_id=432, metadata=None))), (82452, (37, PredictedToken(token=' Jasmine', prob=0.00026702880859375, logit=12.0625, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:18 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:18 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:39:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.617, logit=20.000)', '\" Hospital\"[15429] (p=0.258, logit=19.125)', '\" The\"[578] (p=0.051, logit=17.500)', '\" A\"[362] (p=0.016, logit=16.375)', '\" There\"[2684] (p=0.008, logit=15.688)']\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.844, logit=19.500)', '\" Magn\"[20918] (p=0.042, logit=16.500)', '\" The\"[578] (p=0.029, logit=16.125)', '\" Mall\"[32498] (p=0.013, logit=15.312)', '\" Book\"[6017] (p=0.008, logit=14.812)']\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.84375, logit=19.5, token_id=42609, metadata=None))), (20918, (2, PredictedToken(token=' Magn', prob=0.0419921875, logit=16.5, token_id=20918, metadata=None))), (32498, (4, PredictedToken(token=' Mall', prob=0.0128173828125, logit=15.3125, token_id=32498, metadata=None))), (6017, (5, PredictedToken(token=' Book', prob=0.007781982421875, logit=14.8125, token_id=6017, metadata=None))), (38571, (9, PredictedToken(token=' Theater', prob=0.004150390625, logit=14.1875, token_id=38571, metadata=None))), (47759, (12, PredictedToken(token=' Guitar', prob=0.0019683837890625, logit=13.4375, token_id=47759, metadata=None))), (24423, (111, PredictedToken(token=' Monitor', prob=4.9114227294921875e-05, logit=9.75, token_id=24423, metadata=None)))])\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.723, logit=19.875)', '\" Mall\"[32498] (p=0.111, logit=18.000)', '\" The\"[578] (p=0.059, logit=17.375)', '\" Magn\"[20918] (p=0.017, logit=16.125)', '\" THE\"[3247] (p=0.012, logit=15.812)']\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.72265625, logit=19.875, token_id=38571, metadata=None))), (32498, (2, PredictedToken(token=' Mall', prob=0.11083984375, logit=18.0, token_id=32498, metadata=None))), (20918, (4, PredictedToken(token=' Magn', prob=0.0169677734375, logit=16.125, token_id=20918, metadata=None))), (47759, (8, PredictedToken(token=' Guitar', prob=0.008544921875, logit=15.4375, token_id=47759, metadata=None))), (6017, (10, PredictedToken(token=' Book', prob=0.006256103515625, logit=15.125, token_id=6017, metadata=None))), (42609, (12, PredictedToken(token=' Pine', prob=0.002777099609375, logit=14.3125, token_id=42609, metadata=None))), (24423, (41, PredictedToken(token=' Monitor', prob=0.0001888275146484375, logit=11.625, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:19 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:19 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     patch_prediction=['\" Calculator\"[37128] (p=0.451, logit=19.500)', '\" P\"[393] (p=0.241, logit=18.875)', '\" The\"[578] (p=0.146, logit=18.375)', '\" A\"[362] (p=0.048, logit=17.250)', '\" None\"[2290] (p=0.020, logit=16.375)']\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.773, logit=20.750)', '\" Elephant\"[79189] (p=0.072, logit=18.375)', '\" The\"[578] (p=0.063, logit=18.250)', '\" BE\"[7354] (p=0.026, logit=17.375)', '\" There\"[2684] (p=0.021, logit=17.125)']\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.7734375, logit=20.75, token_id=24941, metadata=None))), (79189, (2, PredictedToken(token=' Elephant', prob=0.07177734375, logit=18.375, token_id=79189, metadata=None))), (18343, (84, PredictedToken(token=' Paper', prob=5.435943603515625e-05, logit=11.1875, token_id=18343, metadata=None))), (40975, (170, PredictedToken(token=' Marker', prob=1.5616416931152344e-05, logit=9.9375, token_id=40975, metadata=None))), (58403, (398, PredictedToken(token=' Tablet', prob=4.202127456665039e-06, logit=8.625, token_id=58403, metadata=None)))])\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.586, logit=20.250)', '\" Marker\"[40975] (p=0.312, logit=19.625)', '\" The\"[578] (p=0.033, logit=17.375)', '\" A\"[362] (p=0.018, logit=16.750)', '\" Bear\"[24941] (p=0.007, logit=15.812)']\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.5859375, logit=20.25, token_id=18343, metadata=None))), (40975, (2, PredictedToken(token=' Marker', prob=0.3125, logit=19.625, token_id=40975, metadata=None))), (24941, (5, PredictedToken(token=' Bear', prob=0.006927490234375, logit=15.8125, token_id=24941, metadata=None))), (79189, (9, PredictedToken(token=' Elephant', prob=0.0023956298828125, logit=14.75, token_id=79189, metadata=None))), (58403, (14, PredictedToken(token=' Tablet', prob=0.00093841552734375, logit=13.8125, token_id=58403, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:20 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:20 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:39:20 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.586, logit=19.375)', '\" Tennis\"[58251] (p=0.190, logit=18.250)', '\" The\"[578] (p=0.090, logit=17.500)', '\" HEL\"[38757] (p=0.023, logit=16.125)', '\" A\"[362] (p=0.014, logit=15.625)']\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.574, logit=20.625)', '\" Microwave\"[98641] (p=0.309, logit=20.000)', '\" The\"[578] (p=0.047, logit=18.125)', '\" An\"[1556] (p=0.017, logit=17.125)', '\" AIR\"[46994] (p=0.011, logit=16.625)']\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.57421875, logit=20.625, token_id=6690, metadata=None))), (98641, (2, PredictedToken(token=' Microwave', prob=0.30859375, logit=20.0, token_id=98641, metadata=None))), (22725, (10, PredictedToken(token=' Orange', prob=0.0017242431640625, logit=14.8125, token_id=22725, metadata=None))), (4923, (23, PredictedToken(token=' Sk', prob=0.000560760498046875, logit=13.6875, token_id=4923, metadata=None))), (16344, (113, PredictedToken(token=' Rose', prob=2.3126602172851562e-05, logit=10.5, token_id=16344, metadata=None))), (38258, (164, PredictedToken(token=' Baseball', prob=1.233816146850586e-05, logit=9.875, token_id=38258, metadata=None))), (14588, (192, PredictedToken(token=' Dog', prob=1.0251998901367188e-05, logit=9.6875, token_id=14588, metadata=None)))])\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     int_prediction=['\" Baseball\"[38258] (p=0.754, logit=19.875)', '\" The\"[578] (p=0.062, logit=17.375)', '\" Microwave\"[98641] (p=0.038, logit=16.875)', '\" Orange\"[22725] (p=0.029, logit=16.625)', '\" Sk\"[4923] (p=0.018, logit=16.125)']\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     int_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.75390625, logit=19.875, token_id=38258, metadata=None))), (98641, (3, PredictedToken(token=' Microwave', prob=0.03759765625, logit=16.875, token_id=98641, metadata=None))), (22725, (4, PredictedToken(token=' Orange', prob=0.029296875, logit=16.625, token_id=22725, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.0177001953125, logit=16.125, token_id=4923, metadata=None))), (16344, (6, PredictedToken(token=' Rose', prob=0.0101318359375, logit=15.5625, token_id=16344, metadata=None))), (14588, (9, PredictedToken(token=' Dog', prob=0.005096435546875, logit=14.875, token_id=14588, metadata=None))), (6690, (424, PredictedToken(token=' Air', prob=6.735324859619141e-06, logit=8.25, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:21 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.828, logit=20.000)', '\" The\"[578] (p=0.053, logit=17.250)', '\" A\"[362] (p=0.025, logit=16.500)', '\" Chain\"[29625] (p=0.022, logit=16.375)', '\" ring\"[10264] (p=0.008, logit=15.312)']\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.840, logit=21.000)', '\" The\"[578] (p=0.047, logit=18.125)', '\" BAT\"[79081] (p=0.029, logit=17.625)', '\" Tub\"[40640] (p=0.017, logit=17.125)', '\" A\"[362] (p=0.014, logit=16.875)']\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.83984375, logit=21.0, token_id=16488, metadata=None))), (23262, (6, PredictedToken(token=' Comb', prob=0.00933837890625, logit=16.5, token_id=23262, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.0038909912109375, logit=15.625, token_id=356, metadata=None))), (57915, (14, PredictedToken(token=' Ank', prob=0.0013427734375, logit=14.5625, token_id=57915, metadata=None))), (61948, (150, PredictedToken(token=' Sofa', prob=1.6927719116210938e-05, logit=10.1875, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     int_prediction=['\" Ank\"[57915] (p=0.447, logit=19.875)', '\" C\"[356] (p=0.395, logit=19.750)', '\" The\"[578] (p=0.053, logit=17.750)', '\" Bat\"[16488] (p=0.022, logit=16.875)', '\" Comb\"[23262] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     int_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.447265625, logit=19.875, token_id=57915, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.39453125, logit=19.75, token_id=356, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.022216796875, logit=16.875, token_id=16488, metadata=None))), (23262, (5, PredictedToken(token=' Comb', prob=0.010498046875, logit=16.125, token_id=23262, metadata=None))), (61948, (28, PredictedToken(token=' Sofa', prob=0.0004329681396484375, logit=12.9375, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:22 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:22 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:39:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.855, logit=20.250)', '\" The\"[578] (p=0.062, logit=17.625)', '\" Comb\"[23262] (p=0.009, logit=15.688)', '\" Rose\"[16344] (p=0.009, logit=15.688)', '\" C\"[356] (p=0.008, logit=15.625)']\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.844, logit=20.625)', '\" Toilet\"[82994] (p=0.089, logit=18.375)', '\" The\"[578] (p=0.022, logit=17.000)', '\" TO\"[5257] (p=0.004, logit=15.375)', '\" Shower\"[48471] (p=0.004, logit=15.188)']\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.84375, logit=20.625, token_id=41493, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.0888671875, logit=18.375, token_id=82994, metadata=None))), (921, (12, PredictedToken(token=' Ch', prob=0.0009918212890625, logit=13.875, token_id=921, metadata=None))), (74574, (16, PredictedToken(token=' Violet', prob=0.00067901611328125, logit=13.5, token_id=74574, metadata=None)))])\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.836, logit=21.375)', '\" Tow\"[41493] (p=0.113, logit=19.375)', '\" Ch\"[921] (p=0.010, logit=17.000)', '\" The\"[578] (p=0.010, logit=17.000)', '\" Toilet\"[82994] (p=0.008, logit=16.750)']\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.8359375, logit=21.375, token_id=74574, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.11279296875, logit=19.375, token_id=41493, metadata=None))), (921, (4, PredictedToken(token=' Ch', prob=0.010498046875, logit=17.0, token_id=921, metadata=None))), (82994, (5, PredictedToken(token=' Toilet', prob=0.0081787109375, logit=16.75, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:23 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:39:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     patch_prediction=['\" Harmon\"[40759] (p=0.539, logit=20.125)', '\" The\"[578] (p=0.226, logit=19.250)', '\" C\"[356] (p=0.154, logit=18.875)', '\" A\"[362] (p=0.013, logit=16.375)', '\" There\"[2684] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     clean_prediction=['\" Caul\"[90538] (p=0.953, logit=21.875)', '\" The\"[578] (p=0.015, logit=17.750)', '\" Bro\"[6031] (p=0.004, logit=16.375)', '\" Dog\"[14588] (p=0.003, logit=16.250)', '\" There\"[2684] (p=0.003, logit=16.000)']\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     clean_track=OrderedDict([(90538, (1, PredictedToken(token=' Caul', prob=0.953125, logit=21.875, token_id=90538, metadata=None))), (14588, (4, PredictedToken(token=' Dog', prob=0.003448486328125, logit=16.25, token_id=14588, metadata=None))), (41785, (7, PredictedToken(token=' Spin', prob=0.0023651123046875, logit=15.875, token_id=41785, metadata=None))), (94467, (20, PredictedToken(token=' Trom', prob=0.000194549560546875, logit=13.375, token_id=94467, metadata=None))), (4923, (83, PredictedToken(token=' Sk', prob=2.467632293701172e-05, logit=11.3125, token_id=4923, metadata=None))), (3420, (178, PredictedToken(token=' Trump', prob=6.645917892456055e-06, logit=10.0, token_id=3420, metadata=None)))])\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     int_prediction=['\" Trom\"[94467] (p=0.436, logit=19.625)', '\" Trump\"[3420] (p=0.299, logit=19.250)', '\" The\"[578] (p=0.160, logit=18.625)', '\" TR\"[5091] (p=0.017, logit=16.375)', '\" A\"[362] (p=0.017, logit=16.375)']\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     int_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.435546875, logit=19.625, token_id=94467, metadata=None))), (3420, (2, PredictedToken(token=' Trump', prob=0.298828125, logit=19.25, token_id=3420, metadata=None))), (41785, (10, PredictedToken(token=' Spin', prob=0.0031280517578125, logit=14.6875, token_id=41785, metadata=None))), (14588, (15, PredictedToken(token=' Dog', prob=0.001220703125, logit=13.75, token_id=14588, metadata=None))), (90538, (16, PredictedToken(token=' Caul', prob=0.00115203857421875, logit=13.6875, token_id=90538, metadata=None))), (4923, (87, PredictedToken(token=' Sk', prob=7.82012939453125e-05, logit=11.0, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:24 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     patch_prediction=['\" Sco\"[50159] (p=0.398, logit=19.125)', '\" Boat\"[45332] (p=0.352, logit=19.000)', '\" The\"[578] (p=0.114, logit=17.875)', '\" There\"[2684] (p=0.026, logit=16.375)', '\" A\"[362] (p=0.026, logit=16.375)']\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.750, logit=20.500)', '\" The\"[578] (p=0.115, logit=18.625)', '\" Orch\"[55405] (p=0.037, logit=17.500)', '\" sun\"[7160] (p=0.012, logit=16.375)', '\" There\"[2684] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.75, logit=20.5, token_id=8219, metadata=None))), (55405, (3, PredictedToken(token=' Orch', prob=0.037353515625, logit=17.5, token_id=55405, metadata=None))), (16183, (7, PredictedToken(token=' Hel', prob=0.00836181640625, logit=16.0, token_id=16183, metadata=None))), (13000, (16, PredictedToken(token=' Van', prob=0.00128173828125, logit=14.125, token_id=13000, metadata=None))), (16478, (538, PredictedToken(token=' Chair', prob=2.9802322387695312e-06, logit=8.0625, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.820, logit=20.875)', '\" The\"[578] (p=0.067, logit=18.375)', '\" VAN\"[97753] (p=0.022, logit=17.250)', '\" Hel\"[16183] (p=0.015, logit=16.875)', '\" There\"[2684] (p=0.013, logit=16.750)']\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.8203125, logit=20.875, token_id=13000, metadata=None))), (16183, (4, PredictedToken(token=' Hel', prob=0.0150146484375, logit=16.875, token_id=16183, metadata=None))), (55405, (7, PredictedToken(token=' Orch', prob=0.007110595703125, logit=16.125, token_id=55405, metadata=None))), (16478, (26, PredictedToken(token=' Chair', prob=0.0003528594970703125, logit=13.125, token_id=16478, metadata=None))), (8219, (53, PredictedToken(token=' Sun', prob=0.0001010894775390625, logit=11.875, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:25 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.809, logit=20.125)', '\" The\"[578] (p=0.075, logit=17.750)', '\" A\"[362] (p=0.031, logit=16.875)', '\" Helmet\"[67629] (p=0.017, logit=16.250)', '\" Tennis\"[58251] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:39:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.852, logit=20.750)', '\" The\"[578] (p=0.070, logit=18.250)', '\" Suit\"[33711] (p=0.026, logit=17.250)', '\" A\"[362] (p=0.011, logit=16.375)', '\" jacket\"[27300] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.8515625, logit=20.75, token_id=55870, metadata=None))), (33711, (3, PredictedToken(token=' Suit', prob=0.0257568359375, logit=17.25, token_id=33711, metadata=None))), (11683, (8, PredictedToken(token=' Acc', prob=0.0025482177734375, logit=14.9375, token_id=11683, metadata=None))), (100031, (32, PredictedToken(token=' Mosque', prob=0.0002689361572265625, logit=12.6875, token_id=100031, metadata=None))), (38258, (34, PredictedToken(token=' Baseball', prob=0.00023651123046875, logit=12.5625, token_id=38258, metadata=None))), (47589, (53, PredictedToken(token=' Basketball', prob=0.00012683868408203125, logit=11.9375, token_id=47589, metadata=None)))])\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     int_prediction=['\" Acc\"[11683] (p=0.482, logit=18.875)', '\" Jacket\"[55870] (p=0.156, logit=17.750)', '\" Baseball\"[38258] (p=0.156, logit=17.750)', '\" The\"[578] (p=0.074, logit=17.000)', '\" BASE\"[22984] (p=0.014, logit=15.312)']\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     int_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.482421875, logit=18.875, token_id=11683, metadata=None))), (38258, (2, PredictedToken(token=' Baseball', prob=0.15625, logit=17.75, token_id=38258, metadata=None))), (55870, (3, PredictedToken(token=' Jacket', prob=0.15625, logit=17.75, token_id=55870, metadata=None))), (47589, (8, PredictedToken(token=' Basketball', prob=0.0064697265625, logit=14.5625, token_id=47589, metadata=None))), (33711, (11, PredictedToken(token=' Suit', prob=0.004180908203125, logit=14.125, token_id=33711, metadata=None))), (100031, (27, PredictedToken(token=' Mosque', prob=0.00119781494140625, logit=12.875, token_id=100031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:26 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:26 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.770, logit=20.250)', '\" The\"[578] (p=0.118, logit=18.375)', '\" T\"[350] (p=0.026, logit=16.875)', '\" Lion\"[33199] (p=0.018, logit=16.500)', '\" There\"[2684] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:39:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     clean_prediction=['\" Stap\"[63606] (p=0.758, logit=20.125)', '\" The\"[578] (p=0.132, logit=18.375)', '\" A\"[362] (p=0.038, logit=17.125)', '\" ST\"[4015] (p=0.010, logit=15.750)', '\" Marker\"[40975] (p=0.007, logit=15.500)']\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     clean_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.7578125, logit=20.125, token_id=63606, metadata=None))), (40975, (5, PredictedToken(token=' Marker', prob=0.0074462890625, logit=15.5, token_id=40975, metadata=None))), (57225, (8, PredictedToken(token=' Laptop', prob=0.002410888671875, logit=14.375, token_id=57225, metadata=None))), (34392, (23, PredictedToken(token=' Horse', prob=0.000652313232421875, logit=13.0625, token_id=34392, metadata=None))), (68027, (31, PredictedToken(token=' Sax', prob=0.000446319580078125, logit=12.6875, token_id=68027, metadata=None))), (1901, (44, PredictedToken(token=' Z', prob=0.0001983642578125, logit=11.875, token_id=1901, metadata=None))), (40090, (114, PredictedToken(token=' Pressure', prob=5.340576171875e-05, logit=10.5625, token_id=40090, metadata=None)))])\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.816, logit=20.000)', '\" The\"[578] (p=0.076, logit=17.625)', '\" Horse\"[34392] (p=0.028, logit=16.625)', '\" A\"[362] (p=0.017, logit=16.125)', '\" Ze\"[10120] (p=0.008, logit=15.375)']\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.81640625, logit=20.0, token_id=1901, metadata=None))), (34392, (3, PredictedToken(token=' Horse', prob=0.0279541015625, logit=16.625, token_id=34392, metadata=None))), (68027, (7, PredictedToken(token=' Sax', prob=0.0040283203125, logit=14.6875, token_id=68027, metadata=None))), (63606, (17, PredictedToken(token=' Stap', prob=0.00101470947265625, logit=13.3125, token_id=63606, metadata=None))), (57225, (43, PredictedToken(token=' Laptop', prob=0.000213623046875, logit=11.75, token_id=57225, metadata=None))), (40090, (54, PredictedToken(token=' Pressure', prob=0.000156402587890625, logit=11.4375, token_id=40090, metadata=None))), (40975, (57, PredictedToken(token=' Marker', prob=0.0001468658447265625, logit=11.375, token_id=40975, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:27 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:27 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.746, logit=20.750)', '\" The\"[578] (p=0.147, logit=19.125)', '\" Viol\"[30555] (p=0.037, logit=17.750)', '\" TR\"[5091] (p=0.020, logit=17.125)', '\" A\"[362] (p=0.006, logit=15.875)']\n",
      "2025-09-15 09:39:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     clean_prediction=['\" Sheep\"[84008] (p=0.605, logit=19.875)', '\" The\"[578] (p=0.153, logit=18.500)', '\" SHE\"[54695] (p=0.119, logit=18.250)', '\" Rabbit\"[49431] (p=0.021, logit=16.500)', '\" A\"[362] (p=0.016, logit=16.250)']\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     clean_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.60546875, logit=19.875, token_id=84008, metadata=None))), (49431, (4, PredictedToken(token=' Rabbit', prob=0.0206298828125, logit=16.5, token_id=49431, metadata=None))), (40759, (45, PredictedToken(token=' Harmon', prob=0.0002956390380859375, logit=12.25, token_id=40759, metadata=None))), (11683, (61, PredictedToken(token=' Acc', prob=0.0001678466796875, logit=11.6875, token_id=11683, metadata=None))), (8868, (105, PredictedToken(token=' Blue', prob=7.009506225585938e-05, logit=10.8125, token_id=8868, metadata=None))), (34046, (625, PredictedToken(token=' Cabinet', prob=4.082918167114258e-06, logit=7.96875, token_id=34046, metadata=None)))])\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     int_prediction=['\" Acc\"[11683] (p=0.332, logit=18.375)', '\" Harmon\"[40759] (p=0.228, logit=18.000)', '\" The\"[578] (p=0.122, logit=17.375)', '\" Sheep\"[84008] (p=0.084, logit=17.000)', '\" ACC\"[26925] (p=0.051, logit=16.500)']\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     int_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.33203125, logit=18.375, token_id=11683, metadata=None))), (40759, (2, PredictedToken(token=' Harmon', prob=0.2275390625, logit=18.0, token_id=40759, metadata=None))), (84008, (4, PredictedToken(token=' Sheep', prob=0.083984375, logit=17.0, token_id=84008, metadata=None))), (49431, (14, PredictedToken(token=' Rabbit', prob=0.0036773681640625, logit=13.875, token_id=49431, metadata=None))), (8868, (38, PredictedToken(token=' Blue', prob=0.000499725341796875, logit=11.875, token_id=8868, metadata=None))), (34046, (249, PredictedToken(token=' Cabinet', prob=3.838539123535156e-05, logit=9.3125, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:28 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.641, logit=19.500)', '\" The\"[578] (p=0.236, logit=18.500)', '\" A\"[362] (p=0.018, logit=15.938)', '\" PE\"[22557] (p=0.016, logit=15.812)', '\" pe\"[1069] (p=0.007, logit=15.000)']\n",
      "2025-09-15 09:39:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     clean_prediction=['\" Bed\"[13394] (p=0.754, logit=19.500)', '\" The\"[578] (p=0.116, logit=17.625)', '\" BED\"[83364] (p=0.016, logit=15.625)', '\" It\"[1102] (p=0.013, logit=15.438)', '\" Bench\"[36358] (p=0.011, logit=15.250)']\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     clean_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.75390625, logit=19.5, token_id=13394, metadata=None))), (36358, (5, PredictedToken(token=' Bench', prob=0.0107421875, logit=15.25, token_id=36358, metadata=None))), (72392, (15, PredictedToken(token=' Mixer', prob=0.00225830078125, logit=13.6875, token_id=72392, metadata=None))), (48390, (32, PredictedToken(token=' Lily', prob=0.000568389892578125, logit=12.3125, token_id=48390, metadata=None))), (74574, (42, PredictedToken(token=' Violet', prob=0.0004177093505859375, logit=12.0, token_id=74574, metadata=None)))])\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.898, logit=20.125)', '\" The\"[578] (p=0.040, logit=17.000)', '\" Lily\"[48390] (p=0.010, logit=15.625)', '\" It\"[1102] (p=0.005, logit=14.938)', '\" violet\"[80836] (p=0.004, logit=14.812)']\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.8984375, logit=20.125, token_id=74574, metadata=None))), (48390, (3, PredictedToken(token=' Lily', prob=0.010009765625, logit=15.625, token_id=48390, metadata=None))), (13394, (8, PredictedToken(token=' Bed', prob=0.0036773681640625, logit=14.625, token_id=13394, metadata=None))), (36358, (24, PredictedToken(token=' Bench', prob=0.0003871917724609375, logit=12.375, token_id=36358, metadata=None))), (72392, (68, PredictedToken(token=' Mixer', prob=9.202957153320312e-05, logit=10.9375, token_id=72392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:29 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:29 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.836, logit=20.375)', '\" The\"[578] (p=0.047, logit=17.500)', '\" HEAD\"[34180] (p=0.029, logit=17.000)', '\" Speaker\"[30173] (p=0.020, logit=16.625)', '\" None\"[2290] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:39:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.688, logit=19.375)', '\" Pine\"[42609] (p=0.093, logit=17.375)', '\" The\"[578] (p=0.093, logit=17.375)', '\" Phone\"[14642] (p=0.022, logit=15.938)', '\" A\"[362] (p=0.010, logit=15.125)']\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.6875, logit=19.375, token_id=65449, metadata=None))), (42609, (3, PredictedToken(token=' Pine', prob=0.09326171875, logit=17.375, token_id=42609, metadata=None))), (14642, (4, PredictedToken(token=' Phone', prob=0.0220947265625, logit=15.9375, token_id=14642, metadata=None))), (24423, (11, PredictedToken(token=' Monitor', prob=0.0028076171875, logit=13.875, token_id=24423, metadata=None))), (23462, (55, PredictedToken(token=' Stadium', prob=0.000278472900390625, logit=11.5625, token_id=23462, metadata=None))), (94467, (57, PredictedToken(token=' Trom', prob=0.000278472900390625, logit=11.5625, token_id=94467, metadata=None)))])\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.812, logit=20.625)', '\" The\"[578] (p=0.059, logit=18.000)', '\" Pine\"[42609] (p=0.036, logit=17.500)', '\" A\"[362] (p=0.019, logit=16.875)', '\" PHONE\"[92183] (p=0.013, logit=16.500)']\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.8125, logit=20.625, token_id=14642, metadata=None))), (42609, (3, PredictedToken(token=' Pine', prob=0.035888671875, logit=17.5, token_id=42609, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.007049560546875, logit=15.875, token_id=24423, metadata=None))), (94467, (32, PredictedToken(token=' Trom', prob=0.0002899169921875, logit=12.6875, token_id=94467, metadata=None))), (23462, (40, PredictedToken(token=' Stadium', prob=0.00021266937255859375, logit=12.375, token_id=23462, metadata=None))), (65449, (98, PredictedToken(token=' Willow', prob=4.458427429199219e-05, logit=10.8125, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:30 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.586, logit=19.250)', '\" Tow\"[41493] (p=0.131, logit=17.750)', '\" The\"[578] (p=0.070, logit=17.125)', '\" JE\"[71430] (p=0.048, logit=16.750)', '\" Sk\"[4923] (p=0.042, logit=16.625)']\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.797, logit=20.375)', '\" Gloves\"[68554] (p=0.035, logit=17.250)', '\" The\"[578] (p=0.035, logit=17.250)', '\" Sh\"[1443] (p=0.021, logit=16.750)', '\" S\"[328] (p=0.017, logit=16.500)']\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.796875, logit=20.375, token_id=57551, metadata=None))), (68554, (3, PredictedToken(token=' Gloves', prob=0.03515625, logit=17.25, token_id=68554, metadata=None))), (1443, (4, PredictedToken(token=' Sh', prob=0.021240234375, logit=16.75, token_id=1443, metadata=None))), (30760, (25, PredictedToken(token=' Scar', prob=0.000568389892578125, logit=13.125, token_id=30760, metadata=None))), (44570, (65, PredictedToken(token=' Maple', prob=0.00017261505126953125, logit=11.9375, token_id=44570, metadata=None)))])\n",
      "2025-09-15 09:39:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.852, logit=20.250)', '\" Sh\"[1443] (p=0.018, logit=16.375)', '\" The\"[578] (p=0.018, logit=16.375)', '\" Scar\"[30760] (p=0.014, logit=16.125)', '\" None\"[2290] (p=0.011, logit=15.938)']\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.8515625, logit=20.25, token_id=68554, metadata=None))), (1443, (3, PredictedToken(token=' Sh', prob=0.0177001953125, logit=16.375, token_id=1443, metadata=None))), (30760, (4, PredictedToken(token=' Scar', prob=0.01373291015625, logit=16.125, token_id=30760, metadata=None))), (57551, (7, PredictedToken(token=' Sink', prob=0.00836181640625, logit=15.625, token_id=57551, metadata=None))), (44570, (39, PredictedToken(token=' Maple', prob=0.000286102294921875, logit=12.25, token_id=44570, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:31 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     patch_prediction=['\" Acc\"[11683] (p=0.887, logit=21.000)', '\" The\"[578] (p=0.073, logit=18.500)', '\" Accord\"[80657] (p=0.005, logit=15.812)', '\" Piano\"[56491] (p=0.004, logit=15.562)', '\" ACC\"[26925] (p=0.004, logit=15.562)']\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.812, logit=20.250)', '\" E\"[469] (p=0.052, logit=17.500)', '\" The\"[578] (p=0.041, logit=17.250)', '\" There\"[2684] (p=0.022, logit=16.625)', '\" C\"[356] (p=0.015, logit=16.250)']\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.8125, logit=20.25, token_id=79028, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.052001953125, logit=17.5, token_id=469, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.014892578125, logit=16.25, token_id=356, metadata=None))), (40759, (21, PredictedToken(token=' Harmon', prob=0.00054168701171875, logit=12.9375, token_id=40759, metadata=None))), (38571, (221, PredictedToken(token=' Theater', prob=1.4424324035644531e-05, logit=9.3125, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.762, logit=20.250)', '\" Hick\"[79028] (p=0.080, logit=18.000)', '\" The\"[578] (p=0.055, logit=17.625)', '\" E\"[469] (p=0.018, logit=16.500)', '\" There\"[2684] (p=0.016, logit=16.375)']\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.76171875, logit=20.25, token_id=356, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.080078125, logit=18.0, token_id=79028, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.017822265625, logit=16.5, token_id=469, metadata=None))), (40759, (7, PredictedToken(token=' Harmon', prob=0.01019287109375, logit=15.9375, token_id=40759, metadata=None))), (38571, (21, PredictedToken(token=' Theater', prob=0.000576019287109375, logit=13.0625, token_id=38571, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:31 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:31 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:39:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     patch_prediction=['\" B\"[426] (p=0.762, logit=20.625)', '\" The\"[578] (p=0.133, logit=18.875)', '\" A\"[362] (p=0.023, logit=17.125)', '\" b\"[293] (p=0.020, logit=17.000)', '\" It\"[1102] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.570, logit=19.875)', '\" Library\"[11896] (p=0.145, logit=18.500)', '\" The\"[578] (p=0.100, logit=18.125)', '\" HOUSE\"[69461] (p=0.053, logit=17.500)', '\" There\"[2684] (p=0.028, logit=16.875)']\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.5703125, logit=19.875, token_id=4783, metadata=None))), (11896, (2, PredictedToken(token=' Library', prob=0.14453125, logit=18.5, token_id=11896, metadata=None))), (6031, (7, PredictedToken(token=' Bro', prob=0.0118408203125, logit=16.0, token_id=6031, metadata=None))), (69755, (9, PredictedToken(token=' Notebook', prob=0.00921630859375, logit=15.75, token_id=69755, metadata=None))), (98641, (17, PredictedToken(token=' Microwave', prob=0.00103759765625, logit=13.5625, token_id=98641, metadata=None))), (86460, (37, PredictedToken(token=' Necklace', prob=0.0003814697265625, logit=12.5625, token_id=86460, metadata=None)))])\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.871, logit=21.000)', '\" A\"[362] (p=0.038, logit=17.875)', '\" The\"[578] (p=0.023, logit=17.375)', '\" There\"[2684] (p=0.012, logit=16.750)', '\" BRO\"[78687] (p=0.010, logit=16.500)']\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.87109375, logit=21.0, token_id=6031, metadata=None))), (98641, (6, PredictedToken(token=' Microwave', prob=0.00518798828125, logit=15.875, token_id=98641, metadata=None))), (11896, (9, PredictedToken(token=' Library', prob=0.0040283203125, logit=15.625, token_id=11896, metadata=None))), (86460, (10, PredictedToken(token=' Necklace', prob=0.0040283203125, logit=15.625, token_id=86460, metadata=None))), (4783, (11, PredictedToken(token=' House', prob=0.0021514892578125, logit=15.0, token_id=4783, metadata=None))), (69755, (14, PredictedToken(token=' Notebook', prob=0.0009002685546875, logit=14.125, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:32 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.879, logit=21.750)', '\" The\"[578] (p=0.064, logit=19.125)', '\" Monkey\"[58937] (p=0.018, logit=17.875)', '\" A\"[362] (p=0.009, logit=17.125)', '\" There\"[2684] (p=0.005, logit=16.500)']\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     clean_prediction=['\" Soap\"[61731] (p=0.723, logit=20.000)', '\" Toilet\"[82994] (p=0.143, logit=18.375)', '\" SOAP\"[64332] (p=0.032, logit=16.875)', '\" The\"[578] (p=0.028, logit=16.750)', '\" TO\"[5257] (p=0.010, logit=15.750)']\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     clean_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.72265625, logit=20.0, token_id=61731, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.142578125, logit=18.375, token_id=82994, metadata=None))), (36845, (9, PredictedToken(token=' Tiger', prob=0.003143310546875, logit=14.5625, token_id=36845, metadata=None))), (96096, (10, PredictedToken(token=' Dolphin', prob=0.003143310546875, logit=14.5625, token_id=96096, metadata=None))), (45332, (30, PredictedToken(token=' Boat', prob=0.000453948974609375, logit=12.625, token_id=45332, metadata=None)))])\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.746, logit=20.125)', '\" Tiger\"[36845] (p=0.089, logit=18.000)', '\" Toilet\"[82994] (p=0.054, logit=17.500)', '\" The\"[578] (p=0.026, logit=16.750)', '\" A\"[362] (p=0.010, logit=15.812)']\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.74609375, logit=20.125, token_id=96096, metadata=None))), (36845, (2, PredictedToken(token=' Tiger', prob=0.08935546875, logit=18.0, token_id=36845, metadata=None))), (82994, (3, PredictedToken(token=' Toilet', prob=0.05419921875, logit=17.5, token_id=82994, metadata=None))), (61731, (8, PredictedToken(token=' Soap', prob=0.0064697265625, logit=15.375, token_id=61731, metadata=None))), (45332, (10, PredictedToken(token=' Boat', prob=0.00537109375, logit=15.1875, token_id=45332, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:33 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     patch_prediction=['\" Cherry\"[45805] (p=0.695, logit=19.875)', '\" The\"[578] (p=0.137, logit=18.250)', '\" Strawberry\"[89077] (p=0.039, logit=17.000)', '\" CH\"[6969] (p=0.027, logit=16.625)', '\" There\"[2684] (p=0.024, logit=16.500)']\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     clean_prediction=['\" Smart\"[16147] (p=0.719, logit=20.000)', '\" Printer\"[47033] (p=0.097, logit=18.000)', '\" The\"[578] (p=0.097, logit=18.000)', '\" A\"[362] (p=0.025, logit=16.625)', '\" SMART\"[80708] (p=0.007, logit=15.312)']\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     clean_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.71875, logit=20.0, token_id=16147, metadata=None))), (47033, (3, PredictedToken(token=' Printer', prob=0.09716796875, logit=18.0, token_id=47033, metadata=None))), (80629, (31, PredictedToken(token=' Grape', prob=0.00051116943359375, logit=12.75, token_id=80629, metadata=None))), (10164, (48, PredictedToken(token=' Water', prob=0.00019931793212890625, logit=11.8125, token_id=10164, metadata=None))), (68554, (97, PredictedToken(token=' Gloves', prob=6.103515625e-05, logit=10.625, token_id=68554, metadata=None)))])\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.836, logit=20.250)', '\" Water\"[10164] (p=0.053, logit=17.500)', '\" The\"[578] (p=0.037, logit=17.125)', '\" GRA\"[65120] (p=0.014, logit=16.125)', '\" There\"[2684] (p=0.006, logit=15.312)']\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.8359375, logit=20.25, token_id=80629, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.053466796875, logit=17.5, token_id=10164, metadata=None))), (68554, (14, PredictedToken(token=' Gloves', prob=0.00125885009765625, logit=13.75, token_id=68554, metadata=None))), (47033, (21, PredictedToken(token=' Printer', prob=0.0007171630859375, logit=13.1875, token_id=47033, metadata=None))), (16147, (121, PredictedToken(token=' Smart', prob=3.5762786865234375e-05, logit=10.1875, token_id=16147, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:34 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:34 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     patch_prediction=['\" Binder\"[91263] (p=0.793, logit=21.000)', '\" Paper\"[18343] (p=0.107, logit=19.000)', '\" The\"[578] (p=0.040, logit=18.000)', '\" Car\"[3341] (p=0.009, logit=16.500)', '\" A\"[362] (p=0.009, logit=16.500)']\n",
      "2025-09-15 09:39:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.629, logit=19.625)', '\" Football\"[21424] (p=0.159, logit=18.250)', '\" The\"[578] (p=0.097, logit=17.750)', '\" A\"[362] (p=0.046, logit=17.000)', '\" Spin\"[41785] (p=0.007, logit=15.125)']\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.62890625, logit=19.625, token_id=423, metadata=None))), (21424, (2, PredictedToken(token=' Football', prob=0.1591796875, logit=18.25, token_id=21424, metadata=None))), (41785, (5, PredictedToken(token=' Spin', prob=0.00701904296875, logit=15.125, token_id=41785, metadata=None))), (18343, (17, PredictedToken(token=' Paper', prob=0.0012969970703125, logit=13.4375, token_id=18343, metadata=None))), (36943, (68, PredictedToken(token=' Folder', prob=0.00012063980102539062, logit=11.0625, token_id=36943, metadata=None)))])\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.770, logit=20.000)', '\" The\"[578] (p=0.056, logit=17.375)', '\" A\"[362] (p=0.034, logit=16.875)', '\" None\"[2290] (p=0.023, logit=16.500)', '\" Paper\"[18343] (p=0.021, logit=16.375)']\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.76953125, logit=20.0, token_id=36943, metadata=None))), (18343, (5, PredictedToken(token=' Paper', prob=0.0205078125, logit=16.375, token_id=18343, metadata=None))), (21424, (7, PredictedToken(token=' Football', prob=0.0159912109375, logit=16.125, token_id=21424, metadata=None))), (41785, (8, PredictedToken(token=' Spin', prob=0.0096435546875, logit=15.625, token_id=41785, metadata=None))), (423, (12, PredictedToken(token=' D', prob=0.00244140625, logit=14.25, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:35 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.637, logit=19.375)', '\" The\"[578] (p=0.098, logit=17.500)', '\" C\"[356] (p=0.076, logit=17.250)', '\" There\"[2684] (p=0.046, logit=16.750)', '\" None\"[2290] (p=0.028, logit=16.250)']\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.688, logit=19.875)', '\" School\"[6150] (p=0.135, logit=18.250)', '\" The\"[578] (p=0.072, logit=17.625)', '\" A\"[362] (p=0.021, logit=16.375)', '\" E\"[469] (p=0.013, logit=15.938)']\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.6875, logit=19.875, token_id=16730, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.134765625, logit=18.25, token_id=6150, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.01336669921875, logit=15.9375, token_id=469, metadata=None))), (78703, (11, PredictedToken(token=' Potato', prob=0.0020599365234375, logit=14.0625, token_id=78703, metadata=None))), (47643, (16, PredictedToken(token=' Cel', prob=0.0013275146484375, logit=13.625, token_id=47643, metadata=None)))])\n",
      "2025-09-15 09:39:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.354, logit=18.625)', '\" Potato\"[78703] (p=0.243, logit=18.250)', '\" Museum\"[16730] (p=0.102, logit=17.375)', '\" The\"[578] (p=0.089, logit=17.250)', '\" E\"[469] (p=0.062, logit=16.875)']\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.353515625, logit=18.625, token_id=47643, metadata=None))), (78703, (2, PredictedToken(token=' Potato', prob=0.2431640625, logit=18.25, token_id=78703, metadata=None))), (16730, (3, PredictedToken(token=' Museum', prob=0.1015625, logit=17.375, token_id=16730, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.0615234375, logit=16.875, token_id=469, metadata=None))), (6150, (19, PredictedToken(token=' School', prob=0.002105712890625, logit=13.5, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:36 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.660, logit=19.875)', '\" Bear\"[24941] (p=0.189, logit=18.625)', '\" The\"[578] (p=0.042, logit=17.125)', '\" A\"[362] (p=0.020, logit=16.375)', '\" There\"[2684] (p=0.014, logit=16.000)']\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.770, logit=20.875)', '\" Comb\"[23262] (p=0.134, logit=19.125)', '\" TO\"[5257] (p=0.030, logit=17.625)', '\" The\"[578] (p=0.021, logit=17.250)', '\" None\"[2290] (p=0.008, logit=16.250)']\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.76953125, logit=20.875, token_id=83499, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.1337890625, logit=19.125, token_id=23262, metadata=None))), (22607, (25, PredictedToken(token=' Cow', prob=0.0003528594970703125, logit=13.1875, token_id=22607, metadata=None))), (36895, (26, PredictedToken(token=' Eagle', prob=0.0003299713134765625, logit=13.125, token_id=36895, metadata=None))), (47643, (121, PredictedToken(token=' Cel', prob=3.719329833984375e-05, logit=10.9375, token_id=47643, metadata=None)))])\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.668, logit=20.125)', '\" Comb\"[23262] (p=0.149, logit=18.625)', '\" The\"[578] (p=0.038, logit=17.250)', '\" Eagle\"[36895] (p=0.029, logit=17.000)', '\" None\"[2290] (p=0.020, logit=16.625)']\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.66796875, logit=20.125, token_id=22607, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.1494140625, logit=18.625, token_id=23262, metadata=None))), (36895, (4, PredictedToken(token=' Eagle', prob=0.029296875, logit=17.0, token_id=36895, metadata=None))), (47643, (7, PredictedToken(token=' Cel', prob=0.0101318359375, logit=15.9375, token_id=47643, metadata=None))), (83499, (8, PredictedToken(token=' Tooth', prob=0.00787353515625, logit=15.6875, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:36 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.402, logit=19.625)', '\" Theater\"[38571] (p=0.355, logit=19.500)', '\" The\"[578] (p=0.102, logit=18.250)', '\" A\"[362] (p=0.033, logit=17.125)', '\" To\"[2057] (p=0.026, logit=16.875)']\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.598, logit=20.500)', '\" The\"[578] (p=0.250, logit=19.625)', '\" Refriger\"[75258] (p=0.063, logit=18.250)', '\" A\"[362] (p=0.043, logit=17.875)', '\" It\"[1102] (p=0.004, logit=15.500)']\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.59765625, logit=20.5, token_id=735, metadata=None))), (75258, (3, PredictedToken(token=' Refriger', prob=0.06298828125, logit=18.25, token_id=75258, metadata=None))), (72683, (28, PredictedToken(token=' Boxing', prob=0.0004825592041015625, logit=13.375, token_id=72683, metadata=None))), (15429, (175, PredictedToken(token=' Hospital', prob=1.5497207641601562e-05, logit=9.9375, token_id=15429, metadata=None))), (16730, (634, PredictedToken(token=' Museum', prob=1.9669532775878906e-06, logit=7.875, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     int_prediction=['\" Refriger\"[75258] (p=0.279, logit=18.375)', '\" Hospital\"[15429] (p=0.246, logit=18.250)', '\" The\"[578] (p=0.169, logit=17.875)', '\" Museum\"[16730] (p=0.149, logit=17.750)', '\" A\"[362] (p=0.043, logit=16.500)']\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     int_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.279296875, logit=18.375, token_id=75258, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.24609375, logit=18.25, token_id=15429, metadata=None))), (16730, (4, PredictedToken(token=' Museum', prob=0.1494140625, logit=17.75, token_id=16730, metadata=None))), (735, (10, PredictedToken(token=' K', prob=0.00543212890625, logit=14.4375, token_id=735, metadata=None))), (72683, (55, PredictedToken(token=' Boxing', prob=0.0003261566162109375, logit=11.625, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:37 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:39:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.766, logit=19.625)', '\" L\"[445] (p=0.063, logit=17.125)', '\" e\"[384] (p=0.043, logit=16.750)', '\" The\"[578] (p=0.026, logit=16.250)', '\" R\"[432] (p=0.026, logit=16.250)']\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.832, logit=19.375)', '\" The\"[578] (p=0.078, logit=17.000)', '\" None\"[2290] (p=0.013, logit=15.188)', '\" A\"[362] (p=0.007, logit=14.625)', '\" Boxing\"[72683] (p=0.005, logit=14.312)']\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.83203125, logit=19.375, token_id=423, metadata=None))), (22249, (6, PredictedToken(token=' Ring', prob=0.004638671875, logit=14.1875, token_id=22249, metadata=None))), (67629, (20, PredictedToken(token=' Helmet', prob=0.0011749267578125, logit=12.8125, token_id=67629, metadata=None))), (58600, (40, PredictedToken(token=' Charm', prob=0.000316619873046875, logit=11.5, token_id=58600, metadata=None)))])\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.852, logit=19.750)', '\" The\"[578] (p=0.054, logit=17.000)', '\" Helmet\"[67629] (p=0.019, logit=15.938)', '\" Charm\"[58600] (p=0.014, logit=15.625)', '\" A\"[362] (p=0.008, logit=15.062)']\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.8515625, logit=19.75, token_id=22249, metadata=None))), (67629, (3, PredictedToken(token=' Helmet', prob=0.018798828125, logit=15.9375, token_id=67629, metadata=None))), (58600, (4, PredictedToken(token=' Charm', prob=0.0137939453125, logit=15.625, token_id=58600, metadata=None))), (423, (7, PredictedToken(token=' D', prob=0.003082275390625, logit=14.125, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:38 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:39:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     patch_prediction=['\" Tul\"[43316] (p=0.828, logit=20.375)', '\" The\"[578] (p=0.087, logit=18.125)', '\" T\"[350] (p=0.017, logit=16.500)', '\" D\"[423] (p=0.009, logit=15.812)', '\" A\"[362] (p=0.009, logit=15.812)']\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.934, logit=21.250)', '\" The\"[578] (p=0.019, logit=17.375)', '\" Rose\"[16344] (p=0.006, logit=16.125)', '\" Sh\"[1443] (p=0.006, logit=16.125)', '\" L\"[445] (p=0.004, logit=15.750)']\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.93359375, logit=21.25, token_id=81501, metadata=None))), (16344, (4, PredictedToken(token=' Rose', prob=0.00555419921875, logit=16.125, token_id=16344, metadata=None))), (1443, (3, PredictedToken(token=' Sh', prob=0.00555419921875, logit=16.125, token_id=1443, metadata=None))), (445, (5, PredictedToken(token=' L', prob=0.003814697265625, logit=15.75, token_id=445, metadata=None))), (8219, (34, PredictedToken(token=' Sun', prob=0.00015735626220703125, logit=12.5625, token_id=8219, metadata=None)))])\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     int_prediction=['\" Sh\"[1443] (p=0.660, logit=18.125)', '\" Rose\"[16344] (p=0.115, logit=16.375)', '\" The\"[578] (p=0.045, logit=15.438)', '\" SH\"[6570] (p=0.023, logit=14.750)', '\" Sun\"[8219] (p=0.015, logit=14.312)']\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     int_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.66015625, logit=18.125, token_id=1443, metadata=None))), (16344, (2, PredictedToken(token=' Rose', prob=0.11474609375, logit=16.375, token_id=16344, metadata=None))), (8219, (5, PredictedToken(token=' Sun', prob=0.01458740234375, logit=14.3125, token_id=8219, metadata=None))), (445, (6, PredictedToken(token=' L', prob=0.01287841796875, logit=14.1875, token_id=445, metadata=None))), (81501, (7, PredictedToken(token=' Pendant', prob=0.00885009765625, logit=13.8125, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:39 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:39 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:39:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.078, logit=19.000)', '\" Har\"[5340] (p=0.025, logit=17.875)', '\" c\"[272] (p=0.017, logit=17.500)', '\" A\"[362] (p=0.007, logit=16.625)']\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     clean_prediction=['\" Sc\"[2522] (p=0.463, logit=19.625)', '\" Folder\"[36943] (p=0.318, logit=19.250)', '\" Fl\"[3061] (p=0.055, logit=17.500)', '\" The\"[578] (p=0.033, logit=17.000)', '\" None\"[2290] (p=0.023, logit=16.625)']\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     clean_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.462890625, logit=19.625, token_id=2522, metadata=None))), (36943, (2, PredictedToken(token=' Folder', prob=0.318359375, logit=19.25, token_id=36943, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.05517578125, logit=17.5, token_id=3061, metadata=None))), (68027, (9, PredictedToken(token=' Sax', prob=0.006195068359375, logit=15.3125, token_id=68027, metadata=None))), (84409, (58, PredictedToken(token=' Plum', prob=0.00022602081298828125, logit=12.0, token_id=84409, metadata=None)))])\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.613, logit=19.125)', '\" The\"[578] (p=0.107, logit=17.375)', '\" Fl\"[3061] (p=0.065, logit=16.875)', '\" Folder\"[36943] (p=0.051, logit=16.625)', '\" None\"[2290] (p=0.027, logit=16.000)']\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.61328125, logit=19.125, token_id=68027, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.06494140625, logit=16.875, token_id=3061, metadata=None))), (36943, (4, PredictedToken(token=' Folder', prob=0.050537109375, logit=16.625, token_id=36943, metadata=None))), (2522, (6, PredictedToken(token=' Sc', prob=0.0174560546875, logit=15.5625, token_id=2522, metadata=None))), (84409, (14, PredictedToken(token=' Plum', prob=0.0034332275390625, logit=13.9375, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:40 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.828, logit=20.375)', '\" The\"[578] (p=0.060, logit=17.750)', '\" JE\"[71430] (p=0.053, logit=17.625)', '\" There\"[2684] (p=0.007, logit=15.562)', '\" Mosque\"[100031] (p=0.003, logit=14.750)']\n",
      "2025-09-15 09:39:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.656, logit=21.000)', '\" Stap\"[63606] (p=0.213, logit=19.875)', '\" The\"[578] (p=0.048, logit=18.375)', '\" A\"[362] (p=0.033, logit=18.000)', '\" PEN\"[81770] (p=0.015, logit=17.250)']\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.65625, logit=21.0, token_id=13597, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.212890625, logit=19.875, token_id=63606, metadata=None))), (55807, (24, PredictedToken(token=' Shirt', prob=0.0003414154052734375, logit=13.4375, token_id=55807, metadata=None))), (4923, (65, PredictedToken(token=' Sk', prob=7.62939453125e-05, logit=11.9375, token_id=4923, metadata=None))), (15429, (135, PredictedToken(token=' Hospital', prob=1.9311904907226562e-05, logit=10.5625, token_id=15429, metadata=None)))])\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.508, logit=20.125)', '\" Sk\"[4923] (p=0.350, logit=19.750)', '\" The\"[578] (p=0.042, logit=17.625)', '\" Stap\"[63606] (p=0.020, logit=16.875)', '\" None\"[2290] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.5078125, logit=20.125, token_id=55807, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.349609375, logit=19.75, token_id=4923, metadata=None))), (63606, (4, PredictedToken(token=' Stap', prob=0.019775390625, logit=16.875, token_id=63606, metadata=None))), (15429, (9, PredictedToken(token=' Hospital', prob=0.0034332275390625, logit=15.125, token_id=15429, metadata=None))), (13597, (12, PredictedToken(token=' Pen', prob=0.0022125244140625, logit=14.6875, token_id=13597, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:41 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     patch_prediction=['\" Razor\"[74968] (p=0.914, logit=21.500)', '\" Mirror\"[34954] (p=0.045, logit=18.500)', '\" The\"[578] (p=0.008, logit=16.750)', '\" None\"[2290] (p=0.004, logit=16.125)', '\" A\"[362] (p=0.003, logit=15.688)']\n",
      "2025-09-15 09:39:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     clean_prediction=['\" Eagle\"[36895] (p=0.734, logit=20.500)', '\" The\"[578] (p=0.145, logit=18.875)', '\" An\"[1556] (p=0.032, logit=17.375)', '\" E\"[469] (p=0.032, logit=17.375)', '\" Bear\"[24941] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     clean_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.734375, logit=20.5, token_id=36895, metadata=None))), (24941, (5, PredictedToken(token=' Bear', prob=0.01190185546875, logit=16.375, token_id=24941, metadata=None))), (16488, (29, PredictedToken(token=' Bat', prob=0.00035858154296875, logit=12.875, token_id=16488, metadata=None))), (6690, (311, PredictedToken(token=' Air', prob=7.450580596923828e-06, logit=9.0, token_id=6690, metadata=None))), (48471, (354, PredictedToken(token=' Shower', prob=6.16908073425293e-06, logit=8.8125, token_id=48471, metadata=None)))])\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.883, logit=20.625)', '\" BAT\"[79081] (p=0.044, logit=17.625)', '\" The\"[578] (p=0.030, logit=17.250)', '\" Shower\"[48471] (p=0.006, logit=15.562)', '\" There\"[2684] (p=0.003, logit=15.000)']\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.8828125, logit=20.625, token_id=16488, metadata=None))), (48471, (4, PredictedToken(token=' Shower', prob=0.005584716796875, logit=15.5625, token_id=48471, metadata=None))), (24941, (11, PredictedToken(token=' Bear', prob=0.00141143798828125, logit=14.1875, token_id=24941, metadata=None))), (36895, (13, PredictedToken(token=' Eagle', prob=0.0011749267578125, logit=14.0, token_id=36895, metadata=None))), (6690, (15, PredictedToken(token=' Air', prob=0.0010986328125, logit=13.9375, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:42 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.832, logit=19.625)', '\" PEN\"[81770] (p=0.032, logit=16.375)', '\" The\"[578] (p=0.029, logit=16.250)', '\" A\"[362] (p=0.015, logit=15.625)', '\" Paper\"[18343] (p=0.014, logit=15.562)']\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.805, logit=20.500)', '\" The\"[578] (p=0.096, logit=18.375)', '\" Har\"[5340] (p=0.031, logit=17.250)', '\" H\"[473] (p=0.017, logit=16.625)', '\" A\"[362] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8046875, logit=20.5, token_id=40759, metadata=None))), (5340, (3, PredictedToken(token=' Har', prob=0.0311279296875, logit=17.25, token_id=5340, metadata=None))), (18343, (43, PredictedToken(token=' Paper', prob=0.00016307830810546875, logit=12.0, token_id=18343, metadata=None))), (37128, (102, PredictedToken(token=' Calculator', prob=3.886222839355469e-05, logit=10.5625, token_id=37128, metadata=None)))])\n",
      "2025-09-15 09:39:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:43 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.680, logit=19.625)', '\" The\"[578] (p=0.118, logit=17.875)', '\" Har\"[5340] (p=0.063, logit=17.250)', '\" A\"[362] (p=0.030, logit=16.500)', '\" Harmon\"[40759] (p=0.021, logit=16.125)']\n",
      "2025-09-15 09:39:43 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.6796875, logit=19.625, token_id=18343, metadata=None))), (5340, (3, PredictedToken(token=' Har', prob=0.06298828125, logit=17.25, token_id=5340, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.0205078125, logit=16.125, token_id=40759, metadata=None))), (37128, (19, PredictedToken(token=' Calculator', prob=0.001312255859375, logit=13.375, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:43 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:43 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:39:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:43 src.selection.optimization INFO     patch_prediction=['\" Fl\"[3061] (p=0.766, logit=20.750)', '\" The\"[578] (p=0.133, logit=19.000)', '\" FL\"[13062] (p=0.026, logit=17.375)', '\" Sax\"[68027] (p=0.023, logit=17.250)', '\" A\"[362] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:39:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     clean_prediction=['\" Basketball\"[47589] (p=0.848, logit=21.750)', '\" The\"[578] (p=0.101, logit=19.625)', '\" A\"[362] (p=0.023, logit=18.125)', '\" B\"[426] (p=0.003, logit=16.000)', '\" There\"[2684] (p=0.002, logit=15.688)']\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     clean_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.84765625, logit=21.75, token_id=47589, metadata=None))), (432, (16, PredictedToken(token=' R', prob=0.0004138946533203125, logit=14.125, token_id=432, metadata=None))), (356, (25, PredictedToken(token=' C', prob=0.00023555755615234375, logit=13.5625, token_id=356, metadata=None))), (5340, (52, PredictedToken(token=' Har', prob=6.341934204101562e-05, logit=12.25, token_id=5340, metadata=None))), (1630, (57, PredictedToken(token=' X', prob=5.269050598144531e-05, logit=12.0625, token_id=1630, metadata=None))), (39247, (95, PredictedToken(token=' Slow', prob=2.0623207092285156e-05, logit=11.125, token_id=39247, metadata=None)))])\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.793, logit=20.750)', '\" The\"[578] (p=0.138, logit=19.000)', '\" A\"[362] (p=0.015, logit=16.750)', '\" Basketball\"[47589] (p=0.005, logit=15.750)', '\" There\"[2684] (p=0.004, logit=15.500)']\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.79296875, logit=20.75, token_id=1630, metadata=None))), (47589, (4, PredictedToken(token=' Basketball', prob=0.005340576171875, logit=15.75, token_id=47589, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.00323486328125, logit=15.25, token_id=432, metadata=None))), (356, (10, PredictedToken(token=' C', prob=0.0019683837890625, logit=14.75, token_id=356, metadata=None))), (5340, (22, PredictedToken(token=' Har', prob=0.00067901611328125, logit=13.6875, token_id=5340, metadata=None))), (39247, (87, PredictedToken(token=' Slow', prob=4.3392181396484375e-05, logit=10.9375, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:44 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:44 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     patch_prediction=['\" Amb\"[20423] (p=0.680, logit=19.250)', '\" The\"[578] (p=0.118, logit=17.500)', '\" An\"[1556] (p=0.104, logit=17.375)', '\" Car\"[3341] (p=0.030, logit=16.125)', '\" There\"[2684] (p=0.006, logit=14.500)']\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.746, logit=19.500)', '\" The\"[578] (p=0.069, logit=17.125)', '\" School\"[6150] (p=0.042, logit=16.625)', '\" Motorcycle\"[70762] (p=0.033, logit=16.375)', '\" CH\"[6969] (p=0.020, logit=15.875)']\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.74609375, logit=19.5, token_id=9441, metadata=None))), (6150, (3, PredictedToken(token=' School', prob=0.042236328125, logit=16.625, token_id=6150, metadata=None))), (70762, (4, PredictedToken(token=' Motorcycle', prob=0.03271484375, logit=16.375, token_id=70762, metadata=None))), (50159, (6, PredictedToken(token=' Sco', prob=0.01458740234375, logit=15.5625, token_id=50159, metadata=None)))])\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.719, logit=19.250)', '\" Church\"[9441] (p=0.085, logit=17.125)', '\" School\"[6150] (p=0.052, logit=16.625)', '\" The\"[578] (p=0.028, logit=16.000)', '\" A\"[362] (p=0.025, logit=15.875)']\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.71875, logit=19.25, token_id=70762, metadata=None))), (9441, (2, PredictedToken(token=' Church', prob=0.08544921875, logit=17.125, token_id=9441, metadata=None))), (6150, (3, PredictedToken(token=' School', prob=0.052001953125, logit=16.625, token_id=6150, metadata=None))), (50159, (6, PredictedToken(token=' Sco', prob=0.0179443359375, logit=15.5625, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:44 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:39:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     patch_prediction=['\" Temple\"[19176] (p=0.451, logit=18.750)', '\" Sk\"[4923] (p=0.188, logit=17.875)', '\" The\"[578] (p=0.166, logit=17.750)', '\" Tape\"[58586] (p=0.048, logit=16.500)', '\" D\"[423] (p=0.033, logit=16.125)']\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     clean_prediction=['\" Stap\"[63606] (p=0.789, logit=20.500)', '\" The\"[578] (p=0.083, logit=18.250)', '\" Er\"[9939] (p=0.044, logit=17.625)', '\" A\"[362] (p=0.016, logit=16.625)', '\" ST\"[4015] (p=0.011, logit=16.250)']\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     clean_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.7890625, logit=20.5, token_id=63606, metadata=None))), (9939, (3, PredictedToken(token=' Er', prob=0.04443359375, logit=17.625, token_id=9939, metadata=None))), (97796, (72, PredictedToken(token=' Skate', prob=0.00010395050048828125, logit=11.5625, token_id=97796, metadata=None))), (16344, (76, PredictedToken(token=' Rose', prob=9.72747802734375e-05, logit=11.5, token_id=16344, metadata=None))), (23462, (115, PredictedToken(token=' Stadium', prob=4.601478576660156e-05, logit=10.75, token_id=23462, metadata=None))), (6150, (167, PredictedToken(token=' School', prob=2.0384788513183594e-05, logit=9.9375, token_id=6150, metadata=None)))])\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.855, logit=20.750)', '\" The\"[578] (p=0.038, logit=17.625)', '\" None\"[2290] (p=0.016, logit=16.750)', '\" SCHOOL\"[71501] (p=0.012, logit=16.500)', '\" A\"[362] (p=0.012, logit=16.500)']\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.85546875, logit=20.75, token_id=6150, metadata=None))), (63606, (6, PredictedToken(token=' Stap', prob=0.01080322265625, logit=16.375, token_id=63606, metadata=None))), (97796, (8, PredictedToken(token=' Skate', prob=0.004486083984375, logit=15.5, token_id=97796, metadata=None))), (16344, (14, PredictedToken(token=' Rose', prob=0.00121307373046875, logit=14.1875, token_id=16344, metadata=None))), (23462, (18, PredictedToken(token=' Stadium', prob=0.000942230224609375, logit=13.9375, token_id=23462, metadata=None))), (9939, (39, PredictedToken(token=' Er', prob=0.0002880096435546875, logit=12.75, token_id=9939, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:45 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     patch_prediction=['\" Router\"[10777] (p=0.762, logit=19.875)', '\" The\"[578] (p=0.091, logit=17.750)', '\" Phone\"[14642] (p=0.038, logit=16.875)', '\" A\"[362] (p=0.016, logit=16.000)', '\" ROUT\"[54281] (p=0.008, logit=15.312)']\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.699, logit=20.125)', '\" E\"[469] (p=0.177, logit=18.750)', '\" The\"[578] (p=0.057, logit=17.625)', '\" e\"[384] (p=0.009, logit=15.750)', '\" CH\"[6969] (p=0.007, logit=15.500)']\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.69921875, logit=20.125, token_id=58600, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.1767578125, logit=18.75, token_id=469, metadata=None))), (43950, (12, PredictedToken(token=' Lav', prob=0.0013427734375, logit=13.875, token_id=43950, metadata=None))), (26698, (33, PredictedToken(token=' Keyboard', prob=0.000362396240234375, logit=12.5625, token_id=26698, metadata=None))), (47033, (47, PredictedToken(token=' Printer', prob=0.00019359588623046875, logit=11.9375, token_id=47033, metadata=None)))])\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.613, logit=19.000)', '\" The\"[578] (p=0.094, logit=17.125)', '\" Charm\"[58600] (p=0.073, logit=16.875)', '\" KEY\"[12282] (p=0.039, logit=16.250)', '\" E\"[469] (p=0.039, logit=16.250)']\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.61328125, logit=19.0, token_id=26698, metadata=None))), (58600, (3, PredictedToken(token=' Charm', prob=0.0732421875, logit=16.875, token_id=58600, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.0390625, logit=16.25, token_id=469, metadata=None))), (43950, (17, PredictedToken(token=' Lav', prob=0.002838134765625, logit=13.625, token_id=43950, metadata=None))), (47033, (19, PredictedToken(token=' Printer', prob=0.00250244140625, logit=13.5, token_id=47033, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:46 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:39:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.770, logit=20.000)', '\" The\"[578] (p=0.104, logit=18.000)', '\" Truck\"[34785] (p=0.018, logit=16.250)', '\" A\"[362] (p=0.018, logit=16.250)', '\" TR\"[5091] (p=0.016, logit=16.125)']\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     clean_prediction=['\" Fl\"[3061] (p=0.715, logit=20.375)', '\" The\"[578] (p=0.110, logit=18.500)', '\" Viol\"[30555] (p=0.076, logit=18.125)', '\" FL\"[13062] (p=0.028, logit=17.125)', '\" None\"[2290] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     clean_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.71484375, logit=20.375, token_id=3061, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.07568359375, logit=18.125, token_id=30555, metadata=None))), (3804, (8, PredictedToken(token=' Sub', prob=0.005462646484375, logit=15.5, token_id=3804, metadata=None))), (20423, (12, PredictedToken(token=' Amb', prob=0.0024261474609375, logit=14.6875, token_id=20423, metadata=None))), (8868, (46, PredictedToken(token=' Blue', prob=0.00016498565673828125, logit=12.0, token_id=8868, metadata=None)))])\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     int_prediction=['\" Sub\"[3804] (p=0.727, logit=19.875)', '\" Amb\"[20423] (p=0.098, logit=17.875)', '\" The\"[578] (p=0.060, logit=17.375)', '\" Viol\"[30555] (p=0.022, logit=16.375)', '\" SUB\"[16532] (p=0.017, logit=16.125)']\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     int_track=OrderedDict([(3804, (1, PredictedToken(token=' Sub', prob=0.7265625, logit=19.875, token_id=3804, metadata=None))), (20423, (2, PredictedToken(token=' Amb', prob=0.09814453125, logit=17.875, token_id=20423, metadata=None))), (30555, (4, PredictedToken(token=' Viol', prob=0.02197265625, logit=16.375, token_id=30555, metadata=None))), (3061, (27, PredictedToken(token=' Fl', prob=0.00042724609375, logit=12.4375, token_id=3061, metadata=None))), (8868, (49, PredictedToken(token=' Blue', prob=0.000202178955078125, logit=11.6875, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:47 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.797, logit=20.750)', '\" Mouse\"[18191] (p=0.065, logit=18.250)', '\" SOAP\"[64332] (p=0.040, logit=17.750)', '\" The\"[578] (p=0.027, logit=17.375)', '\" Bat\"[16488] (p=0.024, logit=17.250)']\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     clean_prediction=['\" Television\"[41445] (p=0.754, logit=20.625)', '\" The\"[578] (p=0.090, logit=18.500)', '\" Speaker\"[30173] (p=0.070, logit=18.250)', '\" Razor\"[74968] (p=0.011, logit=16.375)', '\" A\"[362] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     clean_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.75390625, logit=20.625, token_id=41445, metadata=None))), (30173, (3, PredictedToken(token=' Speaker', prob=0.0703125, logit=18.25, token_id=30173, metadata=None))), (74968, (4, PredictedToken(token=' Razor', prob=0.0107421875, logit=16.375, token_id=74968, metadata=None))), (6031, (12, PredictedToken(token=' Bro', prob=0.0017547607421875, logit=14.5625, token_id=6031, metadata=None))), (83499, (22, PredictedToken(token=' Tooth', prob=0.000827789306640625, logit=13.8125, token_id=83499, metadata=None)))])\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     int_prediction=['\" Tooth\"[83499] (p=0.820, logit=20.375)', '\" Speaker\"[30173] (p=0.046, logit=17.500)', '\" The\"[578] (p=0.032, logit=17.125)', '\" Bro\"[6031] (p=0.019, logit=16.625)', '\" Razor\"[74968] (p=0.017, logit=16.500)']\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     int_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.8203125, logit=20.375, token_id=83499, metadata=None))), (30173, (2, PredictedToken(token=' Speaker', prob=0.046142578125, logit=17.5, token_id=30173, metadata=None))), (6031, (4, PredictedToken(token=' Bro', prob=0.019287109375, logit=16.625, token_id=6031, metadata=None))), (74968, (5, PredictedToken(token=' Razor', prob=0.0169677734375, logit=16.5, token_id=74968, metadata=None))), (41445, (8, PredictedToken(token=' Television', prob=0.00457763671875, logit=15.1875, token_id=41445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:48 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.734, logit=20.500)', '\" The\"[578] (p=0.113, logit=18.625)', '\" Tennis\"[58251] (p=0.060, logit=18.000)', '\" A\"[362] (p=0.020, logit=16.875)', '\" BAT\"[79081] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:39:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     clean_prediction=['\" Sco\"[50159] (p=0.428, logit=19.000)', '\" Skate\"[97796] (p=0.202, logit=18.250)', '\" The\"[578] (p=0.123, logit=17.750)', '\" Tul\"[43316] (p=0.040, logit=16.625)', '\" Yoga\"[38673] (p=0.040, logit=16.625)']\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     clean_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.427734375, logit=19.0, token_id=50159, metadata=None))), (97796, (2, PredictedToken(token=' Skate', prob=0.2021484375, logit=18.25, token_id=97796, metadata=None))), (38673, (4, PredictedToken(token=' Yoga', prob=0.039794921875, logit=16.625, token_id=38673, metadata=None))), (43316, (5, PredictedToken(token=' Tul', prob=0.039794921875, logit=16.625, token_id=43316, metadata=None))), (19111, (9, PredictedToken(token=' Bus', prob=0.00946044921875, logit=15.1875, token_id=19111, metadata=None)))])\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.455, logit=19.750)', '\" Sco\"[50159] (p=0.354, logit=19.500)', '\" The\"[578] (p=0.079, logit=18.000)', '\" None\"[2290] (p=0.023, logit=16.750)', '\" A\"[362] (p=0.018, logit=16.500)']\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.455078125, logit=19.75, token_id=97796, metadata=None))), (50159, (2, PredictedToken(token=' Sco', prob=0.353515625, logit=19.5, token_id=50159, metadata=None))), (19111, (7, PredictedToken(token=' Bus', prob=0.01214599609375, logit=16.125, token_id=19111, metadata=None))), (43316, (8, PredictedToken(token=' Tul', prob=0.003265380859375, logit=14.8125, token_id=43316, metadata=None))), (38673, (61, PredictedToken(token=' Yoga', prob=0.00012683868408203125, logit=11.5625, token_id=38673, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:49 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:49 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.625, logit=19.250)', '\" The\"[578] (p=0.109, logit=17.500)', '\" Toilet\"[82994] (p=0.085, logit=17.250)', '\" Book\"[6017] (p=0.040, logit=16.500)', '\" Air\"[6690] (p=0.035, logit=16.375)']\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     clean_prediction=['\" Dish\"[49268] (p=0.570, logit=20.125)', '\" To\"[2057] (p=0.210, logit=19.125)', '\" The\"[578] (p=0.145, logit=18.750)', '\" A\"[362] (p=0.013, logit=16.375)', '\" DIS\"[12244] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     clean_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.5703125, logit=20.125, token_id=49268, metadata=None))), (2057, (2, PredictedToken(token=' To', prob=0.2099609375, logit=19.125, token_id=2057, metadata=None))), (83499, (15, PredictedToken(token=' Tooth', prob=0.00102996826171875, logit=13.8125, token_id=83499, metadata=None))), (27738, (32, PredictedToken(token=' Ward', prob=0.0003795623779296875, logit=12.8125, token_id=27738, metadata=None))), (13394, (223, PredictedToken(token=' Bed', prob=1.2993812561035156e-05, logit=9.4375, token_id=13394, metadata=None)))])\n",
      "2025-09-15 09:39:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:50 src.selection.optimization INFO     int_prediction=['\" Ward\"[27738] (p=0.742, logit=20.250)', '\" Bed\"[13394] (p=0.089, logit=18.125)', '\" The\"[578] (p=0.078, logit=18.000)', '\" Dish\"[49268] (p=0.012, logit=16.125)', '\" A\"[362] (p=0.012, logit=16.125)']\n",
      "2025-09-15 09:39:50 src.selection.optimization INFO     int_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.7421875, logit=20.25, token_id=27738, metadata=None))), (13394, (2, PredictedToken(token=' Bed', prob=0.0888671875, logit=18.125, token_id=13394, metadata=None))), (49268, (5, PredictedToken(token=' Dish', prob=0.01202392578125, logit=16.125, token_id=49268, metadata=None))), (2057, (9, PredictedToken(token=' To', prob=0.0050048828125, logit=15.25, token_id=2057, metadata=None))), (83499, (35, PredictedToken(token=' Tooth', prob=0.000301361083984375, logit=12.4375, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:50 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:50 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:39:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:50 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.840, logit=20.625)', '\" The\"[578] (p=0.078, logit=18.250)', '\" Surf\"[65197] (p=0.014, logit=16.500)', '\" A\"[362] (p=0.014, logit=16.500)', '\" There\"[2684] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:39:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.766, logit=20.250)', '\" The\"[578] (p=0.071, logit=17.875)', '\" Cedar\"[57748] (p=0.056, logit=17.625)', '\" There\"[2684] (p=0.030, logit=17.000)', '\" Paper\"[18343] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.765625, logit=20.25, token_id=44570, metadata=None))), (57748, (3, PredictedToken(token=' Cedar', prob=0.0556640625, logit=17.625, token_id=57748, metadata=None))), (18343, (5, PredictedToken(token=' Paper', prob=0.01092529296875, logit=16.0, token_id=18343, metadata=None))), (4923, (14, PredictedToken(token=' Sk', prob=0.0017852783203125, logit=14.1875, token_id=4923, metadata=None))), (1901, (16, PredictedToken(token=' Z', prob=0.00157928466796875, logit=14.0625, token_id=1901, metadata=None))), (41342, (284, PredictedToken(token=' Hockey', prob=1.0609626770019531e-05, logit=9.0625, token_id=41342, metadata=None))), (38673, (351, PredictedToken(token=' Yoga', prob=7.3015689849853516e-06, logit=8.6875, token_id=38673, metadata=None)))])\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.516, logit=19.000)', '\" The\"[578] (p=0.190, logit=18.000)', '\" There\"[2684] (p=0.062, logit=16.875)', '\" A\"[362] (p=0.042, logit=16.500)', '\" H\"[473] (p=0.024, logit=15.938)']\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.515625, logit=19.0, token_id=41342, metadata=None))), (44570, (6, PredictedToken(token=' Maple', prob=0.022705078125, logit=15.875, token_id=44570, metadata=None))), (57748, (7, PredictedToken(token=' Cedar', prob=0.0177001953125, logit=15.625, token_id=57748, metadata=None))), (1901, (10, PredictedToken(token=' Z', prob=0.006500244140625, logit=14.625, token_id=1901, metadata=None))), (4923, (11, PredictedToken(token=' Sk', prob=0.0057373046875, logit=14.5, token_id=4923, metadata=None))), (38673, (14, PredictedToken(token=' Yoga', prob=0.0047607421875, logit=14.3125, token_id=38673, metadata=None))), (18343, (34, PredictedToken(token=' Paper', prob=0.000881195068359375, logit=12.625, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:51 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:51 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     patch_prediction=['\" Mushroom\"[91297] (p=0.422, logit=19.625)', '\" As\"[1666] (p=0.256, logit=19.125)', '\" There\"[2684] (p=0.121, logit=18.375)', '\" The\"[578] (p=0.083, logit=18.000)', '\" None\"[2290] (p=0.021, logit=16.625)']\n",
      "2025-09-15 09:39:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.734, logit=21.125)', '\" The\"[578] (p=0.100, logit=19.125)', '\" Paper\"[18343] (p=0.078, logit=18.875)', '\" A\"[362] (p=0.032, logit=18.000)', '\" PEN\"[81770] (p=0.012, logit=17.000)']\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.734375, logit=21.125, token_id=13597, metadata=None))), (18343, (3, PredictedToken(token=' Paper', prob=0.07763671875, logit=18.875, token_id=18343, metadata=None))), (38930, (130, PredictedToken(token=' Bike', prob=2.1576881408691406e-05, logit=10.6875, token_id=38930, metadata=None))), (1901, (163, PredictedToken(token=' Z', prob=1.4841556549072266e-05, logit=10.3125, token_id=1901, metadata=None))), (23910, (183, PredictedToken(token=' Pear', prob=1.2278556823730469e-05, logit=10.125, token_id=23910, metadata=None))), (87035, (595, PredictedToken(token=' Onion', prob=1.8849968910217285e-06, logit=8.25, token_id=87035, metadata=None))), (16730, (2448, PredictedToken(token=' Museum', prob=2.551823854446411e-07, logit=6.25, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.781, logit=20.750)', '\" The\"[578] (p=0.093, logit=18.625)', '\" Pen\"[13597] (p=0.024, logit=17.250)', '\" P\"[393] (p=0.014, logit=16.750)', '\" There\"[2684] (p=0.011, logit=16.500)']\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.78125, logit=20.75, token_id=1901, metadata=None))), (13597, (3, PredictedToken(token=' Pen', prob=0.023681640625, logit=17.25, token_id=13597, metadata=None))), (87035, (8, PredictedToken(token=' Onion', prob=0.007659912109375, logit=16.125, token_id=87035, metadata=None))), (23910, (7, PredictedToken(token=' Pear', prob=0.007659912109375, logit=16.125, token_id=23910, metadata=None))), (18343, (12, PredictedToken(token=' Paper', prob=0.0023345947265625, logit=14.9375, token_id=18343, metadata=None))), (38930, (56, PredictedToken(token=' Bike', prob=0.00019168853759765625, logit=12.4375, token_id=38930, metadata=None))), (16730, (434, PredictedToken(token=' Museum', prob=3.516674041748047e-06, logit=8.4375, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:52 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.793, logit=19.250)', '\" Router\"[10777] (p=0.045, logit=16.375)', '\" The\"[578] (p=0.035, logit=16.125)', '\" Speaker\"[30173] (p=0.026, logit=15.812)', '\" A\"[362] (p=0.016, logit=15.312)']\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.801, logit=20.375)', '\" The\"[578] (p=0.084, logit=18.125)', '\" Micro\"[18654] (p=0.027, logit=17.000)', '\" HEAD\"[34180] (p=0.019, logit=16.625)', '\" headphones\"[44101] (p=0.011, logit=16.125)']\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.80078125, logit=20.375, token_id=11452, metadata=None))), (18654, (3, PredictedToken(token=' Micro', prob=0.02734375, logit=17.0, token_id=18654, metadata=None))), (4923, (21, PredictedToken(token=' Sk', prob=0.000728607177734375, logit=13.375, token_id=4923, metadata=None))), (53889, (64, PredictedToken(token=' Apartment', prob=0.0001354217529296875, logit=11.6875, token_id=53889, metadata=None))), (15429, (329, PredictedToken(token=' Hospital', prob=7.152557373046875e-06, logit=8.75, token_id=15429, metadata=None)))])\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     int_prediction=['\" Apartment\"[53889] (p=0.598, logit=20.375)', '\" Hospital\"[15429] (p=0.283, logit=19.625)', '\" The\"[578] (p=0.056, logit=18.000)', '\" There\"[2684] (p=0.005, logit=15.688)', '\" None\"[2290] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     int_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.59765625, logit=20.375, token_id=53889, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.283203125, logit=19.625, token_id=15429, metadata=None))), (4923, (9, PredictedToken(token=' Sk', prob=0.0029449462890625, logit=15.0625, token_id=4923, metadata=None))), (18654, (10, PredictedToken(token=' Micro', prob=0.002288818359375, logit=14.8125, token_id=18654, metadata=None))), (11452, (248, PredictedToken(token=' Head', prob=1.0609626770019531e-05, logit=9.4375, token_id=11452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:39:52 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:39:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.512, logit=18.750)', '\" Lion\"[33199] (p=0.166, logit=17.625)', '\" The\"[578] (p=0.166, logit=17.625)', '\" SHE\"[54695] (p=0.029, logit=15.875)', '\" A\"[362] (p=0.016, logit=15.312)']\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     clean_prediction=['\" Pe\"[5250] (p=0.695, logit=19.875)', '\" The\"[578] (p=0.176, logit=18.500)', '\" Tul\"[43316] (p=0.019, logit=16.250)', '\" PE\"[22557] (p=0.013, logit=15.875)', '\" There\"[2684] (p=0.013, logit=15.875)']\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     clean_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.6953125, logit=19.875, token_id=5250, metadata=None))), (43316, (3, PredictedToken(token=' Tul', prob=0.0185546875, logit=16.25, token_id=43316, metadata=None))), (1901, (20, PredictedToken(token=' Z', prob=0.00151824951171875, logit=13.75, token_id=1901, metadata=None))), (49431, (443, PredictedToken(token=' Rabbit', prob=7.4803829193115234e-06, logit=8.4375, token_id=49431, metadata=None)))])\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.484, logit=19.375)', '\" Rabbit\"[49431] (p=0.293, logit=18.875)', '\" The\"[578] (p=0.084, logit=17.625)', '\" Tul\"[43316] (p=0.021, logit=16.250)', '\" There\"[2684] (p=0.019, logit=16.125)']\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.484375, logit=19.375, token_id=1901, metadata=None))), (49431, (2, PredictedToken(token=' Rabbit', prob=0.29296875, logit=18.875, token_id=49431, metadata=None))), (43316, (4, PredictedToken(token=' Tul', prob=0.021240234375, logit=16.25, token_id=43316, metadata=None))), (5250, (33, PredictedToken(token=' Pe', prob=0.0005645751953125, logit=12.625, token_id=5250, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:53 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.746, logit=20.500)', '\" Motorcycle\"[70762] (p=0.130, logit=18.750)', '\" The\"[578] (p=0.037, logit=17.500)', '\" An\"[1556] (p=0.029, logit=17.250)', '\" AIR\"[46994] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.531, logit=19.875)', '\" E\"[469] (p=0.322, logit=19.375)', '\" The\"[578] (p=0.050, logit=17.500)', '\" e\"[384] (p=0.026, logit=16.875)', '\" A\"[362] (p=0.007, logit=15.562)']\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.53125, logit=19.875, token_id=58600, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.322265625, logit=19.375, token_id=469, metadata=None))), (38930, (27, PredictedToken(token=' Bike', prob=0.000484466552734375, logit=12.875, token_id=38930, metadata=None))), (16183, (29, PredictedToken(token=' Hel', prob=0.0004558563232421875, logit=12.8125, token_id=16183, metadata=None))), (42609, (40, PredictedToken(token=' Pine', prob=0.00031280517578125, logit=12.4375, token_id=42609, metadata=None)))])\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.836, logit=20.250)', '\" The\"[578] (p=0.061, logit=17.625)', '\" Hel\"[16183] (p=0.015, logit=16.250)', '\" BI\"[48153] (p=0.012, logit=16.000)', '\" A\"[362] (p=0.009, logit=15.750)']\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.8359375, logit=20.25, token_id=38930, metadata=None))), (16183, (3, PredictedToken(token=' Hel', prob=0.01531982421875, logit=16.25, token_id=16183, metadata=None))), (58600, (13, PredictedToken(token=' Charm', prob=0.00171661376953125, logit=14.0625, token_id=58600, metadata=None))), (42609, (14, PredictedToken(token=' Pine', prob=0.001617431640625, logit=14.0, token_id=42609, metadata=None))), (469, (20, PredictedToken(token=' E', prob=0.000762939453125, logit=13.25, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:39:54 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-15 09:39:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.789, logit=20.625)', '\" The\"[578] (p=0.073, logit=18.250)', '\" Coat\"[68867] (p=0.057, logit=18.000)', '\" SOCK\"[35651] (p=0.019, logit=16.875)', '\" socks\"[40086] (p=0.006, logit=15.812)']\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.832, logit=20.500)', '\" The\"[578] (p=0.060, logit=17.875)', '\" IR\"[16646] (p=0.028, logit=17.125)', '\" An\"[1556] (p=0.022, logit=16.875)', '\" Orch\"[55405] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.83203125, logit=20.5, token_id=66821, metadata=None))), (55405, (5, PredictedToken(token=' Orch', prob=0.010498046875, logit=16.125, token_id=55405, metadata=None))), (37326, (19, PredictedToken(token=' Swe', prob=0.000591278076171875, logit=13.25, token_id=37326, metadata=None))), (16183, (20, PredictedToken(token=' Hel', prob=0.000522613525390625, logit=13.125, token_id=16183, metadata=None))), (91782, (44, PredictedToken(token=' Shorts', prob=0.00018024444580078125, logit=12.0625, token_id=91782, metadata=None))), (23462, (58, PredictedToken(token=' Stadium', prob=0.0001239776611328125, logit=11.6875, token_id=23462, metadata=None)))])\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.613, logit=19.500)', '\" Swe\"[37326] (p=0.199, logit=18.375)', '\" The\"[578] (p=0.057, logit=17.125)', '\" Hel\"[16183] (p=0.031, logit=16.500)', '\" A\"[362] (p=0.013, logit=15.625)']\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.61328125, logit=19.5, token_id=91782, metadata=None))), (37326, (2, PredictedToken(token=' Swe', prob=0.19921875, logit=18.375, token_id=37326, metadata=None))), (16183, (4, PredictedToken(token=' Hel', prob=0.030517578125, logit=16.5, token_id=16183, metadata=None))), (55405, (22, PredictedToken(token=' Orch', prob=0.00092315673828125, logit=13.0, token_id=55405, metadata=None))), (23462, (88, PredictedToken(token=' Stadium', prob=0.00010347366333007812, logit=10.8125, token_id=23462, metadata=None))), (66821, (111, PredictedToken(token=' Iris', prob=6.67572021484375e-05, logit=10.375, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:55 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.762, logit=20.500)', '\" The\"[578] (p=0.117, logit=18.625)', '\" B\"[426] (p=0.030, logit=17.250)', '\" Raspberry\"[48665] (p=0.020, logit=16.875)', '\" There\"[2684] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:39:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     clean_prediction=['\" Van\"[13000] (p=0.836, logit=21.250)', '\" The\"[578] (p=0.078, logit=18.875)', '\" VAN\"[97753] (p=0.029, logit=17.875)', '\" A\"[362] (p=0.012, logit=17.000)', '\" Tow\"[41493] (p=0.006, logit=16.375)']\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     clean_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.8359375, logit=21.25, token_id=13000, metadata=None))), (41493, (5, PredictedToken(token=' Tow', prob=0.006378173828125, logit=16.375, token_id=41493, metadata=None))), (38930, (11, PredictedToken(token=' Bike', prob=0.00142669677734375, logit=14.875, token_id=38930, metadata=None))), (84409, (21, PredictedToken(token=' Plum', prob=0.000492095947265625, logit=13.8125, token_id=84409, metadata=None))), (8868, (48, PredictedToken(token=' Blue', prob=0.00011682510375976562, logit=12.375, token_id=8868, metadata=None)))])\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.684, logit=20.000)', '\" Van\"[13000] (p=0.072, logit=17.750)', '\" The\"[578] (p=0.072, logit=17.750)', '\" Tow\"[41493] (p=0.056, logit=17.500)', '\" BLUE\"[56992] (p=0.023, logit=16.625)']\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.68359375, logit=20.0, token_id=8868, metadata=None))), (13000, (3, PredictedToken(token=' Van', prob=0.07177734375, logit=17.75, token_id=13000, metadata=None))), (41493, (4, PredictedToken(token=' Tow', prob=0.055908203125, logit=17.5, token_id=41493, metadata=None))), (84409, (7, PredictedToken(token=' Plum', prob=0.01251220703125, logit=16.0, token_id=84409, metadata=None))), (38930, (10, PredictedToken(token=' Bike', prob=0.004058837890625, logit=14.875, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:56 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.777, logit=20.750)', '\" The\"[578] (p=0.082, logit=18.500)', '\" Onion\"[87035] (p=0.039, logit=17.750)', '\" There\"[2684] (p=0.030, logit=17.500)', '\" None\"[2290] (p=0.011, logit=16.500)']\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.539, logit=19.250)', '\" Jeans\"[82507] (p=0.136, logit=17.875)', '\" The\"[578] (p=0.136, logit=17.875)', '\" SHORT\"[66024] (p=0.030, logit=16.375)', '\" D\"[423] (p=0.015, logit=15.688)']\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.5390625, logit=19.25, token_id=91782, metadata=None))), (82507, (3, PredictedToken(token=' Jeans', prob=0.1357421875, logit=17.875, token_id=82507, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.0152587890625, logit=15.6875, token_id=423, metadata=None))), (78703, (72, PredictedToken(token=' Potato', prob=0.00023174285888671875, logit=11.5, token_id=78703, metadata=None))), (47643, (75, PredictedToken(token=' Cel', prob=0.000217437744140625, logit=11.4375, token_id=47643, metadata=None)))])\n",
      "2025-09-15 09:39:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.312, logit=18.875)', '\" Potato\"[78703] (p=0.275, logit=18.750)', '\" Jeans\"[82507] (p=0.215, logit=18.500)', '\" The\"[578] (p=0.079, logit=17.500)', '\" JE\"[71430] (p=0.012, logit=15.625)']\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.3125, logit=18.875, token_id=47643, metadata=None))), (78703, (2, PredictedToken(token=' Potato', prob=0.275390625, logit=18.75, token_id=78703, metadata=None))), (82507, (3, PredictedToken(token=' Jeans', prob=0.21484375, logit=18.5, token_id=82507, metadata=None))), (423, (8, PredictedToken(token=' D', prob=0.005706787109375, logit=14.875, token_id=423, metadata=None))), (91782, (14, PredictedToken(token=' Shorts', prob=0.003692626953125, logit=14.4375, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:57 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.805, logit=20.875)', '\" The\"[578] (p=0.096, logit=18.750)', '\" Lion\"[33199] (p=0.028, logit=17.500)', '\" BE\"[7354] (p=0.021, logit=17.250)', '\" A\"[362] (p=0.017, logit=17.000)']\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     clean_prediction=['\" Raspberry\"[48665] (p=0.688, logit=20.750)', '\" The\"[578] (p=0.120, logit=19.000)', '\" Pear\"[23910] (p=0.093, logit=18.750)', '\" R\"[432] (p=0.034, logit=17.750)', '\" There\"[2684] (p=0.014, logit=16.875)']\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     clean_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.6875, logit=20.75, token_id=48665, metadata=None))), (23910, (3, PredictedToken(token=' Pear', prob=0.09326171875, logit=18.75, token_id=23910, metadata=None))), (816, (8, PredictedToken(token=' Y', prob=0.0036163330078125, logit=15.5, token_id=816, metadata=None))), (49431, (89, PredictedToken(token=' Rabbit', prob=5.841255187988281e-05, logit=11.375, token_id=49431, metadata=None))), (14588, (98, PredictedToken(token=' Dog', prob=4.839897155761719e-05, logit=11.1875, token_id=14588, metadata=None)))])\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.664, logit=20.625)', '\" The\"[578] (p=0.190, logit=19.375)', '\" Pear\"[23910] (p=0.055, logit=18.125)', '\" DO\"[9503] (p=0.026, logit=17.375)', '\" Rabbit\"[49431] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.6640625, logit=20.625, token_id=14588, metadata=None))), (23910, (3, PredictedToken(token=' Pear', prob=0.0546875, logit=18.125, token_id=23910, metadata=None))), (49431, (5, PredictedToken(token=' Rabbit', prob=0.009521484375, logit=16.375, token_id=49431, metadata=None))), (816, (8, PredictedToken(token=' Y', prob=0.00372314453125, logit=15.4375, token_id=816, metadata=None))), (48665, (14, PredictedToken(token=' Raspberry', prob=0.00113677978515625, logit=14.25, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:57 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:39:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.703, logit=20.250)', '\" The\"[578] (p=0.108, logit=18.375)', '\" Surf\"[65197] (p=0.065, logit=17.875)', '\" SUR\"[53083] (p=0.031, logit=17.125)', '\" A\"[362] (p=0.024, logit=16.875)']\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.547, logit=20.625)', '\" Stap\"[63606] (p=0.375, logit=20.250)', '\" The\"[578] (p=0.031, logit=17.750)', '\" A\"[362] (p=0.011, logit=16.750)', '\" D\"[423] (p=0.006, logit=16.125)']\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.546875, logit=20.625, token_id=91263, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.375, logit=20.25, token_id=63606, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.006072998046875, logit=16.125, token_id=423, metadata=None))), (43950, (6, PredictedToken(token=' Lav', prob=0.0027008056640625, logit=15.3125, token_id=43950, metadata=None))), (4923, (64, PredictedToken(token=' Sk', prob=6.341934204101562e-05, logit=11.5625, token_id=4923, metadata=None)))])\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.605, logit=19.250)', '\" Sk\"[4923] (p=0.174, logit=18.000)', '\" Stap\"[63606] (p=0.082, logit=17.250)', '\" The\"[578] (p=0.039, logit=16.500)', '\" None\"[2290] (p=0.024, logit=16.000)']\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.60546875, logit=19.25, token_id=423, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.173828125, logit=18.0, token_id=4923, metadata=None))), (63606, (3, PredictedToken(token=' Stap', prob=0.08203125, logit=17.25, token_id=63606, metadata=None))), (43950, (7, PredictedToken(token=' Lav', prob=0.005950927734375, logit=14.625, token_id=43950, metadata=None))), (91263, (144, PredictedToken(token=' Binder', prob=3.7670135498046875e-05, logit=9.5625, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:39:58 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:39:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.770, logit=20.250)', '\" The\"[578] (p=0.092, logit=18.125)', '\" A\"[362] (p=0.034, logit=17.125)', '\" CAR\"[28876] (p=0.030, logit=17.000)', '\" There\"[2684] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.824, logit=20.250)', '\" The\"[578] (p=0.077, logit=17.875)', '\" Magn\"[20918] (p=0.019, logit=16.500)', '\" W\"[468] (p=0.011, logit=15.938)', '\" There\"[2684] (p=0.008, logit=15.625)']\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.82421875, logit=20.25, token_id=65449, metadata=None))), (20918, (3, PredictedToken(token=' Magn', prob=0.0194091796875, logit=16.5, token_id=20918, metadata=None))), (34785, (18, PredictedToken(token=' Truck', prob=0.00109100341796875, logit=13.625, token_id=34785, metadata=None))), (36943, (38, PredictedToken(token=' Folder', prob=0.000293731689453125, logit=12.3125, token_id=36943, metadata=None))), (45332, (218, PredictedToken(token=' Boat', prob=1.6570091247558594e-05, logit=9.4375, token_id=45332, metadata=None)))])\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     int_prediction=['\" Truck\"[34785] (p=0.652, logit=19.500)', '\" The\"[578] (p=0.113, logit=17.750)', '\" Willow\"[65449] (p=0.047, logit=16.875)', '\" A\"[362] (p=0.047, logit=16.875)', '\" TR\"[5091] (p=0.025, logit=16.250)']\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     int_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.65234375, logit=19.5, token_id=34785, metadata=None))), (65449, (4, PredictedToken(token=' Willow', prob=0.047119140625, logit=16.875, token_id=65449, metadata=None))), (20918, (8, PredictedToken(token=' Magn', prob=0.00927734375, logit=15.25, token_id=20918, metadata=None))), (45332, (28, PredictedToken(token=' Boat', prob=0.0007171630859375, logit=12.6875, token_id=45332, metadata=None))), (36943, (109, PredictedToken(token=' Folder', prob=9.679794311523438e-05, logit=10.6875, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:39:59 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:39:59 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:39:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.895, logit=21.625)', '\" The\"[578] (p=0.051, logit=18.750)', '\" Bro\"[6031] (p=0.019, logit=17.750)', '\" There\"[2684] (p=0.007, logit=16.750)', '\" \"[220] (p=0.003, logit=15.812)']\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.883, logit=21.125)', '\" The\"[578] (p=0.034, logit=17.875)', '\" Paper\"[18343] (p=0.016, logit=17.125)', '\" Tr\"[1183] (p=0.014, logit=17.000)', '\" A\"[362] (p=0.013, logit=16.875)']\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.8828125, logit=21.125, token_id=91263, metadata=None))), (18343, (3, PredictedToken(token=' Paper', prob=0.0162353515625, logit=17.125, token_id=18343, metadata=None))), (1183, (4, PredictedToken(token=' Tr', prob=0.0142822265625, logit=17.0, token_id=1183, metadata=None))), (11896, (19, PredictedToken(token=' Library', prob=0.000553131103515625, logit=13.75, token_id=11896, metadata=None))), (47643, (37, PredictedToken(token=' Cel', prob=0.00019168853759765625, logit=12.6875, token_id=47643, metadata=None))), (87035, (103, PredictedToken(token=' Onion', prob=3.7670135498046875e-05, logit=11.0625, token_id=87035, metadata=None))), (36358, (126, PredictedToken(token=' Bench', prob=2.753734588623047e-05, logit=10.75, token_id=36358, metadata=None)))])\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.824, logit=20.250)', '\" The\"[578] (p=0.041, logit=17.250)', '\" ON\"[6328] (p=0.019, logit=16.500)', '\" Tr\"[1183] (p=0.019, logit=16.500)', '\" Binder\"[91263] (p=0.011, logit=15.938)']\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.82421875, logit=20.25, token_id=87035, metadata=None))), (1183, (3, PredictedToken(token=' Tr', prob=0.0194091796875, logit=16.5, token_id=1183, metadata=None))), (91263, (5, PredictedToken(token=' Binder', prob=0.01104736328125, logit=15.9375, token_id=91263, metadata=None))), (18343, (6, PredictedToken(token=' Paper', prob=0.0091552734375, logit=15.75, token_id=18343, metadata=None))), (47643, (7, PredictedToken(token=' Cel', prob=0.00592041015625, logit=15.3125, token_id=47643, metadata=None))), (11896, (42, PredictedToken(token=' Library', prob=0.0003337860107421875, logit=12.4375, token_id=11896, metadata=None))), (36358, (134, PredictedToken(token=' Bench', prob=4.2438507080078125e-05, logit=10.375, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:00 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:00 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     patch_prediction=['\" Rice\"[30616] (p=0.750, logit=20.250)', '\" The\"[578] (p=0.102, logit=18.250)', '\" Slow\"[39247] (p=0.062, logit=17.750)', '\" A\"[362] (p=0.018, logit=16.500)', '\" Head\"[11452] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.809, logit=20.125)', '\" The\"[578] (p=0.109, logit=18.125)', '\" It\"[1102] (p=0.008, logit=15.562)', '\" Tablet\"[58403] (p=0.006, logit=15.250)', '\" A\"[362] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.80859375, logit=20.125, token_id=47033, metadata=None))), (58403, (4, PredictedToken(token=' Tablet', prob=0.00616455078125, logit=15.25, token_id=58403, metadata=None))), (72392, (7, PredictedToken(token=' Mixer', prob=0.00579833984375, logit=15.1875, token_id=72392, metadata=None))), (75258, (11, PredictedToken(token=' Refriger', prob=0.0025634765625, logit=14.375, token_id=75258, metadata=None))), (17810, (118, PredictedToken(token=' Cat', prob=4.696846008300781e-05, logit=10.375, token_id=17810, metadata=None)))])\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.672, logit=19.250)', '\" The\"[578] (p=0.103, logit=17.375)', '\" MIX\"[81309] (p=0.091, logit=17.250)', '\" Tablet\"[58403] (p=0.019, logit=15.688)', '\" A\"[362] (p=0.016, logit=15.500)']\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.671875, logit=19.25, token_id=72392, metadata=None))), (58403, (4, PredictedToken(token=' Tablet', prob=0.01904296875, logit=15.6875, token_id=58403, metadata=None))), (47033, (6, PredictedToken(token=' Printer', prob=0.015869140625, logit=15.5, token_id=47033, metadata=None))), (17810, (29, PredictedToken(token=' Cat', prob=0.00069427490234375, logit=12.375, token_id=17810, metadata=None))), (75258, (32, PredictedToken(token=' Refriger', prob=0.000652313232421875, logit=12.3125, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:01 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:40:01 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     patch_prediction=['\" Pendant\"[81501] (p=0.875, logit=21.000)', '\" The\"[578] (p=0.049, logit=18.125)', '\" C\"[356] (p=0.026, logit=17.500)', '\" A\"[362] (p=0.012, logit=16.750)', '\" St\"[800] (p=0.004, logit=15.688)']\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     clean_prediction=['\" Ottoman\"[70110] (p=0.479, logit=18.000)', '\" Brace\"[70306] (p=0.137, logit=16.750)', '\" The\"[578] (p=0.083, logit=16.250)', '\" Cabinet\"[34046] (p=0.057, logit=15.875)', '\" Trump\"[3420] (p=0.031, logit=15.250)']\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     clean_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.478515625, logit=18.0, token_id=70110, metadata=None))), (70306, (2, PredictedToken(token=' Brace', prob=0.13671875, logit=16.75, token_id=70306, metadata=None))), (34046, (4, PredictedToken(token=' Cabinet', prob=0.05712890625, logit=15.875, token_id=34046, metadata=None))), (3420, (5, PredictedToken(token=' Trump', prob=0.030517578125, logit=15.25, token_id=3420, metadata=None))), (29625, (9, PredictedToken(token=' Chain', prob=0.011962890625, logit=14.3125, token_id=29625, metadata=None)))])\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     int_prediction=['\" Brace\"[70306] (p=0.805, logit=19.500)', '\" Trump\"[3420] (p=0.051, logit=16.750)', '\" The\"[578] (p=0.035, logit=16.375)', '\" Chain\"[29625] (p=0.011, logit=15.188)', '\" A\"[362] (p=0.010, logit=15.125)']\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     int_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.8046875, logit=19.5, token_id=70306, metadata=None))), (3420, (2, PredictedToken(token=' Trump', prob=0.05126953125, logit=16.75, token_id=3420, metadata=None))), (29625, (4, PredictedToken(token=' Chain', prob=0.0107421875, logit=15.1875, token_id=29625, metadata=None))), (34046, (15, PredictedToken(token=' Cabinet', prob=0.00136566162109375, logit=13.125, token_id=34046, metadata=None))), (70110, (16, PredictedToken(token=' Ottoman', prob=0.00136566162109375, logit=13.125, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:02 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.688, logit=20.375)', '\" Tennis\"[58251] (p=0.105, logit=18.500)', '\" The\"[578] (p=0.105, logit=18.500)', '\" A\"[362] (p=0.039, logit=17.500)', '\" FOOT\"[81137] (p=0.007, logit=15.750)']\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.715, logit=20.375)', '\" The\"[578] (p=0.124, logit=18.625)', '\" Slow\"[39247] (p=0.046, logit=17.625)', '\" R\"[432] (p=0.028, logit=17.125)', '\" CO\"[7432] (p=0.019, logit=16.750)']\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.71484375, logit=20.375, token_id=27171, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.045654296875, logit=17.625, token_id=39247, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.0277099609375, logit=17.125, token_id=432, metadata=None))), (33199, (47, PredictedToken(token=' Lion', prob=0.0001983642578125, logit=12.1875, token_id=33199, metadata=None))), (47589, (75, PredictedToken(token=' Basketball', prob=7.772445678710938e-05, logit=11.25, token_id=47589, metadata=None)))])\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.723, logit=20.750)', '\" R\"[432] (p=0.126, logit=19.000)', '\" The\"[578] (p=0.059, logit=18.250)', '\" A\"[362] (p=0.032, logit=17.625)', '\" Lion\"[33199] (p=0.013, logit=16.750)']\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.72265625, logit=20.75, token_id=47589, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.1259765625, logit=19.0, token_id=432, metadata=None))), (33199, (5, PredictedToken(token=' Lion', prob=0.01324462890625, logit=16.75, token_id=33199, metadata=None))), (27171, (9, PredictedToken(token=' Coffee', prob=0.0026092529296875, logit=15.125, token_id=27171, metadata=None))), (39247, (80, PredictedToken(token=' Slow', prob=5.078315734863281e-05, logit=11.1875, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:03 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:40:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.770, logit=20.875)', '\" The\"[578] (p=0.152, logit=19.250)', '\" L\"[445] (p=0.034, logit=17.750)', '\" A\"[362] (p=0.006, logit=16.000)', '\" There\"[2684] (p=0.003, logit=15.438)']\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     clean_prediction=['\" Pants\"[67553] (p=0.559, logit=19.250)', '\" Sk\"[4923] (p=0.299, logit=18.625)', '\" The\"[578] (p=0.059, logit=17.000)', '\" SK\"[12343] (p=0.007, logit=14.875)', '\" None\"[2290] (p=0.006, logit=14.688)']\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     clean_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.55859375, logit=19.25, token_id=67553, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.298828125, logit=18.625, token_id=4923, metadata=None))), (49431, (12, PredictedToken(token=' Rabbit', prob=0.0025787353515625, logit=13.875, token_id=49431, metadata=None))), (48390, (13, PredictedToken(token=' Lily', prob=0.0022735595703125, logit=13.75, token_id=48390, metadata=None))), (52466, (17, PredictedToken(token=' Warehouse', prob=0.00138092041015625, logit=13.25, token_id=52466, metadata=None))), (96096, (80, PredictedToken(token=' Dolphin', prob=0.00010633468627929688, logit=10.6875, token_id=96096, metadata=None)))])\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.770, logit=19.125)', '\" The\"[578] (p=0.072, logit=16.750)', '\" Lily\"[48390] (p=0.043, logit=16.250)', '\" There\"[2684] (p=0.008, logit=14.562)', '\" D\"[423] (p=0.008, logit=14.500)']\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.76953125, logit=19.125, token_id=96096, metadata=None))), (48390, (3, PredictedToken(token=' Lily', prob=0.04345703125, logit=16.25, token_id=48390, metadata=None))), (67553, (9, PredictedToken(token=' Pants', prob=0.006256103515625, logit=14.3125, token_id=67553, metadata=None))), (49431, (11, PredictedToken(token=' Rabbit', prob=0.003570556640625, logit=13.75, token_id=49431, metadata=None))), (4923, (15, PredictedToken(token=' Sk', prob=0.0023040771484375, logit=13.3125, token_id=4923, metadata=None))), (52466, (18, PredictedToken(token=' Warehouse', prob=0.00157928466796875, logit=12.9375, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:04 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:04 src.selection.optimization DEBUG    torch.Size([7, 36])\n",
      "2025-09-15 09:40:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.535, logit=20.250)', '\" The\"[578] (p=0.367, logit=19.875)', '\" T\"[350] (p=0.024, logit=17.125)', '\" A\"[362] (p=0.016, logit=16.750)', '\" There\"[2684] (p=0.005, logit=15.625)']\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.664, logit=20.125)', '\" The\"[578] (p=0.115, logit=18.375)', '\" Cel\"[47643] (p=0.054, logit=17.625)', '\" There\"[2684] (p=0.054, logit=17.625)', '\" ON\"[6328] (p=0.020, logit=16.625)']\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.6640625, logit=20.125, token_id=87035, metadata=None))), (47643, (4, PredictedToken(token=' Cel', prob=0.054443359375, logit=17.625, token_id=47643, metadata=None))), (11683, (7, PredictedToken(token=' Acc', prob=0.0078125, logit=15.6875, token_id=11683, metadata=None))), (735, (28, PredictedToken(token=' K', prob=0.000682830810546875, logit=13.25, token_id=735, metadata=None))), (36943, (151, PredictedToken(token=' Folder', prob=4.100799560546875e-05, logit=10.4375, token_id=36943, metadata=None))), (57748, (156, PredictedToken(token=' Cedar', prob=3.8623809814453125e-05, logit=10.375, token_id=57748, metadata=None))), (56491, (1624, PredictedToken(token=' Piano', prob=9.387731552124023e-07, logit=6.65625, token_id=56491, metadata=None)))])\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.355, logit=19.125)', '\" The\"[578] (p=0.277, logit=18.875)', '\" Acc\"[11683] (p=0.148, logit=18.250)', '\" There\"[2684] (p=0.070, logit=17.500)', '\" None\"[2290] (p=0.029, logit=16.625)']\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.35546875, logit=19.125, token_id=56491, metadata=None))), (11683, (3, PredictedToken(token=' Acc', prob=0.1484375, logit=18.25, token_id=11683, metadata=None))), (47643, (7, PredictedToken(token=' Cel', prob=0.0146484375, logit=15.9375, token_id=47643, metadata=None))), (735, (9, PredictedToken(token=' K', prob=0.0047607421875, logit=14.8125, token_id=735, metadata=None))), (87035, (64, PredictedToken(token=' Onion', prob=0.00023746490478515625, logit=11.8125, token_id=87035, metadata=None))), (36943, (69, PredictedToken(token=' Folder', prob=0.00020885467529296875, logit=11.6875, token_id=36943, metadata=None))), (57748, (141, PredictedToken(token=' Cedar', prob=4.982948303222656e-05, logit=10.25, token_id=57748, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:05 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.891, logit=21.125)', '\" The\"[578] (p=0.034, logit=17.875)', '\" Scar\"[30760] (p=0.024, logit=17.500)', '\" SOCK\"[35651] (p=0.014, logit=17.000)', '\" socks\"[40086] (p=0.004, logit=15.812)']\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.727, logit=19.625)', '\" The\"[578] (p=0.099, logit=17.625)', '\" Y\"[816] (p=0.032, logit=16.500)', '\" There\"[2684] (p=0.025, logit=16.250)', '\" A\"[362] (p=0.022, logit=16.125)']\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.7265625, logit=19.625, token_id=45332, metadata=None))), (816, (3, PredictedToken(token=' Y', prob=0.031982421875, logit=16.5, token_id=816, metadata=None))), (9939, (8, PredictedToken(token=' Er', prob=0.005218505859375, logit=14.6875, token_id=9939, metadata=None))), (91782, (25, PredictedToken(token=' Shorts', prob=0.000751495361328125, logit=12.75, token_id=91782, metadata=None))), (37326, (31, PredictedToken(token=' Swe', prob=0.00066375732421875, logit=12.625, token_id=37326, metadata=None)))])\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.508, logit=19.000)', '\" Swe\"[37326] (p=0.146, logit=17.750)', '\" The\"[578] (p=0.078, logit=17.125)', '\" There\"[2684] (p=0.042, logit=16.500)', '\" Er\"[9939] (p=0.037, logit=16.375)']\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.5078125, logit=19.0, token_id=91782, metadata=None))), (37326, (2, PredictedToken(token=' Swe', prob=0.1455078125, logit=17.75, token_id=37326, metadata=None))), (9939, (5, PredictedToken(token=' Er', prob=0.036865234375, logit=16.375, token_id=9939, metadata=None))), (45332, (6, PredictedToken(token=' Boat', prob=0.0238037109375, logit=15.9375, token_id=45332, metadata=None))), (816, (10, PredictedToken(token=' Y', prob=0.01123046875, logit=15.1875, token_id=816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:40:06 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:40:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     patch_prediction=['\" Willow\"[65449] (p=0.797, logit=20.000)', '\" The\"[578] (p=0.084, logit=17.750)', '\" W\"[468] (p=0.035, logit=16.875)', '\" WILL\"[29015] (p=0.011, logit=15.750)', '\" Will\"[4946] (p=0.007, logit=15.312)']\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.785, logit=19.875)', '\" The\"[578] (p=0.106, logit=17.875)', '\" Pendant\"[81501] (p=0.034, logit=16.750)', '\" A\"[362] (p=0.006, logit=15.062)', '\" Oak\"[18787] (p=0.006, logit=14.938)']\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.78515625, logit=19.875, token_id=356, metadata=None))), (81501, (3, PredictedToken(token=' Pendant', prob=0.034423828125, logit=16.75, token_id=81501, metadata=None))), (18787, (5, PredictedToken(token=' Oak', prob=0.005645751953125, logit=14.9375, token_id=18787, metadata=None))), (44570, (44, PredictedToken(token=' Maple', prob=0.000247955322265625, logit=11.8125, token_id=44570, metadata=None)))])\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.816, logit=19.625)', '\" The\"[578] (p=0.076, logit=17.250)', '\" Pendant\"[81501] (p=0.028, logit=16.250)', '\" Jewelry\"[62968] (p=0.006, logit=14.750)', '\" A\"[362] (p=0.005, logit=14.625)']\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.81640625, logit=19.625, token_id=356, metadata=None))), (81501, (3, PredictedToken(token=' Pendant', prob=0.02783203125, logit=16.25, token_id=81501, metadata=None))), (18787, (48, PredictedToken(token=' Oak', prob=0.0002574920654296875, logit=11.5625, token_id=18787, metadata=None))), (44570, (72, PredictedToken(token=' Maple', prob=0.00012111663818359375, logit=10.8125, token_id=44570, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:07 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     patch_prediction=['\" Mixer\"[72392] (p=0.447, logit=19.875)', '\" The\"[578] (p=0.240, logit=19.250)', '\" To\"[2057] (p=0.113, logit=18.500)', '\" A\"[362] (p=0.069, logit=18.000)', '\" MIX\"[81309] (p=0.047, logit=17.625)']\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.848, logit=20.250)', '\" Paper\"[18343] (p=0.079, logit=17.875)', '\" The\"[578] (p=0.016, logit=16.250)', '\" None\"[2290] (p=0.008, logit=15.562)', '\" Pen\"[13597] (p=0.006, logit=15.250)']\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.84765625, logit=20.25, token_id=58586, metadata=None))), (18343, (2, PredictedToken(token=' Paper', prob=0.0791015625, logit=17.875, token_id=18343, metadata=None))), (70110, (29, PredictedToken(token=' Ottoman', prob=0.00025177001953125, logit=12.125, token_id=70110, metadata=None))), (98641, (41, PredictedToken(token=' Microwave', prob=0.00020885467529296875, logit=11.9375, token_id=98641, metadata=None))), (88668, (67, PredictedToken(token=' Blender', prob=8.678436279296875e-05, logit=11.0625, token_id=88668, metadata=None)))])\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     int_prediction=['\" Tape\"[58586] (p=0.812, logit=20.250)', '\" Paper\"[18343] (p=0.097, logit=18.125)', '\" Blender\"[88668] (p=0.019, logit=16.500)', '\" The\"[578] (p=0.013, logit=16.125)', '\" None\"[2290] (p=0.010, logit=15.812)']\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     int_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.8125, logit=20.25, token_id=58586, metadata=None))), (18343, (2, PredictedToken(token=' Paper', prob=0.09716796875, logit=18.125, token_id=18343, metadata=None))), (88668, (3, PredictedToken(token=' Blender', prob=0.0191650390625, logit=16.5, token_id=88668, metadata=None))), (98641, (14, PredictedToken(token=' Microwave', prob=0.00177764892578125, logit=14.125, token_id=98641, metadata=None))), (70110, (67, PredictedToken(token=' Ottoman', prob=8.869171142578125e-05, logit=11.125, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:08 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:08 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.816, logit=20.875)', '\" Soap\"[61731] (p=0.052, logit=18.125)', '\" The\"[578] (p=0.032, logit=17.625)', '\" BAT\"[79081] (p=0.019, logit=17.125)', '\" Tub\"[40640] (p=0.013, logit=16.750)']\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.496, logit=19.000)', '\" Sk\"[4923] (p=0.266, logit=18.375)', '\" The\"[578] (p=0.111, logit=17.500)', '\" A\"[362] (p=0.028, logit=16.125)', '\" SK\"[12343] (p=0.009, logit=15.000)']\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.49609375, logit=19.0, token_id=328, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.265625, logit=18.375, token_id=4923, metadata=None))), (23262, (6, PredictedToken(token=' Comb', prob=0.008544921875, logit=14.9375, token_id=23262, metadata=None))), (469, (12, PredictedToken(token=' E', prob=0.003143310546875, logit=13.9375, token_id=469, metadata=None))), (34954, (49, PredictedToken(token=' Mirror', prob=0.0003108978271484375, logit=11.625, token_id=34954, metadata=None)))])\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.738, logit=20.000)', '\" Mirror\"[34954] (p=0.078, logit=17.750)', '\" The\"[578] (p=0.042, logit=17.125)', '\" Comb\"[23262] (p=0.025, logit=16.625)', '\" E\"[469] (p=0.025, logit=16.625)']\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.73828125, logit=20.0, token_id=328, metadata=None))), (34954, (2, PredictedToken(token=' Mirror', prob=0.07763671875, logit=17.75, token_id=34954, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.0252685546875, logit=16.625, token_id=469, metadata=None))), (23262, (5, PredictedToken(token=' Comb', prob=0.0252685546875, logit=16.625, token_id=23262, metadata=None))), (4923, (6, PredictedToken(token=' Sk', prob=0.017333984375, logit=16.25, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:09 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.574, logit=19.750)', '\" Car\"[3341] (p=0.145, logit=18.375)', '\" The\"[578] (p=0.145, logit=18.375)', '\" A\"[362] (p=0.047, logit=17.250)', '\" There\"[2684] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:40:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     clean_prediction=['\" Re\"[1050] (p=0.805, logit=20.000)', '\" The\"[578] (p=0.066, logit=17.500)', '\" A\"[362] (p=0.024, logit=16.500)', '\" RE\"[3680] (p=0.017, logit=16.125)', '\" Fl\"[3061] (p=0.017, logit=16.125)']\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     clean_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.8046875, logit=20.0, token_id=1050, metadata=None))), (3061, (4, PredictedToken(token=' Fl', prob=0.0167236328125, logit=16.125, token_id=3061, metadata=None))), (29318, (6, PredictedToken(token=' Dress', prob=0.0101318359375, logit=15.625, token_id=29318, metadata=None))), (13000, (10, PredictedToken(token=' Van', prob=0.0032806396484375, logit=14.5, token_id=13000, metadata=None))), (20423, (19, PredictedToken(token=' Amb', prob=0.00113677978515625, logit=13.4375, token_id=20423, metadata=None)))])\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.711, logit=19.625)', '\" VAN\"[97753] (p=0.075, logit=17.375)', '\" The\"[578] (p=0.066, logit=17.250)', '\" Amb\"[20423] (p=0.045, logit=16.875)', '\" Fl\"[3061] (p=0.031, logit=16.500)']\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.7109375, logit=19.625, token_id=13000, metadata=None))), (20423, (4, PredictedToken(token=' Amb', prob=0.04541015625, logit=16.875, token_id=20423, metadata=None))), (3061, (5, PredictedToken(token=' Fl', prob=0.0311279296875, logit=16.5, token_id=3061, metadata=None))), (29318, (11, PredictedToken(token=' Dress', prob=0.0032806396484375, logit=14.25, token_id=29318, metadata=None))), (1050, (19, PredictedToken(token=' Re', prob=0.001068115234375, logit=13.125, token_id=1050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:10 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:10 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     patch_prediction=['\" Chain\"[29625] (p=0.867, logit=20.125)', '\" The\"[578] (p=0.023, logit=16.500)', '\" Watch\"[10573] (p=0.018, logit=16.250)', '\" None\"[2290] (p=0.014, logit=16.000)', '\" Suit\"[33711] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:40:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     clean_prediction=['\" Re\"[1050] (p=0.781, logit=19.875)', '\" The\"[578] (p=0.105, logit=17.875)', '\" RE\"[3680] (p=0.024, logit=16.375)', '\" A\"[362] (p=0.021, logit=16.250)', '\" It\"[1102] (p=0.008, logit=15.250)']\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     clean_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.78125, logit=19.875, token_id=1050, metadata=None))), (13120, (10, PredictedToken(token=' Night', prob=0.0026397705078125, logit=14.1875, token_id=13120, metadata=None))), (18654, (12, PredictedToken(token=' Micro', prob=0.0023345947265625, logit=14.0625, token_id=18654, metadata=None))), (22249, (19, PredictedToken(token=' Ring', prob=0.0011749267578125, logit=13.375, token_id=22249, metadata=None))), (426, (20, PredictedToken(token=' B', prob=0.00103759765625, logit=13.25, token_id=426, metadata=None))), (65329, (40, PredictedToken(token=' Elm', prob=0.000278472900390625, logit=11.9375, token_id=65329, metadata=None))), (30760, (207, PredictedToken(token=' Scar', prob=2.288818359375e-05, logit=9.4375, token_id=30760, metadata=None)))])\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.777, logit=20.125)', '\" The\"[578] (p=0.072, logit=17.750)', '\" Elm\"[65329] (p=0.050, logit=17.375)', '\" Night\"[13120] (p=0.010, logit=15.812)', '\" b\"[293] (p=0.009, logit=15.625)']\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.77734375, logit=20.125, token_id=426, metadata=None))), (65329, (3, PredictedToken(token=' Elm', prob=0.049560546875, logit=17.375, token_id=65329, metadata=None))), (13120, (4, PredictedToken(token=' Night', prob=0.0103759765625, logit=15.8125, token_id=13120, metadata=None))), (22249, (8, PredictedToken(token=' Ring', prob=0.004913330078125, logit=15.0625, token_id=22249, metadata=None))), (18654, (12, PredictedToken(token=' Micro', prob=0.00408935546875, logit=14.875, token_id=18654, metadata=None))), (30760, (27, PredictedToken(token=' Scar', prob=0.00075531005859375, logit=13.1875, token_id=30760, metadata=None))), (1050, (41, PredictedToken(token=' Re', prob=0.0003566741943359375, logit=12.4375, token_id=1050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:11 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:11 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     patch_prediction=['\" Shirt\"[55807] (p=0.836, logit=20.500)', '\" Suit\"[33711] (p=0.042, logit=17.500)', '\" The\"[578] (p=0.037, logit=17.375)', '\" SH\"[6570] (p=0.015, logit=16.500)', '\" A\"[362] (p=0.015, logit=16.500)']\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.805, logit=20.250)', '\" The\"[578] (p=0.085, logit=18.000)', '\" A\"[362] (p=0.035, logit=17.125)', '\" None\"[2290] (p=0.008, logit=15.688)', '\" It\"[1102] (p=0.006, logit=15.312)']\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.8046875, logit=20.25, token_id=423, metadata=None))), (97796, (7, PredictedToken(token=' Skate', prob=0.004791259765625, logit=15.125, token_id=97796, metadata=None))), (328, (8, PredictedToken(token=' S', prob=0.00372314453125, logit=14.875, token_id=328, metadata=None))), (38930, (9, PredictedToken(token=' Bike', prob=0.002899169921875, logit=14.625, token_id=38930, metadata=None))), (67553, (67, PredictedToken(token=' Pants', prob=9.34600830078125e-05, logit=11.1875, token_id=67553, metadata=None)))])\n",
      "2025-09-15 09:40:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.457, logit=19.375)', '\" S\"[328] (p=0.357, logit=19.125)', '\" The\"[578] (p=0.048, logit=17.125)', '\" Skate\"[97796] (p=0.033, logit=16.750)', '\" None\"[2290] (p=0.020, logit=16.250)']\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.45703125, logit=19.375, token_id=67553, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.357421875, logit=19.125, token_id=328, metadata=None))), (97796, (4, PredictedToken(token=' Skate', prob=0.033203125, logit=16.75, token_id=97796, metadata=None))), (38930, (7, PredictedToken(token=' Bike', prob=0.004791259765625, logit=14.8125, token_id=38930, metadata=None))), (423, (13, PredictedToken(token=' D', prob=0.0025634765625, logit=14.1875, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:12 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:12 src.selection.optimization DEBUG    torch.Size([7, 36])\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     patch_prediction=['\" Re\"[1050] (p=0.773, logit=20.875)', '\" The\"[578] (p=0.119, logit=19.000)', '\" A\"[362] (p=0.039, logit=17.875)', '\" Head\"[11452] (p=0.016, logit=17.000)', '\" RE\"[3680] (p=0.016, logit=17.000)']\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.664, logit=20.000)', '\" There\"[2684] (p=0.116, logit=18.250)', '\" The\"[578] (p=0.090, logit=18.000)', '\" Tomato\"[94091] (p=0.054, logit=17.500)', '\" ON\"[6328] (p=0.011, logit=15.875)']\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.6640625, logit=20.0, token_id=87035, metadata=None))), (94091, (4, PredictedToken(token=' Tomato', prob=0.054443359375, logit=17.5, token_id=94091, metadata=None))), (393, (13, PredictedToken(token=' P', prob=0.00145721435546875, logit=13.875, token_id=393, metadata=None))), (13394, (84, PredictedToken(token=' Bed', prob=6.818771362304688e-05, logit=10.8125, token_id=13394, metadata=None))), (98641, (163, PredictedToken(token=' Microwave', prob=2.5033950805664062e-05, logit=9.8125, token_id=98641, metadata=None))), (47033, (203, PredictedToken(token=' Printer', prob=1.609325408935547e-05, logit=9.375, token_id=47033, metadata=None))), (27171, (452, PredictedToken(token=' Coffee', prob=4.6193599700927734e-06, logit=8.125, token_id=27171, metadata=None)))])\n",
      "2025-09-15 09:40:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.301, logit=18.500)', '\" The\"[578] (p=0.183, logit=18.000)', '\" Coffee\"[27171] (p=0.161, logit=17.875)', '\" There\"[2684] (p=0.143, logit=17.750)', '\" Microwave\"[98641] (p=0.111, logit=17.500)']\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.30078125, logit=18.5, token_id=47033, metadata=None))), (27171, (3, PredictedToken(token=' Coffee', prob=0.1611328125, logit=17.875, token_id=27171, metadata=None))), (98641, (5, PredictedToken(token=' Microwave', prob=0.11083984375, logit=17.5, token_id=98641, metadata=None))), (393, (7, PredictedToken(token=' P', prob=0.010986328125, logit=15.1875, token_id=393, metadata=None))), (13394, (26, PredictedToken(token=' Bed', prob=0.00079345703125, logit=12.5625, token_id=13394, metadata=None))), (94091, (79, PredictedToken(token=' Tomato', prob=0.0001468658447265625, logit=10.875, token_id=94091, metadata=None))), (87035, (277, PredictedToken(token=' Onion', prob=1.8715858459472656e-05, logit=8.8125, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:13 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:13 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     patch_prediction=['\" Onion\"[87035] (p=0.637, logit=19.625)', '\" The\"[578] (p=0.206, logit=18.500)', '\" There\"[2684] (p=0.028, logit=16.500)', '\" ON\"[6328] (p=0.025, logit=16.375)', '\" Z\"[1901] (p=0.015, logit=15.875)']\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     clean_prediction=['\" Mixer\"[72392] (p=0.424, logit=19.625)', '\" The\"[578] (p=0.256, logit=19.125)', '\" Slow\"[39247] (p=0.138, logit=18.500)', '\" A\"[362] (p=0.065, logit=17.750)', '\" MIX\"[81309] (p=0.045, logit=17.375)']\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     clean_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.423828125, logit=19.625, token_id=72392, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.1376953125, logit=18.5, token_id=39247, metadata=None))), (8868, (8, PredictedToken(token=' Blue', prob=0.0030364990234375, logit=14.6875, token_id=8868, metadata=None))), (3341, (9, PredictedToken(token=' Car', prob=0.0028533935546875, logit=14.625, token_id=3341, metadata=None))), (69755, (28, PredictedToken(token=' Notebook', prob=0.00081634521484375, logit=13.375, token_id=69755, metadata=None))), (47643, (60, PredictedToken(token=' Cel', prob=0.00019359588623046875, logit=11.9375, token_id=47643, metadata=None))), (16478, (134, PredictedToken(token=' Chair', prob=3.5762786865234375e-05, logit=10.25, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:40:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.410, logit=19.125)', '\" Car\"[3341] (p=0.318, logit=18.875)', '\" The\"[578] (p=0.171, logit=18.250)', '\" Chair\"[16478] (p=0.012, logit=15.562)', '\" There\"[2684] (p=0.012, logit=15.562)']\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.41015625, logit=19.125, token_id=47643, metadata=None))), (3341, (2, PredictedToken(token=' Car', prob=0.318359375, logit=18.875, token_id=3341, metadata=None))), (16478, (5, PredictedToken(token=' Chair', prob=0.0115966796875, logit=15.5625, token_id=16478, metadata=None))), (8868, (8, PredictedToken(token=' Blue', prob=0.0035400390625, logit=14.375, token_id=8868, metadata=None))), (39247, (10, PredictedToken(token=' Slow', prob=0.0029296875, logit=14.1875, token_id=39247, metadata=None))), (69755, (191, PredictedToken(token=' Notebook', prob=2.7060508728027344e-05, logit=9.5, token_id=69755, metadata=None))), (72392, (335, PredictedToken(token=' Mixer', prob=1.1980533599853516e-05, logit=8.6875, token_id=72392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:14 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.844, logit=20.875)', '\" School\"[6150] (p=0.069, logit=18.375)', '\" The\"[578] (p=0.037, logit=17.750)', '\" A\"[362] (p=0.018, logit=17.000)', '\" MOS\"[74174] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     clean_prediction=['\" Rabbit\"[49431] (p=0.664, logit=19.625)', '\" The\"[578] (p=0.148, logit=18.125)', '\" Cow\"[22607] (p=0.029, logit=16.500)', '\" R\"[432] (p=0.026, logit=16.375)', '\" A\"[362] (p=0.026, logit=16.375)']\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     clean_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.6640625, logit=19.625, token_id=49431, metadata=None))), (22607, (3, PredictedToken(token=' Cow', prob=0.029296875, logit=16.5, token_id=22607, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.005767822265625, logit=14.875, token_id=4923, metadata=None))), (68027, (122, PredictedToken(token=' Sax', prob=9.298324584960938e-05, logit=10.75, token_id=68027, metadata=None))), (53889, (203, PredictedToken(token=' Apartment', prob=3.886222839355469e-05, logit=9.875, token_id=53889, metadata=None)))])\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.824, logit=19.750)', '\" The\"[578] (p=0.053, logit=17.000)', '\" Cow\"[22607] (p=0.028, logit=16.375)', '\" There\"[2684] (p=0.013, logit=15.562)', '\" A\"[362] (p=0.012, logit=15.500)']\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.82421875, logit=19.75, token_id=4923, metadata=None))), (22607, (3, PredictedToken(token=' Cow', prob=0.0281982421875, logit=16.375, token_id=22607, metadata=None))), (53889, (6, PredictedToken(token=' Apartment', prob=0.00860595703125, logit=15.1875, token_id=53889, metadata=None))), (68027, (12, PredictedToken(token=' Sax', prob=0.002044677734375, logit=13.75, token_id=68027, metadata=None))), (49431, (152, PredictedToken(token=' Rabbit', prob=3.981590270996094e-05, logit=9.8125, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:14 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:14 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:40:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.707, logit=20.875)', '\" The\"[578] (p=0.123, logit=19.125)', '\" LO\"[5125] (p=0.051, logit=18.250)', '\" A\"[362] (p=0.040, logit=18.000)', '\" Brace\"[70306] (p=0.024, logit=17.500)']\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.859, logit=20.500)', '\" C\"[356] (p=0.043, logit=17.500)', '\" There\"[2684] (p=0.023, logit=16.875)', '\" The\"[578] (p=0.023, logit=16.875)', '\" None\"[2290] (p=0.012, logit=16.250)']\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.859375, logit=20.5, token_id=1901, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.042724609375, logit=17.5, token_id=356, metadata=None))), (58251, (11, PredictedToken(token=' Tennis', prob=0.0018768310546875, logit=14.375, token_id=58251, metadata=None))), (29625, (17, PredictedToken(token=' Chain', prob=0.000690460205078125, logit=13.375, token_id=29625, metadata=None))), (36895, (76, PredictedToken(token=' Eagle', prob=8.7738037109375e-05, logit=11.3125, token_id=36895, metadata=None))), (81501, (142, PredictedToken(token=' Pendant', prob=2.682209014892578e-05, logit=10.125, token_id=81501, metadata=None)))])\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     int_prediction=['\" Pendant\"[81501] (p=0.520, logit=19.625)', '\" Eagle\"[36895] (p=0.191, logit=18.625)', '\" Chain\"[29625] (p=0.149, logit=18.375)', '\" The\"[578] (p=0.043, logit=17.125)', '\" There\"[2684] (p=0.026, logit=16.625)']\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     int_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.51953125, logit=19.625, token_id=81501, metadata=None))), (36895, (2, PredictedToken(token=' Eagle', prob=0.19140625, logit=18.625, token_id=36895, metadata=None))), (29625, (3, PredictedToken(token=' Chain', prob=0.1494140625, logit=18.375, token_id=29625, metadata=None))), (58251, (7, PredictedToken(token=' Tennis', prob=0.006988525390625, logit=15.3125, token_id=58251, metadata=None))), (356, (12, PredictedToken(token=' C', prob=0.0019989013671875, logit=14.0625, token_id=356, metadata=None))), (1901, (86, PredictedToken(token=' Z', prob=6.866455078125e-05, logit=10.6875, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:15 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:40:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.543, logit=19.750)', '\" Suit\"[33711] (p=0.328, logit=19.250)', '\" The\"[578] (p=0.057, logit=17.500)', '\" SU\"[15857] (p=0.006, logit=15.250)', '\" A\"[362] (p=0.005, logit=15.125)']\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     clean_prediction=['\" Amb\"[20423] (p=0.398, logit=19.500)', '\" Motorcycle\"[70762] (p=0.311, logit=19.250)', '\" The\"[578] (p=0.146, logit=18.500)', '\" An\"[1556] (p=0.069, logit=17.750)', '\" There\"[2684] (p=0.011, logit=15.938)']\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     clean_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.3984375, logit=19.5, token_id=20423, metadata=None))), (70762, (2, PredictedToken(token=' Motorcycle', prob=0.310546875, logit=19.25, token_id=70762, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.00469970703125, logit=15.0625, token_id=356, metadata=None))), (59825, (79, PredictedToken(token=' Tie', prob=9.775161743164062e-05, logit=11.1875, token_id=59825, metadata=None))), (22050, (118, PredictedToken(token=' Hat', prob=4.9114227294921875e-05, logit=10.5, token_id=22050, metadata=None)))])\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.582, logit=20.000)', '\" Motorcycle\"[70762] (p=0.214, logit=19.000)', '\" The\"[578] (p=0.101, logit=18.250)', '\" A\"[362] (p=0.018, logit=16.500)', '\" There\"[2684] (p=0.016, logit=16.375)']\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.58203125, logit=20.0, token_id=59825, metadata=None))), (70762, (2, PredictedToken(token=' Motorcycle', prob=0.2138671875, logit=19.0, token_id=70762, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0106201171875, logit=16.0, token_id=356, metadata=None))), (22050, (7, PredictedToken(token=' Hat', prob=0.006072998046875, logit=15.4375, token_id=22050, metadata=None))), (20423, (11, PredictedToken(token=' Amb', prob=0.003448486328125, logit=14.875, token_id=20423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:16 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:40:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:17 src.selection.optimization INFO     patch_prediction=['\" Charm\"[58600] (p=0.352, logit=19.000)', '\" D\"[423] (p=0.273, logit=18.750)', '\" Pendant\"[81501] (p=0.214, logit=18.500)', '\" The\"[578] (p=0.042, logit=16.875)', '\" A\"[362] (p=0.037, logit=16.750)']\n",
      "2025-09-15 09:40:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:17 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.848, logit=20.375)', '\" The\"[578] (p=0.089, logit=18.125)', '\" BOX\"[53783] (p=0.009, logit=15.812)', '\" C\"[356] (p=0.004, logit=15.000)', '\" #\"[674] (p=0.003, logit=14.875)']\n",
      "2025-09-15 09:40:17 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.84765625, logit=20.375, token_id=72683, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.00390625, logit=15.0, token_id=356, metadata=None))), (38673, (18, PredictedToken(token=' Yoga', prob=0.00112152099609375, logit=13.75, token_id=38673, metadata=None))), (57915, (21, PredictedToken(token=' Ank', prob=0.0010528564453125, logit=13.6875, token_id=57915, metadata=None))), (921, (83, PredictedToken(token=' Ch', prob=7.62939453125e-05, logit=11.0625, token_id=921, metadata=None)))])\n",
      "2025-09-15 09:40:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.582, logit=19.750)', '\" Ank\"[57915] (p=0.188, logit=18.625)', '\" Boxing\"[72683] (p=0.079, logit=17.750)', '\" The\"[578] (p=0.079, logit=17.750)', '\" A\"[362] (p=0.014, logit=16.000)']\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.58203125, logit=19.75, token_id=356, metadata=None))), (57915, (2, PredictedToken(token=' Ank', prob=0.1884765625, logit=18.625, token_id=57915, metadata=None))), (72683, (4, PredictedToken(token=' Boxing', prob=0.07861328125, logit=17.75, token_id=72683, metadata=None))), (38673, (30, PredictedToken(token=' Yoga', prob=0.00049591064453125, logit=12.6875, token_id=38673, metadata=None))), (921, (35, PredictedToken(token=' Ch', prob=0.0003204345703125, logit=12.25, token_id=921, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:18 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:18 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.695, logit=19.750)', '\" The\"[578] (p=0.121, logit=18.000)', '\" Baseball\"[38258] (p=0.065, logit=17.375)', '\" A\"[362] (p=0.039, logit=16.875)', '\" BAT\"[79081] (p=0.019, logit=16.125)']\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.824, logit=21.000)', '\" The\"[578] (p=0.077, logit=18.625)', '\" Potato\"[78703] (p=0.028, logit=17.625)', '\" AS\"[5871] (p=0.017, logit=17.125)', '\" There\"[2684] (p=0.012, logit=16.750)']\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.82421875, logit=21.0, token_id=1666, metadata=None))), (78703, (3, PredictedToken(token=' Potato', prob=0.0281982421875, logit=17.625, token_id=78703, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.00131988525390625, logit=14.5625, token_id=356, metadata=None))), (41342, (83, PredictedToken(token=' Hockey', prob=5.435943603515625e-05, logit=11.375, token_id=41342, metadata=None))), (6690, (87, PredictedToken(token=' Air', prob=4.792213439941406e-05, logit=11.25, token_id=6690, metadata=None))), (21424, (154, PredictedToken(token=' Football', prob=1.8835067749023438e-05, logit=10.3125, token_id=21424, metadata=None))), (68867, (529, PredictedToken(token=' Coat', prob=2.250075340270996e-06, logit=8.1875, token_id=68867, metadata=None)))])\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.703, logit=20.625)', '\" The\"[578] (p=0.157, logit=19.125)', '\" Football\"[21424] (p=0.040, logit=17.750)', '\" A\"[362] (p=0.031, logit=17.500)', '\" H\"[473] (p=0.013, logit=16.625)']\n",
      "2025-09-15 09:40:18 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.703125, logit=20.625, token_id=41342, metadata=None))), (21424, (3, PredictedToken(token=' Football', prob=0.039794921875, logit=17.75, token_id=21424, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.00347900390625, logit=15.3125, token_id=356, metadata=None))), (1666, (10, PredictedToken(token=' As', prob=0.0025482177734375, logit=15.0, token_id=1666, metadata=None))), (78703, (11, PredictedToken(token=' Potato', prob=0.0023956298828125, logit=14.9375, token_id=78703, metadata=None))), (6690, (275, PredictedToken(token=' Air', prob=6.705522537231445e-06, logit=9.0625, token_id=6690, metadata=None))), (68867, (1631, PredictedToken(token=' Coat', prob=5.327165126800537e-07, logit=6.53125, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:19 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.754, logit=20.375)', '\" The\"[578] (p=0.131, logit=18.625)', '\" Mar\"[2947] (p=0.023, logit=16.875)', '\" A\"[362] (p=0.014, logit=16.375)', '\" L\"[445] (p=0.012, logit=16.250)']\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.879, logit=20.750)', '\" The\"[578] (p=0.050, logit=17.875)', '\" R\"[432] (p=0.016, logit=16.750)', '\" Stadium\"[23462] (p=0.004, logit=15.312)', '\" BOX\"[53783] (p=0.003, logit=15.188)']\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.87890625, logit=20.75, token_id=72683, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.01611328125, logit=16.75, token_id=432, metadata=None))), (23462, (4, PredictedToken(token=' Stadium', prob=0.0038299560546875, logit=15.3125, token_id=23462, metadata=None))), (921, (36, PredictedToken(token=' Ch', prob=0.00022983551025390625, logit=12.5, token_id=921, metadata=None))), (16344, (368, PredictedToken(token=' Rose', prob=4.470348358154297e-06, logit=8.5625, token_id=16344, metadata=None)))])\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.758, logit=19.500)', '\" The\"[578] (p=0.055, logit=16.875)', '\" Ch\"[921] (p=0.049, logit=16.750)', '\" R\"[432] (p=0.033, logit=16.375)', '\" A\"[362] (p=0.015, logit=15.562)']\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.7578125, logit=19.5, token_id=16344, metadata=None))), (921, (3, PredictedToken(token=' Ch', prob=0.048583984375, logit=16.75, token_id=921, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.033447265625, logit=16.375, token_id=432, metadata=None))), (72683, (14, PredictedToken(token=' Boxing', prob=0.0030975341796875, logit=14.0, token_id=72683, metadata=None))), (23462, (23, PredictedToken(token=' Stadium', prob=0.00121307373046875, logit=13.0625, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:19 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:19 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:20 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.672, logit=19.375)', '\" The\"[578] (p=0.117, logit=17.625)', '\" Elm\"[65329] (p=0.081, logit=17.250)', '\" There\"[2684] (p=0.015, logit=15.562)', '\" B\"[426] (p=0.011, logit=15.250)']\n",
      "2025-09-15 09:40:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:20 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.494, logit=18.625)', '\" The\"[578] (p=0.206, logit=17.750)', '\" TABLE\"[14700] (p=0.052, logit=16.375)', '\" A\"[362] (p=0.041, logit=16.125)', '\" Smart\"[16147] (p=0.016, logit=15.188)']\n",
      "2025-09-15 09:40:20 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.494140625, logit=18.625, token_id=58403, metadata=None))), (16147, (5, PredictedToken(token=' Smart', prob=0.015869140625, logit=15.1875, token_id=16147, metadata=None))), (33578, (6, PredictedToken(token=' Palm', prob=0.01397705078125, logit=15.0625, token_id=33578, metadata=None))), (70762, (12, PredictedToken(token=' Motorcycle', prob=0.007049560546875, logit=14.375, token_id=70762, metadata=None))), (44570, (42, PredictedToken(token=' Maple', prob=0.00101470947265625, logit=12.4375, token_id=44570, metadata=None)))])\n",
      "2025-09-15 09:40:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.699, logit=18.625)', '\" The\"[578] (p=0.095, logit=16.625)', '\" Tablet\"[58403] (p=0.051, logit=16.000)', '\" A\"[362] (p=0.012, logit=14.562)', '\" There\"[2684] (p=0.009, logit=14.312)']\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.69921875, logit=18.625, token_id=33578, metadata=None))), (58403, (3, PredictedToken(token=' Tablet', prob=0.05078125, logit=16.0, token_id=58403, metadata=None))), (44570, (10, PredictedToken(token=' Maple', prob=0.005035400390625, logit=13.6875, token_id=44570, metadata=None))), (70762, (17, PredictedToken(token=' Motorcycle', prob=0.002532958984375, logit=13.0, token_id=70762, metadata=None))), (16147, (24, PredictedToken(token=' Smart', prob=0.001739501953125, logit=12.625, token_id=16147, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:21 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     patch_prediction=['\" Binder\"[91263] (p=0.895, logit=20.750)', '\" The\"[578] (p=0.031, logit=17.375)', '\" A\"[362] (p=0.019, logit=16.875)', '\" R\"[432] (p=0.011, logit=16.375)', '\" To\"[2057] (p=0.006, logit=15.812)']\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.766, logit=20.500)', '\" The\"[578] (p=0.118, logit=18.625)', '\" A\"[362] (p=0.043, logit=17.625)', '\" BLE\"[52818] (p=0.006, logit=15.625)', '\" Food\"[12369] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.765625, logit=20.5, token_id=88668, metadata=None))), (12369, (5, PredictedToken(token=' Food', prob=0.0054931640625, logit=15.5625, token_id=12369, metadata=None))), (816, (6, PredictedToken(token=' Y', prob=0.0040283203125, logit=15.25, token_id=816, metadata=None))), (63606, (9, PredictedToken(token=' Stap', prob=0.0035552978515625, logit=15.125, token_id=63606, metadata=None))), (2522, (12, PredictedToken(token=' Sc', prob=0.00244140625, logit=14.75, token_id=2522, metadata=None)))])\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     int_prediction=['\" Sc\"[2522] (p=0.625, logit=19.750)', '\" Stap\"[63606] (p=0.140, logit=18.250)', '\" The\"[578] (p=0.108, logit=18.000)', '\" Food\"[12369] (p=0.035, logit=16.875)', '\" A\"[362] (p=0.021, logit=16.375)']\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     int_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.625, logit=19.75, token_id=2522, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.1396484375, logit=18.25, token_id=63606, metadata=None))), (12369, (4, PredictedToken(token=' Food', prob=0.03515625, logit=16.875, token_id=12369, metadata=None))), (816, (7, PredictedToken(token=' Y', prob=0.00738525390625, logit=15.3125, token_id=816, metadata=None))), (88668, (8, PredictedToken(token=' Blender', prob=0.005401611328125, logit=15.0, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:21 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.801, logit=20.500)', '\" Jeans\"[82507] (p=0.066, logit=18.000)', '\" The\"[578] (p=0.040, logit=17.500)', '\" SOCK\"[35651] (p=0.024, logit=17.000)', '\" Sc\"[2522] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     clean_prediction=['\" Surf\"[65197] (p=0.430, logit=19.375)', '\" Boxing\"[72683] (p=0.379, logit=19.250)', '\" The\"[578] (p=0.096, logit=17.875)', '\" SUR\"[53083] (p=0.012, logit=15.812)', '\" A\"[362] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     clean_track=OrderedDict([(65197, (1, PredictedToken(token=' Surf', prob=0.4296875, logit=19.375, token_id=65197, metadata=None))), (72683, (2, PredictedToken(token=' Boxing', prob=0.37890625, logit=19.25, token_id=72683, metadata=None))), (33711, (32, PredictedToken(token=' Suit', prob=0.000644683837890625, logit=12.875, token_id=33711, metadata=None))), (29318, (309, PredictedToken(token=' Dress', prob=1.043081283569336e-05, logit=8.75, token_id=29318, metadata=None))), (36943, (439, PredictedToken(token=' Folder', prob=6.3478946685791016e-06, logit=8.25, token_id=36943, metadata=None)))])\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.727, logit=20.375)', '\" Suit\"[33711] (p=0.068, logit=18.000)', '\" The\"[578] (p=0.068, logit=18.000)', '\" Boxing\"[72683] (p=0.046, logit=17.625)', '\" A\"[362] (p=0.022, logit=16.875)']\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.7265625, logit=20.375, token_id=29318, metadata=None))), (33711, (3, PredictedToken(token=' Suit', prob=0.06787109375, logit=18.0, token_id=33711, metadata=None))), (72683, (4, PredictedToken(token=' Boxing', prob=0.04638671875, logit=17.625, token_id=72683, metadata=None))), (36943, (6, PredictedToken(token=' Folder', prob=0.00592041015625, logit=15.5625, token_id=36943, metadata=None))), (65197, (12, PredictedToken(token=' Surf', prob=0.002044677734375, logit=14.5, token_id=65197, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:22 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:22 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:40:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.633, logit=19.875)', '\" Tie\"[59825] (p=0.182, logit=18.625)', '\" The\"[578] (p=0.097, logit=18.000)', '\" There\"[2684] (p=0.017, logit=16.250)', '\" Glo\"[25372] (p=0.011, logit=15.812)']\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.816, logit=21.125)', '\" The\"[578] (p=0.110, logit=19.125)', '\" PL\"[10528] (p=0.015, logit=17.125)', '\" A\"[362] (p=0.015, logit=17.125)', '\" There\"[2684] (p=0.009, logit=16.625)']\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.81640625, logit=21.125, token_id=84409, metadata=None))), (76924, (6, PredictedToken(token=' Banana', prob=0.0054931640625, logit=16.125, token_id=76924, metadata=None))), (31181, (54, PredictedToken(token=' Clar', prob=8.344650268554688e-05, logit=11.9375, token_id=31181, metadata=None))), (22607, (148, PredictedToken(token=' Cow', prob=1.5497207641601562e-05, logit=10.25, token_id=22607, metadata=None))), (33711, (319, PredictedToken(token=' Suit', prob=4.708766937255859e-06, logit=9.0625, token_id=33711, metadata=None))), (45332, (514, PredictedToken(token=' Boat', prob=2.2202730178833008e-06, logit=8.3125, token_id=45332, metadata=None))), (22050, (579, PredictedToken(token=' Hat', prob=1.8477439880371094e-06, logit=8.125, token_id=22050, metadata=None)))])\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.633, logit=19.875)', '\" The\"[578] (p=0.205, logit=18.750)', '\" A\"[362] (p=0.031, logit=16.875)', '\" Banana\"[76924] (p=0.025, logit=16.625)', '\" Boat\"[45332] (p=0.017, logit=16.250)']\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.6328125, logit=19.875, token_id=33711, metadata=None))), (76924, (4, PredictedToken(token=' Banana', prob=0.0245361328125, logit=16.625, token_id=76924, metadata=None))), (45332, (5, PredictedToken(token=' Boat', prob=0.016845703125, logit=16.25, token_id=45332, metadata=None))), (22050, (8, PredictedToken(token=' Hat', prob=0.006195068359375, logit=15.25, token_id=22050, metadata=None))), (31181, (13, PredictedToken(token=' Clar', prob=0.00274658203125, logit=14.4375, token_id=31181, metadata=None))), (84409, (17, PredictedToken(token=' Plum', prob=0.00147247314453125, logit=13.8125, token_id=84409, metadata=None))), (22607, (25, PredictedToken(token=' Cow', prob=0.000949859619140625, logit=13.375, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:23 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:40:23 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:40:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.879, logit=20.500)', '\" The\"[578] (p=0.050, logit=17.625)', '\" Coat\"[68867] (p=0.009, logit=15.875)', '\" None\"[2290] (p=0.006, logit=15.438)', '\" There\"[2684] (p=0.005, logit=15.375)']\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.805, logit=20.375)', '\" The\"[578] (p=0.096, logit=18.250)', '\" Lion\"[33199] (p=0.028, logit=17.000)', '\" There\"[2684] (p=0.015, logit=16.375)', '\" A\"[362] (p=0.009, logit=15.875)']\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.8046875, logit=20.375, token_id=48035, metadata=None))), (33199, (3, PredictedToken(token=' Lion', prob=0.027587890625, logit=17.0, token_id=33199, metadata=None))), (55870, (78, PredictedToken(token=' Jacket', prob=7.724761962890625e-05, logit=11.125, token_id=55870, metadata=None))), (29318, (93, PredictedToken(token=' Dress', prob=6.031990051269531e-05, logit=10.875, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     int_prediction=['\" Jacket\"[55870] (p=0.832, logit=20.375)', '\" Dress\"[29318] (p=0.032, logit=17.125)', '\" The\"[578] (p=0.032, logit=17.125)', '\" There\"[2684] (p=0.022, logit=16.750)', '\" Lion\"[33199] (p=0.020, logit=16.625)']\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     int_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.83203125, logit=20.375, token_id=55870, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.0322265625, logit=17.125, token_id=29318, metadata=None))), (33199, (5, PredictedToken(token=' Lion', prob=0.01953125, logit=16.625, token_id=33199, metadata=None))), (48035, (8, PredictedToken(token=' Gir', prob=0.005584716796875, logit=15.375, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:24 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     patch_prediction=['\" Basketball\"[47589] (p=0.859, logit=20.250)', '\" The\"[578] (p=0.038, logit=17.125)', '\" Football\"[21424] (p=0.026, logit=16.750)', '\" None\"[2290] (p=0.012, logit=15.938)', '\" A\"[362] (p=0.009, logit=15.688)']\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     clean_prediction=['\" Lion\"[33199] (p=0.668, logit=19.500)', '\" Monkey\"[58937] (p=0.116, logit=17.750)', '\" The\"[578] (p=0.091, logit=17.500)', '\" L\"[445] (p=0.043, logit=16.750)', '\" A\"[362] (p=0.015, logit=15.688)']\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     clean_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.66796875, logit=19.5, token_id=33199, metadata=None))), (58937, (2, PredictedToken(token=' Monkey', prob=0.1162109375, logit=17.75, token_id=58937, metadata=None))), (423, (7, PredictedToken(token=' D', prob=0.004241943359375, logit=14.4375, token_id=423, metadata=None))), (40090, (11, PredictedToken(token=' Pressure', prob=0.0029144287109375, logit=14.0625, token_id=40090, metadata=None))), (65197, (16, PredictedToken(token=' Surf', prob=0.00121307373046875, logit=13.1875, token_id=65197, metadata=None)))])\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.645, logit=18.875)', '\" Surf\"[65197] (p=0.112, logit=17.125)', '\" The\"[578] (p=0.060, logit=16.500)', '\" SUR\"[53083] (p=0.041, logit=16.125)', '\" Monkey\"[58937] (p=0.028, logit=15.750)']\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.64453125, logit=18.875, token_id=423, metadata=None))), (65197, (2, PredictedToken(token=' Surf', prob=0.11181640625, logit=17.125, token_id=65197, metadata=None))), (58937, (5, PredictedToken(token=' Monkey', prob=0.0283203125, logit=15.75, token_id=58937, metadata=None))), (40090, (7, PredictedToken(token=' Pressure', prob=0.01513671875, logit=15.125, token_id=40090, metadata=None))), (33199, (14, PredictedToken(token=' Lion', prob=0.002471923828125, logit=13.3125, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:25 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:40:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.746, logit=20.750)', '\" The\"[578] (p=0.101, logit=18.750)', '\" Dolphin\"[96096] (p=0.062, logit=18.250)', '\" L\"[445] (p=0.048, logit=18.000)', '\" A\"[362] (p=0.008, logit=16.250)']\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     clean_prediction=['\" Oak\"[18787] (p=0.797, logit=20.250)', '\" The\"[578] (p=0.074, logit=17.875)', '\" E\"[469] (p=0.024, logit=16.750)', '\" Hick\"[79028] (p=0.019, logit=16.500)', '\" There\"[2684] (p=0.019, logit=16.500)']\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     clean_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.796875, logit=20.25, token_id=18787, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.0240478515625, logit=16.75, token_id=469, metadata=None))), (79028, (5, PredictedToken(token=' Hick', prob=0.0186767578125, logit=16.5, token_id=79028, metadata=None))), (1901, (8, PredictedToken(token=' Z', prob=0.00445556640625, logit=15.0625, token_id=1901, metadata=None))), (40759, (14, PredictedToken(token=' Harmon', prob=0.00127410888671875, logit=13.8125, token_id=40759, metadata=None))), (48035, (23, PredictedToken(token=' Gir', prob=0.000823974609375, logit=13.375, token_id=48035, metadata=None)))])\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.400, logit=19.250)', '\" Hick\"[79028] (p=0.167, logit=18.375)', '\" Gir\"[48035] (p=0.130, logit=18.125)', '\" Z\"[1901] (p=0.101, logit=17.875)', '\" The\"[578] (p=0.079, logit=17.625)']\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.400390625, logit=19.25, token_id=469, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.1669921875, logit=18.375, token_id=79028, metadata=None))), (48035, (3, PredictedToken(token=' Gir', prob=0.1298828125, logit=18.125, token_id=48035, metadata=None))), (1901, (4, PredictedToken(token=' Z', prob=0.10107421875, logit=17.875, token_id=1901, metadata=None))), (40759, (7, PredictedToken(token=' Harmon', prob=0.017578125, logit=16.125, token_id=40759, metadata=None))), (18787, (11, PredictedToken(token=' Oak', prob=0.0032501220703125, logit=14.4375, token_id=18787, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:26 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.828, logit=20.750)', '\" The\"[578] (p=0.060, logit=18.125)', '\" Bus\"[19111] (p=0.036, logit=17.625)', '\" There\"[2684] (p=0.012, logit=16.500)', '\" An\"[1556] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     clean_prediction=['\" Ti\"[23126] (p=0.578, logit=19.875)', '\" B\"[426] (p=0.240, logit=19.000)', '\" The\"[578] (p=0.069, logit=17.750)', '\" TI\"[39237] (p=0.015, logit=16.250)', '\" A\"[362] (p=0.015, logit=16.250)']\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     clean_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.578125, logit=19.875, token_id=23126, metadata=None))), (426, (2, PredictedToken(token=' B', prob=0.240234375, logit=19.0, token_id=426, metadata=None))), (50159, (7, PredictedToken(token=' Sco', prob=0.00726318359375, logit=15.5, token_id=50159, metadata=None))), (13000, (21, PredictedToken(token=' Van', prob=0.00104522705078125, logit=13.5625, token_id=13000, metadata=None))), (8219, (51, PredictedToken(token=' Sun', prob=0.0002193450927734375, logit=12.0, token_id=8219, metadata=None)))])\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.691, logit=19.125)', '\" The\"[578] (p=0.106, logit=17.250)', '\" Van\"[13000] (p=0.044, logit=16.375)', '\" It\"[1102] (p=0.020, logit=15.562)', '\" A\"[362] (p=0.018, logit=15.500)']\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.69140625, logit=19.125, token_id=50159, metadata=None))), (13000, (3, PredictedToken(token=' Van', prob=0.044189453125, logit=16.375, token_id=13000, metadata=None))), (426, (22, PredictedToken(token=' B', prob=0.0009765625, logit=12.5625, token_id=426, metadata=None))), (8219, (42, PredictedToken(token=' Sun', prob=0.000492095947265625, logit=11.875, token_id=8219, metadata=None))), (23126, (58, PredictedToken(token=' Ti', prob=0.000278472900390625, logit=11.3125, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:27 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     patch_prediction=['\" Razor\"[74968] (p=0.852, logit=20.625)', '\" Tooth\"[83499] (p=0.033, logit=17.375)', '\" The\"[578] (p=0.033, logit=17.375)', '\" Cabinet\"[34046] (p=0.016, logit=16.625)', '\" A\"[362] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:40:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     clean_prediction=['\" Sofa\"[61948] (p=0.391, logit=18.875)', '\" Night\"[13120] (p=0.305, logit=18.625)', '\" The\"[578] (p=0.127, logit=17.750)', '\" A\"[362] (p=0.036, logit=16.500)', '\" Ch\"[921] (p=0.015, logit=15.625)']\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     clean_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.390625, logit=18.875, token_id=61948, metadata=None))), (13120, (2, PredictedToken(token=' Night', prob=0.3046875, logit=18.625, token_id=13120, metadata=None))), (921, (5, PredictedToken(token=' Ch', prob=0.01513671875, logit=15.625, token_id=921, metadata=None))), (82994, (12, PredictedToken(token=' Toilet', prob=0.004913330078125, logit=14.5, token_id=82994, metadata=None)))])\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.746, logit=19.375)', '\" The\"[578] (p=0.079, logit=17.125)', '\" TO\"[5257] (p=0.024, logit=15.938)', '\" None\"[2290] (p=0.019, logit=15.688)', '\" A\"[362] (p=0.016, logit=15.562)']\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.74609375, logit=19.375, token_id=82994, metadata=None))), (13120, (6, PredictedToken(token=' Night', prob=0.0128173828125, logit=15.3125, token_id=13120, metadata=None))), (61948, (8, PredictedToken(token=' Sofa', prob=0.00830078125, logit=14.875, token_id=61948, metadata=None))), (921, (9, PredictedToken(token=' Ch', prob=0.007781982421875, logit=14.8125, token_id=921, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:28 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.656, logit=19.375)', '\" Pear\"[23910] (p=0.069, logit=17.125)', '\" The\"[578] (p=0.061, logit=17.000)', '\" Highlight\"[57094] (p=0.048, logit=16.750)', '\" Spr\"[15883] (p=0.037, logit=16.500)']\n",
      "2025-09-15 09:40:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:29 src.selection.optimization INFO     clean_prediction=['\" Elm\"[65329] (p=0.637, logit=19.625)', '\" The\"[578] (p=0.086, logit=17.625)', '\" There\"[2684] (p=0.059, logit=17.250)', '\" Plum\"[84409] (p=0.052, logit=17.125)', '\" Oak\"[18787] (p=0.046, logit=17.000)']\n",
      "2025-09-15 09:40:29 src.selection.optimization INFO     clean_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.63671875, logit=19.625, token_id=65329, metadata=None))), (84409, (4, PredictedToken(token=' Plum', prob=0.052490234375, logit=17.125, token_id=84409, metadata=None))), (18787, (5, PredictedToken(token=' Oak', prob=0.046142578125, logit=17.0, token_id=18787, metadata=None))), (2522, (7, PredictedToken(token=' Sc', prob=0.0150146484375, logit=15.875, token_id=2522, metadata=None))), (10164, (10, PredictedToken(token=' Water', prob=0.005889892578125, logit=14.9375, token_id=10164, metadata=None)))])\n",
      "2025-09-15 09:40:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:29 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.648, logit=20.125)', '\" PL\"[10528] (p=0.088, logit=18.125)', '\" The\"[578] (p=0.088, logit=18.125)', '\" Elm\"[65329] (p=0.047, logit=17.500)', '\" Sc\"[2522] (p=0.028, logit=17.000)']\n",
      "2025-09-15 09:40:29 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.6484375, logit=20.125, token_id=84409, metadata=None))), (65329, (4, PredictedToken(token=' Elm', prob=0.046875, logit=17.5, token_id=65329, metadata=None))), (10164, (6, PredictedToken(token=' Water', prob=0.0284423828125, logit=17.0, token_id=10164, metadata=None))), (2522, (5, PredictedToken(token=' Sc', prob=0.0284423828125, logit=17.0, token_id=2522, metadata=None))), (18787, (9, PredictedToken(token=' Oak', prob=0.005279541015625, logit=15.3125, token_id=18787, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:29 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:29 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:40:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.492, logit=19.750)', '\" Printer\"[47033] (p=0.299, logit=19.250)', '\" The\"[578] (p=0.110, logit=18.250)', '\" A\"[362] (p=0.017, logit=16.375)', '\" PHONE\"[92183] (p=0.010, logit=15.812)']\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     clean_prediction=['\" Ring\"[22249] (p=0.879, logit=20.750)', '\" The\"[578] (p=0.044, logit=17.750)', '\" A\"[362] (p=0.016, logit=16.750)', '\" Brace\"[70306] (p=0.013, logit=16.500)', '\" ring\"[10264] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     clean_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.87890625, logit=20.75, token_id=22249, metadata=None))), (70306, (4, PredictedToken(token=' Brace', prob=0.0125732421875, logit=16.5, token_id=70306, metadata=None))), (45805, (10, PredictedToken(token=' Cherry', prob=0.00180816650390625, logit=14.5625, token_id=45805, metadata=None))), (11452, (21, PredictedToken(token=' Head', prob=0.0004863739013671875, logit=13.25, token_id=11452, metadata=None))), (14937, (25, PredictedToken(token=' Ash', prob=0.0004291534423828125, logit=13.125, token_id=14937, metadata=None))), (26698, (202, PredictedToken(token=' Keyboard', prob=1.0788440704345703e-05, logit=9.4375, token_id=26698, metadata=None))), (97796, (281, PredictedToken(token=' Skate', prob=6.139278411865234e-06, logit=8.875, token_id=97796, metadata=None)))])\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.490, logit=19.250)', '\" Head\"[11452] (p=0.297, logit=18.750)', '\" The\"[578] (p=0.059, logit=17.125)', '\" HEAD\"[34180] (p=0.035, logit=16.625)', '\" KEY\"[12282] (p=0.019, logit=16.000)']\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.490234375, logit=19.25, token_id=26698, metadata=None))), (11452, (2, PredictedToken(token=' Head', prob=0.296875, logit=18.75, token_id=11452, metadata=None))), (14937, (15, PredictedToken(token=' Ash', prob=0.00188446044921875, logit=13.6875, token_id=14937, metadata=None))), (70306, (22, PredictedToken(token=' Brace', prob=0.0012969970703125, logit=13.3125, token_id=70306, metadata=None))), (97796, (24, PredictedToken(token=' Skate', prob=0.001007080078125, logit=13.0625, token_id=97796, metadata=None))), (22249, (43, PredictedToken(token=' Ring', prob=0.0003948211669921875, logit=12.125, token_id=22249, metadata=None))), (45805, (210, PredictedToken(token=' Cherry', prob=2.682209014892578e-05, logit=9.4375, token_id=45805, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:30 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:40:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.898, logit=21.625)', '\" The\"[578] (p=0.051, logit=18.750)', '\" Sheep\"[84008] (p=0.009, logit=17.000)', '\" HOR\"[84666] (p=0.007, logit=16.750)', '\" There\"[2684] (p=0.006, logit=16.625)']\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     clean_prediction=['\" Camera\"[14669] (p=0.582, logit=19.500)', '\" Tablet\"[58403] (p=0.147, logit=18.125)', '\" The\"[578] (p=0.147, logit=18.125)', '\" There\"[2684] (p=0.012, logit=15.625)', '\" CAMERA\"[67898] (p=0.011, logit=15.562)']\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     clean_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.58203125, logit=19.5, token_id=14669, metadata=None))), (58403, (3, PredictedToken(token=' Tablet', prob=0.1474609375, logit=18.125, token_id=58403, metadata=None))), (36845, (83, PredictedToken(token=' Tiger', prob=0.0001430511474609375, logit=11.1875, token_id=36845, metadata=None))), (16488, (142, PredictedToken(token=' Bat', prob=5.9604644775390625e-05, logit=10.3125, token_id=16488, metadata=None))), (79189, (149, PredictedToken(token=' Elephant', prob=5.602836608886719e-05, logit=10.25, token_id=79189, metadata=None)))])\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.816, logit=19.750)', '\" The\"[578] (p=0.076, logit=17.375)', '\" Elephant\"[79189] (p=0.014, logit=15.688)', '\" T\"[350] (p=0.011, logit=15.438)', '\" There\"[2684] (p=0.008, logit=15.125)']\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.81640625, logit=19.75, token_id=36845, metadata=None))), (79189, (3, PredictedToken(token=' Elephant', prob=0.0140380859375, logit=15.6875, token_id=79189, metadata=None))), (16488, (6, PredictedToken(token=' Bat', prob=0.005859375, logit=14.8125, token_id=16488, metadata=None))), (58403, (12, PredictedToken(token=' Tablet', prob=0.002288818359375, logit=13.875, token_id=58403, metadata=None))), (14669, (27, PredictedToken(token=' Camera', prob=0.0006561279296875, logit=12.625, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:31 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:40:31 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     patch_prediction=['\" Mar\"[2947] (p=0.578, logit=18.250)', '\" The\"[578] (p=0.114, logit=16.625)', '\" Iris\"[66821] (p=0.100, logit=16.500)', '\" MAR\"[38599] (p=0.019, logit=14.812)', '\" There\"[2684] (p=0.015, logit=14.625)']\n",
      "2025-09-15 09:40:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.457, logit=18.250)', '\" Jasmine\"[82452] (p=0.244, logit=17.625)', '\" The\"[578] (p=0.131, logit=17.000)', '\" PIN\"[28228] (p=0.011, logit=14.562)', '\" A\"[362] (p=0.008, logit=14.250)']\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.45703125, logit=18.25, token_id=17929, metadata=None))), (82452, (2, PredictedToken(token=' Jasmine', prob=0.244140625, logit=17.625, token_id=82452, metadata=None))), (445, (6, PredictedToken(token=' L', prob=0.00836181640625, logit=14.25, token_id=445, metadata=None))), (74574, (8, PredictedToken(token=' Violet', prob=0.00787353515625, logit=14.1875, token_id=74574, metadata=None)))])\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.656, logit=19.250)', '\" Violet\"[74574] (p=0.101, logit=17.375)', '\" The\"[578] (p=0.101, logit=17.375)', '\" J\"[622] (p=0.029, logit=16.125)', '\" jasmine\"[66909] (p=0.024, logit=15.938)']\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.65625, logit=19.25, token_id=82452, metadata=None))), (74574, (3, PredictedToken(token=' Violet', prob=0.1005859375, logit=17.375, token_id=74574, metadata=None))), (445, (28, PredictedToken(token=' L', prob=0.000766754150390625, logit=12.5, token_id=445, metadata=None))), (17929, (29, PredictedToken(token=' Pin', prob=0.000720977783203125, logit=12.4375, token_id=17929, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:32 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.922, logit=21.125)', '\" A\"[362] (p=0.019, logit=17.250)', '\" The\"[578] (p=0.017, logit=17.125)', '\" Folder\"[36943] (p=0.007, logit=16.250)', '\" None\"[2290] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:40:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.715, logit=19.625)', '\" The\"[578] (p=0.110, logit=17.750)', '\" HOUSE\"[69461] (p=0.046, logit=16.875)', '\" A\"[362] (p=0.031, logit=16.500)', '\" Museum\"[16730] (p=0.025, logit=16.250)']\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.71484375, logit=19.625, token_id=4783, metadata=None))), (16730, (5, PredictedToken(token=' Museum', prob=0.0245361328125, logit=16.25, token_id=16730, metadata=None))), (393, (10, PredictedToken(token=' P', prob=0.003753662109375, logit=14.375, token_id=393, metadata=None))), (9939, (14, PredictedToken(token=' Er', prob=0.0022735595703125, logit=13.875, token_id=9939, metadata=None))), (68554, (47, PredictedToken(token=' Gloves', prob=0.00017547607421875, logit=11.3125, token_id=68554, metadata=None)))])\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     int_prediction=['\" Er\"[9939] (p=0.680, logit=19.500)', '\" P\"[393] (p=0.118, logit=17.750)', '\" The\"[578] (p=0.056, logit=17.000)', '\" An\"[1556] (p=0.030, logit=16.375)', '\" There\"[2684] (p=0.017, logit=15.812)']\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     int_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.6796875, logit=19.5, token_id=9939, metadata=None))), (393, (2, PredictedToken(token=' P', prob=0.11767578125, logit=17.75, token_id=393, metadata=None))), (4783, (11, PredictedToken(token=' House', prob=0.0040283203125, logit=14.375, token_id=4783, metadata=None))), (68554, (14, PredictedToken(token=' Gloves', prob=0.002777099609375, logit=14.0, token_id=68554, metadata=None))), (16730, (17, PredictedToken(token=' Museum', prob=0.0020294189453125, logit=13.6875, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:33 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.730, logit=20.125)', '\" The\"[578] (p=0.099, logit=18.125)', '\" Apartment\"[53889] (p=0.053, logit=17.500)', '\" FACT\"[59643] (p=0.017, logit=16.375)', '\" A\"[362] (p=0.017, logit=16.375)']\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.707, logit=19.875)', '\" The\"[578] (p=0.096, logit=17.875)', '\" Pear\"[23910] (p=0.075, logit=17.625)', '\" There\"[2684] (p=0.019, logit=16.250)', '\" GRA\"[65120] (p=0.012, logit=15.812)']\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.70703125, logit=19.875, token_id=80629, metadata=None))), (23910, (3, PredictedToken(token=' Pear', prob=0.07470703125, logit=17.625, token_id=23910, metadata=None))), (6150, (9, PredictedToken(token=' School', prob=0.0032806396484375, logit=14.5, token_id=6150, metadata=None))), (29318, (117, PredictedToken(token=' Dress', prob=5.2928924560546875e-05, logit=10.375, token_id=29318, metadata=None))), (38571, (303, PredictedToken(token=' Theater', prob=1.341104507446289e-05, logit=9.0, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:40:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.668, logit=19.375)', '\" The\"[578] (p=0.062, logit=17.000)', '\" Dress\"[29318] (p=0.055, logit=16.875)', '\" Theater\"[38571] (p=0.055, logit=16.875)', '\" Pear\"[23910] (p=0.033, logit=16.375)']\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.66796875, logit=19.375, token_id=6150, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.054931640625, logit=16.875, token_id=29318, metadata=None))), (38571, (4, PredictedToken(token=' Theater', prob=0.054931640625, logit=16.875, token_id=38571, metadata=None))), (23910, (5, PredictedToken(token=' Pear', prob=0.033447265625, logit=16.375, token_id=23910, metadata=None))), (80629, (9, PredictedToken(token=' Grape', prob=0.006561279296875, logit=14.75, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:34 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:34 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.404, logit=19.250)', '\" Pressure\"[40090] (p=0.277, logit=18.875)', '\" The\"[578] (p=0.169, logit=18.375)', '\" A\"[362] (p=0.042, logit=17.000)', '\" J\"[622] (p=0.010, logit=15.562)']\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.605, logit=19.625)', '\" Magn\"[20918] (p=0.197, logit=18.500)', '\" The\"[578] (p=0.072, logit=17.500)', '\" There\"[2684] (p=0.034, logit=16.750)', '\" None\"[2290] (p=0.013, logit=15.750)']\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.60546875, logit=19.625, token_id=79028, metadata=None))), (20918, (2, PredictedToken(token=' Magn', prob=0.197265625, logit=18.5, token_id=20918, metadata=None))), (328, (6, PredictedToken(token=' S', prob=0.007171630859375, logit=15.1875, token_id=328, metadata=None))), (36358, (9, PredictedToken(token=' Bench', prob=0.004913330078125, logit=14.8125, token_id=36358, metadata=None))), (2522, (11, PredictedToken(token=' Sc', prob=0.00299072265625, logit=14.3125, token_id=2522, metadata=None))), (6690, (94, PredictedToken(token=' Air', prob=9.012222290039062e-05, logit=10.8125, token_id=6690, metadata=None))), (98641, (218, PredictedToken(token=' Microwave', prob=2.1457672119140625e-05, logit=9.375, token_id=98641, metadata=None)))])\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.750, logit=20.125)', '\" The\"[578] (p=0.037, logit=17.125)', '\" Sc\"[2522] (p=0.029, logit=16.875)', '\" There\"[2684] (p=0.020, logit=16.500)', '\" None\"[2290] (p=0.020, logit=16.500)']\n",
      "2025-09-15 09:40:34 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.75, logit=20.125, token_id=6690, metadata=None))), (2522, (3, PredictedToken(token=' Sc', prob=0.029052734375, logit=16.875, token_id=2522, metadata=None))), (20918, (6, PredictedToken(token=' Magn', prob=0.0198974609375, logit=16.5, token_id=20918, metadata=None))), (98641, (8, PredictedToken(token=' Microwave', prob=0.017578125, logit=16.375, token_id=98641, metadata=None))), (79028, (9, PredictedToken(token=' Hick', prob=0.01373291015625, logit=16.125, token_id=79028, metadata=None))), (328, (10, PredictedToken(token=' S', prob=0.0120849609375, logit=16.0, token_id=328, metadata=None))), (36358, (27, PredictedToken(token=' Bench', prob=0.000823974609375, logit=13.3125, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:35 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.459, logit=20.000)', '\" Dish\"[49268] (p=0.245, logit=19.375)', '\" The\"[578] (p=0.191, logit=19.125)', '\" A\"[362] (p=0.023, logit=17.000)', '\" There\"[2684] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.840, logit=21.625)', '\" Tow\"[41493] (p=0.069, logit=19.125)', '\" The\"[578] (p=0.037, logit=18.500)', '\" BAT\"[79081] (p=0.020, logit=17.875)', '\" A\"[362] (p=0.007, logit=16.875)']\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.83984375, logit=21.625, token_id=16488, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.06884765625, logit=19.125, token_id=41493, metadata=None))), (3804, (12, PredictedToken(token=' Sub', prob=0.0008697509765625, logit=14.75, token_id=3804, metadata=None))), (75258, (18, PredictedToken(token=' Refriger', prob=0.00046539306640625, logit=14.125, token_id=75258, metadata=None))), (3341, (94, PredictedToken(token=' Car', prob=2.3126602172851562e-05, logit=11.125, token_id=3341, metadata=None))), (88668, (192, PredictedToken(token=' Blender', prob=6.22868537902832e-06, logit=9.8125, token_id=88668, metadata=None)))])\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     int_prediction=['\" Refriger\"[75258] (p=0.445, logit=20.000)', '\" Tow\"[41493] (p=0.307, logit=19.625)', '\" The\"[578] (p=0.113, logit=18.625)', '\" Blender\"[88668] (p=0.047, logit=17.750)', '\" A\"[362] (p=0.017, logit=16.750)']\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     int_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.4453125, logit=20.0, token_id=75258, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.306640625, logit=19.625, token_id=41493, metadata=None))), (88668, (4, PredictedToken(token=' Blender', prob=0.046875, logit=17.75, token_id=88668, metadata=None))), (3341, (6, PredictedToken(token=' Car', prob=0.0152587890625, logit=16.625, token_id=3341, metadata=None))), (3804, (10, PredictedToken(token=' Sub', prob=0.002655029296875, logit=14.875, token_id=3804, metadata=None))), (16488, (23, PredictedToken(token=' Bat', prob=0.000591278076171875, logit=13.375, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:35 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:36 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.494, logit=19.375)', '\" Television\"[41445] (p=0.233, logit=18.625)', '\" Motorcycle\"[70762] (p=0.076, logit=17.500)', '\" The\"[578] (p=0.041, logit=16.875)', '\" Y\"[816] (p=0.025, logit=16.375)']\n",
      "2025-09-15 09:40:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:36 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.793, logit=20.375)', '\" Van\"[13000] (p=0.065, logit=17.875)', '\" The\"[578] (p=0.045, logit=17.500)', '\" A\"[362] (p=0.019, logit=16.625)', '\" HEL\"[38757] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:40:36 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.79296875, logit=20.375, token_id=16183, metadata=None))), (13000, (2, PredictedToken(token=' Van', prob=0.06494140625, logit=17.875, token_id=13000, metadata=None))), (19176, (8, PredictedToken(token=' Temple', prob=0.00604248046875, logit=15.5, token_id=19176, metadata=None))), (26698, (21, PredictedToken(token=' Keyboard', prob=0.0008697509765625, logit=13.5625, token_id=26698, metadata=None))), (14642, (26, PredictedToken(token=' Phone', prob=0.00067901611328125, logit=13.3125, token_id=14642, metadata=None)))])\n",
      "2025-09-15 09:40:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.672, logit=19.875)', '\" Hel\"[16183] (p=0.091, logit=17.875)', '\" The\"[578] (p=0.080, logit=17.750)', '\" Van\"[13000] (p=0.026, logit=16.625)', '\" A\"[362] (p=0.018, logit=16.250)']\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.671875, logit=19.875, token_id=26698, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.0908203125, logit=17.875, token_id=16183, metadata=None))), (13000, (4, PredictedToken(token=' Van', prob=0.0260009765625, logit=16.625, token_id=13000, metadata=None))), (14642, (8, PredictedToken(token=' Phone', prob=0.00848388671875, logit=15.5, token_id=14642, metadata=None))), (19176, (82, PredictedToken(token=' Temple', prob=0.00012874603271484375, logit=11.3125, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:37 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:37 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.449, logit=19.250)', '\" The\"[578] (p=0.309, logit=18.875)', '\" Swe\"[37326] (p=0.053, logit=17.125)', '\" SHORT\"[66024] (p=0.047, logit=17.000)', '\" Short\"[10928] (p=0.013, logit=15.688)']\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.773, logit=20.875)', '\" The\"[578] (p=0.173, logit=19.375)', '\" T\"[350] (p=0.010, logit=16.500)', '\" It\"[1102] (p=0.005, logit=15.875)', '\" A\"[362] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.7734375, logit=20.875, token_id=94467, metadata=None))), (1630, (8, PredictedToken(token=' X', prob=0.0021820068359375, logit=15.0, token_id=1630, metadata=None))), (22725, (100, PredictedToken(token=' Orange', prob=3.743171691894531e-05, logit=10.9375, token_id=22725, metadata=None))), (68867, (140, PredictedToken(token=' Coat', prob=2.2649765014648438e-05, logit=10.4375, token_id=68867, metadata=None))), (29318, (828, PredictedToken(token=' Dress', prob=1.2442469596862793e-06, logit=7.53125, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:40:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:38 src.selection.optimization INFO     int_prediction=['\" Coat\"[68867] (p=0.547, logit=19.625)', '\" The\"[578] (p=0.200, logit=18.625)', '\" Dress\"[29318] (p=0.107, logit=18.000)', '\" CO\"[7432] (p=0.045, logit=17.125)', '\" A\"[362] (p=0.013, logit=15.875)']\n",
      "2025-09-15 09:40:38 src.selection.optimization INFO     int_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.546875, logit=19.625, token_id=68867, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.107421875, logit=18.0, token_id=29318, metadata=None))), (22725, (14, PredictedToken(token=' Orange', prob=0.0019683837890625, logit=14.0, token_id=22725, metadata=None))), (1630, (16, PredictedToken(token=' X', prob=0.0018463134765625, logit=13.9375, token_id=1630, metadata=None))), (94467, (88, PredictedToken(token=' Trom', prob=0.00011110305786132812, logit=11.125, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:38 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:38 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.770, logit=19.875)', '\" Baseball\"[38258] (p=0.071, logit=17.500)', '\" The\"[578] (p=0.071, logit=17.500)', '\" A\"[362] (p=0.018, logit=16.125)', '\" BAT\"[79081] (p=0.010, logit=15.562)']\n",
      "2025-09-15 09:40:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.471, logit=19.875)', '\" Bus\"[19111] (p=0.252, logit=19.250)', '\" The\"[578] (p=0.119, logit=18.500)', '\" A\"[362] (p=0.044, logit=17.500)', '\" There\"[2684] (p=0.018, logit=16.625)']\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.470703125, logit=19.875, token_id=45332, metadata=None))), (19111, (2, PredictedToken(token=' Bus', prob=0.251953125, logit=19.25, token_id=19111, metadata=None))), (6150, (6, PredictedToken(token=' School', prob=0.01611328125, logit=16.5, token_id=6150, metadata=None))), (97796, (10, PredictedToken(token=' Skate', prob=0.004608154296875, logit=15.25, token_id=97796, metadata=None))), (28131, (14, PredictedToken(token=' Golf', prob=0.0027923583984375, logit=14.75, token_id=28131, metadata=None)))])\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     int_prediction=['\" Golf\"[28131] (p=0.500, logit=19.625)', '\" The\"[578] (p=0.099, logit=18.000)', '\" Boat\"[45332] (p=0.087, logit=17.875)', '\" Bus\"[19111] (p=0.068, logit=17.625)', '\" A\"[362] (p=0.060, logit=17.500)']\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     int_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.5, logit=19.625, token_id=28131, metadata=None))), (45332, (3, PredictedToken(token=' Boat', prob=0.0869140625, logit=17.875, token_id=45332, metadata=None))), (19111, (4, PredictedToken(token=' Bus', prob=0.06787109375, logit=17.625, token_id=19111, metadata=None))), (97796, (7, PredictedToken(token=' Skate', prob=0.046630859375, logit=17.25, token_id=97796, metadata=None))), (6150, (6, PredictedToken(token=' School', prob=0.046630859375, logit=17.25, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:39 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:39 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     patch_prediction=['\" Har\"[5340] (p=0.719, logit=20.500)', '\" The\"[578] (p=0.160, logit=19.000)', '\" H\"[473] (p=0.025, logit=17.125)', '\" Trump\"[3420] (p=0.017, logit=16.750)', '\" HAR\"[87588] (p=0.013, logit=16.500)']\n",
      "2025-09-15 09:40:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     clean_prediction=['\" Mosque\"[100031] (p=0.941, logit=21.750)', '\" The\"[578] (p=0.025, logit=18.125)', '\" MOS\"[74174] (p=0.009, logit=17.125)', '\" A\"[362] (p=0.005, logit=16.500)', '\" Church\"[9441] (p=0.004, logit=16.375)']\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     clean_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.94140625, logit=21.75, token_id=100031, metadata=None))), (9441, (5, PredictedToken(token=' Church', prob=0.004364013671875, logit=16.375, token_id=9441, metadata=None))), (29318, (13, PredictedToken(token=' Dress', prob=0.000316619873046875, logit=13.75, token_id=29318, metadata=None))), (3061, (30, PredictedToken(token=' Fl', prob=9.632110595703125e-05, logit=12.5625, token_id=3061, metadata=None))), (31181, (243, PredictedToken(token=' Clar', prob=3.7401914596557617e-06, logit=9.3125, token_id=31181, metadata=None)))])\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     int_prediction=['\" Mosque\"[100031] (p=0.852, logit=20.125)', '\" Clar\"[31181] (p=0.042, logit=17.125)', '\" The\"[578] (p=0.029, logit=16.750)', '\" MOS\"[74174] (p=0.013, logit=15.938)', '\" A\"[362] (p=0.009, logit=15.562)']\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     int_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.8515625, logit=20.125, token_id=100031, metadata=None))), (31181, (2, PredictedToken(token=' Clar', prob=0.04248046875, logit=17.125, token_id=31181, metadata=None))), (3061, (6, PredictedToken(token=' Fl', prob=0.0057373046875, logit=15.125, token_id=3061, metadata=None))), (29318, (8, PredictedToken(token=' Dress', prob=0.003936767578125, logit=14.75, token_id=29318, metadata=None))), (9441, (10, PredictedToken(token=' Church', prob=0.002716064453125, logit=14.375, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:40 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.848, logit=20.750)', '\" The\"[578] (p=0.054, logit=18.000)', '\" C\"[356] (p=0.023, logit=17.125)', '\" Tie\"[59825] (p=0.020, logit=17.000)', '\" P\"[393] (p=0.005, logit=15.625)']\n",
      "2025-09-15 09:40:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.793, logit=20.750)', '\" Dolphin\"[96096] (p=0.065, logit=18.250)', '\" The\"[578] (p=0.045, logit=17.875)', '\" C\"[356] (p=0.045, logit=17.875)', '\" A\"[362] (p=0.015, logit=16.750)']\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.79296875, logit=20.75, token_id=22607, metadata=None))), (96096, (2, PredictedToken(token=' Dolphin', prob=0.06494140625, logit=18.25, token_id=96096, metadata=None))), (17929, (48, PredictedToken(token=' Pin', prob=0.00010395050048828125, logit=11.8125, token_id=17929, metadata=None))), (68867, (157, PredictedToken(token=' Coat', prob=2.0503997802734375e-05, logit=10.1875, token_id=68867, metadata=None))), (33711, (211, PredictedToken(token=' Suit', prob=1.3232231140136719e-05, logit=9.75, token_id=33711, metadata=None)))])\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.369, logit=18.875)', '\" Cow\"[22607] (p=0.324, logit=18.750)', '\" The\"[578] (p=0.073, logit=17.250)', '\" Dolphin\"[96096] (p=0.064, logit=17.125)', '\" There\"[2684] (p=0.024, logit=16.125)']\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.369140625, logit=18.875, token_id=33711, metadata=None))), (22607, (2, PredictedToken(token=' Cow', prob=0.32421875, logit=18.75, token_id=22607, metadata=None))), (96096, (4, PredictedToken(token=' Dolphin', prob=0.06396484375, logit=17.125, token_id=96096, metadata=None))), (17929, (6, PredictedToken(token=' Pin', prob=0.0235595703125, logit=16.125, token_id=17929, metadata=None))), (68867, (17, PredictedToken(token=' Coat', prob=0.001708984375, logit=13.5, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:41 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     patch_prediction=['\" Rice\"[30616] (p=0.637, logit=20.000)', '\" Coffee\"[27171] (p=0.142, logit=18.500)', '\" The\"[578] (p=0.125, logit=18.375)', '\" A\"[362] (p=0.032, logit=17.000)', '\" None\"[2290] (p=0.006, logit=15.312)']\n",
      "2025-09-15 09:40:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:42 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.307, logit=19.000)', '\" The\"[578] (p=0.238, logit=18.750)', '\" Slow\"[39247] (p=0.211, logit=18.625)', '\" Chair\"[16478] (p=0.088, logit=17.750)', '\" Pine\"[42609] (p=0.053, logit=17.250)']\n",
      "2025-09-15 09:40:42 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.306640625, logit=19.0, token_id=27171, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.2109375, logit=18.625, token_id=39247, metadata=None))), (16478, (4, PredictedToken(token=' Chair', prob=0.087890625, logit=17.75, token_id=16478, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.05322265625, logit=17.25, token_id=42609, metadata=None))), (48665, (21, PredictedToken(token=' Raspberry', prob=0.00133514404296875, logit=13.5625, token_id=48665, metadata=None))), (75258, (98, PredictedToken(token=' Refriger', prob=7.534027099609375e-05, logit=10.6875, token_id=75258, metadata=None)))])\n",
      "2025-09-15 09:40:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:42 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.836, logit=20.750)', '\" The\"[578] (p=0.100, logit=18.625)', '\" A\"[362] (p=0.015, logit=16.750)', '\" S\"[328] (p=0.008, logit=16.125)', '\" slow\"[6435] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:40:42 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.8359375, logit=20.75, token_id=39247, metadata=None))), (42609, (10, PredictedToken(token=' Pine', prob=0.00133514404296875, logit=14.3125, token_id=42609, metadata=None))), (48665, (26, PredictedToken(token=' Raspberry', prob=0.0003604888916015625, logit=13.0, token_id=48665, metadata=None))), (75258, (30, PredictedToken(token=' Refriger', prob=0.000247955322265625, logit=12.625, token_id=75258, metadata=None))), (27171, (33, PredictedToken(token=' Coffee', prob=0.0001811981201171875, logit=12.3125, token_id=27171, metadata=None))), (16478, (88, PredictedToken(token=' Chair', prob=3.790855407714844e-05, logit=10.75, token_id=16478, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:42 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:42 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:40:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     patch_prediction=['\" House\"[4783] (p=0.559, logit=19.250)', '\" The\"[578] (p=0.159, logit=18.000)', '\" Stadium\"[23462] (p=0.085, logit=17.375)', '\" Hel\"[16183] (p=0.040, logit=16.625)', '\" A\"[362] (p=0.036, logit=16.500)']\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.719, logit=19.875)', '\" The\"[578] (p=0.067, logit=17.500)', '\" E\"[469] (p=0.052, logit=17.250)', '\" RED\"[26895] (p=0.036, logit=16.875)', '\" Re\"[1050] (p=0.025, logit=16.500)']\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.71875, logit=19.875, token_id=3816, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.052001953125, logit=17.25, token_id=469, metadata=None))), (1050, (5, PredictedToken(token=' Re', prob=0.0245361328125, logit=16.5, token_id=1050, metadata=None))), (4923, (7, PredictedToken(token=' Sk', prob=0.01318359375, logit=15.875, token_id=4923, metadata=None))), (432, (15, PredictedToken(token=' R', prob=0.0021514892578125, logit=14.0625, token_id=432, metadata=None))), (70762, (120, PredictedToken(token=' Motorcycle', prob=5.054473876953125e-05, logit=10.3125, token_id=70762, metadata=None))), (38571, (537, PredictedToken(token=' Theater', prob=3.6656856536865234e-06, logit=7.6875, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.324, logit=19.000)', '\" Red\"[3816] (p=0.287, logit=18.875)', '\" Re\"[1050] (p=0.174, logit=18.375)', '\" The\"[578] (p=0.082, logit=17.625)', '\" A\"[362] (p=0.018, logit=16.125)']\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.32421875, logit=19.0, token_id=4923, metadata=None))), (3816, (2, PredictedToken(token=' Red', prob=0.287109375, logit=18.875, token_id=3816, metadata=None))), (1050, (3, PredictedToken(token=' Re', prob=0.173828125, logit=18.375, token_id=1050, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.018310546875, logit=16.125, token_id=469, metadata=None))), (432, (9, PredictedToken(token=' R', prob=0.01043701171875, logit=15.5625, token_id=432, metadata=None))), (38571, (14, PredictedToken(token=' Theater', prob=0.0023345947265625, logit=14.0625, token_id=38571, metadata=None))), (70762, (88, PredictedToken(token=' Motorcycle', prob=7.009506225585938e-05, logit=10.5625, token_id=70762, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:43 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:43 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:40:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.578, logit=19.500)', '\" Ju\"[22410] (p=0.129, logit=18.000)', '\" The\"[578] (p=0.129, logit=18.000)', '\" Caul\"[90538] (p=0.042, logit=16.875)', '\" A\"[362] (p=0.025, logit=16.375)']\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.824, logit=20.500)', '\" The\"[578] (p=0.077, logit=18.125)', '\" There\"[2684] (p=0.019, logit=16.750)', '\" Spin\"[41785] (p=0.017, logit=16.625)', '\" Re\"[1050] (p=0.012, logit=16.250)']\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.82421875, logit=20.5, token_id=1901, metadata=None))), (41785, (4, PredictedToken(token=' Spin', prob=0.01708984375, logit=16.625, token_id=41785, metadata=None))), (1050, (5, PredictedToken(token=' Re', prob=0.01177978515625, logit=16.25, token_id=1050, metadata=None))), (6690, (30, PredictedToken(token=' Air', prob=0.0004291534423828125, logit=12.9375, token_id=6690, metadata=None))), (75258, (83, PredictedToken(token=' Refriger', prob=7.009506225585938e-05, logit=11.125, token_id=75258, metadata=None))), (22050, (109, PredictedToken(token=' Hat', prob=4.8160552978515625e-05, logit=10.75, token_id=22050, metadata=None))), (58586, (500, PredictedToken(token=' Tape', prob=2.8908252716064453e-06, logit=7.9375, token_id=58586, metadata=None)))])\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.691, logit=20.000)', '\" The\"[578] (p=0.106, logit=18.125)', '\" Re\"[1050] (p=0.050, logit=17.375)', '\" Refriger\"[75258] (p=0.030, logit=16.875)', '\" An\"[1556] (p=0.021, logit=16.500)']\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.69140625, logit=20.0, token_id=6690, metadata=None))), (1050, (3, PredictedToken(token=' Re', prob=0.05029296875, logit=17.375, token_id=1050, metadata=None))), (75258, (4, PredictedToken(token=' Refriger', prob=0.0303955078125, logit=16.875, token_id=75258, metadata=None))), (41785, (13, PredictedToken(token=' Spin', prob=0.003204345703125, logit=14.625, token_id=41785, metadata=None))), (58586, (15, PredictedToken(token=' Tape', prob=0.002655029296875, logit=14.4375, token_id=58586, metadata=None))), (1901, (25, PredictedToken(token=' Z', prob=0.00063323974609375, logit=13.0, token_id=1901, metadata=None))), (22050, (107, PredictedToken(token=' Hat', prob=5.173683166503906e-05, logit=10.5, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:44 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     patch_prediction=['\" Printer\"[47033] (p=0.711, logit=19.750)', '\" Router\"[10777] (p=0.085, logit=17.625)', '\" The\"[578] (p=0.066, logit=17.375)', '\" Helmet\"[67629] (p=0.052, logit=17.125)', '\" A\"[362] (p=0.008, logit=15.312)']\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.793, logit=21.125)', '\" The\"[578] (p=0.122, logit=19.250)', '\" Tennis\"[58251] (p=0.021, logit=17.500)', '\" A\"[362] (p=0.016, logit=17.250)', '\" Skate\"[97796] (p=0.004, logit=15.875)']\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.79296875, logit=21.125, token_id=432, metadata=None))), (97796, (5, PredictedToken(token=' Skate', prob=0.004180908203125, logit=15.875, token_id=97796, metadata=None))), (6690, (42, PredictedToken(token=' Air', prob=0.000171661376953125, logit=12.6875, token_id=6690, metadata=None))), (18191, (121, PredictedToken(token=' Mouse', prob=2.47955322265625e-05, logit=10.75, token_id=18191, metadata=None))), (14669, (224, PredictedToken(token=' Camera', prob=8.046627044677734e-06, logit=9.625, token_id=14669, metadata=None)))])\n",
      "2025-09-15 09:40:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     int_prediction=['\" Mouse\"[18191] (p=0.406, logit=18.875)', '\" Air\"[6690] (p=0.169, logit=18.000)', '\" The\"[578] (p=0.116, logit=17.625)', '\" Skate\"[97796] (p=0.103, logit=17.500)', '\" Camera\"[14669] (p=0.055, logit=16.875)']\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     int_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.40625, logit=18.875, token_id=18191, metadata=None))), (6690, (2, PredictedToken(token=' Air', prob=0.1689453125, logit=18.0, token_id=6690, metadata=None))), (97796, (4, PredictedToken(token=' Skate', prob=0.1025390625, logit=17.5, token_id=97796, metadata=None))), (14669, (5, PredictedToken(token=' Camera', prob=0.054931640625, logit=16.875, token_id=14669, metadata=None))), (432, (14, PredictedToken(token=' R', prob=0.0037384033203125, logit=14.1875, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:40:45 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     patch_prediction=['\" Library\"[11896] (p=0.730, logit=20.000)', '\" The\"[578] (p=0.144, logit=18.375)', '\" House\"[4783] (p=0.047, logit=17.250)', '\" A\"[362] (p=0.013, logit=16.000)', '\" It\"[1102] (p=0.006, logit=15.125)']\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     clean_prediction=['\" Caul\"[90538] (p=0.902, logit=21.875)', '\" Car\"[3341] (p=0.040, logit=18.750)', '\" The\"[578] (p=0.035, logit=18.625)', '\" There\"[2684] (p=0.007, logit=17.000)', '\" CA\"[9362] (p=0.002, logit=15.812)']\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     clean_track=OrderedDict([(90538, (1, PredictedToken(token=' Caul', prob=0.90234375, logit=21.875, token_id=90538, metadata=None))), (3341, (2, PredictedToken(token=' Car', prob=0.03955078125, logit=18.75, token_id=3341, metadata=None))), (19176, (188, PredictedToken(token=' Temple', prob=5.185604095458984e-06, logit=9.8125, token_id=19176, metadata=None))), (16730, (3294, PredictedToken(token=' Museum', prob=8.149072527885437e-08, logit=5.65625, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.355, logit=18.250)', '\" Museum\"[16730] (p=0.277, logit=18.000)', '\" The\"[578] (p=0.148, logit=17.375)', '\" There\"[2684] (p=0.054, logit=16.375)', '\" Car\"[3341] (p=0.024, logit=15.562)']\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.35546875, logit=18.25, token_id=19176, metadata=None))), (16730, (2, PredictedToken(token=' Museum', prob=0.27734375, logit=18.0, token_id=16730, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.024169921875, logit=15.5625, token_id=3341, metadata=None))), (90538, (6, PredictedToken(token=' Caul', prob=0.0213623046875, logit=15.4375, token_id=90538, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:45 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:45 src.selection.optimization DEBUG    torch.Size([7, 38])\n",
      "2025-09-15 09:40:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     patch_prediction=['\" Bed\"[13394] (p=0.438, logit=19.500)', '\" Desk\"[39794] (p=0.183, logit=18.625)', '\" The\"[578] (p=0.161, logit=18.500)', '\" A\"[362] (p=0.059, logit=17.500)', '\" BED\"[83364] (p=0.046, logit=17.250)']\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     clean_prediction=['\" Dish\"[49268] (p=0.664, logit=20.500)', '\" Blender\"[88668] (p=0.131, logit=18.875)', '\" The\"[578] (p=0.116, logit=18.750)', '\" St\"[800] (p=0.018, logit=16.875)', '\" A\"[362] (p=0.011, logit=16.375)']\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     clean_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.6640625, logit=20.5, token_id=49268, metadata=None))), (88668, (2, PredictedToken(token=' Blender', prob=0.130859375, logit=18.875, token_id=88668, metadata=None))), (800, (4, PredictedToken(token=' St', prob=0.0177001953125, logit=16.875, token_id=800, metadata=None))), (26781, (16, PredictedToken(token=' Hair', prob=0.00099945068359375, logit=14.0, token_id=26781, metadata=None))), (13120, (38, PredictedToken(token=' Night', prob=0.0003452301025390625, logit=12.9375, token_id=13120, metadata=None))), (57748, (50, PredictedToken(token=' Cedar', prob=0.00023746490478515625, logit=12.5625, token_id=57748, metadata=None))), (36943, (89, PredictedToken(token=' Folder', prob=7.2479248046875e-05, logit=11.375, token_id=36943, metadata=None)))])\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     int_prediction=['\" St\"[800] (p=0.859, logit=20.875)', '\" Night\"[13120] (p=0.029, logit=17.500)', '\" The\"[578] (p=0.026, logit=17.375)', '\" A\"[362] (p=0.014, logit=16.750)', '\" Blender\"[88668] (p=0.012, logit=16.625)']\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     int_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.859375, logit=20.875, token_id=800, metadata=None))), (13120, (2, PredictedToken(token=' Night', prob=0.0294189453125, logit=17.5, token_id=13120, metadata=None))), (88668, (5, PredictedToken(token=' Blender', prob=0.01226806640625, logit=16.625, token_id=88668, metadata=None))), (57748, (6, PredictedToken(token=' Cedar', prob=0.0084228515625, logit=16.25, token_id=57748, metadata=None))), (49268, (8, PredictedToken(token=' Dish', prob=0.004791259765625, logit=15.6875, token_id=49268, metadata=None))), (36943, (10, PredictedToken(token=' Folder', prob=0.0037384033203125, logit=15.4375, token_id=36943, metadata=None))), (26781, (13, PredictedToken(token=' Hair', prob=0.00176239013671875, logit=14.6875, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:46 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-15 09:40:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.895, logit=21.250)', '\" The\"[578] (p=0.050, logit=18.375)', '\" CH\"[6969] (p=0.011, logit=16.875)', '\" Lav\"[43950] (p=0.005, logit=16.125)', '\" A\"[362] (p=0.004, logit=15.938)']\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.504, logit=19.875)', '\" Church\"[9441] (p=0.305, logit=19.375)', '\" The\"[578] (p=0.099, logit=18.250)', '\" A\"[362] (p=0.028, logit=17.000)', '\" It\"[1102] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.50390625, logit=19.875, token_id=16730, metadata=None))), (9441, (2, PredictedToken(token=' Church', prob=0.3046875, logit=19.375, token_id=9441, metadata=None))), (43316, (9, PredictedToken(token=' Tul', prob=0.0026397705078125, logit=14.625, token_id=43316, metadata=None))), (423, (17, PredictedToken(token=' D', prob=0.00103759765625, logit=13.6875, token_id=423, metadata=None))), (18343, (35, PredictedToken(token=' Paper', prob=0.0002956390380859375, logit=12.4375, token_id=18343, metadata=None)))])\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.660, logit=20.125)', '\" Museum\"[16730] (p=0.147, logit=18.625)', '\" The\"[578] (p=0.070, logit=17.875)', '\" Paper\"[18343] (p=0.033, logit=17.125)', '\" A\"[362] (p=0.016, logit=16.375)']\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.66015625, logit=20.125, token_id=423, metadata=None))), (16730, (2, PredictedToken(token=' Museum', prob=0.1474609375, logit=18.625, token_id=16730, metadata=None))), (18343, (4, PredictedToken(token=' Paper', prob=0.032958984375, logit=17.125, token_id=18343, metadata=None))), (43316, (6, PredictedToken(token=' Tul', prob=0.01373291015625, logit=16.25, token_id=43316, metadata=None))), (9441, (9, PredictedToken(token=' Church', prob=0.005035400390625, logit=15.25, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:47 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     patch_prediction=['\" Uk\"[60413] (p=0.688, logit=19.875)', '\" The\"[578] (p=0.153, logit=18.375)', '\" Basketball\"[47589] (p=0.064, logit=17.500)', '\" A\"[362] (p=0.012, logit=15.812)', '\" Guitar\"[47759] (p=0.007, logit=15.312)']\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.598, logit=19.375)', '\" The\"[578] (p=0.133, logit=17.875)', '\" Fl\"[3061] (p=0.063, logit=17.125)', '\" Skate\"[97796] (p=0.038, logit=16.625)', '\" Ski\"[61595] (p=0.038, logit=16.625)']\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.59765625, logit=19.375, token_id=4923, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.06298828125, logit=17.125, token_id=3061, metadata=None))), (97796, (5, PredictedToken(token=' Skate', prob=0.0380859375, logit=16.625, token_id=97796, metadata=None))), (56491, (8, PredictedToken(token=' Piano', prob=0.00799560546875, logit=15.0625, token_id=56491, metadata=None))), (423, (25, PredictedToken(token=' D', prob=0.00167083740234375, logit=13.5, token_id=423, metadata=None)))])\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     int_prediction=['\" Fl\"[3061] (p=0.789, logit=20.375)', '\" The\"[578] (p=0.073, logit=18.000)', '\" Piano\"[56491] (p=0.039, logit=17.375)', '\" Skate\"[97796] (p=0.019, logit=16.625)', '\" Sk\"[4923] (p=0.016, logit=16.500)']\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     int_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.7890625, logit=20.375, token_id=3061, metadata=None))), (56491, (3, PredictedToken(token=' Piano', prob=0.039306640625, logit=17.375, token_id=56491, metadata=None))), (97796, (4, PredictedToken(token=' Skate', prob=0.0185546875, logit=16.625, token_id=97796, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.016357421875, logit=16.5, token_id=4923, metadata=None))), (423, (22, PredictedToken(token=' D', prob=0.000766754150390625, logit=13.4375, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:48 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:40:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.668, logit=19.125)', '\" The\"[578] (p=0.149, logit=17.625)', '\" A\"[362] (p=0.014, logit=15.250)', '\" CO\"[7432] (p=0.013, logit=15.188)', '\" It\"[1102] (p=0.013, logit=15.188)']\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.688, logit=19.750)', '\" Red\"[3816] (p=0.196, logit=18.500)', '\" The\"[578] (p=0.034, logit=16.750)', '\" There\"[2684] (p=0.013, logit=15.750)', '\" Ottoman\"[70110] (p=0.010, logit=15.562)']\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.6875, logit=19.75, token_id=42609, metadata=None))), (3816, (2, PredictedToken(token=' Red', prob=0.1962890625, logit=18.5, token_id=3816, metadata=None))), (70110, (5, PredictedToken(token=' Ottoman', prob=0.01043701171875, logit=15.5625, token_id=70110, metadata=None))), (39794, (93, PredictedToken(token=' Desk', prob=7.963180541992188e-05, logit=10.6875, token_id=39794, metadata=None))), (72683, (138, PredictedToken(token=' Boxing', prob=3.7670135498046875e-05, logit=9.9375, token_id=72683, metadata=None)))])\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.859, logit=20.500)', '\" Pine\"[42609] (p=0.048, logit=17.625)', '\" The\"[578] (p=0.023, logit=16.875)', '\" There\"[2684] (p=0.014, logit=16.375)', '\" An\"[1556] (p=0.011, logit=16.125)']\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.859375, logit=20.5, token_id=70110, metadata=None))), (42609, (2, PredictedToken(token=' Pine', prob=0.04833984375, logit=17.625, token_id=42609, metadata=None))), (3816, (7, PredictedToken(token=' Red', prob=0.00543212890625, logit=15.4375, token_id=3816, metadata=None))), (39794, (20, PredictedToken(token=' Desk', prob=0.00064849853515625, logit=13.3125, token_id=39794, metadata=None))), (72683, (73, PredictedToken(token=' Boxing', prob=7.295608520507812e-05, logit=11.125, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:49 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:49 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:40:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.389, logit=18.625)', '\" Food\"[12369] (p=0.235, logit=18.125)', '\" The\"[578] (p=0.143, logit=17.625)', '\" A\"[362] (p=0.036, logit=16.250)', '\" Pen\"[13597] (p=0.021, logit=15.688)']\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     clean_prediction=['\" Soap\"[61731] (p=0.645, logit=20.000)', '\" Razor\"[74968] (p=0.209, logit=18.875)', '\" The\"[578] (p=0.053, logit=17.500)', '\" SOAP\"[64332] (p=0.032, logit=17.000)', '\" A\"[362] (p=0.007, logit=15.500)']\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     clean_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.64453125, logit=20.0, token_id=61731, metadata=None))), (74968, (2, PredictedToken(token=' Razor', prob=0.208984375, logit=18.875, token_id=74968, metadata=None))), (72392, (8, PredictedToken(token=' Mixer', prob=0.0027923583984375, logit=14.5625, token_id=72392, metadata=None))), (70306, (10, PredictedToken(token=' Brace', prob=0.0023193359375, logit=14.375, token_id=70306, metadata=None))), (27171, (11, PredictedToken(token=' Coffee', prob=0.0021820068359375, logit=14.3125, token_id=27171, metadata=None))), (91263, (38, PredictedToken(token=' Binder', prob=0.00031280517578125, logit=12.375, token_id=91263, metadata=None))), (65329, (110, PredictedToken(token=' Elm', prob=6.198883056640625e-05, logit=10.75, token_id=65329, metadata=None)))])\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.426, logit=19.625)', '\" Coffee\"[27171] (p=0.228, logit=19.000)', '\" Soap\"[61731] (p=0.138, logit=18.500)', '\" The\"[578] (p=0.095, logit=18.125)', '\" MIX\"[81309] (p=0.027, logit=16.875)']\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.42578125, logit=19.625, token_id=72392, metadata=None))), (27171, (2, PredictedToken(token=' Coffee', prob=0.2275390625, logit=19.0, token_id=27171, metadata=None))), (61731, (3, PredictedToken(token=' Soap', prob=0.1376953125, logit=18.5, token_id=61731, metadata=None))), (74968, (12, PredictedToken(token=' Razor', prob=0.00153350830078125, logit=14.0, token_id=74968, metadata=None))), (70306, (31, PredictedToken(token=' Brace', prob=0.000499725341796875, logit=12.875, token_id=70306, metadata=None))), (91263, (38, PredictedToken(token=' Binder', prob=0.0004119873046875, logit=12.6875, token_id=91263, metadata=None))), (65329, (410, PredictedToken(token=' Elm', prob=7.092952728271484e-06, logit=8.625, token_id=65329, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:50 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.809, logit=19.875)', '\" Razor\"[74968] (p=0.059, logit=17.250)', '\" The\"[578] (p=0.036, logit=16.750)', '\" None\"[2290] (p=0.017, logit=16.000)', '\" A\"[362] (p=0.012, logit=15.625)']\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.410, logit=18.750)', '\" Hair\"[26781] (p=0.320, logit=18.500)', '\" The\"[578] (p=0.071, logit=17.000)', '\" Notebook\"[69755] (p=0.038, logit=16.375)', '\" Tablet\"[58403] (p=0.038, logit=16.375)']\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.41015625, logit=18.75, token_id=47033, metadata=None))), (26781, (2, PredictedToken(token=' Hair', prob=0.3203125, logit=18.5, token_id=26781, metadata=None))), (58403, (4, PredictedToken(token=' Tablet', prob=0.0380859375, logit=16.375, token_id=58403, metadata=None))), (69755, (5, PredictedToken(token=' Notebook', prob=0.0380859375, logit=16.375, token_id=69755, metadata=None))), (18343, (12, PredictedToken(token=' Paper', prob=0.005859375, logit=14.5, token_id=18343, metadata=None)))])\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.520, logit=20.000)', '\" Notebook\"[69755] (p=0.404, logit=19.750)', '\" The\"[578] (p=0.018, logit=16.625)', '\" Tablet\"[58403] (p=0.010, logit=16.000)', '\" A\"[362] (p=0.008, logit=15.812)']\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.51953125, logit=20.0, token_id=47033, metadata=None))), (69755, (2, PredictedToken(token=' Notebook', prob=0.404296875, logit=19.75, token_id=69755, metadata=None))), (58403, (4, PredictedToken(token=' Tablet', prob=0.009521484375, logit=16.0, token_id=58403, metadata=None))), (18343, (6, PredictedToken(token=' Paper', prob=0.00396728515625, logit=15.125, token_id=18343, metadata=None))), (26781, (193, PredictedToken(token=' Hair', prob=1.519918441772461e-05, logit=9.5625, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:51 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:40:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.504, logit=19.750)', '\" The\"[578] (p=0.211, logit=18.875)', '\" Router\"[10777] (p=0.145, logit=18.500)', '\" A\"[362] (p=0.025, logit=16.750)', '\" K\"[735] (p=0.017, logit=16.375)']\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.801, logit=19.750)', '\" The\"[578] (p=0.058, logit=17.125)', '\" Oven\"[87213] (p=0.031, logit=16.500)', '\" A\"[362] (p=0.021, logit=16.125)', '\" FOOD\"[88227] (p=0.019, logit=16.000)']\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.80078125, logit=19.75, token_id=12369, metadata=None))), (87213, (3, PredictedToken(token=' Oven', prob=0.031005859375, logit=16.5, token_id=87213, metadata=None))), (79028, (8, PredictedToken(token=' Hick', prob=0.004486083984375, logit=14.5625, token_id=79028, metadata=None))), (45805, (10, PredictedToken(token=' Cherry', prob=0.0037078857421875, logit=14.375, token_id=45805, metadata=None))), (47033, (11, PredictedToken(token=' Printer', prob=0.00347900390625, logit=14.3125, token_id=47033, metadata=None))), (58403, (26, PredictedToken(token=' Tablet', prob=0.0005340576171875, logit=12.4375, token_id=58403, metadata=None)))])\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.582, logit=19.250)', '\" Tablet\"[58403] (p=0.188, logit=18.125)', '\" Printer\"[47033] (p=0.061, logit=17.000)', '\" The\"[578] (p=0.054, logit=16.875)', '\" Hick\"[79028] (p=0.023, logit=16.000)']\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.58203125, logit=19.25, token_id=87213, metadata=None))), (58403, (2, PredictedToken(token=' Tablet', prob=0.1884765625, logit=18.125, token_id=58403, metadata=None))), (47033, (3, PredictedToken(token=' Printer', prob=0.061279296875, logit=17.0, token_id=47033, metadata=None))), (79028, (5, PredictedToken(token=' Hick', prob=0.0225830078125, logit=16.0, token_id=79028, metadata=None))), (45805, (9, PredictedToken(token=' Cherry', prob=0.0036773681640625, logit=14.1875, token_id=45805, metadata=None))), (12369, (264, PredictedToken(token=' Food', prob=1.811981201171875e-05, logit=8.875, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:52 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:40:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.436, logit=18.875)', '\" The\"[578] (p=0.142, logit=17.750)', '\" Pressure\"[40090] (p=0.125, logit=17.625)', '\" C\"[356] (p=0.110, logit=17.500)', '\" A\"[362] (p=0.059, logit=16.875)']\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.688, logit=19.125)', '\" The\"[578] (p=0.120, logit=17.375)', '\" Potato\"[78703] (p=0.039, logit=16.250)', '\" There\"[2684] (p=0.039, logit=16.250)', '\" CEL\"[91521] (p=0.013, logit=15.125)']\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.6875, logit=19.125, token_id=47643, metadata=None))), (78703, (4, PredictedToken(token=' Potato', prob=0.038818359375, logit=16.25, token_id=78703, metadata=None))), (46506, (136, PredictedToken(token=' Drum', prob=7.486343383789062e-05, logit=10.0, token_id=46506, metadata=None))), (39247, (135, PredictedToken(token=' Slow', prob=7.486343383789062e-05, logit=10.0, token_id=39247, metadata=None))), (6690, (224, PredictedToken(token=' Air', prob=3.314018249511719e-05, logit=9.1875, token_id=6690, metadata=None)))])\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.555, logit=18.250)', '\" Slow\"[39247] (p=0.159, logit=17.000)', '\" The\"[578] (p=0.059, logit=16.000)', '\" Fry\"[53517] (p=0.046, logit=15.750)', '\" There\"[2684] (p=0.029, logit=15.312)']\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.5546875, logit=18.25, token_id=6690, metadata=None))), (39247, (2, PredictedToken(token=' Slow', prob=0.1591796875, logit=17.0, token_id=39247, metadata=None))), (78703, (10, PredictedToken(token=' Potato', prob=0.00616455078125, logit=13.75, token_id=78703, metadata=None))), (47643, (12, PredictedToken(token=' Cel', prob=0.00543212890625, logit=13.625, token_id=47643, metadata=None))), (46506, (23, PredictedToken(token=' Drum', prob=0.0019989013671875, logit=12.625, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:53 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:40:53 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:40:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.930, logit=22.125)', '\" Car\"[3341] (p=0.032, logit=18.750)', '\" The\"[578] (p=0.019, logit=18.250)', '\" CA\"[9362] (p=0.005, logit=16.875)', '\" There\"[2684] (p=0.002, logit=16.125)']\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.605, logit=19.875)', '\" Hair\"[26781] (p=0.173, logit=18.625)', '\" The\"[578] (p=0.093, logit=18.000)', '\" Ti\"[23126] (p=0.030, logit=16.875)', '\" TO\"[5257] (p=0.014, logit=16.125)']\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.60546875, logit=19.875, token_id=82994, metadata=None))), (26781, (2, PredictedToken(token=' Hair', prob=0.1728515625, logit=18.625, token_id=26781, metadata=None))), (23126, (4, PredictedToken(token=' Ti', prob=0.030029296875, logit=16.875, token_id=23126, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.00714111328125, logit=15.4375, token_id=469, metadata=None))), (78703, (59, PredictedToken(token=' Potato', prob=0.0001678466796875, logit=11.6875, token_id=78703, metadata=None))), (94091, (88, PredictedToken(token=' Tomato', prob=9.012222290039062e-05, logit=11.0625, token_id=94091, metadata=None)))])\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.754, logit=20.250)', '\" Potato\"[78703] (p=0.102, logit=18.250)', '\" The\"[578] (p=0.055, logit=17.625)', '\" TO\"[5257] (p=0.020, logit=16.625)', '\" POT\"[62602] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.75390625, logit=20.25, token_id=82994, metadata=None))), (78703, (2, PredictedToken(token=' Potato', prob=0.10205078125, logit=18.25, token_id=78703, metadata=None))), (23126, (9, PredictedToken(token=' Ti', prob=0.004486083984375, logit=15.125, token_id=23126, metadata=None))), (26781, (10, PredictedToken(token=' Hair', prob=0.00154876708984375, logit=14.0625, token_id=26781, metadata=None))), (94091, (12, PredictedToken(token=' Tomato', prob=0.00154876708984375, logit=14.0625, token_id=94091, metadata=None))), (469, (17, PredictedToken(token=' E', prob=0.000690460205078125, logit=13.25, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:54 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:40:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.770, logit=19.500)', '\" The\"[578] (p=0.063, logit=17.000)', '\" None\"[2290] (p=0.038, logit=16.500)', '\" Fl\"[3061] (p=0.026, logit=16.125)', '\" There\"[2684] (p=0.010, logit=15.188)']\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.574, logit=18.375)', '\" The\"[578] (p=0.113, logit=16.750)', '\" Magn\"[20918] (p=0.050, logit=15.938)', '\" Drum\"[46506] (p=0.042, logit=15.750)', '\" RED\"[26895] (p=0.027, logit=15.312)']\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.57421875, logit=18.375, token_id=3816, metadata=None))), (20918, (3, PredictedToken(token=' Magn', prob=0.05029296875, logit=15.9375, token_id=20918, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.041748046875, logit=15.75, token_id=46506, metadata=None))), (3341, (7, PredictedToken(token=' Car', prob=0.016357421875, logit=14.8125, token_id=3341, metadata=None))), (5340, (12, PredictedToken(token=' Har', prob=0.006805419921875, logit=13.9375, token_id=5340, metadata=None)))])\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     int_prediction=['\" Drum\"[46506] (p=0.688, logit=19.000)', '\" The\"[578] (p=0.082, logit=16.875)', '\" DR\"[14644] (p=0.073, logit=16.750)', '\" Har\"[5340] (p=0.020, logit=15.438)', '\" There\"[2684] (p=0.020, logit=15.438)']\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     int_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.6875, logit=19.0, token_id=46506, metadata=None))), (5340, (5, PredictedToken(token=' Har', prob=0.01953125, logit=15.4375, token_id=5340, metadata=None))), (3816, (8, PredictedToken(token=' Red', prob=0.0072021484375, logit=14.4375, token_id=3816, metadata=None))), (20918, (9, PredictedToken(token=' Magn', prob=0.0034027099609375, logit=13.6875, token_id=20918, metadata=None))), (3341, (13, PredictedToken(token=' Car', prob=0.00299072265625, logit=13.5625, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:40:55 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.828, logit=19.875)', '\" R\"[432] (p=0.036, logit=16.750)', '\" An\"[1556] (p=0.028, logit=16.500)', '\" The\"[578] (p=0.022, logit=16.250)', '\" ER\"[27590] (p=0.014, logit=15.812)']\n",
      "2025-09-15 09:40:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     clean_prediction=['\" Scar\"[30760] (p=0.695, logit=20.125)', '\" Tie\"[59825] (p=0.154, logit=18.625)', '\" The\"[578] (p=0.064, logit=17.750)', '\" A\"[362] (p=0.031, logit=17.000)', '\" SC\"[7683] (p=0.007, logit=15.562)']\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     clean_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.6953125, logit=20.125, token_id=30760, metadata=None))), (59825, (2, PredictedToken(token=' Tie', prob=0.154296875, logit=18.625, token_id=59825, metadata=None))), (40975, (6, PredictedToken(token=' Marker', prob=0.006805419921875, logit=15.5, token_id=40975, metadata=None))), (393, (11, PredictedToken(token=' P', prob=0.001617431640625, logit=14.0625, token_id=393, metadata=None)))])\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.574, logit=19.500)', '\" Tie\"[59825] (p=0.145, logit=18.125)', '\" Marker\"[40975] (p=0.088, logit=17.625)', '\" Scar\"[30760] (p=0.053, logit=17.125)', '\" The\"[578] (p=0.042, logit=16.875)']\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.57421875, logit=19.5, token_id=393, metadata=None))), (59825, (2, PredictedToken(token=' Tie', prob=0.14453125, logit=18.125, token_id=59825, metadata=None))), (40975, (3, PredictedToken(token=' Marker', prob=0.087890625, logit=17.625, token_id=40975, metadata=None))), (30760, (4, PredictedToken(token=' Scar', prob=0.05322265625, logit=17.125, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:56 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:40:56 src.selection.optimization DEBUG    torch.Size([7, 36])\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     patch_prediction=['\" Guitar\"[47759] (p=0.621, logit=19.750)', '\" The\"[578] (p=0.229, logit=18.750)', '\" G\"[480] (p=0.058, logit=17.375)', '\" Acc\"[11683] (p=0.012, logit=15.812)', '\" A\"[362] (p=0.011, logit=15.688)']\n",
      "2025-09-15 09:40:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     clean_prediction=['\" Rice\"[30616] (p=0.738, logit=19.875)', '\" The\"[578] (p=0.128, logit=18.125)', '\" Oven\"[87213] (p=0.022, logit=16.375)', '\" A\"[362] (p=0.017, logit=16.125)', '\" Clar\"[31181] (p=0.010, logit=15.562)']\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     clean_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.73828125, logit=19.875, token_id=30616, metadata=None))), (87213, (3, PredictedToken(token=' Oven', prob=0.022216796875, logit=16.375, token_id=87213, metadata=None))), (31181, (5, PredictedToken(token=' Clar', prob=0.0098876953125, logit=15.5625, token_id=31181, metadata=None))), (70306, (20, PredictedToken(token=' Brace', prob=0.0011749267578125, logit=13.4375, token_id=70306, metadata=None))), (3420, (39, PredictedToken(token=' Trump', prob=0.0004329681396484375, logit=12.4375, token_id=3420, metadata=None))), (29318, (103, PredictedToken(token=' Dress', prob=8.0108642578125e-05, logit=10.75, token_id=29318, metadata=None))), (82452, (165, PredictedToken(token=' Jasmine', prob=3.147125244140625e-05, logit=9.8125, token_id=82452, metadata=None)))])\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.691, logit=20.250)', '\" Clar\"[31181] (p=0.137, logit=18.625)', '\" The\"[578] (p=0.106, logit=18.375)', '\" TR\"[5091] (p=0.013, logit=16.250)', '\" There\"[2684] (p=0.008, logit=15.812)']\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.69140625, logit=20.25, token_id=3420, metadata=None))), (31181, (2, PredictedToken(token=' Clar', prob=0.13671875, logit=18.625, token_id=31181, metadata=None))), (87213, (22, PredictedToken(token=' Oven', prob=0.000461578369140625, logit=12.9375, token_id=87213, metadata=None))), (70306, (39, PredictedToken(token=' Brace', prob=0.0001926422119140625, logit=12.0625, token_id=70306, metadata=None))), (30616, (154, PredictedToken(token=' Rice', prob=1.6808509826660156e-05, logit=9.625, token_id=30616, metadata=None))), (29318, (243, PredictedToken(token=' Dress', prob=8.463859558105469e-06, logit=8.9375, token_id=29318, metadata=None))), (82452, (442, PredictedToken(token=' Jasmine', prob=3.7550926208496094e-06, logit=8.125, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:57 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.773, logit=20.125)', '\" The\"[578] (p=0.082, logit=17.875)', '\" House\"[4783] (p=0.043, logit=17.250)', '\" A\"[362] (p=0.026, logit=16.750)', '\" Magn\"[20918] (p=0.010, logit=15.750)']\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     clean_prediction=['\" Elm\"[65329] (p=0.727, logit=19.250)', '\" Pine\"[42609] (p=0.077, logit=17.000)', '\" The\"[578] (p=0.077, logit=17.000)', '\" None\"[2290] (p=0.013, logit=15.250)', '\" There\"[2684] (p=0.013, logit=15.188)']\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     clean_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.7265625, logit=19.25, token_id=65329, metadata=None))), (42609, (3, PredictedToken(token=' Pine', prob=0.07666015625, logit=17.0, token_id=42609, metadata=None))), (9441, (13, PredictedToken(token=' Church', prob=0.00262451171875, logit=13.625, token_id=9441, metadata=None))), (59825, (40, PredictedToken(token=' Tie', prob=0.000400543212890625, logit=11.75, token_id=59825, metadata=None))), (17367, (152, PredictedToken(token=' Factory', prob=5.1021575927734375e-05, logit=9.6875, token_id=17367, metadata=None)))])\n",
      "2025-09-15 09:40:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.629, logit=19.125)', '\" Church\"[9441] (p=0.159, logit=17.750)', '\" The\"[578] (p=0.058, logit=16.750)', '\" Tie\"[59825] (p=0.020, logit=15.688)', '\" Pine\"[42609] (p=0.019, logit=15.625)']\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.62890625, logit=19.125, token_id=65329, metadata=None))), (9441, (2, PredictedToken(token=' Church', prob=0.1591796875, logit=17.75, token_id=9441, metadata=None))), (59825, (4, PredictedToken(token=' Tie', prob=0.0201416015625, logit=15.6875, token_id=59825, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.0189208984375, logit=15.625, token_id=42609, metadata=None))), (17367, (8, PredictedToken(token=' Factory', prob=0.01080322265625, logit=15.0625, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:58 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.848, logit=21.750)', '\" The\"[578] (p=0.070, logit=19.250)', '\" Plum\"[84409] (p=0.048, logit=18.875)', '\" PE\"[22557] (p=0.006, logit=16.875)', '\" A\"[362] (p=0.006, logit=16.750)']\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.820, logit=20.750)', '\" The\"[578] (p=0.086, logit=18.500)', '\" A\"[362] (p=0.019, logit=17.000)', '\" Bat\"[16488] (p=0.012, logit=16.500)', '\" Tennis\"[58251] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.8203125, logit=20.75, token_id=432, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.01171875, logit=16.5, token_id=16488, metadata=None))), (3341, (32, PredictedToken(token=' Car', prob=0.00042724609375, logit=13.1875, token_id=3341, metadata=None))), (8868, (61, PredictedToken(token=' Blue', prob=8.392333984375e-05, logit=11.5625, token_id=8868, metadata=None))), (45805, (337, PredictedToken(token=' Cherry', prob=6.079673767089844e-06, logit=8.9375, token_id=45805, metadata=None)))])\n",
      "2025-09-15 09:40:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     int_prediction=['\" Cherry\"[45805] (p=0.652, logit=19.500)', '\" Bat\"[16488] (p=0.146, logit=18.000)', '\" The\"[578] (p=0.078, logit=17.375)', '\" CH\"[6969] (p=0.016, logit=15.812)', '\" Blue\"[8868] (p=0.014, logit=15.625)']\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     int_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.65234375, logit=19.5, token_id=45805, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.1455078125, logit=18.0, token_id=16488, metadata=None))), (8868, (5, PredictedToken(token=' Blue', prob=0.0135498046875, logit=15.625, token_id=8868, metadata=None))), (432, (7, PredictedToken(token=' R', prob=0.007232666015625, logit=15.0, token_id=432, metadata=None))), (3341, (11, PredictedToken(token=' Car', prob=0.0036468505859375, logit=14.3125, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:40:59 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     patch_prediction=['\" Mango\"[91963] (p=0.777, logit=20.500)', '\" The\"[578] (p=0.136, logit=18.750)', '\" M\"[386] (p=0.021, logit=16.875)', '\" A\"[362] (p=0.011, logit=16.250)', '\" There\"[2684] (p=0.006, logit=15.688)']\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.859, logit=20.625)', '\" The\"[578] (p=0.026, logit=17.125)', '\" Folder\"[36943] (p=0.020, logit=16.875)', '\" P\"[393] (p=0.018, logit=16.750)', '\" A\"[362] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.859375, logit=20.625, token_id=18343, metadata=None))), (36943, (3, PredictedToken(token=' Folder', prob=0.020263671875, logit=16.875, token_id=36943, metadata=None))), (70306, (10, PredictedToken(token=' Brace', prob=0.0024261474609375, logit=14.75, token_id=70306, metadata=None))), (30558, (24, PredictedToken(token=' Ki', prob=0.000652313232421875, logit=13.4375, token_id=30558, metadata=None))), (42609, (26, PredictedToken(token=' Pine', prob=0.000576019287109375, logit=13.3125, token_id=42609, metadata=None)))])\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.578, logit=19.500)', '\" Ki\"[30558] (p=0.241, logit=18.625)', '\" The\"[578] (p=0.042, logit=16.875)', '\" P\"[393] (p=0.022, logit=16.250)', '\" A\"[362] (p=0.015, logit=15.875)']\n",
      "2025-09-15 09:40:59 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.578125, logit=19.5, token_id=42609, metadata=None))), (30558, (2, PredictedToken(token=' Ki', prob=0.2412109375, logit=18.625, token_id=30558, metadata=None))), (36943, (7, PredictedToken(token=' Folder', prob=0.01361083984375, logit=15.75, token_id=36943, metadata=None))), (18343, (8, PredictedToken(token=' Paper', prob=0.007293701171875, logit=15.125, token_id=18343, metadata=None))), (70306, (25, PredictedToken(token=' Brace', prob=0.000720977783203125, logit=12.8125, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:40:59 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:00 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:41:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:00 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.668, logit=19.875)', '\" The\"[578] (p=0.169, logit=18.500)', '\" Iris\"[66821] (p=0.049, logit=17.250)', '\" C\"[356] (p=0.033, logit=16.875)', '\" A\"[362] (p=0.020, logit=16.375)']\n",
      "2025-09-15 09:41:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:00 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.754, logit=20.750)', '\" The\"[578] (p=0.080, logit=18.500)', '\" Rice\"[30616] (p=0.062, logit=18.250)', '\" An\"[1556] (p=0.048, logit=18.000)', '\" AIR\"[46994] (p=0.011, logit=16.500)']\n",
      "2025-09-15 09:41:00 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.75390625, logit=20.75, token_id=6690, metadata=None))), (30616, (3, PredictedToken(token=' Rice', prob=0.06201171875, logit=18.25, token_id=30616, metadata=None))), (6031, (17, PredictedToken(token=' Bro', prob=0.00099945068359375, logit=14.125, token_id=6031, metadata=None))), (8219, (77, PredictedToken(token=' Sun', prob=4.696846008300781e-05, logit=11.0625, token_id=8219, metadata=None))), (13120, (134, PredictedToken(token=' Night', prob=1.8358230590820312e-05, logit=10.125, token_id=13120, metadata=None))), (28131, (140, PredictedToken(token=' Golf', prob=1.728534698486328e-05, logit=10.0625, token_id=28131, metadata=None))), (43316, (864, PredictedToken(token=' Tul', prob=8.568167686462402e-07, logit=7.0625, token_id=43316, metadata=None)))])\n",
      "2025-09-15 09:41:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.770, logit=20.625)', '\" Tul\"[43316] (p=0.104, logit=18.625)', '\" The\"[578] (p=0.063, logit=18.125)', '\" Night\"[13120] (p=0.011, logit=16.375)', '\" SUN\"[57328] (p=0.006, logit=15.812)']\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.76953125, logit=20.625, token_id=8219, metadata=None))), (43316, (2, PredictedToken(token=' Tul', prob=0.1044921875, logit=18.625, token_id=43316, metadata=None))), (13120, (4, PredictedToken(token=' Night', prob=0.010986328125, logit=16.375, token_id=13120, metadata=None))), (30616, (21, PredictedToken(token=' Rice', prob=0.000583648681640625, logit=13.4375, token_id=30616, metadata=None))), (28131, (28, PredictedToken(token=' Golf', prob=0.000331878662109375, logit=12.875, token_id=28131, metadata=None))), (6031, (66, PredictedToken(token=' Bro', prob=7.390975952148438e-05, logit=11.375, token_id=6031, metadata=None))), (6690, (646, PredictedToken(token=' Air', prob=1.9818544387817383e-06, logit=7.75, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:01 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     patch_prediction=['\" Pressure\"[40090] (p=0.781, logit=20.125)', '\" Oven\"[87213] (p=0.056, logit=17.500)', '\" The\"[578] (p=0.050, logit=17.375)', '\" Mar\"[2947] (p=0.044, logit=17.250)', '\" A\"[362] (p=0.010, logit=15.812)']\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.680, logit=19.750)', '\" The\"[578] (p=0.151, logit=18.250)', '\" Surf\"[65197] (p=0.072, logit=17.500)', '\" A\"[362] (p=0.021, logit=16.250)', '\" SUR\"[53083] (p=0.010, logit=15.562)']\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.6796875, logit=19.75, token_id=423, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.07177734375, logit=17.5, token_id=65197, metadata=None))), (2057, (27, PredictedToken(token=' To', prob=0.000514984130859375, logit=12.5625, token_id=2057, metadata=None))), (72392, (97, PredictedToken(token=' Mixer', prob=6.961822509765625e-05, logit=10.5625, token_id=72392, metadata=None))), (8219, (93, PredictedToken(token=' Sun', prob=6.961822509765625e-05, logit=10.5625, token_id=8219, metadata=None)))])\n",
      "2025-09-15 09:41:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.504, logit=19.500)', '\" To\"[2057] (p=0.145, logit=18.250)', '\" The\"[578] (p=0.145, logit=18.250)', '\" MIX\"[81309] (p=0.060, logit=17.375)', '\" TO\"[5257] (p=0.047, logit=17.125)']\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.50390625, logit=19.5, token_id=72392, metadata=None))), (2057, (3, PredictedToken(token=' To', prob=0.14453125, logit=18.25, token_id=2057, metadata=None))), (65197, (11, PredictedToken(token=' Surf', prob=0.002655029296875, logit=14.25, token_id=65197, metadata=None))), (423, (28, PredictedToken(token=' D', prob=0.000629425048828125, logit=12.8125, token_id=423, metadata=None))), (8219, (91, PredictedToken(token=' Sun', prob=6.628036499023438e-05, logit=10.5625, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:02 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.373, logit=19.000)', '\" Hockey\"[41342] (p=0.226, logit=18.500)', '\" The\"[578] (p=0.226, logit=18.500)', '\" A\"[362] (p=0.057, logit=17.125)', '\" Stick\"[47561] (p=0.009, logit=15.312)']\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     clean_prediction=['\" Monkey\"[58937] (p=0.848, logit=20.375)', '\" Cow\"[22607] (p=0.037, logit=17.250)', '\" The\"[578] (p=0.029, logit=17.000)', '\" MON\"[29637] (p=0.026, logit=16.875)', '\" A\"[362] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     clean_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.84765625, logit=20.375, token_id=58937, metadata=None))), (22607, (2, PredictedToken(token=' Cow', prob=0.037109375, logit=17.25, token_id=22607, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.006072998046875, logit=15.4375, token_id=432, metadata=None))), (42609, (9, PredictedToken(token=' Pine', prob=0.0030517578125, logit=14.75, token_id=42609, metadata=None))), (47589, (56, PredictedToken(token=' Basketball', prob=0.0001430511474609375, logit=11.6875, token_id=47589, metadata=None)))])\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.590, logit=19.750)', '\" Basketball\"[47589] (p=0.246, logit=18.875)', '\" Monkey\"[58937] (p=0.043, logit=17.125)', '\" The\"[578] (p=0.023, logit=16.500)', '\" A\"[362] (p=0.014, logit=16.000)']\n",
      "2025-09-15 09:41:02 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.58984375, logit=19.75, token_id=432, metadata=None))), (47589, (2, PredictedToken(token=' Basketball', prob=0.24609375, logit=18.875, token_id=47589, metadata=None))), (58937, (3, PredictedToken(token=' Monkey', prob=0.042724609375, logit=17.125, token_id=58937, metadata=None))), (22607, (6, PredictedToken(token=' Cow', prob=0.009521484375, logit=15.625, token_id=22607, metadata=None))), (42609, (9, PredictedToken(token=' Pine', prob=0.005767822265625, logit=15.125, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:03 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:03 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:41:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:03 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.836, logit=20.875)', '\" The\"[578] (p=0.078, logit=18.500)', '\" OR\"[2794] (p=0.032, logit=17.625)', '\" An\"[1556] (p=0.008, logit=16.250)', '\" orch\"[41245] (p=0.007, logit=16.125)']\n",
      "2025-09-15 09:41:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:03 src.selection.optimization INFO     clean_prediction=['\" Fl\"[3061] (p=0.660, logit=20.125)', '\" The\"[578] (p=0.242, logit=19.125)', '\" X\"[1630] (p=0.026, logit=16.875)', '\" FL\"[13062] (p=0.018, logit=16.500)', '\" A\"[362] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:41:03 src.selection.optimization INFO     clean_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.66015625, logit=20.125, token_id=3061, metadata=None))), (1630, (3, PredictedToken(token=' X', prob=0.0255126953125, logit=16.875, token_id=1630, metadata=None))), (6031, (22, PredictedToken(token=' Bro', prob=0.00072479248046875, logit=13.3125, token_id=6031, metadata=None))), (43316, (38, PredictedToken(token=' Tul', prob=0.00023555755615234375, logit=12.1875, token_id=43316, metadata=None))), (24941, (96, PredictedToken(token=' Bear', prob=5.245208740234375e-05, logit=10.6875, token_id=24941, metadata=None))), (43950, (103, PredictedToken(token=' Lav', prob=4.935264587402344e-05, logit=10.625, token_id=43950, metadata=None))), (26781, (252, PredictedToken(token=' Hair', prob=9.715557098388672e-06, logit=9.0, token_id=26781, metadata=None)))])\n",
      "2025-09-15 09:41:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     int_prediction=['\" Tul\"[43316] (p=0.676, logit=20.000)', '\" The\"[578] (p=0.171, logit=18.625)', '\" Bro\"[6031] (p=0.034, logit=17.000)', '\" Bear\"[24941] (p=0.020, logit=16.500)', '\" Lav\"[43950] (p=0.016, logit=16.250)']\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     int_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.67578125, logit=20.0, token_id=43316, metadata=None))), (6031, (3, PredictedToken(token=' Bro', prob=0.03369140625, logit=17.0, token_id=6031, metadata=None))), (24941, (4, PredictedToken(token=' Bear', prob=0.0203857421875, logit=16.5, token_id=24941, metadata=None))), (43950, (5, PredictedToken(token=' Lav', prob=0.015869140625, logit=16.25, token_id=43950, metadata=None))), (1630, (25, PredictedToken(token=' X', prob=0.000698089599609375, logit=13.125, token_id=1630, metadata=None))), (3061, (30, PredictedToken(token=' Fl', prob=0.00051116943359375, logit=12.8125, token_id=3061, metadata=None))), (26781, (439, PredictedToken(token=' Hair', prob=5.0067901611328125e-06, logit=8.1875, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:04 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.855, logit=21.250)', '\" The\"[578] (p=0.080, logit=18.875)', '\" P\"[393] (p=0.026, logit=17.750)', '\" It\"[1102] (p=0.005, logit=16.125)', '\" A\"[362] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.613, logit=18.875)', '\" The\"[578] (p=0.121, logit=17.250)', '\" Har\"[5340] (p=0.051, logit=16.375)', '\" A\"[362] (p=0.051, logit=16.375)', '\" Viol\"[30555] (p=0.031, logit=15.875)']\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.61328125, logit=18.875, token_id=17367, metadata=None))), (5340, (4, PredictedToken(token=' Har', prob=0.050537109375, logit=16.375, token_id=5340, metadata=None))), (30555, (5, PredictedToken(token=' Viol', prob=0.0306396484375, logit=15.875, token_id=30555, metadata=None))), (32498, (6, PredictedToken(token=' Mall', prob=0.0269775390625, logit=15.75, token_id=32498, metadata=None))), (22410, (14, PredictedToken(token=' Ju', prob=0.0026702880859375, logit=13.4375, token_id=22410, metadata=None)))])\n",
      "2025-09-15 09:41:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.680, logit=19.375)', '\" Factory\"[17367] (p=0.081, logit=17.250)', '\" The\"[578] (p=0.081, logit=17.250)', '\" Har\"[5340] (p=0.038, logit=16.500)', '\" A\"[362] (p=0.021, logit=15.875)']\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.6796875, logit=19.375, token_id=30555, metadata=None))), (17367, (3, PredictedToken(token=' Factory', prob=0.0810546875, logit=17.25, token_id=17367, metadata=None))), (5340, (4, PredictedToken(token=' Har', prob=0.038330078125, logit=16.5, token_id=5340, metadata=None))), (32498, (7, PredictedToken(token=' Mall', prob=0.012451171875, logit=15.375, token_id=32498, metadata=None))), (22410, (14, PredictedToken(token=' Ju', prob=0.0023040771484375, logit=13.6875, token_id=22410, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:05 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     patch_prediction=['\" Let\"[6914] (p=0.762, logit=21.250)', '\" The\"[578] (p=0.103, logit=19.250)', '\" Z\"[1901] (p=0.071, logit=18.875)', '\" LET\"[36757] (p=0.016, logit=17.375)', '\" There\"[2684] (p=0.014, logit=17.250)']\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     clean_prediction=['\" Desk\"[39794] (p=0.707, logit=20.375)', '\" The\"[578] (p=0.158, logit=18.875)', '\" Table\"[6771] (p=0.040, logit=17.500)', '\" DES\"[13022] (p=0.019, logit=16.750)', '\" A\"[362] (p=0.013, logit=16.375)']\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     clean_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.70703125, logit=20.375, token_id=39794, metadata=None))), (6771, (3, PredictedToken(token=' Table', prob=0.039794921875, logit=17.5, token_id=6771, metadata=None))), (22050, (25, PredictedToken(token=' Hat', prob=0.0006866455078125, logit=13.4375, token_id=22050, metadata=None))), (47643, (113, PredictedToken(token=' Cel', prob=3.8623809814453125e-05, logit=10.5625, token_id=47643, metadata=None))), (90538, (264, PredictedToken(token=' Caul', prob=9.179115295410156e-06, logit=9.125, token_id=90538, metadata=None)))])\n",
      "2025-09-15 09:41:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     int_prediction=['\" Caul\"[90538] (p=0.688, logit=19.500)', '\" The\"[578] (p=0.120, logit=17.750)', '\" Cel\"[47643] (p=0.073, logit=17.250)', '\" Desk\"[39794] (p=0.021, logit=16.000)', '\" CA\"[9362] (p=0.013, logit=15.562)']\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     int_track=OrderedDict([(90538, (1, PredictedToken(token=' Caul', prob=0.6875, logit=19.5, token_id=90538, metadata=None))), (47643, (3, PredictedToken(token=' Cel', prob=0.07275390625, logit=17.25, token_id=47643, metadata=None))), (39794, (4, PredictedToken(token=' Desk', prob=0.020751953125, logit=16.0, token_id=39794, metadata=None))), (6771, (14, PredictedToken(token=' Table', prob=0.0020599365234375, logit=13.6875, token_id=6771, metadata=None))), (22050, (270, PredictedToken(token=' Hat', prob=1.5735626220703125e-05, logit=8.8125, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:06 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.895, logit=21.375)', '\" The\"[578] (p=0.065, logit=18.750)', '\" Clar\"[31181] (p=0.007, logit=16.500)', '\" violin\"[63137] (p=0.003, logit=15.812)', '\" It\"[1102] (p=0.003, logit=15.812)']\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.770, logit=19.500)', '\" The\"[578] (p=0.081, logit=17.250)', '\" Har\"[5340] (p=0.049, logit=16.750)', '\" Trump\"[3420] (p=0.011, logit=15.250)', '\" There\"[2684] (p=0.007, logit=14.812)']\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.76953125, logit=19.5, token_id=8219, metadata=None))), (5340, (3, PredictedToken(token=' Har', prob=0.049072265625, logit=16.75, token_id=5340, metadata=None))), (3420, (4, PredictedToken(token=' Trump', prob=0.010986328125, logit=15.25, token_id=3420, metadata=None))), (16344, (13, PredictedToken(token=' Rose', prob=0.0023040771484375, logit=13.6875, token_id=16344, metadata=None)))])\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.840, logit=19.875)', '\" The\"[578] (p=0.061, logit=17.250)', '\" HAR\"[87588] (p=0.012, logit=15.625)', '\" har\"[4960] (p=0.009, logit=15.375)', '\" There\"[2684] (p=0.007, logit=15.125)']\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.83984375, logit=19.875, token_id=5340, metadata=None))), (8219, (6, PredictedToken(token=' Sun', prob=0.00726318359375, logit=15.125, token_id=8219, metadata=None))), (3420, (7, PredictedToken(token=' Trump', prob=0.0050048828125, logit=14.75, token_id=3420, metadata=None))), (16344, (13, PredictedToken(token=' Rose', prob=0.0022125244140625, logit=13.9375, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:06 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:41:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.734, logit=21.000)', '\" The\"[578] (p=0.113, logit=19.125)', '\" Air\"[6690] (p=0.047, logit=18.250)', '\" A\"[362] (p=0.042, logit=18.125)', '\" FOOD\"[88227] (p=0.022, logit=17.500)']\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.750, logit=19.875)', '\" The\"[578] (p=0.130, logit=18.125)', '\" A\"[362] (p=0.048, logit=17.125)', '\" Shirt\"[55807] (p=0.007, logit=15.250)', '\" SK\"[12343] (p=0.007, logit=15.188)']\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.75, logit=19.875, token_id=4923, metadata=None))), (67553, (10, PredictedToken(token=' Pants', prob=0.0027008056640625, logit=14.25, token_id=67553, metadata=None))), (39247, (34, PredictedToken(token=' Slow', prob=0.0003223419189453125, logit=12.125, token_id=39247, metadata=None))), (30616, (79, PredictedToken(token=' Rice', prob=9.822845458984375e-05, logit=10.9375, token_id=30616, metadata=None))), (39794, (151, PredictedToken(token=' Desk', prob=3.3855438232421875e-05, logit=9.875, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.613, logit=20.000)', '\" Rice\"[30616] (p=0.226, logit=19.000)', '\" The\"[578] (p=0.064, logit=17.750)', '\" A\"[362] (p=0.031, logit=17.000)', '\" slow\"[6435] (p=0.009, logit=15.750)']\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.61328125, logit=20.0, token_id=39247, metadata=None))), (30616, (2, PredictedToken(token=' Rice', prob=0.2255859375, logit=19.0, token_id=30616, metadata=None))), (67553, (9, PredictedToken(token=' Pants', prob=0.0034332275390625, logit=14.8125, token_id=67553, metadata=None))), (4923, (28, PredictedToken(token=' Sk', prob=0.0004100799560546875, logit=12.6875, token_id=4923, metadata=None))), (39794, (89, PredictedToken(token=' Desk', prob=6.67572021484375e-05, logit=10.875, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:07 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:41:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:08 src.selection.optimization INFO     patch_prediction=['\" Oak\"[18787] (p=0.598, logit=18.750)', '\" Pine\"[42609] (p=0.092, logit=16.875)', '\" Ank\"[57915] (p=0.055, logit=16.375)', '\" Orange\"[22725] (p=0.055, logit=16.375)', '\" The\"[578] (p=0.049, logit=16.250)']\n",
      "2025-09-15 09:41:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:08 src.selection.optimization INFO     clean_prediction=['\" Ki\"[30558] (p=0.605, logit=19.000)', '\" The\"[578] (p=0.173, logit=17.750)', '\" Ash\"[14937] (p=0.105, logit=17.250)', '\" AS\"[5871] (p=0.011, logit=15.000)', '\" Fruit\"[44187] (p=0.008, logit=14.625)']\n",
      "2025-09-15 09:41:08 src.selection.optimization INFO     clean_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.60546875, logit=19.0, token_id=30558, metadata=None))), (14937, (3, PredictedToken(token=' Ash', prob=0.10498046875, logit=17.25, token_id=14937, metadata=None))), (48665, (13, PredictedToken(token=' Raspberry', prob=0.003173828125, logit=13.75, token_id=48665, metadata=None))), (469, (18, PredictedToken(token=' E', prob=0.00140380859375, logit=12.9375, token_id=469, metadata=None))), (6031, (148, PredictedToken(token=' Bro', prob=5.817413330078125e-05, logit=9.75, token_id=6031, metadata=None)))])\n",
      "2025-09-15 09:41:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     int_prediction=['\" Ash\"[14937] (p=0.641, logit=19.375)', '\" The\"[578] (p=0.208, logit=18.250)', '\" AS\"[5871] (p=0.028, logit=16.250)', '\" Ki\"[30558] (p=0.021, logit=15.938)', '\" There\"[2684] (p=0.009, logit=15.125)']\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     int_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.640625, logit=19.375, token_id=14937, metadata=None))), (30558, (4, PredictedToken(token=' Ki', prob=0.0206298828125, logit=15.9375, token_id=30558, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.0048828125, logit=14.5, token_id=6031, metadata=None))), (469, (10, PredictedToken(token=' E', prob=0.003570556640625, logit=14.1875, token_id=469, metadata=None))), (48665, (17, PredictedToken(token=' Raspberry', prob=0.002044677734375, logit=13.625, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:09 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:09 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.602, logit=19.750)', '\" Y\"[816] (p=0.134, logit=18.250)', '\" The\"[578] (p=0.104, logit=18.000)', '\" There\"[2684] (p=0.030, logit=16.750)', '\" A\"[362] (p=0.030, logit=16.750)']\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.836, logit=20.875)', '\" The\"[578] (p=0.100, logit=18.750)', '\" Guitar\"[47759] (p=0.012, logit=16.625)', '\" Accord\"[80657] (p=0.009, logit=16.375)', '\" ACC\"[26925] (p=0.008, logit=16.250)']\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.8359375, logit=20.875, token_id=11683, metadata=None))), (47759, (3, PredictedToken(token=' Guitar', prob=0.01190185546875, logit=16.625, token_id=47759, metadata=None))), (6914, (14, PredictedToken(token=' Let', prob=0.000919342041015625, logit=14.0625, token_id=6914, metadata=None))), (3341, (110, PredictedToken(token=' Car', prob=3.147125244140625e-05, logit=10.6875, token_id=3341, metadata=None))), (57551, (127, PredictedToken(token=' Sink', prob=2.300739288330078e-05, logit=10.375, token_id=57551, metadata=None))), (45332, (180, PredictedToken(token=' Boat', prob=1.3947486877441406e-05, logit=9.875, token_id=45332, metadata=None)))])\n",
      "2025-09-15 09:41:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:10 src.selection.optimization INFO     int_prediction=['\" Boat\"[45332] (p=0.551, logit=20.000)', '\" Car\"[3341] (p=0.229, logit=19.125)', '\" The\"[578] (p=0.074, logit=18.000)', '\" BO\"[7967] (p=0.065, logit=17.875)', '\" A\"[362] (p=0.010, logit=16.000)']\n",
      "2025-09-15 09:41:10 src.selection.optimization INFO     int_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.55078125, logit=20.0, token_id=45332, metadata=None))), (3341, (2, PredictedToken(token=' Car', prob=0.228515625, logit=19.125, token_id=3341, metadata=None))), (47759, (7, PredictedToken(token=' Guitar', prob=0.006927490234375, logit=15.625, token_id=47759, metadata=None))), (57551, (8, PredictedToken(token=' Sink', prob=0.00445556640625, logit=15.1875, token_id=57551, metadata=None))), (6914, (27, PredictedToken(token=' Let', prob=0.0005340576171875, logit=13.0625, token_id=6914, metadata=None))), (11683, (65, PredictedToken(token=' Acc', prob=0.00011157989501953125, logit=11.5, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:10 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:10 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:41:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:10 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.781, logit=20.125)', '\" The\"[578] (p=0.073, logit=17.750)', '\" Cedar\"[57748] (p=0.057, logit=17.500)', '\" Pine\"[42609] (p=0.014, logit=16.125)', '\" There\"[2684] (p=0.012, logit=15.938)']\n",
      "2025-09-15 09:41:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     clean_prediction=['\" Chair\"[16478] (p=0.531, logit=19.000)', '\" Ottoman\"[70110] (p=0.222, logit=18.125)', '\" The\"[578] (p=0.082, logit=17.125)', '\" CH\"[6969] (p=0.034, logit=16.250)', '\" A\"[362] (p=0.012, logit=15.188)']\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     clean_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.53125, logit=19.0, token_id=16478, metadata=None))), (70110, (2, PredictedToken(token=' Ottoman', prob=0.2216796875, logit=18.125, token_id=70110, metadata=None))), (3816, (8, PredictedToken(token=' Red', prob=0.00592041015625, logit=14.5, token_id=3816, metadata=None))), (98028, (103, PredictedToken(token=' Bamboo', prob=0.00015735626220703125, logit=10.875, token_id=98028, metadata=None))), (43950, (127, PredictedToken(token=' Lav', prob=0.00010824203491210938, logit=10.5, token_id=43950, metadata=None))), (22050, (199, PredictedToken(token=' Hat', prob=3.981590270996094e-05, logit=9.5, token_id=22050, metadata=None))), (18343, (337, PredictedToken(token=' Paper', prob=1.7642974853515625e-05, logit=8.6875, token_id=18343, metadata=None)))])\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     int_prediction=['\" Red\"[3816] (p=0.443, logit=18.250)', '\" Bamboo\"[98028] (p=0.237, logit=17.625)', '\" The\"[578] (p=0.077, logit=16.500)', '\" Ottoman\"[70110] (p=0.053, logit=16.125)', '\" RED\"[26895] (p=0.028, logit=15.500)']\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     int_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.443359375, logit=18.25, token_id=3816, metadata=None))), (98028, (2, PredictedToken(token=' Bamboo', prob=0.2373046875, logit=17.625, token_id=98028, metadata=None))), (70110, (4, PredictedToken(token=' Ottoman', prob=0.052978515625, logit=16.125, token_id=70110, metadata=None))), (43950, (8, PredictedToken(token=' Lav', prob=0.0111083984375, logit=14.5625, token_id=43950, metadata=None))), (18343, (27, PredictedToken(token=' Paper', prob=0.0010986328125, logit=12.25, token_id=18343, metadata=None))), (16478, (48, PredictedToken(token=' Chair', prob=0.0006256103515625, logit=11.6875, token_id=16478, metadata=None))), (22050, (94, PredictedToken(token=' Hat', prob=0.00019073486328125, logit=10.5, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:11 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:11 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     patch_prediction=['\" Sco\"[50159] (p=0.820, logit=19.750)', '\" The\"[578] (p=0.046, logit=16.875)', '\" Bike\"[38930] (p=0.028, logit=16.375)', '\" scooter\"[76140] (p=0.025, logit=16.250)', '\" Head\"[11452] (p=0.010, logit=15.375)']\n",
      "2025-09-15 09:41:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     clean_prediction=['\" Television\"[41445] (p=0.848, logit=20.500)', '\" The\"[578] (p=0.054, logit=17.750)', '\" Camera\"[14669] (p=0.012, logit=16.250)', '\" There\"[2684] (p=0.007, logit=15.688)', '\" TV\"[6007] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     clean_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.84765625, logit=20.5, token_id=41445, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.0120849609375, logit=16.25, token_id=14669, metadata=None))), (34785, (7, PredictedToken(token=' Truck', prob=0.005706787109375, logit=15.5, token_id=34785, metadata=None))), (60413, (8, PredictedToken(token=' Uk', prob=0.004730224609375, logit=15.3125, token_id=60413, metadata=None))), (70762, (13, PredictedToken(token=' Motorcycle', prob=0.00238037109375, logit=14.625, token_id=70762, metadata=None)))])\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.322, logit=18.500)', '\" Truck\"[34785] (p=0.285, logit=18.375)', '\" Camera\"[14669] (p=0.135, logit=17.625)', '\" The\"[578] (p=0.082, logit=17.125)', '\" TR\"[5091] (p=0.022, logit=15.812)']\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.322265625, logit=18.5, token_id=70762, metadata=None))), (34785, (2, PredictedToken(token=' Truck', prob=0.28515625, logit=18.375, token_id=34785, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.134765625, logit=17.625, token_id=14669, metadata=None))), (41445, (7, PredictedToken(token=' Television', prob=0.0159912109375, logit=15.5, token_id=41445, metadata=None))), (60413, (20, PredictedToken(token=' Uk', prob=0.00191497802734375, logit=13.375, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:12 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:12 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     patch_prediction=['\" Laptop\"[57225] (p=0.809, logit=19.875)', '\" The\"[578] (p=0.097, logit=17.750)', '\" Printer\"[47033] (p=0.014, logit=15.812)', '\" It\"[1102] (p=0.010, logit=15.438)', '\" A\"[362] (p=0.006, logit=14.938)']\n",
      "2025-09-15 09:41:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.781, logit=20.375)', '\" The\"[578] (p=0.120, logit=18.500)', '\" Jacket\"[55870] (p=0.018, logit=16.625)', '\" SH\"[6570] (p=0.018, logit=16.625)', '\" A\"[362] (p=0.016, logit=16.500)']\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.78125, logit=20.375, token_id=55807, metadata=None))), (55870, (4, PredictedToken(token=' Jacket', prob=0.018310546875, logit=16.625, token_id=55870, metadata=None))), (24423, (14, PredictedToken(token=' Monitor', prob=0.00103759765625, logit=13.75, token_id=24423, metadata=None))), (41445, (143, PredictedToken(token=' Television', prob=2.9325485229492188e-05, logit=10.1875, token_id=41445, metadata=None)))])\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.742, logit=20.250)', '\" Television\"[41445] (p=0.100, logit=18.250)', '\" The\"[578] (p=0.069, logit=17.875)', '\" MON\"[29637] (p=0.017, logit=16.500)', '\" None\"[2290] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.7421875, logit=20.25, token_id=24423, metadata=None))), (41445, (2, PredictedToken(token=' Television', prob=0.10009765625, logit=18.25, token_id=41445, metadata=None))), (55870, (6, PredictedToken(token=' Jacket', prob=0.0087890625, logit=15.8125, token_id=55870, metadata=None))), (55807, (7, PredictedToken(token=' Shirt', prob=0.00531005859375, logit=15.3125, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:13 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:13 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.824, logit=19.375)', '\" The\"[578] (p=0.077, logit=17.000)', '\" Bed\"[13394] (p=0.019, logit=15.625)', '\" A\"[362] (p=0.009, logit=14.875)', '\" W\"[468] (p=0.007, logit=14.562)']\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.789, logit=20.125)', '\" Scar\"[30760] (p=0.107, logit=18.125)', '\" The\"[578] (p=0.031, logit=16.875)', '\" socks\"[40086] (p=0.009, logit=15.625)', '\" SOCK\"[35651] (p=0.009, logit=15.625)']\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.7890625, logit=20.125, token_id=328, metadata=None))), (30760, (2, PredictedToken(token=' Scar', prob=0.10693359375, logit=18.125, token_id=30760, metadata=None))), (16478, (44, PredictedToken(token=' Chair', prob=0.00020599365234375, logit=11.875, token_id=16478, metadata=None))), (34046, (248, PredictedToken(token=' Cabinet', prob=1.4066696166992188e-05, logit=9.1875, token_id=34046, metadata=None)))])\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.703, logit=19.375)', '\" Scar\"[30760] (p=0.084, logit=17.250)', '\" The\"[578] (p=0.051, logit=16.750)', '\" None\"[2290] (p=0.031, logit=16.250)', '\" S\"[328] (p=0.018, logit=15.688)']\n",
      "2025-09-15 09:41:13 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.703125, logit=19.375, token_id=16478, metadata=None))), (30760, (2, PredictedToken(token=' Scar', prob=0.083984375, logit=17.25, token_id=30760, metadata=None))), (328, (5, PredictedToken(token=' S', prob=0.0177001953125, logit=15.6875, token_id=328, metadata=None))), (34046, (10, PredictedToken(token=' Cabinet', prob=0.006500244140625, logit=14.6875, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:14 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     patch_prediction=['\" Printer\"[47033] (p=0.746, logit=19.625)', '\" Tablet\"[58403] (p=0.114, logit=17.750)', '\" The\"[578] (p=0.048, logit=16.875)', '\" Iris\"[66821] (p=0.011, logit=15.438)', '\" TABLE\"[14700] (p=0.009, logit=15.188)']\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     clean_prediction=['\" Ch\"[921] (p=0.773, logit=20.000)', '\" The\"[578] (p=0.092, logit=17.875)', '\" Rose\"[16344] (p=0.044, logit=17.125)', '\" There\"[2684] (p=0.010, logit=15.688)', '\" Mum\"[67937] (p=0.009, logit=15.562)']\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     clean_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.7734375, logit=20.0, token_id=921, metadata=None))), (16344, (3, PredictedToken(token=' Rose', prob=0.043701171875, logit=17.125, token_id=16344, metadata=None))), (426, (10, PredictedToken(token=' B', prob=0.0031585693359375, logit=14.5, token_id=426, metadata=None))), (18191, (39, PredictedToken(token=' Mouse', prob=0.0004558563232421875, logit=12.5625, token_id=18191, metadata=None))), (30173, (656, PredictedToken(token=' Speaker', prob=2.7865171432495117e-06, logit=7.46875, token_id=30173, metadata=None)))])\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.785, logit=19.875)', '\" The\"[578] (p=0.050, logit=17.125)', '\" Mouse\"[18191] (p=0.039, logit=16.875)', '\" There\"[2684] (p=0.018, logit=16.125)', '\" SPE\"[68835] (p=0.013, logit=15.750)']\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.78515625, logit=19.875, token_id=30173, metadata=None))), (18191, (3, PredictedToken(token=' Mouse', prob=0.0390625, logit=16.875, token_id=18191, metadata=None))), (426, (9, PredictedToken(token=' B', prob=0.005645751953125, logit=14.9375, token_id=426, metadata=None))), (16344, (14, PredictedToken(token=' Rose', prob=0.002349853515625, logit=14.0625, token_id=16344, metadata=None))), (921, (78, PredictedToken(token=' Ch', prob=9.107589721679688e-05, logit=10.8125, token_id=921, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     patch_prediction=['\" Basketball\"[47589] (p=0.898, logit=21.625)', '\" The\"[578] (p=0.057, logit=18.875)', '\" A\"[362] (p=0.016, logit=17.625)', '\" It\"[1102] (p=0.002, logit=15.688)', '\" #\"[674] (p=0.002, logit=15.562)']\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.562, logit=19.750)', '\" Cat\"[17810] (p=0.266, logit=19.000)', '\" The\"[578] (p=0.046, logit=17.250)', '\" C\"[356] (p=0.032, logit=16.875)', '\" CAT\"[45081] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.5625, logit=19.75, token_id=22607, metadata=None))), (17810, (2, PredictedToken(token=' Cat', prob=0.265625, logit=19.0, token_id=17810, metadata=None))), (423, (9, PredictedToken(token=' D', prob=0.00518798828125, logit=15.0625, token_id=423, metadata=None))), (21424, (23, PredictedToken(token=' Football', prob=0.00084686279296875, logit=13.25, token_id=21424, metadata=None))), (57094, (165, PredictedToken(token=' Highlight', prob=3.075599670410156e-05, logit=9.9375, token_id=57094, metadata=None)))])\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     int_prediction=['\" Football\"[21424] (p=0.516, logit=19.500)', '\" D\"[423] (p=0.244, logit=18.750)', '\" Highlight\"[57094] (p=0.054, logit=17.250)', '\" Cow\"[22607] (p=0.037, logit=16.875)', '\" The\"[578] (p=0.037, logit=16.875)']\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     int_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.515625, logit=19.5, token_id=21424, metadata=None))), (423, (2, PredictedToken(token=' D', prob=0.244140625, logit=18.75, token_id=423, metadata=None))), (57094, (3, PredictedToken(token=' Highlight', prob=0.054443359375, logit=17.25, token_id=57094, metadata=None))), (22607, (5, PredictedToken(token=' Cow', prob=0.037353515625, logit=16.875, token_id=22607, metadata=None))), (17810, (7, PredictedToken(token=' Cat', prob=0.00946044921875, logit=15.5, token_id=17810, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:15 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     patch_prediction=['\" Bus\"[19111] (p=0.688, logit=20.250)', '\" The\"[578] (p=0.174, logit=18.875)', '\" Air\"[6690] (p=0.044, logit=17.500)', '\" An\"[1556] (p=0.014, logit=16.375)', '\" A\"[362] (p=0.014, logit=16.375)']\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.605, logit=19.750)', '\" The\"[578] (p=0.252, logit=18.875)', '\" Harmon\"[40759] (p=0.034, logit=16.875)', '\" A\"[362] (p=0.018, logit=16.250)', '\" uk\"[15012] (p=0.010, logit=15.688)']\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.60546875, logit=19.75, token_id=60413, metadata=None))), (40759, (3, PredictedToken(token=' Harmon', prob=0.0341796875, logit=16.875, token_id=40759, metadata=None))), (50159, (49, PredictedToken(token=' Sco', prob=0.00022983551025390625, logit=11.875, token_id=50159, metadata=None))), (63606, (54, PredictedToken(token=' Stap', prob=0.000179290771484375, logit=11.625, token_id=63606, metadata=None))), (38930, (126, PredictedToken(token=' Bike', prob=4.5299530029296875e-05, logit=10.25, token_id=38930, metadata=None)))])\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.562, logit=18.875)', '\" The\"[578] (p=0.161, logit=17.625)', '\" Bike\"[38930] (p=0.086, logit=17.000)', '\" Stap\"[63606] (p=0.046, logit=16.375)', '\" A\"[362] (p=0.036, logit=16.125)']\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.5625, logit=18.875, token_id=50159, metadata=None))), (38930, (3, PredictedToken(token=' Bike', prob=0.0859375, logit=17.0, token_id=38930, metadata=None))), (63606, (4, PredictedToken(token=' Stap', prob=0.046142578125, logit=16.375, token_id=63606, metadata=None))), (40759, (12, PredictedToken(token=' Harmon', prob=0.004302978515625, logit=14.0, token_id=40759, metadata=None))), (60413, (195, PredictedToken(token=' Uk', prob=3.4809112548828125e-05, logit=9.1875, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:16 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:41:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     patch_prediction=['\" Bench\"[36358] (p=0.594, logit=20.625)', '\" The\"[578] (p=0.170, logit=19.375)', '\" Book\"[6017] (p=0.150, logit=19.250)', '\" A\"[362] (p=0.030, logit=17.625)', '\" It\"[1102] (p=0.010, logit=16.500)']\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     clean_prediction=['\" Marker\"[40975] (p=0.664, logit=20.750)', '\" P\"[393] (p=0.147, logit=19.250)', '\" The\"[578] (p=0.090, logit=18.750)', '\" There\"[2684] (p=0.018, logit=17.125)', '\" None\"[2290] (p=0.016, logit=17.000)']\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     clean_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.6640625, logit=20.75, token_id=40975, metadata=None))), (393, (2, PredictedToken(token=' P', prob=0.1474609375, logit=19.25, token_id=393, metadata=None))), (16478, (44, PredictedToken(token=' Chair', prob=0.00023651123046875, logit=12.8125, token_id=16478, metadata=None))), (22050, (45, PredictedToken(token=' Hat', prob=0.00023651123046875, logit=12.8125, token_id=22050, metadata=None))), (34392, (63, PredictedToken(token=' Horse', prob=0.00013446807861328125, logit=12.25, token_id=34392, metadata=None))), (29318, (507, PredictedToken(token=' Dress', prob=3.591179847717285e-06, logit=8.625, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.848, logit=21.125)', '\" The\"[578] (p=0.062, logit=18.500)', '\" There\"[2684] (p=0.014, logit=17.000)', '\" Hat\"[22050] (p=0.012, logit=16.875)', '\" None\"[2290] (p=0.009, logit=16.625)']\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.84765625, logit=21.125, token_id=29318, metadata=None))), (22050, (4, PredictedToken(token=' Hat', prob=0.01214599609375, logit=16.875, token_id=22050, metadata=None))), (16478, (6, PredictedToken(token=' Chair', prob=0.00946044921875, logit=16.625, token_id=16478, metadata=None))), (393, (8, PredictedToken(token=' P', prob=0.004180908203125, logit=15.8125, token_id=393, metadata=None))), (40975, (9, PredictedToken(token=' Marker', prob=0.003265380859375, logit=15.5625, token_id=40975, metadata=None))), (34392, (12, PredictedToken(token=' Horse', prob=0.00119781494140625, logit=14.5625, token_id=34392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:17 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:17 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:41:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.586, logit=18.125)', '\" Cow\"[22607] (p=0.080, logit=16.125)', '\" None\"[2290] (p=0.048, logit=15.625)', '\" SHE\"[54695] (p=0.045, logit=15.562)', '\" The\"[578] (p=0.045, logit=15.562)']\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     clean_prediction=['\" Stap\"[63606] (p=0.848, logit=19.500)', '\" The\"[578] (p=0.033, logit=16.250)', '\" ST\"[4015] (p=0.020, logit=15.750)', '\" Eagle\"[36895] (p=0.011, logit=15.188)', '\" A\"[362] (p=0.011, logit=15.125)']\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     clean_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.84765625, logit=19.5, token_id=63606, metadata=None))), (36895, (4, PredictedToken(token=' Eagle', prob=0.0113525390625, logit=15.1875, token_id=36895, metadata=None))), (96096, (7, PredictedToken(token=' Dolphin', prob=0.00885009765625, logit=14.9375, token_id=96096, metadata=None))), (432, (10, PredictedToken(token=' R', prob=0.0034637451171875, logit=14.0, token_id=432, metadata=None)))])\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.840, logit=19.500)', '\" Stap\"[63606] (p=0.029, logit=16.125)', '\" The\"[578] (p=0.024, logit=15.938)', '\" R\"[432] (p=0.020, logit=15.750)', '\" None\"[2290] (p=0.016, logit=15.562)']\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.83984375, logit=19.5, token_id=96096, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.0286865234375, logit=16.125, token_id=63606, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.019775390625, logit=15.75, token_id=432, metadata=None))), (36895, (6, PredictedToken(token=' Eagle', prob=0.00933837890625, logit=15.0, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:18 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     patch_prediction=['\" Jasmine\"[82452] (p=0.715, logit=20.500)', '\" Lav\"[43950] (p=0.097, logit=18.500)', '\" The\"[578] (p=0.097, logit=18.500)', '\" There\"[2684] (p=0.024, logit=17.125)', '\" J\"[622] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.844, logit=20.625)', '\" The\"[578] (p=0.061, logit=18.000)', '\" Monkey\"[58937] (p=0.029, logit=17.250)', '\" HOR\"[84666] (p=0.014, logit=16.500)', '\" There\"[2684] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.84375, logit=20.625, token_id=34392, metadata=None))), (58937, (3, PredictedToken(token=' Monkey', prob=0.02880859375, logit=17.25, token_id=58937, metadata=None))), (39247, (6, PredictedToken(token=' Slow', prob=0.0050048828125, logit=15.5, token_id=39247, metadata=None))), (55405, (52, PredictedToken(token=' Orch', prob=0.000125885009765625, logit=11.8125, token_id=55405, metadata=None))), (48390, (100, PredictedToken(token=' Lily', prob=4.9114227294921875e-05, logit=10.875, token_id=48390, metadata=None)))])\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     int_prediction=['\" Orch\"[55405] (p=0.570, logit=19.000)', '\" Lily\"[48390] (p=0.163, logit=17.750)', '\" The\"[578] (p=0.112, logit=17.375)', '\" OR\"[2794] (p=0.021, logit=15.688)', '\" L\"[445] (p=0.021, logit=15.688)']\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     int_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.5703125, logit=19.0, token_id=55405, metadata=None))), (48390, (2, PredictedToken(token=' Lily', prob=0.1630859375, logit=17.75, token_id=48390, metadata=None))), (58937, (9, PredictedToken(token=' Monkey', prob=0.0052490234375, logit=14.3125, token_id=58937, metadata=None))), (39247, (10, PredictedToken(token=' Slow', prob=0.00494384765625, logit=14.25, token_id=39247, metadata=None))), (34392, (13, PredictedToken(token=' Horse', prob=0.0031890869140625, logit=13.8125, token_id=34392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:19 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     patch_prediction=['\" Ti\"[23126] (p=0.459, logit=19.000)', '\" Ank\"[57915] (p=0.314, logit=18.625)', '\" The\"[578] (p=0.070, logit=17.125)', '\" An\"[1556] (p=0.021, logit=15.938)', '\" TI\"[39237] (p=0.017, logit=15.688)']\n",
      "2025-09-15 09:41:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.668, logit=18.875)', '\" The\"[578] (p=0.169, logit=17.500)', '\" Ski\"[61595] (p=0.043, logit=16.125)', '\" R\"[432] (p=0.010, logit=14.688)', '\" sk\"[1940] (p=0.010, logit=14.625)']\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.66796875, logit=18.875, token_id=4923, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.0101318359375, logit=14.6875, token_id=432, metadata=None))), (22249, (8, PredictedToken(token=' Ring', prob=0.0069580078125, logit=14.3125, token_id=22249, metadata=None))), (58600, (136, PredictedToken(token=' Charm', prob=5.650520324707031e-05, logit=9.5, token_id=58600, metadata=None)))])\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.730, logit=19.625)', '\" The\"[578] (p=0.099, logit=17.625)', '\" R\"[432] (p=0.077, logit=17.375)', '\" A\"[362] (p=0.014, logit=15.688)', '\" None\"[2290] (p=0.009, logit=15.250)']\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.73046875, logit=19.625, token_id=22249, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.0771484375, logit=17.375, token_id=432, metadata=None))), (58600, (6, PredictedToken(token=' Charm', prob=0.00921630859375, logit=15.25, token_id=58600, metadata=None))), (4923, (7, PredictedToken(token=' Sk', prob=0.0086669921875, logit=15.1875, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:20 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:20 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     patch_prediction=['\" Cedar\"[57748] (p=0.488, logit=18.500)', '\" Birch\"[88088] (p=0.158, logit=17.375)', '\" The\"[578] (p=0.096, logit=16.875)', '\" There\"[2684] (p=0.045, logit=16.125)', '\" None\"[2290] (p=0.040, logit=16.000)']\n",
      "2025-09-15 09:41:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.738, logit=20.500)', '\" Temple\"[19176] (p=0.100, logit=18.500)', '\" The\"[578] (p=0.053, logit=17.875)', '\" CH\"[6969] (p=0.042, logit=17.625)', '\" A\"[362] (p=0.013, logit=16.500)']\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.73828125, logit=20.5, token_id=9441, metadata=None))), (19176, (2, PredictedToken(token=' Temple', prob=0.10009765625, logit=18.5, token_id=19176, metadata=None))), (16488, (9, PredictedToken(token=' Bat', prob=0.003875732421875, logit=15.25, token_id=16488, metadata=None))), (79028, (11, PredictedToken(token=' Hick', prob=0.00250244140625, logit=14.8125, token_id=79028, metadata=None))), (65329, (13, PredictedToken(token=' Elm', prob=0.002349853515625, logit=14.75, token_id=65329, metadata=None))), (55807, (14, PredictedToken(token=' Shirt', prob=0.0018310546875, logit=14.5, token_id=55807, metadata=None)))])\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.467, logit=19.000)', '\" Elm\"[65329] (p=0.320, logit=18.625)', '\" The\"[578] (p=0.043, logit=16.625)', '\" Temple\"[19176] (p=0.034, logit=16.375)', '\" None\"[2290] (p=0.014, logit=15.500)']\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.466796875, logit=19.0, token_id=79028, metadata=None))), (65329, (2, PredictedToken(token=' Elm', prob=0.3203125, logit=18.625, token_id=65329, metadata=None))), (19176, (4, PredictedToken(token=' Temple', prob=0.03369140625, logit=16.375, token_id=19176, metadata=None))), (16488, (7, PredictedToken(token=' Bat', prob=0.01165771484375, logit=15.3125, token_id=16488, metadata=None))), (9441, (12, PredictedToken(token=' Church', prob=0.00518798828125, logit=14.5, token_id=9441, metadata=None))), (55807, (33, PredictedToken(token=' Shirt', prob=0.0004253387451171875, logit=12.0, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:21 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     patch_prediction=['\" Rose\"[16344] (p=0.699, logit=20.125)', '\" The\"[578] (p=0.138, logit=18.500)', '\" Jasmine\"[82452] (p=0.057, logit=17.625)', '\" There\"[2684] (p=0.024, logit=16.750)', '\" RO\"[12076] (p=0.015, logit=16.250)']\n",
      "2025-09-15 09:41:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     clean_prediction=['\" Rice\"[30616] (p=0.820, logit=21.125)', '\" The\"[578] (p=0.077, logit=18.750)', '\" Slow\"[39247] (p=0.052, logit=18.375)', '\" A\"[362] (p=0.013, logit=17.000)', '\" None\"[2290] (p=0.006, logit=16.125)']\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     clean_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.8203125, logit=21.125, token_id=30616, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.052490234375, logit=18.375, token_id=39247, metadata=None))), (43950, (10, PredictedToken(token=' Lav', prob=0.0010223388671875, logit=14.4375, token_id=43950, metadata=None))), (48035, (72, PredictedToken(token=' Gir', prob=5.1021575927734375e-05, logit=11.4375, token_id=48035, metadata=None))), (48390, (84, PredictedToken(token=' Lily', prob=3.981590270996094e-05, logit=11.1875, token_id=48390, metadata=None)))])\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     int_prediction=['\" Lily\"[48390] (p=0.387, logit=19.125)', '\" Lav\"[43950] (p=0.303, logit=18.875)', '\" The\"[578] (p=0.184, logit=18.375)', '\" Gir\"[48035] (p=0.019, logit=16.125)', '\" There\"[2684] (p=0.012, logit=15.625)']\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     int_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.38671875, logit=19.125, token_id=48390, metadata=None))), (43950, (2, PredictedToken(token=' Lav', prob=0.302734375, logit=18.875, token_id=43950, metadata=None))), (48035, (4, PredictedToken(token=' Gir', prob=0.019287109375, logit=16.125, token_id=48035, metadata=None))), (39247, (25, PredictedToken(token=' Slow', prob=0.000797271728515625, logit=12.9375, token_id=39247, metadata=None))), (30616, (318, PredictedToken(token=' Rice', prob=1.2099742889404297e-05, logit=8.75, token_id=30616, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:22 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:22 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.867, logit=21.375)', '\" The\"[578] (p=0.081, logit=19.000)', '\" Let\"[6914] (p=0.010, logit=16.875)', '\" There\"[2684] (p=0.008, logit=16.750)', '\" Pine\"[42609] (p=0.004, logit=15.875)']\n",
      "2025-09-15 09:41:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.809, logit=20.500)', '\" The\"[578] (p=0.097, logit=18.375)', '\" M\"[386] (p=0.022, logit=16.875)', '\" Banana\"[76924] (p=0.007, logit=15.812)', '\" There\"[2684] (p=0.007, logit=15.812)']\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.80859375, logit=20.5, token_id=91963, metadata=None))), (76924, (5, PredictedToken(token=' Banana', prob=0.0074462890625, logit=15.8125, token_id=76924, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.00311279296875, logit=14.9375, token_id=356, metadata=None))), (87035, (11, PredictedToken(token=' Onion', prob=0.00201416015625, logit=14.5, token_id=87035, metadata=None))), (6150, (25, PredictedToken(token=' School', prob=0.000652313232421875, logit=13.375, token_id=6150, metadata=None))), (1901, (40, PredictedToken(token=' Z', prob=0.0003070831298828125, logit=12.625, token_id=1901, metadata=None))), (91263, (277, PredictedToken(token=' Binder', prob=1.1920928955078125e-05, logit=9.375, token_id=91263, metadata=None)))])\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.789, logit=20.500)', '\" The\"[578] (p=0.094, logit=18.375)', '\" ON\"[6328] (p=0.014, logit=16.500)', '\" School\"[6150] (p=0.014, logit=16.500)', '\" An\"[1556] (p=0.014, logit=16.500)']\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.7890625, logit=20.5, token_id=87035, metadata=None))), (6150, (4, PredictedToken(token=' School', prob=0.014404296875, logit=16.5, token_id=6150, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.007720947265625, logit=15.875, token_id=356, metadata=None))), (76924, (8, PredictedToken(token=' Banana', prob=0.006805419921875, logit=15.75, token_id=76924, metadata=None))), (91263, (9, PredictedToken(token=' Binder', prob=0.00640869140625, logit=15.6875, token_id=91263, metadata=None))), (91963, (18, PredictedToken(token=' Mango', prob=0.00104522705078125, logit=13.875, token_id=91963, metadata=None))), (1901, (27, PredictedToken(token=' Z', prob=0.00052642822265625, logit=13.1875, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:23 src.selection.optimization DEBUG    torch.Size([6, 36])\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.551, logit=20.250)', '\" Sink\"[57551] (p=0.334, logit=19.750)', '\" The\"[578] (p=0.040, logit=17.625)', '\" TO\"[5257] (p=0.017, logit=16.750)', '\" A\"[362] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:41:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     clean_prediction=['\" Mar\"[2947] (p=0.766, logit=20.000)', '\" The\"[578] (p=0.104, logit=18.000)', '\" MAR\"[38599] (p=0.055, logit=17.375)', '\" A\"[362] (p=0.012, logit=15.875)', '\" mar\"[3678] (p=0.010, logit=15.688)']\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     clean_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.765625, logit=20.0, token_id=2947, metadata=None))), (445, (14, PredictedToken(token=' L', prob=0.0014801025390625, logit=13.75, token_id=445, metadata=None))), (5250, (19, PredictedToken(token=' Pe', prob=0.000896453857421875, logit=13.25, token_id=5250, metadata=None))), (33199, (35, PredictedToken(token=' Lion', prob=0.000423431396484375, logit=12.5, token_id=33199, metadata=None))), (34954, (204, PredictedToken(token=' Mirror', prob=1.8596649169921875e-05, logit=9.375, token_id=34954, metadata=None))), (15429, (822, PredictedToken(token=' Hospital', prob=1.9669532775878906e-06, logit=7.125, token_id=15429, metadata=None)))])\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.633, logit=18.875)', '\" The\"[578] (p=0.125, logit=17.250)', '\" Lion\"[33199] (p=0.040, logit=16.125)', '\" LOT\"[54460] (p=0.036, logit=16.000)', '\" Hospital\"[15429] (p=0.023, logit=15.562)']\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.6328125, logit=18.875, token_id=445, metadata=None))), (33199, (3, PredictedToken(token=' Lion', prob=0.040283203125, logit=16.125, token_id=33199, metadata=None))), (15429, (5, PredictedToken(token=' Hospital', prob=0.02294921875, logit=15.5625, token_id=15429, metadata=None))), (34954, (6, PredictedToken(token=' Mirror', prob=0.0157470703125, logit=15.1875, token_id=34954, metadata=None))), (5250, (10, PredictedToken(token=' Pe', prob=0.00701904296875, logit=14.375, token_id=5250, metadata=None))), (2947, (34, PredictedToken(token=' Mar', prob=0.000576019287109375, logit=11.875, token_id=2947, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:24 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.527, logit=18.875)', '\" Birch\"[88088] (p=0.221, logit=18.000)', '\" The\"[578] (p=0.104, logit=17.250)', '\" There\"[2684] (p=0.013, logit=15.188)', '\" Sun\"[8219] (p=0.010, logit=14.938)']\n",
      "2025-09-15 09:41:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.574, logit=19.875)', '\" C\"[356] (p=0.271, logit=19.125)', '\" The\"[578] (p=0.047, logit=17.375)', '\" There\"[2684] (p=0.029, logit=16.875)', '\" None\"[2290] (p=0.011, logit=15.938)']\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.57421875, logit=19.875, token_id=3341, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.271484375, logit=19.125, token_id=356, metadata=None))), (32749, (8, PredictedToken(token=' Carn', prob=0.0030059814453125, logit=14.625, token_id=32749, metadata=None))), (3816, (16, PredictedToken(token=' Red', prob=0.0015106201171875, logit=13.9375, token_id=3816, metadata=None))), (66821, (23, PredictedToken(token=' Iris', prob=0.00091552734375, logit=13.4375, token_id=66821, metadata=None)))])\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.656, logit=19.625)', '\" The\"[578] (p=0.114, logit=17.875)', '\" There\"[2684] (p=0.054, logit=17.125)', '\" IR\"[16646] (p=0.042, logit=16.875)', '\" Car\"[3341] (p=0.018, logit=16.000)']\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.65625, logit=19.625, token_id=66821, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.017578125, logit=16.0, token_id=3341, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.01202392578125, logit=15.625, token_id=356, metadata=None))), (3816, (8, PredictedToken(token=' Red', prob=0.01129150390625, logit=15.5625, token_id=3816, metadata=None))), (32749, (10, PredictedToken(token=' Carn', prob=0.004730224609375, logit=14.6875, token_id=32749, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:25 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:25 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     patch_prediction=['\" Baseball\"[38258] (p=0.781, logit=20.250)', '\" The\"[578] (p=0.082, logit=18.000)', '\" Tennis\"[58251] (p=0.044, logit=17.375)', '\" A\"[362] (p=0.021, logit=16.625)', '\" BASE\"[22984] (p=0.014, logit=16.250)']\n",
      "2025-09-15 09:41:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.562, logit=20.000)', '\" The\"[578] (p=0.266, logit=19.250)', '\" Viol\"[30555] (p=0.067, logit=17.875)', '\" A\"[362] (p=0.019, logit=16.625)', '\" It\"[1102] (p=0.009, logit=15.812)']\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.5625, logit=20.0, token_id=1630, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.0673828125, logit=17.875, token_id=30555, metadata=None))), (72683, (32, PredictedToken(token=' Boxing', prob=0.00031280517578125, logit=12.5, token_id=72683, metadata=None))), (13597, (50, PredictedToken(token=' Pen', prob=0.0001773834228515625, logit=11.9375, token_id=13597, metadata=None))), (39247, (64, PredictedToken(token=' Slow', prob=0.00012969970703125, logit=11.625, token_id=39247, metadata=None))), (67629, (91, PredictedToken(token=' Helmet', prob=7.390975952148438e-05, logit=11.0625, token_id=67629, metadata=None))), (38571, (314, PredictedToken(token=' Theater', prob=6.884336471557617e-06, logit=8.6875, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     int_prediction=['\" Boxing\"[72683] (p=0.750, logit=19.875)', '\" The\"[578] (p=0.130, logit=18.125)', '\" BOX\"[53783] (p=0.016, logit=16.000)', '\" Gloves\"[68554] (p=0.013, logit=15.812)', '\" \"\"[330] (p=0.006, logit=15.062)']\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     int_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.75, logit=19.875, token_id=72683, metadata=None))), (67629, (7, PredictedToken(token=' Helmet', prob=0.0057373046875, logit=15.0, token_id=67629, metadata=None))), (30555, (8, PredictedToken(token=' Viol', prob=0.00537109375, logit=14.9375, token_id=30555, metadata=None))), (39247, (26, PredictedToken(token=' Slow', prob=0.000934600830078125, logit=13.1875, token_id=39247, metadata=None))), (13597, (37, PredictedToken(token=' Pen', prob=0.000469207763671875, logit=12.5, token_id=13597, metadata=None))), (1630, (160, PredictedToken(token=' X', prob=3.409385681152344e-05, logit=9.875, token_id=1630, metadata=None))), (38571, (385, PredictedToken(token=' Theater', prob=8.58306884765625e-06, logit=8.5, token_id=38571, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:26 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:26 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     patch_prediction=['\" Library\"[11896] (p=0.750, logit=20.250)', '\" Apartment\"[53889] (p=0.130, logit=18.500)', '\" The\"[578] (p=0.048, logit=17.500)', '\" There\"[2684] (p=0.010, logit=15.938)', '\" None\"[2290] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:41:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.711, logit=19.500)', '\" The\"[578] (p=0.096, logit=17.500)', '\" IR\"[16646] (p=0.045, logit=16.750)', '\" Lav\"[43950] (p=0.040, logit=16.625)', '\" There\"[2684] (p=0.021, logit=16.000)']\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.7109375, logit=19.5, token_id=66821, metadata=None))), (43950, (4, PredictedToken(token=' Lav', prob=0.0400390625, logit=16.625, token_id=43950, metadata=None))), (83499, (22, PredictedToken(token=' Tooth', prob=0.001007080078125, logit=12.9375, token_id=83499, metadata=None))), (4783, (26, PredictedToken(token=' House', prob=0.000736236572265625, logit=12.625, token_id=4783, metadata=None))), (40759, (30, PredictedToken(token=' Harmon', prob=0.0006103515625, logit=12.4375, token_id=40759, metadata=None))), (22249, (73, PredictedToken(token=' Ring', prob=0.00017452239990234375, logit=11.1875, token_id=22249, metadata=None))), (52466, (4528, PredictedToken(token=' Warehouse', prob=3.371387720108032e-07, logit=4.9375, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     int_prediction=['\" House\"[4783] (p=0.316, logit=18.625)', '\" Ring\"[22249] (p=0.246, logit=18.375)', '\" The\"[578] (p=0.149, logit=17.875)', '\" Warehouse\"[52466] (p=0.132, logit=17.750)', '\" There\"[2684] (p=0.026, logit=16.125)']\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     int_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.31640625, logit=18.625, token_id=4783, metadata=None))), (22249, (2, PredictedToken(token=' Ring', prob=0.24609375, logit=18.375, token_id=22249, metadata=None))), (52466, (4, PredictedToken(token=' Warehouse', prob=0.1318359375, logit=17.75, token_id=52466, metadata=None))), (83499, (12, PredictedToken(token=' Tooth', prob=0.004241943359375, logit=14.3125, token_id=83499, metadata=None))), (40759, (53, PredictedToken(token=' Harmon', prob=0.0002880096435546875, logit=11.625, token_id=40759, metadata=None))), (43950, (72, PredictedToken(token=' Lav', prob=0.00017452239990234375, logit=11.125, token_id=43950, metadata=None))), (66821, (174, PredictedToken(token=' Iris', prob=3.6716461181640625e-05, logit=9.5625, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:27 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.719, logit=20.000)', '\" Sub\"[3804] (p=0.125, logit=18.250)', '\" The\"[578] (p=0.059, logit=17.500)', '\" A\"[362] (p=0.017, logit=16.250)', '\" There\"[2684] (p=0.011, logit=15.812)']\n",
      "2025-09-15 09:41:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.738, logit=19.875)', '\" The\"[578] (p=0.128, logit=18.125)', '\" Pendant\"[81501] (p=0.032, logit=16.750)', '\" BRO\"[78687] (p=0.022, logit=16.375)', '\" A\"[362] (p=0.020, logit=16.250)']\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.73828125, logit=19.875, token_id=6031, metadata=None))), (81501, (3, PredictedToken(token=' Pendant', prob=0.032470703125, logit=16.75, token_id=81501, metadata=None))), (20918, (8, PredictedToken(token=' Magn', prob=0.003631591796875, logit=14.5625, token_id=20918, metadata=None))), (27217, (34, PredictedToken(token=' Train', prob=0.0003185272216796875, logit=12.125, token_id=27217, metadata=None))), (38930, (81, PredictedToken(token=' Bike', prob=8.535385131835938e-05, logit=10.8125, token_id=38930, metadata=None)))])\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.691, logit=19.625)', '\" Train\"[27217] (p=0.083, logit=17.500)', '\" Pendant\"[81501] (p=0.073, logit=17.375)', '\" The\"[578] (p=0.073, logit=17.375)', '\" A\"[362] (p=0.010, logit=15.438)']\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.69140625, logit=19.625, token_id=38930, metadata=None))), (27217, (2, PredictedToken(token=' Train', prob=0.08251953125, logit=17.5, token_id=27217, metadata=None))), (81501, (4, PredictedToken(token=' Pendant', prob=0.07275390625, logit=17.375, token_id=81501, metadata=None))), (20918, (14, PredictedToken(token=' Magn', prob=0.0020599365234375, logit=13.8125, token_id=20918, metadata=None))), (6031, (25, PredictedToken(token=' Bro', prob=0.00067138671875, logit=12.6875, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:28 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.770, logit=20.125)', '\" The\"[578] (p=0.118, logit=18.250)', '\" Tennis\"[58251] (p=0.026, logit=16.750)', '\" A\"[362] (p=0.018, logit=16.375)', '\" \"\"[330] (p=0.004, logit=14.875)']\n",
      "2025-09-15 09:41:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.711, logit=20.125)', '\" B\"[426] (p=0.140, logit=18.500)', '\" The\"[578] (p=0.066, logit=17.750)', '\" A\"[362] (p=0.011, logit=15.938)', '\" b\"[293] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.7109375, logit=20.125, token_id=356, metadata=None))), (426, (2, PredictedToken(token=' B', prob=0.1396484375, logit=18.5, token_id=426, metadata=None))), (11683, (9, PredictedToken(token=' Acc', prob=0.004486083984375, logit=15.0625, token_id=11683, metadata=None))), (97796, (59, PredictedToken(token=' Skate', prob=0.00014400482177734375, logit=11.625, token_id=97796, metadata=None))), (65197, (89, PredictedToken(token=' Surf', prob=7.724761962890625e-05, logit=11.0, token_id=65197, metadata=None)))])\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.422, logit=18.375)', '\" Surf\"[65197] (p=0.200, logit=17.625)', '\" The\"[578] (p=0.094, logit=16.875)', '\" SUR\"[53083] (p=0.065, logit=16.500)', '\" Acc\"[11683] (p=0.045, logit=16.125)']\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.421875, logit=18.375, token_id=97796, metadata=None))), (65197, (2, PredictedToken(token=' Surf', prob=0.2001953125, logit=17.625, token_id=65197, metadata=None))), (11683, (5, PredictedToken(token=' Acc', prob=0.044677734375, logit=16.125, token_id=11683, metadata=None))), (426, (25, PredictedToken(token=' B', prob=0.0013427734375, logit=12.625, token_id=426, metadata=None))), (356, (42, PredictedToken(token=' C', prob=0.000598907470703125, logit=11.8125, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:29 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:29 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     patch_prediction=['\" Boat\"[45332] (p=0.609, logit=20.250)', '\" Bike\"[38930] (p=0.175, logit=19.000)', '\" The\"[578] (p=0.064, logit=18.000)', '\" A\"[362] (p=0.050, logit=17.750)', '\" BO\"[7967] (p=0.021, logit=16.875)']\n",
      "2025-09-15 09:41:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.758, logit=20.375)', '\" Notebook\"[69755] (p=0.116, logit=18.500)', '\" The\"[578] (p=0.055, logit=17.750)', '\" Sh\"[1443] (p=0.010, logit=16.000)', '\" A\"[362] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.7578125, logit=20.375, token_id=58586, metadata=None))), (69755, (2, PredictedToken(token=' Notebook', prob=0.1162109375, logit=18.5, token_id=69755, metadata=None))), (1443, (4, PredictedToken(token=' Sh', prob=0.009521484375, logit=16.0, token_id=1443, metadata=None))), (3804, (23, PredictedToken(token=' Sub', prob=0.000507354736328125, logit=13.0625, token_id=3804, metadata=None))), (36895, (28, PredictedToken(token=' Eagle', prob=0.000446319580078125, logit=12.9375, token_id=36895, metadata=None))), (40090, (37, PredictedToken(token=' Pressure', prob=0.0002880096435546875, logit=12.5, token_id=40090, metadata=None))), (6690, (44, PredictedToken(token=' Air', prob=0.00021076202392578125, logit=12.1875, token_id=6690, metadata=None)))])\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.875, logit=20.500)', '\" The\"[578] (p=0.030, logit=17.125)', '\" Eagle\"[36895] (p=0.018, logit=16.625)', '\" An\"[1556] (p=0.010, logit=16.000)', '\" There\"[2684] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.875, logit=20.5, token_id=6690, metadata=None))), (36895, (3, PredictedToken(token=' Eagle', prob=0.0181884765625, logit=16.625, token_id=36895, metadata=None))), (69755, (7, PredictedToken(token=' Notebook', prob=0.005218505859375, logit=15.375, token_id=69755, metadata=None))), (3804, (12, PredictedToken(token=' Sub', prob=0.002044677734375, logit=14.4375, token_id=3804, metadata=None))), (1443, (17, PredictedToken(token=' Sh', prob=0.00131988525390625, logit=14.0, token_id=1443, metadata=None))), (58586, (19, PredictedToken(token=' Tape', prob=0.00109100341796875, logit=13.8125, token_id=58586, metadata=None))), (40090, (133, PredictedToken(token=' Pressure', prob=2.9087066650390625e-05, logit=10.1875, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:30 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     patch_prediction=['\" Binder\"[91263] (p=0.699, logit=20.250)', '\" Paper\"[18343] (p=0.121, logit=18.500)', '\" The\"[578] (p=0.065, logit=17.875)', '\" A\"[362] (p=0.035, logit=17.250)', '\" Stap\"[63606] (p=0.010, logit=16.000)']\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.871, logit=21.375)', '\" The\"[578] (p=0.081, logit=19.000)', '\" VI\"[30768] (p=0.007, logit=16.500)', '\" violin\"[63137] (p=0.004, logit=15.938)', '\" It\"[1102] (p=0.003, logit=15.688)']\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.87109375, logit=21.375, token_id=30555, metadata=None))), (393, (7, PredictedToken(token=' P', prob=0.0026092529296875, logit=15.5625, token_id=393, metadata=None))), (94467, (9, PredictedToken(token=' Trom', prob=0.00179290771484375, logit=15.1875, token_id=94467, metadata=None))), (9939, (21, PredictedToken(token=' Er', prob=0.000545501708984375, logit=14.0, token_id=9939, metadata=None))), (6690, (38, PredictedToken(token=' Air', prob=0.0001773834228515625, logit=12.875, token_id=6690, metadata=None)))])\n",
      "2025-09-15 09:41:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     int_prediction=['\" Er\"[9939] (p=0.750, logit=20.375)', '\" P\"[393] (p=0.079, logit=18.125)', '\" The\"[578] (p=0.062, logit=17.875)', '\" ER\"[27590] (p=0.033, logit=17.250)', '\" An\"[1556] (p=0.023, logit=16.875)']\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     int_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.75, logit=20.375, token_id=9939, metadata=None))), (393, (2, PredictedToken(token=' P', prob=0.0791015625, logit=18.125, token_id=393, metadata=None))), (94467, (6, PredictedToken(token=' Trom', prob=0.004730224609375, logit=15.3125, token_id=94467, metadata=None))), (30555, (17, PredictedToken(token=' Viol', prob=0.00127410888671875, logit=14.0, token_id=30555, metadata=None))), (6690, (29, PredictedToken(token=' Air', prob=0.0004138946533203125, logit=12.875, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:31 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.570, logit=19.625)', '\" Train\"[27217] (p=0.163, logit=18.375)', '\" The\"[578] (p=0.144, logit=18.250)', '\" A\"[362] (p=0.036, logit=16.875)', '\" SUB\"[16532] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     clean_prediction=['\" Magn\"[20918] (p=0.562, logit=20.000)', '\" Willow\"[65449] (p=0.301, logit=19.375)', '\" The\"[578] (p=0.052, logit=17.625)', '\" Hel\"[16183] (p=0.019, logit=16.625)', '\" There\"[2684] (p=0.017, logit=16.500)']\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     clean_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.5625, logit=20.0, token_id=20918, metadata=None))), (65449, (2, PredictedToken(token=' Willow', prob=0.30078125, logit=19.375, token_id=65449, metadata=None))), (16183, (4, PredictedToken(token=' Hel', prob=0.0191650390625, logit=16.625, token_id=16183, metadata=None))), (29318, (13, PredictedToken(token=' Dress', prob=0.00101470947265625, logit=13.6875, token_id=29318, metadata=None))), (45332, (85, PredictedToken(token=' Boat', prob=6.914138793945312e-05, logit=11.0, token_id=45332, metadata=None)))])\n",
      "2025-09-15 09:41:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.863, logit=21.125)', '\" Willow\"[65449] (p=0.033, logit=17.875)', '\" The\"[578] (p=0.026, logit=17.625)', '\" Boat\"[45332] (p=0.018, logit=17.250)', '\" There\"[2684] (p=0.014, logit=17.000)']\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.86328125, logit=21.125, token_id=16183, metadata=None))), (65449, (2, PredictedToken(token=' Willow', prob=0.033447265625, logit=17.875, token_id=65449, metadata=None))), (45332, (4, PredictedToken(token=' Boat', prob=0.0179443359375, logit=17.25, token_id=45332, metadata=None))), (20918, (15, PredictedToken(token=' Magn', prob=0.00078582763671875, logit=14.125, token_id=20918, metadata=None))), (29318, (29, PredictedToken(token=' Dress', prob=0.0002899169921875, logit=13.125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:32 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.363, logit=18.500)', '\" Ash\"[14937] (p=0.322, logit=18.375)', '\" The\"[578] (p=0.118, logit=17.375)', '\" There\"[2684] (p=0.056, logit=16.625)', '\" Daisy\"[71264] (p=0.030, logit=16.000)']\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.457, logit=19.125)', '\" Router\"[10777] (p=0.314, logit=18.750)', '\" The\"[578] (p=0.080, logit=17.375)', '\" Sco\"[50159] (p=0.026, logit=16.250)', '\" HEAD\"[34180] (p=0.016, logit=15.750)']\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.45703125, logit=19.125, token_id=11452, metadata=None))), (10777, (2, PredictedToken(token=' Router', prob=0.314453125, logit=18.75, token_id=10777, metadata=None))), (50159, (4, PredictedToken(token=' Sco', prob=0.02587890625, logit=16.25, token_id=50159, metadata=None))), (79028, (8, PredictedToken(token=' Hick', prob=0.00738525390625, logit=15.0, token_id=79028, metadata=None))), (33578, (50, PredictedToken(token=' Palm', prob=0.000286102294921875, logit=11.75, token_id=33578, metadata=None))), (32749, (105, PredictedToken(token=' Carn', prob=8.7738037109375e-05, logit=10.5625, token_id=32749, metadata=None)))])\n",
      "2025-09-15 09:41:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     int_prediction=['\" Router\"[10777] (p=0.676, logit=19.125)', '\" Palm\"[33578] (p=0.081, logit=17.000)', '\" The\"[578] (p=0.055, logit=16.625)', '\" Sco\"[50159] (p=0.049, logit=16.500)', '\" Carn\"[32749] (p=0.017, logit=15.438)']\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     int_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.67578125, logit=19.125, token_id=10777, metadata=None))), (33578, (2, PredictedToken(token=' Palm', prob=0.08056640625, logit=17.0, token_id=33578, metadata=None))), (50159, (4, PredictedToken(token=' Sco', prob=0.048828125, logit=16.5, token_id=50159, metadata=None))), (32749, (5, PredictedToken(token=' Carn', prob=0.0169677734375, logit=15.4375, token_id=32749, metadata=None))), (79028, (7, PredictedToken(token=' Hick', prob=0.0140380859375, logit=15.25, token_id=79028, metadata=None))), (11452, (576, PredictedToken(token=' Head', prob=6.645917892456055e-06, logit=7.59375, token_id=11452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:33 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:33 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.898, logit=21.875)', '\" Bamboo\"[98028] (p=0.058, logit=19.125)', '\" The\"[578] (p=0.016, logit=17.875)', '\" There\"[2684] (p=0.006, logit=16.875)', '\" None\"[2290] (p=0.004, logit=16.375)']\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.746, logit=19.750)', '\" The\"[578] (p=0.089, logit=17.625)', '\" LO\"[5125] (p=0.029, logit=16.500)', '\" A\"[362] (p=0.026, logit=16.375)', '\" C\"[356] (p=0.022, logit=16.250)']\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.74609375, logit=19.75, token_id=445, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.0224609375, logit=16.25, token_id=356, metadata=None))), (57094, (7, PredictedToken(token=' Highlight', prob=0.00830078125, logit=15.25, token_id=57094, metadata=None))), (14669, (13, PredictedToken(token=' Camera', prob=0.0023651123046875, logit=14.0, token_id=14669, metadata=None))), (33578, (21, PredictedToken(token=' Palm', prob=0.0010528564453125, logit=13.1875, token_id=33578, metadata=None))), (65329, (22, PredictedToken(token=' Elm', prob=0.000926971435546875, logit=13.0625, token_id=65329, metadata=None)))])\n",
      "2025-09-15 09:41:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:34 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.477, logit=18.625)', '\" Palm\"[33578] (p=0.225, logit=17.875)', '\" The\"[578] (p=0.094, logit=17.000)', '\" EL\"[17705] (p=0.017, logit=15.312)', '\" E\"[469] (p=0.017, logit=15.312)']\n",
      "2025-09-15 09:41:34 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.4765625, logit=18.625, token_id=65329, metadata=None))), (33578, (2, PredictedToken(token=' Palm', prob=0.224609375, logit=17.875, token_id=33578, metadata=None))), (57094, (8, PredictedToken(token=' Highlight', prob=0.010498046875, logit=14.8125, token_id=57094, metadata=None))), (14669, (14, PredictedToken(token=' Camera', prob=0.004974365234375, logit=14.0625, token_id=14669, metadata=None))), (356, (18, PredictedToken(token=' C', prob=0.00341796875, logit=13.6875, token_id=356, metadata=None))), (445, (32, PredictedToken(token=' L', prob=0.000919342041015625, logit=12.375, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:34 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:41:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:34 src.selection.optimization INFO     patch_prediction=['\" Mango\"[91963] (p=0.871, logit=21.250)', '\" The\"[578] (p=0.071, logit=18.750)', '\" M\"[386] (p=0.014, logit=17.125)', '\" There\"[2684] (p=0.010, logit=16.750)', '\" Apple\"[8325] (p=0.004, logit=15.750)']\n",
      "2025-09-15 09:41:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.621, logit=19.625)', '\" Ring\"[22249] (p=0.122, logit=18.000)', '\" The\"[578] (p=0.084, logit=17.625)', '\" Tooth\"[83499] (p=0.035, logit=16.750)', '\" CH\"[6969] (p=0.027, logit=16.500)']\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.62109375, logit=19.625, token_id=58600, metadata=None))), (22249, (2, PredictedToken(token=' Ring', prob=0.1220703125, logit=18.0, token_id=22249, metadata=None))), (83499, (4, PredictedToken(token=' Tooth', prob=0.034912109375, logit=16.75, token_id=83499, metadata=None))), (64695, (7, PredictedToken(token=' Peach', prob=0.0078125, logit=15.25, token_id=64695, metadata=None))), (22607, (12, PredictedToken(token=' Cow', prob=0.003692626953125, logit=14.5, token_id=22607, metadata=None))), (76924, (131, PredictedToken(token=' Banana', prob=5.602836608886719e-05, logit=10.3125, token_id=76924, metadata=None)))])\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     int_prediction=['\" Banana\"[76924] (p=0.637, logit=20.500)', '\" Ring\"[22249] (p=0.142, logit=19.000)', '\" Peach\"[64695] (p=0.086, logit=18.500)', '\" The\"[578] (p=0.041, logit=17.750)', '\" B\"[426] (p=0.036, logit=17.625)']\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     int_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.63671875, logit=20.5, token_id=76924, metadata=None))), (22249, (2, PredictedToken(token=' Ring', prob=0.1416015625, logit=19.0, token_id=22249, metadata=None))), (64695, (3, PredictedToken(token=' Peach', prob=0.0859375, logit=18.5, token_id=64695, metadata=None))), (83499, (7, PredictedToken(token=' Tooth', prob=0.005157470703125, logit=15.6875, token_id=83499, metadata=None))), (58600, (29, PredictedToken(token=' Charm', prob=0.000274658203125, logit=12.75, token_id=58600, metadata=None))), (22607, (73, PredictedToken(token=' Cow', prob=7.390975952148438e-05, logit=11.4375, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:35 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:35 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     patch_prediction=['\" Jasmine\"[82452] (p=0.609, logit=20.125)', '\" The\"[578] (p=0.225, logit=19.125)', '\" There\"[2684] (p=0.034, logit=17.250)', '\" Daisy\"[71264] (p=0.030, logit=17.125)', '\" J\"[622] (p=0.027, logit=17.000)']\n",
      "2025-09-15 09:41:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.734, logit=20.250)', '\" The\"[578] (p=0.145, logit=18.625)', '\" Jacket\"[55870] (p=0.025, logit=16.875)', '\" A\"[362] (p=0.020, logit=16.625)', '\" There\"[2684] (p=0.006, logit=15.500)']\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.734375, logit=20.25, token_id=29318, metadata=None))), (55870, (3, PredictedToken(token=' Jacket', prob=0.025146484375, logit=16.875, token_id=55870, metadata=None))), (55405, (12, PredictedToken(token=' Orch', prob=0.0024871826171875, logit=14.5625, token_id=55405, metadata=None))), (83499, (18, PredictedToken(token=' Tooth', prob=0.00133514404296875, logit=13.9375, token_id=83499, metadata=None))), (8219, (31, PredictedToken(token=' Sun', prob=0.00055694580078125, logit=13.0625, token_id=8219, metadata=None))), (12369, (212, PredictedToken(token=' Food', prob=1.6808509826660156e-05, logit=9.5625, token_id=12369, metadata=None)))])\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.844, logit=20.250)', '\" Orch\"[55405] (p=0.054, logit=17.500)', '\" The\"[578] (p=0.042, logit=17.250)', '\" sun\"[7160] (p=0.007, logit=15.500)', '\" There\"[2684] (p=0.004, logit=14.938)']\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.84375, logit=20.25, token_id=8219, metadata=None))), (55405, (2, PredictedToken(token=' Orch', prob=0.053955078125, logit=17.5, token_id=55405, metadata=None))), (55870, (8, PredictedToken(token=' Jacket', prob=0.002685546875, logit=14.5, token_id=55870, metadata=None))), (83499, (18, PredictedToken(token=' Tooth', prob=0.00112152099609375, logit=13.625, token_id=83499, metadata=None))), (29318, (48, PredictedToken(token=' Dress', prob=0.000171661376953125, logit=11.75, token_id=29318, metadata=None))), (12369, (152, PredictedToken(token=' Food', prob=2.467632293701172e-05, logit=9.8125, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:36 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     patch_prediction=['\" Spin\"[41785] (p=0.617, logit=19.000)', '\" Mushroom\"[91297] (p=0.107, logit=17.250)', '\" There\"[2684] (p=0.083, logit=17.000)', '\" The\"[578] (p=0.051, logit=16.500)', '\" None\"[2290] (p=0.035, logit=16.125)']\n",
      "2025-09-15 09:41:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.793, logit=20.625)', '\" The\"[578] (p=0.107, logit=18.625)', '\" PL\"[10528] (p=0.024, logit=17.125)', '\" Peach\"[64695] (p=0.013, logit=16.500)', '\" plum\"[42272] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.79296875, logit=20.625, token_id=84409, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.0128173828125, logit=16.5, token_id=64695, metadata=None))), (6914, (10, PredictedToken(token=' Let', prob=0.002227783203125, logit=14.75, token_id=6914, metadata=None))), (47643, (44, PredictedToken(token=' Cel', prob=0.00018310546875, logit=12.25, token_id=47643, metadata=None)))])\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.805, logit=20.500)', '\" The\"[578] (p=0.075, logit=18.125)', '\" Cel\"[47643] (p=0.035, logit=17.375)', '\" Peach\"[64695] (p=0.021, logit=16.875)', '\" Plum\"[84409] (p=0.015, logit=16.500)']\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.8046875, logit=20.5, token_id=6914, metadata=None))), (47643, (3, PredictedToken(token=' Cel', prob=0.035400390625, logit=17.375, token_id=47643, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.021484375, logit=16.875, token_id=64695, metadata=None))), (84409, (5, PredictedToken(token=' Plum', prob=0.0147705078125, logit=16.5, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:37 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:37 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.738, logit=19.875)', '\" Pine\"[42609] (p=0.053, logit=17.250)', '\" C\"[356] (p=0.047, logit=17.125)', '\" The\"[578] (p=0.042, logit=17.000)', '\" SPR\"[52367] (p=0.022, logit=16.375)']\n",
      "2025-09-15 09:41:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.617, logit=20.375)', '\" The\"[578] (p=0.200, logit=19.250)', '\" Viol\"[30555] (p=0.107, logit=18.625)', '\" A\"[362] (p=0.011, logit=16.375)', '\" It\"[1102] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.6171875, logit=20.375, token_id=1630, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.10693359375, logit=18.625, token_id=30555, metadata=None))), (469, (21, PredictedToken(token=' E', prob=0.0008697509765625, logit=13.8125, token_id=469, metadata=None))), (65329, (996, PredictedToken(token=' Elm', prob=1.0505318641662598e-06, logit=7.09375, token_id=65329, metadata=None))), (12369, (2413, PredictedToken(token=' Food', prob=2.9243528842926025e-07, logit=5.8125, token_id=12369, metadata=None)))])\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.676, logit=19.750)', '\" The\"[578] (p=0.117, logit=18.000)', '\" E\"[469] (p=0.091, logit=17.750)', '\" Viol\"[30555] (p=0.023, logit=16.375)', '\" EL\"[17705] (p=0.011, logit=15.625)']\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.67578125, logit=19.75, token_id=65329, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.09130859375, logit=17.75, token_id=469, metadata=None))), (30555, (4, PredictedToken(token=' Viol', prob=0.0230712890625, logit=16.375, token_id=30555, metadata=None))), (1630, (31, PredictedToken(token=' X', prob=0.000423431396484375, logit=12.375, token_id=1630, metadata=None))), (12369, (699, PredictedToken(token=' Food', prob=3.6656856536865234e-06, logit=7.625, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:38 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.609, logit=20.125)', '\" Sh\"[1443] (p=0.225, logit=19.125)', '\" The\"[578] (p=0.044, logit=17.500)', '\" A\"[362] (p=0.018, logit=16.625)', '\" SH\"[6570] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     clean_prediction=['\" Swe\"[37326] (p=0.656, logit=19.125)', '\" The\"[578] (p=0.166, logit=17.750)', '\" A\"[362] (p=0.033, logit=16.125)', '\" Dress\"[29318] (p=0.024, logit=15.812)', '\" S\"[328] (p=0.019, logit=15.562)']\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     clean_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.65625, logit=19.125, token_id=37326, metadata=None))), (29318, (4, PredictedToken(token=' Dress', prob=0.02392578125, logit=15.8125, token_id=29318, metadata=None))), (34954, (13, PredictedToken(token=' Mirror', prob=0.002685546875, logit=13.625, token_id=34954, metadata=None))), (82994, (19, PredictedToken(token=' Toilet', prob=0.001434326171875, logit=13.0, token_id=82994, metadata=None)))])\n",
      "2025-09-15 09:41:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:39 src.selection.optimization INFO     int_prediction=['\" Mirror\"[34954] (p=0.275, logit=17.875)', '\" Toilet\"[82994] (p=0.275, logit=17.875)', '\" Swe\"[37326] (p=0.188, logit=17.500)', '\" The\"[578] (p=0.101, logit=16.875)', '\" TO\"[5257] (p=0.029, logit=15.625)']\n",
      "2025-09-15 09:41:39 src.selection.optimization INFO     int_track=OrderedDict([(82994, (2, PredictedToken(token=' Toilet', prob=0.275390625, logit=17.875, token_id=82994, metadata=None))), (34954, (1, PredictedToken(token=' Mirror', prob=0.275390625, logit=17.875, token_id=34954, metadata=None))), (37326, (3, PredictedToken(token=' Swe', prob=0.1884765625, logit=17.5, token_id=37326, metadata=None))), (29318, (11, PredictedToken(token=' Dress', prob=0.004730224609375, logit=13.8125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:39 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:39 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:41:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:39 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.699, logit=20.000)', '\" The\"[578] (p=0.121, logit=18.250)', '\" Pe\"[5250] (p=0.083, logit=17.875)', '\" L\"[445] (p=0.014, logit=16.125)', '\" There\"[2684] (p=0.012, logit=15.938)']\n",
      "2025-09-15 09:41:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.867, logit=20.875)', '\" The\"[578] (p=0.063, logit=18.250)', '\" SOCK\"[35651] (p=0.011, logit=16.500)', '\" socks\"[40086] (p=0.008, logit=16.125)', '\" There\"[2684] (p=0.004, logit=15.438)']\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.8671875, logit=20.875, token_id=328, metadata=None))), (74574, (8, PredictedToken(token=' Violet', prob=0.0035400390625, logit=15.375, token_id=74574, metadata=None))), (90538, (9, PredictedToken(token=' Caul', prob=0.0024261474609375, logit=15.0, token_id=90538, metadata=None))), (68867, (12, PredictedToken(token=' Coat', prob=0.00201416015625, logit=14.8125, token_id=68867, metadata=None))), (16488, (11, PredictedToken(token=' Bat', prob=0.00201416015625, logit=14.8125, token_id=16488, metadata=None))), (4783, (15, PredictedToken(token=' House', prob=0.001220703125, logit=14.3125, token_id=4783, metadata=None))), (71264, (16, PredictedToken(token=' Daisy', prob=0.001220703125, logit=14.3125, token_id=71264, metadata=None)))])\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.934, logit=21.875)', '\" Caul\"[90538] (p=0.019, logit=18.000)', '\" The\"[578] (p=0.013, logit=17.625)', '\" Coat\"[68867] (p=0.010, logit=17.375)', '\" CA\"[9362] (p=0.004, logit=16.375)']\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.93359375, logit=21.875, token_id=74574, metadata=None))), (90538, (2, PredictedToken(token=' Caul', prob=0.0194091796875, logit=18.0, token_id=90538, metadata=None))), (68867, (4, PredictedToken(token=' Coat', prob=0.0103759765625, logit=17.375, token_id=68867, metadata=None))), (71264, (7, PredictedToken(token=' Daisy', prob=0.00262451171875, logit=16.0, token_id=71264, metadata=None))), (4783, (10, PredictedToken(token=' House', prob=0.00080108642578125, logit=14.8125, token_id=4783, metadata=None))), (16488, (15, PredictedToken(token=' Bat', prob=0.000377655029296875, logit=14.0625, token_id=16488, metadata=None))), (328, (44, PredictedToken(token=' S', prob=5.1021575927734375e-05, logit=12.0625, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:40 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.781, logit=20.875)', '\" Sink\"[57551] (p=0.120, logit=19.000)', '\" The\"[578] (p=0.039, logit=17.875)', '\" BAT\"[79081] (p=0.014, logit=16.875)', '\" Tub\"[40640] (p=0.010, logit=16.500)']\n",
      "2025-09-15 09:41:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     clean_prediction=['\" Dish\"[49268] (p=0.559, logit=20.250)', '\" The\"[578] (p=0.182, logit=19.125)', '\" Air\"[6690] (p=0.160, logit=19.000)', '\" A\"[362] (p=0.019, logit=16.875)', '\" DIS\"[12244] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     clean_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.55859375, logit=20.25, token_id=49268, metadata=None))), (6690, (3, PredictedToken(token=' Air', prob=0.16015625, logit=19.0, token_id=6690, metadata=None))), (82994, (16, PredictedToken(token=' Toilet', prob=0.00122833251953125, logit=14.125, token_id=82994, metadata=None))), (83499, (29, PredictedToken(token=' Tooth', prob=0.000743865966796875, logit=13.625, token_id=83499, metadata=None))), (70762, (56, PredictedToken(token=' Motorcycle', prob=0.00018787384033203125, logit=12.25, token_id=70762, metadata=None)))])\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     int_prediction=['\" Tooth\"[83499] (p=0.535, logit=19.375)', '\" Motorcycle\"[70762] (p=0.136, logit=18.000)', '\" Air\"[6690] (p=0.093, logit=17.625)', '\" The\"[578] (p=0.073, logit=17.375)', '\" TO\"[5257] (p=0.044, logit=16.875)']\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     int_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.53515625, logit=19.375, token_id=83499, metadata=None))), (70762, (2, PredictedToken(token=' Motorcycle', prob=0.1357421875, logit=18.0, token_id=70762, metadata=None))), (6690, (3, PredictedToken(token=' Air', prob=0.09326171875, logit=17.625, token_id=6690, metadata=None))), (82994, (7, PredictedToken(token=' Toilet', prob=0.0162353515625, logit=15.875, token_id=82994, metadata=None))), (49268, (24, PredictedToken(token=' Dish', prob=0.000972747802734375, logit=13.0625, token_id=49268, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:41 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.809, logit=21.375)', '\" Caul\"[90538] (p=0.109, logit=19.375)', '\" The\"[578] (p=0.040, logit=18.375)', '\" There\"[2684] (p=0.010, logit=17.000)', '\" AS\"[5871] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     clean_prediction=['\" Tiger\"[36845] (p=0.887, logit=21.000)', '\" The\"[578] (p=0.050, logit=18.125)', '\" T\"[350] (p=0.018, logit=17.125)', '\" Eagle\"[36895] (p=0.011, logit=16.625)', '\" There\"[2684] (p=0.004, logit=15.625)']\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     clean_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.88671875, logit=21.0, token_id=36845, metadata=None))), (36895, (4, PredictedToken(token=' Eagle', prob=0.01116943359375, logit=16.625, token_id=36895, metadata=None))), (1901, (7, PredictedToken(token=' Z', prob=0.0019378662109375, logit=14.875, token_id=1901, metadata=None))), (328, (10, PredictedToken(token=' S', prob=0.001251220703125, logit=14.4375, token_id=328, metadata=None))), (52882, (61, PredictedToken(token=' Pepper', prob=7.05718994140625e-05, logit=11.5625, token_id=52882, metadata=None)))])\n",
      "2025-09-15 09:41:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.762, logit=20.500)', '\" The\"[578] (p=0.049, logit=17.750)', '\" S\"[328] (p=0.049, logit=17.750)', '\" Tiger\"[36845] (p=0.043, logit=17.625)', '\" PE\"[22557] (p=0.030, logit=17.250)']\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.76171875, logit=20.5, token_id=52882, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.048828125, logit=17.75, token_id=328, metadata=None))), (36845, (4, PredictedToken(token=' Tiger', prob=0.04296875, logit=17.625, token_id=36845, metadata=None))), (1901, (6, PredictedToken(token=' Z', prob=0.01397705078125, logit=16.5, token_id=1901, metadata=None))), (36895, (8, PredictedToken(token=' Eagle', prob=0.006591796875, logit=15.75, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:42 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:42 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     patch_prediction=['\" Camera\"[14669] (p=0.547, logit=19.000)', '\" Keyboard\"[26698] (p=0.138, logit=17.625)', '\" The\"[578] (p=0.083, logit=17.125)', '\" Har\"[5340] (p=0.065, logit=16.875)', '\" None\"[2290] (p=0.019, logit=15.625)']\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.707, logit=20.250)', '\" Temple\"[19176] (p=0.140, logit=18.625)', '\" The\"[578] (p=0.058, logit=17.750)', '\" CH\"[6969] (p=0.015, logit=16.375)', '\" A\"[362] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.70703125, logit=20.25, token_id=9441, metadata=None))), (19176, (2, PredictedToken(token=' Temple', prob=0.1396484375, logit=18.625, token_id=19176, metadata=None))), (47033, (6, PredictedToken(token=' Printer', prob=0.01141357421875, logit=16.125, token_id=47033, metadata=None))), (5907, (8, PredictedToken(token=' Project', prob=0.00506591796875, logit=15.3125, token_id=5907, metadata=None))), (6771, (9, PredictedToken(token=' Table', prob=0.00421142578125, logit=15.125, token_id=6771, metadata=None))), (6690, (18, PredictedToken(token=' Air', prob=0.000881195068359375, logit=13.5625, token_id=6690, metadata=None))), (94467, (61, PredictedToken(token=' Trom', prob=0.00011205673217773438, logit=11.5, token_id=94467, metadata=None)))])\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.475, logit=19.500)', '\" Project\"[5907] (p=0.326, logit=19.125)', '\" The\"[578] (p=0.073, logit=17.625)', '\" A\"[362] (p=0.027, logit=16.625)', '\" PROJECT\"[40992] (p=0.011, logit=15.750)']\n",
      "2025-09-15 09:41:42 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.474609375, logit=19.5, token_id=47033, metadata=None))), (5907, (2, PredictedToken(token=' Project', prob=0.326171875, logit=19.125, token_id=5907, metadata=None))), (94467, (6, PredictedToken(token=' Trom', prob=0.00982666015625, logit=15.625, token_id=94467, metadata=None))), (19176, (8, PredictedToken(token=' Temple', prob=0.0072021484375, logit=15.3125, token_id=19176, metadata=None))), (6690, (10, PredictedToken(token=' Air', prob=0.004638671875, logit=14.875, token_id=6690, metadata=None))), (6771, (13, PredictedToken(token=' Table', prob=0.0030059814453125, logit=14.4375, token_id=6771, metadata=None))), (9441, (14, PredictedToken(token=' Church', prob=0.0026397705078125, logit=14.3125, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:43 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     patch_prediction=['\" Shower\"[48471] (p=0.727, logit=20.375)', '\" Toilet\"[82994] (p=0.143, logit=18.750)', '\" The\"[578] (p=0.060, logit=17.875)', '\" SH\"[6570] (p=0.017, logit=16.625)', '\" TO\"[5257] (p=0.007, logit=15.750)']\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     clean_prediction=['\" Banana\"[76924] (p=0.730, logit=20.500)', '\" The\"[578] (p=0.099, logit=18.500)', '\" Ki\"[30558] (p=0.077, logit=18.250)', '\" B\"[426] (p=0.036, logit=17.500)', '\" There\"[2684] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     clean_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.73046875, logit=20.5, token_id=76924, metadata=None))), (30558, (3, PredictedToken(token=' Ki', prob=0.07666015625, logit=18.25, token_id=30558, metadata=None))), (83499, (16, PredictedToken(token=' Tooth', prob=0.000965118408203125, logit=13.875, token_id=83499, metadata=None))), (82994, (50, PredictedToken(token=' Toilet', prob=0.00019073486328125, logit=12.25, token_id=82994, metadata=None))), (39794, (258, PredictedToken(token=' Desk', prob=9.47713851928711e-06, logit=9.25, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.605, logit=19.125)', '\" The\"[578] (p=0.136, logit=17.625)', '\" Ki\"[30558] (p=0.064, logit=16.875)', '\" Banana\"[76924] (p=0.050, logit=16.625)', '\" TO\"[5257] (p=0.034, logit=16.250)']\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.60546875, logit=19.125, token_id=82994, metadata=None))), (30558, (3, PredictedToken(token=' Ki', prob=0.06396484375, logit=16.875, token_id=30558, metadata=None))), (76924, (4, PredictedToken(token=' Banana', prob=0.0498046875, logit=16.625, token_id=76924, metadata=None))), (83499, (7, PredictedToken(token=' Tooth', prob=0.0086669921875, logit=14.875, token_id=83499, metadata=None))), (39794, (74, PredictedToken(token=' Desk', prob=0.0002307891845703125, logit=11.25, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:43 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:43 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:41:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     patch_prediction=['\" House\"[4783] (p=0.715, logit=20.250)', '\" The\"[578] (p=0.085, logit=18.125)', '\" HOUSE\"[69461] (p=0.046, logit=17.500)', '\" Apartment\"[53889] (p=0.031, logit=17.125)', '\" A\"[362] (p=0.028, logit=17.000)']\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.742, logit=21.000)', '\" The\"[578] (p=0.088, logit=18.875)', '\" Van\"[13000] (p=0.069, logit=18.625)', '\" BO\"[7967] (p=0.032, logit=17.875)', '\" A\"[362] (p=0.022, logit=17.500)']\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.7421875, logit=21.0, token_id=45332, metadata=None))), (13000, (3, PredictedToken(token=' Van', prob=0.06884765625, logit=18.625, token_id=13000, metadata=None))), (14642, (8, PredictedToken(token=' Phone', prob=0.0038909912109375, logit=15.75, token_id=14642, metadata=None))), (2057, (9, PredictedToken(token=' To', prob=0.0025177001953125, logit=15.3125, token_id=2057, metadata=None))), (8219, (44, PredictedToken(token=' Sun', prob=0.00018215179443359375, logit=12.6875, token_id=8219, metadata=None))), (16730, (151, PredictedToken(token=' Museum', prob=1.919269561767578e-05, logit=10.4375, token_id=16730, metadata=None))), (52466, (439, PredictedToken(token=' Warehouse', prob=3.129243850708008e-06, logit=8.625, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.723, logit=20.750)', '\" Boat\"[45332] (p=0.086, logit=18.625)', '\" The\"[578] (p=0.086, logit=18.625)', '\" Van\"[13000] (p=0.022, logit=17.250)', '\" A\"[362] (p=0.019, logit=17.125)']\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.72265625, logit=20.75, token_id=16730, metadata=None))), (45332, (3, PredictedToken(token=' Boat', prob=0.0859375, logit=18.625, token_id=45332, metadata=None))), (13000, (4, PredictedToken(token=' Van', prob=0.021728515625, logit=17.25, token_id=13000, metadata=None))), (2057, (7, PredictedToken(token=' To', prob=0.007080078125, logit=16.125, token_id=2057, metadata=None))), (14642, (9, PredictedToken(token=' Phone', prob=0.0033416748046875, logit=15.375, token_id=14642, metadata=None))), (8219, (84, PredictedToken(token=' Sun', prob=6.914138793945312e-05, logit=11.5, token_id=8219, metadata=None))), (52466, (131, PredictedToken(token=' Warehouse', prob=3.4809112548828125e-05, logit=10.8125, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:44 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:41:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     patch_prediction=['\" Razor\"[74968] (p=0.574, logit=20.625)', '\" Sink\"[57551] (p=0.348, logit=20.125)', '\" The\"[578] (p=0.015, logit=17.000)', '\" Shower\"[48471] (p=0.009, logit=16.500)', '\" SH\"[6570] (p=0.006, logit=16.125)']\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.605, logit=19.750)', '\" Gloves\"[68554] (p=0.252, logit=18.875)', '\" The\"[578] (p=0.056, logit=17.375)', '\" Glo\"[25372] (p=0.009, logit=15.500)', '\" A\"[362] (p=0.008, logit=15.375)']\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.60546875, logit=19.75, token_id=59825, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.251953125, logit=18.875, token_id=68554, metadata=None))), (48471, (6, PredictedToken(token=' Shower', prob=0.007598876953125, logit=15.375, token_id=48471, metadata=None))), (19111, (18, PredictedToken(token=' Bus', prob=0.000965118408203125, logit=13.3125, token_id=19111, metadata=None))), (82994, (26, PredictedToken(token=' Toilet', prob=0.00054931640625, logit=12.75, token_id=82994, metadata=None)))])\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.863, logit=20.250)', '\" Toilet\"[82994] (p=0.026, logit=16.750)', '\" The\"[578] (p=0.023, logit=16.625)', '\" TO\"[5257] (p=0.014, logit=16.125)', '\" G\"[480] (p=0.007, logit=15.438)']\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.86328125, logit=20.25, token_id=68554, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.026123046875, logit=16.75, token_id=82994, metadata=None))), (48471, (13, PredictedToken(token=' Shower', prob=0.0016632080078125, logit=14.0, token_id=48471, metadata=None))), (59825, (21, PredictedToken(token=' Tie', prob=0.00089263916015625, logit=13.375, token_id=59825, metadata=None))), (19111, (36, PredictedToken(token=' Bus', prob=0.0003490447998046875, logit=12.4375, token_id=19111, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:45 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:41:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.754, logit=19.750)', '\" The\"[578] (p=0.070, logit=17.375)', '\" Mosque\"[100031] (p=0.062, logit=17.250)', '\" CH\"[6969] (p=0.033, logit=16.625)', '\" A\"[362] (p=0.029, logit=16.500)']\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     clean_prediction=['\" Ju\"[22410] (p=0.586, logit=19.375)', '\" The\"[578] (p=0.148, logit=18.000)', '\" A\"[362] (p=0.090, logit=17.500)', '\" Oven\"[87213] (p=0.048, logit=16.875)', '\" J\"[622] (p=0.017, logit=15.812)']\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     clean_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.5859375, logit=19.375, token_id=22410, metadata=None))), (87213, (4, PredictedToken(token=' Oven', prob=0.048095703125, logit=16.875, token_id=87213, metadata=None))), (15429, (22, PredictedToken(token=' Hospital', prob=0.00136566162109375, logit=13.3125, token_id=15429, metadata=None))), (6150, (32, PredictedToken(token=' School', prob=0.000827789306640625, logit=12.8125, token_id=6150, metadata=None)))])\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.797, logit=20.875)', '\" School\"[6150] (p=0.122, logit=19.000)', '\" The\"[578] (p=0.031, logit=17.625)', '\" None\"[2290] (p=0.005, logit=15.875)', '\" O\"[507] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.796875, logit=20.875, token_id=87213, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.1220703125, logit=19.0, token_id=6150, metadata=None))), (15429, (8, PredictedToken(token=' Hospital', prob=0.0032501220703125, logit=15.375, token_id=15429, metadata=None))), (22410, (90, PredictedToken(token=' Ju', prob=4.100799560546875e-05, logit=11.0, token_id=22410, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:46 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:46 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:41:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.949, logit=22.250)', '\" The\"[578] (p=0.029, logit=18.750)', '\" PE\"[22557] (p=0.008, logit=17.500)', '\" A\"[362] (p=0.002, logit=16.250)', '\" There\"[2684] (p=0.001, logit=15.562)']\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     clean_prediction=['\" Pants\"[67553] (p=0.777, logit=20.250)', '\" Tie\"[59825] (p=0.105, logit=18.250)', '\" The\"[578] (p=0.050, logit=17.500)', '\" T\"[350] (p=0.011, logit=16.000)', '\" A\"[362] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     clean_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.77734375, logit=20.25, token_id=67553, metadata=None))), (59825, (2, PredictedToken(token=' Tie', prob=0.10498046875, logit=18.25, token_id=59825, metadata=None))), (80629, (12, PredictedToken(token=' Grape', prob=0.0023193359375, logit=14.4375, token_id=80629, metadata=None))), (3420, (16, PredictedToken(token=' Trump', prob=0.00090789794921875, logit=13.5, token_id=3420, metadata=None))), (8325, (37, PredictedToken(token=' Apple', prob=0.0002613067626953125, logit=12.25, token_id=8325, metadata=None))), (88088, (83, PredictedToken(token=' Birch', prob=7.43865966796875e-05, logit=11.0, token_id=88088, metadata=None)))])\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.559, logit=19.500)', '\" Tie\"[59825] (p=0.264, logit=18.750)', '\" The\"[578] (p=0.067, logit=17.375)', '\" APPLE\"[91436] (p=0.022, logit=16.250)', '\" Grape\"[80629] (p=0.017, logit=16.000)']\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.55859375, logit=19.5, token_id=8325, metadata=None))), (59825, (2, PredictedToken(token=' Tie', prob=0.263671875, logit=18.75, token_id=59825, metadata=None))), (80629, (5, PredictedToken(token=' Grape', prob=0.016845703125, logit=16.0, token_id=80629, metadata=None))), (3420, (7, PredictedToken(token=' Trump', prob=0.006591796875, logit=15.0625, token_id=3420, metadata=None))), (88088, (24, PredictedToken(token=' Birch', prob=0.000652313232421875, logit=12.75, token_id=88088, metadata=None))), (67553, (53, PredictedToken(token=' Pants', prob=0.00019931793212890625, logit=11.5625, token_id=67553, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:47 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:47 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:41:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.688, logit=20.250)', '\" The\"[578] (p=0.119, logit=18.500)', '\" SHE\"[54695] (p=0.082, logit=18.125)', '\" Cow\"[22607] (p=0.016, logit=16.500)', '\" A\"[362] (p=0.014, logit=16.375)']\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     clean_prediction=['\" Pepper\"[52882] (p=0.637, logit=20.750)', '\" Let\"[6914] (p=0.125, logit=19.125)', '\" The\"[578] (p=0.125, logit=19.125)', '\" There\"[2684] (p=0.022, logit=17.375)', '\" Bear\"[24941] (p=0.019, logit=17.250)']\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     clean_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.63671875, logit=20.75, token_id=52882, metadata=None))), (6914, (3, PredictedToken(token=' Let', prob=0.125, logit=19.125, token_id=6914, metadata=None))), (24941, (5, PredictedToken(token=' Bear', prob=0.0191650390625, logit=17.25, token_id=24941, metadata=None))), (393, (6, PredictedToken(token=' P', prob=0.01318359375, logit=16.875, token_id=393, metadata=None))), (21424, (57, PredictedToken(token=' Football', prob=0.00010728836059570312, logit=12.0625, token_id=21424, metadata=None))), (36845, (67, PredictedToken(token=' Tiger', prob=7.867813110351562e-05, logit=11.75, token_id=36845, metadata=None))), (33711, (114, PredictedToken(token=' Suit', prob=3.933906555175781e-05, logit=11.0625, token_id=33711, metadata=None)))])\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.311, logit=19.125)', '\" Pepper\"[52882] (p=0.241, logit=18.875)', '\" The\"[578] (p=0.188, logit=18.625)', '\" Bear\"[24941] (p=0.114, logit=18.125)', '\" There\"[2684] (p=0.025, logit=16.625)']\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.310546875, logit=19.125, token_id=36845, metadata=None))), (52882, (2, PredictedToken(token=' Pepper', prob=0.2412109375, logit=18.875, token_id=52882, metadata=None))), (24941, (4, PredictedToken(token=' Bear', prob=0.1142578125, logit=18.125, token_id=24941, metadata=None))), (393, (7, PredictedToken(token=' P', prob=0.01129150390625, logit=15.8125, token_id=393, metadata=None))), (6914, (11, PredictedToken(token=' Let', prob=0.00567626953125, logit=15.125, token_id=6914, metadata=None))), (21424, (35, PredictedToken(token=' Football', prob=0.000438690185546875, logit=12.5625, token_id=21424, metadata=None))), (33711, (60, PredictedToken(token=' Suit', prob=0.000171661376953125, logit=11.625, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:48 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:41:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:49 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.801, logit=20.250)', '\" The\"[578] (p=0.123, logit=18.375)', '\" A\"[362] (p=0.008, logit=15.688)', '\" SUN\"[57328] (p=0.007, logit=15.500)', '\" Mar\"[2947] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:41:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:49 src.selection.optimization INFO     clean_prediction=['\" Ottoman\"[70110] (p=0.805, logit=19.875)', '\" The\"[578] (p=0.075, logit=17.500)', '\" Ward\"[27738] (p=0.028, logit=16.500)', '\" School\"[6150] (p=0.019, logit=16.125)', '\" It\"[1102] (p=0.007, logit=15.188)']\n",
      "2025-09-15 09:41:49 src.selection.optimization INFO     clean_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.8046875, logit=19.875, token_id=70110, metadata=None))), (27738, (3, PredictedToken(token=' Ward', prob=0.027587890625, logit=16.5, token_id=27738, metadata=None))), (6150, (4, PredictedToken(token=' School', prob=0.0189208984375, logit=16.125, token_id=6150, metadata=None))), (423, (24, PredictedToken(token=' D', prob=0.000732421875, logit=12.875, token_id=423, metadata=None))), (43316, (34, PredictedToken(token=' Tul', prob=0.0004730224609375, logit=12.4375, token_id=43316, metadata=None)))])\n",
      "2025-09-15 09:41:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     int_prediction=['\" Tul\"[43316] (p=0.836, logit=19.500)', '\" School\"[6150] (p=0.053, logit=16.750)', '\" The\"[578] (p=0.037, logit=16.375)', '\" Ward\"[27738] (p=0.017, logit=15.625)', '\" It\"[1102] (p=0.004, logit=14.250)']\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     int_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.8359375, logit=19.5, token_id=43316, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.053466796875, logit=16.75, token_id=6150, metadata=None))), (27738, (4, PredictedToken(token=' Ward', prob=0.017333984375, logit=15.625, token_id=27738, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.004119873046875, logit=14.1875, token_id=423, metadata=None))), (70110, (25, PredictedToken(token=' Ottoman', prob=0.000492095947265625, logit=12.0625, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:50 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:41:50 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     patch_prediction=['\" Suit\"[33711] (p=0.236, logit=18.750)', '\" Watch\"[10573] (p=0.209, logit=18.625)', '\" The\"[578] (p=0.185, logit=18.500)', '\" A\"[362] (p=0.163, logit=18.375)', '\" Swe\"[37326] (p=0.112, logit=18.000)']\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     clean_prediction=['\" Dish\"[49268] (p=0.551, logit=19.750)', '\" The\"[578] (p=0.229, logit=18.875)', '\" Refriger\"[75258] (p=0.108, logit=18.125)', '\" A\"[362] (p=0.031, logit=16.875)', '\" Project\"[5907] (p=0.008, logit=15.562)']\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     clean_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.55078125, logit=19.75, token_id=49268, metadata=None))), (75258, (3, PredictedToken(token=' Refriger', prob=0.1083984375, logit=18.125, token_id=75258, metadata=None))), (5907, (5, PredictedToken(token=' Project', prob=0.00836181640625, logit=15.5625, token_id=5907, metadata=None))), (816, (11, PredictedToken(token=' Y', prob=0.001983642578125, logit=14.125, token_id=816, metadata=None))), (6031, (13, PredictedToken(token=' Bro', prob=0.00164031982421875, logit=13.9375, token_id=6031, metadata=None))), (59825, (54, PredictedToken(token=' Tie', prob=0.00023651123046875, logit=12.0, token_id=59825, metadata=None))), (4923, (55, PredictedToken(token=' Sk', prob=0.00022220611572265625, logit=11.9375, token_id=4923, metadata=None)))])\n",
      "2025-09-15 09:41:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.455, logit=19.500)', '\" Tie\"[59825] (p=0.312, logit=19.125)', '\" The\"[578] (p=0.102, logit=18.000)', '\" A\"[362] (p=0.054, logit=17.375)', '\" Bro\"[6031] (p=0.026, logit=16.625)']\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.455078125, logit=19.5, token_id=4923, metadata=None))), (59825, (2, PredictedToken(token=' Tie', prob=0.3125, logit=19.125, token_id=59825, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.025634765625, logit=16.625, token_id=6031, metadata=None))), (5907, (15, PredictedToken(token=' Project', prob=0.00106048583984375, logit=13.4375, token_id=5907, metadata=None))), (816, (14, PredictedToken(token=' Y', prob=0.00106048583984375, logit=13.4375, token_id=816, metadata=None))), (75258, (31, PredictedToken(token=' Refriger', prob=0.000286102294921875, logit=12.125, token_id=75258, metadata=None))), (49268, (58, PredictedToken(token=' Dish', prob=0.0001049041748046875, logit=11.125, token_id=49268, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:51 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:51 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     patch_prediction=['\" Ash\"[14937] (p=0.467, logit=18.750)', '\" Spr\"[15883] (p=0.320, logit=18.375)', '\" The\"[578] (p=0.104, logit=17.250)', '\" There\"[2684] (p=0.030, logit=16.000)', '\" None\"[2290] (p=0.010, logit=14.875)']\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.812, logit=20.500)', '\" Horse\"[34392] (p=0.085, logit=18.250)', '\" The\"[578] (p=0.036, logit=17.375)', '\" C\"[356] (p=0.017, logit=16.625)', '\" A\"[362] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.8125, logit=20.5, token_id=22607, metadata=None))), (34392, (2, PredictedToken(token=' Horse', prob=0.08544921875, logit=18.25, token_id=34392, metadata=None))), (34785, (15, PredictedToken(token=' Truck', prob=0.00074005126953125, logit=13.5, token_id=34785, metadata=None))), (18787, (96, PredictedToken(token=' Oak', prob=4.7206878662109375e-05, logit=10.75, token_id=18787, metadata=None))), (65329, (144, PredictedToken(token=' Elm', prob=2.6941299438476562e-05, logit=10.1875, token_id=65329, metadata=None)))])\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.531, logit=19.000)', '\" The\"[578] (p=0.104, logit=17.375)', '\" Horse\"[34392] (p=0.072, logit=17.000)', '\" Oak\"[18787] (p=0.063, logit=16.875)', '\" E\"[469] (p=0.038, logit=16.375)']\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.53125, logit=19.0, token_id=65329, metadata=None))), (34392, (3, PredictedToken(token=' Horse', prob=0.07177734375, logit=17.0, token_id=34392, metadata=None))), (18787, (4, PredictedToken(token=' Oak', prob=0.06298828125, logit=16.875, token_id=18787, metadata=None))), (22607, (16, PredictedToken(token=' Cow', prob=0.002960205078125, logit=13.8125, token_id=22607, metadata=None))), (34785, (33, PredictedToken(token=' Truck', prob=0.0007476806640625, logit=12.4375, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:51 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:51 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:41:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.420, logit=19.250)', '\" Gloves\"[68554] (p=0.371, logit=19.125)', '\" The\"[578] (p=0.083, logit=17.625)', '\" Tennis\"[58251] (p=0.030, logit=16.625)', '\" A\"[362] (p=0.010, logit=15.500)']\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.684, logit=20.500)', '\" The\"[578] (p=0.152, logit=19.000)', '\" Tie\"[59825] (p=0.044, logit=17.750)', '\" A\"[362] (p=0.039, logit=17.625)', '\" CO\"[7432] (p=0.021, logit=17.000)']\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.68359375, logit=20.5, token_id=68867, metadata=None))), (59825, (3, PredictedToken(token=' Tie', prob=0.043701171875, logit=17.75, token_id=59825, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.00628662109375, logit=15.8125, token_id=423, metadata=None))), (67629, (9, PredictedToken(token=' Helmet', prob=0.0029754638671875, logit=15.0625, token_id=67629, metadata=None))), (87035, (65, PredictedToken(token=' Onion', prob=0.00011539459228515625, logit=11.8125, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.801, logit=20.500)', '\" Helmet\"[67629] (p=0.096, logit=18.375)', '\" The\"[578] (p=0.040, logit=17.500)', '\" A\"[362] (p=0.013, logit=16.375)', '\" HEL\"[38757] (p=0.005, logit=15.438)']\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.80078125, logit=20.5, token_id=423, metadata=None))), (67629, (2, PredictedToken(token=' Helmet', prob=0.095703125, logit=18.375, token_id=67629, metadata=None))), (59825, (7, PredictedToken(token=' Tie', prob=0.00445556640625, logit=15.3125, token_id=59825, metadata=None))), (87035, (12, PredictedToken(token=' Onion', prob=0.00136566162109375, logit=14.125, token_id=87035, metadata=None))), (68867, (15, PredictedToken(token=' Coat', prob=0.001129150390625, logit=13.9375, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:52 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:41:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     patch_prediction=['\" Bench\"[36358] (p=0.812, logit=20.000)', '\" The\"[578] (p=0.097, logit=17.875)', '\" A\"[362] (p=0.012, logit=15.750)', '\" It\"[1102] (p=0.010, logit=15.562)', '\" B\"[426] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.287, logit=17.750)', '\" Maple\"[44570] (p=0.175, logit=17.250)', '\" Chair\"[16478] (p=0.154, logit=17.125)', '\" Table\"[6771] (p=0.083, logit=16.500)', '\" Oak\"[18787] (p=0.057, logit=16.125)']\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.287109375, logit=17.75, token_id=79028, metadata=None))), (44570, (2, PredictedToken(token=' Maple', prob=0.1748046875, logit=17.25, token_id=44570, metadata=None))), (16478, (3, PredictedToken(token=' Chair', prob=0.154296875, logit=17.125, token_id=16478, metadata=None))), (6771, (4, PredictedToken(token=' Table', prob=0.08251953125, logit=16.5, token_id=6771, metadata=None)))])\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.602, logit=18.875)', '\" Hick\"[79028] (p=0.072, logit=16.750)', '\" Maple\"[44570] (p=0.063, logit=16.625)', '\" Oak\"[18787] (p=0.050, logit=16.375)', '\" CH\"[6969] (p=0.044, logit=16.250)']\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.6015625, logit=18.875, token_id=16478, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.072265625, logit=16.75, token_id=79028, metadata=None))), (44570, (3, PredictedToken(token=' Maple', prob=0.0634765625, logit=16.625, token_id=44570, metadata=None))), (6771, (6, PredictedToken(token=' Table', prob=0.0264892578125, logit=15.75, token_id=6771, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:53 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.402, logit=19.250)', '\" Amb\"[20423] (p=0.277, logit=18.875)', '\" The\"[578] (p=0.190, logit=18.500)', '\" An\"[1556] (p=0.042, logit=17.000)', '\" There\"[2684] (p=0.018, logit=16.125)']\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     clean_prediction=['\" Dish\"[49268] (p=0.727, logit=20.750)', '\" The\"[578] (p=0.162, logit=19.250)', '\" Refriger\"[75258] (p=0.041, logit=17.875)', '\" A\"[362] (p=0.015, logit=16.875)', '\" DIS\"[12244] (p=0.006, logit=15.938)']\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     clean_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.7265625, logit=20.75, token_id=49268, metadata=None))), (75258, (3, PredictedToken(token=' Refriger', prob=0.041015625, logit=17.875, token_id=75258, metadata=None))), (74574, (6, PredictedToken(token=' Violet', prob=0.005218505859375, logit=15.8125, token_id=74574, metadata=None))), (6690, (7, PredictedToken(token=' Air', prob=0.004608154296875, logit=15.6875, token_id=6690, metadata=None))), (45332, (132, PredictedToken(token=' Boat', prob=2.9087066650390625e-05, logit=10.625, token_id=45332, metadata=None)))])\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.867, logit=21.500)', '\" The\"[578] (p=0.055, logit=18.750)', '\" An\"[1556] (p=0.038, logit=18.375)', '\" Boat\"[45332] (p=0.007, logit=16.625)', '\" There\"[2684] (p=0.006, logit=16.500)']\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.8671875, logit=21.5, token_id=6690, metadata=None))), (45332, (4, PredictedToken(token=' Boat', prob=0.006622314453125, logit=16.625, token_id=45332, metadata=None))), (74574, (15, PredictedToken(token=' Violet', prob=0.000789642333984375, logit=14.5, token_id=74574, metadata=None))), (75258, (18, PredictedToken(token=' Refriger', prob=0.00054168701171875, logit=14.125, token_id=75258, metadata=None))), (49268, (33, PredictedToken(token=' Dish', prob=0.0001373291015625, logit=12.75, token_id=49268, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:54 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:41:54 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:41:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.766, logit=20.250)', '\" The\"[578] (p=0.171, logit=18.750)', '\" W\"[468] (p=0.012, logit=16.125)', '\" It\"[1102] (p=0.005, logit=15.125)', '\" A\"[362] (p=0.005, logit=15.125)']\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.824, logit=19.625)', '\" Bed\"[13394] (p=0.036, logit=16.500)', '\" The\"[578] (p=0.036, logit=16.500)', '\" Magn\"[20918] (p=0.009, logit=15.125)', '\" MAP\"[28322] (p=0.008, logit=15.000)']\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.82421875, logit=19.625, token_id=44570, metadata=None))), (13394, (3, PredictedToken(token=' Bed', prob=0.0361328125, logit=16.5, token_id=13394, metadata=None))), (20918, (4, PredictedToken(token=' Magn', prob=0.0091552734375, logit=15.125, token_id=20918, metadata=None))), (61948, (156, PredictedToken(token=' Sofa', prob=3.981590270996094e-05, logit=9.6875, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     int_prediction=['\" Bed\"[13394] (p=0.730, logit=19.250)', '\" BED\"[83364] (p=0.060, logit=16.750)', '\" The\"[578] (p=0.053, logit=16.625)', '\" Maple\"[44570] (p=0.041, logit=16.375)', '\" There\"[2684] (p=0.011, logit=15.062)']\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     int_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.73046875, logit=19.25, token_id=13394, metadata=None))), (44570, (4, PredictedToken(token=' Maple', prob=0.041259765625, logit=16.375, token_id=44570, metadata=None))), (20918, (15, PredictedToken(token=' Magn', prob=0.0021820068359375, logit=13.4375, token_id=20918, metadata=None))), (61948, (30, PredictedToken(token=' Sofa', prob=0.00070953369140625, logit=12.3125, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:55 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:41:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.734, logit=21.000)', '\" Hat\"[22050] (p=0.128, logit=19.250)', '\" The\"[578] (p=0.078, logit=18.750)', '\" SOCK\"[35651] (p=0.010, logit=16.750)', '\" A\"[362] (p=0.010, logit=16.750)']\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.633, logit=20.250)', '\" The\"[578] (p=0.160, logit=18.875)', '\" A\"[362] (p=0.067, logit=18.000)', '\" Mixer\"[72392] (p=0.052, logit=17.750)', '\" BLE\"[52818] (p=0.012, logit=16.250)']\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.6328125, logit=20.25, token_id=88668, metadata=None))), (72392, (4, PredictedToken(token=' Mixer', prob=0.052001953125, logit=17.75, token_id=72392, metadata=None))), (83499, (19, PredictedToken(token=' Tooth', prob=0.00115203857421875, logit=13.9375, token_id=83499, metadata=None))), (37326, (42, PredictedToken(token=' Swe', prob=0.000255584716796875, logit=12.4375, token_id=37326, metadata=None))), (29318, (70, PredictedToken(token=' Dress', prob=0.00012111663818359375, logit=11.6875, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.609, logit=19.875)', '\" The\"[578] (p=0.154, logit=18.500)', '\" Swe\"[37326] (p=0.064, logit=17.625)', '\" A\"[362] (p=0.050, logit=17.375)', '\" Tooth\"[83499] (p=0.027, logit=16.750)']\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.609375, logit=19.875, token_id=29318, metadata=None))), (37326, (3, PredictedToken(token=' Swe', prob=0.06396484375, logit=17.625, token_id=37326, metadata=None))), (83499, (5, PredictedToken(token=' Tooth', prob=0.0267333984375, logit=16.75, token_id=83499, metadata=None))), (72392, (6, PredictedToken(token=' Mixer', prob=0.0235595703125, logit=16.625, token_id=72392, metadata=None))), (88668, (23, PredictedToken(token=' Blender', prob=0.00091552734375, logit=13.375, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:56 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-15 09:41:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.738, logit=20.625)', '\" The\"[578] (p=0.129, logit=18.875)', '\" Ch\"[921] (p=0.069, logit=18.250)', '\" L\"[445] (p=0.015, logit=16.750)', '\" There\"[2684] (p=0.004, logit=15.438)']\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.801, logit=20.375)', '\" The\"[578] (p=0.123, logit=18.500)', '\" VI\"[30768] (p=0.011, logit=16.125)', '\" A\"[362] (p=0.010, logit=16.000)', '\" violin\"[63137] (p=0.005, logit=15.375)']\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.80078125, logit=20.375, token_id=30555, metadata=None))), (46506, (10, PredictedToken(token=' Drum', prob=0.001983642578125, logit=14.375, token_id=46506, metadata=None))), (3804, (45, PredictedToken(token=' Sub', prob=0.00020885467529296875, logit=12.125, token_id=3804, metadata=None))), (8219, (81, PredictedToken(token=' Sun', prob=7.677078247070312e-05, logit=11.125, token_id=8219, metadata=None))), (32749, (117, PredictedToken(token=' Carn', prob=4.124641418457031e-05, logit=10.5, token_id=32749, metadata=None)))])\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.840, logit=19.625)', '\" The\"[578] (p=0.054, logit=16.875)', '\" Viol\"[30555] (p=0.022, logit=16.000)', '\" SUN\"[57328] (p=0.009, logit=15.125)', '\" sun\"[7160] (p=0.009, logit=15.062)']\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.83984375, logit=19.625, token_id=8219, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.0223388671875, logit=16.0, token_id=30555, metadata=None))), (3804, (6, PredictedToken(token=' Sub', prob=0.00640869140625, logit=14.75, token_id=3804, metadata=None))), (32749, (13, PredictedToken(token=' Carn', prob=0.00183868408203125, logit=13.5, token_id=32749, metadata=None))), (46506, (22, PredictedToken(token=' Drum', prob=0.000766754150390625, logit=12.625, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:41:57 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:41:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     patch_prediction=['\" Blender\"[88668] (p=0.801, logit=21.125)', '\" The\"[578] (p=0.095, logit=19.000)', '\" A\"[362] (p=0.035, logit=18.000)', '\" Peach\"[64695] (p=0.017, logit=17.250)', '\" Hel\"[16183] (p=0.005, logit=16.125)']\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.656, logit=20.625)', '\" The\"[578] (p=0.213, logit=19.500)', '\" Car\"[3341] (p=0.029, logit=17.500)', '\" Sheep\"[84008] (p=0.022, logit=17.250)', '\" A\"[362] (p=0.022, logit=17.250)']\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.65625, logit=20.625, token_id=19111, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.02880859375, logit=17.5, token_id=3341, metadata=None))), (84008, (5, PredictedToken(token=' Sheep', prob=0.0224609375, logit=17.25, token_id=84008, metadata=None))), (40090, (19, PredictedToken(token=' Pressure', prob=0.00067901611328125, logit=13.75, token_id=40090, metadata=None))), (39247, (22, PredictedToken(token=' Slow', prob=0.000560760498046875, logit=13.5625, token_id=39247, metadata=None))), (89077, (235, PredictedToken(token=' Strawberry', prob=1.0311603546142578e-05, logit=9.5625, token_id=89077, metadata=None)))])\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.498, logit=20.250)', '\" Pressure\"[40090] (p=0.184, logit=19.250)', '\" Bus\"[19111] (p=0.126, logit=18.875)', '\" The\"[578] (p=0.126, logit=18.875)', '\" A\"[362] (p=0.013, logit=16.625)']\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.498046875, logit=20.25, token_id=39247, metadata=None))), (40090, (2, PredictedToken(token=' Pressure', prob=0.18359375, logit=19.25, token_id=40090, metadata=None))), (19111, (4, PredictedToken(token=' Bus', prob=0.1259765625, logit=18.875, token_id=19111, metadata=None))), (3341, (11, PredictedToken(token=' Car', prob=0.0016937255859375, logit=14.5625, token_id=3341, metadata=None))), (84008, (19, PredictedToken(token=' Sheep', prob=0.000850677490234375, logit=13.875, token_id=84008, metadata=None))), (89077, (30, PredictedToken(token=' Strawberry', prob=0.000293731689453125, logit=12.8125, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:58 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:41:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     patch_prediction=['\" Table\"[6771] (p=0.555, logit=19.750)', '\" Night\"[13120] (p=0.159, logit=18.500)', '\" The\"[578] (p=0.140, logit=18.375)', '\" TABLE\"[14700] (p=0.045, logit=17.250)', '\" A\"[362] (p=0.031, logit=16.875)']\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.617, logit=20.000)', '\" Comb\"[23262] (p=0.200, logit=18.875)', '\" TO\"[5257] (p=0.035, logit=17.125)', '\" The\"[578] (p=0.035, logit=17.125)', '\" None\"[2290] (p=0.021, logit=16.625)']\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.6171875, logit=20.0, token_id=83499, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.2001953125, logit=18.875, token_id=23262, metadata=None))), (90538, (7, PredictedToken(token=' Caul', prob=0.01129150390625, logit=16.0, token_id=90538, metadata=None))), (70110, (13, PredictedToken(token=' Ottoman', prob=0.0019683837890625, logit=14.25, token_id=70110, metadata=None))), (6017, (50, PredictedToken(token=' Book', prob=0.00020694732666015625, logit=12.0, token_id=6017, metadata=None)))])\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     int_prediction=['\" Book\"[6017] (p=0.914, logit=21.375)', '\" The\"[578] (p=0.017, logit=17.375)', '\" Caul\"[90538] (p=0.012, logit=17.000)', '\" BOOK\"[48198] (p=0.010, logit=16.875)', '\" Tooth\"[83499] (p=0.008, logit=16.625)']\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     int_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.9140625, logit=21.375, token_id=6017, metadata=None))), (90538, (3, PredictedToken(token=' Caul', prob=0.01153564453125, logit=17.0, token_id=90538, metadata=None))), (83499, (5, PredictedToken(token=' Tooth', prob=0.0079345703125, logit=16.625, token_id=83499, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.004241943359375, logit=16.0, token_id=23262, metadata=None))), (70110, (10, PredictedToken(token=' Ottoman', prob=0.00128936767578125, logit=14.8125, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:41:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:41:59 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     patch_prediction=['\" Television\"[41445] (p=0.723, logit=20.375)', '\" Printer\"[47033] (p=0.183, logit=19.000)', '\" The\"[578] (p=0.025, logit=17.000)', '\" Pendant\"[81501] (p=0.019, logit=16.750)', '\" TV\"[6007] (p=0.012, logit=16.250)']\n",
      "2025-09-15 09:41:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.902, logit=20.750)', '\" The\"[578] (p=0.024, logit=17.125)', '\" Truck\"[34785] (p=0.015, logit=16.625)', '\" A\"[362] (p=0.010, logit=16.250)', '\" None\"[2290] (p=0.007, logit=15.938)']\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.90234375, logit=20.75, token_id=70762, metadata=None))), (34785, (3, PredictedToken(token=' Truck', prob=0.01458740234375, logit=16.625, token_id=34785, metadata=None))), (29625, (6, PredictedToken(token=' Chain', prob=0.00506591796875, logit=15.5625, token_id=29625, metadata=None))), (5907, (11, PredictedToken(token=' Project', prob=0.00119781494140625, logit=14.125, token_id=5907, metadata=None))), (14669, (21, PredictedToken(token=' Camera', prob=0.0005340576171875, logit=13.3125, token_id=14669, metadata=None)))])\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.598, logit=20.000)', '\" Project\"[5907] (p=0.194, logit=18.875)', '\" Camera\"[14669] (p=0.081, logit=18.000)', '\" The\"[578] (p=0.038, logit=17.250)', '\" A\"[362] (p=0.016, logit=16.375)']\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.59765625, logit=20.0, token_id=70762, metadata=None))), (5907, (2, PredictedToken(token=' Project', prob=0.1943359375, logit=18.875, token_id=5907, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.0810546875, logit=18.0, token_id=14669, metadata=None))), (34785, (9, PredictedToken(token=' Truck', prob=0.00457763671875, logit=15.125, token_id=34785, metadata=None))), (29625, (17, PredictedToken(token=' Chain', prob=0.00122833251953125, logit=13.8125, token_id=29625, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:00 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:00 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.645, logit=19.375)', '\" Van\"[13000] (p=0.127, logit=17.750)', '\" The\"[578] (p=0.068, logit=17.125)', '\" Sk\"[4923] (p=0.036, logit=16.500)', '\" VAN\"[97753] (p=0.016, logit=15.688)']\n",
      "2025-09-15 09:42:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:01 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.695, logit=20.500)', '\" Monitor\"[24423] (p=0.107, logit=18.625)', '\" The\"[578] (p=0.107, logit=18.625)', '\" KEY\"[12282] (p=0.013, logit=16.500)', '\" There\"[2684] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:42:01 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.6953125, logit=20.5, token_id=26698, metadata=None))), (24423, (3, PredictedToken(token=' Monitor', prob=0.10693359375, logit=18.625, token_id=24423, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.00125885009765625, logit=14.1875, token_id=1183, metadata=None))), (328, (66, PredictedToken(token=' S', prob=0.00011730194091796875, logit=11.8125, token_id=328, metadata=None))), (5250, (299, PredictedToken(token=' Pe', prob=7.510185241699219e-06, logit=9.0625, token_id=5250, metadata=None))), (37326, (767, PredictedToken(token=' Swe', prob=1.8998980522155762e-06, logit=7.6875, token_id=37326, metadata=None))), (29318, (1900, PredictedToken(token=' Dress', prob=5.438923835754395e-07, logit=6.4375, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:42:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:01 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.633, logit=19.500)', '\" Dress\"[29318] (p=0.160, logit=18.125)', '\" Swe\"[37326] (p=0.046, logit=16.875)', '\" The\"[578] (p=0.041, logit=16.750)', '\" Keyboard\"[26698] (p=0.036, logit=16.625)']\n",
      "2025-09-15 09:42:01 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.6328125, logit=19.5, token_id=328, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.16015625, logit=18.125, token_id=29318, metadata=None))), (37326, (3, PredictedToken(token=' Swe', prob=0.0458984375, logit=16.875, token_id=37326, metadata=None))), (26698, (5, PredictedToken(token=' Keyboard', prob=0.03564453125, logit=16.625, token_id=26698, metadata=None))), (24423, (12, PredictedToken(token=' Monitor', prob=0.0029296875, logit=14.125, token_id=24423, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.001220703125, logit=13.25, token_id=1183, metadata=None))), (5250, (75, PredictedToken(token=' Pe', prob=0.00012874603271484375, logit=11.0, token_id=5250, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:01 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:01 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.805, logit=20.500)', '\" Highlight\"[57094] (p=0.109, logit=18.500)', '\" The\"[578] (p=0.035, logit=17.375)', '\" A\"[362] (p=0.015, logit=16.500)', '\" None\"[2290] (p=0.003, logit=14.812)']\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.828, logit=20.875)', '\" The\"[578] (p=0.068, logit=18.375)', '\" Daisy\"[71264] (p=0.041, logit=17.875)', '\" jasmine\"[66909] (p=0.008, logit=16.250)', '\" There\"[2684] (p=0.006, logit=15.875)']\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.828125, logit=20.875, token_id=82452, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.041259765625, logit=17.875, token_id=71264, metadata=None))), (2522, (9, PredictedToken(token=' Sc', prob=0.003387451171875, logit=15.375, token_id=2522, metadata=None))), (30760, (19, PredictedToken(token=' Scar', prob=0.00070953369140625, logit=13.8125, token_id=30760, metadata=None))), (18343, (23, PredictedToken(token=' Paper', prob=0.000591278076171875, logit=13.625, token_id=18343, metadata=None)))])\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.598, logit=20.375)', '\" Sc\"[2522] (p=0.318, logit=19.750)', '\" The\"[578] (p=0.038, logit=17.625)', '\" A\"[362] (p=0.007, logit=15.938)', '\" There\"[2684] (p=0.004, logit=15.438)']\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.59765625, logit=20.375, token_id=18343, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.318359375, logit=19.75, token_id=2522, metadata=None))), (71264, (9, PredictedToken(token=' Daisy', prob=0.00167083740234375, logit=14.5, token_id=71264, metadata=None))), (30760, (11, PredictedToken(token=' Scar', prob=0.00122833251953125, logit=14.1875, token_id=30760, metadata=None))), (82452, (83, PredictedToken(token=' Jasmine', prob=4.744529724121094e-05, logit=10.9375, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:02 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:02 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:42:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.773, logit=20.000)', '\" Bus\"[19111] (p=0.063, logit=17.500)', '\" The\"[578] (p=0.063, logit=17.500)', '\" Ring\"[22249] (p=0.026, logit=16.625)', '\" A\"[362] (p=0.016, logit=16.125)']\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.707, logit=19.000)', '\" Ank\"[57915] (p=0.066, logit=16.625)', '\" The\"[578] (p=0.058, logit=16.500)', '\" CH\"[6969] (p=0.019, logit=15.375)', '\" AN\"[2147] (p=0.012, logit=14.938)']\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.70703125, logit=19.0, token_id=58600, metadata=None))), (57915, (2, PredictedToken(token=' Ank', prob=0.06591796875, logit=16.625, token_id=57915, metadata=None))), (13000, (7, PredictedToken(token=' Van', prob=0.00836181640625, logit=14.5625, token_id=13000, metadata=None))), (34785, (194, PredictedToken(token=' Truck', prob=4.38690185546875e-05, logit=9.3125, token_id=34785, metadata=None)))])\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.809, logit=20.250)', '\" VAN\"[97753] (p=0.096, logit=18.125)', '\" The\"[578] (p=0.021, logit=16.625)', '\" Truck\"[34785] (p=0.015, logit=16.250)', '\" van\"[5355] (p=0.007, logit=15.500)']\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.80859375, logit=20.25, token_id=13000, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.0147705078125, logit=16.25, token_id=34785, metadata=None))), (58600, (21, PredictedToken(token=' Charm', prob=0.000736236572265625, logit=13.25, token_id=58600, metadata=None))), (57915, (60, PredictedToken(token=' Ank', prob=9.965896606445312e-05, logit=11.25, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:03 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.887, logit=21.750)', '\" The\"[578] (p=0.064, logit=19.125)', '\" Caul\"[90538] (p=0.024, logit=18.125)', '\" There\"[2684] (p=0.005, logit=16.500)', '\" A\"[362] (p=0.002, logit=15.625)']\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     clean_prediction=['\" Sh\"[1443] (p=0.820, logit=20.500)', '\" SH\"[6570] (p=0.052, logit=17.750)', '\" The\"[578] (p=0.036, logit=17.375)', '\" L\"[445] (p=0.032, logit=17.250)', '\" None\"[2290] (p=0.005, logit=15.438)']\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     clean_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.8203125, logit=20.5, token_id=1443, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.03173828125, logit=17.25, token_id=445, metadata=None))), (6914, (9, PredictedToken(token=' Let', prob=0.003143310546875, logit=14.9375, token_id=6914, metadata=None))), (91297, (24, PredictedToken(token=' Mushroom', prob=0.000545501708984375, logit=13.1875, token_id=91297, metadata=None))), (16730, (466, PredictedToken(token=' Museum', prob=4.172325134277344e-06, logit=8.3125, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.836, logit=20.875)', '\" LET\"[36757] (p=0.047, logit=18.000)', '\" L\"[445] (p=0.032, logit=17.625)', '\" Mushroom\"[91297] (p=0.025, logit=17.375)', '\" The\"[578] (p=0.013, logit=16.750)']\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.8359375, logit=20.875, token_id=6914, metadata=None))), (445, (3, PredictedToken(token=' L', prob=0.032470703125, logit=17.625, token_id=445, metadata=None))), (91297, (4, PredictedToken(token=' Mushroom', prob=0.0252685546875, logit=17.375, token_id=91297, metadata=None))), (1443, (6, PredictedToken(token=' Sh', prob=0.010498046875, logit=16.5, token_id=1443, metadata=None))), (16730, (186, PredictedToken(token=' Museum', prob=1.0192394256591797e-05, logit=9.5625, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:04 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     patch_prediction=['\" To\"[2057] (p=0.766, logit=21.000)', '\" The\"[578] (p=0.091, logit=18.875)', '\" Oven\"[87213] (p=0.063, logit=18.500)', '\" TO\"[5257] (p=0.026, logit=17.625)', '\" A\"[362] (p=0.011, logit=16.750)']\n",
      "2025-09-15 09:42:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.824, logit=20.500)', '\" The\"[578] (p=0.098, logit=18.375)', '\" A\"[362] (p=0.015, logit=16.500)', '\" jacket\"[27300] (p=0.007, logit=15.750)', '\" Shorts\"[91782] (p=0.006, logit=15.625)']\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.82421875, logit=20.5, token_id=55870, metadata=None))), (91782, (5, PredictedToken(token=' Shorts', prob=0.00628662109375, logit=15.625, token_id=91782, metadata=None))), (48471, (7, PredictedToken(token=' Shower', prob=0.004302978515625, logit=15.25, token_id=48471, metadata=None))), (735, (12, PredictedToken(token=' K', prob=0.0016937255859375, logit=14.3125, token_id=735, metadata=None))), (88668, (307, PredictedToken(token=' Blender', prob=7.361173629760742e-06, logit=8.875, token_id=88668, metadata=None)))])\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     int_prediction=['\" K\"[735] (p=0.711, logit=20.000)', '\" Blender\"[88668] (p=0.084, logit=17.875)', '\" The\"[578] (p=0.075, logit=17.750)', '\" Shorts\"[91782] (p=0.040, logit=17.125)', '\" A\"[362] (p=0.010, logit=15.750)']\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     int_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.7109375, logit=20.0, token_id=735, metadata=None))), (88668, (2, PredictedToken(token=' Blender', prob=0.08447265625, logit=17.875, token_id=88668, metadata=None))), (91782, (4, PredictedToken(token=' Shorts', prob=0.0400390625, logit=17.125, token_id=91782, metadata=None))), (48471, (6, PredictedToken(token=' Shower', prob=0.0089111328125, logit=15.625, token_id=48471, metadata=None))), (55870, (7, PredictedToken(token=' Jacket', prob=0.00738525390625, logit=15.4375, token_id=55870, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:05 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:05 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     patch_prediction=['\" Spin\"[41785] (p=0.855, logit=20.625)', '\" The\"[578] (p=0.062, logit=18.000)', '\" SP\"[9440] (p=0.026, logit=17.125)', '\" As\"[1666] (p=0.018, logit=16.750)', '\" There\"[2684] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:42:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:06 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.586, logit=20.375)', '\" Pressure\"[40090] (p=0.215, logit=19.375)', '\" The\"[578] (p=0.115, logit=18.750)', '\" A\"[362] (p=0.026, logit=17.250)', '\" FOOD\"[88227] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:42:06 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.5859375, logit=20.375, token_id=12369, metadata=None))), (40090, (2, PredictedToken(token=' Pressure', prob=0.21484375, logit=19.375, token_id=40090, metadata=None))), (44570, (8, PredictedToken(token=' Maple', prob=0.00347900390625, logit=15.25, token_id=44570, metadata=None))), (6031, (10, PredictedToken(token=' Bro', prob=0.0030670166015625, logit=15.125, token_id=6031, metadata=None))), (91297, (27, PredictedToken(token=' Mushroom', prob=0.0004425048828125, logit=13.1875, token_id=91297, metadata=None))), (43316, (31, PredictedToken(token=' Tul', prob=0.00038909912109375, logit=13.0625, token_id=43316, metadata=None))), (9441, (356, PredictedToken(token=' Church', prob=4.32133674621582e-06, logit=8.5625, token_id=9441, metadata=None)))])\n",
      "2025-09-15 09:42:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:06 src.selection.optimization INFO     int_prediction=['\" Mushroom\"[91297] (p=0.412, logit=19.375)', '\" Maple\"[44570] (p=0.283, logit=19.000)', '\" The\"[578] (p=0.118, logit=18.125)', '\" Bro\"[6031] (p=0.081, logit=17.750)', '\" Tul\"[43316] (p=0.018, logit=16.250)']\n",
      "2025-09-15 09:42:06 src.selection.optimization INFO     int_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.412109375, logit=19.375, token_id=91297, metadata=None))), (44570, (2, PredictedToken(token=' Maple', prob=0.283203125, logit=19.0, token_id=44570, metadata=None))), (6031, (4, PredictedToken(token=' Bro', prob=0.0810546875, logit=17.75, token_id=6031, metadata=None))), (43316, (5, PredictedToken(token=' Tul', prob=0.01806640625, logit=16.25, token_id=43316, metadata=None))), (40090, (31, PredictedToken(token=' Pressure', prob=0.000453948974609375, logit=12.5625, token_id=40090, metadata=None))), (9441, (410, PredictedToken(token=' Church', prob=6.467103958129883e-06, logit=8.3125, token_id=9441, metadata=None))), (12369, (432, PredictedToken(token=' Food', prob=6.079673767089844e-06, logit=8.25, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:06 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:06 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:42:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.613, logit=20.000)', '\" The\"[578] (p=0.176, logit=18.750)', '\" Hick\"[79028] (p=0.073, logit=17.875)', '\" A\"[362] (p=0.039, logit=17.250)', '\" Bench\"[36358] (p=0.035, logit=17.125)']\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     clean_prediction=['\" Television\"[41445] (p=0.684, logit=20.375)', '\" Monitor\"[24423] (p=0.195, logit=19.125)', '\" The\"[578] (p=0.044, logit=17.625)', '\" MON\"[29637] (p=0.018, logit=16.750)', '\" None\"[2290] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     clean_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.68359375, logit=20.375, token_id=41445, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.1953125, logit=19.125, token_id=24423, metadata=None))), (58937, (112, PredictedToken(token=' Monkey', prob=4.2438507080078125e-05, logit=10.6875, token_id=58937, metadata=None))), (29318, (215, PredictedToken(token=' Dress', prob=1.4662742614746094e-05, logit=9.625, token_id=29318, metadata=None))), (61948, (216, PredictedToken(token=' Sofa', prob=1.4662742614746094e-05, logit=9.625, token_id=61948, metadata=None))), (98028, (1525, PredictedToken(token=' Bamboo', prob=7.301568984985352e-07, logit=6.625, token_id=98028, metadata=None)))])\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     int_prediction=['\" Sofa\"[61948] (p=0.523, logit=19.000)', '\" Dress\"[29318] (p=0.150, logit=17.750)', '\" The\"[578] (p=0.091, logit=17.250)', '\" SO\"[5745] (p=0.081, logit=17.125)', '\" Television\"[41445] (p=0.020, logit=15.750)']\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     int_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.5234375, logit=19.0, token_id=61948, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.150390625, logit=17.75, token_id=29318, metadata=None))), (41445, (5, PredictedToken(token=' Television', prob=0.0203857421875, logit=15.75, token_id=41445, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.0115966796875, logit=15.1875, token_id=24423, metadata=None))), (58937, (39, PredictedToken(token=' Monkey', prob=0.00054168701171875, logit=12.125, token_id=58937, metadata=None))), (98028, (78, PredictedToken(token=' Bamboo', prob=0.00019931793212890625, logit=11.125, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:07 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:42:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     patch_prediction=['\" Television\"[41445] (p=0.773, logit=21.000)', '\" Printer\"[47033] (p=0.104, logit=19.000)', '\" The\"[578] (p=0.063, logit=18.500)', '\" TELE\"[90340] (p=0.009, logit=16.500)', '\" A\"[362] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.758, logit=19.875)', '\" The\"[578] (p=0.103, logit=17.875)', '\" Pants\"[67553] (p=0.029, logit=16.625)', '\" A\"[362] (p=0.018, logit=16.125)', '\" CO\"[7432] (p=0.014, logit=15.875)']\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.7578125, logit=19.875, token_id=68867, metadata=None))), (67553, (3, PredictedToken(token=' Pants', prob=0.029296875, logit=16.625, token_id=67553, metadata=None))), (18787, (6, PredictedToken(token=' Oak', prob=0.01080322265625, logit=15.625, token_id=18787, metadata=None))), (14669, (76, PredictedToken(token=' Camera', prob=0.00014495849609375, logit=11.3125, token_id=14669, metadata=None))), (30173, (150, PredictedToken(token=' Speaker', prob=4.1484832763671875e-05, logit=10.0625, token_id=30173, metadata=None)))])\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.887, logit=20.500)', '\" The\"[578] (p=0.034, logit=17.250)', '\" Camera\"[14669] (p=0.014, logit=16.375)', '\" SPE\"[68835] (p=0.013, logit=16.250)', '\" speaker\"[19114] (p=0.006, logit=15.500)']\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.88671875, logit=20.5, token_id=30173, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.01434326171875, logit=16.375, token_id=14669, metadata=None))), (67553, (7, PredictedToken(token=' Pants', prob=0.0031890869140625, logit=14.875, token_id=67553, metadata=None))), (18787, (54, PredictedToken(token=' Oak', prob=0.0001316070556640625, logit=11.6875, token_id=18787, metadata=None))), (68867, (60, PredictedToken(token=' Coat', prob=0.0001163482666015625, logit=11.5625, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:08 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:42:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     patch_prediction=['\" Guitar\"[47759] (p=0.719, logit=20.250)', '\" The\"[578] (p=0.160, logit=18.750)', '\" G\"[480] (p=0.036, logit=17.250)', '\" Piano\"[56491] (p=0.017, logit=16.500)', '\" A\"[362] (p=0.007, logit=15.625)']\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     clean_prediction=['\" Train\"[27217] (p=0.801, logit=20.125)', '\" The\"[578] (p=0.108, logit=18.125)', '\" A\"[362] (p=0.011, logit=15.875)', '\" TRAIN\"[68609] (p=0.011, logit=15.812)', '\" There\"[2684] (p=0.010, logit=15.750)']\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     clean_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.80078125, logit=20.125, token_id=27217, metadata=None))), (1183, (6, PredictedToken(token=' Tr', prob=0.00787353515625, logit=15.5, token_id=1183, metadata=None))), (1630, (9, PredictedToken(token=' X', prob=0.0023956298828125, logit=14.3125, token_id=1630, metadata=None))), (3420, (66, PredictedToken(token=' Trump', prob=9.870529174804688e-05, logit=11.125, token_id=3420, metadata=None)))])\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.781, logit=20.125)', '\" The\"[578] (p=0.093, logit=18.000)', '\" Train\"[27217] (p=0.030, logit=16.875)', '\" There\"[2684] (p=0.018, logit=16.375)', '\" None\"[2290] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.78125, logit=20.125, token_id=1630, metadata=None))), (27217, (3, PredictedToken(token=' Train', prob=0.0302734375, logit=16.875, token_id=27217, metadata=None))), (1183, (7, PredictedToken(token=' Tr', prob=0.005584716796875, logit=15.1875, token_id=1183, metadata=None))), (3420, (21, PredictedToken(token=' Trump', prob=0.0010986328125, logit=13.5625, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:09 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.475, logit=18.500)', '\" Palm\"[33578] (p=0.287, logit=18.000)', '\" Monitor\"[24423] (p=0.064, logit=16.500)', '\" The\"[578] (p=0.064, logit=16.500)', '\" There\"[2684] (p=0.013, logit=14.875)']\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     clean_prediction=['\" Theater\"[38571] (p=0.750, logit=19.500)', '\" The\"[578] (p=0.102, logit=17.500)', '\" Bamboo\"[98028] (p=0.020, logit=15.875)', '\" Museum\"[16730] (p=0.018, logit=15.750)', '\" Smart\"[16147] (p=0.012, logit=15.375)']\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     clean_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.75, logit=19.5, token_id=38571, metadata=None))), (98028, (3, PredictedToken(token=' Bamboo', prob=0.02001953125, logit=15.875, token_id=98028, metadata=None))), (16730, (4, PredictedToken(token=' Museum', prob=0.0177001953125, logit=15.75, token_id=16730, metadata=None))), (65449, (6, PredictedToken(token=' Willow', prob=0.01214599609375, logit=15.375, token_id=65449, metadata=None))), (16147, (5, PredictedToken(token=' Smart', prob=0.01214599609375, logit=15.375, token_id=16147, metadata=None)))])\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     int_prediction=['\" Bamboo\"[98028] (p=0.504, logit=18.375)', '\" Willow\"[65449] (p=0.307, logit=17.875)', '\" The\"[578] (p=0.034, logit=15.688)', '\" Museum\"[16730] (p=0.027, logit=15.438)', '\" None\"[2290] (p=0.015, logit=14.875)']\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     int_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.50390625, logit=18.375, token_id=98028, metadata=None))), (65449, (2, PredictedToken(token=' Willow', prob=0.306640625, logit=17.875, token_id=65449, metadata=None))), (16730, (4, PredictedToken(token=' Museum', prob=0.0267333984375, logit=15.4375, token_id=16730, metadata=None))), (16147, (6, PredictedToken(token=' Smart', prob=0.01263427734375, logit=14.6875, token_id=16147, metadata=None))), (38571, (10, PredictedToken(token=' Theater', prob=0.0036163330078125, logit=13.4375, token_id=38571, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:10 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:10 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:42:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.516, logit=19.750)', '\" Warehouse\"[52466] (p=0.312, logit=19.250)', '\" The\"[578] (p=0.061, logit=17.625)', '\" A\"[362] (p=0.048, logit=17.375)', '\" None\"[2290] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.508, logit=18.625)', '\" The\"[578] (p=0.240, logit=17.875)', '\" Jacket\"[55870] (p=0.042, logit=16.125)', '\" SHORT\"[66024] (p=0.035, logit=15.938)', '\" Short\"[10928] (p=0.014, logit=15.000)']\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.5078125, logit=18.625, token_id=91782, metadata=None))), (55870, (3, PredictedToken(token=' Jacket', prob=0.041748046875, logit=16.125, token_id=55870, metadata=None))), (58251, (17, PredictedToken(token=' Tennis', prob=0.0038909912109375, logit=13.75, token_id=58251, metadata=None))), (6150, (58, PredictedToken(token=' School', prob=0.0004367828369140625, logit=11.5625, token_id=6150, metadata=None))), (32498, (96, PredictedToken(token=' Mall', prob=0.00019359588623046875, logit=10.75, token_id=32498, metadata=None)))])\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.824, logit=20.000)', '\" The\"[578] (p=0.068, logit=17.500)', '\" Tennis\"[58251] (p=0.017, logit=16.125)', '\" SCHOOL\"[71501] (p=0.015, logit=16.000)', '\" Mall\"[32498] (p=0.012, logit=15.750)']\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.82421875, logit=20.0, token_id=6150, metadata=None))), (58251, (3, PredictedToken(token=' Tennis', prob=0.01708984375, logit=16.125, token_id=58251, metadata=None))), (32498, (5, PredictedToken(token=' Mall', prob=0.01177978515625, logit=15.75, token_id=32498, metadata=None))), (55870, (17, PredictedToken(token=' Jacket', prob=0.0010986328125, logit=13.375, token_id=55870, metadata=None))), (91782, (32, PredictedToken(token=' Shorts', prob=0.0004291534423828125, logit=12.4375, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:11 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:11 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:42:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.742, logit=20.500)', '\" Football\"[21424] (p=0.129, logit=18.750)', '\" The\"[578] (p=0.069, logit=18.125)', '\" S\"[328] (p=0.006, logit=15.625)', '\" BOX\"[53783] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     clean_prediction=['\" Carn\"[32749] (p=0.691, logit=20.375)', '\" The\"[578] (p=0.154, logit=18.875)', '\" Daisy\"[71264] (p=0.050, logit=17.750)', '\" A\"[362] (p=0.044, logit=17.625)', '\" C\"[356] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     clean_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.69140625, logit=20.375, token_id=32749, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.050048828125, logit=17.75, token_id=71264, metadata=None))), (4923, (12, PredictedToken(token=' Sk', prob=0.00160980224609375, logit=14.3125, token_id=4923, metadata=None))), (61731, (40, PredictedToken(token=' Soap', prob=0.0001697540283203125, logit=12.0625, token_id=61731, metadata=None))), (38258, (80, PredictedToken(token=' Baseball', prob=6.67572021484375e-05, logit=11.125, token_id=38258, metadata=None))), (87213, (277, PredictedToken(token=' Oven', prob=9.000301361083984e-06, logit=9.125, token_id=87213, metadata=None))), (55870, (288, PredictedToken(token=' Jacket', prob=8.463859558105469e-06, logit=9.0625, token_id=55870, metadata=None)))])\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.365, logit=18.250)', '\" Baseball\"[38258] (p=0.365, logit=18.250)', '\" The\"[578] (p=0.072, logit=16.625)', '\" There\"[2684] (p=0.023, logit=15.500)', '\" Oven\"[87213] (p=0.018, logit=15.250)']\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     int_track=OrderedDict([(38258, (2, PredictedToken(token=' Baseball', prob=0.365234375, logit=18.25, token_id=38258, metadata=None))), (4923, (1, PredictedToken(token=' Sk', prob=0.365234375, logit=18.25, token_id=4923, metadata=None))), (87213, (5, PredictedToken(token=' Oven', prob=0.0181884765625, logit=15.25, token_id=87213, metadata=None))), (55870, (6, PredictedToken(token=' Jacket', prob=0.01708984375, logit=15.1875, token_id=55870, metadata=None))), (61731, (9, PredictedToken(token=' Soap', prob=0.0103759765625, logit=14.6875, token_id=61731, metadata=None))), (71264, (19, PredictedToken(token=' Daisy', prob=0.0027923583984375, logit=13.375, token_id=71264, metadata=None))), (32749, (133, PredictedToken(token=' Carn', prob=7.43865966796875e-05, logit=9.75, token_id=32749, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:12 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:12 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:42:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.812, logit=20.375)', '\" The\"[578] (p=0.076, logit=18.000)', '\" Oven\"[87213] (p=0.025, logit=16.875)', '\" A\"[362] (p=0.013, logit=16.250)', '\" None\"[2290] (p=0.012, logit=16.125)']\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     clean_prediction=['\" Sofa\"[61948] (p=0.609, logit=19.500)', '\" The\"[578] (p=0.225, logit=18.500)', '\" A\"[362] (p=0.044, logit=16.875)', '\" SO\"[5745] (p=0.012, logit=15.562)', '\" It\"[1102] (p=0.012, logit=15.562)']\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     clean_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.609375, logit=19.5, token_id=61948, metadata=None))), (6017, (7, PredictedToken(token=' Book', prob=0.0076904296875, logit=15.125, token_id=6017, metadata=None))), (12369, (98, PredictedToken(token=' Food', prob=8.535385131835938e-05, logit=10.625, token_id=12369, metadata=None))), (30616, (143, PredictedToken(token=' Rice', prob=4.57763671875e-05, logit=10.0, token_id=30616, metadata=None)))])\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.408, logit=18.125)', '\" Food\"[12369] (p=0.361, logit=18.000)', '\" The\"[578] (p=0.104, logit=16.750)', '\" A\"[362] (p=0.019, logit=15.062)', '\" It\"[1102] (p=0.012, logit=14.562)']\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.408203125, logit=18.125, token_id=30616, metadata=None))), (12369, (2, PredictedToken(token=' Food', prob=0.361328125, logit=18.0, token_id=12369, metadata=None))), (6017, (12, PredictedToken(token=' Book', prob=0.0037689208984375, logit=13.4375, token_id=6017, metadata=None))), (61948, (25, PredictedToken(token=' Sofa', prob=0.000949859619140625, logit=12.0625, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:13 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:13 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:42:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     patch_prediction=['\" Amb\"[20423] (p=0.699, logit=20.125)', '\" An\"[1556] (p=0.107, logit=18.250)', '\" The\"[578] (p=0.095, logit=18.125)', '\" Y\"[816] (p=0.024, logit=16.750)', '\" There\"[2684] (p=0.013, logit=16.125)']\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.812, logit=20.375)', '\" The\"[578] (p=0.085, logit=18.125)', '\" Magn\"[20918] (p=0.025, logit=16.875)', '\" There\"[2684] (p=0.013, logit=16.250)', '\" Let\"[6914] (p=0.010, logit=16.000)']\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.8125, logit=20.375, token_id=14937, metadata=None))), (20918, (3, PredictedToken(token=' Magn', prob=0.0245361328125, logit=16.875, token_id=20918, metadata=None))), (6914, (5, PredictedToken(token=' Let', prob=0.01019287109375, logit=16.0, token_id=6914, metadata=None))), (19111, (10, PredictedToken(token=' Bus', prob=0.0025787353515625, logit=14.625, token_id=19111, metadata=None))), (72392, (50, PredictedToken(token=' Mixer', prob=0.00019931793212890625, logit=12.0625, token_id=72392, metadata=None))), (27217, (156, PredictedToken(token=' Train', prob=2.5272369384765625e-05, logit=10.0, token_id=27217, metadata=None)))])\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.836, logit=20.750)', '\" The\"[578] (p=0.047, logit=17.875)', '\" BUS\"[23504] (p=0.032, logit=17.500)', '\" None\"[2290] (p=0.011, logit=16.375)', '\" A\"[362] (p=0.011, logit=16.375)']\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.8359375, logit=20.75, token_id=19111, metadata=None))), (27217, (7, PredictedToken(token=' Train', prob=0.00823974609375, logit=16.125, token_id=27217, metadata=None))), (14937, (8, PredictedToken(token=' Ash', prob=0.006011962890625, logit=15.8125, token_id=14937, metadata=None))), (6914, (9, PredictedToken(token=' Let', prob=0.005645751953125, logit=15.75, token_id=6914, metadata=None))), (72392, (10, PredictedToken(token=' Mixer', prob=0.002838134765625, logit=15.0625, token_id=72392, metadata=None))), (20918, (15, PredictedToken(token=' Magn', prob=0.00125885009765625, logit=14.25, token_id=20918, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:14 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:42:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.516, logit=18.625)', '\" School\"[6150] (p=0.148, logit=17.375)', '\" The\"[578] (p=0.131, logit=17.250)', '\" A\"[362] (p=0.029, logit=15.750)', '\" Palm\"[33578] (p=0.024, logit=15.562)']\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.762, logit=19.625)', '\" Spr\"[15883] (p=0.103, logit=17.625)', '\" The\"[578] (p=0.049, logit=16.875)', '\" Library\"[11896] (p=0.012, logit=15.500)', '\" There\"[2684] (p=0.012, logit=15.438)']\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.76171875, logit=19.625, token_id=14937, metadata=None))), (15883, (2, PredictedToken(token=' Spr', prob=0.10302734375, logit=17.625, token_id=15883, metadata=None))), (11896, (4, PredictedToken(token=' Library', prob=0.0123291015625, logit=15.5, token_id=11896, metadata=None))), (27171, (24, PredictedToken(token=' Coffee', prob=0.00069427490234375, logit=12.625, token_id=27171, metadata=None))), (16730, (50, PredictedToken(token=' Museum', prob=0.0002117156982421875, logit=11.4375, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.637, logit=19.750)', '\" Spr\"[15883] (p=0.125, logit=18.125)', '\" The\"[578] (p=0.086, logit=17.750)', '\" Coffee\"[27171] (p=0.028, logit=16.625)', '\" Library\"[11896] (p=0.028, logit=16.625)']\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.63671875, logit=19.75, token_id=16730, metadata=None))), (15883, (2, PredictedToken(token=' Spr', prob=0.125, logit=18.125, token_id=15883, metadata=None))), (11896, (4, PredictedToken(token=' Library', prob=0.0279541015625, logit=16.625, token_id=11896, metadata=None))), (27171, (5, PredictedToken(token=' Coffee', prob=0.0279541015625, logit=16.625, token_id=27171, metadata=None))), (14937, (8, PredictedToken(token=' Ash', prob=0.00799560546875, logit=15.375, token_id=14937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:15 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:42:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.926, logit=22.500)', '\" The\"[578] (p=0.032, logit=19.125)', '\" Car\"[3341] (p=0.025, logit=18.875)', '\" There\"[2684] (p=0.004, logit=17.000)', '\" CA\"[9362] (p=0.002, logit=16.500)']\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.482, logit=19.500)', '\" The\"[578] (p=0.332, logit=19.125)', '\" Laptop\"[57225] (p=0.035, logit=16.875)', '\" TABLE\"[14700] (p=0.024, logit=16.500)', '\" A\"[362] (p=0.015, logit=16.000)']\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.482421875, logit=19.5, token_id=58403, metadata=None))), (57225, (3, PredictedToken(token=' Laptop', prob=0.034912109375, logit=16.875, token_id=57225, metadata=None))), (1666, (8, PredictedToken(token=' As', prob=0.007354736328125, logit=15.3125, token_id=1666, metadata=None))), (34954, (45, PredictedToken(token=' Mirror', prob=0.0004138946533203125, logit=12.4375, token_id=34954, metadata=None))), (52882, (57, PredictedToken(token=' Pepper', prob=0.00034332275390625, logit=12.25, token_id=52882, metadata=None)))])\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.781, logit=20.250)', '\" The\"[578] (p=0.106, logit=18.250)', '\" As\"[1666] (p=0.021, logit=16.625)', '\" PE\"[22557] (p=0.010, logit=15.938)', '\" There\"[2684] (p=0.009, logit=15.812)']\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.78125, logit=20.25, token_id=52882, metadata=None))), (1666, (3, PredictedToken(token=' As', prob=0.0208740234375, logit=16.625, token_id=1666, metadata=None))), (57225, (6, PredictedToken(token=' Laptop', prob=0.0086669921875, logit=15.75, token_id=57225, metadata=None))), (34954, (7, PredictedToken(token=' Mirror', prob=0.0059814453125, logit=15.375, token_id=34954, metadata=None))), (58403, (25, PredictedToken(token=' Tablet', prob=0.000713348388671875, logit=13.25, token_id=58403, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:16 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:42:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     patch_prediction=['\" P\"[393] (p=0.711, logit=20.000)', '\" The\"[578] (p=0.096, logit=18.000)', '\" A\"[362] (p=0.059, logit=17.500)', '\" Paper\"[18343] (p=0.046, logit=17.250)', '\" There\"[2684] (p=0.008, logit=15.562)']\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     clean_prediction=['\" Sco\"[50159] (p=0.820, logit=20.625)', '\" The\"[578] (p=0.076, logit=18.250)', '\" A\"[362] (p=0.036, logit=17.500)', '\" scooter\"[76140] (p=0.013, logit=16.500)', '\" Bike\"[38930] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     clean_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.8203125, logit=20.625, token_id=50159, metadata=None))), (38930, (5, PredictedToken(token=' Bike', prob=0.01171875, logit=16.375, token_id=38930, metadata=None))), (2947, (19, PredictedToken(token=' Mar', prob=0.000659942626953125, logit=13.5, token_id=2947, metadata=None))), (2522, (24, PredictedToken(token=' Sc', prob=0.000453948974609375, logit=13.125, token_id=2522, metadata=None))), (22410, (34, PredictedToken(token=' Ju', prob=0.000274658203125, logit=12.625, token_id=22410, metadata=None))), (13597, (53, PredictedToken(token=' Pen', prob=0.00012969970703125, logit=11.875, token_id=13597, metadata=None)))])\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.598, logit=19.500)', '\" The\"[578] (p=0.118, logit=17.875)', '\" Sc\"[2522] (p=0.063, logit=17.250)', '\" A\"[362] (p=0.063, logit=17.250)', '\" PEN\"[81770] (p=0.021, logit=16.125)']\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.59765625, logit=19.5, token_id=13597, metadata=None))), (2522, (4, PredictedToken(token=' Sc', prob=0.06298828125, logit=17.25, token_id=2522, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.01806640625, logit=16.0, token_id=38930, metadata=None))), (22410, (7, PredictedToken(token=' Ju', prob=0.0169677734375, logit=15.9375, token_id=22410, metadata=None))), (50159, (8, PredictedToken(token=' Sco', prob=0.01495361328125, logit=15.8125, token_id=50159, metadata=None))), (2947, (12, PredictedToken(token=' Mar', prob=0.00518798828125, logit=14.75, token_id=2947, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:17 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:17 src.selection.optimization DEBUG    torch.Size([7, 29])\n",
      "2025-09-15 09:42:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:18 src.selection.optimization INFO     patch_prediction=['\" Charm\"[58600] (p=0.809, logit=19.500)', '\" The\"[578] (p=0.059, logit=16.875)', '\" A\"[362] (p=0.023, logit=15.938)', '\" Pin\"[17929] (p=0.018, logit=15.688)', '\" There\"[2684] (p=0.010, logit=15.062)']\n",
      "2025-09-15 09:42:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:18 src.selection.optimization INFO     clean_prediction=['\" Er\"[9939] (p=0.684, logit=20.250)', '\" Paper\"[18343] (p=0.153, logit=18.750)', '\" The\"[578] (p=0.050, logit=17.625)', '\" An\"[1556] (p=0.030, logit=17.125)', '\" E\"[469] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:42:18 src.selection.optimization INFO     clean_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.68359375, logit=20.25, token_id=9939, metadata=None))), (18343, (2, PredictedToken(token=' Paper', prob=0.1533203125, logit=18.75, token_id=18343, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.0125732421875, logit=16.25, token_id=469, metadata=None))), (10573, (17, PredictedToken(token=' Watch', prob=0.00096893310546875, logit=13.6875, token_id=10573, metadata=None))), (16147, (20, PredictedToken(token=' Smart', prob=0.0008544921875, logit=13.5625, token_id=16147, metadata=None))), (55807, (50, PredictedToken(token=' Shirt', prob=0.00019073486328125, logit=12.0625, token_id=55807, metadata=None))), (91963, (110, PredictedToken(token=' Mango', prob=5.459785461425781e-05, logit=10.8125, token_id=91963, metadata=None)))])\n",
      "2025-09-15 09:42:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.746, logit=20.500)', '\" Paper\"[18343] (p=0.079, logit=18.250)', '\" Shirt\"[55807] (p=0.042, logit=17.625)', '\" The\"[578] (p=0.037, logit=17.500)', '\" Watch\"[10573] (p=0.014, logit=16.500)']\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.74609375, logit=20.5, token_id=469, metadata=None))), (18343, (2, PredictedToken(token=' Paper', prob=0.07861328125, logit=18.25, token_id=18343, metadata=None))), (55807, (3, PredictedToken(token=' Shirt', prob=0.0419921875, logit=17.625, token_id=55807, metadata=None))), (10573, (5, PredictedToken(token=' Watch', prob=0.01361083984375, logit=16.5, token_id=10573, metadata=None))), (9939, (12, PredictedToken(token=' Er', prob=0.0025177001953125, logit=14.8125, token_id=9939, metadata=None))), (16147, (31, PredictedToken(token=' Smart', prob=0.000362396240234375, logit=12.875, token_id=16147, metadata=None))), (91963, (35, PredictedToken(token=' Mango', prob=0.000301361083984375, logit=12.6875, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:19 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     patch_prediction=['\" Drum\"[46506] (p=0.691, logit=19.500)', '\" The\"[578] (p=0.154, logit=18.000)', '\" DR\"[14644] (p=0.050, logit=16.875)', '\" Clar\"[31181] (p=0.012, logit=15.438)', '\" A\"[362] (p=0.011, logit=15.375)']\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     clean_prediction=['\" Raspberry\"[48665] (p=0.621, logit=18.875)', '\" Pear\"[23910] (p=0.178, logit=17.625)', '\" The\"[578] (p=0.051, logit=16.375)', '\" C\"[356] (p=0.019, logit=15.375)', '\" Apple\"[8325] (p=0.016, logit=15.188)']\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     clean_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.62109375, logit=18.875, token_id=48665, metadata=None))), (23910, (2, PredictedToken(token=' Pear', prob=0.177734375, logit=17.625, token_id=23910, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.018798828125, logit=15.375, token_id=356, metadata=None))), (56491, (69, PredictedToken(token=' Piano', prob=0.00023651123046875, logit=11.0, token_id=56491, metadata=None)))])\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.414, logit=18.000)', '\" C\"[356] (p=0.285, logit=17.625)', '\" The\"[578] (p=0.056, logit=16.000)', '\" Raspberry\"[48665] (p=0.044, logit=15.750)', '\" Pine\"[42609] (p=0.022, logit=15.062)']\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.4140625, logit=18.0, token_id=56491, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.28515625, logit=17.625, token_id=356, metadata=None))), (48665, (4, PredictedToken(token=' Raspberry', prob=0.043701171875, logit=15.75, token_id=48665, metadata=None))), (23910, (10, PredictedToken(token=' Pear', prob=0.00714111328125, logit=13.9375, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:19 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:42:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:20 src.selection.optimization INFO     patch_prediction=['\" Boat\"[45332] (p=0.707, logit=19.250)', '\" The\"[578] (p=0.096, logit=17.250)', '\" Caul\"[90538] (p=0.040, logit=16.375)', '\" BO\"[7967] (p=0.024, logit=15.875)', '\" There\"[2684] (p=0.020, logit=15.688)']\n",
      "2025-09-15 09:42:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:20 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.574, logit=19.375)', '\" Cel\"[47643] (p=0.113, logit=17.750)', '\" The\"[578] (p=0.113, logit=17.750)', '\" There\"[2684] (p=0.078, logit=17.375)', '\" None\"[2290] (p=0.022, logit=16.125)']\n",
      "2025-09-15 09:42:20 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.57421875, logit=19.375, token_id=87035, metadata=None))), (47643, (3, PredictedToken(token=' Cel', prob=0.11279296875, logit=17.75, token_id=47643, metadata=None))), (34785, (10, PredictedToken(token=' Truck', prob=0.0038604736328125, logit=14.375, token_id=34785, metadata=None))), (70762, (13, PredictedToken(token=' Motorcycle', prob=0.0030059814453125, logit=14.125, token_id=70762, metadata=None)))])\n",
      "2025-09-15 09:42:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.641, logit=19.500)', '\" Truck\"[34785] (p=0.098, logit=17.625)', '\" The\"[578] (p=0.067, logit=17.250)', '\" There\"[2684] (p=0.060, logit=17.125)', '\" None\"[2290] (p=0.032, logit=16.500)']\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.640625, logit=19.5, token_id=70762, metadata=None))), (34785, (2, PredictedToken(token=' Truck', prob=0.09814453125, logit=17.625, token_id=34785, metadata=None))), (47643, (6, PredictedToken(token=' Cel', prob=0.019287109375, logit=16.0, token_id=47643, metadata=None))), (87035, (13, PredictedToken(token=' Onion', prob=0.0026092529296875, logit=14.0, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:21 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.859, logit=19.750)', '\" The\"[578] (p=0.062, logit=17.125)', '\" A\"[362] (p=0.013, logit=15.562)', '\" Monitor\"[24423] (p=0.005, logit=14.688)', '\" It\"[1102] (p=0.005, logit=14.688)']\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     clean_prediction=['\" Mall\"[32498] (p=0.270, logit=17.250)', '\" Laptop\"[57225] (p=0.237, logit=17.125)', '\" The\"[578] (p=0.163, logit=16.750)', '\" Head\"[11452] (p=0.087, logit=16.125)', '\" Factory\"[17367] (p=0.064, logit=15.812)']\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     clean_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.26953125, logit=17.25, token_id=32498, metadata=None))), (57225, (2, PredictedToken(token=' Laptop', prob=0.2373046875, logit=17.125, token_id=57225, metadata=None))), (11452, (4, PredictedToken(token=' Head', prob=0.08740234375, logit=16.125, token_id=11452, metadata=None))), (17367, (5, PredictedToken(token=' Factory', prob=0.06396484375, logit=15.8125, token_id=17367, metadata=None)))])\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     int_prediction=['\" Head\"[11452] (p=0.719, logit=18.750)', '\" HEAD\"[34180] (p=0.059, logit=16.250)', '\" The\"[578] (p=0.059, logit=16.250)', '\" Laptop\"[57225] (p=0.023, logit=15.312)', '\" Mall\"[32498] (p=0.017, logit=15.000)']\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     int_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.71875, logit=18.75, token_id=11452, metadata=None))), (57225, (4, PredictedToken(token=' Laptop', prob=0.0230712890625, logit=15.3125, token_id=57225, metadata=None))), (32498, (5, PredictedToken(token=' Mall', prob=0.016845703125, logit=15.0, token_id=32498, metadata=None))), (17367, (6, PredictedToken(token=' Factory', prob=0.014892578125, logit=14.875, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:21 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:42:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.754, logit=20.750)', '\" Boxing\"[72683] (p=0.148, logit=19.125)', '\" The\"[578] (p=0.048, logit=18.000)', '\" A\"[362] (p=0.008, logit=16.250)', '\" FOOT\"[81137] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.848, logit=20.750)', '\" The\"[578] (p=0.054, logit=18.000)', '\" R\"[432] (p=0.020, logit=17.000)', '\" E\"[469] (p=0.018, logit=16.875)', '\" SPR\"[52367] (p=0.016, logit=16.750)']\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.84765625, logit=20.75, token_id=15883, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.0198974609375, logit=17.0, token_id=432, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.017578125, logit=16.875, token_id=469, metadata=None))), (22410, (18, PredictedToken(token=' Ju', prob=0.00077056884765625, logit=13.75, token_id=22410, metadata=None))), (4923, (19, PredictedToken(token=' Sk', prob=0.00067901611328125, logit=13.625, token_id=4923, metadata=None)))])\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.820, logit=20.375)', '\" The\"[578] (p=0.060, logit=17.750)', '\" Spr\"[15883] (p=0.036, logit=17.250)', '\" A\"[362] (p=0.028, logit=17.000)', '\" E\"[469] (p=0.009, logit=15.812)']\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.8203125, logit=20.375, token_id=432, metadata=None))), (15883, (3, PredictedToken(token=' Spr', prob=0.0361328125, logit=17.25, token_id=15883, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.008544921875, logit=15.8125, token_id=469, metadata=None))), (4923, (14, PredictedToken(token=' Sk', prob=0.0012359619140625, logit=13.875, token_id=4923, metadata=None))), (22410, (16, PredictedToken(token=' Ju', prob=0.0009613037109375, logit=13.625, token_id=22410, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:22 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:23 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.424, logit=19.250)', '\" Cow\"[22607] (p=0.373, logit=19.125)', '\" The\"[578] (p=0.065, logit=17.375)', '\" E\"[469] (p=0.024, logit=16.375)', '\" An\"[1556] (p=0.019, logit=16.125)']\n",
      "2025-09-15 09:42:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:23 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.914, logit=21.625)', '\" The\"[578] (p=0.046, logit=18.625)', '\" Ch\"[921] (p=0.012, logit=17.250)', '\" V\"[650] (p=0.005, logit=16.375)', '\" There\"[2684] (p=0.003, logit=15.812)']\n",
      "2025-09-15 09:42:23 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.9140625, logit=21.625, token_id=74574, metadata=None))), (921, (3, PredictedToken(token=' Ch', prob=0.01153564453125, logit=17.25, token_id=921, metadata=None))), (1901, (32, PredictedToken(token=' Z', prob=0.000164031982421875, logit=13.0, token_id=1901, metadata=None))), (24941, (53, PredictedToken(token=' Bear', prob=6.031990051269531e-05, logit=12.0, token_id=24941, metadata=None))), (83499, (217, PredictedToken(token=' Tooth', prob=5.990266799926758e-06, logit=9.6875, token_id=83499, metadata=None)))])\n",
      "2025-09-15 09:42:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.777, logit=20.500)', '\" The\"[578] (p=0.105, logit=18.500)', '\" A\"[362] (p=0.039, logit=17.500)', '\" BE\"[7354] (p=0.021, logit=16.875)', '\" There\"[2684] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.77734375, logit=20.5, token_id=24941, metadata=None))), (74574, (6, PredictedToken(token=' Violet', prob=0.004364013671875, logit=15.3125, token_id=74574, metadata=None))), (1901, (21, PredictedToken(token=' Z', prob=0.000911712646484375, logit=13.75, token_id=1901, metadata=None))), (921, (70, PredictedToken(token=' Ch', prob=7.963180541992188e-05, logit=11.3125, token_id=921, metadata=None))), (83499, (111, PredictedToken(token=' Tooth', prob=3.7670135498046875e-05, logit=10.5625, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:24 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:24 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     patch_prediction=['\" Tie\"[59825] (p=0.715, logit=20.250)', '\" The\"[578] (p=0.124, logit=18.500)', '\" A\"[362] (p=0.085, logit=18.125)', '\" Sk\"[4923] (p=0.024, logit=16.875)', '\" T\"[350] (p=0.007, logit=15.625)']\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.520, logit=20.625)', '\" Bro\"[6031] (p=0.279, logit=20.000)', '\" The\"[578] (p=0.132, logit=19.250)', '\" There\"[2684] (p=0.026, logit=17.625)', '\" CAR\"[28876] (p=0.005, logit=15.938)']\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.51953125, logit=20.625, token_id=3341, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.279296875, logit=20.0, token_id=6031, metadata=None))), (19111, (68, PredictedToken(token=' Bus', prob=6.866455078125e-05, logit=11.6875, token_id=19111, metadata=None))), (22050, (108, PredictedToken(token=' Hat', prob=3.24249267578125e-05, logit=10.9375, token_id=22050, metadata=None))), (29318, (181, PredictedToken(token=' Dress', prob=1.2636184692382812e-05, logit=10.0, token_id=29318, metadata=None))), (67629, (797, PredictedToken(token=' Helmet', prob=1.1771917343139648e-06, logit=7.625, token_id=67629, metadata=None)))])\n",
      "2025-09-15 09:42:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.566, logit=20.375)', '\" The\"[578] (p=0.208, logit=19.375)', '\" Hat\"[22050] (p=0.060, logit=18.125)', '\" There\"[2684] (p=0.060, logit=18.125)', '\" Car\"[3341] (p=0.017, logit=16.875)']\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.56640625, logit=20.375, token_id=29318, metadata=None))), (22050, (4, PredictedToken(token=' Hat', prob=0.0595703125, logit=18.125, token_id=22050, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.01708984375, logit=16.875, token_id=3341, metadata=None))), (67629, (6, PredictedToken(token=' Helmet', prob=0.01708984375, logit=16.875, token_id=67629, metadata=None))), (19111, (9, PredictedToken(token=' Bus', prob=0.006683349609375, logit=15.9375, token_id=19111, metadata=None))), (6031, (12, PredictedToken(token=' Bro', prob=0.002777099609375, logit=15.0625, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:25 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     patch_prediction=['\" Sco\"[50159] (p=0.527, logit=19.875)', '\" The\"[578] (p=0.194, logit=18.875)', '\" Amb\"[20423] (p=0.151, logit=18.625)', '\" An\"[1556] (p=0.038, logit=17.250)', '\" There\"[2684] (p=0.026, logit=16.875)']\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     clean_prediction=['\" Swe\"[37326] (p=0.797, logit=20.500)', '\" The\"[578] (p=0.108, logit=18.500)', '\" A\"[362] (p=0.031, logit=17.250)', '\" Shirt\"[55807] (p=0.008, logit=15.875)', '\" S\"[328] (p=0.007, logit=15.812)']\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     clean_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.796875, logit=20.5, token_id=37326, metadata=None))), (55807, (4, PredictedToken(token=' Shirt', prob=0.0078125, logit=15.875, token_id=55807, metadata=None))), (19111, (12, PredictedToken(token=' Bus', prob=0.00127410888671875, logit=14.0625, token_id=19111, metadata=None))), (3804, (16, PredictedToken(token=' Sub', prob=0.00106048583984375, logit=13.875, token_id=3804, metadata=None))), (91297, (31, PredictedToken(token=' Mushroom', prob=0.00034332275390625, logit=12.75, token_id=91297, metadata=None)))])\n",
      "2025-09-15 09:42:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.707, logit=20.500)', '\" Sub\"[3804] (p=0.096, logit=18.500)', '\" The\"[578] (p=0.075, logit=18.250)', '\" Swe\"[37326] (p=0.031, logit=17.375)', '\" BUS\"[23504] (p=0.027, logit=17.250)']\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.70703125, logit=20.5, token_id=19111, metadata=None))), (3804, (2, PredictedToken(token=' Sub', prob=0.095703125, logit=18.5, token_id=3804, metadata=None))), (37326, (4, PredictedToken(token=' Swe', prob=0.031005859375, logit=17.375, token_id=37326, metadata=None))), (55807, (24, PredictedToken(token=' Shirt', prob=0.0004711151123046875, logit=13.1875, token_id=55807, metadata=None))), (91297, (32, PredictedToken(token=' Mushroom', prob=0.0003452301025390625, logit=12.875, token_id=91297, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:26 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.910, logit=21.750)', '\" The\"[578] (p=0.040, logit=18.625)', '\" Mushroom\"[91297] (p=0.021, logit=18.000)', '\" There\"[2684] (p=0.010, logit=17.250)', '\" None\"[2290] (p=0.002, logit=15.500)']\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     clean_prediction=['\" Pants\"[67553] (p=0.711, logit=20.250)', '\" Swe\"[37326] (p=0.109, logit=18.375)', '\" The\"[578] (p=0.109, logit=18.375)', '\" There\"[2684] (p=0.006, logit=15.500)', '\" Pant\"[54222] (p=0.004, logit=15.188)']\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     clean_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.7109375, logit=20.25, token_id=67553, metadata=None))), (37326, (3, PredictedToken(token=' Swe', prob=0.10888671875, logit=18.375, token_id=37326, metadata=None))), (70110, (10, PredictedToken(token=' Ottoman', prob=0.0030975341796875, logit=14.8125, token_id=70110, metadata=None))), (1666, (14, PredictedToken(token=' As', prob=0.00176239013671875, logit=14.25, token_id=1666, metadata=None))), (3341, (42, PredictedToken(token=' Car', prob=0.000270843505859375, logit=12.375, token_id=3341, metadata=None)))])\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     int_prediction=['\" As\"[1666] (p=0.824, logit=20.750)', '\" Swe\"[37326] (p=0.036, logit=17.625)', '\" The\"[578] (p=0.036, logit=17.625)', '\" Car\"[3341] (p=0.036, logit=17.625)', '\" AS\"[5871] (p=0.022, logit=17.125)']\n",
      "2025-09-15 09:42:26 src.selection.optimization INFO     int_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.82421875, logit=20.75, token_id=1666, metadata=None))), (37326, (4, PredictedToken(token=' Swe', prob=0.0361328125, logit=17.625, token_id=37326, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.0361328125, logit=17.625, token_id=3341, metadata=None))), (67553, (6, PredictedToken(token=' Pants', prob=0.008056640625, logit=16.125, token_id=67553, metadata=None))), (70110, (10, PredictedToken(token=' Ottoman', prob=0.00191497802734375, logit=14.6875, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:26 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:27 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.699, logit=19.500)', '\" Notebook\"[69755] (p=0.121, logit=17.750)', '\" A\"[362] (p=0.045, logit=16.750)', '\" The\"[578] (p=0.039, logit=16.625)', '\" PEN\"[81770] (p=0.027, logit=16.250)']\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.781, logit=20.500)', '\" The\"[578] (p=0.083, logit=18.250)', '\" Uk\"[60413] (p=0.064, logit=18.000)', '\" violin\"[63137] (p=0.009, logit=16.000)', '\" VI\"[30768] (p=0.007, logit=15.750)']\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.78125, logit=20.5, token_id=30555, metadata=None))), (60413, (3, PredictedToken(token=' Uk', prob=0.064453125, logit=18.0, token_id=60413, metadata=None))), (9939, (8, PredictedToken(token=' Er', prob=0.004364013671875, logit=15.3125, token_id=9939, metadata=None))), (432, (7, PredictedToken(token=' R', prob=0.004364013671875, logit=15.3125, token_id=432, metadata=None)))])\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     int_prediction=['\" Er\"[9939] (p=0.443, logit=19.375)', '\" R\"[432] (p=0.237, logit=18.750)', '\" Viol\"[30555] (p=0.185, logit=18.500)', '\" The\"[578] (p=0.060, logit=17.375)', '\" ER\"[27590] (p=0.014, logit=15.938)']\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     int_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.443359375, logit=19.375, token_id=9939, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.2373046875, logit=18.75, token_id=432, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.1845703125, logit=18.5, token_id=30555, metadata=None))), (60413, (22, PredictedToken(token=' Uk', prob=0.0006256103515625, logit=12.8125, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:27 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:42:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.676, logit=20.500)', '\" Onion\"[87035] (p=0.133, logit=18.875)', '\" There\"[2684] (p=0.071, logit=18.250)', '\" The\"[578] (p=0.043, logit=17.750)', '\" None\"[2290] (p=0.014, logit=16.625)']\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.676, logit=20.875)', '\" Tape\"[58586] (p=0.151, logit=19.375)', '\" The\"[578] (p=0.081, logit=18.750)', '\" A\"[362] (p=0.030, logit=17.750)', '\" Stap\"[63606] (p=0.009, logit=16.500)']\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.67578125, logit=20.875, token_id=18343, metadata=None))), (58586, (2, PredictedToken(token=' Tape', prob=0.1513671875, logit=19.375, token_id=58586, metadata=None))), (3341, (6, PredictedToken(token=' Car', prob=0.005859375, logit=16.125, token_id=3341, metadata=None))), (6914, (12, PredictedToken(token=' Let', prob=0.001678466796875, logit=14.875, token_id=6914, metadata=None))), (42609, (37, PredictedToken(token=' Pine', prob=0.0003108978271484375, logit=13.1875, token_id=42609, metadata=None)))])\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.695, logit=20.875)', '\" Car\"[3341] (p=0.138, logit=19.250)', '\" Tape\"[58586] (p=0.065, logit=18.500)', '\" The\"[578] (p=0.031, logit=17.750)', '\" None\"[2290] (p=0.019, logit=17.250)']\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.6953125, logit=20.875, token_id=6914, metadata=None))), (3341, (2, PredictedToken(token=' Car', prob=0.1376953125, logit=19.25, token_id=3341, metadata=None))), (58586, (3, PredictedToken(token=' Tape', prob=0.06494140625, logit=18.5, token_id=58586, metadata=None))), (18343, (7, PredictedToken(token=' Paper', prob=0.004150390625, logit=15.75, token_id=18343, metadata=None))), (42609, (9, PredictedToken(token=' Pine', prob=0.0028533935546875, logit=15.375, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:28 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:28 src.selection.optimization DEBUG    torch.Size([6, 35])\n",
      "2025-09-15 09:42:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.688, logit=19.875)', '\" The\"[578] (p=0.174, logit=18.500)', '\" A\"[362] (p=0.021, logit=16.375)', '\" Guitar\"[47759] (p=0.014, logit=16.000)', '\" R\"[432] (p=0.014, logit=16.000)']\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     clean_prediction=['\" Tennis\"[58251] (p=0.648, logit=19.625)', '\" The\"[578] (p=0.099, logit=17.750)', '\" Football\"[21424] (p=0.077, logit=17.500)', '\" A\"[362] (p=0.060, logit=17.250)', '\" Bench\"[36358] (p=0.036, logit=16.750)']\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     clean_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.6484375, logit=19.625, token_id=58251, metadata=None))), (21424, (3, PredictedToken(token=' Football', prob=0.0771484375, logit=17.5, token_id=21424, metadata=None))), (36358, (5, PredictedToken(token=' Bench', prob=0.036376953125, logit=16.75, token_id=36358, metadata=None))), (40090, (32, PredictedToken(token=' Pressure', prob=0.00070953369140625, logit=12.8125, token_id=40090, metadata=None))), (46506, (74, PredictedToken(token=' Drum', prob=0.00014019012451171875, logit=11.1875, token_id=46506, metadata=None))), (3420, (128, PredictedToken(token=' Trump', prob=5.14984130859375e-05, logit=10.1875, token_id=3420, metadata=None)))])\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.812, logit=20.125)', '\" The\"[578] (p=0.076, logit=17.750)', '\" Football\"[21424] (p=0.019, logit=16.375)', '\" Pressure\"[40090] (p=0.013, logit=16.000)', '\" TR\"[5091] (p=0.012, logit=15.875)']\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.8125, logit=20.125, token_id=3420, metadata=None))), (21424, (3, PredictedToken(token=' Football', prob=0.0191650390625, logit=16.375, token_id=21424, metadata=None))), (40090, (4, PredictedToken(token=' Pressure', prob=0.01312255859375, logit=16.0, token_id=40090, metadata=None))), (58251, (7, PredictedToken(token=' Tennis', prob=0.004547119140625, logit=14.9375, token_id=58251, metadata=None))), (46506, (9, PredictedToken(token=' Drum', prob=0.003326416015625, logit=14.625, token_id=46506, metadata=None))), (36358, (11, PredictedToken(token=' Bench', prob=0.0025787353515625, logit=14.375, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:29 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:29 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:42:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.494, logit=19.750)', '\" Monitor\"[24423] (p=0.266, logit=19.125)', '\" The\"[578] (p=0.110, logit=18.250)', '\" A\"[362] (p=0.031, logit=17.000)', '\" PHONE\"[92183] (p=0.015, logit=16.250)']\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.781, logit=19.500)', '\" The\"[578] (p=0.082, logit=17.250)', '\" Cedar\"[57748] (p=0.030, logit=16.250)', '\" There\"[2684] (p=0.015, logit=15.562)', '\" Suit\"[33711] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.78125, logit=19.5, token_id=42609, metadata=None))), (57748, (3, PredictedToken(token=' Cedar', prob=0.0302734375, logit=16.25, token_id=57748, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.013427734375, logit=15.4375, token_id=33711, metadata=None))), (5907, (22, PredictedToken(token=' Project', prob=0.000759124755859375, logit=12.5625, token_id=5907, metadata=None))), (70306, (110, PredictedToken(token=' Brace', prob=7.486343383789062e-05, logit=10.25, token_id=70306, metadata=None))), (22410, (128, PredictedToken(token=' Ju', prob=5.4836273193359375e-05, logit=9.9375, token_id=22410, metadata=None))), (47033, (580, PredictedToken(token=' Printer', prob=5.0961971282958984e-06, logit=7.5625, token_id=47033, metadata=None)))])\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.801, logit=20.125)', '\" The\"[578] (p=0.066, logit=17.625)', '\" A\"[362] (p=0.031, logit=16.875)', '\" Project\"[5907] (p=0.017, logit=16.250)', '\" PR\"[8743] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.80078125, logit=20.125, token_id=47033, metadata=None))), (5907, (4, PredictedToken(token=' Project', prob=0.0166015625, logit=16.25, token_id=5907, metadata=None))), (42609, (6, PredictedToken(token=' Pine', prob=0.01141357421875, logit=15.875, token_id=42609, metadata=None))), (22410, (7, PredictedToken(token=' Ju', prob=0.006103515625, logit=15.25, token_id=22410, metadata=None))), (70306, (13, PredictedToken(token=' Brace', prob=0.0021209716796875, logit=14.1875, token_id=70306, metadata=None))), (33711, (14, PredictedToken(token=' Suit', prob=0.00186920166015625, logit=14.0625, token_id=33711, metadata=None))), (57748, (20, PredictedToken(token=' Cedar', prob=0.0012054443359375, logit=13.625, token_id=57748, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:30 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.691, logit=20.000)', '\" The\"[578] (p=0.225, logit=18.875)', '\" A\"[362] (p=0.018, logit=16.375)', '\" It\"[1102] (p=0.006, logit=15.312)', '\" There\"[2684] (p=0.003, logit=14.688)']\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     clean_prediction=['\" Elm\"[65329] (p=0.824, logit=20.125)', '\" The\"[578] (p=0.047, logit=17.250)', '\" There\"[2684] (p=0.025, logit=16.625)', '\" Dog\"[14588] (p=0.013, logit=16.000)', '\" None\"[2290] (p=0.012, logit=15.875)']\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     clean_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.82421875, logit=20.125, token_id=65329, metadata=None))), (14588, (4, PredictedToken(token=' Dog', prob=0.0133056640625, logit=16.0, token_id=14588, metadata=None))), (79028, (6, PredictedToken(token=' Hick', prob=0.009765625, logit=15.6875, token_id=79028, metadata=None))), (70110, (9, PredictedToken(token=' Ottoman', prob=0.005218505859375, logit=15.0625, token_id=70110, metadata=None))), (16478, (58, PredictedToken(token=' Chair', prob=0.00017833709716796875, logit=11.6875, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.410, logit=18.500)', '\" Chair\"[16478] (p=0.133, logit=17.375)', '\" The\"[578] (p=0.091, logit=17.000)', '\" Dog\"[14588] (p=0.049, logit=16.375)', '\" There\"[2684] (p=0.043, logit=16.250)']\n",
      "2025-09-15 09:42:31 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.41015625, logit=18.5, token_id=65329, metadata=None))), (16478, (2, PredictedToken(token=' Chair', prob=0.1328125, logit=17.375, token_id=16478, metadata=None))), (14588, (4, PredictedToken(token=' Dog', prob=0.048828125, logit=16.375, token_id=14588, metadata=None))), (79028, (11, PredictedToken(token=' Hick', prob=0.0115966796875, logit=14.9375, token_id=79028, metadata=None))), (70110, (56, PredictedToken(token=' Ottoman', prob=0.00045013427734375, logit=11.6875, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:32 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.695, logit=20.500)', '\" Slow\"[39247] (p=0.107, logit=18.625)', '\" The\"[578] (p=0.094, logit=18.500)', '\" An\"[1556] (p=0.039, logit=17.625)', '\" AIR\"[46994] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.738, logit=19.125)', '\" The\"[578] (p=0.100, logit=17.125)', '\" Cabinet\"[34046] (p=0.047, logit=16.375)', '\" Air\"[6690] (p=0.031, logit=15.938)', '\" It\"[1102] (p=0.010, logit=14.812)']\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.73828125, logit=19.125, token_id=27738, metadata=None))), (34046, (3, PredictedToken(token=' Cabinet', prob=0.04736328125, logit=16.375, token_id=34046, metadata=None))), (6690, (4, PredictedToken(token=' Air', prob=0.030517578125, logit=15.9375, token_id=6690, metadata=None))), (12369, (253, PredictedToken(token=' Food', prob=1.6927719116210938e-05, logit=8.4375, token_id=12369, metadata=None))), (72392, (354, PredictedToken(token=' Mixer', prob=9.298324584960938e-06, logit=7.84375, token_id=72392, metadata=None)))])\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     int_prediction=['\" Food\"[12369] (p=0.406, logit=16.250)', '\" The\"[578] (p=0.132, logit=15.125)', '\" Furniture\"[30339] (p=0.052, logit=14.188)', '\" None\"[2290] (p=0.040, logit=13.938)', '\" Cabinet\"[34046] (p=0.033, logit=13.750)']\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     int_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.40625, logit=16.25, token_id=12369, metadata=None))), (34046, (5, PredictedToken(token=' Cabinet', prob=0.033203125, logit=13.75, token_id=34046, metadata=None))), (72392, (11, PredictedToken(token=' Mixer', prob=0.01153564453125, logit=12.6875, token_id=72392, metadata=None))), (6690, (16, PredictedToken(token=' Air', prob=0.0074462890625, logit=12.25, token_id=6690, metadata=None))), (27738, (20, PredictedToken(token=' Ward', prob=0.005096435546875, logit=11.875, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:32 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:42:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     patch_prediction=['\" Sofa\"[61948] (p=0.578, logit=19.500)', '\" The\"[578] (p=0.213, logit=18.500)', '\" Ward\"[27738] (p=0.042, logit=16.875)', '\" SO\"[5745] (p=0.022, logit=16.250)', '\" A\"[362] (p=0.022, logit=16.250)']\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.832, logit=19.875)', '\" The\"[578] (p=0.042, logit=16.875)', '\" SH\"[6570] (p=0.032, logit=16.625)', '\" Gloves\"[68554] (p=0.028, logit=16.500)', '\" There\"[2684] (p=0.005, logit=14.688)']\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.83203125, logit=19.875, token_id=55807, metadata=None))), (68554, (4, PredictedToken(token=' Gloves', prob=0.0284423828125, logit=16.5, token_id=68554, metadata=None))), (800, (14, PredictedToken(token=' St', prob=0.001708984375, logit=13.6875, token_id=800, metadata=None))), (27171, (75, PredictedToken(token=' Coffee', prob=0.00010251998901367188, logit=10.875, token_id=27171, metadata=None)))])\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.535, logit=18.875)', '\" Coffee\"[27171] (p=0.174, logit=17.750)', '\" Gloves\"[68554] (p=0.072, logit=16.875)', '\" The\"[578] (p=0.034, logit=16.125)', '\" None\"[2290] (p=0.030, logit=16.000)']\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.53515625, logit=18.875, token_id=55807, metadata=None))), (27171, (2, PredictedToken(token=' Coffee', prob=0.173828125, logit=17.75, token_id=27171, metadata=None))), (68554, (3, PredictedToken(token=' Gloves', prob=0.072265625, logit=16.875, token_id=68554, metadata=None))), (800, (6, PredictedToken(token=' St', prob=0.0283203125, logit=15.9375, token_id=800, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:33 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.914, logit=21.875)', '\" The\"[578] (p=0.045, logit=18.875)', '\" Tomato\"[94091] (p=0.013, logit=17.625)', '\" There\"[2684] (p=0.011, logit=17.500)', '\" None\"[2290] (p=0.002, logit=15.688)']\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.711, logit=20.375)', '\" The\"[578] (p=0.140, logit=18.750)', '\" A\"[362] (p=0.045, logit=17.625)', '\" Golf\"[28131] (p=0.035, logit=17.375)', '\" Tennis\"[58251] (p=0.015, logit=16.500)']\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.7109375, logit=20.375, token_id=432, metadata=None))), (28131, (4, PredictedToken(token=' Golf', prob=0.035400390625, logit=17.375, token_id=28131, metadata=None))), (1666, (6, PredictedToken(token=' As', prob=0.004791259765625, logit=15.375, token_id=1666, metadata=None))), (27738, (86, PredictedToken(token=' Ward', prob=6.437301635742188e-05, logit=11.0625, token_id=27738, metadata=None))), (78703, (276, PredictedToken(token=' Potato', prob=9.834766387939453e-06, logit=9.1875, token_id=78703, metadata=None)))])\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     int_prediction=['\" As\"[1666] (p=0.809, logit=20.625)', '\" Golf\"[28131] (p=0.059, logit=18.000)', '\" The\"[578] (p=0.046, logit=17.750)', '\" Potato\"[78703] (p=0.028, logit=17.250)', '\" AS\"[5871] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     int_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.80859375, logit=20.625, token_id=1666, metadata=None))), (28131, (2, PredictedToken(token=' Golf', prob=0.05859375, logit=18.0, token_id=28131, metadata=None))), (78703, (4, PredictedToken(token=' Potato', prob=0.0277099609375, logit=17.25, token_id=78703, metadata=None))), (432, (18, PredictedToken(token=' R', prob=0.00078582763671875, logit=13.6875, token_id=432, metadata=None))), (27738, (30, PredictedToken(token=' Ward', prob=0.0003490447998046875, logit=12.875, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:34 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:42:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.887, logit=20.125)', '\" The\"[578] (p=0.027, logit=16.625)', '\" A\"[362] (p=0.009, logit=15.500)', '\" Sheep\"[84008] (p=0.008, logit=15.438)', '\" Sk\"[4923] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     clean_prediction=['\" Gloves\"[68554] (p=0.809, logit=20.250)', '\" S\"[328] (p=0.085, logit=18.000)', '\" The\"[578] (p=0.040, logit=17.250)', '\" None\"[2290] (p=0.008, logit=15.625)', '\" There\"[2684] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     clean_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.80859375, logit=20.25, token_id=68554, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.0849609375, logit=18.0, token_id=328, metadata=None))), (48035, (77, PredictedToken(token=' Gir', prob=9.34600830078125e-05, logit=11.1875, token_id=48035, metadata=None))), (79189, (236, PredictedToken(token=' Elephant', prob=1.8477439880371094e-05, logit=9.5625, token_id=79189, metadata=None)))])\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     int_prediction=['\" Elephant\"[79189] (p=0.695, logit=19.500)', '\" Gloves\"[68554] (p=0.107, logit=17.625)', '\" The\"[578] (p=0.057, logit=17.000)', '\" Gir\"[48035] (p=0.044, logit=16.750)', '\" None\"[2290] (p=0.012, logit=15.438)']\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     int_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.6953125, logit=19.5, token_id=79189, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.10693359375, logit=17.625, token_id=68554, metadata=None))), (48035, (4, PredictedToken(token=' Gir', prob=0.04443359375, logit=16.75, token_id=48035, metadata=None))), (328, (8, PredictedToken(token=' S', prob=0.00531005859375, logit=14.625, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:35 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.762, logit=20.250)', '\" The\"[578] (p=0.091, logit=18.125)', '\" A\"[362] (p=0.033, logit=17.125)', '\" FOOD\"[88227] (p=0.020, logit=16.625)', '\" Pear\"[23910] (p=0.016, logit=16.375)']\n",
      "2025-09-15 09:42:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:36 src.selection.optimization INFO     clean_prediction=['\" Cherry\"[45805] (p=0.699, logit=20.125)', '\" The\"[578] (p=0.200, logit=18.875)', '\" Water\"[10164] (p=0.016, logit=16.375)', '\" CH\"[6969] (p=0.011, logit=16.000)', '\" A\"[362] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:42:36 src.selection.optimization INFO     clean_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.69921875, logit=20.125, token_id=45805, metadata=None))), (10164, (3, PredictedToken(token=' Water', prob=0.016357421875, logit=16.375, token_id=10164, metadata=None))), (22410, (19, PredictedToken(token=' Ju', prob=0.000926971435546875, logit=13.5, token_id=22410, metadata=None))), (30616, (288, PredictedToken(token=' Rice', prob=1.0311603546142578e-05, logit=9.0, token_id=30616, metadata=None)))])\n",
      "2025-09-15 09:42:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:36 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.340, logit=18.500)', '\" Water\"[10164] (p=0.299, logit=18.375)', '\" The\"[578] (p=0.142, logit=17.625)', '\" Cherry\"[45805] (p=0.097, logit=17.250)', '\" WATER\"[76347] (p=0.012, logit=15.125)']\n",
      "2025-09-15 09:42:36 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.33984375, logit=18.5, token_id=30616, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.298828125, logit=18.375, token_id=10164, metadata=None))), (45805, (4, PredictedToken(token=' Cherry', prob=0.09716796875, logit=17.25, token_id=45805, metadata=None))), (22410, (27, PredictedToken(token=' Ju', prob=0.000789642333984375, logit=12.4375, token_id=22410, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:36 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:42:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.494, logit=19.375)', '\" The\"[578] (p=0.182, logit=18.375)', '\" SHE\"[54695] (p=0.097, logit=17.750)', '\" Tiger\"[36845] (p=0.052, logit=17.125)', '\" Bat\"[16488] (p=0.046, logit=17.000)']\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.914, logit=21.750)', '\" L\"[445] (p=0.052, logit=18.875)', '\" The\"[578] (p=0.013, logit=17.500)', '\" A\"[362] (p=0.002, logit=15.625)', '\" Shower\"[48471] (p=0.002, logit=15.500)']\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.9140625, logit=21.75, token_id=41493, metadata=None))), (445, (2, PredictedToken(token=' L', prob=0.051513671875, logit=18.875, token_id=445, metadata=None))), (1901, (19, PredictedToken(token=' Z', prob=0.0002880096435546875, logit=13.6875, token_id=1901, metadata=None))), (24941, (46, PredictedToken(token=' Bear', prob=6.437301635742188e-05, logit=12.1875, token_id=24941, metadata=None))), (16147, (70, PredictedToken(token=' Smart', prob=4.410743713378906e-05, logit=11.8125, token_id=16147, metadata=None)))])\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.512, logit=19.750)', '\" Z\"[1901] (p=0.213, logit=18.875)', '\" Tow\"[41493] (p=0.166, logit=18.625)', '\" The\"[578] (p=0.033, logit=17.000)', '\" A\"[362] (p=0.012, logit=16.000)']\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.51171875, logit=19.75, token_id=24941, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.212890625, logit=18.875, token_id=1901, metadata=None))), (41493, (3, PredictedToken(token=' Tow', prob=0.166015625, logit=18.625, token_id=41493, metadata=None))), (445, (7, PredictedToken(token=' L', prob=0.003662109375, logit=14.8125, token_id=445, metadata=None))), (16147, (10, PredictedToken(token=' Smart', prob=0.0025177001953125, logit=14.4375, token_id=16147, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:37 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:37 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:42:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.691, logit=20.125)', '\" The\"[578] (p=0.137, logit=18.500)', '\" A\"[362] (p=0.073, logit=17.875)', '\" R\"[432] (p=0.014, logit=16.250)', '\" It\"[1102] (p=0.006, logit=15.438)']\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.559, logit=19.500)', '\" Dolphin\"[96096] (p=0.182, logit=18.375)', '\" The\"[578] (p=0.142, logit=18.125)', '\" There\"[2684] (p=0.017, logit=16.000)', '\" A\"[362] (p=0.013, logit=15.750)']\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.55859375, logit=19.5, token_id=48035, metadata=None))), (96096, (2, PredictedToken(token=' Dolphin', prob=0.181640625, logit=18.375, token_id=96096, metadata=None))), (30760, (8, PredictedToken(token=' Scar', prob=0.00799560546875, logit=15.25, token_id=30760, metadata=None))), (28131, (23, PredictedToken(token=' Golf', prob=0.00069427490234375, logit=12.8125, token_id=28131, metadata=None))), (47589, (96, PredictedToken(token=' Basketball', prob=8.869171142578125e-05, logit=10.75, token_id=47589, metadata=None))), (40975, (219, PredictedToken(token=' Marker', prob=2.384185791015625e-05, logit=9.4375, token_id=40975, metadata=None))), (14669, (600, PredictedToken(token=' Camera', prob=4.410743713378906e-06, logit=7.75, token_id=14669, metadata=None)))])\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.836, logit=20.500)', '\" The\"[578] (p=0.061, logit=17.875)', '\" Dolphin\"[96096] (p=0.017, logit=16.625)', '\" A\"[362] (p=0.014, logit=16.375)', '\" There\"[2684] (p=0.009, logit=15.938)']\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.8359375, logit=20.5, token_id=47589, metadata=None))), (96096, (3, PredictedToken(token=' Dolphin', prob=0.017333984375, logit=16.625, token_id=96096, metadata=None))), (40975, (8, PredictedToken(token=' Marker', prob=0.00439453125, logit=15.25, token_id=40975, metadata=None))), (28131, (9, PredictedToken(token=' Golf', prob=0.004119873046875, logit=15.1875, token_id=28131, metadata=None))), (30760, (11, PredictedToken(token=' Scar', prob=0.002349853515625, logit=14.625, token_id=30760, metadata=None))), (14669, (18, PredictedToken(token=' Camera', prob=0.0011138916015625, logit=13.875, token_id=14669, metadata=None))), (48035, (24, PredictedToken(token=' Gir', prob=0.000675201416015625, logit=13.375, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:38 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.625, logit=19.500)', '\" Jeans\"[82507] (p=0.230, logit=18.500)', '\" The\"[578] (p=0.031, logit=16.500)', '\" None\"[2290] (p=0.016, logit=15.812)', '\" Router\"[10777] (p=0.011, logit=15.438)']\n",
      "2025-09-15 09:42:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.836, logit=20.375)', '\" The\"[578] (p=0.061, logit=17.750)', '\" E\"[469] (p=0.029, logit=17.000)', '\" There\"[2684] (p=0.013, logit=16.250)', '\" Air\"[6690] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.8359375, logit=20.375, token_id=65449, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.028564453125, logit=17.0, token_id=469, metadata=None))), (6690, (5, PredictedToken(token=' Air', prob=0.0081787109375, logit=15.75, token_id=6690, metadata=None))), (37326, (11, PredictedToken(token=' Swe', prob=0.00194549560546875, logit=14.3125, token_id=37326, metadata=None))), (91782, (30, PredictedToken(token=' Shorts', prob=0.0003376007080078125, logit=12.5625, token_id=91782, metadata=None))), (24423, (36, PredictedToken(token=' Monitor', prob=0.00029754638671875, logit=12.4375, token_id=24423, metadata=None)))])\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.633, logit=19.750)', '\" Willow\"[65449] (p=0.181, logit=18.500)', '\" Shorts\"[91782] (p=0.059, logit=17.375)', '\" The\"[578] (p=0.036, logit=16.875)', '\" E\"[469] (p=0.019, logit=16.250)']\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.6328125, logit=19.75, token_id=37326, metadata=None))), (65449, (2, PredictedToken(token=' Willow', prob=0.1806640625, logit=18.5, token_id=65449, metadata=None))), (91782, (3, PredictedToken(token=' Shorts', prob=0.058837890625, logit=17.375, token_id=91782, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.01904296875, logit=16.25, token_id=469, metadata=None))), (6690, (6, PredictedToken(token=' Air', prob=0.014892578125, logit=16.0, token_id=6690, metadata=None))), (24423, (24, PredictedToken(token=' Monitor', prob=0.000652313232421875, logit=12.875, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:39 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:39 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.486, logit=18.125)', '\" Cat\"[17810] (p=0.229, logit=17.375)', '\" The\"[578] (p=0.066, logit=16.125)', '\" None\"[2290] (p=0.024, logit=15.125)', '\" There\"[2684] (p=0.020, logit=14.938)']\n",
      "2025-09-15 09:42:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.832, logit=20.375)', '\" The\"[578] (p=0.053, logit=17.625)', '\" e\"[384] (p=0.037, logit=17.250)', '\" Bro\"[6031] (p=0.013, logit=16.250)', '\" An\"[1556] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.83203125, logit=20.375, token_id=469, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.01348876953125, logit=16.25, token_id=6031, metadata=None))), (33578, (18, PredictedToken(token=' Palm', prob=0.0009765625, logit=13.625, token_id=33578, metadata=None))), (49431, (25, PredictedToken(token=' Rabbit', prob=0.00055694580078125, logit=13.0625, token_id=49431, metadata=None))), (79189, (40, PredictedToken(token=' Elephant', prob=0.000263214111328125, logit=12.3125, token_id=79189, metadata=None)))])\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.848, logit=19.875)', '\" The\"[578] (p=0.037, logit=16.750)', '\" Elephant\"[79189] (p=0.026, logit=16.375)', '\" rabbit\"[39824] (p=0.011, logit=15.500)', '\" Bro\"[6031] (p=0.008, logit=15.250)']\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.84765625, logit=19.875, token_id=49431, metadata=None))), (79189, (3, PredictedToken(token=' Elephant', prob=0.0255126953125, logit=16.375, token_id=79189, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.00830078125, logit=15.25, token_id=6031, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.006072998046875, logit=14.9375, token_id=469, metadata=None))), (33578, (9, PredictedToken(token=' Palm', prob=0.0034637451171875, logit=14.375, token_id=33578, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:40 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     patch_prediction=['\" Mixer\"[72392] (p=0.609, logit=20.125)', '\" The\"[578] (p=0.154, logit=18.750)', '\" Air\"[6690] (p=0.094, logit=18.250)', '\" MIX\"[81309] (p=0.050, logit=17.625)', '\" A\"[362] (p=0.014, logit=16.375)']\n",
      "2025-09-15 09:42:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.758, logit=20.250)', '\" The\"[578] (p=0.149, logit=18.625)', '\" ACC\"[26925] (p=0.012, logit=16.125)', '\" Accord\"[80657] (p=0.010, logit=15.938)', '\" Ju\"[22410] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.7578125, logit=20.25, token_id=11683, metadata=None))), (22410, (4, PredictedToken(token=' Ju', prob=0.0101318359375, logit=15.9375, token_id=22410, metadata=None))), (47759, (6, PredictedToken(token=' Guitar', prob=0.006988525390625, logit=15.5625, token_id=47759, metadata=None))), (75258, (643, PredictedToken(token=' Refriger', prob=2.4884939193725586e-06, logit=7.625, token_id=75258, metadata=None)))])\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     int_prediction=['\" Ju\"[22410] (p=0.652, logit=19.250)', '\" The\"[578] (p=0.165, logit=17.875)', '\" Acc\"[11683] (p=0.029, logit=16.125)', '\" Guitar\"[47759] (p=0.025, logit=16.000)', '\" A\"[362] (p=0.021, logit=15.812)']\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     int_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.65234375, logit=19.25, token_id=22410, metadata=None))), (11683, (3, PredictedToken(token=' Acc', prob=0.0286865234375, logit=16.125, token_id=11683, metadata=None))), (47759, (4, PredictedToken(token=' Guitar', prob=0.0252685546875, logit=16.0, token_id=47759, metadata=None))), (75258, (14, PredictedToken(token=' Refriger', prob=0.00250244140625, logit=13.6875, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:41 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.832, logit=21.250)', '\" The\"[578] (p=0.099, logit=19.125)', '\" A\"[362] (p=0.015, logit=17.250)', '\" BE\"[7354] (p=0.012, logit=17.000)', '\" Sheep\"[84008] (p=0.009, logit=16.750)']\n",
      "2025-09-15 09:42:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.645, logit=20.500)', '\" The\"[578] (p=0.270, logit=19.625)', '\" Clar\"[31181] (p=0.010, logit=16.375)', '\" A\"[362] (p=0.009, logit=16.250)', '\" There\"[2684] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.64453125, logit=20.5, token_id=1630, metadata=None))), (31181, (3, PredictedToken(token=' Clar', prob=0.01043701171875, logit=16.375, token_id=31181, metadata=None))), (3341, (97, PredictedToken(token=' Car', prob=5.4836273193359375e-05, logit=11.125, token_id=3341, metadata=None))), (96096, (110, PredictedToken(token=' Dolphin', prob=4.00543212890625e-05, logit=10.8125, token_id=96096, metadata=None))), (34392, (125, PredictedToken(token=' Horse', prob=3.123283386230469e-05, logit=10.5625, token_id=34392, metadata=None)))])\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.527, logit=19.125)', '\" The\"[578] (p=0.249, logit=18.375)', '\" Dolphin\"[96096] (p=0.049, logit=16.750)', '\" A\"[362] (p=0.026, logit=16.125)', '\" H\"[473] (p=0.019, logit=15.812)']\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.52734375, logit=19.125, token_id=34392, metadata=None))), (96096, (3, PredictedToken(token=' Dolphin', prob=0.048828125, logit=16.75, token_id=96096, metadata=None))), (31181, (8, PredictedToken(token=' Clar', prob=0.0096435546875, logit=15.125, token_id=31181, metadata=None))), (3341, (26, PredictedToken(token=' Car', prob=0.0013885498046875, logit=13.1875, token_id=3341, metadata=None))), (1630, (87, PredictedToken(token=' X', prob=0.00015544891357421875, logit=11.0, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:42 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.734, logit=19.375)', '\" Cow\"[22607] (p=0.078, logit=17.125)', '\" The\"[578] (p=0.053, logit=16.750)', '\" MON\"[29637] (p=0.032, logit=16.250)', '\" A\"[362] (p=0.015, logit=15.500)']\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.652, logit=19.875)', '\" The\"[578] (p=0.188, logit=18.625)', '\" Hat\"[22050] (p=0.037, logit=17.000)', '\" A\"[362] (p=0.029, logit=16.750)', '\" SK\"[12343] (p=0.014, logit=16.000)']\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.65234375, logit=19.875, token_id=4923, metadata=None))), (22050, (3, PredictedToken(token=' Hat', prob=0.036865234375, logit=17.0, token_id=22050, metadata=None))), (49431, (135, PredictedToken(token=' Rabbit', prob=4.601478576660156e-05, logit=10.3125, token_id=49431, metadata=None))), (14588, (140, PredictedToken(token=' Dog', prob=4.315376281738281e-05, logit=10.25, token_id=14588, metadata=None)))])\n",
      "2025-09-15 09:42:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.547, logit=19.875)', '\" Rabbit\"[49431] (p=0.201, logit=18.875)', '\" The\"[578] (p=0.122, logit=18.375)', '\" Hat\"[22050] (p=0.045, logit=17.375)', '\" A\"[362] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.546875, logit=19.875, token_id=14588, metadata=None))), (49431, (2, PredictedToken(token=' Rabbit', prob=0.201171875, logit=18.875, token_id=49431, metadata=None))), (22050, (4, PredictedToken(token=' Hat', prob=0.044921875, logit=17.375, token_id=22050, metadata=None))), (4923, (45, PredictedToken(token=' Sk', prob=0.0002498626708984375, logit=12.1875, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:43 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.441, logit=19.875)', '\" Smart\"[16147] (p=0.344, logit=19.625)', '\" The\"[578] (p=0.112, logit=18.500)', '\" A\"[362] (p=0.036, logit=17.375)', '\" SMART\"[80708] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.559, logit=19.375)', '\" The\"[578] (p=0.125, logit=17.875)', '\" Spin\"[41785] (p=0.110, logit=17.750)', '\" There\"[2684] (p=0.067, logit=17.250)', '\" None\"[2290] (p=0.036, logit=16.625)']\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.55859375, logit=19.375, token_id=47643, metadata=None))), (41785, (3, PredictedToken(token=' Spin', prob=0.10986328125, logit=17.75, token_id=41785, metadata=None))), (18191, (6, PredictedToken(token=' Mouse', prob=0.014892578125, logit=15.75, token_id=18191, metadata=None))), (24423, (8, PredictedToken(token=' Monitor', prob=0.005157470703125, logit=14.6875, token_id=24423, metadata=None))), (53889, (21, PredictedToken(token=' Apartment', prob=0.00130462646484375, logit=13.3125, token_id=53889, metadata=None)))])\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.785, logit=19.875)', '\" The\"[578] (p=0.083, logit=17.625)', '\" There\"[2684] (p=0.024, logit=16.375)', '\" None\"[2290] (p=0.021, logit=16.250)', '\" MON\"[29637] (p=0.016, logit=16.000)']\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.78515625, logit=19.875, token_id=24423, metadata=None))), (18191, (6, PredictedToken(token=' Mouse', prob=0.014404296875, logit=15.875, token_id=18191, metadata=None))), (53889, (9, PredictedToken(token=' Apartment', prob=0.004119873046875, logit=14.625, token_id=53889, metadata=None))), (41785, (19, PredictedToken(token=' Spin', prob=0.00086212158203125, logit=13.0625, token_id=41785, metadata=None))), (47643, (43, PredictedToken(token=' Cel', prob=0.000247955322265625, logit=11.8125, token_id=47643, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:43 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:43 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-15 09:42:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:44 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.824, logit=20.125)', '\" Cedar\"[57748] (p=0.068, logit=17.625)', '\" The\"[578] (p=0.041, logit=17.125)', '\" Pine\"[42609] (p=0.011, logit=15.812)', '\" PAL\"[52569] (p=0.006, logit=15.125)']\n",
      "2025-09-15 09:42:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:45 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.859, logit=20.125)', '\" The\"[578] (p=0.048, logit=17.250)', '\" A\"[362] (p=0.026, logit=16.625)', '\" dress\"[8679] (p=0.008, logit=15.500)', '\" Oak\"[18787] (p=0.006, logit=15.188)']\n",
      "2025-09-15 09:42:45 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.859375, logit=20.125, token_id=29318, metadata=None))), (18787, (5, PredictedToken(token=' Oak', prob=0.00616455078125, logit=15.1875, token_id=18787, metadata=None))), (91782, (6, PredictedToken(token=' Shorts', prob=0.004791259765625, logit=14.9375, token_id=91782, metadata=None))), (88088, (26, PredictedToken(token=' Birch', prob=0.00057220458984375, logit=12.8125, token_id=88088, metadata=None)))])\n",
      "2025-09-15 09:42:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:45 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.402, logit=18.125)', '\" Birch\"[88088] (p=0.312, logit=17.875)', '\" The\"[578] (p=0.062, logit=16.250)', '\" Oak\"[18787] (p=0.031, logit=15.562)', '\" Dress\"[29318] (p=0.018, logit=15.000)']\n",
      "2025-09-15 09:42:45 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.40234375, logit=18.125, token_id=91782, metadata=None))), (88088, (2, PredictedToken(token=' Birch', prob=0.3125, logit=17.875, token_id=88088, metadata=None))), (18787, (4, PredictedToken(token=' Oak', prob=0.031005859375, logit=15.5625, token_id=18787, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.017578125, logit=15.0, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:45 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:42:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.699, logit=19.750)', '\" Willow\"[65449] (p=0.095, logit=17.750)', '\" The\"[578] (p=0.083, logit=17.625)', '\" SPR\"[52367] (p=0.031, logit=16.625)', '\" There\"[2684] (p=0.009, logit=15.438)']\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.438, logit=17.750)', '\" Ki\"[30558] (p=0.098, logit=16.250)', '\" None\"[2290] (p=0.098, logit=16.250)', '\" The\"[578] (p=0.086, logit=16.125)', '\" D\"[423] (p=0.038, logit=15.312)']\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.4375, logit=17.75, token_id=38258, metadata=None))), (30558, (3, PredictedToken(token=' Ki', prob=0.09765625, logit=16.25, token_id=30558, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.038330078125, logit=15.3125, token_id=423, metadata=None))), (98028, (6, PredictedToken(token=' Bamboo', prob=0.0262451171875, logit=14.9375, token_id=98028, metadata=None))), (33578, (9, PredictedToken(token=' Palm', prob=0.01165771484375, logit=14.125, token_id=33578, metadata=None)))])\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.523, logit=18.500)', '\" Ki\"[30558] (p=0.149, logit=17.250)', '\" The\"[578] (p=0.091, logit=16.750)', '\" Baseball\"[38258] (p=0.035, logit=15.812)', '\" Bamboo\"[98028] (p=0.029, logit=15.625)']\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.5234375, logit=18.5, token_id=33578, metadata=None))), (30558, (2, PredictedToken(token=' Ki', prob=0.1494140625, logit=17.25, token_id=30558, metadata=None))), (38258, (4, PredictedToken(token=' Baseball', prob=0.035400390625, logit=15.8125, token_id=38258, metadata=None))), (98028, (5, PredictedToken(token=' Bamboo', prob=0.0294189453125, logit=15.625, token_id=98028, metadata=None))), (423, (13, PredictedToken(token=' D', prob=0.0030975341796875, logit=13.375, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:46 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:46 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:42:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     patch_prediction=['\" Book\"[6017] (p=0.695, logit=20.250)', '\" The\"[578] (p=0.176, logit=18.875)', '\" BOOK\"[48198] (p=0.021, logit=16.750)', '\" A\"[362] (p=0.019, logit=16.625)', '\" Ottoman\"[70110] (p=0.014, logit=16.375)']\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     clean_prediction=['\" Potato\"[78703] (p=0.684, logit=20.500)', '\" The\"[578] (p=0.119, logit=18.750)', '\" Tomato\"[94091] (p=0.082, logit=18.375)', '\" There\"[2684] (p=0.044, logit=17.750)', '\" Spr\"[15883] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     clean_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.68359375, logit=20.5, token_id=78703, metadata=None))), (94091, (3, PredictedToken(token=' Tomato', prob=0.08154296875, logit=18.375, token_id=94091, metadata=None))), (15883, (5, PredictedToken(token=' Spr', prob=0.00970458984375, logit=16.25, token_id=15883, metadata=None))), (60413, (22, PredictedToken(token=' Uk', prob=0.000751495361328125, logit=13.6875, token_id=60413, metadata=None))), (6771, (32, PredictedToken(token=' Table', prob=0.0004558563232421875, logit=13.1875, token_id=6771, metadata=None))), (34046, (868, PredictedToken(token=' Cabinet', prob=1.5944242477416992e-06, logit=7.53125, token_id=34046, metadata=None)))])\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     int_prediction=['\" Table\"[6771] (p=0.527, logit=19.875)', '\" Cabinet\"[34046] (p=0.171, logit=18.750)', '\" The\"[578] (p=0.134, logit=18.500)', '\" There\"[2684] (p=0.038, logit=17.250)', '\" Tomato\"[94091] (p=0.034, logit=17.125)']\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     int_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.52734375, logit=19.875, token_id=6771, metadata=None))), (34046, (2, PredictedToken(token=' Cabinet', prob=0.1708984375, logit=18.75, token_id=34046, metadata=None))), (94091, (5, PredictedToken(token=' Tomato', prob=0.03369140625, logit=17.125, token_id=94091, metadata=None))), (78703, (6, PredictedToken(token=' Potato', prob=0.0203857421875, logit=16.625, token_id=78703, metadata=None))), (15883, (9, PredictedToken(token=' Spr', prob=0.00665283203125, logit=15.5, token_id=15883, metadata=None))), (60413, (50, PredictedToken(token=' Uk', prob=0.0002269744873046875, logit=12.125, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:47 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.609, logit=19.250)', '\" Elm\"[65329] (p=0.136, logit=17.750)', '\" The\"[578] (p=0.106, logit=17.500)', '\" There\"[2684] (p=0.050, logit=16.750)', '\" None\"[2290] (p=0.012, logit=15.312)']\n",
      "2025-09-15 09:42:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.707, logit=18.875)', '\" The\"[578] (p=0.074, logit=16.625)', '\" BAT\"[79081] (p=0.026, logit=15.562)', '\" R\"[432] (p=0.026, logit=15.562)', '\" None\"[2290] (p=0.024, logit=15.500)']\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.70703125, logit=18.875, token_id=16488, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.0257568359375, logit=15.5625, token_id=432, metadata=None))), (3061, (6, PredictedToken(token=' Fl', prob=0.02001953125, logit=15.3125, token_id=3061, metadata=None))), (57748, (10, PredictedToken(token=' Cedar', prob=0.006103515625, logit=14.125, token_id=57748, metadata=None))), (33578, (11, PredictedToken(token=' Palm', prob=0.0047607421875, logit=13.875, token_id=33578, metadata=None)))])\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.445, logit=17.750)', '\" R\"[432] (p=0.127, logit=16.500)', '\" Fl\"[3061] (p=0.112, logit=16.375)', '\" The\"[578] (p=0.068, logit=15.875)', '\" None\"[2290] (p=0.053, logit=15.625)']\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.4453125, logit=17.75, token_id=33578, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.126953125, logit=16.5, token_id=432, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.1123046875, logit=16.375, token_id=3061, metadata=None))), (16488, (8, PredictedToken(token=' Bat', prob=0.0111083984375, logit=14.0625, token_id=16488, metadata=None))), (57748, (14, PredictedToken(token=' Cedar', prob=0.005584716796875, logit=13.375, token_id=57748, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:48 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     patch_prediction=['\" Calculator\"[37128] (p=0.648, logit=19.625)', '\" Highlight\"[57094] (p=0.164, logit=18.250)', '\" The\"[578] (p=0.078, logit=17.500)', '\" A\"[362] (p=0.017, logit=16.000)', '\" None\"[2290] (p=0.016, logit=15.938)']\n",
      "2025-09-15 09:42:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:49 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.746, logit=19.625)', '\" Mar\"[2947] (p=0.061, logit=17.125)', '\" The\"[578] (p=0.054, logit=17.000)', '\" P\"[393] (p=0.022, logit=16.125)', '\" There\"[2684] (p=0.018, logit=15.875)']\n",
      "2025-09-15 09:42:49 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.74609375, logit=19.625, token_id=71264, metadata=None))), (2947, (2, PredictedToken(token=' Mar', prob=0.061279296875, logit=17.125, token_id=2947, metadata=None))), (393, (4, PredictedToken(token=' P', prob=0.0224609375, logit=16.125, token_id=393, metadata=None))), (36943, (37, PredictedToken(token=' Folder', prob=0.000530242919921875, logit=12.375, token_id=36943, metadata=None))), (23462, (36, PredictedToken(token=' Stadium', prob=0.000530242919921875, logit=12.375, token_id=23462, metadata=None)))])\n",
      "2025-09-15 09:42:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:49 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.590, logit=19.125)', '\" Folder\"[36943] (p=0.169, logit=17.875)', '\" Daisy\"[71264] (p=0.062, logit=16.875)', '\" The\"[578] (p=0.033, logit=16.250)', '\" None\"[2290] (p=0.026, logit=16.000)']\n",
      "2025-09-15 09:42:49 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.58984375, logit=19.125, token_id=393, metadata=None))), (36943, (2, PredictedToken(token=' Folder', prob=0.1689453125, logit=17.875, token_id=36943, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.06201171875, logit=16.875, token_id=71264, metadata=None))), (2947, (18, PredictedToken(token=' Mar', prob=0.0019989013671875, logit=13.4375, token_id=2947, metadata=None))), (23462, (38, PredictedToken(token=' Stadium', prob=0.00057220458984375, logit=12.1875, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:49 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:49 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.848, logit=21.375)', '\" Comb\"[23262] (p=0.101, logit=19.250)', '\" The\"[578] (p=0.020, logit=17.625)', '\" A\"[362] (p=0.007, logit=16.625)', '\" None\"[2290] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     clean_prediction=['\" Apple\"[8325] (p=0.766, logit=20.875)', '\" The\"[578] (p=0.117, logit=19.000)', '\" Pine\"[42609] (p=0.030, logit=17.625)', '\" An\"[1556] (p=0.020, logit=17.250)', '\" There\"[2684] (p=0.018, logit=17.125)']\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     clean_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.765625, logit=20.875, token_id=8325, metadata=None))), (42609, (3, PredictedToken(token=' Pine', prob=0.0296630859375, logit=17.625, token_id=42609, metadata=None))), (16488, (59, PredictedToken(token=' Bat', prob=0.00011396408081054688, logit=12.0625, token_id=16488, metadata=None))), (82994, (144, PredictedToken(token=' Toilet', prob=2.384185791015625e-05, logit=10.5, token_id=82994, metadata=None))), (16730, (1378, PredictedToken(token=' Museum', prob=6.370246410369873e-07, logit=6.875, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.455, logit=19.500)', '\" Toilet\"[82994] (p=0.243, logit=18.875)', '\" The\"[578] (p=0.130, logit=18.250)', '\" There\"[2684] (p=0.048, logit=17.250)', '\" TO\"[5257] (p=0.023, logit=16.500)']\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.455078125, logit=19.5, token_id=16488, metadata=None))), (82994, (2, PredictedToken(token=' Toilet', prob=0.2431640625, logit=18.875, token_id=82994, metadata=None))), (42609, (6, PredictedToken(token=' Pine', prob=0.01287841796875, logit=15.9375, token_id=42609, metadata=None))), (8325, (24, PredictedToken(token=' Apple', prob=0.000774383544921875, logit=13.125, token_id=8325, metadata=None))), (16730, (832, PredictedToken(token=' Museum', prob=3.159046173095703e-06, logit=7.625, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:50 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:50 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:42:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.781, logit=20.500)', '\" St\"[800] (p=0.073, logit=18.125)', '\" The\"[578] (p=0.064, logit=18.000)', '\" CAB\"[81217] (p=0.014, logit=16.500)', '\" Fl\"[3061] (p=0.013, logit=16.375)']\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     clean_prediction=['\" Er\"[9939] (p=0.508, logit=20.000)', '\" Pen\"[13597] (p=0.273, logit=19.375)', '\" The\"[578] (p=0.069, logit=18.000)', '\" An\"[1556] (p=0.061, logit=17.875)', '\" PEN\"[81770] (p=0.014, logit=16.375)']\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     clean_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.5078125, logit=20.0, token_id=9939, metadata=None))), (13597, (2, PredictedToken(token=' Pen', prob=0.2734375, logit=19.375, token_id=13597, metadata=None))), (46506, (13, PredictedToken(token=' Drum', prob=0.001434326171875, logit=14.125, token_id=46506, metadata=None))), (1050, (19, PredictedToken(token=' Re', prob=0.00098419189453125, logit=13.75, token_id=1050, metadata=None))), (90538, (69, PredictedToken(token=' Caul', prob=0.00014209747314453125, logit=11.8125, token_id=90538, metadata=None))), (8868, (101, PredictedToken(token=' Blue', prob=7.581710815429688e-05, logit=11.1875, token_id=8868, metadata=None))), (36358, (169, PredictedToken(token=' Bench', prob=2.1696090698242188e-05, logit=9.9375, token_id=36358, metadata=None)))])\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.785, logit=20.750)', '\" Re\"[1050] (p=0.106, logit=18.750)', '\" The\"[578] (p=0.050, logit=18.000)', '\" A\"[362] (p=0.010, logit=16.375)', '\" Pen\"[13597] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.78515625, logit=20.75, token_id=36358, metadata=None))), (1050, (2, PredictedToken(token=' Re', prob=0.10595703125, logit=18.75, token_id=1050, metadata=None))), (13597, (5, PredictedToken(token=' Pen', prob=0.0076904296875, logit=16.125, token_id=13597, metadata=None))), (46506, (13, PredictedToken(token=' Drum', prob=0.00110626220703125, logit=14.1875, token_id=46506, metadata=None))), (90538, (79, PredictedToken(token=' Caul', prob=6.628036499023438e-05, logit=11.375, token_id=90538, metadata=None))), (9939, (93, PredictedToken(token=' Er', prob=4.863739013671875e-05, logit=11.0625, token_id=9939, metadata=None))), (8868, (104, PredictedToken(token=' Blue', prob=3.790855407714844e-05, logit=10.8125, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:51 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:51 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.691, logit=19.500)', '\" Lion\"[33199] (p=0.120, logit=17.750)', '\" The\"[578] (p=0.057, logit=17.000)', '\" R\"[432] (p=0.014, logit=15.625)', '\" There\"[2684] (p=0.013, logit=15.500)']\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.463, logit=19.250)', '\" There\"[2684] (p=0.193, logit=18.375)', '\" Bamboo\"[98028] (p=0.091, logit=17.625)', '\" The\"[578] (p=0.091, logit=17.625)', '\" None\"[2290] (p=0.033, logit=16.625)']\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.462890625, logit=19.25, token_id=14937, metadata=None))), (98028, (4, PredictedToken(token=' Bamboo', prob=0.09130859375, logit=17.625, token_id=98028, metadata=None))), (1666, (6, PredictedToken(token=' As', prob=0.015869140625, logit=15.875, token_id=1666, metadata=None))), (34392, (7, PredictedToken(token=' Horse', prob=0.014892578125, logit=15.8125, token_id=34392, metadata=None))), (22607, (8, PredictedToken(token=' Cow', prob=0.0115966796875, logit=15.5625, token_id=22607, metadata=None)))])\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.785, logit=20.875)', '\" There\"[2684] (p=0.083, logit=18.625)', '\" The\"[578] (p=0.034, logit=17.750)', '\" Bamboo\"[98028] (p=0.016, logit=17.000)', '\" None\"[2290] (p=0.014, logit=16.875)']\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.78515625, logit=20.875, token_id=34392, metadata=None))), (98028, (4, PredictedToken(token=' Bamboo', prob=0.0162353515625, logit=17.0, token_id=98028, metadata=None))), (22607, (7, PredictedToken(token=' Cow', prob=0.00872802734375, logit=16.375, token_id=22607, metadata=None))), (14937, (10, PredictedToken(token=' Ash', prob=0.002197265625, logit=15.0, token_id=14937, metadata=None))), (1666, (20, PredictedToken(token=' As', prob=0.0007171630859375, logit=13.875, token_id=1666, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:52 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     patch_prediction=['\" Printer\"[47033] (p=0.652, logit=20.000)', '\" Monitor\"[24423] (p=0.187, logit=18.750)', '\" The\"[578] (p=0.047, logit=17.375)', '\" B\"[426] (p=0.017, logit=16.375)', '\" printer\"[23185] (p=0.012, logit=16.000)']\n",
      "2025-09-15 09:42:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:53 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.486, logit=19.375)', '\" Bro\"[6031] (p=0.295, logit=18.875)', '\" The\"[578] (p=0.075, logit=17.500)', '\" LO\"[5125] (p=0.024, logit=16.375)', '\" A\"[362] (p=0.024, logit=16.375)']\n",
      "2025-09-15 09:42:53 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.486328125, logit=19.375, token_id=445, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.294921875, logit=18.875, token_id=6031, metadata=None))), (5907, (9, PredictedToken(token=' Project', prob=0.00506591796875, logit=14.8125, token_id=5907, metadata=None))), (39794, (33, PredictedToken(token=' Desk', prob=0.000606536865234375, logit=12.6875, token_id=39794, metadata=None))), (30173, (205, PredictedToken(token=' Speaker', prob=2.658367156982422e-05, logit=9.5625, token_id=30173, metadata=None)))])\n",
      "2025-09-15 09:42:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:53 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.711, logit=19.625)', '\" Project\"[5907] (p=0.096, logit=17.625)', '\" The\"[578] (p=0.058, logit=17.125)', '\" A\"[362] (p=0.021, logit=16.125)', '\" It\"[1102] (p=0.013, logit=15.625)']\n",
      "2025-09-15 09:42:53 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.7109375, logit=19.625, token_id=30173, metadata=None))), (5907, (2, PredictedToken(token=' Project', prob=0.09619140625, logit=17.625, token_id=5907, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.007415771484375, logit=15.0625, token_id=6031, metadata=None))), (39794, (49, PredictedToken(token=' Desk', prob=0.0002880096435546875, logit=11.8125, token_id=39794, metadata=None))), (445, (82, PredictedToken(token=' L', prob=0.00013637542724609375, logit=11.0625, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:53 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.750, logit=19.750)', '\" The\"[578] (p=0.090, logit=17.625)', '\" Gir\"[48035] (p=0.062, logit=17.250)', '\" A\"[362] (p=0.015, logit=15.812)', '\" Elephant\"[79189] (p=0.009, logit=15.312)']\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.336, logit=18.250)', '\" Mall\"[32498] (p=0.262, logit=18.000)', '\" The\"[578] (p=0.180, logit=17.625)', '\" A\"[362] (p=0.075, logit=16.750)', '\" Tiger\"[36845] (p=0.023, logit=15.562)']\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.3359375, logit=18.25, token_id=17367, metadata=None))), (32498, (2, PredictedToken(token=' Mall', prob=0.26171875, logit=18.0, token_id=32498, metadata=None))), (36845, (5, PredictedToken(token=' Tiger', prob=0.0228271484375, logit=15.5625, token_id=36845, metadata=None))), (84008, (9, PredictedToken(token=' Sheep', prob=0.00787353515625, logit=14.5, token_id=84008, metadata=None))), (49268, (19, PredictedToken(token=' Dish', prob=0.00099945068359375, logit=12.4375, token_id=49268, metadata=None)))])\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.750, logit=18.875)', '\" The\"[578] (p=0.062, logit=16.375)', '\" Factory\"[17367] (p=0.029, logit=15.625)', '\" A\"[362] (p=0.029, logit=15.625)', '\" Sheep\"[84008] (p=0.026, logit=15.500)']\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.75, logit=18.875, token_id=36845, metadata=None))), (17367, (4, PredictedToken(token=' Factory', prob=0.0291748046875, logit=15.625, token_id=17367, metadata=None))), (84008, (5, PredictedToken(token=' Sheep', prob=0.0257568359375, logit=15.5, token_id=84008, metadata=None))), (32498, (8, PredictedToken(token=' Mall', prob=0.00946044921875, logit=14.5, token_id=32498, metadata=None))), (49268, (11, PredictedToken(token=' Dish', prob=0.003265380859375, logit=13.4375, token_id=49268, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:54 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:54 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:42:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.859, logit=20.375)', '\" The\"[578] (p=0.033, logit=17.125)', '\" Maple\"[44570] (p=0.020, logit=16.625)', '\" SPR\"[52367] (p=0.020, logit=16.625)', '\" There\"[2684] (p=0.008, logit=15.688)']\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.949, logit=21.750)', '\" The\"[578] (p=0.012, logit=17.375)', '\" Comb\"[23262] (p=0.009, logit=17.125)', '\" Stap\"[63606] (p=0.007, logit=16.875)', '\" A\"[362] (p=0.006, logit=16.625)']\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.94921875, logit=21.75, token_id=41493, metadata=None))), (23262, (3, PredictedToken(token=' Comb', prob=0.00927734375, logit=17.125, token_id=23262, metadata=None))), (63606, (4, PredictedToken(token=' Stap', prob=0.007232666015625, logit=16.875, token_id=63606, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.0022125244140625, logit=15.6875, token_id=469, metadata=None))), (18654, (9, PredictedToken(token=' Micro', prob=0.00110626220703125, logit=15.0, token_id=18654, metadata=None))), (42609, (44, PredictedToken(token=' Pine', prob=6.67572021484375e-05, logit=12.1875, token_id=42609, metadata=None))), (75258, (119, PredictedToken(token=' Refriger', prob=1.4841556549072266e-05, logit=10.6875, token_id=75258, metadata=None)))])\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.832, logit=20.375)', '\" E\"[469] (p=0.053, logit=17.625)', '\" The\"[578] (p=0.029, logit=17.000)', '\" None\"[2290] (p=0.010, logit=16.000)', '\" Comb\"[23262] (p=0.009, logit=15.875)']\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.83203125, logit=20.375, token_id=42609, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.05322265625, logit=17.625, token_id=469, metadata=None))), (23262, (5, PredictedToken(token=' Comb', prob=0.00927734375, logit=15.875, token_id=23262, metadata=None))), (41493, (6, PredictedToken(token=' Tow', prob=0.0081787109375, logit=15.75, token_id=41493, metadata=None))), (18654, (13, PredictedToken(token=' Micro', prob=0.0019378662109375, logit=14.3125, token_id=18654, metadata=None))), (75258, (14, PredictedToken(token=' Refriger', prob=0.00182342529296875, logit=14.25, token_id=75258, metadata=None))), (63606, (165, PredictedToken(token=' Stap', prob=2.4437904357910156e-05, logit=9.9375, token_id=63606, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:55 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:42:55 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:42:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.617, logit=19.625)', '\" Book\"[6017] (p=0.138, logit=18.125)', '\" The\"[578] (p=0.083, logit=17.625)', '\" Bus\"[19111] (p=0.074, logit=17.500)', '\" A\"[362] (p=0.016, logit=16.000)']\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.523, logit=20.125)', '\" The\"[578] (p=0.192, logit=19.125)', '\" Dish\"[49268] (p=0.170, logit=19.000)', '\" An\"[1556] (p=0.014, logit=16.500)', '\" O\"[507] (p=0.011, logit=16.250)']\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.5234375, logit=20.125, token_id=87213, metadata=None))), (49268, (3, PredictedToken(token=' Dish', prob=0.169921875, logit=19.0, token_id=49268, metadata=None))), (20423, (6, PredictedToken(token=' Amb', prob=0.0108642578125, logit=16.25, token_id=20423, metadata=None))), (61948, (44, PredictedToken(token=' Sofa', prob=0.000270843505859375, logit=12.5625, token_id=61948, metadata=None))), (68867, (133, PredictedToken(token=' Coat', prob=4.4345855712890625e-05, logit=10.75, token_id=68867, metadata=None))), (16478, (310, PredictedToken(token=' Chair', prob=9.298324584960938e-06, logit=9.1875, token_id=16478, metadata=None)))])\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.486, logit=19.250)', '\" Sofa\"[61948] (p=0.140, logit=18.000)', '\" The\"[578] (p=0.140, logit=18.000)', '\" Dish\"[49268] (p=0.045, logit=16.875)', '\" A\"[362] (p=0.027, logit=16.375)']\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.486328125, logit=19.25, token_id=16478, metadata=None))), (61948, (3, PredictedToken(token=' Sofa', prob=0.1396484375, logit=18.0, token_id=61948, metadata=None))), (49268, (4, PredictedToken(token=' Dish', prob=0.045166015625, logit=16.875, token_id=49268, metadata=None))), (20423, (6, PredictedToken(token=' Amb', prob=0.0242919921875, logit=16.25, token_id=20423, metadata=None))), (68867, (25, PredictedToken(token=' Coat', prob=0.0007781982421875, logit=12.8125, token_id=68867, metadata=None))), (87213, (64, PredictedToken(token=' Oven', prob=0.0002231597900390625, logit=11.5625, token_id=87213, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:56 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:42:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.871, logit=20.375)', '\" The\"[578] (p=0.026, logit=16.875)', '\" A\"[362] (p=0.023, logit=16.750)', '\" To\"[2057] (p=0.014, logit=16.250)', '\" Paper\"[18343] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     clean_prediction=['\" Hospital\"[15429] (p=0.793, logit=20.750)', '\" The\"[578] (p=0.074, logit=18.375)', '\" A\"[362] (p=0.035, logit=17.625)', '\" Stadium\"[23462] (p=0.019, logit=17.000)', '\" H\"[473] (p=0.016, logit=16.875)']\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     clean_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.79296875, logit=20.75, token_id=15429, metadata=None))), (23462, (4, PredictedToken(token=' Stadium', prob=0.0186767578125, logit=17.0, token_id=23462, metadata=None))), (6690, (8, PredictedToken(token=' Air', prob=0.0032501220703125, logit=15.25, token_id=6690, metadata=None))), (18343, (15, PredictedToken(token=' Paper', prob=0.00127410888671875, logit=14.3125, token_id=18343, metadata=None))), (37128, (45, PredictedToken(token=' Calculator', prob=0.00022125244140625, logit=12.5625, token_id=37128, metadata=None)))])\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.785, logit=20.000)', '\" The\"[578] (p=0.057, logit=17.375)', '\" Calculator\"[37128] (p=0.031, logit=16.750)', '\" A\"[362] (p=0.024, logit=16.500)', '\" None\"[2290] (p=0.018, logit=16.250)']\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.78515625, logit=20.0, token_id=18343, metadata=None))), (37128, (3, PredictedToken(token=' Calculator', prob=0.030517578125, logit=16.75, token_id=37128, metadata=None))), (15429, (6, PredictedToken(token=' Hospital', prob=0.01055908203125, logit=15.6875, token_id=15429, metadata=None))), (23462, (8, PredictedToken(token=' Stadium', prob=0.006805419921875, logit=15.25, token_id=23462, metadata=None))), (6690, (9, PredictedToken(token=' Air', prob=0.00531005859375, logit=15.0, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:57 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:42:57 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.459, logit=17.750)', '\" Rabbit\"[49431] (p=0.169, logit=16.750)', '\" The\"[578] (p=0.102, logit=16.250)', '\" There\"[2684] (p=0.031, logit=15.062)', '\" Sk\"[4923] (p=0.024, logit=14.812)']\n",
      "2025-09-15 09:42:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     clean_prediction=['\" Football\"[21424] (p=0.809, logit=20.125)', '\" The\"[578] (p=0.097, logit=18.000)', '\" A\"[362] (p=0.013, logit=16.000)', '\" FOOT\"[81137] (p=0.011, logit=15.812)', '\" Surf\"[65197] (p=0.009, logit=15.625)']\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     clean_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.80859375, logit=20.125, token_id=21424, metadata=None))), (65197, (5, PredictedToken(token=' Surf', prob=0.00897216796875, logit=15.625, token_id=65197, metadata=None))), (33199, (103, PredictedToken(token=' Lion', prob=6.0558319091796875e-05, logit=10.625, token_id=33199, metadata=None))), (58937, (153, PredictedToken(token=' Monkey', prob=3.24249267578125e-05, logit=10.0, token_id=58937, metadata=None)))])\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     int_prediction=['\" Monkey\"[58937] (p=0.875, logit=20.000)', '\" The\"[578] (p=0.034, logit=16.750)', '\" Football\"[21424] (p=0.011, logit=15.625)', '\" MON\"[29637] (p=0.009, logit=15.438)', '\" There\"[2684] (p=0.009, logit=15.375)']\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     int_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.875, logit=20.0, token_id=58937, metadata=None))), (21424, (3, PredictedToken(token=' Football', prob=0.01104736328125, logit=15.625, token_id=21424, metadata=None))), (65197, (7, PredictedToken(token=' Surf', prob=0.007568359375, logit=15.25, token_id=65197, metadata=None))), (33199, (20, PredictedToken(token=' Lion', prob=0.0010223388671875, logit=13.25, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:42:58 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     patch_prediction=['\" Acc\"[11683] (p=0.770, logit=21.125)', '\" The\"[578] (p=0.118, logit=19.250)', '\" R\"[432] (p=0.049, logit=18.375)', '\" Accord\"[80657] (p=0.011, logit=16.875)', '\" An\"[1556] (p=0.006, logit=16.250)']\n",
      "2025-09-15 09:42:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:42:59 src.selection.optimization INFO     clean_prediction=['\" Gloves\"[68554] (p=0.809, logit=20.250)', '\" The\"[578] (p=0.085, logit=18.000)', '\" Sk\"[4923] (p=0.035, logit=17.125)', '\" Glo\"[25372] (p=0.006, logit=15.375)', '\" G\"[480] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:42:59 src.selection.optimization INFO     clean_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.80859375, logit=20.25, token_id=68554, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.035400390625, logit=17.125, token_id=4923, metadata=None))), (40759, (9, PredictedToken(token=' Harmon', prob=0.0025787353515625, logit=14.5, token_id=40759, metadata=None))), (97796, (17, PredictedToken(token=' Skate', prob=0.001007080078125, logit=13.5625, token_id=97796, metadata=None))), (3420, (125, PredictedToken(token=' Trump', prob=4.4345855712890625e-05, logit=10.4375, token_id=3420, metadata=None)))])\n",
      "2025-09-15 09:42:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:42:59 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.875, logit=20.750)', '\" The\"[578] (p=0.043, logit=17.750)', '\" TR\"[5091] (p=0.026, logit=17.250)', '\" Sk\"[4923] (p=0.012, logit=16.500)', '\" Harmon\"[40759] (p=0.007, logit=15.875)']\n",
      "2025-09-15 09:42:59 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.875, logit=20.75, token_id=3420, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.012451171875, logit=16.5, token_id=4923, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.006683349609375, logit=15.875, token_id=40759, metadata=None))), (68554, (11, PredictedToken(token=' Gloves', prob=0.00168609619140625, logit=14.5, token_id=68554, metadata=None))), (97796, (21, PredictedToken(token=' Skate', prob=0.0004825592041015625, logit=13.25, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:42:59 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:42:59 src.selection.optimization DEBUG    torch.Size([7, 31])\n",
      "2025-09-15 09:42:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     patch_prediction=['\" Router\"[10777] (p=0.656, logit=19.875)', '\" Phone\"[14642] (p=0.129, logit=18.250)', '\" The\"[578] (p=0.114, logit=18.125)', '\" A\"[362] (p=0.015, logit=16.125)', '\" ROUT\"[54281] (p=0.006, logit=15.125)']\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.883, logit=21.375)', '\" The\"[578] (p=0.050, logit=18.500)', '\" Car\"[3341] (p=0.021, logit=17.625)', '\" There\"[2684] (p=0.013, logit=17.125)', '\" AS\"[5871] (p=0.006, logit=16.375)']\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.8828125, logit=21.375, token_id=1666, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.020751953125, logit=17.625, token_id=3341, metadata=None))), (49268, (19, PredictedToken(token=' Dish', prob=0.0003566741943359375, logit=13.5625, token_id=49268, metadata=None))), (57094, (34, PredictedToken(token=' Highlight', prob=0.00016880035400390625, logit=12.8125, token_id=57094, metadata=None))), (38258, (66, PredictedToken(token=' Baseball', prob=6.198883056640625e-05, logit=11.8125, token_id=38258, metadata=None))), (30173, (150, PredictedToken(token=' Speaker', prob=1.6689300537109375e-05, logit=10.5, token_id=30173, metadata=None))), (18191, (158, PredictedToken(token=' Mouse', prob=1.4722347259521484e-05, logit=10.375, token_id=18191, metadata=None)))])\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.531, logit=20.375)', '\" The\"[578] (p=0.223, logit=19.500)', '\" Highlight\"[57094] (p=0.119, logit=18.875)', '\" A\"[362] (p=0.039, logit=17.750)', '\" There\"[2684] (p=0.016, logit=16.875)']\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.53125, logit=20.375, token_id=30173, metadata=None))), (57094, (3, PredictedToken(token=' Highlight', prob=0.119140625, logit=18.875, token_id=57094, metadata=None))), (18191, (6, PredictedToken(token=' Mouse', prob=0.01422119140625, logit=16.75, token_id=18191, metadata=None))), (38258, (13, PredictedToken(token=' Baseball', prob=0.00140380859375, logit=14.4375, token_id=38258, metadata=None))), (3341, (16, PredictedToken(token=' Car', prob=0.0010986328125, logit=14.1875, token_id=3341, metadata=None))), (1666, (26, PredictedToken(token=' As', prob=0.000518798828125, logit=13.4375, token_id=1666, metadata=None))), (49268, (28, PredictedToken(token=' Dish', prob=0.0004558563232421875, logit=13.3125, token_id=49268, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:00 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:00 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     patch_prediction=['\" Blender\"[88668] (p=0.730, logit=21.250)', '\" The\"[578] (p=0.144, logit=19.625)', '\" K\"[735] (p=0.053, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.125)', '\" BLE\"[52818] (p=0.008, logit=16.750)']\n",
      "2025-09-15 09:43:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.777, logit=21.250)', '\" The\"[578] (p=0.120, logit=19.375)', '\" A\"[362] (p=0.050, logit=18.500)', '\" BRO\"[78687] (p=0.014, logit=17.250)', '\" It\"[1102] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.77734375, logit=21.25, token_id=6031, metadata=None))), (2057, (6, PredictedToken(token=' To', prob=0.0031890869140625, logit=15.75, token_id=2057, metadata=None))), (10573, (15, PredictedToken(token=' Watch', prob=0.000972747802734375, logit=14.5625, token_id=10573, metadata=None))), (22410, (34, PredictedToken(token=' Ju', prob=0.000179290771484375, logit=12.875, token_id=22410, metadata=None))), (14588, (45, PredictedToken(token=' Dog', prob=0.00011587142944335938, logit=12.4375, token_id=14588, metadata=None)))])\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     int_prediction=['\" To\"[2057] (p=0.711, logit=20.500)', '\" The\"[578] (p=0.123, logit=18.750)', '\" TO\"[5257] (p=0.066, logit=18.125)', '\" A\"[362] (p=0.024, logit=17.125)', '\" Watch\"[10573] (p=0.021, logit=17.000)']\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     int_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.7109375, logit=20.5, token_id=2057, metadata=None))), (10573, (5, PredictedToken(token=' Watch', prob=0.0213623046875, logit=17.0, token_id=10573, metadata=None))), (6031, (6, PredictedToken(token=' Bro', prob=0.0167236328125, logit=16.75, token_id=6031, metadata=None))), (22410, (16, PredictedToken(token=' Ju', prob=0.001068115234375, logit=14.0, token_id=22410, metadata=None))), (14588, (57, PredictedToken(token=' Dog', prob=0.00010538101196289062, logit=11.6875, token_id=14588, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:01 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.867, logit=21.375)', '\" The\"[578] (p=0.071, logit=18.875)', '\" P\"[393] (p=0.016, logit=17.375)', '\" X\"[1630] (p=0.011, logit=17.000)', '\" A\"[362] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:43:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:02 src.selection.optimization INFO     clean_prediction=['\" Ki\"[30558] (p=0.820, logit=21.000)', '\" Pear\"[23910] (p=0.076, logit=18.625)', '\" The\"[578] (p=0.052, logit=18.250)', '\" Fl\"[3061] (p=0.009, logit=16.500)', '\" K\"[735] (p=0.008, logit=16.375)']\n",
      "2025-09-15 09:43:02 src.selection.optimization INFO     clean_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.8203125, logit=21.0, token_id=30558, metadata=None))), (23910, (2, PredictedToken(token=' Pear', prob=0.076171875, logit=18.625, token_id=23910, metadata=None))), (3061, (4, PredictedToken(token=' Fl', prob=0.00909423828125, logit=16.5, token_id=3061, metadata=None))), (1443, (11, PredictedToken(token=' Sh', prob=0.00157928466796875, logit=14.75, token_id=1443, metadata=None))), (40759, (16, PredictedToken(token=' Harmon', prob=0.000659942626953125, logit=13.875, token_id=40759, metadata=None)))])\n",
      "2025-09-15 09:43:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:02 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.855, logit=20.625)', '\" The\"[578] (p=0.055, logit=17.875)', '\" Fl\"[3061] (p=0.023, logit=17.000)', '\" Ki\"[30558] (p=0.018, logit=16.750)', '\" Sh\"[1443] (p=0.008, logit=15.938)']\n",
      "2025-09-15 09:43:02 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.85546875, logit=20.625, token_id=40759, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.0228271484375, logit=17.0, token_id=3061, metadata=None))), (30558, (4, PredictedToken(token=' Ki', prob=0.017822265625, logit=16.75, token_id=30558, metadata=None))), (1443, (5, PredictedToken(token=' Sh', prob=0.00787353515625, logit=15.9375, token_id=1443, metadata=None))), (23910, (11, PredictedToken(token=' Pear', prob=0.00165557861328125, logit=14.375, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:02 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:02 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:43:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.820, logit=20.250)', '\" The\"[578] (p=0.052, logit=17.500)', '\" An\"[1556] (p=0.028, logit=16.875)', '\" Cow\"[22607] (p=0.022, logit=16.625)', '\" E\"[469] (p=0.019, logit=16.500)']\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.809, logit=19.875)', '\" The\"[578] (p=0.066, logit=17.375)', '\" None\"[2290] (p=0.015, logit=15.875)', '\" A\"[362] (p=0.015, logit=15.875)', '\" Food\"[12369] (p=0.011, logit=15.562)']\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.80859375, logit=19.875, token_id=75258, metadata=None))), (12369, (5, PredictedToken(token=' Food', prob=0.0108642578125, logit=15.5625, token_id=12369, metadata=None))), (58937, (8, PredictedToken(token=' Monkey', prob=0.0045166015625, logit=14.6875, token_id=58937, metadata=None))), (49431, (40, PredictedToken(token=' Rabbit', prob=0.0004215240478515625, logit=12.3125, token_id=49431, metadata=None)))])\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.680, logit=18.875)', '\" Monkey\"[58937] (p=0.071, logit=16.625)', '\" The\"[578] (p=0.049, logit=16.250)', '\" None\"[2290] (p=0.043, logit=16.125)', '\" A\"[362] (p=0.023, logit=15.500)']\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.6796875, logit=18.875, token_id=49431, metadata=None))), (58937, (2, PredictedToken(token=' Monkey', prob=0.0712890625, logit=16.625, token_id=58937, metadata=None))), (75258, (7, PredictedToken(token=' Refriger', prob=0.023193359375, logit=15.5, token_id=75258, metadata=None))), (12369, (16, PredictedToken(token=' Food', prob=0.0019073486328125, logit=13.0, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:03 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:03 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     patch_prediction=['\" Baseball\"[38258] (p=0.754, logit=20.875)', '\" The\"[578] (p=0.168, logit=19.375)', '\" A\"[362] (p=0.023, logit=17.375)', '\" BASE\"[22984] (p=0.011, logit=16.625)', '\" It\"[1102] (p=0.003, logit=15.250)']\n",
      "2025-09-15 09:43:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     clean_prediction=['\" Strawberry\"[89077] (p=0.613, logit=20.250)', '\" Pear\"[23910] (p=0.227, logit=19.250)', '\" The\"[578] (p=0.083, logit=18.250)', '\" A\"[362] (p=0.011, logit=16.250)', '\" There\"[2684] (p=0.009, logit=16.000)']\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     clean_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.61328125, logit=20.25, token_id=89077, metadata=None))), (23910, (2, PredictedToken(token=' Pear', prob=0.2265625, logit=19.25, token_id=23910, metadata=None))), (16488, (11, PredictedToken(token=' Bat', prob=0.001953125, logit=14.5, token_id=16488, metadata=None))), (28131, (29, PredictedToken(token=' Golf', prob=0.0004367828369140625, logit=13.0, token_id=28131, metadata=None)))])\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.570, logit=20.125)', '\" Golf\"[28131] (p=0.237, logit=19.250)', '\" The\"[578] (p=0.077, logit=18.125)', '\" Pear\"[23910] (p=0.025, logit=17.000)', '\" A\"[362] (p=0.025, logit=17.000)']\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.5703125, logit=20.125, token_id=16488, metadata=None))), (28131, (2, PredictedToken(token=' Golf', prob=0.2373046875, logit=19.25, token_id=28131, metadata=None))), (23910, (5, PredictedToken(token=' Pear', prob=0.0250244140625, logit=17.0, token_id=23910, metadata=None))), (89077, (33, PredictedToken(token=' Strawberry', prob=0.000335693359375, logit=12.6875, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:04 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:04 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     patch_prediction=['\" Onion\"[87035] (p=0.539, logit=19.875)', '\" Caul\"[90538] (p=0.226, logit=19.000)', '\" The\"[578] (p=0.137, logit=18.500)', '\" There\"[2684] (p=0.021, logit=16.625)', '\" ON\"[6328] (p=0.014, logit=16.250)']\n",
      "2025-09-15 09:43:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:05 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.777, logit=20.750)', '\" The\"[578] (p=0.064, logit=18.250)', '\" A\"[362] (p=0.050, logit=18.000)', '\" R\"[432] (p=0.044, logit=17.875)', '\" PEN\"[81770] (p=0.018, logit=17.000)']\n",
      "2025-09-15 09:43:05 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.77734375, logit=20.75, token_id=13597, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.0439453125, logit=17.875, token_id=432, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.003387451171875, logit=15.3125, token_id=6031, metadata=None))), (1901, (59, PredictedToken(token=' Z', prob=0.00011587142944335938, logit=11.9375, token_id=1901, metadata=None)))])\n",
      "2025-09-15 09:43:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:05 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.770, logit=20.125)', '\" Z\"[1901] (p=0.104, logit=18.125)', '\" The\"[578] (p=0.026, logit=16.750)', '\" R\"[432] (p=0.023, logit=16.625)', '\" BRO\"[78687] (p=0.014, logit=16.125)']\n",
      "2025-09-15 09:43:05 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.76953125, logit=20.125, token_id=6031, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.10400390625, logit=18.125, token_id=1901, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.023193359375, logit=16.625, token_id=432, metadata=None))), (13597, (7, PredictedToken(token=' Pen', prob=0.006256103515625, logit=15.3125, token_id=13597, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:05 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.602, logit=19.500)', '\" Theater\"[38571] (p=0.195, logit=18.375)', '\" The\"[578] (p=0.072, logit=17.375)', '\" A\"[362] (p=0.038, logit=16.750)', '\" CH\"[6969] (p=0.011, logit=15.500)']\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     clean_prediction=['\" To\"[2057] (p=0.797, logit=20.500)', '\" The\"[578] (p=0.065, logit=18.000)', '\" Microwave\"[98641] (p=0.051, logit=17.750)', '\" TO\"[5257] (p=0.024, logit=17.000)', '\" A\"[362] (p=0.016, logit=16.625)']\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     clean_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.796875, logit=20.5, token_id=2057, metadata=None))), (98641, (3, PredictedToken(token=' Microwave', prob=0.05078125, logit=17.75, token_id=98641, metadata=None))), (48471, (6, PredictedToken(token=' Shower', prob=0.0078125, logit=15.875, token_id=48471, metadata=None))), (4783, (83, PredictedToken(token=' House', prob=6.341934204101562e-05, logit=11.0625, token_id=4783, metadata=None))), (52466, (96, PredictedToken(token=' Warehouse', prob=4.935264587402344e-05, logit=10.8125, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     int_prediction=['\" House\"[4783] (p=0.734, logit=20.125)', '\" HOUSE\"[69461] (p=0.078, logit=17.875)', '\" The\"[578] (p=0.078, logit=17.875)', '\" Microwave\"[98641] (p=0.037, logit=17.125)', '\" Shower\"[48471] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     int_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.734375, logit=20.125, token_id=4783, metadata=None))), (98641, (4, PredictedToken(token=' Microwave', prob=0.03662109375, logit=17.125, token_id=98641, metadata=None))), (48471, (5, PredictedToken(token=' Shower', prob=0.010498046875, logit=15.875, token_id=48471, metadata=None))), (52466, (10, PredictedToken(token=' Warehouse', prob=0.0030059814453125, logit=14.625, token_id=52466, metadata=None))), (2057, (20, PredictedToken(token=' To', prob=0.000759124755859375, logit=13.25, token_id=2057, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:06 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:06 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:06 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.758, logit=20.625)', '\" The\"[578] (p=0.149, logit=19.000)', '\" Horse\"[34392] (p=0.020, logit=17.000)', '\" R\"[432] (p=0.020, logit=17.000)', '\" A\"[362] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     clean_prediction=['\" Oak\"[18787] (p=0.691, logit=19.375)', '\" The\"[578] (p=0.083, logit=17.250)', '\" Palm\"[33578] (p=0.057, logit=16.875)', '\" SPE\"[68835] (p=0.024, logit=16.000)', '\" Speaker\"[30173] (p=0.022, logit=15.938)']\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     clean_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.69140625, logit=19.375, token_id=18787, metadata=None))), (33578, (3, PredictedToken(token=' Palm', prob=0.056884765625, logit=16.875, token_id=33578, metadata=None))), (30173, (5, PredictedToken(token=' Speaker', prob=0.022216796875, logit=15.9375, token_id=30173, metadata=None))), (5340, (8, PredictedToken(token=' Har', prob=0.0098876953125, logit=15.125, token_id=5340, metadata=None))), (36845, (9, PredictedToken(token=' Tiger', prob=0.007232666015625, logit=14.8125, token_id=36845, metadata=None))), (47643, (13, PredictedToken(token=' Cel', prob=0.002197265625, logit=13.625, token_id=47643, metadata=None))), (24941, (38, PredictedToken(token=' Bear', prob=0.000762939453125, logit=12.5625, token_id=24941, metadata=None)))])\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.801, logit=19.500)', '\" The\"[578] (p=0.058, logit=16.875)', '\" Bear\"[24941] (p=0.020, logit=15.812)', '\" There\"[2684] (p=0.018, logit=15.688)', '\" T\"[350] (p=0.009, logit=15.062)']\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.80078125, logit=19.5, token_id=36845, metadata=None))), (24941, (3, PredictedToken(token=' Bear', prob=0.02001953125, logit=15.8125, token_id=24941, metadata=None))), (30173, (8, PredictedToken(token=' Speaker', prob=0.006103515625, logit=14.625, token_id=30173, metadata=None))), (33578, (12, PredictedToken(token=' Palm', prob=0.004180908203125, logit=14.25, token_id=33578, metadata=None))), (18787, (16, PredictedToken(token=' Oak', prob=0.001861572265625, logit=13.4375, token_id=18787, metadata=None))), (47643, (19, PredictedToken(token=' Cel', prob=0.00128173828125, logit=13.0625, token_id=47643, metadata=None))), (5340, (22, PredictedToken(token=' Har', prob=0.00106048583984375, logit=12.875, token_id=5340, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:07 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:07 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:43:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.836, logit=21.250)', '\" The\"[578] (p=0.078, logit=18.875)', '\" Monkey\"[58937] (p=0.032, logit=18.000)', '\" A\"[362] (p=0.020, logit=17.500)', '\" There\"[2684] (p=0.004, logit=16.000)']\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.820, logit=20.250)', '\" The\"[578] (p=0.059, logit=17.625)', '\" BAT\"[79081] (p=0.022, logit=16.625)', '\" Gloves\"[68554] (p=0.015, logit=16.250)', '\" A\"[362] (p=0.015, logit=16.250)']\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.8203125, logit=20.25, token_id=16488, metadata=None))), (68554, (5, PredictedToken(token=' Gloves', prob=0.0150146484375, logit=16.25, token_id=68554, metadata=None))), (11683, (7, PredictedToken(token=' Acc', prob=0.005523681640625, logit=15.25, token_id=11683, metadata=None))), (38673, (23, PredictedToken(token=' Yoga', prob=0.0007476806640625, logit=13.25, token_id=38673, metadata=None))), (48035, (72, PredictedToken(token=' Gir', prob=8.392333984375e-05, logit=11.0625, token_id=48035, metadata=None))), (14588, (103, PredictedToken(token=' Dog', prob=5.078315734863281e-05, logit=10.5625, token_id=14588, metadata=None))), (12369, (173, PredictedToken(token=' Food', prob=2.1219253540039062e-05, logit=9.6875, token_id=12369, metadata=None)))])\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.590, logit=19.750)', '\" Gir\"[48035] (p=0.132, logit=18.250)', '\" The\"[578] (p=0.055, logit=17.375)', '\" Gloves\"[68554] (p=0.043, logit=17.125)', '\" Dog\"[14588] (p=0.038, logit=17.000)']\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.58984375, logit=19.75, token_id=16488, metadata=None))), (48035, (2, PredictedToken(token=' Gir', prob=0.1318359375, logit=18.25, token_id=48035, metadata=None))), (68554, (4, PredictedToken(token=' Gloves', prob=0.042724609375, logit=17.125, token_id=68554, metadata=None))), (14588, (5, PredictedToken(token=' Dog', prob=0.037841796875, logit=17.0, token_id=14588, metadata=None))), (38673, (22, PredictedToken(token=' Yoga', prob=0.00113677978515625, logit=13.5, token_id=38673, metadata=None))), (11683, (43, PredictedToken(token=' Acc', prob=0.0002880096435546875, logit=12.125, token_id=11683, metadata=None))), (12369, (1213, PredictedToken(token=' Food', prob=1.3336539268493652e-06, logit=6.75, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:08 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:08 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:43:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.859, logit=21.125)', '\" The\"[578] (p=0.080, logit=18.750)', '\" A\"[362] (p=0.014, logit=17.000)', '\" J\"[622] (p=0.007, logit=16.250)', '\" There\"[2684] (p=0.004, logit=15.750)']\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     clean_prediction=['\" Orange\"[22725] (p=0.719, logit=21.000)', '\" Mango\"[91963] (p=0.097, logit=19.000)', '\" The\"[578] (p=0.086, logit=18.875)', '\" OR\"[2794] (p=0.025, logit=17.625)', '\" An\"[1556] (p=0.019, logit=17.375)']\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     clean_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.71875, logit=21.0, token_id=22725, metadata=None))), (91963, (2, PredictedToken(token=' Mango', prob=0.09716796875, logit=19.0, token_id=91963, metadata=None))), (60413, (48, PredictedToken(token=' Uk', prob=0.0001373291015625, logit=12.4375, token_id=60413, metadata=None))), (328, (59, PredictedToken(token=' S', prob=9.441375732421875e-05, logit=12.0625, token_id=328, metadata=None))), (4923, (90, PredictedToken(token=' Sk', prob=5.3882598876953125e-05, logit=11.5, token_id=4923, metadata=None))), (96096, (102, PredictedToken(token=' Dolphin', prob=4.458427429199219e-05, logit=11.3125, token_id=96096, metadata=None))), (16147, (421, PredictedToken(token=' Smart', prob=3.4421682357788086e-06, logit=8.75, token_id=16147, metadata=None)))])\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.715, logit=20.250)', '\" The\"[578] (p=0.181, logit=18.875)', '\" A\"[362] (p=0.019, logit=16.625)', '\" S\"[328] (p=0.017, logit=16.500)', '\" There\"[2684] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.71484375, logit=20.25, token_id=4923, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.016845703125, logit=16.5, token_id=328, metadata=None))), (91963, (6, PredictedToken(token=' Mango', prob=0.0045166015625, logit=15.1875, token_id=91963, metadata=None))), (60413, (9, PredictedToken(token=' Uk', prob=0.00274658203125, logit=14.6875, token_id=60413, metadata=None))), (22725, (13, PredictedToken(token=' Orange', prob=0.0016632080078125, logit=14.1875, token_id=22725, metadata=None))), (96096, (50, PredictedToken(token=' Dolphin', prob=0.0002117156982421875, logit=12.125, token_id=96096, metadata=None))), (16147, (56, PredictedToken(token=' Smart', prob=0.0001544952392578125, logit=11.8125, token_id=16147, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:09 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:43:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.738, logit=21.250)', '\" The\"[578] (p=0.187, logit=19.875)', '\" It\"[1102] (p=0.014, logit=17.250)', '\" c\"[272] (p=0.012, logit=17.125)', '\" Piano\"[56491] (p=0.009, logit=16.875)']\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.777, logit=20.375)', '\" The\"[578] (p=0.135, logit=18.625)', '\" Pants\"[67553] (p=0.016, logit=16.500)', '\" A\"[362] (p=0.013, logit=16.250)', '\" J\"[622] (p=0.008, logit=15.812)']\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.77734375, logit=20.375, token_id=55870, metadata=None))), (67553, (3, PredictedToken(token=' Pants', prob=0.01611328125, logit=16.5, token_id=67553, metadata=None))), (11683, (6, PredictedToken(token=' Acc', prob=0.00433349609375, logit=15.1875, token_id=11683, metadata=None))), (47759, (66, PredictedToken(token=' Guitar', prob=0.00011587142944335938, logit=11.5625, token_id=47759, metadata=None))), (14669, (231, PredictedToken(token=' Camera', prob=1.2993812561035156e-05, logit=9.375, token_id=14669, metadata=None)))])\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     int_prediction=['\" Acc\"[11683] (p=0.578, logit=18.875)', '\" The\"[578] (p=0.146, logit=17.500)', '\" Jacket\"[55870] (p=0.089, logit=17.000)', '\" Guitar\"[47759] (p=0.069, logit=16.750)', '\" ACC\"[26925] (p=0.009, logit=14.688)']\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     int_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.578125, logit=18.875, token_id=11683, metadata=None))), (55870, (3, PredictedToken(token=' Jacket', prob=0.0888671875, logit=17.0, token_id=55870, metadata=None))), (47759, (4, PredictedToken(token=' Guitar', prob=0.0693359375, logit=16.75, token_id=47759, metadata=None))), (67553, (11, PredictedToken(token=' Pants', prob=0.00390625, logit=13.875, token_id=67553, metadata=None))), (14669, (16, PredictedToken(token=' Camera', prob=0.0028533935546875, logit=13.5625, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:10 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:10 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     patch_prediction=['\" B\"[426] (p=0.785, logit=20.375)', '\" The\"[578] (p=0.064, logit=17.875)', '\" C\"[356] (p=0.057, logit=17.750)', '\" A\"[362] (p=0.018, logit=16.625)', '\" b\"[293] (p=0.016, logit=16.500)']\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.801, logit=21.250)', '\" The\"[578] (p=0.123, logit=19.375)', '\" X\"[1630] (p=0.015, logit=17.250)', '\" A\"[362] (p=0.011, logit=17.000)', '\" VI\"[30768] (p=0.008, logit=16.625)']\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.80078125, logit=21.25, token_id=30555, metadata=None))), (1630, (3, PredictedToken(token=' X', prob=0.01470947265625, logit=17.25, token_id=1630, metadata=None))), (469, (9, PredictedToken(token=' E', prob=0.0023956298828125, logit=15.4375, token_id=469, metadata=None))), (28131, (153, PredictedToken(token=' Golf', prob=1.424551010131836e-05, logit=10.3125, token_id=28131, metadata=None))), (70306, (262, PredictedToken(token=' Brace', prob=4.9173831939697266e-06, logit=9.25, token_id=70306, metadata=None)))])\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.805, logit=20.875)', '\" The\"[578] (p=0.075, logit=18.500)', '\" An\"[1556] (p=0.058, logit=18.250)', '\" e\"[384] (p=0.013, logit=16.750)', '\" Viol\"[30555] (p=0.005, logit=15.812)']\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.8046875, logit=20.875, token_id=469, metadata=None))), (30555, (5, PredictedToken(token=' Viol', prob=0.005096435546875, logit=15.8125, token_id=30555, metadata=None))), (1630, (6, PredictedToken(token=' X', prob=0.004791259765625, logit=15.75, token_id=1630, metadata=None))), (70306, (7, PredictedToken(token=' Brace', prob=0.00421142578125, logit=15.625, token_id=70306, metadata=None))), (28131, (52, PredictedToken(token=' Golf', prob=9.918212890625e-05, logit=11.875, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:11 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:11 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     patch_prediction=['\" Yoga\"[38673] (p=0.498, logit=19.000)', '\" None\"[2290] (p=0.208, logit=18.125)', '\" There\"[2684] (p=0.076, logit=17.125)', '\" The\"[578] (p=0.076, logit=17.125)', '\" Helmet\"[67629] (p=0.028, logit=16.125)']\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.777, logit=20.375)', '\" The\"[578] (p=0.135, logit=18.625)', '\" TR\"[5091] (p=0.014, logit=16.375)', '\" Guitar\"[47759] (p=0.009, logit=15.938)', '\" A\"[362] (p=0.007, logit=15.625)']\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.77734375, logit=20.375, token_id=3420, metadata=None))), (47759, (4, PredictedToken(token=' Guitar', prob=0.0091552734375, logit=15.9375, token_id=47759, metadata=None))), (65197, (9, PredictedToken(token=' Surf', prob=0.0035858154296875, logit=15.0, token_id=65197, metadata=None))), (58251, (234, PredictedToken(token=' Tennis', prob=1.1444091796875e-05, logit=9.25, token_id=58251, metadata=None))), (39794, (252, PredictedToken(token=' Desk', prob=1.0073184967041016e-05, logit=9.125, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     int_prediction=['\" Desk\"[39794] (p=0.201, logit=17.250)', '\" Surf\"[65197] (p=0.178, logit=17.125)', '\" Tennis\"[58251] (p=0.138, logit=16.875)', '\" The\"[578] (p=0.138, logit=16.875)', '\" Guitar\"[47759] (p=0.095, logit=16.500)']\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     int_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.201171875, logit=17.25, token_id=39794, metadata=None))), (65197, (2, PredictedToken(token=' Surf', prob=0.177734375, logit=17.125, token_id=65197, metadata=None))), (58251, (4, PredictedToken(token=' Tennis', prob=0.1376953125, logit=16.875, token_id=58251, metadata=None))), (47759, (5, PredictedToken(token=' Guitar', prob=0.0947265625, logit=16.5, token_id=47759, metadata=None))), (3420, (163, PredictedToken(token=' Trump', prob=7.152557373046875e-05, logit=9.3125, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:12 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:12 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:43:12 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.715, logit=20.625)', '\" The\"[578] (p=0.085, logit=18.500)', '\" A\"[362] (p=0.075, logit=18.375)', '\" R\"[432] (p=0.052, logit=18.000)', '\" PEN\"[81770] (p=0.031, logit=17.500)']\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     clean_prediction=['\" Ki\"[30558] (p=0.891, logit=21.625)', '\" The\"[578] (p=0.073, logit=19.125)', '\" K\"[735] (p=0.005, logit=16.375)', '\" Raspberry\"[48665] (p=0.004, logit=16.250)', '\" A\"[362] (p=0.004, logit=16.125)']\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     clean_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.890625, logit=21.625, token_id=30558, metadata=None))), (48665, (4, PredictedToken(token=' Raspberry', prob=0.004119873046875, logit=16.25, token_id=48665, metadata=None))), (29625, (8, PredictedToken(token=' Chain', prob=0.0018310546875, logit=15.4375, token_id=29625, metadata=None))), (18343, (183, PredictedToken(token=' Paper', prob=6.616115570068359e-06, logit=9.8125, token_id=18343, metadata=None))), (55807, (316, PredictedToken(token=' Shirt', prob=2.9355287551879883e-06, logit=9.0, token_id=55807, metadata=None))), (26781, (581, PredictedToken(token=' Hair', prob=1.080334186553955e-06, logit=8.0, token_id=26781, metadata=None))), (91263, (2490, PredictedToken(token=' Binder', prob=1.5087425708770752e-07, logit=6.03125, token_id=91263, metadata=None)))])\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.879, logit=21.125)', '\" The\"[578] (p=0.064, logit=18.500)', '\" A\"[362] (p=0.011, logit=16.750)', '\" Binder\"[91263] (p=0.006, logit=16.125)', '\" There\"[2684] (p=0.005, logit=15.875)']\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.87890625, logit=21.125, token_id=18343, metadata=None))), (91263, (4, PredictedToken(token=' Binder', prob=0.00592041015625, logit=16.125, token_id=91263, metadata=None))), (29625, (9, PredictedToken(token=' Chain', prob=0.002044677734375, logit=15.0625, token_id=29625, metadata=None))), (48665, (15, PredictedToken(token=' Raspberry', prob=0.00096893310546875, logit=14.3125, token_id=48665, metadata=None))), (30558, (30, PredictedToken(token=' Ki', prob=0.000278472900390625, logit=13.0625, token_id=30558, metadata=None))), (26781, (56, PredictedToken(token=' Hair', prob=9.012222290039062e-05, logit=11.9375, token_id=26781, metadata=None))), (55807, (103, PredictedToken(token=' Shirt', prob=2.9206275939941406e-05, logit=10.8125, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:13 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.910, logit=22.000)', '\" The\"[578] (p=0.051, logit=19.125)', '\" Apple\"[8325] (p=0.010, logit=17.500)', '\" A\"[362] (p=0.010, logit=17.500)', '\" pear\"[38790] (p=0.002, logit=16.000)']\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.723, logit=20.125)', '\" The\"[578] (p=0.143, logit=18.500)', '\" Helmet\"[67629] (p=0.028, logit=16.875)', '\" Ski\"[61595] (p=0.015, logit=16.250)', '\" There\"[2684] (p=0.011, logit=15.938)']\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.72265625, logit=20.125, token_id=4923, metadata=None))), (67629, (3, PredictedToken(token=' Helmet', prob=0.028076171875, logit=16.875, token_id=67629, metadata=None))), (10164, (6, PredictedToken(token=' Water', prob=0.006256103515625, logit=15.375, token_id=10164, metadata=None))), (6690, (16, PredictedToken(token=' Air', prob=0.0024566650390625, logit=14.4375, token_id=6690, metadata=None))), (84409, (50, PredictedToken(token=' Plum', prob=0.00020122528076171875, logit=11.9375, token_id=84409, metadata=None)))])\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.840, logit=21.125)', '\" Water\"[10164] (p=0.061, logit=18.500)', '\" The\"[578] (p=0.042, logit=18.125)', '\" Sk\"[4923] (p=0.008, logit=16.500)', '\" Ski\"[61595] (p=0.005, logit=16.000)']\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.83984375, logit=21.125, token_id=84409, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.06103515625, logit=18.5, token_id=10164, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.00823974609375, logit=16.5, token_id=4923, metadata=None))), (67629, (7, PredictedToken(token=' Helmet', prob=0.004425048828125, logit=15.875, token_id=67629, metadata=None))), (6690, (47, PredictedToken(token=' Air', prob=0.00010395050048828125, logit=12.125, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:14 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:14 src.selection.optimization DEBUG    torch.Size([7, 36])\n",
      "2025-09-15 09:43:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.836, logit=21.000)', '\" Let\"[6914] (p=0.047, logit=18.125)', '\" The\"[578] (p=0.042, logit=18.000)', '\" AS\"[5871] (p=0.020, logit=17.250)', '\" ASP\"[49509] (p=0.010, logit=16.625)']\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.770, logit=20.750)', '\" The\"[578] (p=0.134, logit=19.000)', '\" Jasmine\"[82452] (p=0.023, logit=17.250)', '\" There\"[2684] (p=0.011, logit=16.500)', '\" Car\"[3341] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.76953125, logit=20.75, token_id=8219, metadata=None))), (82452, (3, PredictedToken(token=' Jasmine', prob=0.023193359375, logit=17.25, token_id=82452, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.00970458984375, logit=16.375, token_id=3341, metadata=None))), (36845, (6, PredictedToken(token=' Tiger', prob=0.006256103515625, logit=15.9375, token_id=36845, metadata=None))), (91297, (11, PredictedToken(token=' Mushroom', prob=0.002166748046875, logit=14.875, token_id=91297, metadata=None))), (55870, (20, PredictedToken(token=' Jacket', prob=0.000514984130859375, logit=13.4375, token_id=55870, metadata=None))), (70762, (45, PredictedToken(token=' Motorcycle', prob=0.00020122528076171875, logit=12.5, token_id=70762, metadata=None)))])\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.699, logit=20.375)', '\" The\"[578] (p=0.107, logit=18.500)', '\" Mushroom\"[91297] (p=0.051, logit=17.750)', '\" Jacket\"[55870] (p=0.035, logit=17.375)', '\" Motorcycle\"[70762] (p=0.021, logit=16.875)']\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.69921875, logit=20.375, token_id=3341, metadata=None))), (91297, (3, PredictedToken(token=' Mushroom', prob=0.05078125, logit=17.75, token_id=91297, metadata=None))), (55870, (4, PredictedToken(token=' Jacket', prob=0.034912109375, logit=17.375, token_id=55870, metadata=None))), (70762, (5, PredictedToken(token=' Motorcycle', prob=0.0211181640625, logit=16.875, token_id=70762, metadata=None))), (82452, (6, PredictedToken(token=' Jasmine', prob=0.0145263671875, logit=16.5, token_id=82452, metadata=None))), (36845, (8, PredictedToken(token=' Tiger', prob=0.00885009765625, logit=16.0, token_id=36845, metadata=None))), (8219, (19, PredictedToken(token=' Sun', prob=0.000820159912109375, logit=13.625, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:15 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:43:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:16 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.820, logit=20.125)', '\" The\"[578] (p=0.076, logit=17.750)', '\" Pressure\"[40090] (p=0.022, logit=16.500)', '\" Basketball\"[47589] (p=0.015, logit=16.125)', '\" BOX\"[53783] (p=0.011, logit=15.812)']\n",
      "2025-09-15 09:43:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:16 src.selection.optimization INFO     clean_prediction=['\" Chair\"[16478] (p=0.539, logit=19.750)', '\" The\"[578] (p=0.136, logit=18.375)', '\" Sofa\"[61948] (p=0.120, logit=18.250)', '\" A\"[362] (p=0.064, logit=17.625)', '\" Sk\"[4923] (p=0.018, logit=16.375)']\n",
      "2025-09-15 09:43:16 src.selection.optimization INFO     clean_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.5390625, logit=19.75, token_id=16478, metadata=None))), (61948, (3, PredictedToken(token=' Sofa', prob=0.1201171875, logit=18.25, token_id=61948, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.0184326171875, logit=16.375, token_id=4923, metadata=None))), (423, (7, PredictedToken(token=' D', prob=0.010498046875, logit=15.8125, token_id=423, metadata=None))), (30616, (101, PredictedToken(token=' Rice', prob=7.534027099609375e-05, logit=10.875, token_id=30616, metadata=None)))])\n",
      "2025-09-15 09:43:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.711, logit=19.000)', '\" The\"[578] (p=0.085, logit=16.875)', '\" D\"[423] (p=0.021, logit=15.500)', '\" Rice\"[30616] (p=0.019, logit=15.375)', '\" It\"[1102] (p=0.017, logit=15.250)']\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.7109375, logit=19.0, token_id=4923, metadata=None))), (423, (3, PredictedToken(token=' D', prob=0.021484375, logit=15.5, token_id=423, metadata=None))), (30616, (4, PredictedToken(token=' Rice', prob=0.0189208984375, logit=15.375, token_id=30616, metadata=None))), (61948, (11, PredictedToken(token=' Sofa', prob=0.00653076171875, logit=14.3125, token_id=61948, metadata=None))), (16478, (15, PredictedToken(token=' Chair', prob=0.00372314453125, logit=13.75, token_id=16478, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:17 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:17 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.754, logit=20.500)', '\" The\"[578] (p=0.131, logit=18.750)', '\" Rice\"[30616] (p=0.033, logit=17.375)', '\" Acc\"[11683] (p=0.008, logit=16.000)', '\" A\"[362] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.428, logit=19.125)', '\" The\"[578] (p=0.334, logit=18.875)', '\" TR\"[5091] (p=0.058, logit=17.125)', '\" A\"[362] (p=0.031, logit=16.500)', '\" Van\"[13000] (p=0.024, logit=16.250)']\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.427734375, logit=19.125, token_id=34785, metadata=None))), (13000, (5, PredictedToken(token=' Van', prob=0.024169921875, logit=16.25, token_id=13000, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.00946044921875, logit=15.3125, token_id=469, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.006500244140625, logit=14.9375, token_id=356, metadata=None))), (6690, (90, PredictedToken(token=' Air', prob=0.00013446807861328125, logit=11.0625, token_id=6690, metadata=None))), (89077, (97, PredictedToken(token=' Strawberry', prob=0.00012683868408203125, logit=11.0, token_id=89077, metadata=None))), (27171, (180, PredictedToken(token=' Coffee', prob=4.649162292480469e-05, logit=10.0, token_id=27171, metadata=None)))])\n",
      "2025-09-15 09:43:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.355, logit=19.375)', '\" The\"[578] (p=0.216, logit=18.875)', '\" E\"[469] (p=0.168, logit=18.625)', '\" Strawberry\"[89077] (p=0.131, logit=18.375)', '\" An\"[1556] (p=0.020, logit=16.500)']\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.35546875, logit=19.375, token_id=27171, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.16796875, logit=18.625, token_id=469, metadata=None))), (89077, (4, PredictedToken(token=' Strawberry', prob=0.130859375, logit=18.375, token_id=89077, metadata=None))), (6690, (7, PredictedToken(token=' Air', prob=0.009521484375, logit=15.75, token_id=6690, metadata=None))), (356, (12, PredictedToken(token=' C', prob=0.00421142578125, logit=14.9375, token_id=356, metadata=None))), (13000, (50, PredictedToken(token=' Van', prob=0.00023746490478515625, logit=12.0625, token_id=13000, metadata=None))), (34785, (563, PredictedToken(token=' Truck', prob=4.082918167114258e-06, logit=8.0, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:18 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.688, logit=19.125)', '\" Night\"[13120] (p=0.073, logit=16.875)', '\" The\"[578] (p=0.064, logit=16.750)', '\" Ottoman\"[70110] (p=0.034, logit=16.125)', '\" Museum\"[16730] (p=0.022, logit=15.688)']\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.676, logit=18.625)', '\" The\"[578] (p=0.133, logit=17.000)', '\" Apartment\"[53889] (p=0.026, logit=15.375)', '\" Sofa\"[61948] (p=0.014, logit=14.750)', '\" W\"[468] (p=0.013, logit=14.688)']\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.67578125, logit=18.625, token_id=27738, metadata=None))), (53889, (3, PredictedToken(token=' Apartment', prob=0.0262451171875, logit=15.375, token_id=53889, metadata=None))), (61948, (4, PredictedToken(token=' Sofa', prob=0.0140380859375, logit=14.75, token_id=61948, metadata=None))), (43316, (8, PredictedToken(token=' Tul', prob=0.00909423828125, logit=14.3125, token_id=43316, metadata=None))), (52466, (51, PredictedToken(token=' Warehouse', prob=0.0003986358642578125, logit=11.1875, token_id=52466, metadata=None)))])\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     int_prediction=['\" Apartment\"[53889] (p=0.562, logit=18.875)', '\" Sofa\"[61948] (p=0.184, logit=17.750)', '\" The\"[578] (p=0.098, logit=17.125)', '\" None\"[2290] (p=0.012, logit=15.000)', '\" It\"[1102] (p=0.011, logit=14.938)']\n",
      "2025-09-15 09:43:18 src.selection.optimization INFO     int_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.5625, logit=18.875, token_id=53889, metadata=None))), (61948, (2, PredictedToken(token=' Sofa', prob=0.18359375, logit=17.75, token_id=61948, metadata=None))), (52466, (8, PredictedToken(token=' Warehouse', prob=0.008056640625, logit=14.625, token_id=52466, metadata=None))), (43316, (12, PredictedToken(token=' Tul', prob=0.004058837890625, logit=13.9375, token_id=43316, metadata=None))), (27738, (26, PredictedToken(token=' Ward', prob=0.00148773193359375, logit=12.9375, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:19 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.695, logit=19.750)', '\" Pine\"[42609] (p=0.155, logit=18.250)', '\" The\"[578] (p=0.035, logit=16.750)', '\" Apple\"[8325] (p=0.027, logit=16.500)', '\" Blender\"[88668] (p=0.013, logit=15.750)']\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.766, logit=20.625)', '\" The\"[578] (p=0.104, logit=18.625)', '\" There\"[2684] (p=0.030, logit=17.375)', '\" Spr\"[15883] (p=0.018, logit=16.875)', '\" To\"[2057] (p=0.011, logit=16.375)']\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.765625, logit=20.625, token_id=65449, metadata=None))), (15883, (4, PredictedToken(token=' Spr', prob=0.0179443359375, logit=16.875, token_id=15883, metadata=None))), (2057, (5, PredictedToken(token=' To', prob=0.01092529296875, logit=16.375, token_id=2057, metadata=None))), (76924, (7, PredictedToken(token=' Banana', prob=0.007049560546875, logit=15.9375, token_id=76924, metadata=None))), (48665, (13, PredictedToken(token=' Raspberry', prob=0.0024261474609375, logit=14.875, token_id=48665, metadata=None)))])\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.371, logit=19.625)', '\" Raspberry\"[48665] (p=0.289, logit=19.375)', '\" The\"[578] (p=0.094, logit=18.250)', '\" To\"[2057] (p=0.073, logit=18.000)', '\" Spr\"[15883] (p=0.057, logit=17.750)']\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.37109375, logit=19.625, token_id=65449, metadata=None))), (48665, (2, PredictedToken(token=' Raspberry', prob=0.2890625, logit=19.375, token_id=48665, metadata=None))), (2057, (4, PredictedToken(token=' To', prob=0.0732421875, logit=18.0, token_id=2057, metadata=None))), (15883, (5, PredictedToken(token=' Spr', prob=0.05712890625, logit=17.75, token_id=15883, metadata=None))), (76924, (7, PredictedToken(token=' Banana', prob=0.0185546875, logit=16.625, token_id=76924, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:19 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:19 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     patch_prediction=['\" Violet\"[74574] (p=0.949, logit=21.750)', '\" The\"[578] (p=0.020, logit=17.875)', '\" Orch\"[55405] (p=0.012, logit=17.375)', '\" V\"[650] (p=0.003, logit=15.938)', '\" violet\"[80836] (p=0.002, logit=15.625)']\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.859, logit=20.875)', '\" The\"[578] (p=0.049, logit=18.000)', '\" Mixer\"[72392] (p=0.029, logit=17.500)', '\" A\"[362] (p=0.016, logit=16.875)', '\" BLE\"[52818] (p=0.010, logit=16.375)']\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.859375, logit=20.875, token_id=88668, metadata=None))), (72392, (3, PredictedToken(token=' Mixer', prob=0.0294189453125, logit=17.5, token_id=72392, metadata=None))), (16344, (45, PredictedToken(token=' Rose', prob=0.0001201629638671875, logit=12.0, token_id=16344, metadata=None))), (21424, (187, PredictedToken(token=' Football', prob=1.3470649719238281e-05, logit=9.8125, token_id=21424, metadata=None))), (82452, (893, PredictedToken(token=' Jasmine', prob=1.564621925354004e-06, logit=7.65625, token_id=82452, metadata=None)))])\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.582, logit=18.750)', '\" Jasmine\"[82452] (p=0.166, logit=17.500)', '\" The\"[578] (p=0.089, logit=16.875)', '\" RO\"[12076] (p=0.019, logit=15.312)', '\" J\"[622] (p=0.016, logit=15.125)']\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.58203125, logit=18.75, token_id=16344, metadata=None))), (82452, (2, PredictedToken(token=' Jasmine', prob=0.166015625, logit=17.5, token_id=82452, metadata=None))), (72392, (6, PredictedToken(token=' Mixer', prob=0.00732421875, logit=14.375, token_id=72392, metadata=None))), (88668, (10, PredictedToken(token=' Blender', prob=0.004730224609375, logit=13.9375, token_id=88668, metadata=None))), (21424, (492, PredictedToken(token=' Football', prob=1.2099742889404297e-05, logit=7.96875, token_id=21424, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:20 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:43:20 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     patch_prediction=['\" Spin\"[41785] (p=0.750, logit=19.875)', '\" Potato\"[78703] (p=0.089, logit=17.750)', '\" The\"[578] (p=0.054, logit=17.250)', '\" There\"[2684] (p=0.033, logit=16.750)', '\" None\"[2290] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.660, logit=19.375)', '\" The\"[578] (p=0.130, logit=17.750)', '\" Hat\"[22050] (p=0.037, logit=16.500)', '\" SHORT\"[66024] (p=0.016, logit=15.688)', '\" None\"[2290] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.66015625, logit=19.375, token_id=91782, metadata=None))), (22050, (3, PredictedToken(token=' Hat', prob=0.037109375, logit=16.5, token_id=22050, metadata=None))), (52882, (45, PredictedToken(token=' Pepper', prob=0.000469207763671875, logit=12.125, token_id=52882, metadata=None))), (87035, (96, PredictedToken(token=' Onion', prob=0.0001430511474609375, logit=10.9375, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.590, logit=19.500)', '\" Onion\"[87035] (p=0.192, logit=18.375)', '\" The\"[578] (p=0.071, logit=17.375)', '\" Hat\"[22050] (p=0.029, logit=16.500)', '\" There\"[2684] (p=0.012, logit=15.625)']\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.58984375, logit=19.5, token_id=52882, metadata=None))), (87035, (2, PredictedToken(token=' Onion', prob=0.1923828125, logit=18.375, token_id=87035, metadata=None))), (22050, (4, PredictedToken(token=' Hat', prob=0.0294189453125, logit=16.5, token_id=22050, metadata=None))), (91782, (27, PredictedToken(token=' Shorts', prob=0.001007080078125, logit=13.125, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:21 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.691, logit=19.250)', '\" D\"[423] (p=0.073, logit=17.000)', '\" There\"[2684] (p=0.050, logit=16.625)', '\" The\"[578] (p=0.050, logit=16.625)', '\" None\"[2290] (p=0.022, logit=15.812)']\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.459, logit=19.125)', '\" Hospital\"[15429] (p=0.277, logit=18.625)', '\" The\"[578] (p=0.070, logit=17.250)', '\" Er\"[9939] (p=0.062, logit=17.125)', '\" There\"[2684] (p=0.023, logit=16.125)']\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.458984375, logit=19.125, token_id=4923, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.27734375, logit=18.625, token_id=15429, metadata=None))), (9939, (4, PredictedToken(token=' Er', prob=0.06201171875, logit=17.125, token_id=9939, metadata=None))), (16344, (8, PredictedToken(token=' Rose', prob=0.01385498046875, logit=15.625, token_id=16344, metadata=None))), (82452, (32, PredictedToken(token=' Jasmine', prob=0.0006103515625, logit=12.5, token_id=82452, metadata=None)))])\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.684, logit=19.625)', '\" Hospital\"[15429] (p=0.152, logit=18.125)', '\" The\"[578] (p=0.039, logit=16.750)', '\" There\"[2684] (p=0.021, logit=16.125)', '\" None\"[2290] (p=0.013, logit=15.688)']\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.68359375, logit=19.625, token_id=82452, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.15234375, logit=18.125, token_id=15429, metadata=None))), (16344, (7, PredictedToken(token=' Rose', prob=0.0091552734375, logit=15.3125, token_id=16344, metadata=None))), (9939, (6, PredictedToken(token=' Er', prob=0.0091552734375, logit=15.3125, token_id=9939, metadata=None))), (4923, (10, PredictedToken(token=' Sk', prob=0.005218505859375, logit=14.75, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:22 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.883, logit=21.625)', '\" The\"[578] (p=0.082, logit=19.250)', '\" It\"[1102] (p=0.005, logit=16.500)', '\" A\"[362] (p=0.004, logit=16.125)', '\" VI\"[30768] (p=0.003, logit=15.938)']\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     clean_prediction=['\" Highlight\"[57094] (p=0.543, logit=20.125)', '\" Stap\"[63606] (p=0.328, logit=19.625)', '\" The\"[578] (p=0.044, logit=17.625)', '\" A\"[362] (p=0.031, logit=17.250)', '\" None\"[2290] (p=0.009, logit=16.000)']\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     clean_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.54296875, logit=20.125, token_id=57094, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.328125, logit=19.625, token_id=63606, metadata=None))), (5340, (13, PredictedToken(token=' Har', prob=0.00098419189453125, logit=13.8125, token_id=5340, metadata=None))), (94467, (24, PredictedToken(token=' Trom', prob=0.0004367828369140625, logit=13.0, token_id=94467, metadata=None))), (58937, (115, PredictedToken(token=' Monkey', prob=4.315376281738281e-05, logit=10.6875, token_id=58937, metadata=None)))])\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.457, logit=18.875)', '\" Trom\"[94467] (p=0.244, logit=18.250)', '\" The\"[578] (p=0.131, logit=17.625)', '\" Stap\"[63606] (p=0.026, logit=16.000)', '\" HAR\"[87588] (p=0.020, logit=15.750)']\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.45703125, logit=18.875, token_id=5340, metadata=None))), (94467, (2, PredictedToken(token=' Trom', prob=0.244140625, logit=18.25, token_id=94467, metadata=None))), (63606, (4, PredictedToken(token=' Stap', prob=0.0257568359375, logit=16.0, token_id=63606, metadata=None))), (58937, (17, PredictedToken(token=' Monkey', prob=0.00154876708984375, logit=13.1875, token_id=58937, metadata=None))), (57094, (133, PredictedToken(token=' Highlight', prob=5.626678466796875e-05, logit=9.875, token_id=57094, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:23 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:43:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:24 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.777, logit=19.500)', '\" Apartment\"[53889] (p=0.064, logit=17.000)', '\" The\"[578] (p=0.039, logit=16.500)', '\" SCHOOL\"[71501] (p=0.015, logit=15.562)', '\" Cedar\"[57748] (p=0.015, logit=15.562)']\n",
      "2025-09-15 09:43:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:24 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.738, logit=20.000)', '\" The\"[578] (p=0.061, logit=17.500)', '\" E\"[469] (p=0.037, logit=17.000)', '\" Mall\"[32498] (p=0.032, logit=16.875)', '\" None\"[2290] (p=0.025, logit=16.625)']\n",
      "2025-09-15 09:43:24 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.73828125, logit=20.0, token_id=65449, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.036865234375, logit=17.0, token_id=469, metadata=None))), (32498, (4, PredictedToken(token=' Mall', prob=0.032470703125, logit=16.875, token_id=32498, metadata=None))), (98028, (7, PredictedToken(token=' Bamboo', prob=0.0196533203125, logit=16.375, token_id=98028, metadata=None))), (4783, (8, PredictedToken(token=' House', prob=0.01055908203125, logit=15.75, token_id=4783, metadata=None)))])\n",
      "2025-09-15 09:43:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     int_prediction=['\" Mall\"[32498] (p=0.500, logit=19.250)', '\" E\"[469] (p=0.144, logit=18.000)', '\" The\"[578] (p=0.112, logit=17.750)', '\" Willow\"[65449] (p=0.047, logit=16.875)', '\" There\"[2684] (p=0.041, logit=16.750)']\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     int_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.5, logit=19.25, token_id=32498, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.1435546875, logit=18.0, token_id=469, metadata=None))), (65449, (4, PredictedToken(token=' Willow', prob=0.046630859375, logit=16.875, token_id=65449, metadata=None))), (4783, (6, PredictedToken(token=' House', prob=0.031982421875, logit=16.5, token_id=4783, metadata=None))), (98028, (8, PredictedToken(token=' Bamboo', prob=0.02197265625, logit=16.125, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:25 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.848, logit=20.250)', '\" The\"[578] (p=0.037, logit=17.125)', '\" Raspberry\"[48665] (p=0.033, logit=17.000)', '\" There\"[2684] (p=0.016, logit=16.250)', '\" STR\"[12428] (p=0.011, logit=15.938)']\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.389, logit=19.500)', '\" Spin\"[41785] (p=0.303, logit=19.250)', '\" The\"[578] (p=0.098, logit=18.125)', '\" There\"[2684] (p=0.077, logit=17.875)', '\" None\"[2290] (p=0.060, logit=17.625)']\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.388671875, logit=19.5, token_id=47643, metadata=None))), (41785, (2, PredictedToken(token=' Spin', prob=0.302734375, logit=19.25, token_id=41785, metadata=None))), (42609, (6, PredictedToken(token=' Pine', prob=0.007568359375, logit=15.5625, token_id=42609, metadata=None))), (4923, (7, PredictedToken(token=' Sk', prob=0.006683349609375, logit=15.4375, token_id=4923, metadata=None))), (10164, (8, PredictedToken(token=' Water', prob=0.004608154296875, logit=15.0625, token_id=10164, metadata=None)))])\n",
      "2025-09-15 09:43:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.416, logit=19.875)', '\" There\"[2684] (p=0.153, logit=18.875)', '\" Water\"[10164] (p=0.136, logit=18.750)', '\" None\"[2290] (p=0.082, logit=18.250)', '\" The\"[578] (p=0.064, logit=18.000)']\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.416015625, logit=19.875, token_id=42609, metadata=None))), (10164, (3, PredictedToken(token=' Water', prob=0.1357421875, logit=18.75, token_id=10164, metadata=None))), (41785, (6, PredictedToken(token=' Spin', prob=0.0498046875, logit=17.75, token_id=41785, metadata=None))), (47643, (7, PredictedToken(token=' Cel', prob=0.0498046875, logit=17.75, token_id=47643, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.0052490234375, logit=15.5, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:26 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.859, logit=20.750)', '\" The\"[578] (p=0.070, logit=18.250)', '\" T\"[350] (p=0.018, logit=16.875)', '\" Dog\"[14588] (p=0.007, logit=16.000)', '\" A\"[362] (p=0.007, logit=15.875)']\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.797, logit=21.125)', '\" The\"[578] (p=0.139, logit=19.375)', '\" SH\"[6570] (p=0.015, logit=17.125)', '\" A\"[362] (p=0.011, logit=16.875)', '\" There\"[2684] (p=0.004, logit=15.938)']\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.796875, logit=21.125, token_id=55807, metadata=None))), (22050, (10, PredictedToken(token=' Hat', prob=0.00127410888671875, logit=14.6875, token_id=22050, metadata=None))), (68027, (12, PredictedToken(token=' Sax', prob=0.0009307861328125, logit=14.375, token_id=68027, metadata=None))), (79189, (20, PredictedToken(token=' Elephant', prob=0.000640869140625, logit=14.0, token_id=79189, metadata=None))), (36895, (63, PredictedToken(token=' Eagle', prob=8.678436279296875e-05, logit=12.0, token_id=36895, metadata=None)))])\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     int_prediction=['\" Eagle\"[36895] (p=0.766, logit=20.000)', '\" The\"[578] (p=0.104, logit=18.000)', '\" E\"[469] (p=0.030, logit=16.750)', '\" Elephant\"[79189] (p=0.023, logit=16.500)', '\" An\"[1556] (p=0.016, logit=16.125)']\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     int_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.765625, logit=20.0, token_id=36895, metadata=None))), (79189, (4, PredictedToken(token=' Elephant', prob=0.0230712890625, logit=16.5, token_id=79189, metadata=None))), (22050, (8, PredictedToken(token=' Hat', prob=0.0027618408203125, logit=14.375, token_id=22050, metadata=None))), (55807, (24, PredictedToken(token=' Shirt', prob=0.0006561279296875, logit=12.9375, token_id=55807, metadata=None))), (68027, (79, PredictedToken(token=' Sax', prob=7.82012939453125e-05, logit=10.8125, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:26 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:27 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.486, logit=19.375)', '\" The\"[578] (p=0.179, logit=18.375)', '\" There\"[2684] (p=0.158, logit=18.250)', '\" None\"[2290] (p=0.051, logit=17.125)', '\" Mushroom\"[91297] (p=0.021, logit=16.250)']\n",
      "2025-09-15 09:43:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:27 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.824, logit=20.875)', '\" The\"[578] (p=0.060, logit=18.250)', '\" Shirt\"[55807] (p=0.028, logit=17.500)', '\" Van\"[13000] (p=0.022, logit=17.250)', '\" A\"[362] (p=0.022, logit=17.250)']\n",
      "2025-09-15 09:43:27 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.82421875, logit=20.875, token_id=33711, metadata=None))), (55807, (3, PredictedToken(token=' Shirt', prob=0.0283203125, logit=17.5, token_id=55807, metadata=None))), (13000, (5, PredictedToken(token=' Van', prob=0.02197265625, logit=17.25, token_id=13000, metadata=None))), (41785, (19, PredictedToken(token=' Spin', prob=0.00054931640625, logit=13.5625, token_id=41785, metadata=None))), (87035, (505, PredictedToken(token=' Onion', prob=2.5480985641479492e-06, logit=8.1875, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:43:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.844, logit=21.125)', '\" The\"[578] (p=0.037, logit=18.000)', '\" Van\"[13000] (p=0.025, logit=17.625)', '\" Shirt\"[55807] (p=0.017, logit=17.250)', '\" Suit\"[33711] (p=0.017, logit=17.250)']\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.84375, logit=21.125, token_id=87035, metadata=None))), (13000, (3, PredictedToken(token=' Van', prob=0.025390625, logit=17.625, token_id=13000, metadata=None))), (55807, (5, PredictedToken(token=' Shirt', prob=0.0174560546875, logit=17.25, token_id=55807, metadata=None))), (33711, (4, PredictedToken(token=' Suit', prob=0.0174560546875, logit=17.25, token_id=33711, metadata=None))), (41785, (6, PredictedToken(token=' Spin', prob=0.0106201171875, logit=16.75, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:28 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     patch_prediction=['\" Pendant\"[81501] (p=0.953, logit=22.000)', '\" The\"[578] (p=0.022, logit=18.250)', '\" B\"[426] (p=0.003, logit=16.250)', '\" It\"[1102] (p=0.003, logit=16.125)', '\" A\"[362] (p=0.003, logit=16.125)']\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     clean_prediction=['\" Guitar\"[47759] (p=0.516, logit=19.000)', '\" The\"[578] (p=0.275, logit=18.375)', '\" Sax\"[68027] (p=0.048, logit=16.625)', '\" G\"[480] (p=0.026, logit=16.000)', '\" A\"[362] (p=0.016, logit=15.562)']\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     clean_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.515625, logit=19.0, token_id=47759, metadata=None))), (68027, (3, PredictedToken(token=' Sax', prob=0.0478515625, logit=16.625, token_id=68027, metadata=None))), (17929, (11, PredictedToken(token=' Pin', prob=0.003936767578125, logit=14.125, token_id=17929, metadata=None))), (37326, (13, PredictedToken(token=' Swe', prob=0.00286865234375, logit=13.8125, token_id=37326, metadata=None))), (86460, (37, PredictedToken(token=' Necklace', prob=0.000640869140625, logit=12.3125, token_id=86460, metadata=None)))])\n",
      "2025-09-15 09:43:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:29 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.516, logit=18.625)', '\" The\"[578] (p=0.167, logit=17.500)', '\" Necklace\"[86460] (p=0.062, logit=16.500)', '\" Swe\"[37326] (p=0.042, logit=16.125)', '\" A\"[362] (p=0.037, logit=16.000)']\n",
      "2025-09-15 09:43:29 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.515625, logit=18.625, token_id=17929, metadata=None))), (86460, (3, PredictedToken(token=' Necklace', prob=0.0615234375, logit=16.5, token_id=86460, metadata=None))), (37326, (4, PredictedToken(token=' Swe', prob=0.042236328125, logit=16.125, token_id=37326, metadata=None))), (68027, (10, PredictedToken(token=' Sax', prob=0.00689697265625, logit=14.3125, token_id=68027, metadata=None))), (47759, (30, PredictedToken(token=' Guitar', prob=0.00119781494140625, logit=12.5625, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:29 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:29 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:43:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:29 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.420, logit=18.750)', '\" Bear\"[24941] (p=0.226, logit=18.125)', '\" The\"[578] (p=0.106, logit=17.375)', '\" SHE\"[54695] (p=0.057, logit=16.750)', '\" There\"[2684] (p=0.044, logit=16.500)']\n",
      "2025-09-15 09:43:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     clean_prediction=['\" Football\"[21424] (p=0.762, logit=21.000)', '\" Basketball\"[47589] (p=0.132, logit=19.250)', '\" The\"[578] (p=0.055, logit=18.375)', '\" FOOT\"[81137] (p=0.010, logit=16.625)', '\" There\"[2684] (p=0.006, logit=16.125)']\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     clean_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.76171875, logit=21.0, token_id=21424, metadata=None))), (47589, (2, PredictedToken(token=' Basketball', prob=0.1318359375, logit=19.25, token_id=47589, metadata=None))), (4923, (33, PredictedToken(token=' Sk', prob=0.0003070831298828125, logit=13.1875, token_id=4923, metadata=None))), (14669, (95, PredictedToken(token=' Camera', prob=3.910064697265625e-05, logit=11.125, token_id=14669, metadata=None))), (36845, (212, PredictedToken(token=' Tiger', prob=9.298324584960938e-06, logit=9.6875, token_id=36845, metadata=None))), (22607, (2062, PredictedToken(token=' Cow', prob=2.980232238769531e-07, logit=6.25, token_id=22607, metadata=None)))])\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.395, logit=19.125)', '\" Tiger\"[36845] (p=0.307, logit=18.875)', '\" The\"[578] (p=0.078, logit=17.500)', '\" Basketball\"[47589] (p=0.047, logit=17.000)', '\" Football\"[21424] (p=0.047, logit=17.000)']\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.39453125, logit=19.125, token_id=22607, metadata=None))), (36845, (2, PredictedToken(token=' Tiger', prob=0.306640625, logit=18.875, token_id=36845, metadata=None))), (47589, (5, PredictedToken(token=' Basketball', prob=0.047119140625, logit=17.0, token_id=47589, metadata=None))), (21424, (4, PredictedToken(token=' Football', prob=0.047119140625, logit=17.0, token_id=21424, metadata=None))), (14669, (7, PredictedToken(token=' Camera', prob=0.01434326171875, logit=15.8125, token_id=14669, metadata=None))), (4923, (15, PredictedToken(token=' Sk', prob=0.00182342529296875, logit=13.75, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:30 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     patch_prediction=['\" Tennis\"[58251] (p=0.699, logit=19.750)', '\" Golf\"[28131] (p=0.121, logit=18.000)', '\" The\"[578] (p=0.074, logit=17.500)', '\" A\"[362] (p=0.024, logit=16.375)', '\" TEN\"[75366] (p=0.007, logit=15.125)']\n",
      "2025-09-15 09:43:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.832, logit=20.750)', '\" The\"[578] (p=0.087, logit=18.500)', '\" Viol\"[30555] (p=0.025, logit=17.250)', '\" A\"[362] (p=0.009, logit=16.250)', '\" It\"[1102] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.83203125, logit=20.75, token_id=40759, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.025146484375, logit=17.25, token_id=30555, metadata=None))), (11452, (11, PredictedToken(token=' Head', prob=0.001708984375, logit=14.5625, token_id=11452, metadata=None))), (432, (12, PredictedToken(token=' R', prob=0.0015106201171875, logit=14.4375, token_id=432, metadata=None))), (65197, (82, PredictedToken(token=' Surf', prob=4.553794860839844e-05, logit=10.9375, token_id=65197, metadata=None)))])\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.723, logit=19.500)', '\" The\"[578] (p=0.076, logit=17.250)', '\" Surf\"[65197] (p=0.052, logit=16.875)', '\" A\"[362] (p=0.025, logit=16.125)', '\" Head\"[11452] (p=0.022, logit=16.000)']\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.72265625, logit=19.5, token_id=432, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.05224609375, logit=16.875, token_id=65197, metadata=None))), (11452, (5, PredictedToken(token=' Head', prob=0.0218505859375, logit=16.0, token_id=11452, metadata=None))), (40759, (7, PredictedToken(token=' Harmon', prob=0.007537841796875, logit=14.9375, token_id=40759, metadata=None))), (30555, (11, PredictedToken(token=' Viol', prob=0.00518798828125, logit=14.5625, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:31 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:31 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     patch_prediction=['\" Apple\"[8325] (p=0.660, logit=18.625)', '\" The\"[578] (p=0.147, logit=17.125)', '\" Ki\"[30558] (p=0.029, logit=15.500)', '\" There\"[2684] (p=0.015, logit=14.812)', '\" APPLE\"[91436] (p=0.011, logit=14.562)']\n",
      "2025-09-15 09:43:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.490, logit=18.375)', '\" The\"[578] (p=0.181, logit=17.375)', '\" B\"[426] (p=0.097, logit=16.750)', '\" Willow\"[65449] (p=0.024, logit=15.375)', '\" There\"[2684] (p=0.021, logit=15.250)']\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.490234375, logit=18.375, token_id=88088, metadata=None))), (65449, (4, PredictedToken(token=' Willow', prob=0.0244140625, logit=15.375, token_id=65449, metadata=None))), (64695, (6, PredictedToken(token=' Peach', prob=0.021484375, logit=15.25, token_id=64695, metadata=None))), (48665, (7, PredictedToken(token=' Raspberry', prob=0.01904296875, logit=15.125, token_id=48665, metadata=None)))])\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     int_prediction=['\" Raspberry\"[48665] (p=0.449, logit=18.375)', '\" Birch\"[88088] (p=0.240, logit=17.750)', '\" The\"[578] (p=0.100, logit=16.875)', '\" Willow\"[65449] (p=0.032, logit=15.750)', '\" B\"[426] (p=0.029, logit=15.625)']\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     int_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.44921875, logit=18.375, token_id=48665, metadata=None))), (88088, (2, PredictedToken(token=' Birch', prob=0.240234375, logit=17.75, token_id=88088, metadata=None))), (65449, (4, PredictedToken(token=' Willow', prob=0.032470703125, logit=15.75, token_id=65449, metadata=None))), (64695, (8, PredictedToken(token=' Peach', prob=0.011962890625, logit=14.75, token_id=64695, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:32 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.742, logit=20.250)', '\" The\"[578] (p=0.165, logit=18.750)', '\" A\"[362] (p=0.012, logit=16.125)', '\" It\"[1102] (p=0.008, logit=15.688)', '\" There\"[2684] (p=0.007, logit=15.562)']\n",
      "2025-09-15 09:43:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.801, logit=21.000)', '\" The\"[578] (p=0.123, logit=19.125)', '\" BE\"[7354] (p=0.027, logit=17.625)', '\" A\"[362] (p=0.009, logit=16.500)', '\" Elephant\"[79189] (p=0.008, logit=16.375)']\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.80078125, logit=21.0, token_id=24941, metadata=None))), (79189, (5, PredictedToken(token=' Elephant', prob=0.00787353515625, logit=16.375, token_id=79189, metadata=None))), (393, (7, PredictedToken(token=' P', prob=0.0021209716796875, logit=15.0625, token_id=393, metadata=None))), (5340, (51, PredictedToken(token=' Har', prob=9.298324584960938e-05, logit=11.9375, token_id=5340, metadata=None))), (46506, (109, PredictedToken(token=' Drum', prob=2.8371810913085938e-05, logit=10.75, token_id=46506, metadata=None))), (21424, (656, PredictedToken(token=' Football', prob=1.8104910850524902e-06, logit=8.0, token_id=21424, metadata=None)))])\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     int_prediction=['\" Drum\"[46506] (p=0.590, logit=19.875)', '\" The\"[578] (p=0.132, logit=18.375)', '\" DR\"[14644] (p=0.080, logit=17.875)', '\" Elephant\"[79189] (p=0.062, logit=17.625)', '\" P\"[393] (p=0.055, logit=17.500)']\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     int_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.58984375, logit=19.875, token_id=46506, metadata=None))), (79189, (4, PredictedToken(token=' Elephant', prob=0.06201171875, logit=17.625, token_id=79189, metadata=None))), (393, (5, PredictedToken(token=' P', prob=0.0546875, logit=17.5, token_id=393, metadata=None))), (5340, (6, PredictedToken(token=' Har', prob=0.02587890625, logit=16.75, token_id=5340, metadata=None))), (21424, (24, PredictedToken(token=' Football', prob=0.0004730224609375, logit=12.75, token_id=21424, metadata=None))), (24941, (104, PredictedToken(token=' Bear', prob=4.982948303222656e-05, logit=10.5, token_id=24941, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:33 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.820, logit=20.875)', '\" Mushroom\"[91297] (p=0.060, logit=18.250)', '\" There\"[2684] (p=0.036, logit=17.750)', '\" The\"[578] (p=0.028, logit=17.500)', '\" None\"[2290] (p=0.015, logit=16.875)']\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.586, logit=19.500)', '\" The\"[578] (p=0.168, logit=18.250)', '\" Pine\"[42609] (p=0.080, logit=17.500)', '\" GRA\"[65120] (p=0.033, logit=16.625)', '\" There\"[2684] (p=0.016, logit=15.875)']\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.5859375, logit=19.5, token_id=80629, metadata=None))), (42609, (3, PredictedToken(token=' Pine', prob=0.07958984375, logit=17.5, token_id=42609, metadata=None))), (11452, (7, PredictedToken(token=' Head', prob=0.01220703125, logit=15.625, token_id=11452, metadata=None))), (356, (12, PredictedToken(token=' C', prob=0.00421142578125, logit=14.5625, token_id=356, metadata=None))), (94091, (26, PredictedToken(token=' Tomato', prob=0.00083160400390625, logit=12.9375, token_id=94091, metadata=None)))])\n",
      "2025-09-15 09:43:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     int_prediction=['\" Tomato\"[94091] (p=0.424, logit=19.500)', '\" C\"[356] (p=0.330, logit=19.250)', '\" The\"[578] (p=0.095, logit=18.000)', '\" Head\"[11452] (p=0.039, logit=17.125)', '\" TOM\"[83565] (p=0.019, logit=16.375)']\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     int_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.423828125, logit=19.5, token_id=94091, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.330078125, logit=19.25, token_id=356, metadata=None))), (11452, (4, PredictedToken(token=' Head', prob=0.039306640625, logit=17.125, token_id=11452, metadata=None))), (42609, (7, PredictedToken(token=' Pine', prob=0.01446533203125, logit=16.125, token_id=42609, metadata=None))), (80629, (22, PredictedToken(token=' Grape', prob=0.0008697509765625, logit=13.3125, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:34 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.758, logit=21.000)', '\" The\"[578] (p=0.090, logit=18.875)', '\" Monkey\"[58937] (p=0.080, logit=18.750)', '\" An\"[1556] (p=0.018, logit=17.250)', '\" E\"[469] (p=0.012, logit=16.875)']\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.617, logit=19.250)', '\" Printer\"[47033] (p=0.138, logit=17.750)', '\" The\"[578] (p=0.094, logit=17.375)', '\" TABLE\"[14700] (p=0.039, logit=16.500)', '\" None\"[2290] (p=0.011, logit=15.188)']\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.6171875, logit=19.25, token_id=58403, metadata=None))), (47033, (2, PredictedToken(token=' Printer', prob=0.1376953125, logit=17.75, token_id=47033, metadata=None))), (36895, (10, PredictedToken(token=' Eagle', prob=0.003662109375, logit=14.125, token_id=36895, metadata=None))), (49431, (14, PredictedToken(token=' Rabbit', prob=0.002685546875, logit=13.8125, token_id=49431, metadata=None))), (55405, (26, PredictedToken(token=' Orch', prob=0.0011138916015625, logit=12.9375, token_id=55405, metadata=None))), (356, (23, PredictedToken(token=' C', prob=0.0011138916015625, logit=12.9375, token_id=356, metadata=None)))])\n",
      "2025-09-15 09:43:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:35 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.754, logit=19.500)', '\" Eagle\"[36895] (p=0.090, logit=17.375)', '\" The\"[578] (p=0.048, logit=16.750)', '\" Printer\"[47033] (p=0.014, logit=15.500)', '\" R\"[432] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:43:35 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.75390625, logit=19.5, token_id=49431, metadata=None))), (36895, (2, PredictedToken(token=' Eagle', prob=0.09033203125, logit=17.375, token_id=36895, metadata=None))), (47033, (4, PredictedToken(token=' Printer', prob=0.01385498046875, logit=15.5, token_id=47033, metadata=None))), (356, (9, PredictedToken(token=' C', prob=0.0032806396484375, logit=14.0625, token_id=356, metadata=None))), (58403, (12, PredictedToken(token=' Tablet', prob=0.002899169921875, logit=13.9375, token_id=58403, metadata=None))), (55405, (56, PredictedToken(token=' Orch', prob=0.000164031982421875, logit=11.0625, token_id=55405, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:35 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:35 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-15 09:43:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:35 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.820, logit=20.000)', '\" The\"[578] (p=0.076, logit=17.625)', '\" Printer\"[47033] (p=0.019, logit=16.250)', '\" St\"[800] (p=0.017, logit=16.125)', '\" CAB\"[81217] (p=0.011, logit=15.688)']\n",
      "2025-09-15 09:43:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     clean_prediction=['\" Router\"[10777] (p=0.723, logit=19.875)', '\" The\"[578] (p=0.126, logit=18.125)', '\" A\"[362] (p=0.025, logit=16.500)', '\" ROUT\"[54281] (p=0.019, logit=16.250)', '\" It\"[1102] (p=0.012, logit=15.750)']\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     clean_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.72265625, logit=19.875, token_id=10777, metadata=None))), (18191, (7, PredictedToken(token=' Mouse', prob=0.007568359375, logit=15.3125, token_id=18191, metadata=None))), (27738, (9, PredictedToken(token=' Ward', prob=0.007110595703125, logit=15.25, token_id=27738, metadata=None))), (445, (23, PredictedToken(token=' L', prob=0.00109100341796875, logit=13.375, token_id=445, metadata=None))), (36358, (31, PredictedToken(token=' Bench', prob=0.000583648681640625, logit=12.75, token_id=36358, metadata=None))), (8219, (131, PredictedToken(token=' Sun', prob=5.1021575927734375e-05, logit=10.3125, token_id=8219, metadata=None)))])\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.832, logit=20.375)', '\" The\"[578] (p=0.047, logit=17.500)', '\" Ward\"[27738] (p=0.032, logit=17.125)', '\" Router\"[10777] (p=0.025, logit=16.875)', '\" There\"[2684] (p=0.008, logit=15.688)']\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.83203125, logit=20.375, token_id=36358, metadata=None))), (27738, (3, PredictedToken(token=' Ward', prob=0.0322265625, logit=17.125, token_id=27738, metadata=None))), (10777, (4, PredictedToken(token=' Router', prob=0.025146484375, logit=16.875, token_id=10777, metadata=None))), (18191, (7, PredictedToken(token=' Mouse', prob=0.00494384765625, logit=15.25, token_id=18191, metadata=None))), (8219, (15, PredictedToken(token=' Sun', prob=0.0011749267578125, logit=13.8125, token_id=8219, metadata=None))), (445, (22, PredictedToken(token=' L', prob=0.000667572021484375, logit=13.25, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:36 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     patch_prediction=['\" Scar\"[30760] (p=0.551, logit=20.125)', '\" The\"[578] (p=0.202, logit=19.125)', '\" S\"[328] (p=0.108, logit=18.500)', '\" A\"[362] (p=0.074, logit=18.125)', '\" It\"[1102] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.455, logit=20.250)', '\" K\"[735] (p=0.355, logit=20.000)', '\" The\"[578] (p=0.115, logit=18.875)', '\" A\"[362] (p=0.014, logit=16.750)', '\" There\"[2684] (p=0.009, logit=16.375)']\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.455078125, logit=20.25, token_id=75258, metadata=None))), (735, (2, PredictedToken(token=' K', prob=0.35546875, logit=20.0, token_id=735, metadata=None))), (55870, (50, PredictedToken(token=' Jacket', prob=0.00016307830810546875, logit=12.3125, token_id=55870, metadata=None))), (91782, (156, PredictedToken(token=' Shorts', prob=2.658367156982422e-05, logit=10.5, token_id=91782, metadata=None))), (100031, (487, PredictedToken(token=' Mosque', prob=3.591179847717285e-06, logit=8.5, token_id=100031, metadata=None)))])\n",
      "2025-09-15 09:43:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:37 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.555, logit=18.875)', '\" K\"[735] (p=0.124, logit=17.375)', '\" The\"[578] (p=0.096, logit=17.125)', '\" SHORT\"[66024] (p=0.046, logit=16.375)', '\" None\"[2290] (p=0.021, logit=15.625)']\n",
      "2025-09-15 09:43:37 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.5546875, logit=18.875, token_id=91782, metadata=None))), (735, (2, PredictedToken(token=' K', prob=0.12353515625, logit=17.375, token_id=735, metadata=None))), (55870, (6, PredictedToken(token=' Jacket', prob=0.017822265625, logit=15.4375, token_id=55870, metadata=None))), (100031, (18, PredictedToken(token=' Mosque', prob=0.00213623046875, logit=13.3125, token_id=100031, metadata=None))), (75258, (26, PredictedToken(token=' Refriger', prob=0.00128936767578125, logit=12.8125, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:37 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:37 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:43:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:37 src.selection.optimization INFO     patch_prediction=['\" Ash\"[14937] (p=0.617, logit=20.000)', '\" Pine\"[42609] (p=0.201, logit=18.875)', '\" The\"[578] (p=0.095, logit=18.125)', '\" Phone\"[14642] (p=0.024, logit=16.750)', '\" There\"[2684] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:43:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     clean_prediction=['\" Guitar\"[47759] (p=0.699, logit=20.625)', '\" The\"[578] (p=0.200, logit=19.375)', '\" G\"[480] (p=0.027, logit=17.375)', '\" Sax\"[68027] (p=0.015, logit=16.750)', '\" A\"[362] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     clean_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.69921875, logit=20.625, token_id=47759, metadata=None))), (68027, (4, PredictedToken(token=' Sax', prob=0.0145263671875, logit=16.75, token_id=68027, metadata=None))), (469, (16, PredictedToken(token=' E', prob=0.0012664794921875, logit=14.3125, token_id=469, metadata=None))), (18191, (136, PredictedToken(token=' Mouse', prob=3.170967102050781e-05, logit=10.625, token_id=18191, metadata=None))), (88088, (401, PredictedToken(token=' Birch', prob=4.023313522338867e-06, logit=8.5625, token_id=88088, metadata=None)))])\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     int_prediction=['\" Birch\"[88088] (p=0.562, logit=19.750)', '\" E\"[469] (p=0.266, logit=19.000)', '\" The\"[578] (p=0.086, logit=17.875)', '\" There\"[2684] (p=0.013, logit=16.000)', '\" None\"[2290] (p=0.006, logit=15.125)']\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     int_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.5625, logit=19.75, token_id=88088, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.265625, logit=19.0, token_id=469, metadata=None))), (47759, (13, PredictedToken(token=' Guitar', prob=0.0020294189453125, logit=14.125, token_id=47759, metadata=None))), (68027, (16, PredictedToken(token=' Sax', prob=0.001678466796875, logit=13.9375, token_id=68027, metadata=None))), (18191, (18, PredictedToken(token=' Mouse', prob=0.00122833251953125, logit=13.625, token_id=18191, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:38 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     patch_prediction=['\" Gir\"[48035] (p=0.793, logit=20.625)', '\" The\"[578] (p=0.107, logit=18.625)', '\" Horse\"[34392] (p=0.024, logit=17.125)', '\" A\"[362] (p=0.015, logit=16.625)', '\" There\"[2684] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.906, logit=21.625)', '\" The\"[578] (p=0.058, logit=18.875)', '\" M\"[386] (p=0.008, logit=16.875)', '\" There\"[2684] (p=0.004, logit=16.250)', '\" Pine\"[42609] (p=0.002, logit=15.688)']\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.90625, logit=21.625, token_id=91963, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.0023956298828125, logit=15.6875, token_id=42609, metadata=None))), (79189, (15, PredictedToken(token=' Elephant', prob=0.000606536865234375, logit=14.3125, token_id=79189, metadata=None))), (9939, (48, PredictedToken(token=' Er', prob=8.726119995117188e-05, logit=12.375, token_id=9939, metadata=None))), (24941, (247, PredictedToken(token=' Bear', prob=5.245208740234375e-06, logit=9.5625, token_id=24941, metadata=None)))])\n",
      "2025-09-15 09:43:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:39 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.520, logit=20.375)', '\" Elephant\"[79189] (p=0.314, logit=19.875)', '\" The\"[578] (p=0.102, logit=18.750)', '\" Pine\"[42609] (p=0.007, logit=16.125)', '\" Ele\"[27039] (p=0.005, logit=15.750)']\n",
      "2025-09-15 09:43:39 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.51953125, logit=20.375, token_id=24941, metadata=None))), (79189, (2, PredictedToken(token=' Elephant', prob=0.314453125, logit=19.875, token_id=79189, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.007415771484375, logit=16.125, token_id=42609, metadata=None))), (9939, (6, PredictedToken(token=' Er', prob=0.004486083984375, logit=15.625, token_id=9939, metadata=None))), (91963, (13, PredictedToken(token=' Mango', prob=0.00165557861328125, logit=14.625, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:39 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:39 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:43:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:39 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.742, logit=20.125)', '\" The\"[578] (p=0.114, logit=18.250)', '\" Acc\"[11683] (p=0.047, logit=17.375)', '\" T\"[350] (p=0.025, logit=16.750)', '\" There\"[2684] (p=0.012, logit=16.000)']\n",
      "2025-09-15 09:43:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.785, logit=18.500)', '\" The\"[578] (p=0.083, logit=16.250)', '\" Fl\"[3061] (p=0.014, logit=14.500)', '\" Harmon\"[40759] (p=0.011, logit=14.250)', '\" W\"[468] (p=0.010, logit=14.188)']\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.78515625, logit=18.5, token_id=27738, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.01434326171875, logit=14.5, token_id=3061, metadata=None))), (40759, (4, PredictedToken(token=' Harmon', prob=0.01116943359375, logit=14.25, token_id=40759, metadata=None))), (39794, (8, PredictedToken(token=' Desk', prob=0.0059814453125, logit=13.625, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     int_prediction=['\" Fl\"[3061] (p=0.723, logit=18.500)', '\" Harmon\"[40759] (p=0.111, logit=16.625)', '\" The\"[578] (p=0.067, logit=16.125)', '\" FL\"[13062] (p=0.010, logit=14.250)', '\" Ward\"[27738] (p=0.008, logit=13.938)']\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     int_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.72265625, logit=18.5, token_id=3061, metadata=None))), (40759, (2, PredictedToken(token=' Harmon', prob=0.11083984375, logit=16.625, token_id=40759, metadata=None))), (27738, (5, PredictedToken(token=' Ward', prob=0.007537841796875, logit=13.9375, token_id=27738, metadata=None))), (39794, (61, PredictedToken(token=' Desk', prob=0.0001888275146484375, logit=10.25, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:40 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.516, logit=19.750)', '\" Caul\"[90538] (p=0.314, logit=19.250)', '\" The\"[578] (p=0.054, logit=17.500)', '\" D\"[423] (p=0.026, logit=16.750)', '\" Onion\"[87035] (p=0.023, logit=16.625)']\n",
      "2025-09-15 09:43:40 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.805, logit=20.500)', '\" Bro\"[6031] (p=0.109, logit=18.500)', '\" The\"[578] (p=0.031, logit=17.250)', '\" There\"[2684] (p=0.015, logit=16.500)', '\" None\"[2290] (p=0.008, logit=15.875)']\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.8046875, logit=20.5, token_id=41785, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.10888671875, logit=18.5, token_id=6031, metadata=None))), (6150, (42, PredictedToken(token=' School', prob=0.00015354156494140625, logit=11.9375, token_id=6150, metadata=None))), (55405, (80, PredictedToken(token=' Orch', prob=6.818771362304688e-05, logit=11.125, token_id=55405, metadata=None))), (74574, (94, PredictedToken(token=' Violet', prob=5.316734313964844e-05, logit=10.875, token_id=74574, metadata=None)))])\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.824, logit=20.625)', '\" Orch\"[55405] (p=0.041, logit=17.625)', '\" The\"[578] (p=0.036, logit=17.500)', '\" There\"[2684] (p=0.022, logit=17.000)', '\" Spin\"[41785] (p=0.019, logit=16.875)']\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.82421875, logit=20.625, token_id=74574, metadata=None))), (55405, (2, PredictedToken(token=' Orch', prob=0.041015625, logit=17.625, token_id=55405, metadata=None))), (41785, (5, PredictedToken(token=' Spin', prob=0.0194091796875, logit=16.875, token_id=41785, metadata=None))), (6031, (7, PredictedToken(token=' Bro', prob=0.0091552734375, logit=16.125, token_id=6031, metadata=None))), (6150, (17, PredictedToken(token=' School', prob=0.00090789794921875, logit=13.8125, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:41 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:41 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.785, logit=20.125)', '\" The\"[578] (p=0.064, logit=17.625)', '\" Television\"[41445] (p=0.027, logit=16.750)', '\" MON\"[29637] (p=0.021, logit=16.500)', '\" Book\"[6017] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:43:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:42 src.selection.optimization INFO     clean_prediction=['\" Bed\"[13394] (p=0.527, logit=18.750)', '\" The\"[578] (p=0.104, logit=17.125)', '\" Library\"[11896] (p=0.092, logit=17.000)', '\" Sofa\"[61948] (p=0.081, logit=16.875)', '\" A\"[362] (p=0.032, logit=15.938)']\n",
      "2025-09-15 09:43:42 src.selection.optimization INFO     clean_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.52734375, logit=18.75, token_id=13394, metadata=None))), (11896, (3, PredictedToken(token=' Library', prob=0.091796875, logit=17.0, token_id=11896, metadata=None))), (61948, (4, PredictedToken(token=' Sofa', prob=0.0810546875, logit=16.875, token_id=61948, metadata=None))), (5907, (7, PredictedToken(token=' Project', prob=0.01318359375, logit=15.0625, token_id=5907, metadata=None))), (10777, (16, PredictedToken(token=' Router', prob=0.002593994140625, logit=13.4375, token_id=10777, metadata=None))), (23126, (38, PredictedToken(token=' Ti', prob=0.000701904296875, logit=12.125, token_id=23126, metadata=None))), (64695, (87, PredictedToken(token=' Peach', prob=0.0001659393310546875, logit=10.6875, token_id=64695, metadata=None)))])\n",
      "2025-09-15 09:43:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:42 src.selection.optimization INFO     int_prediction=['\" Project\"[5907] (p=0.785, logit=19.625)', '\" The\"[578] (p=0.083, logit=17.375)', '\" A\"[362] (p=0.020, logit=15.938)', '\" PROJECT\"[40992] (p=0.017, logit=15.812)', '\" It\"[1102] (p=0.010, logit=15.312)']\n",
      "2025-09-15 09:43:42 src.selection.optimization INFO     int_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.78515625, logit=19.625, token_id=5907, metadata=None))), (10777, (7, PredictedToken(token=' Router', prob=0.00872802734375, logit=15.125, token_id=10777, metadata=None))), (13394, (9, PredictedToken(token=' Bed', prob=0.003875732421875, logit=14.3125, token_id=13394, metadata=None))), (23126, (12, PredictedToken(token=' Ti', prob=0.002655029296875, logit=13.9375, token_id=23126, metadata=None))), (11896, (29, PredictedToken(token=' Library', prob=0.0007171630859375, logit=12.625, token_id=11896, metadata=None))), (61948, (31, PredictedToken(token=' Sofa', prob=0.00063323974609375, logit=12.5, token_id=61948, metadata=None))), (64695, (436, PredictedToken(token=' Peach', prob=7.4803829193115234e-06, logit=8.0625, token_id=64695, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:42 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.434, logit=19.125)', '\" Sk\"[4923] (p=0.338, logit=18.875)', '\" The\"[578] (p=0.076, logit=17.375)', '\" Ski\"[61595] (p=0.019, logit=16.000)', '\" Helm\"[63142] (p=0.017, logit=15.875)']\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.742, logit=19.750)', '\" The\"[578] (p=0.079, logit=17.500)', '\" Apartment\"[53889] (p=0.054, logit=17.125)', '\" A\"[362] (p=0.020, logit=16.125)', '\" CH\"[6969] (p=0.016, logit=15.938)']\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.7421875, logit=19.75, token_id=9441, metadata=None))), (53889, (3, PredictedToken(token=' Apartment', prob=0.053955078125, logit=17.125, token_id=53889, metadata=None))), (16488, (7, PredictedToken(token=' Bat', prob=0.00933837890625, logit=15.375, token_id=16488, metadata=None))), (34954, (9, PredictedToken(token=' Mirror', prob=0.00567626953125, logit=14.875, token_id=34954, metadata=None))), (65197, (13, PredictedToken(token=' Surf', prob=0.003662109375, logit=14.4375, token_id=65197, metadata=None)))])\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     int_prediction=['\" Surf\"[65197] (p=0.447, logit=19.125)', '\" Bat\"[16488] (p=0.350, logit=18.875)', '\" The\"[578] (p=0.053, logit=17.000)', '\" BAT\"[79081] (p=0.022, logit=16.125)', '\" Mirror\"[34954] (p=0.019, logit=15.938)']\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     int_track=OrderedDict([(65197, (1, PredictedToken(token=' Surf', prob=0.447265625, logit=19.125, token_id=65197, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.349609375, logit=18.875, token_id=16488, metadata=None))), (34954, (5, PredictedToken(token=' Mirror', prob=0.0185546875, logit=15.9375, token_id=34954, metadata=None))), (9441, (7, PredictedToken(token=' Church', prob=0.01531982421875, logit=15.75, token_id=9441, metadata=None))), (53889, (33, PredictedToken(token=' Apartment', prob=0.0003833770751953125, logit=12.0625, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:43 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     patch_prediction=['\" Train\"[27217] (p=0.805, logit=20.750)', '\" The\"[578] (p=0.124, logit=18.875)', '\" A\"[362] (p=0.015, logit=16.750)', '\" There\"[2684] (p=0.007, logit=16.000)', '\" None\"[2290] (p=0.007, logit=15.938)']\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     clean_prediction=['\" Orch\"[55405] (p=0.848, logit=20.000)', '\" The\"[578] (p=0.048, logit=17.125)', '\" orch\"[41245] (p=0.023, logit=16.375)', '\" OR\"[2794] (p=0.016, logit=16.000)', '\" An\"[1556] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     clean_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.84765625, logit=20.0, token_id=55405, metadata=None))), (82452, (7, PredictedToken(token=' Jasmine', prob=0.003936767578125, logit=14.625, token_id=82452, metadata=None))), (1630, (11, PredictedToken(token=' X', prob=0.0015411376953125, logit=13.6875, token_id=1630, metadata=None))), (19111, (12, PredictedToken(token=' Bus', prob=0.0015411376953125, logit=13.6875, token_id=19111, metadata=None))), (50159, (32, PredictedToken(token=' Sco', prob=0.0004138946533203125, logit=12.375, token_id=50159, metadata=None)))])\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.840, logit=20.000)', '\" The\"[578] (p=0.037, logit=16.875)', '\" bus\"[5951] (p=0.025, logit=16.500)', '\" BUS\"[23504] (p=0.022, logit=16.375)', '\" There\"[2684] (p=0.014, logit=15.875)']\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.83984375, logit=20.0, token_id=19111, metadata=None))), (50159, (8, PredictedToken(token=' Sco', prob=0.00726318359375, logit=15.25, token_id=50159, metadata=None))), (55405, (22, PredictedToken(token=' Orch', prob=0.00049591064453125, logit=12.5625, token_id=55405, metadata=None))), (1630, (27, PredictedToken(token=' X', prob=0.000339508056640625, logit=12.1875, token_id=1630, metadata=None))), (82452, (39, PredictedToken(token=' Jasmine', prob=0.00019359588623046875, logit=11.625, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:44 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.922, logit=20.875)', '\" TO\"[5257] (p=0.017, logit=16.875)', '\" The\"[578] (p=0.015, logit=16.750)', '\" None\"[2290] (p=0.006, logit=15.812)', '\" A\"[362] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     clean_prediction=['\" Warehouse\"[52466] (p=0.461, logit=18.750)', '\" Mosque\"[100031] (p=0.218, logit=18.000)', '\" The\"[578] (p=0.117, logit=17.375)', '\" Bat\"[16488] (p=0.055, logit=16.625)', '\" A\"[362] (p=0.033, logit=16.125)']\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     clean_track=OrderedDict([(52466, (1, PredictedToken(token=' Warehouse', prob=0.4609375, logit=18.75, token_id=52466, metadata=None))), (100031, (2, PredictedToken(token=' Mosque', prob=0.2177734375, logit=18.0, token_id=100031, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.054931640625, logit=16.625, token_id=16488, metadata=None))), (48471, (12, PredictedToken(token=' Shower', prob=0.0045166015625, logit=14.125, token_id=48471, metadata=None))), (61948, (13, PredictedToken(token=' Sofa', prob=0.004241943359375, logit=14.0625, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.637, logit=18.875)', '\" Mosque\"[100031] (p=0.098, logit=17.000)', '\" Shower\"[48471] (p=0.067, logit=16.625)', '\" The\"[578] (p=0.041, logit=16.125)', '\" Sofa\"[61948] (p=0.028, logit=15.750)']\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.63671875, logit=18.875, token_id=16488, metadata=None))), (100031, (2, PredictedToken(token=' Mosque', prob=0.09765625, logit=17.0, token_id=100031, metadata=None))), (48471, (3, PredictedToken(token=' Shower', prob=0.06689453125, logit=16.625, token_id=48471, metadata=None))), (61948, (5, PredictedToken(token=' Sofa', prob=0.0279541015625, logit=15.75, token_id=61948, metadata=None))), (52466, (8, PredictedToken(token=' Warehouse', prob=0.008544921875, logit=14.5625, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:45 src.selection.optimization DEBUG    torch.Size([4, 30])\n",
      "2025-09-15 09:43:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.330, logit=18.375)', '\" Elm\"[65329] (p=0.200, logit=17.875)', '\" Bat\"[16488] (p=0.122, logit=17.375)', '\" The\"[578] (p=0.107, logit=17.250)', '\" There\"[2684] (p=0.051, logit=16.500)']\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.938, logit=20.625)', '\" The\"[578] (p=0.006, logit=15.500)', '\" L\"[445] (p=0.006, logit=15.500)', '\" R\"[432] (p=0.005, logit=15.438)', '\" A\"[362] (p=0.004, logit=15.188)']\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.9375, logit=20.625, token_id=74968, metadata=None))), (445, (2, PredictedToken(token=' L', prob=0.005584716796875, logit=15.5, token_id=445, metadata=None))), (44570, (7, PredictedToken(token=' Maple', prob=0.00408935546875, logit=15.1875, token_id=44570, metadata=None))), (18787, (8, PredictedToken(token=' Oak', prob=0.003173828125, logit=14.9375, token_id=18787, metadata=None)))])\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     int_prediction=['\" Maple\"[44570] (p=0.883, logit=20.375)', '\" Razor\"[74968] (p=0.050, logit=17.500)', '\" Oak\"[18787] (p=0.013, logit=16.125)', '\" MAP\"[28322] (p=0.011, logit=16.000)', '\" None\"[2290] (p=0.006, logit=15.375)']\n",
      "2025-09-15 09:43:46 src.selection.optimization INFO     int_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.8828125, logit=20.375, token_id=44570, metadata=None))), (74968, (2, PredictedToken(token=' Razor', prob=0.0498046875, logit=17.5, token_id=74968, metadata=None))), (18787, (3, PredictedToken(token=' Oak', prob=0.0125732421875, logit=16.125, token_id=18787, metadata=None))), (445, (7, PredictedToken(token=' L', prob=0.003387451171875, logit=14.8125, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:46 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:43:47 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.455, logit=18.375)', '\" Y\"[816] (p=0.215, logit=17.625)', '\" The\"[578] (p=0.090, logit=16.750)', '\" Boat\"[45332] (p=0.048, logit=16.125)', '\" A\"[362] (p=0.040, logit=15.938)']\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.805, logit=20.500)', '\" The\"[578] (p=0.085, logit=18.250)', '\" A\"[362] (p=0.040, logit=17.500)', '\" Sk\"[4923] (p=0.011, logit=16.250)', '\" Stick\"[47561] (p=0.004, logit=15.312)']\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.8046875, logit=20.5, token_id=41342, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.011474609375, logit=16.25, token_id=4923, metadata=None))), (20423, (21, PredictedToken(token=' Amb', prob=0.000885009765625, logit=13.6875, token_id=20423, metadata=None))), (50159, (31, PredictedToken(token=' Sco', prob=0.000392913818359375, logit=12.875, token_id=50159, metadata=None)))])\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.621, logit=19.000)', '\" The\"[578] (p=0.108, logit=17.250)', '\" Sk\"[4923] (p=0.051, logit=16.500)', '\" Amb\"[20423] (p=0.045, logit=16.375)', '\" A\"[362] (p=0.035, logit=16.125)']\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.62109375, logit=19.0, token_id=50159, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.051025390625, logit=16.5, token_id=4923, metadata=None))), (20423, (4, PredictedToken(token=' Amb', prob=0.044921875, logit=16.375, token_id=20423, metadata=None))), (41342, (15, PredictedToken(token=' Hockey', prob=0.003692626953125, logit=13.875, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:47 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:47 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:43:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.594, logit=20.250)', '\" E\"[469] (p=0.218, logit=19.250)', '\" The\"[578] (p=0.091, logit=18.375)', '\" Spin\"[41785] (p=0.020, logit=16.875)', '\" A\"[362] (p=0.018, logit=16.750)']\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     clean_prediction=['\" Camera\"[14669] (p=0.770, logit=20.375)', '\" The\"[578] (p=0.072, logit=18.000)', '\" Router\"[10777] (p=0.049, logit=17.625)', '\" Pin\"[17929] (p=0.014, logit=16.375)', '\" A\"[362] (p=0.012, logit=16.250)']\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     clean_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.76953125, logit=20.375, token_id=14669, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.04931640625, logit=17.625, token_id=10777, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.01409912109375, logit=16.375, token_id=17929, metadata=None))), (6031, (11, PredictedToken(token=' Bro', prob=0.0026092529296875, logit=14.6875, token_id=6031, metadata=None))), (29625, (12, PredictedToken(token=' Chain', prob=0.002166748046875, logit=14.5, token_id=29625, metadata=None))), (45332, (23, PredictedToken(token=' Boat', prob=0.0009002685546875, logit=13.625, token_id=45332, metadata=None)))])\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.447, logit=19.750)', '\" Chain\"[29625] (p=0.348, logit=19.500)', '\" Router\"[10777] (p=0.047, logit=17.500)', '\" The\"[578] (p=0.032, logit=17.125)', '\" Boat\"[45332] (p=0.029, logit=17.000)']\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.447265625, logit=19.75, token_id=17929, metadata=None))), (29625, (2, PredictedToken(token=' Chain', prob=0.34765625, logit=19.5, token_id=29625, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.047119140625, logit=17.5, token_id=10777, metadata=None))), (45332, (5, PredictedToken(token=' Boat', prob=0.028564453125, logit=17.0, token_id=45332, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.007232666015625, logit=15.625, token_id=6031, metadata=None))), (14669, (22, PredictedToken(token=' Camera', prob=0.00067138671875, logit=13.25, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:48 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:48 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-15 09:43:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     patch_prediction=['\" Elm\"[65329] (p=0.727, logit=19.375)', '\" The\"[578] (p=0.087, logit=17.250)', '\" Cherry\"[45805] (p=0.023, logit=15.938)', '\" EL\"[17705] (p=0.019, logit=15.750)', '\" There\"[2684] (p=0.017, logit=15.625)']\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.918, logit=21.125)', '\" The\"[578] (p=0.046, logit=18.125)', '\" M\"[386] (p=0.007, logit=16.250)', '\" There\"[2684] (p=0.002, logit=15.000)', '\" A\"[362] (p=0.002, logit=15.000)']\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.91796875, logit=21.125, token_id=91963, metadata=None))), (76924, (8, PredictedToken(token=' Banana', prob=0.001220703125, logit=14.5, token_id=76924, metadata=None))), (22410, (20, PredictedToken(token=' Ju', prob=0.0003490447998046875, logit=13.25, token_id=22410, metadata=None))), (98028, (105, PredictedToken(token=' Bamboo', prob=3.0517578125e-05, logit=10.8125, token_id=98028, metadata=None))), (68554, (179, PredictedToken(token=' Gloves', prob=1.2695789337158203e-05, logit=9.9375, token_id=68554, metadata=None))), (18787, (512, PredictedToken(token=' Oak', prob=2.205371856689453e-06, logit=8.1875, token_id=18787, metadata=None)))])\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     int_prediction=['\" Oak\"[18787] (p=0.633, logit=18.875)', '\" The\"[578] (p=0.181, logit=17.625)', '\" Ju\"[22410] (p=0.016, logit=15.188)', '\" It\"[1102] (p=0.013, logit=15.000)', '\" There\"[2684] (p=0.012, logit=14.875)']\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     int_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.6328125, logit=18.875, token_id=18787, metadata=None))), (22410, (3, PredictedToken(token=' Ju', prob=0.015869140625, logit=15.1875, token_id=22410, metadata=None))), (91963, (9, PredictedToken(token=' Mango', prob=0.006591796875, logit=14.3125, token_id=91963, metadata=None))), (68554, (13, PredictedToken(token=' Gloves', prob=0.0045166015625, logit=13.9375, token_id=68554, metadata=None))), (98028, (14, PredictedToken(token=' Bamboo', prob=0.003753662109375, logit=13.75, token_id=98028, metadata=None))), (76924, (23, PredictedToken(token=' Banana', prob=0.00177001953125, logit=13.0, token_id=76924, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:43:49 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-15 09:43:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.883, logit=22.000)', '\" The\"[578] (p=0.082, logit=19.625)', '\" P\"[393] (p=0.008, logit=17.250)', '\" A\"[362] (p=0.008, logit=17.250)', '\" There\"[2684] (p=0.002, logit=15.875)']\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.613, logit=20.375)', '\" Rice\"[30616] (p=0.155, logit=19.000)', '\" The\"[578] (p=0.155, logit=19.000)', '\" A\"[362] (p=0.011, logit=16.375)', '\" Water\"[10164] (p=0.007, logit=15.938)']\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.61328125, logit=20.375, token_id=75258, metadata=None))), (30616, (3, PredictedToken(token=' Rice', prob=0.1552734375, logit=19.0, token_id=30616, metadata=None))), (10164, (5, PredictedToken(token=' Water', prob=0.007232666015625, logit=15.9375, token_id=10164, metadata=None))), (3420, (39, PredictedToken(token=' Trump', prob=0.0003185272216796875, logit=12.8125, token_id=3420, metadata=None))), (8325, (44, PredictedToken(token=' Apple', prob=0.0002803802490234375, logit=12.6875, token_id=8325, metadata=None))), (84008, (61, PredictedToken(token=' Sheep', prob=0.0001506805419921875, logit=12.0625, token_id=84008, metadata=None)))])\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.594, logit=20.375)', '\" Water\"[10164] (p=0.281, logit=19.625)', '\" The\"[578] (p=0.049, logit=17.875)', '\" Rice\"[30616] (p=0.016, logit=16.750)', '\" APPLE\"[91436] (p=0.012, logit=16.500)']\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.59375, logit=20.375, token_id=8325, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.28125, logit=19.625, token_id=10164, metadata=None))), (30616, (4, PredictedToken(token=' Rice', prob=0.015869140625, logit=16.75, token_id=30616, metadata=None))), (3420, (9, PredictedToken(token=' Trump', prob=0.0022735595703125, logit=14.8125, token_id=3420, metadata=None))), (84008, (16, PredictedToken(token=' Sheep', prob=0.000949859619140625, logit=13.9375, token_id=84008, metadata=None))), (75258, (96, PredictedToken(token=' Refriger', prob=4.7206878662109375e-05, logit=10.9375, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:50 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.734, logit=20.125)', '\" The\"[578] (p=0.145, logit=18.500)', '\" Desk\"[39794] (p=0.028, logit=16.875)', '\" It\"[1102] (p=0.010, logit=15.875)', '\" A\"[362] (p=0.010, logit=15.875)']\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     clean_prediction=['\" Brace\"[70306] (p=0.762, logit=19.500)', '\" The\"[578] (p=0.080, logit=17.250)', '\" Ank\"[57915] (p=0.030, logit=16.250)', '\" A\"[362] (p=0.018, logit=15.750)', '\" BR\"[19333] (p=0.013, logit=15.438)']\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     clean_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.76171875, logit=19.5, token_id=70306, metadata=None))), (57915, (3, PredictedToken(token=' Ank', prob=0.029541015625, logit=16.25, token_id=57915, metadata=None))), (800, (13, PredictedToken(token=' St', prob=0.0025787353515625, logit=13.8125, token_id=800, metadata=None))), (98028, (15, PredictedToken(token=' Bamboo', prob=0.0024261474609375, logit=13.75, token_id=98028, metadata=None))), (61948, (57, PredictedToken(token=' Sofa', prob=0.000255584716796875, logit=11.5, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     int_prediction=['\" Sofa\"[61948] (p=0.520, logit=19.000)', '\" Bamboo\"[98028] (p=0.191, logit=18.000)', '\" Ank\"[57915] (p=0.070, logit=17.000)', '\" St\"[800] (p=0.048, logit=16.625)', '\" The\"[578] (p=0.043, logit=16.500)']\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     int_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.51953125, logit=19.0, token_id=61948, metadata=None))), (98028, (2, PredictedToken(token=' Bamboo', prob=0.19140625, logit=18.0, token_id=98028, metadata=None))), (57915, (3, PredictedToken(token=' Ank', prob=0.0703125, logit=17.0, token_id=57915, metadata=None))), (800, (4, PredictedToken(token=' St', prob=0.04833984375, logit=16.625, token_id=800, metadata=None))), (70306, (100, PredictedToken(token=' Brace', prob=9.918212890625e-05, logit=10.4375, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:51 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:51 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:43:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.855, logit=21.375)', '\" The\"[578] (p=0.080, logit=19.000)', '\" Acc\"[11683] (p=0.014, logit=17.250)', '\" A\"[362] (p=0.011, logit=17.000)', '\" J\"[622] (p=0.005, logit=16.250)']\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     clean_prediction=['\" Tul\"[43316] (p=0.672, logit=20.125)', '\" Violet\"[74574] (p=0.192, logit=18.875)', '\" The\"[578] (p=0.080, logit=18.000)', '\" There\"[2684] (p=0.011, logit=16.000)', '\" A\"[362] (p=0.005, logit=15.250)']\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     clean_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.671875, logit=20.125, token_id=43316, metadata=None))), (74574, (2, PredictedToken(token=' Violet', prob=0.1923828125, logit=18.875, token_id=74574, metadata=None))), (68027, (11, PredictedToken(token=' Sax', prob=0.0011444091796875, logit=13.75, token_id=68027, metadata=None))), (29318, (33, PredictedToken(token=' Dress', prob=0.00032806396484375, logit=12.5, token_id=29318, metadata=None))), (55807, (68, PredictedToken(token=' Shirt', prob=9.393692016601562e-05, logit=11.25, token_id=55807, metadata=None)))])\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.508, logit=19.750)', '\" Dress\"[29318] (p=0.309, logit=19.250)', '\" The\"[578] (p=0.053, logit=17.500)', '\" Violet\"[74574] (p=0.042, logit=17.250)', '\" There\"[2684] (p=0.017, logit=16.375)']\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.5078125, logit=19.75, token_id=55807, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.30859375, logit=19.25, token_id=29318, metadata=None))), (74574, (4, PredictedToken(token=' Violet', prob=0.041748046875, logit=17.25, token_id=74574, metadata=None))), (68027, (6, PredictedToken(token=' Sax', prob=0.00933837890625, logit=15.75, token_id=68027, metadata=None))), (43316, (11, PredictedToken(token=' Tul', prob=0.002349853515625, logit=14.375, token_id=43316, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:52 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.852, logit=20.375)', '\" The\"[578] (p=0.054, logit=17.625)', '\" Mixer\"[72392] (p=0.016, logit=16.375)', '\" A\"[362] (p=0.009, logit=15.812)', '\" Oven\"[87213] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     clean_prediction=['\" Mosque\"[100031] (p=0.852, logit=20.750)', '\" School\"[6150] (p=0.062, logit=18.125)', '\" The\"[578] (p=0.038, logit=17.625)', '\" A\"[362] (p=0.009, logit=16.250)', '\" MOS\"[74174] (p=0.004, logit=15.438)']\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     clean_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.8515625, logit=20.75, token_id=100031, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.061767578125, logit=18.125, token_id=6150, metadata=None))), (16478, (8, PredictedToken(token=' Chair', prob=0.0021209716796875, logit=14.75, token_id=16478, metadata=None))), (88668, (13, PredictedToken(token=' Blender', prob=0.00093841552734375, logit=13.9375, token_id=88668, metadata=None))), (40090, (12, PredictedToken(token=' Pressure', prob=0.00093841552734375, logit=13.9375, token_id=40090, metadata=None)))])\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.404, logit=18.375)', '\" Mosque\"[100031] (p=0.191, logit=17.625)', '\" Chair\"[16478] (p=0.191, logit=17.625)', '\" The\"[578] (p=0.055, logit=16.375)', '\" A\"[362] (p=0.029, logit=15.750)']\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.404296875, logit=18.375, token_id=40090, metadata=None))), (100031, (3, PredictedToken(token=' Mosque', prob=0.19140625, logit=17.625, token_id=100031, metadata=None))), (16478, (2, PredictedToken(token=' Chair', prob=0.19140625, logit=17.625, token_id=16478, metadata=None))), (6150, (8, PredictedToken(token=' School', prob=0.01385498046875, logit=15.0, token_id=6150, metadata=None))), (88668, (21, PredictedToken(token=' Blender', prob=0.001068115234375, logit=12.4375, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:53 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:43:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.801, logit=20.375)', '\" Air\"[6690] (p=0.066, logit=17.875)', '\" The\"[578] (p=0.051, logit=17.625)', '\" There\"[2684] (p=0.010, logit=15.938)', '\" C\"[356] (p=0.007, logit=15.688)']\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     clean_prediction=['\" Orch\"[55405] (p=0.770, logit=20.500)', '\" The\"[578] (p=0.134, logit=18.750)', '\" OR\"[2794] (p=0.026, logit=17.125)', '\" An\"[1556] (p=0.018, logit=16.750)', '\" orch\"[41245] (p=0.010, logit=16.125)']\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     clean_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.76953125, logit=20.5, token_id=55405, metadata=None))), (32749, (8, PredictedToken(token=' Carn', prob=0.0033416748046875, logit=15.0625, token_id=32749, metadata=None))), (1183, (33, PredictedToken(token=' Tr', prob=0.0002269744873046875, logit=12.375, token_id=1183, metadata=None))), (22249, (104, PredictedToken(token=' Ring', prob=3.9577484130859375e-05, logit=10.625, token_id=22249, metadata=None))), (70762, (510, PredictedToken(token=' Motorcycle', prob=3.039836883544922e-06, logit=8.0625, token_id=70762, metadata=None)))])\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.934, logit=21.375)', '\" The\"[578] (p=0.025, logit=17.750)', '\" Tr\"[1183] (p=0.010, logit=16.875)', '\" motorcycle\"[35404] (p=0.004, logit=16.000)', '\" There\"[2684] (p=0.003, logit=15.688)']\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.93359375, logit=21.375, token_id=70762, metadata=None))), (1183, (3, PredictedToken(token=' Tr', prob=0.0103759765625, logit=16.875, token_id=1183, metadata=None))), (22249, (28, PredictedToken(token=' Ring', prob=0.0001392364501953125, logit=12.5625, token_id=22249, metadata=None))), (55405, (65, PredictedToken(token=' Orch', prob=4.8160552978515625e-05, logit=11.5, token_id=55405, metadata=None))), (32749, (105, PredictedToken(token=' Carn', prob=2.002716064453125e-05, logit=10.625, token_id=32749, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:54 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     patch_prediction=['\" Plum\"[84409] (p=0.750, logit=18.875)', '\" The\"[578] (p=0.079, logit=16.625)', '\" PL\"[10528] (p=0.062, logit=16.375)', '\" Cherry\"[45805] (p=0.009, logit=14.438)', '\" plum\"[42272] (p=0.009, logit=14.438)']\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.586, logit=19.250)', '\" The\"[578] (p=0.090, logit=17.375)', '\" Bat\"[16488] (p=0.080, logit=17.250)', '\" Water\"[10164] (p=0.070, logit=17.125)', '\" E\"[469] (p=0.033, logit=16.375)']\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.5859375, logit=19.25, token_id=3816, metadata=None))), (16488, (3, PredictedToken(token=' Bat', prob=0.07958984375, logit=17.25, token_id=16488, metadata=None))), (10164, (4, PredictedToken(token=' Water', prob=0.0703125, logit=17.125, token_id=10164, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.033203125, logit=16.375, token_id=469, metadata=None))), (48665, (11, PredictedToken(token=' Raspberry', prob=0.004486083984375, logit=14.375, token_id=48665, metadata=None)))])\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     int_prediction=['\" Raspberry\"[48665] (p=0.527, logit=19.500)', '\" Water\"[10164] (p=0.151, logit=18.250)', '\" Bat\"[16488] (p=0.092, logit=17.750)', '\" Red\"[3816] (p=0.072, logit=17.500)', '\" The\"[578] (p=0.034, logit=16.750)']\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     int_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.52734375, logit=19.5, token_id=48665, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.1513671875, logit=18.25, token_id=10164, metadata=None))), (16488, (3, PredictedToken(token=' Bat', prob=0.091796875, logit=17.75, token_id=16488, metadata=None))), (3816, (4, PredictedToken(token=' Red', prob=0.07177734375, logit=17.5, token_id=3816, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.0205078125, logit=16.25, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:55 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:55 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:43:55 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.633, logit=20.375)', '\" The\"[578] (p=0.181, logit=19.125)', '\" Ju\"[22410] (p=0.075, logit=18.250)', '\" A\"[362] (p=0.031, logit=17.375)', '\" There\"[2684] (p=0.007, logit=15.938)']\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.789, logit=20.875)', '\" The\"[578] (p=0.121, logit=19.000)', '\" Surf\"[65197] (p=0.035, logit=17.750)', '\" BOX\"[53783] (p=0.014, logit=16.875)', '\" SUR\"[53083] (p=0.006, logit=15.938)']\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.7890625, logit=20.875, token_id=72683, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.03466796875, logit=17.75, token_id=65197, metadata=None))), (469, (21, PredictedToken(token=' E', prob=0.0005950927734375, logit=13.6875, token_id=469, metadata=None))), (6690, (145, PredictedToken(token=' Air', prob=1.800060272216797e-05, logit=10.1875, token_id=6690, metadata=None))), (88668, (238, PredictedToken(token=' Blender', prob=7.987022399902344e-06, logit=9.375, token_id=88668, metadata=None))), (29318, (353, PredictedToken(token=' Dress', prob=4.023313522338867e-06, logit=8.6875, token_id=29318, metadata=None))), (4783, (454, PredictedToken(token=' House', prob=2.7567148208618164e-06, logit=8.3125, token_id=4783, metadata=None)))])\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     int_prediction=['\" Blender\"[88668] (p=0.750, logit=20.625)', '\" The\"[578] (p=0.115, logit=18.750)', '\" Air\"[6690] (p=0.048, logit=17.875)', '\" Boxing\"[72683] (p=0.026, logit=17.250)', '\" A\"[362] (p=0.007, logit=16.000)']\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     int_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.75, logit=20.625, token_id=88668, metadata=None))), (6690, (3, PredictedToken(token=' Air', prob=0.048095703125, logit=17.875, token_id=6690, metadata=None))), (72683, (4, PredictedToken(token=' Boxing', prob=0.025634765625, logit=17.25, token_id=72683, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.0028839111328125, logit=15.0625, token_id=469, metadata=None))), (29318, (29, PredictedToken(token=' Dress', prob=0.000415802001953125, logit=13.125, token_id=29318, metadata=None))), (65197, (37, PredictedToken(token=' Surf', prob=0.0003032684326171875, logit=12.8125, token_id=65197, metadata=None))), (4783, (329, PredictedToken(token=' House', prob=6.288290023803711e-06, logit=8.9375, token_id=4783, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:56 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:43:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     patch_prediction=['\" Temple\"[19176] (p=0.715, logit=18.625)', '\" The\"[578] (p=0.059, logit=16.125)', '\" Mixer\"[72392] (p=0.046, logit=15.875)', '\" Factory\"[17367] (p=0.046, logit=15.875)', '\" Shorts\"[91782] (p=0.028, logit=15.375)']\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.590, logit=20.500)', '\" Hat\"[22050] (p=0.279, logit=19.750)', '\" The\"[578] (p=0.062, logit=18.250)', '\" SOCK\"[35651] (p=0.007, logit=16.000)', '\" \"\"[330] (p=0.006, logit=15.938)']\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.58984375, logit=20.5, token_id=328, metadata=None))), (22050, (2, PredictedToken(token=' Hat', prob=0.279296875, logit=19.75, token_id=22050, metadata=None))), (11896, (20, PredictedToken(token=' Library', prob=0.000946044921875, logit=14.0625, token_id=11896, metadata=None))), (87213, (25, PredictedToken(token=' Oven', prob=0.00064849853515625, logit=13.6875, token_id=87213, metadata=None))), (16730, (317, PredictedToken(token=' Museum', prob=6.794929504394531e-06, logit=9.125, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.637, logit=20.500)', '\" Oven\"[87213] (p=0.183, logit=19.250)', '\" Hat\"[22050] (p=0.067, logit=18.250)', '\" The\"[578] (p=0.041, logit=17.750)', '\" S\"[328] (p=0.009, logit=16.250)']\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.63671875, logit=20.5, token_id=11896, metadata=None))), (87213, (2, PredictedToken(token=' Oven', prob=0.1826171875, logit=19.25, token_id=87213, metadata=None))), (22050, (3, PredictedToken(token=' Hat', prob=0.0673828125, logit=18.25, token_id=22050, metadata=None))), (328, (5, PredictedToken(token=' S', prob=0.00909423828125, logit=16.25, token_id=328, metadata=None))), (16730, (11, PredictedToken(token=' Museum', prob=0.003143310546875, logit=15.1875, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:57 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:43:57 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:43:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.555, logit=20.250)', '\" Van\"[13000] (p=0.159, logit=19.000)', '\" The\"[578] (p=0.159, logit=19.000)', '\" A\"[362] (p=0.024, logit=17.125)', '\" CAR\"[28876] (p=0.019, logit=16.875)']\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     clean_prediction=['\" Fl\"[3061] (p=0.746, logit=20.000)', '\" The\"[578] (p=0.130, logit=18.250)', '\" FL\"[13062] (p=0.029, logit=16.750)', '\" X\"[1630] (p=0.029, logit=16.750)', '\" A\"[362] (p=0.011, logit=15.812)']\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     clean_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.74609375, logit=20.0, token_id=3061, metadata=None))), (1630, (3, PredictedToken(token=' X', prob=0.0289306640625, logit=16.75, token_id=1630, metadata=None))), (16183, (8, PredictedToken(token=' Hel', prob=0.004425048828125, logit=14.875, token_id=16183, metadata=None))), (3804, (13, PredictedToken(token=' Sub', prob=0.00119781494140625, logit=13.5625, token_id=3804, metadata=None))), (14642, (34, PredictedToken(token=' Phone', prob=0.0003223419189453125, logit=12.25, token_id=14642, metadata=None))), (26781, (133, PredictedToken(token=' Hair', prob=2.9921531677246094e-05, logit=9.875, token_id=26781, metadata=None))), (67553, (161, PredictedToken(token=' Pants', prob=2.193450927734375e-05, logit=9.5625, token_id=67553, metadata=None)))])\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.840, logit=20.625)', '\" Sub\"[3804] (p=0.078, logit=18.250)', '\" The\"[578] (p=0.032, logit=17.375)', '\" HEL\"[38757] (p=0.007, logit=15.812)', '\" A\"[362] (p=0.006, logit=15.688)']\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.83984375, logit=20.625, token_id=16183, metadata=None))), (3804, (2, PredictedToken(token=' Sub', prob=0.078125, logit=18.25, token_id=3804, metadata=None))), (1630, (6, PredictedToken(token=' X', prob=0.00439453125, logit=15.375, token_id=1630, metadata=None))), (3061, (11, PredictedToken(token=' Fl', prob=0.001617431640625, logit=14.375, token_id=3061, metadata=None))), (14642, (15, PredictedToken(token=' Phone', prob=0.0011138916015625, logit=14.0, token_id=14642, metadata=None))), (67553, (138, PredictedToken(token=' Pants', prob=1.800060272216797e-05, logit=9.875, token_id=67553, metadata=None))), (26781, (205, PredictedToken(token=' Hair', prob=9.059906005859375e-06, logit=9.1875, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:58 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:43:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.742, logit=20.750)', '\" The\"[578] (p=0.114, logit=18.875)', '\" Camera\"[14669] (p=0.069, logit=18.375)', '\" HEAD\"[34180] (p=0.020, logit=17.125)', '\" There\"[2684] (p=0.006, logit=15.875)']\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     clean_prediction=['\" Orch\"[55405] (p=0.871, logit=20.625)', '\" The\"[578] (p=0.043, logit=17.625)', '\" An\"[1556] (p=0.021, logit=16.875)', '\" OR\"[2794] (p=0.012, logit=16.375)', '\" orch\"[41245] (p=0.009, logit=16.000)']\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     clean_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.87109375, logit=20.625, token_id=55405, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.007080078125, logit=15.8125, token_id=423, metadata=None))), (16147, (99, PredictedToken(token=' Smart', prob=3.719329833984375e-05, logit=10.5625, token_id=16147, metadata=None))), (17367, (440, PredictedToken(token=' Factory', prob=3.680586814880371e-06, logit=8.25, token_id=17367, metadata=None))), (47033, (1293, PredictedToken(token=' Printer', prob=8.456408977508545e-07, logit=6.78125, token_id=47033, metadata=None)))])\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.463, logit=19.500)', '\" Printer\"[47033] (p=0.361, logit=19.250)', '\" The\"[578] (p=0.049, logit=17.250)', '\" A\"[362] (p=0.049, logit=17.250)', '\" None\"[2290] (p=0.011, logit=15.750)']\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.462890625, logit=19.5, token_id=16147, metadata=None))), (47033, (2, PredictedToken(token=' Printer', prob=0.361328125, logit=19.25, token_id=47033, metadata=None))), (17367, (8, PredictedToken(token=' Factory', prob=0.003997802734375, logit=14.75, token_id=17367, metadata=None))), (423, (11, PredictedToken(token=' D', prob=0.0025787353515625, logit=14.3125, token_id=423, metadata=None))), (55405, (134, PredictedToken(token=' Orch', prob=3.24249267578125e-05, logit=9.9375, token_id=55405, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:43:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:43:59 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:43:59 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.859, logit=21.000)', '\" Sheep\"[84008] (p=0.038, logit=17.875)', '\" The\"[578] (p=0.038, logit=17.875)', '\" E\"[469] (p=0.014, logit=16.875)', '\" An\"[1556] (p=0.012, logit=16.750)']\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.672, logit=20.375)', '\" The\"[578] (p=0.133, logit=18.750)', '\" Viol\"[30555] (p=0.103, logit=18.500)', '\" U\"[549] (p=0.014, logit=16.500)', '\" UK\"[6560] (p=0.011, logit=16.250)']\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.671875, logit=20.375, token_id=60413, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.10302734375, logit=18.5, token_id=30555, metadata=None))), (36845, (20, PredictedToken(token=' Tiger', prob=0.0008392333984375, logit=13.6875, token_id=36845, metadata=None))), (17810, (63, PredictedToken(token=' Cat', prob=0.00012063980102539062, logit=11.75, token_id=17810, metadata=None))), (87035, (169, PredictedToken(token=' Onion', prob=2.2292137145996094e-05, logit=10.0625, token_id=87035, metadata=None)))])\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     int_prediction=['\" Cat\"[17810] (p=0.746, logit=20.500)', '\" CAT\"[45081] (p=0.061, logit=18.000)', '\" Viol\"[30555] (p=0.054, logit=17.875)', '\" The\"[578] (p=0.048, logit=17.750)', '\" Tiger\"[36845] (p=0.042, logit=17.625)']\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     int_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.74609375, logit=20.5, token_id=17810, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.05419921875, logit=17.875, token_id=30555, metadata=None))), (36845, (5, PredictedToken(token=' Tiger', prob=0.042236328125, logit=17.625, token_id=36845, metadata=None))), (60413, (27, PredictedToken(token=' Uk', prob=0.0003871917724609375, logit=12.9375, token_id=60413, metadata=None))), (87035, (174, PredictedToken(token=' Onion', prob=1.5974044799804688e-05, logit=9.75, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:00 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:00 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:44:00 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.699, logit=19.875)', '\" House\"[4783] (p=0.138, logit=18.250)', '\" The\"[578] (p=0.051, logit=17.250)', '\" Mirror\"[34954] (p=0.024, logit=16.500)', '\" A\"[362] (p=0.021, logit=16.375)']\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.590, logit=19.375)', '\" Tow\"[41493] (p=0.170, logit=18.125)', '\" The\"[578] (p=0.117, logit=17.750)', '\" A\"[362] (p=0.029, logit=16.375)', '\" Baseball\"[38258] (p=0.023, logit=16.125)']\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.58984375, logit=19.375, token_id=28131, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.169921875, logit=18.125, token_id=41493, metadata=None))), (38258, (5, PredictedToken(token=' Baseball', prob=0.02294921875, logit=16.125, token_id=38258, metadata=None))), (11896, (128, PredictedToken(token=' Library', prob=4.7206878662109375e-05, logit=9.9375, token_id=11896, metadata=None))), (19176, (520, PredictedToken(token=' Temple', prob=4.678964614868164e-06, logit=7.625, token_id=19176, metadata=None)))])\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.365, logit=18.250)', '\" Tow\"[41493] (p=0.173, logit=17.500)', '\" The\"[578] (p=0.134, logit=17.250)', '\" Baseball\"[38258] (p=0.119, logit=17.125)', '\" Temple\"[19176] (p=0.044, logit=16.125)']\n",
      "2025-09-15 09:44:01 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.365234375, logit=18.25, token_id=11896, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.1728515625, logit=17.5, token_id=41493, metadata=None))), (38258, (4, PredictedToken(token=' Baseball', prob=0.11865234375, logit=17.125, token_id=38258, metadata=None))), (19176, (5, PredictedToken(token=' Temple', prob=0.043701171875, logit=16.125, token_id=19176, metadata=None))), (28131, (6, PredictedToken(token=' Golf', prob=0.031982421875, logit=15.8125, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:01 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:44:02 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.570, logit=20.000)', '\" The\"[578] (p=0.211, logit=19.000)', '\" SHE\"[54695] (p=0.060, logit=17.750)', '\" Lion\"[33199] (p=0.053, logit=17.625)', '\" A\"[362] (p=0.037, logit=17.250)']\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.520, logit=19.250)', '\" The\"[578] (p=0.217, logit=18.375)', '\" Book\"[6017] (p=0.062, logit=17.125)', '\" Oven\"[87213] (p=0.033, logit=16.500)', '\" CO\"[7432] (p=0.019, logit=15.938)']\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.51953125, logit=19.25, token_id=27171, metadata=None))), (6017, (3, PredictedToken(token=' Book', prob=0.062255859375, logit=17.125, token_id=6017, metadata=None))), (87213, (4, PredictedToken(token=' Oven', prob=0.033203125, logit=16.5, token_id=87213, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0167236328125, logit=15.8125, token_id=356, metadata=None))), (34392, (62, PredictedToken(token=' Horse', prob=0.000270843505859375, logit=11.6875, token_id=34392, metadata=None))), (24941, (84, PredictedToken(token=' Bear', prob=0.00018596649169921875, logit=11.3125, token_id=24941, metadata=None)))])\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.723, logit=19.625)', '\" The\"[578] (p=0.111, logit=17.750)', '\" Horse\"[34392] (p=0.032, logit=16.500)', '\" Furniture\"[30339] (p=0.019, logit=16.000)', '\" A\"[362] (p=0.019, logit=16.000)']\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.72265625, logit=19.625, token_id=24941, metadata=None))), (34392, (3, PredictedToken(token=' Horse', prob=0.03173828125, logit=16.5, token_id=34392, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.00665283203125, logit=14.9375, token_id=356, metadata=None))), (87213, (12, PredictedToken(token=' Oven', prob=0.003143310546875, logit=14.1875, token_id=87213, metadata=None))), (6017, (58, PredictedToken(token=' Book', prob=0.00020122528076171875, logit=11.4375, token_id=6017, metadata=None))), (27171, (207, PredictedToken(token=' Coffee', prob=2.1219253540039062e-05, logit=9.1875, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:02 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:44:02 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:44:02 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.357, logit=17.000)', '\" Cherry\"[45805] (p=0.103, logit=15.750)', '\" The\"[578] (p=0.103, logit=15.750)', '\" Sun\"[8219] (p=0.070, logit=15.375)', '\" There\"[2684] (p=0.062, logit=15.250)']\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     clean_prediction=['\" Pe\"[5250] (p=0.680, logit=20.250)', '\" The\"[578] (p=0.221, logit=19.125)', '\" PE\"[22557] (p=0.014, logit=16.375)', '\" Iris\"[66821] (p=0.011, logit=16.125)', '\" It\"[1102] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     clean_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.6796875, logit=20.25, token_id=5250, metadata=None))), (66821, (4, PredictedToken(token=' Iris', prob=0.010986328125, logit=16.125, token_id=66821, metadata=None))), (8325, (52, PredictedToken(token=' Apple', prob=0.00018978118896484375, logit=12.0625, token_id=8325, metadata=None))), (22725, (74, PredictedToken(token=' Orange', prob=0.00011491775512695312, logit=11.5625, token_id=22725, metadata=None)))])\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     int_prediction=['\" Pe\"[5250] (p=0.695, logit=19.375)', '\" The\"[578] (p=0.121, logit=17.625)', '\" Apple\"[8325] (p=0.035, logit=16.375)', '\" Orange\"[22725] (p=0.031, logit=16.250)', '\" PE\"[22557] (p=0.009, logit=15.000)']\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     int_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.6953125, logit=19.375, token_id=5250, metadata=None))), (8325, (3, PredictedToken(token=' Apple', prob=0.03466796875, logit=16.375, token_id=8325, metadata=None))), (22725, (4, PredictedToken(token=' Orange', prob=0.030517578125, logit=16.25, token_id=22725, metadata=None))), (66821, (7, PredictedToken(token=' Iris', prob=0.006805419921875, logit=14.75, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:03 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:03 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.859, logit=21.250)', '\" Tow\"[41493] (p=0.091, logit=19.000)', '\" SOAP\"[64332] (p=0.018, logit=17.375)', '\" The\"[578] (p=0.010, logit=16.750)', '\" There\"[2684] (p=0.002, logit=15.312)']\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     clean_prediction=['\" Swe\"[37326] (p=0.586, logit=20.125)', '\" The\"[578] (p=0.216, logit=19.125)', '\" A\"[362] (p=0.115, logit=18.500)', '\" Hat\"[22050] (p=0.016, logit=16.500)', '\" It\"[1102] (p=0.007, logit=15.688)']\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     clean_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.5859375, logit=20.125, token_id=37326, metadata=None))), (22050, (4, PredictedToken(token=' Hat', prob=0.015625, logit=16.5, token_id=22050, metadata=None))), (445, (8, PredictedToken(token=' L', prob=0.00421142578125, logit=15.1875, token_id=445, metadata=None))), (26781, (63, PredictedToken(token=' Hair', prob=0.00012683868408203125, logit=11.6875, token_id=26781, metadata=None))), (12369, (580, PredictedToken(token=' Food', prob=3.382563591003418e-06, logit=8.0625, token_id=12369, metadata=None)))])\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.711, logit=20.250)', '\" The\"[578] (p=0.181, logit=18.875)', '\" Food\"[12369] (p=0.017, logit=16.500)', '\" A\"[362] (p=0.015, logit=16.375)', '\" Hair\"[26781] (p=0.012, logit=16.125)']\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.7109375, logit=20.25, token_id=445, metadata=None))), (12369, (3, PredictedToken(token=' Food', prob=0.0167236328125, logit=16.5, token_id=12369, metadata=None))), (26781, (5, PredictedToken(token=' Hair', prob=0.01153564453125, logit=16.125, token_id=26781, metadata=None))), (22050, (9, PredictedToken(token=' Hat', prob=0.004241943359375, logit=15.125, token_id=22050, metadata=None))), (37326, (41, PredictedToken(token=' Swe', prob=0.000270843505859375, logit=12.375, token_id=37326, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:04 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:04 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:44:04 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     patch_prediction=['\" Pine\"[42609] (p=0.680, logit=20.500)', '\" The\"[578] (p=0.134, logit=18.875)', '\" Peach\"[64695] (p=0.104, logit=18.625)', '\" There\"[2684] (p=0.018, logit=16.875)', '\" PE\"[22557] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.828, logit=20.625)', '\" The\"[578] (p=0.060, logit=18.000)', '\" Tul\"[43316] (p=0.028, logit=17.250)', '\" DA\"[25561] (p=0.019, logit=16.875)', '\" d\"[294] (p=0.010, logit=16.250)']\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.828125, logit=20.625, token_id=423, metadata=None))), (43316, (3, PredictedToken(token=' Tul', prob=0.0283203125, logit=17.25, token_id=43316, metadata=None))), (84409, (9, PredictedToken(token=' Plum', prob=0.002471923828125, logit=14.8125, token_id=84409, metadata=None))), (89077, (10, PredictedToken(token=' Strawberry', prob=0.00193023681640625, logit=14.5625, token_id=89077, metadata=None))), (45332, (30, PredictedToken(token=' Boat', prob=0.0003566741943359375, logit=12.875, token_id=45332, metadata=None))), (32498, (118, PredictedToken(token=' Mall', prob=3.528594970703125e-05, logit=10.5625, token_id=32498, metadata=None))), (49431, (294, PredictedToken(token=' Rabbit', prob=7.867813110351562e-06, logit=9.0625, token_id=49431, metadata=None)))])\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     int_prediction=['\" Strawberry\"[89077] (p=0.516, logit=19.000)', '\" Plum\"[84409] (p=0.275, logit=18.375)', '\" The\"[578] (p=0.062, logit=16.875)', '\" Boat\"[45332] (p=0.026, logit=16.000)', '\" STR\"[12428] (p=0.016, logit=15.500)']\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     int_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.515625, logit=19.0, token_id=89077, metadata=None))), (84409, (2, PredictedToken(token=' Plum', prob=0.275390625, logit=18.375, token_id=84409, metadata=None))), (45332, (4, PredictedToken(token=' Boat', prob=0.025634765625, logit=16.0, token_id=45332, metadata=None))), (32498, (17, PredictedToken(token=' Mall', prob=0.002532958984375, logit=13.6875, token_id=32498, metadata=None))), (43316, (24, PredictedToken(token=' Tul', prob=0.0009307861328125, logit=12.6875, token_id=43316, metadata=None))), (423, (33, PredictedToken(token=' D', prob=0.000530242919921875, logit=12.125, token_id=423, metadata=None))), (49431, (108, PredictedToken(token=' Rabbit', prob=0.00010442733764648438, logit=10.5, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:05 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:44:05 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-15 09:44:05 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:06 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.805, logit=20.000)', '\" The\"[578] (p=0.084, logit=17.750)', '\" Mall\"[32498] (p=0.024, logit=16.500)', '\" A\"[362] (p=0.019, logit=16.250)', '\" H\"[473] (p=0.008, logit=15.438)']\n",
      "2025-09-15 09:44:06 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:06 src.selection.optimization INFO     clean_prediction=['\" Jeans\"[82507] (p=0.711, logit=20.250)', '\" The\"[578] (p=0.124, logit=18.500)', '\" JE\"[71430] (p=0.085, logit=18.125)', '\" Hat\"[22050] (p=0.011, logit=16.125)', '\" A\"[362] (p=0.006, logit=15.500)']\n",
      "2025-09-15 09:44:06 src.selection.optimization INFO     clean_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.7109375, logit=20.25, token_id=82507, metadata=None))), (22050, (4, PredictedToken(token=' Hat', prob=0.011474609375, logit=16.125, token_id=22050, metadata=None))), (4923, (11, PredictedToken(token=' Sk', prob=0.00176239013671875, logit=14.25, token_id=4923, metadata=None))), (1630, (98, PredictedToken(token=' X', prob=6.437301635742188e-05, logit=10.9375, token_id=1630, metadata=None))), (11896, (242, PredictedToken(token=' Library', prob=1.52587890625e-05, logit=9.5, token_id=11896, metadata=None))), (38571, (1541, PredictedToken(token=' Theater', prob=9.164214134216309e-07, logit=6.6875, token_id=38571, metadata=None)))])\n",
      "2025-09-15 09:44:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.605, logit=19.875)', '\" The\"[578] (p=0.197, logit=18.750)', '\" X\"[1630] (p=0.082, logit=17.875)', '\" THE\"[3247] (p=0.016, logit=16.250)', '\" Library\"[11896] (p=0.012, logit=15.938)']\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.60546875, logit=19.875, token_id=38571, metadata=None))), (1630, (3, PredictedToken(token=' X', prob=0.08203125, logit=17.875, token_id=1630, metadata=None))), (11896, (5, PredictedToken(token=' Library', prob=0.0118408203125, logit=15.9375, token_id=11896, metadata=None))), (4923, (43, PredictedToken(token=' Sk', prob=0.0002956390380859375, logit=12.25, token_id=4923, metadata=None))), (82507, (60, PredictedToken(token=' Jeans', prob=0.00019168853759765625, logit=11.8125, token_id=82507, metadata=None))), (22050, (63, PredictedToken(token=' Hat', prob=0.00018024444580078125, logit=11.75, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:07 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.859, logit=20.250)', '\" BE\"[7354] (p=0.038, logit=17.125)', '\" The\"[578] (p=0.038, logit=17.125)', '\" Tiger\"[36845] (p=0.018, logit=16.375)', '\" There\"[2684] (p=0.005, logit=15.188)']\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.824, logit=20.000)', '\" The\"[578] (p=0.087, logit=17.750)', '\" Ottoman\"[70110] (p=0.022, logit=16.375)', '\" A\"[362] (p=0.009, logit=15.438)', '\" W\"[468] (p=0.008, logit=15.312)']\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.82421875, logit=20.0, token_id=27738, metadata=None))), (70110, (3, PredictedToken(token=' Ottoman', prob=0.02197265625, logit=16.375, token_id=70110, metadata=None))), (48035, (17, PredictedToken(token=' Gir', prob=0.000850677490234375, logit=13.125, token_id=48035, metadata=None))), (49431, (39, PredictedToken(token=' Rabbit', prob=0.0002155303955078125, logit=11.75, token_id=49431, metadata=None))), (71264, (438, PredictedToken(token=' Daisy', prob=4.470348358154297e-06, logit=7.875, token_id=71264, metadata=None)))])\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.824, logit=19.375)', '\" The\"[578] (p=0.053, logit=16.625)', '\" Gir\"[48035] (p=0.025, logit=15.875)', '\" R\"[432] (p=0.009, logit=14.812)', '\" rabbit\"[39824] (p=0.007, logit=14.625)']\n",
      "2025-09-15 09:44:07 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.82421875, logit=19.375, token_id=49431, metadata=None))), (48035, (3, PredictedToken(token=' Gir', prob=0.02490234375, logit=15.875, token_id=48035, metadata=None))), (71264, (6, PredictedToken(token=' Daisy', prob=0.00592041015625, logit=14.4375, token_id=71264, metadata=None))), (27738, (8, PredictedToken(token=' Ward', prob=0.00555419921875, logit=14.375, token_id=27738, metadata=None))), (70110, (17, PredictedToken(token=' Ottoman', prob=0.0016937255859375, logit=13.1875, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:07 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:08 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     patch_prediction=['\" Sh\"[1443] (p=0.707, logit=20.125)', '\" L\"[445] (p=0.123, logit=18.375)', '\" The\"[578] (p=0.051, logit=17.500)', '\" SH\"[6570] (p=0.024, logit=16.750)', '\" Shower\"[48471] (p=0.017, logit=16.375)']\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.672, logit=19.375)', '\" Hick\"[79028] (p=0.193, logit=18.125)', '\" The\"[578] (p=0.043, logit=16.625)', '\" There\"[2684] (p=0.019, logit=15.812)', '\" None\"[2290] (p=0.008, logit=14.938)']\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.671875, logit=19.375, token_id=44570, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.193359375, logit=18.125, token_id=79028, metadata=None))), (47589, (10, PredictedToken(token=' Basketball', prob=0.00201416015625, logit=13.5625, token_id=47589, metadata=None))), (18654, (27, PredictedToken(token=' Micro', prob=0.000652313232421875, logit=12.4375, token_id=18654, metadata=None))), (41493, (34, PredictedToken(token=' Tow', prob=0.000507354736328125, logit=12.1875, token_id=41493, metadata=None))), (61948, (122, PredictedToken(token=' Sofa', prob=5.7220458984375e-05, logit=10.0, token_id=61948, metadata=None))), (74968, (343, PredictedToken(token=' Razor', prob=1.055002212524414e-05, logit=8.3125, token_id=74968, metadata=None)))])\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.516, logit=18.500)', '\" Razor\"[74968] (p=0.190, logit=17.500)', '\" Hick\"[79028] (p=0.115, logit=17.000)', '\" The\"[578] (p=0.048, logit=16.125)', '\" None\"[2290] (p=0.014, logit=14.875)']\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.515625, logit=18.5, token_id=41493, metadata=None))), (74968, (2, PredictedToken(token=' Razor', prob=0.1904296875, logit=17.5, token_id=74968, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.115234375, logit=17.0, token_id=79028, metadata=None))), (18654, (7, PredictedToken(token=' Micro', prob=0.01141357421875, logit=14.6875, token_id=18654, metadata=None))), (44570, (8, PredictedToken(token=' Maple', prob=0.01141357421875, logit=14.6875, token_id=44570, metadata=None))), (47589, (9, PredictedToken(token=' Basketball', prob=0.00946044921875, logit=14.5, token_id=47589, metadata=None))), (61948, (38, PredictedToken(token=' Sofa', prob=0.0004711151123046875, logit=11.5, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:08 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:08 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:08 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.820, logit=21.375)', '\" The\"[578] (p=0.111, logit=19.375)', '\" Har\"[5340] (p=0.017, logit=17.500)', '\" P\"[393] (p=0.008, logit=16.750)', '\" It\"[1102] (p=0.006, logit=16.375)']\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     clean_prediction=['\" Ch\"[921] (p=0.855, logit=20.625)', '\" The\"[578] (p=0.070, logit=18.125)', '\" Tiger\"[36845] (p=0.020, logit=16.875)', '\" CH\"[6969] (p=0.006, logit=15.625)', '\" A\"[362] (p=0.005, logit=15.562)']\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     clean_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.85546875, logit=20.625, token_id=921, metadata=None))), (36845, (3, PredictedToken(token=' Tiger', prob=0.02001953125, logit=16.875, token_id=36845, metadata=None))), (8219, (7, PredictedToken(token=' Sun', prob=0.0023956298828125, logit=14.75, token_id=8219, metadata=None))), (11683, (23, PredictedToken(token=' Acc', prob=0.000644683837890625, logit=13.4375, token_id=11683, metadata=None))), (68027, (39, PredictedToken(token=' Sax', prob=0.0002689361572265625, logit=12.5625, token_id=68027, metadata=None)))])\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     int_prediction=['\" Acc\"[11683] (p=0.467, logit=19.375)', '\" Sax\"[68027] (p=0.320, logit=19.000)', '\" The\"[578] (p=0.104, logit=17.875)', '\" An\"[1556] (p=0.018, logit=16.125)', '\" It\"[1102] (p=0.011, logit=15.625)']\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     int_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.466796875, logit=19.375, token_id=11683, metadata=None))), (68027, (2, PredictedToken(token=' Sax', prob=0.3203125, logit=19.0, token_id=68027, metadata=None))), (8219, (24, PredictedToken(token=' Sun', prob=0.00061798095703125, logit=12.75, token_id=8219, metadata=None))), (36845, (40, PredictedToken(token=' Tiger', prob=0.0003108978271484375, logit=12.0625, token_id=36845, metadata=None))), (921, (230, PredictedToken(token=' Ch', prob=1.8715858459472656e-05, logit=9.25, token_id=921, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:09 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:09 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:44:09 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     patch_prediction=['\" Van\"[13000] (p=0.789, logit=21.125)', '\" The\"[578] (p=0.121, logit=19.250)', '\" VAN\"[97753] (p=0.027, logit=17.750)', '\" A\"[362] (p=0.016, logit=17.250)', '\" Car\"[3341] (p=0.005, logit=16.125)']\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.629, logit=20.125)', '\" The\"[578] (p=0.204, logit=19.000)', '\" Jasmine\"[82452] (p=0.035, logit=17.250)', '\" There\"[2684] (p=0.028, logit=17.000)', '\" D\"[423] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.62890625, logit=20.125, token_id=71264, metadata=None))), (82452, (3, PredictedToken(token=' Jasmine', prob=0.035400390625, logit=17.25, token_id=82452, metadata=None))), (1183, (9, PredictedToken(token=' Tr', prob=0.00616455078125, logit=15.5, token_id=1183, metadata=None))), (33711, (12, PredictedToken(token=' Suit', prob=0.0030975341796875, logit=14.8125, token_id=33711, metadata=None))), (9441, (58, PredictedToken(token=' Church', prob=0.00017547607421875, logit=11.9375, token_id=9441, metadata=None))), (27217, (157, PredictedToken(token=' Train', prob=3.6716461181640625e-05, logit=10.375, token_id=27217, metadata=None))), (47759, (1489, PredictedToken(token=' Guitar', prob=1.259148120880127e-06, logit=7.0, token_id=47759, metadata=None)))])\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.660, logit=20.500)', '\" Train\"[27217] (p=0.188, logit=19.250)', '\" The\"[578] (p=0.089, logit=18.500)', '\" There\"[2684] (p=0.009, logit=16.250)', '\" Church\"[9441] (p=0.008, logit=16.125)']\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.66015625, logit=20.5, token_id=1183, metadata=None))), (27217, (2, PredictedToken(token=' Train', prob=0.1884765625, logit=19.25, token_id=27217, metadata=None))), (9441, (5, PredictedToken(token=' Church', prob=0.00830078125, logit=16.125, token_id=9441, metadata=None))), (33711, (9, PredictedToken(token=' Suit', prob=0.0030517578125, logit=15.125, token_id=33711, metadata=None))), (82452, (18, PredictedToken(token=' Jasmine', prob=0.000530242919921875, logit=13.375, token_id=82452, metadata=None))), (47759, (19, PredictedToken(token=' Guitar', prob=0.000499725341796875, logit=13.3125, token_id=47759, metadata=None))), (71264, (48, PredictedToken(token=' Daisy', prob=0.000118255615234375, logit=11.875, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:10 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:10 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:10 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.781, logit=20.375)', '\" The\"[578] (p=0.093, logit=18.250)', '\" Iris\"[66821] (p=0.030, logit=17.125)', '\" OR\"[2794] (p=0.018, logit=16.625)', '\" An\"[1556] (p=0.010, logit=16.000)']\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     clean_prediction=['\" Guitar\"[47759] (p=0.641, logit=20.125)', '\" The\"[578] (p=0.208, logit=19.000)', '\" G\"[480] (p=0.060, logit=17.750)', '\" Viol\"[30555] (p=0.013, logit=16.250)', '\" A\"[362] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     clean_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.640625, logit=20.125, token_id=47759, metadata=None))), (30555, (4, PredictedToken(token=' Viol', prob=0.01324462890625, logit=16.25, token_id=30555, metadata=None))), (445, (24, PredictedToken(token=' L', prob=0.0007476806640625, logit=13.375, token_id=445, metadata=None))), (74574, (107, PredictedToken(token=' Violet', prob=6.532669067382812e-05, logit=10.9375, token_id=74574, metadata=None))), (5250, (298, PredictedToken(token=' Pe', prob=9.417533874511719e-06, logit=9.0, token_id=5250, metadata=None)))])\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.414, logit=19.375)', '\" Violet\"[74574] (p=0.414, logit=19.375)', '\" The\"[578] (p=0.063, logit=17.500)', '\" Pe\"[5250] (p=0.026, logit=16.625)', '\" V\"[650] (p=0.009, logit=15.500)']\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.4140625, logit=19.375, token_id=30555, metadata=None))), (74574, (2, PredictedToken(token=' Violet', prob=0.4140625, logit=19.375, token_id=74574, metadata=None))), (5250, (4, PredictedToken(token=' Pe', prob=0.0264892578125, logit=16.625, token_id=5250, metadata=None))), (445, (13, PredictedToken(token=' L', prob=0.0024566650390625, logit=14.25, token_id=445, metadata=None))), (47759, (26, PredictedToken(token=' Guitar', prob=0.000797271728515625, logit=13.125, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:11 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:11 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:44:11 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:12 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.688, logit=20.750)', '\" School\"[6150] (p=0.174, logit=19.375)', '\" The\"[578] (p=0.064, logit=18.375)', '\" A\"[362] (p=0.021, logit=17.250)', '\" There\"[2684] (p=0.013, logit=16.750)']\n",
      "2025-09-15 09:44:12 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:12 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.859, logit=20.500)', '\" The\"[578] (p=0.048, logit=17.625)', '\" Trump\"[3420] (p=0.038, logit=17.375)', '\" None\"[2290] (p=0.007, logit=15.625)', '\" TR\"[5091] (p=0.006, logit=15.562)']\n",
      "2025-09-15 09:44:12 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.859375, logit=20.5, token_id=40759, metadata=None))), (3420, (3, PredictedToken(token=' Trump', prob=0.03759765625, logit=17.375, token_id=3420, metadata=None))), (19176, (9, PredictedToken(token=' Temple', prob=0.0018768310546875, logit=14.375, token_id=19176, metadata=None))), (1901, (12, PredictedToken(token=' Z', prob=0.001373291015625, logit=14.0625, token_id=1901, metadata=None))), (98028, (19, PredictedToken(token=' Bamboo', prob=0.00057220458984375, logit=13.1875, token_id=98028, metadata=None))), (24423, (28, PredictedToken(token=' Monitor', prob=0.000347137451171875, logit=12.6875, token_id=24423, metadata=None))), (100031, (351, PredictedToken(token=' Mosque', prob=5.602836608886719e-06, logit=8.5625, token_id=100031, metadata=None)))])\n",
      "2025-09-15 09:44:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     int_prediction=['\" Mosque\"[100031] (p=0.363, logit=18.375)', '\" Trump\"[3420] (p=0.250, logit=18.000)', '\" Temple\"[19176] (p=0.092, logit=17.000)', '\" The\"[578] (p=0.063, logit=16.625)', '\" MOS\"[74174] (p=0.043, logit=16.250)']\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     int_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.36328125, logit=18.375, token_id=100031, metadata=None))), (3420, (2, PredictedToken(token=' Trump', prob=0.25, logit=18.0, token_id=3420, metadata=None))), (19176, (3, PredictedToken(token=' Temple', prob=0.091796875, logit=17.0, token_id=19176, metadata=None))), (24423, (9, PredictedToken(token=' Monitor', prob=0.0159912109375, logit=15.25, token_id=24423, metadata=None))), (1901, (21, PredictedToken(token=' Z', prob=0.00148773193359375, logit=12.875, token_id=1901, metadata=None))), (40759, (38, PredictedToken(token=' Harmon', prob=0.0007476806640625, logit=12.1875, token_id=40759, metadata=None))), (98028, (59, PredictedToken(token=' Bamboo', prob=0.0003757476806640625, logit=11.5, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:13 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.918, logit=21.625)', '\" The\"[578] (p=0.040, logit=18.500)', '\" Water\"[10164] (p=0.005, logit=16.500)', '\" Spr\"[15883] (p=0.005, logit=16.375)', '\" A\"[362] (p=0.004, logit=16.250)']\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     clean_prediction=['\" Rabbit\"[49431] (p=0.707, logit=19.750)', '\" The\"[578] (p=0.108, logit=17.875)', '\" Elephant\"[79189] (p=0.066, logit=17.375)', '\" R\"[432] (p=0.027, logit=16.500)', '\" There\"[2684] (p=0.012, logit=15.688)']\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     clean_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.70703125, logit=19.75, token_id=49431, metadata=None))), (79189, (3, PredictedToken(token=' Elephant', prob=0.06591796875, logit=17.375, token_id=79189, metadata=None))), (98028, (32, PredictedToken(token=' Bamboo', prob=0.000568389892578125, logit=12.625, token_id=98028, metadata=None))), (48665, (80, PredictedToken(token=' Raspberry', prob=0.0001354217529296875, logit=11.1875, token_id=48665, metadata=None))), (8325, (103, PredictedToken(token=' Apple', prob=9.298324584960938e-05, logit=10.8125, token_id=8325, metadata=None)))])\n",
      "2025-09-15 09:44:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.291, logit=18.125)', '\" Raspberry\"[48665] (p=0.199, logit=17.750)', '\" The\"[578] (p=0.137, logit=17.375)', '\" Apple\"[8325] (p=0.107, logit=17.125)', '\" R\"[432] (p=0.065, logit=16.625)']\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.291015625, logit=18.125, token_id=49431, metadata=None))), (48665, (2, PredictedToken(token=' Raspberry', prob=0.19921875, logit=17.75, token_id=48665, metadata=None))), (8325, (4, PredictedToken(token=' Apple', prob=0.10693359375, logit=17.125, token_id=8325, metadata=None))), (79189, (6, PredictedToken(token=' Elephant', prob=0.04443359375, logit=16.25, token_id=79189, metadata=None))), (98028, (11, PredictedToken(token=' Bamboo', prob=0.0068359375, logit=14.375, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:14 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.684, logit=20.750)', '\" The\"[578] (p=0.173, logit=19.375)', '\" Dish\"[49268] (p=0.064, logit=18.375)', '\" O\"[507] (p=0.016, logit=17.000)', '\" A\"[362] (p=0.009, logit=16.375)']\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     clean_prediction=['\" Har\"[5340] (p=0.605, logit=20.125)', '\" The\"[578] (p=0.196, logit=19.000)', '\" Uk\"[60413] (p=0.093, logit=18.250)', '\" H\"[473] (p=0.014, logit=16.375)', '\" HAR\"[87588] (p=0.011, logit=16.125)']\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     clean_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.60546875, logit=20.125, token_id=5340, metadata=None))), (60413, (3, PredictedToken(token=' Uk', prob=0.0927734375, logit=18.25, token_id=60413, metadata=None))), (8219, (25, PredictedToken(token=' Sun', prob=0.000911712646484375, logit=13.625, token_id=8219, metadata=None))), (98641, (34, PredictedToken(token=' Microwave', prob=0.000431060791015625, logit=12.875, token_id=98641, metadata=None))), (27171, (129, PredictedToken(token=' Coffee', prob=4.00543212890625e-05, logit=10.5, token_id=27171, metadata=None)))])\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.500, logit=19.875)', '\" Microwave\"[98641] (p=0.268, logit=19.250)', '\" The\"[578] (p=0.087, logit=18.125)', '\" Uk\"[60413] (p=0.060, logit=17.750)', '\" CO\"[7432] (p=0.010, logit=16.000)']\n",
      "2025-09-15 09:44:14 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.5, logit=19.875, token_id=27171, metadata=None))), (98641, (2, PredictedToken(token=' Microwave', prob=0.267578125, logit=19.25, token_id=98641, metadata=None))), (60413, (4, PredictedToken(token=' Uk', prob=0.0595703125, logit=17.75, token_id=60413, metadata=None))), (5340, (19, PredictedToken(token=' Har', prob=0.00131988525390625, logit=13.9375, token_id=5340, metadata=None))), (8219, (126, PredictedToken(token=' Sun', prob=3.981590270996094e-05, logit=10.4375, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:15 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     patch_prediction=['\" Calculator\"[37128] (p=0.504, logit=19.250)', '\" R\"[432] (p=0.239, logit=18.500)', '\" The\"[578] (p=0.078, logit=17.375)', '\" A\"[362] (p=0.042, logit=16.750)', '\" None\"[2290] (p=0.037, logit=16.625)']\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     clean_prediction=['\" Scar\"[30760] (p=0.504, logit=18.500)', '\" Jeans\"[82507] (p=0.163, logit=17.375)', '\" The\"[578] (p=0.127, logit=17.125)', '\" A\"[362] (p=0.053, logit=16.250)', '\" JE\"[71430] (p=0.027, logit=15.562)']\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     clean_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.50390625, logit=18.5, token_id=30760, metadata=None))), (82507, (2, PredictedToken(token=' Jeans', prob=0.1630859375, logit=17.375, token_id=82507, metadata=None))), (16488, (13, PredictedToken(token=' Bat', prob=0.00384521484375, logit=13.625, token_id=16488, metadata=None))), (63606, (27, PredictedToken(token=' Stap', prob=0.00124359130859375, logit=12.5, token_id=63606, metadata=None))), (58586, (98, PredictedToken(token=' Tape', prob=0.0001583099365234375, logit=10.4375, token_id=58586, metadata=None)))])\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.715, logit=19.625)', '\" Scar\"[30760] (p=0.085, logit=17.500)', '\" The\"[578] (p=0.066, logit=17.250)', '\" A\"[362] (p=0.031, logit=16.500)', '\" Bat\"[16488] (p=0.011, logit=15.438)']\n",
      "2025-09-15 09:44:15 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.71484375, logit=19.625, token_id=63606, metadata=None))), (30760, (2, PredictedToken(token=' Scar', prob=0.08544921875, logit=17.5, token_id=30760, metadata=None))), (16488, (5, PredictedToken(token=' Bat', prob=0.0108642578125, logit=15.4375, token_id=16488, metadata=None))), (58586, (8, PredictedToken(token=' Tape', prob=0.0079345703125, logit=15.125, token_id=58586, metadata=None))), (82507, (9, PredictedToken(token=' Jeans', prob=0.0045166015625, logit=14.5625, token_id=82507, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:16 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.480, logit=18.750)', '\" The\"[578] (p=0.177, logit=17.750)', '\" Van\"[13000] (p=0.107, logit=17.250)', '\" A\"[362] (p=0.045, logit=16.375)', '\" Stadium\"[23462] (p=0.035, logit=16.125)']\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     clean_prediction=['\" Sco\"[50159] (p=0.625, logit=19.625)', '\" Sub\"[3804] (p=0.123, logit=18.000)', '\" The\"[578] (p=0.096, logit=17.750)', '\" A\"[362] (p=0.045, logit=17.000)', '\" There\"[2684] (p=0.019, logit=16.125)']\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     clean_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.625, logit=19.625, token_id=50159, metadata=None))), (3804, (2, PredictedToken(token=' Sub', prob=0.12255859375, logit=18.0, token_id=3804, metadata=None))), (6150, (6, PredictedToken(token=' School', prob=0.00946044921875, logit=15.4375, token_id=6150, metadata=None))), (91263, (11, PredictedToken(token=' Binder', prob=0.00347900390625, logit=14.4375, token_id=91263, metadata=None))), (9441, (134, PredictedToken(token=' Church', prob=5.626678466796875e-05, logit=10.3125, token_id=9441, metadata=None)))])\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.467, logit=19.625)', '\" School\"[6150] (p=0.250, logit=19.000)', '\" Binder\"[91263] (p=0.092, logit=18.000)', '\" A\"[362] (p=0.049, logit=17.375)', '\" The\"[578] (p=0.043, logit=17.250)']\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.466796875, logit=19.625, token_id=9441, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.25, logit=19.0, token_id=6150, metadata=None))), (91263, (3, PredictedToken(token=' Binder', prob=0.091796875, logit=18.0, token_id=91263, metadata=None))), (50159, (8, PredictedToken(token=' Sco', prob=0.012451171875, logit=16.0, token_id=50159, metadata=None))), (3804, (9, PredictedToken(token=' Sub', prob=0.00909423828125, logit=15.6875, token_id=3804, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:16 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:16 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:44:16 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     patch_prediction=['\" Chain\"[29625] (p=0.594, logit=19.000)', '\" Pin\"[17929] (p=0.149, logit=17.625)', '\" The\"[578] (p=0.038, logit=16.250)', '\" PIN\"[28228] (p=0.028, logit=15.938)', '\" A\"[362] (p=0.028, logit=15.938)']\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.934, logit=21.250)', '\" The\"[578] (p=0.022, logit=17.500)', '\" Red\"[3816] (p=0.010, logit=16.750)', '\" MAP\"[28322] (p=0.007, logit=16.375)', '\" There\"[2684] (p=0.006, logit=16.250)']\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.93359375, logit=21.25, token_id=44570, metadata=None))), (3816, (3, PredictedToken(token=' Red', prob=0.0103759765625, logit=16.75, token_id=3816, metadata=None))), (18191, (21, PredictedToken(token=' Mouse', prob=0.0002593994140625, logit=13.0625, token_id=18191, metadata=None))), (13597, (24, PredictedToken(token=' Pen', prob=0.00024318695068359375, logit=13.0, token_id=13597, metadata=None))), (86460, (51, PredictedToken(token=' Necklace', prob=8.392333984375e-05, logit=11.9375, token_id=86460, metadata=None))), (22249, (92, PredictedToken(token=' Ring', prob=3.2901763916015625e-05, logit=11.0, token_id=22249, metadata=None))), (12369, (381, PredictedToken(token=' Food', prob=2.6971101760864258e-06, logit=8.5, token_id=12369, metadata=None)))])\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.641, logit=19.500)', '\" Pen\"[13597] (p=0.086, logit=17.500)', '\" The\"[578] (p=0.052, logit=17.000)', '\" A\"[362] (p=0.052, logit=17.000)', '\" There\"[2684] (p=0.022, logit=16.125)']\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.640625, logit=19.5, token_id=86460, metadata=None))), (13597, (2, PredictedToken(token=' Pen', prob=0.08642578125, logit=17.5, token_id=13597, metadata=None))), (44570, (9, PredictedToken(token=' Maple', prob=0.00628662109375, logit=14.875, token_id=44570, metadata=None))), (3816, (12, PredictedToken(token=' Red', prob=0.0037994384765625, logit=14.375, token_id=3816, metadata=None))), (22249, (14, PredictedToken(token=' Ring', prob=0.003570556640625, logit=14.3125, token_id=22249, metadata=None))), (18191, (15, PredictedToken(token=' Mouse', prob=0.0026092529296875, logit=14.0, token_id=18191, metadata=None))), (12369, (249, PredictedToken(token=' Food', prob=2.562999725341797e-05, logit=9.375, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:17 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:44:17 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-15 09:44:17 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.688, logit=20.000)', '\" The\"[578] (p=0.093, logit=18.000)', '\" A\"[362] (p=0.073, logit=17.750)', '\" Coat\"[68867] (p=0.030, logit=16.875)', '\" D\"[423] (p=0.021, logit=16.500)']\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.816, logit=21.000)', '\" The\"[578] (p=0.067, logit=18.500)', '\" An\"[1556] (p=0.041, logit=18.000)', '\" Bus\"[19111] (p=0.022, logit=17.375)', '\" There\"[2684] (p=0.007, logit=16.250)']\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.81640625, logit=21.0, token_id=6690, metadata=None))), (19111, (4, PredictedToken(token=' Bus', prob=0.021728515625, logit=17.375, token_id=19111, metadata=None))), (432, (7, PredictedToken(token=' R', prob=0.0040283203125, logit=15.6875, token_id=432, metadata=None))), (57225, (31, PredictedToken(token=' Laptop', prob=0.0003509521484375, logit=13.25, token_id=57225, metadata=None))), (30760, (40, PredictedToken(token=' Scar', prob=0.00017642974853515625, logit=12.5625, token_id=30760, metadata=None))), (59825, (42, PredictedToken(token=' Tie', prob=0.0001659393310546875, logit=12.5, token_id=59825, metadata=None)))])\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.727, logit=19.875)', '\" The\"[578] (p=0.098, logit=17.875)', '\" Bus\"[19111] (p=0.046, logit=17.125)', '\" R\"[432] (p=0.028, logit=16.625)', '\" A\"[362] (p=0.019, logit=16.250)']\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.7265625, logit=19.875, token_id=59825, metadata=None))), (19111, (3, PredictedToken(token=' Bus', prob=0.04638671875, logit=17.125, token_id=19111, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.0281982421875, logit=16.625, token_id=432, metadata=None))), (30760, (11, PredictedToken(token=' Scar', prob=0.0027923583984375, logit=14.3125, token_id=30760, metadata=None))), (6690, (22, PredictedToken(token=' Air', prob=0.00115966796875, logit=13.4375, token_id=6690, metadata=None))), (57225, (29, PredictedToken(token=' Laptop', prob=0.000621795654296875, logit=12.8125, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:44:18 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-15 09:44:18 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     patch_prediction=['\" Binder\"[91263] (p=0.766, logit=19.375)', '\" Paper\"[18343] (p=0.081, logit=17.125)', '\" The\"[578] (p=0.022, logit=15.812)', '\" None\"[2290] (p=0.019, logit=15.688)', '\" A\"[362] (p=0.011, logit=15.125)']\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.734, logit=19.500)', '\" Palm\"[33578] (p=0.077, logit=17.250)', '\" The\"[578] (p=0.077, logit=17.250)', '\" A\"[362] (p=0.011, logit=15.312)', '\" RED\"[26895] (p=0.010, logit=15.250)']\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.734375, logit=19.5, token_id=3816, metadata=None))), (33578, (3, PredictedToken(token=' Palm', prob=0.0771484375, logit=17.25, token_id=33578, metadata=None))), (36943, (6, PredictedToken(token=' Folder', prob=0.010498046875, logit=15.25, token_id=36943, metadata=None))), (57094, (13, PredictedToken(token=' Highlight', prob=0.0030059814453125, logit=14.0, token_id=57094, metadata=None)))])\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.436, logit=18.750)', '\" Folder\"[36943] (p=0.264, logit=18.250)', '\" Red\"[3816] (p=0.076, logit=17.000)', '\" The\"[578] (p=0.076, logit=17.000)', '\" A\"[362] (p=0.025, logit=15.875)']\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.435546875, logit=18.75, token_id=33578, metadata=None))), (36943, (2, PredictedToken(token=' Folder', prob=0.263671875, logit=18.25, token_id=36943, metadata=None))), (3816, (4, PredictedToken(token=' Red', prob=0.07568359375, logit=17.0, token_id=3816, metadata=None))), (57094, (9, PredictedToken(token=' Highlight', prob=0.007049560546875, logit=14.625, token_id=57094, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:19 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:19 src.selection.optimization DEBUG    torch.Size([7, 32])\n",
      "2025-09-15 09:44:19 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.559, logit=19.250)', '\" Sun\"[8219] (p=0.159, logit=18.000)', '\" The\"[578] (p=0.125, logit=17.750)', '\" Bamboo\"[98028] (p=0.046, logit=16.750)', '\" There\"[2684] (p=0.018, logit=15.812)']\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.648, logit=19.375)', '\" The\"[578] (p=0.145, logit=17.875)', '\" B\"[426] (p=0.053, logit=16.875)', '\" Hick\"[79028] (p=0.047, logit=16.750)', '\" There\"[2684] (p=0.015, logit=15.625)']\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.6484375, logit=19.375, token_id=88088, metadata=None))), (79028, (4, PredictedToken(token=' Hick', prob=0.046875, logit=16.75, token_id=79028, metadata=None))), (16344, (9, PredictedToken(token=' Rose', prob=0.0038604736328125, logit=14.25, token_id=16344, metadata=None))), (71264, (15, PredictedToken(token=' Daisy', prob=0.001708984375, logit=13.4375, token_id=71264, metadata=None))), (47589, (96, PredictedToken(token=' Basketball', prob=0.0001163482666015625, logit=10.75, token_id=47589, metadata=None))), (30173, (126, PredictedToken(token=' Speaker', prob=7.05718994140625e-05, logit=10.25, token_id=30173, metadata=None))), (29318, (245, PredictedToken(token=' Dress', prob=2.4437904357910156e-05, logit=9.1875, token_id=29318, metadata=None)))])\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.664, logit=19.250)', '\" The\"[578] (p=0.115, logit=17.500)', '\" Daisy\"[71264] (p=0.037, logit=16.375)', '\" Birch\"[88088] (p=0.024, logit=15.938)', '\" A\"[362] (p=0.021, logit=15.812)']\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.6640625, logit=19.25, token_id=16344, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.037353515625, logit=16.375, token_id=71264, metadata=None))), (88088, (4, PredictedToken(token=' Birch', prob=0.024169921875, logit=15.9375, token_id=88088, metadata=None))), (79028, (8, PredictedToken(token=' Hick', prob=0.00787353515625, logit=14.8125, token_id=79028, metadata=None))), (29318, (27, PredictedToken(token=' Dress', prob=0.0012054443359375, logit=12.9375, token_id=29318, metadata=None))), (30173, (104, PredictedToken(token=' Speaker', prob=0.00011205673217773438, logit=10.5625, token_id=30173, metadata=None))), (47589, (111, PredictedToken(token=' Basketball', prob=0.00010538101196289062, logit=10.5, token_id=47589, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:20 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:20 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-15 09:44:20 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.695, logit=19.375)', '\" The\"[578] (p=0.107, logit=17.500)', '\" Yoga\"[38673] (p=0.073, logit=17.125)', '\" A\"[362] (p=0.024, logit=16.000)', '\" None\"[2290] (p=0.015, logit=15.562)']\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     clean_prediction=['\" Mixer\"[72392] (p=0.605, logit=19.875)', '\" The\"[578] (p=0.197, logit=18.750)', '\" K\"[735] (p=0.056, logit=17.500)', '\" A\"[362] (p=0.056, logit=17.500)', '\" MIX\"[81309] (p=0.016, logit=16.250)']\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     clean_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.60546875, logit=19.875, token_id=72392, metadata=None))), (735, (4, PredictedToken(token=' K', prob=0.056396484375, logit=17.5, token_id=735, metadata=None))), (41342, (10, PredictedToken(token=' Hockey', prob=0.0026397705078125, logit=14.4375, token_id=41342, metadata=None))), (17810, (25, PredictedToken(token=' Cat', prob=0.00075531005859375, logit=13.1875, token_id=17810, metadata=None))), (72683, (195, PredictedToken(token=' Boxing', prob=2.1457672119140625e-05, logit=9.625, token_id=72683, metadata=None)))])\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.734, logit=19.750)', '\" The\"[578] (p=0.113, logit=17.875)', '\" A\"[362] (p=0.047, logit=17.000)', '\" K\"[735] (p=0.020, logit=16.125)', '\" None\"[2290] (p=0.017, logit=16.000)']\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.734375, logit=19.75, token_id=41342, metadata=None))), (735, (4, PredictedToken(token=' K', prob=0.0196533203125, logit=16.125, token_id=735, metadata=None))), (17810, (7, PredictedToken(token=' Cat', prob=0.0059814453125, logit=14.9375, token_id=17810, metadata=None))), (72683, (10, PredictedToken(token=' Boxing', prob=0.0024871826171875, logit=14.0625, token_id=72683, metadata=None))), (72392, (20, PredictedToken(token=' Mixer', prob=0.00110626220703125, logit=13.25, token_id=72392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:21 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:44:21 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.887, logit=21.375)', '\" The\"[578] (p=0.064, logit=18.750)', '\" Gir\"[48035] (p=0.011, logit=17.000)', '\" A\"[362] (p=0.009, logit=16.750)', '\" H\"[473] (p=0.007, logit=16.500)']\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     clean_prediction=['\" Speaker\"[30173] (p=0.645, logit=19.875)', '\" Project\"[5907] (p=0.162, logit=18.500)', '\" The\"[578] (p=0.099, logit=18.000)', '\" There\"[2684] (p=0.009, logit=15.625)', '\" A\"[362] (p=0.009, logit=15.562)']\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     clean_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.64453125, logit=19.875, token_id=30173, metadata=None))), (5907, (2, PredictedToken(token=' Project', prob=0.162109375, logit=18.5, token_id=5907, metadata=None))), (1183, (11, PredictedToken(token=' Tr', prob=0.0029754638671875, logit=14.5, token_id=1183, metadata=None))), (49431, (31, PredictedToken(token=' Rabbit', prob=0.00054931640625, logit=12.8125, token_id=49431, metadata=None))), (84008, (425, PredictedToken(token=' Sheep', prob=6.5267086029052734e-06, logit=8.375, token_id=84008, metadata=None)))])\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.447, logit=18.125)', '\" Sheep\"[84008] (p=0.211, logit=17.375)', '\" The\"[578] (p=0.128, logit=16.875)', '\" Tr\"[1183] (p=0.018, logit=14.938)', '\" There\"[2684] (p=0.017, logit=14.875)']\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.447265625, logit=18.125, token_id=49431, metadata=None))), (84008, (2, PredictedToken(token=' Sheep', prob=0.2109375, logit=17.375, token_id=84008, metadata=None))), (1183, (4, PredictedToken(token=' Tr', prob=0.0184326171875, logit=14.9375, token_id=1183, metadata=None))), (5907, (21, PredictedToken(token=' Project', prob=0.002349853515625, logit=12.875, token_id=5907, metadata=None))), (30173, (26, PredictedToken(token=' Speaker', prob=0.0015106201171875, logit=12.4375, token_id=30173, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:22 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:44:22 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.373, logit=19.250)', '\" Bus\"[19111] (p=0.291, logit=19.000)', '\" The\"[578] (p=0.177, logit=18.500)', '\" A\"[362] (p=0.039, logit=17.000)', '\" There\"[2684] (p=0.019, logit=16.250)']\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.586, logit=21.000)', '\" P\"[393] (p=0.314, logit=20.375)', '\" The\"[578] (p=0.042, logit=18.375)', '\" A\"[362] (p=0.016, logit=17.375)', '\" Pen\"[13597] (p=0.006, logit=16.375)']\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.5859375, logit=21.0, token_id=18343, metadata=None))), (393, (2, PredictedToken(token=' P', prob=0.314453125, logit=20.375, token_id=393, metadata=None))), (13000, (9, PredictedToken(token=' Van', prob=0.00136566162109375, logit=14.9375, token_id=13000, metadata=None))), (8868, (13, PredictedToken(token=' Blue', prob=0.000881195068359375, logit=14.5, token_id=8868, metadata=None))), (3341, (23, PredictedToken(token=' Car', prob=0.000324249267578125, logit=13.5, token_id=3341, metadata=None)))])\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.824, logit=21.375)', '\" Car\"[3341] (p=0.060, logit=18.750)', '\" The\"[578] (p=0.041, logit=18.375)', '\" VAN\"[97753] (p=0.022, logit=17.750)', '\" P\"[393] (p=0.013, logit=17.250)']\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.82421875, logit=21.375, token_id=13000, metadata=None))), (3341, (2, PredictedToken(token=' Car', prob=0.0595703125, logit=18.75, token_id=3341, metadata=None))), (393, (5, PredictedToken(token=' P', prob=0.0133056640625, logit=17.25, token_id=393, metadata=None))), (8868, (53, PredictedToken(token=' Blue', prob=7.43865966796875e-05, logit=12.0625, token_id=8868, metadata=None))), (18343, (76, PredictedToken(token=' Paper', prob=3.981590270996094e-05, logit=11.4375, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:23 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:23 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.801, logit=20.125)', '\" The\"[578] (p=0.084, logit=17.875)', '\" Orch\"[55405] (p=0.040, logit=17.125)', '\" C\"[356] (p=0.009, logit=15.688)', '\" There\"[2684] (p=0.008, logit=15.500)']\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.793, logit=20.000)', '\" The\"[578] (p=0.107, logit=18.000)', '\" Surf\"[65197] (p=0.024, logit=16.500)', '\" A\"[362] (p=0.010, logit=15.625)', '\" SUR\"[53083] (p=0.008, logit=15.375)']\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.79296875, logit=20.0, token_id=423, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.02392578125, logit=16.5, token_id=65197, metadata=None))), (5250, (73, PredictedToken(token=' Pe', prob=9.775161743164062e-05, logit=11.0, token_id=5250, metadata=None))), (81501, (80, PredictedToken(token=' Pendant', prob=8.630752563476562e-05, logit=10.875, token_id=81501, metadata=None))), (2947, (116, PredictedToken(token=' Mar', prob=4.6253204345703125e-05, logit=10.25, token_id=2947, metadata=None)))])\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.723, logit=19.000)', '\" The\"[578] (p=0.086, logit=16.875)', '\" MAR\"[38599] (p=0.034, logit=15.938)', '\" Surf\"[65197] (p=0.025, logit=15.625)', '\" Pe\"[5250] (p=0.022, logit=15.500)']\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.72265625, logit=19.0, token_id=2947, metadata=None))), (65197, (4, PredictedToken(token=' Surf', prob=0.024658203125, logit=15.625, token_id=65197, metadata=None))), (5250, (5, PredictedToken(token=' Pe', prob=0.0218505859375, logit=15.5, token_id=5250, metadata=None))), (81501, (9, PredictedToken(token=' Pendant', prob=0.004852294921875, logit=14.0, token_id=81501, metadata=None))), (423, (26, PredictedToken(token=' D', prob=0.0014801025390625, logit=12.8125, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:24 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     patch_prediction=['\" Bed\"[13394] (p=0.480, logit=19.250)', '\" Book\"[6017] (p=0.200, logit=18.375)', '\" The\"[578] (p=0.122, logit=17.875)', '\" BED\"[83364] (p=0.027, logit=16.375)', '\" A\"[362] (p=0.024, logit=16.250)']\n",
      "2025-09-15 09:44:24 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:25 src.selection.optimization INFO     clean_prediction=['\" Brace\"[70306] (p=0.680, logit=19.500)', '\" L\"[445] (p=0.104, logit=17.625)', '\" The\"[578] (p=0.081, logit=17.375)', '\" A\"[362] (p=0.017, logit=15.812)', '\" BR\"[19333] (p=0.016, logit=15.750)']\n",
      "2025-09-15 09:44:25 src.selection.optimization INFO     clean_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.6796875, logit=19.5, token_id=70306, metadata=None))), (445, (2, PredictedToken(token=' L', prob=0.10400390625, logit=17.625, token_id=445, metadata=None))), (70110, (9, PredictedToken(token=' Ottoman', prob=0.005523681640625, logit=14.6875, token_id=70110, metadata=None))), (41342, (12, PredictedToken(token=' Hockey', prob=0.0029449462890625, logit=14.0625, token_id=41342, metadata=None))), (27171, (41, PredictedToken(token=' Coffee', prob=0.0004253387451171875, logit=12.125, token_id=27171, metadata=None)))])\n",
      "2025-09-15 09:44:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:25 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.605, logit=19.000)', '\" Hockey\"[41342] (p=0.119, logit=17.375)', '\" The\"[578] (p=0.082, logit=17.000)', '\" CO\"[7432] (p=0.044, logit=16.375)', '\" Coff\"[76233] (p=0.025, logit=15.812)']\n",
      "2025-09-15 09:44:25 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.60546875, logit=19.0, token_id=27171, metadata=None))), (41342, (2, PredictedToken(token=' Hockey', prob=0.119140625, logit=17.375, token_id=41342, metadata=None))), (70110, (8, PredictedToken(token=' Ottoman', prob=0.0067138671875, logit=14.5, token_id=70110, metadata=None))), (445, (9, PredictedToken(token=' L', prob=0.006317138671875, logit=14.4375, token_id=445, metadata=None))), (70306, (14, PredictedToken(token=' Brace', prob=0.0038299560546875, logit=13.9375, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:25 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-15 09:44:25 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.727, logit=20.000)', '\" Pine\"[42609] (p=0.098, logit=18.000)', '\" The\"[578] (p=0.087, logit=17.875)', '\" RED\"[26895] (p=0.025, logit=16.625)', '\" There\"[2684] (p=0.009, logit=15.562)']\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.582, logit=19.500)', '\" Soap\"[61731] (p=0.273, logit=18.750)', '\" The\"[578] (p=0.029, logit=16.500)', '\" SOAP\"[64332] (p=0.022, logit=16.250)', '\" A\"[362] (p=0.016, logit=15.875)']\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.58203125, logit=19.5, token_id=23262, metadata=None))), (61731, (2, PredictedToken(token=' Soap', prob=0.2734375, logit=18.75, token_id=61731, metadata=None))), (33578, (7, PredictedToken(token=' Palm', prob=0.005706787109375, logit=14.875, token_id=33578, metadata=None))), (5250, (17, PredictedToken(token=' Pe', prob=0.00127410888671875, logit=13.375, token_id=5250, metadata=None))), (57748, (58, PredictedToken(token=' Cedar', prob=0.00022125244140625, logit=11.625, token_id=57748, metadata=None)))])\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.562, logit=18.875)', '\" Comb\"[23262] (p=0.207, logit=17.875)', '\" Cedar\"[57748] (p=0.046, logit=16.375)', '\" The\"[578] (p=0.025, logit=15.750)', '\" None\"[2290] (p=0.018, logit=15.438)']\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.5625, logit=18.875, token_id=33578, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.20703125, logit=17.875, token_id=23262, metadata=None))), (57748, (3, PredictedToken(token=' Cedar', prob=0.04638671875, logit=16.375, token_id=57748, metadata=None))), (61731, (7, PredictedToken(token=' Soap', prob=0.01806640625, logit=15.4375, token_id=61731, metadata=None))), (5250, (9, PredictedToken(token=' Pe', prob=0.008544921875, logit=14.6875, token_id=5250, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:26 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     patch_prediction=['\" Scar\"[30760] (p=0.609, logit=19.625)', '\" The\"[578] (p=0.175, logit=18.375)', '\" Dress\"[29318] (p=0.083, logit=17.625)', '\" A\"[362] (p=0.030, logit=16.625)', '\" There\"[2684] (p=0.011, logit=15.625)']\n",
      "2025-09-15 09:44:26 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.504, logit=19.500)', '\" Sk\"[4923] (p=0.210, logit=18.625)', '\" The\"[578] (p=0.127, logit=18.125)', '\" Suit\"[33711] (p=0.036, logit=16.875)', '\" A\"[362] (p=0.022, logit=16.375)']\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.50390625, logit=19.5, token_id=23462, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.2099609375, logit=18.625, token_id=4923, metadata=None))), (33711, (4, PredictedToken(token=' Suit', prob=0.036376953125, logit=16.875, token_id=33711, metadata=None))), (84008, (9, PredictedToken(token=' Sheep', prob=0.005584716796875, logit=15.0, token_id=84008, metadata=None)))])\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.809, logit=20.125)', '\" The\"[578] (p=0.052, logit=17.375)', '\" Sk\"[4923] (p=0.035, logit=17.000)', '\" A\"[362] (p=0.021, logit=16.500)', '\" SU\"[15857] (p=0.013, logit=16.000)']\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.80859375, logit=20.125, token_id=33711, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.035400390625, logit=17.0, token_id=4923, metadata=None))), (23462, (15, PredictedToken(token=' Stadium', prob=0.00165557861328125, logit=13.9375, token_id=23462, metadata=None))), (84008, (48, PredictedToken(token=' Sheep', prob=0.0001983642578125, logit=11.8125, token_id=84008, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:27 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.852, logit=20.000)', '\" The\"[578] (p=0.037, logit=16.875)', '\" Cedar\"[57748] (p=0.026, logit=16.500)', '\" Sun\"[8219] (p=0.015, logit=15.938)', '\" There\"[2684] (p=0.011, logit=15.688)']\n",
      "2025-09-15 09:44:27 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.742, logit=19.875)', '\" Soap\"[61731] (p=0.129, logit=18.125)', '\" The\"[578] (p=0.020, logit=16.250)', '\" TO\"[5257] (p=0.017, logit=16.125)', '\" Birch\"[88088] (p=0.015, logit=16.000)']\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.7421875, logit=19.875, token_id=82994, metadata=None))), (61731, (2, PredictedToken(token=' Soap', prob=0.12890625, logit=18.125, token_id=61731, metadata=None))), (88088, (5, PredictedToken(token=' Birch', prob=0.01544189453125, logit=16.0, token_id=88088, metadata=None))), (18787, (15, PredictedToken(token=' Oak', prob=0.00162506103515625, logit=13.75, token_id=18787, metadata=None))), (71264, (42, PredictedToken(token=' Daisy', prob=0.00028228759765625, logit=12.0, token_id=71264, metadata=None)))])\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     int_prediction=['\" Oak\"[18787] (p=0.719, logit=20.000)', '\" Birch\"[88088] (p=0.086, logit=17.875)', '\" Soap\"[61731] (p=0.052, logit=17.375)', '\" Toilet\"[82994] (p=0.046, logit=17.250)', '\" The\"[578] (p=0.025, logit=16.625)']\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     int_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.71875, logit=20.0, token_id=18787, metadata=None))), (88088, (2, PredictedToken(token=' Birch', prob=0.0859375, logit=17.875, token_id=88088, metadata=None))), (61731, (3, PredictedToken(token=' Soap', prob=0.052001953125, logit=17.375, token_id=61731, metadata=None))), (82994, (4, PredictedToken(token=' Toilet', prob=0.0458984375, logit=17.25, token_id=82994, metadata=None))), (71264, (6, PredictedToken(token=' Daisy', prob=0.01239013671875, logit=15.9375, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:28 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     patch_prediction=['\" Suit\"[33711] (p=0.730, logit=20.500)', '\" The\"[578] (p=0.087, logit=18.375)', '\" A\"[362] (p=0.068, logit=18.125)', '\" Tie\"[59825] (p=0.053, logit=17.875)', '\" S\"[328] (p=0.008, logit=16.000)']\n",
      "2025-09-15 09:44:28 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.848, logit=19.875)', '\" Sc\"[2522] (p=0.048, logit=17.000)', '\" The\"[578] (p=0.016, logit=15.875)', '\" None\"[2290] (p=0.012, logit=15.625)', '\" Gloves\"[68554] (p=0.006, logit=14.938)']\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.84765625, logit=19.875, token_id=18343, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.0478515625, logit=17.0, token_id=2522, metadata=None))), (68554, (5, PredictedToken(token=' Gloves', prob=0.006072998046875, logit=14.9375, token_id=68554, metadata=None))), (52882, (7, PredictedToken(token=' Pepper', prob=0.003692626953125, logit=14.4375, token_id=52882, metadata=None))), (91782, (12, PredictedToken(token=' Shorts', prob=0.001739501953125, logit=13.6875, token_id=91782, metadata=None)))])\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     int_prediction=['\" Sc\"[2522] (p=0.379, logit=18.375)', '\" Gloves\"[68554] (p=0.230, logit=17.875)', '\" Shorts\"[91782] (p=0.158, logit=17.500)', '\" None\"[2290] (p=0.051, logit=16.375)', '\" The\"[578] (p=0.020, logit=15.438)']\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     int_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.37890625, logit=18.375, token_id=2522, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.23046875, logit=17.875, token_id=68554, metadata=None))), (91782, (3, PredictedToken(token=' Shorts', prob=0.158203125, logit=17.5, token_id=91782, metadata=None))), (18343, (12, PredictedToken(token=' Paper', prob=0.00396728515625, logit=13.8125, token_id=18343, metadata=None))), (52882, (31, PredictedToken(token=' Pepper', prob=0.000827789306640625, logit=12.25, token_id=52882, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:29 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:29 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.824, logit=21.125)', '\" The\"[578] (p=0.099, logit=19.000)', '\" WATER\"[76347] (p=0.022, logit=17.500)', '\" Pine\"[42609] (p=0.013, logit=17.000)', '\" water\"[3090] (p=0.006, logit=16.250)']\n",
      "2025-09-15 09:44:29 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.809, logit=20.875)', '\" The\"[578] (p=0.097, logit=18.750)', '\" A\"[362] (p=0.028, logit=17.500)', '\" SH\"[6570] (p=0.021, logit=17.250)', '\" Scar\"[30760] (p=0.008, logit=16.250)']\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.80859375, logit=20.875, token_id=55807, metadata=None))), (30760, (5, PredictedToken(token=' Scar', prob=0.0079345703125, logit=16.25, token_id=30760, metadata=None))), (26781, (8, PredictedToken(token=' Hair', prob=0.0019989013671875, logit=14.875, token_id=26781, metadata=None))), (8868, (9, PredictedToken(token=' Blue', prob=0.0016632080078125, logit=14.6875, token_id=8868, metadata=None))), (76924, (21, PredictedToken(token=' Banana', prob=0.000537872314453125, logit=13.5625, token_id=76924, metadata=None))), (6771, (33, PredictedToken(token=' Table', prob=0.000270843505859375, logit=12.875, token_id=6771, metadata=None))), (74574, (48, PredictedToken(token=' Violet', prob=0.00017547607421875, logit=12.4375, token_id=74574, metadata=None)))])\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.645, logit=19.500)', '\" Violet\"[74574] (p=0.163, logit=18.125)', '\" The\"[578] (p=0.060, logit=17.125)', '\" BLUE\"[56992] (p=0.025, logit=16.250)', '\" Scar\"[30760] (p=0.025, logit=16.250)']\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.64453125, logit=19.5, token_id=8868, metadata=None))), (74574, (2, PredictedToken(token=' Violet', prob=0.1630859375, logit=18.125, token_id=74574, metadata=None))), (30760, (4, PredictedToken(token=' Scar', prob=0.0250244140625, logit=16.25, token_id=30760, metadata=None))), (76924, (6, PredictedToken(token=' Banana', prob=0.018310546875, logit=15.9375, token_id=76924, metadata=None))), (55807, (14, PredictedToken(token=' Shirt', prob=0.00150299072265625, logit=13.4375, token_id=55807, metadata=None))), (26781, (53, PredictedToken(token=' Hair', prob=0.00022983551025390625, logit=11.5625, token_id=26781, metadata=None))), (6771, (107, PredictedToken(token=' Table', prob=7.009506225585938e-05, logit=10.375, token_id=6771, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:30 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.652, logit=20.125)', '\" Rice\"[30616] (p=0.212, logit=19.000)', '\" The\"[578] (p=0.053, logit=17.625)', '\" AIR\"[46994] (p=0.010, logit=15.938)', '\" Spr\"[15883] (p=0.008, logit=15.688)']\n",
      "2025-09-15 09:44:30 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.785, logit=20.000)', '\" Tow\"[41493] (p=0.083, logit=17.750)', '\" The\"[578] (p=0.044, logit=17.125)', '\" TO\"[5257] (p=0.016, logit=16.125)', '\" There\"[2684] (p=0.011, logit=15.750)']\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.78515625, logit=20.0, token_id=82994, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.08251953125, logit=17.75, token_id=41493, metadata=None))), (735, (8, PredictedToken(token=' K', prob=0.003204345703125, logit=14.5, token_id=735, metadata=None))), (65329, (22, PredictedToken(token=' Elm', prob=0.000713348388671875, logit=13.0, token_id=65329, metadata=None))), (39247, (83, PredictedToken(token=' Slow', prob=0.000102996826171875, logit=11.0625, token_id=39247, metadata=None)))])\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.617, logit=19.500)', '\" K\"[735] (p=0.177, logit=18.250)', '\" Slow\"[39247] (p=0.107, logit=17.750)', '\" None\"[2290] (p=0.021, logit=16.125)', '\" The\"[578] (p=0.019, logit=16.000)']\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.6171875, logit=19.5, token_id=41493, metadata=None))), (735, (2, PredictedToken(token=' K', prob=0.1767578125, logit=18.25, token_id=735, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.10693359375, logit=17.75, token_id=39247, metadata=None))), (82994, (6, PredictedToken(token=' Toilet', prob=0.01129150390625, logit=15.5, token_id=82994, metadata=None))), (65329, (21, PredictedToken(token=' Elm', prob=0.000720977783203125, logit=12.75, token_id=65329, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:31 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.902, logit=21.625)', '\" The\"[578] (p=0.045, logit=18.625)', '\" Caul\"[90538] (p=0.016, logit=17.625)', '\" P\"[393] (p=0.007, logit=16.750)', '\" There\"[2684] (p=0.004, logit=16.250)']\n",
      "2025-09-15 09:44:31 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.641, logit=20.250)', '\" R\"[432] (p=0.143, logit=18.750)', '\" The\"[578] (p=0.052, logit=17.750)', '\" A\"[362] (p=0.052, logit=17.750)', '\" F\"[435] (p=0.036, logit=17.375)']\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.640625, logit=20.25, token_id=36943, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.142578125, logit=18.75, token_id=432, metadata=None))), (6914, (7, PredictedToken(token=' Let', prob=0.007110595703125, logit=15.75, token_id=6914, metadata=None))), (14642, (10, PredictedToken(token=' Phone', prob=0.0027923583984375, logit=14.8125, token_id=14642, metadata=None))), (47643, (41, PredictedToken(token=' Cel', prob=0.00031280517578125, logit=12.625, token_id=47643, metadata=None)))])\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.633, logit=19.625)', '\" Let\"[6914] (p=0.141, logit=18.125)', '\" None\"[2290] (p=0.046, logit=17.000)', '\" The\"[578] (p=0.040, logit=16.875)', '\" R\"[432] (p=0.036, logit=16.750)']\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.6328125, logit=19.625, token_id=47643, metadata=None))), (6914, (2, PredictedToken(token=' Let', prob=0.140625, logit=18.125, token_id=6914, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.03564453125, logit=16.75, token_id=432, metadata=None))), (36943, (7, PredictedToken(token=' Folder', prob=0.00848388671875, logit=15.3125, token_id=36943, metadata=None))), (14642, (11, PredictedToken(token=' Phone', prob=0.0045166015625, logit=14.6875, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:32 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.582, logit=20.000)', '\" C\"[356] (p=0.214, logit=19.000)', '\" The\"[578] (p=0.069, logit=17.875)', '\" There\"[2684] (p=0.054, logit=17.625)', '\" None\"[2290] (p=0.026, logit=16.875)']\n",
      "2025-09-15 09:44:32 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.781, logit=20.125)', '\" The\"[578] (p=0.106, logit=18.125)', '\" Ottoman\"[70110] (p=0.034, logit=17.000)', '\" A\"[362] (p=0.014, logit=16.125)', '\" It\"[1102] (p=0.006, logit=15.250)']\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.78125, logit=20.125, token_id=29318, metadata=None))), (70110, (3, PredictedToken(token=' Ottoman', prob=0.034423828125, logit=17.0, token_id=70110, metadata=None))), (33199, (18, PredictedToken(token=' Lion', prob=0.00103759765625, logit=13.5, token_id=33199, metadata=None))), (87035, (364, PredictedToken(token=' Onion', prob=7.0035457611083984e-06, logit=8.5, token_id=87035, metadata=None))), (91297, (1478, PredictedToken(token=' Mushroom', prob=1.043081283569336e-06, logit=6.59375, token_id=91297, metadata=None)))])\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     int_prediction=['\" Mushroom\"[91297] (p=0.582, logit=18.250)', '\" The\"[578] (p=0.130, logit=16.750)', '\" Onion\"[87035] (p=0.069, logit=16.125)', '\" Lion\"[33199] (p=0.018, logit=14.750)', '\" None\"[2290] (p=0.016, logit=14.688)']\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     int_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.58203125, logit=18.25, token_id=91297, metadata=None))), (87035, (3, PredictedToken(token=' Onion', prob=0.0693359375, logit=16.125, token_id=87035, metadata=None))), (33199, (4, PredictedToken(token=' Lion', prob=0.017578125, logit=14.75, token_id=33199, metadata=None))), (70110, (7, PredictedToken(token=' Ottoman', prob=0.013671875, logit=14.5, token_id=70110, metadata=None))), (29318, (81, PredictedToken(token=' Dress', prob=0.00025177001953125, logit=10.5, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:33 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     patch_prediction=['\" Marker\"[40975] (p=0.812, logit=20.375)', '\" R\"[432] (p=0.041, logit=17.375)', '\" The\"[578] (p=0.036, logit=17.250)', '\" A\"[362] (p=0.022, logit=16.750)', '\" None\"[2290] (p=0.019, logit=16.625)']\n",
      "2025-09-15 09:44:33 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.867, logit=21.250)', '\" The\"[578] (p=0.081, logit=18.875)', '\" Fl\"[3061] (p=0.016, logit=17.250)', '\" A\"[362] (p=0.007, logit=16.375)', '\" It\"[1102] (p=0.002, logit=15.312)']\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8671875, logit=21.25, token_id=40759, metadata=None))), (3061, (3, PredictedToken(token=' Fl', prob=0.015869140625, logit=17.25, token_id=3061, metadata=None))), (1901, (18, PredictedToken(token=' Z', prob=0.00051116943359375, logit=13.8125, token_id=1901, metadata=None))), (37128, (24, PredictedToken(token=' Calculator', prob=0.00037384033203125, logit=13.5, token_id=37128, metadata=None))), (2522, (45, PredictedToken(token=' Sc', prob=0.00010728836059570312, logit=12.25, token_id=2522, metadata=None)))])\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     int_prediction=['\" Calculator\"[37128] (p=0.500, logit=19.750)', '\" Sc\"[2522] (p=0.236, logit=19.000)', '\" The\"[578] (p=0.127, logit=18.375)', '\" A\"[362] (p=0.028, logit=16.875)', '\" Z\"[1901] (p=0.019, logit=16.500)']\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     int_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.5, logit=19.75, token_id=37128, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.236328125, logit=19.0, token_id=2522, metadata=None))), (1901, (5, PredictedToken(token=' Z', prob=0.0194091796875, logit=16.5, token_id=1901, metadata=None))), (3061, (12, PredictedToken(token=' Fl', prob=0.003814697265625, logit=14.875, token_id=3061, metadata=None))), (40759, (29, PredictedToken(token=' Harmon', prob=0.00066375732421875, logit=13.125, token_id=40759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:34 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:34 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     patch_prediction=['\" Temple\"[19176] (p=0.777, logit=19.375)', '\" The\"[578] (p=0.082, logit=17.125)', '\" Hel\"[16183] (p=0.025, logit=15.938)', '\" Mall\"[32498] (p=0.018, logit=15.625)', '\" A\"[362] (p=0.017, logit=15.562)']\n",
      "2025-09-15 09:44:34 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     clean_prediction=['\" Cabinet\"[34046] (p=0.516, logit=19.500)', '\" Re\"[1050] (p=0.244, logit=18.750)', '\" The\"[578] (p=0.148, logit=18.250)', '\" A\"[362] (p=0.013, logit=15.812)', '\" It\"[1102] (p=0.011, logit=15.625)']\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     clean_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.515625, logit=19.5, token_id=34046, metadata=None))), (1050, (2, PredictedToken(token=' Re', prob=0.244140625, logit=18.75, token_id=1050, metadata=None))), (50159, (30, PredictedToken(token=' Sco', prob=0.000568389892578125, logit=12.6875, token_id=50159, metadata=None))), (15429, (217, PredictedToken(token=' Hospital', prob=1.5139579772949219e-05, logit=9.0625, token_id=15429, metadata=None))), (23462, (304, PredictedToken(token=' Stadium', prob=8.64267349243164e-06, logit=8.5, token_id=23462, metadata=None)))])\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     int_prediction=['\" Cabinet\"[34046] (p=0.475, logit=19.250)', '\" Hospital\"[15429] (p=0.254, logit=18.625)', '\" The\"[578] (p=0.154, logit=18.125)', '\" Stadium\"[23462] (p=0.021, logit=16.125)', '\" A\"[362] (p=0.010, logit=15.438)']\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     int_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.474609375, logit=19.25, token_id=34046, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.25390625, logit=18.625, token_id=15429, metadata=None))), (23462, (4, PredictedToken(token=' Stadium', prob=0.0208740234375, logit=16.125, token_id=23462, metadata=None))), (1050, (18, PredictedToken(token=' Re', prob=0.001708984375, logit=13.625, token_id=1050, metadata=None))), (50159, (60, PredictedToken(token=' Sco', prob=0.00019168853759765625, logit=11.4375, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:35 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.738, logit=19.750)', '\" Boxing\"[72683] (p=0.061, logit=17.250)', '\" The\"[578] (p=0.061, logit=17.250)', '\" A\"[362] (p=0.053, logit=17.125)', '\" BAT\"[79081] (p=0.022, logit=16.250)']\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.773, logit=19.875)', '\" Sc\"[2522] (p=0.049, logit=17.125)', '\" The\"[578] (p=0.038, logit=16.875)', '\" Stap\"[63606] (p=0.034, logit=16.750)', '\" A\"[362] (p=0.018, logit=16.125)']\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.7734375, logit=19.875, token_id=91263, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.04931640625, logit=17.125, token_id=2522, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.01416015625, logit=15.875, token_id=423, metadata=None))), (79028, (8, PredictedToken(token=' Hick', prob=0.007110595703125, logit=15.1875, token_id=79028, metadata=None))), (97796, (83, PredictedToken(token=' Skate', prob=0.00010776519775390625, logit=11.0, token_id=97796, metadata=None)))])\n",
      "2025-09-15 09:44:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.391, logit=18.125)', '\" Skate\"[97796] (p=0.268, logit=17.750)', '\" Hick\"[79028] (p=0.087, logit=16.625)', '\" None\"[2290] (p=0.060, logit=16.250)', '\" Stap\"[63606] (p=0.034, logit=15.688)']\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.390625, logit=18.125, token_id=423, metadata=None))), (97796, (2, PredictedToken(token=' Skate', prob=0.267578125, logit=17.75, token_id=97796, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.0869140625, logit=16.625, token_id=79028, metadata=None))), (2522, (7, PredictedToken(token=' Sc', prob=0.01611328125, logit=14.9375, token_id=2522, metadata=None))), (91263, (11, PredictedToken(token=' Binder', prob=0.00628662109375, logit=14.0, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:36 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     patch_prediction=['\" Orange\"[22725] (p=0.730, logit=19.125)', '\" The\"[578] (p=0.041, logit=16.250)', '\" None\"[2290] (p=0.030, logit=15.938)', '\" There\"[2684] (p=0.028, logit=15.875)', '\" Peach\"[64695] (p=0.027, logit=15.812)']\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.754, logit=19.125)', '\" The\"[578] (p=0.062, logit=16.625)', '\" Lav\"[43950] (p=0.055, logit=16.500)', '\" L\"[445] (p=0.020, logit=15.500)', '\" SUN\"[57328] (p=0.019, logit=15.438)']\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.75390625, logit=19.125, token_id=8219, metadata=None))), (43950, (3, PredictedToken(token=' Lav', prob=0.0546875, logit=16.5, token_id=43950, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.02001953125, logit=15.5, token_id=445, metadata=None))), (8325, (13, PredictedToken(token=' Apple', prob=0.0017547607421875, logit=13.0625, token_id=8325, metadata=None))), (48665, (65, PredictedToken(token=' Raspberry', prob=0.0002231597900390625, logit=11.0, token_id=48665, metadata=None)))])\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.473, logit=18.125)', '\" Apple\"[8325] (p=0.153, logit=17.000)', '\" Lav\"[43950] (p=0.082, logit=16.375)', '\" The\"[578] (p=0.056, logit=16.000)', '\" L\"[445] (p=0.039, logit=15.625)']\n",
      "2025-09-15 09:44:36 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.47265625, logit=18.125, token_id=8219, metadata=None))), (8325, (2, PredictedToken(token=' Apple', prob=0.1533203125, logit=17.0, token_id=8325, metadata=None))), (43950, (3, PredictedToken(token=' Lav', prob=0.08203125, logit=16.375, token_id=43950, metadata=None))), (445, (5, PredictedToken(token=' L', prob=0.038818359375, logit=15.625, token_id=445, metadata=None))), (48665, (6, PredictedToken(token=' Raspberry', prob=0.036376953125, logit=15.5625, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:37 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:44:37 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:37 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.824, logit=20.375)', '\" The\"[578] (p=0.077, logit=18.000)', '\" DO\"[9503] (p=0.019, logit=16.625)', '\" There\"[2684] (p=0.012, logit=16.125)', '\" A\"[362] (p=0.008, logit=15.750)']\n",
      "2025-09-15 09:44:37 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:37 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.707, logit=20.250)', '\" The\"[578] (p=0.158, logit=18.750)', '\" A\"[362] (p=0.040, logit=17.375)', '\" Swe\"[37326] (p=0.035, logit=17.250)', '\" There\"[2684] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:44:37 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.70703125, logit=20.25, token_id=59825, metadata=None))), (37326, (4, PredictedToken(token=' Swe', prob=0.035400390625, logit=17.25, token_id=37326, metadata=None))), (423, (22, PredictedToken(token=' D', prob=0.000732421875, logit=13.375, token_id=423, metadata=None))), (79189, (254, PredictedToken(token=' Elephant', prob=1.043081283569336e-05, logit=9.125, token_id=79189, metadata=None))), (22607, (314, PredictedToken(token=' Cow', prob=7.62939453125e-06, logit=8.8125, token_id=22607, metadata=None)))])\n",
      "2025-09-15 09:44:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.734, logit=20.375)', '\" Elephant\"[79189] (p=0.100, logit=18.375)', '\" The\"[578] (p=0.078, logit=18.125)', '\" C\"[356] (p=0.029, logit=17.125)', '\" There\"[2684] (p=0.006, logit=15.625)']\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.734375, logit=20.375, token_id=22607, metadata=None))), (79189, (2, PredictedToken(token=' Elephant', prob=0.099609375, logit=18.375, token_id=79189, metadata=None))), (59825, (9, PredictedToken(token=' Tie', prob=0.003204345703125, logit=14.9375, token_id=59825, metadata=None))), (37326, (12, PredictedToken(token=' Swe', prob=0.002197265625, logit=14.5625, token_id=37326, metadata=None))), (423, (21, PredictedToken(token=' D', prob=0.0008087158203125, logit=13.5625, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:38 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.801, logit=20.625)', '\" The\"[578] (p=0.095, logit=18.500)', '\" Z\"[1901] (p=0.024, logit=17.125)', '\" L\"[445] (p=0.024, logit=17.125)', '\" A\"[362] (p=0.013, logit=16.500)']\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.668, logit=20.375)', '\" The\"[578] (p=0.131, logit=18.750)', '\" There\"[2684] (p=0.070, logit=18.125)', '\" Tomato\"[94091] (p=0.048, logit=17.750)', '\" ON\"[6328] (p=0.014, logit=16.500)']\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.66796875, logit=20.375, token_id=87035, metadata=None))), (94091, (4, PredictedToken(token=' Tomato', prob=0.04833984375, logit=17.75, token_id=94091, metadata=None))), (36845, (17, PredictedToken(token=' Tiger', prob=0.00128936767578125, logit=14.125, token_id=36845, metadata=None))), (34392, (27, PredictedToken(token=' Horse', prob=0.00064849853515625, logit=13.4375, token_id=34392, metadata=None))), (81501, (301, PredictedToken(token=' Pendant', prob=1.043081283569336e-05, logit=9.3125, token_id=81501, metadata=None)))])\n",
      "2025-09-15 09:44:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:39 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.691, logit=20.250)', '\" The\"[578] (p=0.137, logit=18.625)', '\" Tiger\"[36845] (p=0.050, logit=17.625)', '\" There\"[2684] (p=0.034, logit=17.250)', '\" None\"[2290] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:44:39 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.69140625, logit=20.25, token_id=34392, metadata=None))), (36845, (3, PredictedToken(token=' Tiger', prob=0.050048828125, logit=17.625, token_id=36845, metadata=None))), (94091, (7, PredictedToken(token=' Tomato', prob=0.007232666015625, logit=15.6875, token_id=94091, metadata=None))), (81501, (9, PredictedToken(token=' Pendant', prob=0.005279541015625, logit=15.375, token_id=81501, metadata=None))), (87035, (17, PredictedToken(token=' Onion', prob=0.00171661376953125, logit=14.25, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:39 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:39 src.selection.optimization DEBUG    torch.Size([7, 33])\n",
      "2025-09-15 09:44:39 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:39 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.539, logit=20.000)', '\" Pen\"[13597] (p=0.254, logit=19.250)', '\" The\"[578] (p=0.093, logit=18.250)', '\" A\"[362] (p=0.050, logit=17.625)', '\" PEN\"[81770] (p=0.009, logit=15.875)']\n",
      "2025-09-15 09:44:39 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:40 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.660, logit=19.250)', '\" Dress\"[29318] (p=0.114, logit=17.500)', '\" The\"[578] (p=0.101, logit=17.375)', '\" A\"[362] (p=0.024, logit=15.938)', '\" R\"[432] (p=0.008, logit=14.812)']\n",
      "2025-09-15 09:44:40 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.66015625, logit=19.25, token_id=27738, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.1142578125, logit=17.5, token_id=29318, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.007781982421875, logit=14.8125, token_id=432, metadata=None))), (22607, (60, PredictedToken(token=' Cow', prob=0.00019550323486328125, logit=11.125, token_id=22607, metadata=None))), (9939, (96, PredictedToken(token=' Er', prob=8.678436279296875e-05, logit=10.3125, token_id=9939, metadata=None))), (2947, (129, PredictedToken(token=' Mar', prob=4.935264587402344e-05, logit=9.75, token_id=2947, metadata=None))), (91263, (143, PredictedToken(token=' Binder', prob=4.6253204345703125e-05, logit=9.6875, token_id=91263, metadata=None)))])\n",
      "2025-09-15 09:44:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:40 src.selection.optimization INFO     int_prediction=['\" Er\"[9939] (p=0.605, logit=18.500)', '\" The\"[578] (p=0.093, logit=16.625)', '\" R\"[432] (p=0.072, logit=16.375)', '\" Mar\"[2947] (p=0.056, logit=16.125)', '\" ER\"[27590] (p=0.017, logit=14.938)']\n",
      "2025-09-15 09:44:40 src.selection.optimization INFO     int_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.60546875, logit=18.5, token_id=9939, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.072265625, logit=16.375, token_id=432, metadata=None))), (2947, (4, PredictedToken(token=' Mar', prob=0.05615234375, logit=16.125, token_id=2947, metadata=None))), (91263, (7, PredictedToken(token=' Binder', prob=0.01336669921875, logit=14.6875, token_id=91263, metadata=None))), (29318, (15, PredictedToken(token=' Dress', prob=0.0038299560546875, logit=13.4375, token_id=29318, metadata=None))), (27738, (19, PredictedToken(token=' Ward', prob=0.00262451171875, logit=13.0625, token_id=27738, metadata=None))), (22607, (41, PredictedToken(token=' Cow', prob=0.00066375732421875, logit=11.6875, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:40 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-15 09:44:40 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.703, logit=20.375)', '\" The\"[578] (p=0.123, logit=18.625)', '\" Dog\"[14588] (p=0.058, logit=17.875)', '\" L\"[445] (p=0.051, logit=17.750)', '\" A\"[362] (p=0.017, logit=16.625)']\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     clean_prediction=['\" Pear\"[23910] (p=0.855, logit=21.625)', '\" The\"[578] (p=0.090, logit=19.375)', '\" A\"[362] (p=0.012, logit=17.375)', '\" Ki\"[30558] (p=0.007, logit=16.875)', '\" P\"[393] (p=0.007, logit=16.875)']\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     clean_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.85546875, logit=21.625, token_id=23910, metadata=None))), (30558, (5, PredictedToken(token=' Ki', prob=0.00738525390625, logit=16.875, token_id=30558, metadata=None))), (4923, (26, PredictedToken(token=' Sk', prob=0.000209808349609375, logit=13.3125, token_id=4923, metadata=None))), (79189, (30, PredictedToken(token=' Elephant', prob=0.0001850128173828125, logit=13.1875, token_id=79189, metadata=None))), (96096, (108, PredictedToken(token=' Dolphin', prob=2.0742416381835938e-05, logit=11.0, token_id=96096, metadata=None)))])\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     int_prediction=['\" Elephant\"[79189] (p=0.412, logit=19.625)', '\" Ki\"[30558] (p=0.322, logit=19.375)', '\" The\"[578] (p=0.152, logit=18.625)', '\" Dolphin\"[96096] (p=0.023, logit=16.750)', '\" There\"[2684] (p=0.011, logit=16.000)']\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     int_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.412109375, logit=19.625, token_id=79189, metadata=None))), (30558, (2, PredictedToken(token=' Ki', prob=0.322265625, logit=19.375, token_id=30558, metadata=None))), (96096, (4, PredictedToken(token=' Dolphin', prob=0.0233154296875, logit=16.75, token_id=96096, metadata=None))), (23910, (12, PredictedToken(token=' Pear', prob=0.0037994384765625, logit=14.9375, token_id=23910, metadata=None))), (4923, (13, PredictedToken(token=' Sk', prob=0.0031585693359375, logit=14.75, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:41 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:44:41 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.377, logit=19.000)', '\" Hockey\"[41342] (p=0.332, logit=18.875)', '\" The\"[578] (p=0.157, logit=18.125)', '\" A\"[362] (p=0.058, logit=17.125)', '\" None\"[2290] (p=0.008, logit=15.188)']\n",
      "2025-09-15 09:44:41 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:42 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.699, logit=19.875)', '\" Head\"[11452] (p=0.107, logit=18.000)', '\" The\"[578] (p=0.095, logit=17.875)', '\" HEAD\"[34180] (p=0.009, logit=15.562)', '\" There\"[2684] (p=0.007, logit=15.250)']\n",
      "2025-09-15 09:44:42 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.69921875, logit=19.875, token_id=26698, metadata=None))), (11452, (2, PredictedToken(token=' Head', prob=0.10693359375, logit=18.0, token_id=11452, metadata=None))), (16488, (25, PredictedToken(token=' Bat', prob=0.00081634521484375, logit=13.125, token_id=16488, metadata=None))), (38673, (28, PredictedToken(token=' Yoga', prob=0.000598907470703125, logit=12.8125, token_id=38673, metadata=None)))])\n",
      "2025-09-15 09:44:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:42 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.844, logit=19.250)', '\" The\"[578] (p=0.042, logit=16.250)', '\" BAT\"[79081] (p=0.025, logit=15.750)', '\" A\"[362] (p=0.016, logit=15.312)', '\" Head\"[11452] (p=0.006, logit=14.312)']\n",
      "2025-09-15 09:44:42 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.84375, logit=19.25, token_id=16488, metadata=None))), (11452, (5, PredictedToken(token=' Head', prob=0.00604248046875, logit=14.3125, token_id=11452, metadata=None))), (38673, (12, PredictedToken(token=' Yoga', prob=0.002685546875, logit=13.5, token_id=38673, metadata=None))), (26698, (17, PredictedToken(token=' Keyboard', prob=0.00135040283203125, logit=12.8125, token_id=26698, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:42 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-15 09:44:42 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-15 09:44:42 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.621, logit=19.875)', '\" Y\"[816] (p=0.095, logit=18.000)', '\" The\"[578] (p=0.095, logit=18.000)', '\" There\"[2684] (p=0.065, logit=17.625)', '\" A\"[362] (p=0.035, logit=17.000)']\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.432, logit=20.000)', '\" Temple\"[19176] (p=0.336, logit=19.750)', '\" The\"[578] (p=0.140, logit=18.875)', '\" HOUSE\"[69461] (p=0.024, logit=17.125)', '\" A\"[362] (p=0.024, logit=17.125)']\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.431640625, logit=20.0, token_id=4783, metadata=None))), (19176, (2, PredictedToken(token=' Temple', prob=0.3359375, logit=19.75, token_id=19176, metadata=None))), (14588, (18, PredictedToken(token=' Dog', prob=0.00064849853515625, logit=13.5, token_id=14588, metadata=None))), (90538, (44, PredictedToken(token=' Caul', prob=0.000164031982421875, logit=12.125, token_id=90538, metadata=None))), (13000, (57, PredictedToken(token=' Van', prob=0.0001125335693359375, logit=11.75, token_id=13000, metadata=None))), (34785, (109, PredictedToken(token=' Truck', prob=3.4332275390625e-05, logit=10.5625, token_id=34785, metadata=None)))])\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.480, logit=19.375)', '\" Truck\"[34785] (p=0.258, logit=18.750)', '\" The\"[578] (p=0.065, logit=17.375)', '\" House\"[4783] (p=0.045, logit=17.000)', '\" A\"[362] (p=0.031, logit=16.625)']\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.48046875, logit=19.375, token_id=13000, metadata=None))), (34785, (2, PredictedToken(token=' Truck', prob=0.2578125, logit=18.75, token_id=34785, metadata=None))), (4783, (4, PredictedToken(token=' House', prob=0.044677734375, logit=17.0, token_id=4783, metadata=None))), (14588, (6, PredictedToken(token=' Dog', prob=0.027099609375, logit=16.5, token_id=14588, metadata=None))), (90538, (11, PredictedToken(token=' Caul', prob=0.003662109375, logit=14.5, token_id=90538, metadata=None))), (19176, (93, PredictedToken(token=' Temple', prob=8.106231689453125e-05, logit=10.6875, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:43 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:44:43 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.832, logit=21.125)', '\" The\"[578] (p=0.113, logit=19.125)', '\" A\"[362] (p=0.008, logit=16.500)', '\" Harmon\"[40759] (p=0.006, logit=16.125)', '\" \"[220] (p=0.003, logit=15.500)']\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.820, logit=19.250)', '\" The\"[578] (p=0.067, logit=16.750)', '\" AS\"[5871] (p=0.011, logit=14.938)', '\" There\"[2684] (p=0.011, logit=14.938)', '\" Birch\"[88088] (p=0.010, logit=14.812)']\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.8203125, logit=19.25, token_id=14937, metadata=None))), (88088, (5, PredictedToken(token=' Birch', prob=0.00970458984375, logit=14.8125, token_id=88088, metadata=None))), (47589, (11, PredictedToken(token=' Basketball', prob=0.0026092529296875, logit=13.5, token_id=47589, metadata=None))), (68027, (23, PredictedToken(token=' Sax', prob=0.00115966796875, logit=12.6875, token_id=68027, metadata=None))), (30555, (24, PredictedToken(token=' Viol', prob=0.000751495361328125, logit=12.25, token_id=30555, metadata=None)))])\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.711, logit=19.125)', '\" Sax\"[68027] (p=0.109, logit=17.250)', '\" The\"[578] (p=0.059, logit=16.625)', '\" There\"[2684] (p=0.015, logit=15.250)', '\" None\"[2290] (p=0.008, logit=14.688)']\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.7109375, logit=19.125, token_id=30555, metadata=None))), (68027, (2, PredictedToken(token=' Sax', prob=0.109375, logit=17.25, token_id=68027, metadata=None))), (88088, (6, PredictedToken(token=' Birch', prob=0.0074462890625, logit=14.5625, token_id=88088, metadata=None))), (47589, (19, PredictedToken(token=' Basketball', prob=0.00165557861328125, logit=13.0625, token_id=47589, metadata=None))), (14937, (24, PredictedToken(token=' Ash', prob=0.000946044921875, logit=12.5, token_id=14937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:44 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:44 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.465, logit=18.750)', '\" Elephant\"[79189] (p=0.091, logit=17.125)', '\" The\"[578] (p=0.091, logit=17.125)', '\" There\"[2684] (p=0.055, logit=16.625)', '\" Y\"[816] (p=0.055, logit=16.625)']\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     clean_prediction=['\" Dog\"[14588] (p=0.605, logit=19.875)', '\" Monkey\"[58937] (p=0.135, logit=18.375)', '\" The\"[578] (p=0.135, logit=18.375)', '\" DO\"[9503] (p=0.021, logit=16.500)', '\" A\"[362] (p=0.018, logit=16.375)']\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     clean_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.60546875, logit=19.875, token_id=14588, metadata=None))), (58937, (3, PredictedToken(token=' Monkey', prob=0.134765625, logit=18.375, token_id=58937, metadata=None))), (18343, (14, PredictedToken(token=' Paper', prob=0.00159454345703125, logit=13.9375, token_id=18343, metadata=None))), (13000, (49, PredictedToken(token=' Van', prob=0.00022983551025390625, logit=12.0, token_id=13000, metadata=None))), (34785, (53, PredictedToken(token=' Truck', prob=0.0002155303955078125, logit=11.9375, token_id=34785, metadata=None)))])\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     int_prediction=['\" Monkey\"[58937] (p=0.498, logit=19.375)', '\" Van\"[13000] (p=0.207, logit=18.500)', '\" Truck\"[34785] (p=0.067, logit=17.375)', '\" The\"[578] (p=0.067, logit=17.375)', '\" MON\"[29637] (p=0.025, logit=16.375)']\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     int_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.498046875, logit=19.375, token_id=58937, metadata=None))), (13000, (2, PredictedToken(token=' Van', prob=0.20703125, logit=18.5, token_id=13000, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.0673828125, logit=17.375, token_id=34785, metadata=None))), (14588, (11, PredictedToken(token=' Dog', prob=0.008056640625, logit=15.25, token_id=14588, metadata=None))), (18343, (23, PredictedToken(token=' Paper', prob=0.0009613037109375, logit=13.125, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:45 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-15 09:44:45 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.883, logit=21.250)', '\" The\"[578] (p=0.050, logit=18.375)', '\" A\"[362] (p=0.014, logit=17.125)', '\" d\"[294] (p=0.009, logit=16.625)', '\" Mar\"[2947] (p=0.006, logit=16.250)']\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     clean_prediction=['\" Er\"[9939] (p=0.863, logit=20.000)', '\" The\"[578] (p=0.026, logit=16.500)', '\" Paper\"[18343] (p=0.020, logit=16.250)', '\" ER\"[27590] (p=0.020, logit=16.250)', '\" An\"[1556] (p=0.012, logit=15.750)']\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     clean_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.86328125, logit=20.0, token_id=9939, metadata=None))), (18343, (3, PredictedToken(token=' Paper', prob=0.020263671875, logit=16.25, token_id=18343, metadata=None))), (74968, (18, PredictedToken(token=' Razor', prob=0.001007080078125, logit=13.25, token_id=74968, metadata=None))), (32749, (22, PredictedToken(token=' Carn', prob=0.00074005126953125, logit=12.9375, token_id=32749, metadata=None))), (82452, (26, PredictedToken(token=' Jasmine', prob=0.0004482269287109375, logit=12.4375, token_id=82452, metadata=None)))])\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.863, logit=20.125)', '\" The\"[578] (p=0.038, logit=17.000)', '\" J\"[622] (p=0.020, logit=16.375)', '\" jasmine\"[66909] (p=0.016, logit=16.125)', '\" Paper\"[18343] (p=0.016, logit=16.125)']\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.86328125, logit=20.125, token_id=82452, metadata=None))), (18343, (4, PredictedToken(token=' Paper', prob=0.0157470703125, logit=16.125, token_id=18343, metadata=None))), (32749, (9, PredictedToken(token=' Carn', prob=0.00213623046875, logit=14.125, token_id=32749, metadata=None))), (9939, (15, PredictedToken(token=' Er', prob=0.00107574462890625, logit=13.4375, token_id=9939, metadata=None))), (74968, (44, PredictedToken(token=' Razor', prob=0.0001544952392578125, logit=11.5, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:46 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:46 src.selection.optimization DEBUG    torch.Size([7, 35])\n",
      "2025-09-15 09:44:46 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.770, logit=19.875)', '\" The\"[578] (p=0.081, logit=17.625)', '\" E\"[469] (p=0.026, logit=16.500)', '\" Tow\"[41493] (p=0.023, logit=16.375)', '\" There\"[2684] (p=0.018, logit=16.125)']\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.895, logit=20.750)', '\" Sh\"[1443] (p=0.031, logit=17.375)', '\" TO\"[5257] (p=0.024, logit=17.125)', '\" The\"[578] (p=0.010, logit=16.250)', '\" SH\"[6570] (p=0.003, logit=15.125)']\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.89453125, logit=20.75, token_id=83499, metadata=None))), (1443, (2, PredictedToken(token=' Sh', prob=0.0306396484375, logit=17.375, token_id=1443, metadata=None))), (46506, (8, PredictedToken(token=' Drum', prob=0.0020751953125, logit=14.6875, token_id=46506, metadata=None))), (65449, (19, PredictedToken(token=' Willow', prob=0.0005950927734375, logit=13.4375, token_id=65449, metadata=None))), (44570, (21, PredictedToken(token=' Maple', prob=0.000560760498046875, logit=13.375, token_id=44570, metadata=None))), (91263, (22, PredictedToken(token=' Binder', prob=0.00052642822265625, logit=13.3125, token_id=91263, metadata=None))), (49431, (37, PredictedToken(token=' Rabbit', prob=0.00019359588623046875, logit=12.3125, token_id=49431, metadata=None)))])\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     int_prediction=['\" Maple\"[44570] (p=0.852, logit=20.500)', '\" Willow\"[65449] (p=0.042, logit=17.500)', '\" Binder\"[91263] (p=0.033, logit=17.250)', '\" MAP\"[28322] (p=0.020, logit=16.750)', '\" The\"[578] (p=0.016, logit=16.500)']\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     int_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.8515625, logit=20.5, token_id=44570, metadata=None))), (65449, (2, PredictedToken(token=' Willow', prob=0.042236328125, logit=17.5, token_id=65449, metadata=None))), (91263, (3, PredictedToken(token=' Binder', prob=0.032958984375, logit=17.25, token_id=91263, metadata=None))), (49431, (13, PredictedToken(token=' Rabbit', prob=0.001129150390625, logit=13.875, token_id=49431, metadata=None))), (1443, (11, PredictedToken(token=' Sh', prob=0.001129150390625, logit=13.875, token_id=1443, metadata=None))), (46506, (26, PredictedToken(token=' Drum', prob=0.0003662109375, logit=12.75, token_id=46506, metadata=None))), (83499, (28, PredictedToken(token=' Tooth', prob=0.000324249267578125, logit=12.625, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:47 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:47 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     patch_prediction=['\" Shirt\"[55807] (p=0.770, logit=21.000)', '\" The\"[578] (p=0.134, logit=19.250)', '\" A\"[362] (p=0.038, logit=18.000)', '\" SH\"[6570] (p=0.011, logit=16.750)', '\" There\"[2684] (p=0.005, logit=16.000)']\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.898, logit=22.000)', '\" The\"[578] (p=0.065, logit=19.375)', '\" PE\"[22557] (p=0.013, logit=17.750)', '\" A\"[362] (p=0.007, logit=17.125)', '\" There\"[2684] (p=0.002, logit=15.875)']\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.8984375, logit=22.0, token_id=64695, metadata=None))), (8868, (12, PredictedToken(token=' Blue', prob=0.00049591064453125, logit=14.5, token_id=8868, metadata=None))), (56491, (151, PredictedToken(token=' Piano', prob=9.655952453613281e-06, logit=10.5625, token_id=56491, metadata=None))), (67553, (541, PredictedToken(token=' Pants', prob=1.087784767150879e-06, logit=8.375, token_id=67553, metadata=None))), (68554, (2108, PredictedToken(token=' Gloves', prob=1.6670674085617065e-07, logit=6.5, token_id=68554, metadata=None)))])\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.414, logit=18.250)', '\" The\"[578] (p=0.250, logit=17.750)', '\" Pants\"[67553] (p=0.072, logit=16.500)', '\" Glo\"[25372] (p=0.049, logit=16.125)', '\" There\"[2684] (p=0.026, logit=15.500)']\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.4140625, logit=18.25, token_id=68554, metadata=None))), (67553, (3, PredictedToken(token=' Pants', prob=0.07177734375, logit=16.5, token_id=67553, metadata=None))), (8868, (14, PredictedToken(token=' Blue', prob=0.0029754638671875, logit=13.3125, token_id=8868, metadata=None))), (64695, (21, PredictedToken(token=' Peach', prob=0.00191497802734375, logit=12.875, token_id=64695, metadata=None))), (56491, (36, PredictedToken(token=' Piano', prob=0.00109100341796875, logit=12.3125, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:48 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-15 09:44:48 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     patch_prediction=['\" Keyboard\"[26698] (p=0.680, logit=19.500)', '\" Camera\"[14669] (p=0.134, logit=17.875)', '\" The\"[578] (p=0.071, logit=17.250)', '\" None\"[2290] (p=0.014, logit=15.625)', '\" A\"[362] (p=0.006, logit=14.812)']\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     clean_prediction=['\" P\"[393] (p=0.504, logit=19.625)', '\" Binder\"[91263] (p=0.270, logit=19.000)', '\" The\"[578] (p=0.068, logit=17.625)', '\" Monitor\"[24423] (p=0.042, logit=17.125)', '\" A\"[362] (p=0.037, logit=17.000)']\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     clean_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.50390625, logit=19.625, token_id=393, metadata=None))), (91263, (2, PredictedToken(token=' Binder', prob=0.26953125, logit=19.0, token_id=91263, metadata=None))), (24423, (4, PredictedToken(token=' Monitor', prob=0.04150390625, logit=17.125, token_id=24423, metadata=None))), (41445, (17, PredictedToken(token=' Television', prob=0.00110626220703125, logit=13.5, token_id=41445, metadata=None))), (16730, (241, PredictedToken(token=' Museum', prob=1.895427703857422e-05, logit=9.4375, token_id=16730, metadata=None)))])\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.883, logit=21.125)', '\" Television\"[41445] (p=0.034, logit=17.875)', '\" The\"[578] (p=0.018, logit=17.250)', '\" None\"[2290] (p=0.016, logit=17.125)', '\" MON\"[29637] (p=0.011, logit=16.750)']\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.8828125, logit=21.125, token_id=24423, metadata=None))), (41445, (2, PredictedToken(token=' Television', prob=0.0341796875, logit=17.875, token_id=41445, metadata=None))), (393, (8, PredictedToken(token=' P', prob=0.0023345947265625, logit=15.1875, token_id=393, metadata=None))), (91263, (25, PredictedToken(token=' Binder', prob=0.0002613067626953125, logit=13.0, token_id=91263, metadata=None))), (16730, (105, PredictedToken(token=' Museum', prob=2.9325485229492188e-05, logit=10.8125, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:49 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:49 src.selection.optimization DEBUG    torch.Size([7, 34])\n",
      "2025-09-15 09:44:49 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     patch_prediction=['\" Desk\"[39794] (p=0.758, logit=20.500)', '\" Dress\"[29318] (p=0.080, logit=18.250)', '\" The\"[578] (p=0.080, logit=18.250)', '\" DES\"[13022] (p=0.014, logit=16.500)', '\" There\"[2684] (p=0.012, logit=16.375)']\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.797, logit=20.750)', '\" The\"[578] (p=0.095, logit=18.625)', '\" Charm\"[58600] (p=0.027, logit=17.375)', '\" NE\"[8014] (p=0.015, logit=16.750)', '\" A\"[362] (p=0.011, logit=16.500)']\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.796875, logit=20.75, token_id=86460, metadata=None))), (58600, (3, PredictedToken(token=' Charm', prob=0.0272216796875, logit=17.375, token_id=58600, metadata=None))), (11452, (6, PredictedToken(token=' Head', prob=0.0064697265625, logit=15.9375, token_id=11452, metadata=None))), (91963, (188, PredictedToken(token=' Mango', prob=1.704692840576172e-05, logit=10.0, token_id=91963, metadata=None))), (36358, (246, PredictedToken(token=' Bench', prob=9.715557098388672e-06, logit=9.4375, token_id=36358, metadata=None))), (87035, (402, PredictedToken(token=' Onion', prob=4.887580871582031e-06, logit=8.75, token_id=87035, metadata=None))), (6017, (408, PredictedToken(token=' Book', prob=4.589557647705078e-06, logit=8.6875, token_id=6017, metadata=None)))])\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     int_prediction=['\" Book\"[6017] (p=0.484, logit=19.875)', '\" Bench\"[36358] (p=0.334, logit=19.500)', '\" The\"[578] (p=0.065, logit=17.875)', '\" BOOK\"[48198] (p=0.027, logit=17.000)', '\" Head\"[11452] (p=0.019, logit=16.625)']\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     int_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.484375, logit=19.875, token_id=6017, metadata=None))), (36358, (2, PredictedToken(token=' Bench', prob=0.333984375, logit=19.5, token_id=36358, metadata=None))), (11452, (5, PredictedToken(token=' Head', prob=0.018798828125, logit=16.625, token_id=11452, metadata=None))), (86460, (31, PredictedToken(token=' Necklace', prob=0.0003910064697265625, logit=12.75, token_id=86460, metadata=None))), (87035, (55, PredictedToken(token=' Onion', prob=0.0001964569091796875, logit=12.0625, token_id=87035, metadata=None))), (58600, (57, PredictedToken(token=' Charm', prob=0.0001735687255859375, logit=11.9375, token_id=58600, metadata=None))), (91963, (517, PredictedToken(token=' Mango', prob=3.382563591003418e-06, logit=8.0, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:50 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.871, logit=20.750)', '\" The\"[578] (p=0.043, logit=17.750)', '\" D\"[423] (p=0.030, logit=17.375)', '\" BOX\"[53783] (p=0.009, logit=16.125)', '\" E\"[469] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:44:50 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:51 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.875, logit=20.625)', '\" Lily\"[48390] (p=0.049, logit=17.750)', '\" The\"[578] (p=0.026, logit=17.125)', '\" R\"[432] (p=0.008, logit=15.875)', '\" violet\"[80836] (p=0.005, logit=15.500)']\n",
      "2025-09-15 09:44:51 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.875, logit=20.625, token_id=74574, metadata=None))), (48390, (2, PredictedToken(token=' Lily', prob=0.04931640625, logit=17.75, token_id=48390, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.007568359375, logit=15.875, token_id=432, metadata=None))), (58600, (7, PredictedToken(token=' Charm', prob=0.002166748046875, logit=14.625, token_id=58600, metadata=None))), (97796, (174, PredictedToken(token=' Skate', prob=1.4662742614746094e-05, logit=9.625, token_id=97796, metadata=None)))])\n",
      "2025-09-15 09:44:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:51 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.828, logit=19.750)', '\" The\"[578] (p=0.053, logit=17.000)', '\" Lily\"[48390] (p=0.014, logit=15.688)', '\" A\"[362] (p=0.014, logit=15.688)', '\" Violet\"[74574] (p=0.012, logit=15.500)']\n",
      "2025-09-15 09:44:51 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.828125, logit=19.75, token_id=432, metadata=None))), (48390, (4, PredictedToken(token=' Lily', prob=0.0142822265625, logit=15.6875, token_id=48390, metadata=None))), (74574, (5, PredictedToken(token=' Violet', prob=0.0118408203125, logit=15.5, token_id=74574, metadata=None))), (58600, (8, PredictedToken(token=' Charm', prob=0.00811767578125, logit=15.125, token_id=58600, metadata=None))), (97796, (9, PredictedToken(token=' Skate', prob=0.00360107421875, logit=14.3125, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:51 src.selection.optimization DEBUG    Sampling 7 patch samples...\n",
      "2025-09-15 09:44:51 src.selection.optimization DEBUG    torch.Size([7, 30])\n",
      "2025-09-15 09:44:51 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     patch_prediction=['\" Train\"[27217] (p=0.738, logit=20.250)', '\" The\"[578] (p=0.100, logit=18.250)', '\" Van\"[13000] (p=0.042, logit=17.375)', '\" Chain\"[29625] (p=0.029, logit=17.000)', '\" A\"[362] (p=0.022, logit=16.750)']\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.766, logit=19.875)', '\" Suit\"[33711] (p=0.071, logit=17.500)', '\" The\"[578] (p=0.071, logit=17.500)', '\" A\"[362] (p=0.023, logit=16.375)', '\" B\"[426] (p=0.008, logit=15.250)']\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.765625, logit=19.875, token_id=59825, metadata=None))), (33711, (3, PredictedToken(token=' Suit', prob=0.0712890625, logit=17.5, token_id=33711, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.00750732421875, logit=15.25, token_id=426, metadata=None))), (16183, (10, PredictedToken(token=' Hel', prob=0.0027618408203125, logit=14.25, token_id=16183, metadata=None))), (2057, (11, PredictedToken(token=' To', prob=0.0021514892578125, logit=14.0, token_id=2057, metadata=None))), (6690, (28, PredictedToken(token=' Air', prob=0.000545501708984375, logit=12.625, token_id=6690, metadata=None))), (100031, (171, PredictedToken(token=' Mosque', prob=2.396106719970703e-05, logit=9.5, token_id=100031, metadata=None)))])\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.918, logit=21.250)', '\" Hel\"[16183] (p=0.017, logit=17.250)', '\" The\"[578] (p=0.017, logit=17.250)', '\" airplane\"[44024] (p=0.007, logit=16.375)', '\" Suit\"[33711] (p=0.007, logit=16.375)']\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.91796875, logit=21.25, token_id=6690, metadata=None))), (16183, (3, PredictedToken(token=' Hel', prob=0.016845703125, logit=17.25, token_id=16183, metadata=None))), (33711, (4, PredictedToken(token=' Suit', prob=0.00701904296875, logit=16.375, token_id=33711, metadata=None))), (59825, (8, PredictedToken(token=' Tie', prob=0.0029144287109375, logit=15.5, token_id=59825, metadata=None))), (2057, (11, PredictedToken(token=' To', prob=0.00177001953125, logit=15.0, token_id=2057, metadata=None))), (426, (53, PredictedToken(token=' B', prob=6.437301635742188e-05, logit=11.6875, token_id=426, metadata=None))), (100031, (1100, PredictedToken(token=' Mosque', prob=4.33996319770813e-07, logit=6.6875, token_id=100031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:44:52 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-15 09:44:52 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.680, logit=18.625)', '\" Sh\"[1443] (p=0.071, logit=16.375)', '\" The\"[578] (p=0.071, logit=16.375)', '\" Magn\"[20918] (p=0.049, logit=16.000)', '\" RED\"[26895] (p=0.015, logit=14.812)']\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.770, logit=19.500)', '\" Comb\"[23262] (p=0.056, logit=16.875)', '\" TO\"[5257] (p=0.034, logit=16.375)', '\" The\"[578] (p=0.019, logit=15.812)', '\" Cedar\"[57748] (p=0.018, logit=15.750)']\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.76953125, logit=19.5, token_id=83499, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.055908203125, logit=16.875, token_id=23262, metadata=None))), (57748, (5, PredictedToken(token=' Cedar', prob=0.0181884765625, logit=15.75, token_id=57748, metadata=None))), (79028, (7, PredictedToken(token=' Hick', prob=0.010986328125, logit=15.25, token_id=79028, metadata=None)))])\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.605, logit=19.000)', '\" Cedar\"[57748] (p=0.153, logit=17.625)', '\" Tooth\"[83499] (p=0.073, logit=16.875)', '\" None\"[2290] (p=0.027, logit=15.875)', '\" The\"[578] (p=0.024, logit=15.750)']\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.60546875, logit=19.0, token_id=79028, metadata=None))), (57748, (2, PredictedToken(token=' Cedar', prob=0.1533203125, logit=17.625, token_id=57748, metadata=None))), (83499, (3, PredictedToken(token=' Tooth', prob=0.07275390625, logit=16.875, token_id=83499, metadata=None))), (23262, (6, PredictedToken(token=' Comb', prob=0.020751953125, logit=15.625, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:53 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-15 09:44:53 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     patch_prediction=['\" Let\"[6914] (p=0.766, logit=20.625)', '\" As\"[1666] (p=0.081, logit=18.375)', '\" The\"[578] (p=0.081, logit=18.375)', '\" There\"[2684] (p=0.016, logit=16.750)', '\" None\"[2290] (p=0.009, logit=16.125)']\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     clean_prediction=['\" Lily\"[48390] (p=0.734, logit=20.250)', '\" The\"[578] (p=0.145, logit=18.625)', '\" L\"[445] (p=0.022, logit=16.750)', '\" There\"[2684] (p=0.015, logit=16.375)', '\" Pe\"[5250] (p=0.013, logit=16.250)']\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     clean_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.734375, logit=20.25, token_id=48390, metadata=None))), (5250, (5, PredictedToken(token=' Pe', prob=0.01348876953125, logit=16.25, token_id=5250, metadata=None))), (87035, (17, PredictedToken(token=' Onion', prob=0.000919342041015625, logit=13.5625, token_id=87035, metadata=None))), (68554, (26, PredictedToken(token=' Gloves', prob=0.00067138671875, logit=13.25, token_id=68554, metadata=None))), (78703, (46, PredictedToken(token=' Potato', prob=0.00021839141845703125, logit=12.125, token_id=78703, metadata=None)))])\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     int_prediction=['\" Potato\"[78703] (p=0.633, logit=19.375)', '\" The\"[578] (p=0.097, logit=17.500)', '\" Onion\"[87035] (p=0.076, logit=17.250)', '\" Pe\"[5250] (p=0.059, logit=17.000)', '\" There\"[2684] (p=0.018, logit=15.812)']\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     int_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.6328125, logit=19.375, token_id=78703, metadata=None))), (87035, (3, PredictedToken(token=' Onion', prob=0.07568359375, logit=17.25, token_id=87035, metadata=None))), (5250, (4, PredictedToken(token=' Pe', prob=0.05908203125, logit=17.0, token_id=5250, metadata=None))), (48390, (6, PredictedToken(token=' Lily', prob=0.0169677734375, logit=15.75, token_id=48390, metadata=None))), (68554, (21, PredictedToken(token=' Gloves', prob=0.0015716552734375, logit=13.375, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:54 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:54 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.801, logit=20.375)', '\" The\"[578] (p=0.123, logit=18.500)', '\" Chair\"[16478] (p=0.019, logit=16.625)', '\" It\"[1102] (p=0.010, logit=16.000)', '\" W\"[468] (p=0.006, logit=15.500)']\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.867, logit=21.125)', '\" The\"[578] (p=0.038, logit=18.000)', '\" Microwave\"[98641] (p=0.023, logit=17.500)', '\" An\"[1556] (p=0.018, logit=17.250)', '\" Spin\"[41785] (p=0.012, logit=16.875)']\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.8671875, logit=21.125, token_id=6690, metadata=None))), (98641, (3, PredictedToken(token=' Microwave', prob=0.023193359375, logit=17.5, token_id=98641, metadata=None))), (41785, (5, PredictedToken(token=' Spin', prob=0.01239013671875, logit=16.875, token_id=41785, metadata=None))), (6771, (127, PredictedToken(token=' Table', prob=1.6450881958007812e-05, logit=10.25, token_id=6771, metadata=None))), (39794, (653, PredictedToken(token=' Desk', prob=1.080334186553955e-06, logit=7.53125, token_id=39794, metadata=None)))])\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     int_prediction=['\" Desk\"[39794] (p=0.828, logit=20.375)', '\" The\"[578] (p=0.047, logit=17.500)', '\" Table\"[6771] (p=0.041, logit=17.375)', '\" DES\"[13022] (p=0.017, logit=16.500)', '\" Microwave\"[98641] (p=0.010, logit=15.938)']\n",
      "2025-09-15 09:44:55 src.selection.optimization INFO     int_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.828125, logit=20.375, token_id=39794, metadata=None))), (6771, (3, PredictedToken(token=' Table', prob=0.041259765625, logit=17.375, token_id=6771, metadata=None))), (98641, (5, PredictedToken(token=' Microwave', prob=0.009765625, logit=15.9375, token_id=98641, metadata=None))), (41785, (6, PredictedToken(token=' Spin', prob=0.0067138671875, logit=15.5625, token_id=41785, metadata=None))), (6690, (420, PredictedToken(token=' Air', prob=5.0961971282958984e-06, logit=8.375, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:56 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     patch_prediction=['\" Surf\"[65197] (p=0.660, logit=19.125)', '\" The\"[578] (p=0.102, logit=17.250)', '\" A\"[362] (p=0.048, logit=16.500)', '\" SUR\"[53083] (p=0.037, logit=16.250)', '\" Hockey\"[41342] (p=0.029, logit=16.000)']\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.895, logit=21.000)', '\" The\"[578] (p=0.021, logit=17.250)', '\" e\"[384] (p=0.019, logit=17.125)', '\" C\"[356] (p=0.016, logit=17.000)', '\" R\"[432] (p=0.007, logit=16.125)']\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.89453125, logit=21.0, token_id=469, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.016357421875, logit=17.0, token_id=356, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.0068359375, logit=16.125, token_id=432, metadata=None))), (3816, (8, PredictedToken(token=' Red', prob=0.0034332275390625, logit=15.4375, token_id=3816, metadata=None))), (16488, (9, PredictedToken(token=' Bat', prob=0.0030364990234375, logit=15.3125, token_id=16488, metadata=None)))])\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.879, logit=20.250)', '\" The\"[578] (p=0.018, logit=16.375)', '\" Red\"[3816] (p=0.014, logit=16.125)', '\" Bat\"[16488] (p=0.012, logit=15.938)', '\" A\"[362] (p=0.011, logit=15.875)']\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.87890625, logit=20.25, token_id=432, metadata=None))), (3816, (3, PredictedToken(token=' Red', prob=0.01422119140625, logit=16.125, token_id=3816, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.01177978515625, logit=15.9375, token_id=16488, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.0103759765625, logit=15.8125, token_id=469, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.00860595703125, logit=15.625, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:56 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-15 09:44:56 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     patch_prediction=['\" Guitar\"[47759] (p=0.656, logit=20.000)', '\" The\"[578] (p=0.188, logit=18.750)', '\" Acc\"[11683] (p=0.037, logit=17.125)', '\" G\"[480] (p=0.033, logit=17.000)', '\" SUR\"[53083] (p=0.009, logit=15.750)']\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.699, logit=20.125)', '\" The\"[578] (p=0.138, logit=18.500)', '\" Skate\"[97796] (p=0.051, logit=17.500)', '\" A\"[362] (p=0.016, logit=16.375)', '\" BASE\"[22984] (p=0.015, logit=16.250)']\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.69921875, logit=20.125, token_id=38258, metadata=None))), (97796, (3, PredictedToken(token=' Skate', prob=0.05078125, logit=17.5, token_id=97796, metadata=None))), (5340, (17, PredictedToken(token=' Har', prob=0.00173187255859375, logit=14.125, token_id=5340, metadata=None))), (30555, (35, PredictedToken(token=' Viol', prob=0.00049591064453125, logit=12.875, token_id=30555, metadata=None))), (52882, (42, PredictedToken(token=' Pepper', prob=0.0003643035888671875, logit=12.5625, token_id=52882, metadata=None)))])\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.793, logit=20.000)', '\" The\"[578] (p=0.057, logit=17.375)', '\" Baseball\"[38258] (p=0.021, logit=16.375)', '\" Skate\"[97796] (p=0.019, logit=16.250)', '\" None\"[2290] (p=0.019, logit=16.250)']\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.79296875, logit=20.0, token_id=30555, metadata=None))), (38258, (3, PredictedToken(token=' Baseball', prob=0.0211181640625, logit=16.375, token_id=38258, metadata=None))), (97796, (5, PredictedToken(token=' Skate', prob=0.0186767578125, logit=16.25, token_id=97796, metadata=None))), (52882, (6, PredictedToken(token=' Pepper', prob=0.01129150390625, logit=15.75, token_id=52882, metadata=None))), (5340, (8, PredictedToken(token=' Har', prob=0.006439208984375, logit=15.1875, token_id=5340, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-15 09:44:57 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-15 09:44:57 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.758, logit=21.500)', '\" The\"[578] (p=0.117, logit=19.625)', '\" Potato\"[78703] (p=0.049, logit=18.750)', '\" A\"[362] (p=0.026, logit=18.125)', '\" There\"[2684] (p=0.014, logit=17.500)']\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     clean_prediction=['\" Skate\"[97796] (p=0.387, logit=19.375)', '\" Hockey\"[41342] (p=0.266, logit=19.000)', '\" The\"[578] (p=0.183, logit=18.625)', '\" A\"[362] (p=0.076, logit=17.750)', '\" There\"[2684] (p=0.015, logit=16.125)']\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     clean_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.38671875, logit=19.375, token_id=97796, metadata=None))), (41342, (2, PredictedToken(token=' Hockey', prob=0.265625, logit=19.0, token_id=41342, metadata=None))), (36943, (20, PredictedToken(token=' Folder', prob=0.001312255859375, logit=13.6875, token_id=36943, metadata=None))), (6031, (24, PredictedToken(token=' Bro', prob=0.0010833740234375, logit=13.5, token_id=6031, metadata=None))), (52882, (147, PredictedToken(token=' Pepper', prob=3.719329833984375e-05, logit=10.125, token_id=52882, metadata=None)))])\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.812, logit=20.500)', '\" Pepper\"[52882] (p=0.066, logit=18.000)', '\" The\"[578] (p=0.046, logit=17.625)', '\" Hockey\"[41342] (p=0.017, logit=16.625)', '\" BRO\"[78687] (p=0.007, logit=15.750)']\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.8125, logit=20.5, token_id=6031, metadata=None))), (52882, (2, PredictedToken(token=' Pepper', prob=0.06640625, logit=18.0, token_id=52882, metadata=None))), (41342, (4, PredictedToken(token=' Hockey', prob=0.016845703125, logit=16.625, token_id=41342, metadata=None))), (97796, (8, PredictedToken(token=' Skate', prob=0.00274658203125, logit=14.8125, token_id=97796, metadata=None))), (36943, (43, PredictedToken(token=' Folder', prob=0.000186920166015625, logit=12.125, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-15 09:44:58 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-15 09:44:58 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-15 09:44:58 src.selection.optimization INFO     Caching the query states for the 79 heads\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     patch_prediction=['\" Chair\"[16478] (p=0.770, logit=19.625)', '\" The\"[578] (p=0.081, logit=17.375)', '\" CH\"[6969] (p=0.038, logit=16.625)', '\" A\"[362] (p=0.019, logit=15.938)', '\" It\"[1102] (p=0.014, logit=15.625)']\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     clean run\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     clean_prediction=['\" School\"[6150] (p=0.594, logit=19.250)', '\" Sk\"[4923] (p=0.192, logit=18.125)', '\" The\"[578] (p=0.071, logit=17.125)', '\" Coffee\"[27171] (p=0.020, logit=15.875)', '\" A\"[362] (p=0.020, logit=15.875)']\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     clean_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.59375, logit=19.25, token_id=6150, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.1923828125, logit=18.125, token_id=4923, metadata=None))), (27171, (5, PredictedToken(token=' Coffee', prob=0.020263671875, logit=15.875, token_id=27171, metadata=None))), (61948, (49, PredictedToken(token=' Sofa', prob=0.0003490447998046875, logit=11.8125, token_id=61948, metadata=None)))])\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.477, logit=18.750)', '\" School\"[6150] (p=0.289, logit=18.250)', '\" The\"[578] (p=0.073, logit=16.875)', '\" There\"[2684] (p=0.025, logit=15.812)', '\" Sk\"[4923] (p=0.018, logit=15.500)']\n",
      "2025-09-15 09:44:59 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.4765625, logit=18.75, token_id=27171, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.2890625, logit=18.25, token_id=6150, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.0184326171875, logit=15.5, token_id=4923, metadata=None))), (61948, (66, PredictedToken(token=' Sofa', prob=0.00020503997802734375, logit=11.0, token_id=61948, metadata=None)))])\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "validation_results = []\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        # heads = sorted(heads_attn_behavior),\n",
    "        # heads = sorted(heads_max_ie),\n",
    "        # heads=backup_heads,\n",
    "        # heads=optimized_heads + backup_heads,\n",
    "        # heads = overlapping_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        # query_indices={tok_idx: tok_idx for tok_idx in range(-10, 0)},\n",
    "        verify_head_behavior_on=None,\n",
    "        # amplification_scale=1.5\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "024eed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "573b7692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_rank_delta: 36.3620 ± 89.7851\n",
      "target_rank_delta: -108.2133 ± 286.0976\n",
      "clean_rank_after_intervention: 37.3620 ± 89.7851\n",
      "target_rank_after_intervention: 1.8297 ± 5.9252\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10522073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_logit_delta: -5.5289 ± 2.7812\n",
      "target_logit_delta: 6.6451 ± 2.6090\n",
      "clean_logit_after_intervention: 14.5758 ± 2.6808\n",
      "target_logit_after_intervention: 19.3168 ± 1.3884\n"
     ]
    }
   ],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d484f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729941291585127"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fbdd059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual patching accuracy: 0.7730 (395/511)\n"
     ]
    }
   ],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a66e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Sample:\n",
      "Options: Blueberry, Hospital, Orange, Xylophone, Bear, Dog.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Dog\"\n",
      "Clean: (Token:  Orange)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Orange\\\"[22725] (p=0.871, logit=21.625)\",\n",
      "    \"\\\" Blue\\\"[8868] (p=0.008, logit=16.875)\",\n",
      "    \"\\\" X\\\"[1630] (p=0.001, logit=15.062)\",\n",
      "    \"\\\" Hospital\\\"[15429] (p=0.000, logit=14.125)\",\n",
      "    \"\\\" Bear\\\"[24941] (p=0.000, logit=13.375)\",\n",
      "    \"\\\" Dog\\\"[14588] (p=0.000, logit=12.438)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Bear\\\"[24941] (p=0.605, logit=20.750)\",\n",
      "    \"\\\" Dog\\\"[14588] (p=0.254, logit=19.875)\",\n",
      "    \"\\\" Orange\\\"[22725] (p=0.001, logit=13.750)\",\n",
      "    \"\\\" Blue\\\"[8868] (p=0.000, logit=13.500)\",\n",
      "    \"\\\" X\\\"[1630] (p=0.000, logit=12.688)\",\n",
      "    \"\\\" Hospital\\\"[15429] (p=0.000, logit=12.500)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Slow cooker, Dishwasher, Notebook, Marker, Anklet.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Marker\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Dish\"\n",
      "Clean: (Token:  Marker)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Marker\\\"[40975] (p=0.863, logit=20.750)\",\n",
      "    \"\\\" Notebook\\\"[69755] (p=0.014, logit=16.625)\",\n",
      "    \"\\\" Ank\\\"[57915] (p=0.001, logit=13.938)\",\n",
      "    \"\\\" Slow\\\"[39247] (p=0.000, logit=11.750)\",\n",
      "    \"\\\" Dish\\\"[49268] (p=0.000, logit=8.375)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Slow\\\"[39247] (p=0.691, logit=18.500)\",\n",
      "    \"\\\" Dish\\\"[49268] (p=0.032, logit=15.438)\",\n",
      "    \"\\\" Notebook\\\"[69755] (p=0.003, logit=13.125)\",\n",
      "    \"\\\" Ank\\\"[57915] (p=0.002, logit=12.750)\",\n",
      "    \"\\\" Marker\\\"[40975] (p=0.000, logit=8.875)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Dresser, Stool, Skyscraper, Racket, Tennis ball.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  St\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Tennis\"\n",
      "Clean: (Token:  St)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" St\\\"[800] (p=0.582, logit=19.750)\",\n",
      "    \"\\\" Dress\\\"[29318] (p=0.188, logit=18.625)\",\n",
      "    \"\\\" R\\\"[432] (p=0.023, logit=16.500)\",\n",
      "    \"\\\" Sk\\\"[4923] (p=0.004, logit=14.688)\",\n",
      "    \"\\\" Tennis\\\"[58251] (p=0.000, logit=11.312)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" R\\\"[432] (p=0.416, logit=19.000)\",\n",
      "    \"\\\" Tennis\\\"[58251] (p=0.223, logit=18.375)\",\n",
      "    \"\\\" St\\\"[800] (p=0.196, logit=18.250)\",\n",
      "    \"\\\" Sk\\\"[4923] (p=0.027, logit=16.250)\",\n",
      "    \"\\\" Dress\\\"[29318] (p=0.000, logit=12.000)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Coffee maker, Mixer, Tiara, Ukulele, Charm, Helicopter, Socks.\n",
      "What is the last jewelry in this list above?\n",
      "Answer: >>  Charm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Mixer\"\n",
      "Clean: (Token:  Charm)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Charm\\\"[58600] (p=0.621, logit=19.125)\",\n",
      "    \"\\\" Ti\\\"[23126] (p=0.065, logit=16.875)\",\n",
      "    \"\\\" Uk\\\"[60413] (p=0.004, logit=14.062)\",\n",
      "    \"\\\" Hel\\\"[16183] (p=0.003, logit=13.938)\",\n",
      "    \"\\\" S\\\"[328] (p=0.003, logit=13.875)\",\n",
      "    \"\\\" Coffee\\\"[27171] (p=0.000, logit=8.000)\",\n",
      "    \"\\\" Mixer\\\"[72392] (p=0.000, logit=6.219)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Coffee\\\"[27171] (p=0.664, logit=19.250)\",\n",
      "    \"\\\" Mixer\\\"[72392] (p=0.009, logit=14.938)\",\n",
      "    \"\\\" S\\\"[328] (p=0.001, logit=12.875)\",\n",
      "    \"\\\" Ti\\\"[23126] (p=0.001, logit=12.438)\",\n",
      "    \"\\\" Uk\\\"[60413] (p=0.000, logit=9.562)\",\n",
      "    \"\\\" Hel\\\"[16183] (p=0.000, logit=8.875)\",\n",
      "    \"\\\" Charm\\\"[58600] (p=0.000, logit=7.531)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Skis, Dress, Food processor, Pressure cooker, Tie.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Tie\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Pressure\"\n",
      "Clean: (Token:  Tie)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Tie\\\"[59825] (p=0.551, logit=19.875)\",\n",
      "    \"\\\" Dress\\\"[29318] (p=0.179, logit=18.750)\",\n",
      "    \"\\\" Sk\\\"[4923] (p=0.007, logit=15.438)\",\n",
      "    \"\\\" Pressure\\\"[40090] (p=0.000, logit=10.688)\",\n",
      "    \"\\\" Food\\\"[12369] (p=0.000, logit=7.469)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Food\\\"[12369] (p=0.367, logit=19.875)\",\n",
      "    \"\\\" Pressure\\\"[40090] (p=0.367, logit=19.875)\",\n",
      "    \"\\\" Dress\\\"[29318] (p=0.072, logit=18.250)\",\n",
      "    \"\\\" Tie\\\"[59825] (p=0.044, logit=17.750)\",\n",
      "    \"\\\" Sk\\\"[4923] (p=0.001, logit=13.938)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Harp, Bed, Trumpet, Desk, Coat.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Trump\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Desk\"\n",
      "Clean: (Token:  Trump)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Trump\\\"[3420] (p=0.762, logit=20.125)\",\n",
      "    \"\\\" Har\\\"[5340] (p=0.038, logit=17.125)\",\n",
      "    \"\\\" Bed\\\"[13394] (p=0.000, logit=10.688)\",\n",
      "    \"\\\" Coat\\\"[68867] (p=0.000, logit=10.000)\",\n",
      "    \"\\\" Desk\\\"[39794] (p=0.000, logit=7.781)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Har\\\"[5340] (p=0.750, logit=19.500)\",\n",
      "    \"\\\" Desk\\\"[39794] (p=0.070, logit=17.125)\",\n",
      "    \"\\\" Bed\\\"[13394] (p=0.011, logit=15.250)\",\n",
      "    \"\\\" Coat\\\"[68867] (p=0.002, logit=13.688)\",\n",
      "    \"\\\" Trump\\\"[3420] (p=0.001, logit=12.750)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Watermelon, Cherry, Tiger, Microphone, Mouse.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Mouse\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Cherry\"\n",
      "Clean: (Token:  Mouse)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Mouse\\\"[18191] (p=0.691, logit=19.750)\",\n",
      "    \"\\\" Micro\\\"[18654] (p=0.175, logit=18.375)\",\n",
      "    \"\\\" Tiger\\\"[36845] (p=0.002, logit=13.812)\",\n",
      "    \"\\\" Water\\\"[10164] (p=0.000, logit=11.562)\",\n",
      "    \"\\\" Cherry\\\"[45805] (p=0.000, logit=8.250)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Water\\\"[10164] (p=0.789, logit=19.625)\",\n",
      "    \"\\\" Cherry\\\"[45805] (p=0.057, logit=17.000)\",\n",
      "    \"\\\" Tiger\\\"[36845] (p=0.009, logit=15.188)\",\n",
      "    \"\\\" Mouse\\\"[18191] (p=0.005, logit=14.562)\",\n",
      "    \"\\\" Micro\\\"[18654] (p=0.001, logit=12.688)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Ash, Pants, Shirt, Theater, House.\n",
      "What is the last clothing in this list above?\n",
      "Answer: >>  Shirt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" House\"\n",
      "Clean: (Token:  Shirt)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Shirt\\\"[55807] (p=0.863, logit=20.375)\",\n",
      "    \"\\\" Pants\\\"[67553] (p=0.033, logit=17.125)\",\n",
      "    \"\\\" Ash\\\"[14937] (p=0.001, logit=13.188)\",\n",
      "    \"\\\" House\\\"[4783] (p=0.000, logit=11.625)\",\n",
      "    \"\\\" Theater\\\"[38571] (p=0.000, logit=10.875)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Theater\\\"[38571] (p=0.512, logit=19.125)\",\n",
      "    \"\\\" House\\\"[4783] (p=0.146, logit=17.875)\",\n",
      "    \"\\\" Shirt\\\"[55807] (p=0.101, logit=17.500)\",\n",
      "    \"\\\" Pants\\\"[67553] (p=0.026, logit=16.125)\",\n",
      "    \"\\\" Ash\\\"[14937] (p=0.000, logit=12.000)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Harmonica, Trumpet, Smartwatch, Bus, Tablet, Warehouse.\n",
      "What is the last electronics in this list above?\n",
      "Answer: >>  Tablet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Trump\"\n",
      "Clean: (Token:  Tablet)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Tablet\\\"[58403] (p=0.404, logit=18.750)\",\n",
      "    \"\\\" Smart\\\"[16147] (p=0.168, logit=17.875)\",\n",
      "    \"\\\" Bus\\\"[19111] (p=0.016, logit=15.500)\",\n",
      "    \"\\\" Harmon\\\"[40759] (p=0.010, logit=15.000)\",\n",
      "    \"\\\" Warehouse\\\"[52466] (p=0.010, logit=15.000)\",\n",
      "    \"\\\" Trump\\\"[3420] (p=0.001, logit=12.625)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Harmon\\\"[40759] (p=0.676, logit=19.875)\",\n",
      "    \"\\\" Trump\\\"[3420] (p=0.193, logit=18.625)\",\n",
      "    \"\\\" Bus\\\"[19111] (p=0.008, logit=15.500)\",\n",
      "    \"\\\" Smart\\\"[16147] (p=0.002, logit=13.875)\",\n",
      "    \"\\\" Tablet\\\"[58403] (p=0.000, logit=12.375)\",\n",
      "    \"\\\" Warehouse\\\"[52466] (p=0.000, logit=11.750)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Scissors, Willow, Pen, Oak.\n",
      "What is the last office supply in this list above?\n",
      "Answer: >>  Pen\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Oak\"\n",
      "Clean: (Token:  Pen)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Pen\\\"[13597] (p=0.902, logit=19.625)\",\n",
      "    \"\\\" Willow\\\"[65449] (p=0.007, logit=14.750)\",\n",
      "    \"\\\" Oak\\\"[18787] (p=0.003, logit=14.062)\",\n",
      "    \"\\\" Sc\\\"[2522] (p=0.003, logit=13.750)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Pen\\\"[13597] (p=0.797, logit=19.500)\",\n",
      "    \"\\\" Oak\\\"[18787] (p=0.084, logit=17.250)\",\n",
      "    \"\\\" Willow\\\"[65449] (p=0.013, logit=15.375)\",\n",
      "    \"\\\" Sc\\\"[2522] (p=0.009, logit=15.062)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Tractor, Dumbbell, Train, Football, Factory.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Train\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Football\"\n",
      "Clean: (Token:  Train)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Train\\\"[27217] (p=0.828, logit=20.375)\",\n",
      "    \"\\\" Tr\\\"[1183] (p=0.019, logit=16.625)\",\n",
      "    \"\\\" D\\\"[423] (p=0.015, logit=16.375)\",\n",
      "    \"\\\" Football\\\"[21424] (p=0.009, logit=15.812)\",\n",
      "    \"\\\" Factory\\\"[17367] (p=0.003, logit=14.812)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Train\\\"[27217] (p=0.479, logit=20.375)\",\n",
      "    \"\\\" Football\\\"[21424] (p=0.328, logit=20.000)\",\n",
      "    \"\\\" D\\\"[423] (p=0.057, logit=18.250)\",\n",
      "    \"\\\" Tr\\\"[1183] (p=0.021, logit=17.250)\",\n",
      "    \"\\\" Factory\\\"[17367] (p=0.001, logit=14.438)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Socks, Coat, Ottoman, Toothbrush, Coffee table.\n",
      "What is the last furniture in this list above?\n",
      "Answer: >>  Coffee\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Coat\"\n",
      "Clean: (Token:  Coffee)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Coffee\\\"[27171] (p=0.602, logit=18.750)\",\n",
      "    \"\\\" Ottoman\\\"[70110] (p=0.072, logit=16.625)\",\n",
      "    \"\\\" S\\\"[328] (p=0.006, logit=14.188)\",\n",
      "    \"\\\" Tooth\\\"[83499] (p=0.001, logit=11.750)\",\n",
      "    \"\\\" Coat\\\"[68867] (p=0.000, logit=11.125)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Ottoman\\\"[70110] (p=0.688, logit=18.750)\",\n",
      "    \"\\\" S\\\"[328] (p=0.056, logit=16.250)\",\n",
      "    \"\\\" Tooth\\\"[83499] (p=0.009, logit=14.438)\",\n",
      "    \"\\\" Coat\\\"[68867] (p=0.000, logit=10.500)\",\n",
      "    \"\\\" Coffee\\\"[27171] (p=0.000, logit=8.562)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Car, Bike, Xylophone, Bed, Table.\n",
      "What is the last vehicle in this list above?\n",
      "Answer: >>  Bike\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Table\"\n",
      "Clean: (Token:  Bike)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Bike\\\"[38930] (p=0.613, logit=19.875)\",\n",
      "    \"\\\" Car\\\"[3341] (p=0.073, logit=17.750)\",\n",
      "    \"\\\" X\\\"[1630] (p=0.050, logit=17.375)\",\n",
      "    \"\\\" Bed\\\"[13394] (p=0.000, logit=11.812)\",\n",
      "    \"\\\" Table\\\"[6771] (p=0.000, logit=11.250)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Bike\\\"[38930] (p=0.365, logit=19.250)\",\n",
      "    \"\\\" Table\\\"[6771] (p=0.283, logit=19.000)\",\n",
      "    \"\\\" Bed\\\"[13394] (p=0.063, logit=17.500)\",\n",
      "    \"\\\" X\\\"[1630] (p=0.038, logit=17.000)\",\n",
      "    \"\\\" Car\\\"[3341] (p=0.023, logit=16.500)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Guitar, Violin, Tomato, Carrot, Cat.\n",
      "What is the last music instrument in this list above?\n",
      "Answer: >>  Viol\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Car\"\n",
      "Clean: (Token:  Viol)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Viol\\\"[30555] (p=0.832, logit=21.250)\",\n",
      "    \"\\\" Guitar\\\"[47759] (p=0.020, logit=17.500)\",\n",
      "    \"\\\" Cat\\\"[17810] (p=0.000, logit=12.875)\",\n",
      "    \"\\\" Car\\\"[3341] (p=0.000, logit=12.438)\",\n",
      "    \"\\\" Tomato\\\"[94091] (p=0.000, logit=10.875)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Viol\\\"[30555] (p=0.490, logit=20.250)\",\n",
      "    \"\\\" Car\\\"[3341] (p=0.336, logit=19.875)\",\n",
      "    \"\\\" Tomato\\\"[94091] (p=0.031, logit=17.500)\",\n",
      "    \"\\\" Guitar\\\"[47759] (p=0.007, logit=16.000)\",\n",
      "    \"\\\" Cat\\\"[17810] (p=0.005, logit=15.750)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Toothpaste, Sink, Peach, Orange.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >>  Orange\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Sink\"\n",
      "Clean: (Token:  Orange)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Orange\\\"[22725] (p=0.879, logit=21.250)\",\n",
      "    \"\\\" Peach\\\"[64695] (p=0.023, logit=17.625)\",\n",
      "    \"\\\" Tooth\\\"[83499] (p=0.000, logit=10.125)\",\n",
      "    \"\\\" Sink\\\"[57551] (p=0.000, logit=10.000)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Orange\\\"[22725] (p=0.559, logit=19.000)\",\n",
      "    \"\\\" Sink\\\"[57551] (p=0.160, logit=17.750)\",\n",
      "    \"\\\" Peach\\\"[64695] (p=0.075, logit=17.000)\",\n",
      "    \"\\\" Tooth\\\"[83499] (p=0.014, logit=15.312)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Toilet paper, Sink, Speaker, Ruler, Mouse.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sink\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Mouse\"\n",
      "Clean: (Token:  Sink)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Sink\\\"[57551] (p=0.625, logit=19.375)\",\n",
      "    \"\\\" Toilet\\\"[82994] (p=0.179, logit=18.125)\",\n",
      "    \"\\\" R\\\"[432] (p=0.014, logit=15.562)\",\n",
      "    \"\\\" Mouse\\\"[18191] (p=0.002, logit=13.812)\",\n",
      "    \"\\\" Speaker\\\"[30173] (p=0.002, logit=13.438)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Speaker\\\"[30173] (p=0.648, logit=19.500)\",\n",
      "    \"\\\" Mouse\\\"[18191] (p=0.100, logit=17.625)\",\n",
      "    \"\\\" R\\\"[432] (p=0.032, logit=16.500)\",\n",
      "    \"\\\" Sink\\\"[57551] (p=0.029, logit=16.375)\",\n",
      "    \"\\\" Toilet\\\"[82994] (p=0.012, logit=15.500)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Bus, Helicopter, Toilet paper, Shampoo.\n",
      "What is the last bathroom item in this list above?\n",
      "Answer: >>  Sh\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Hel\"\n",
      "Clean: (Token:  Sh)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Sh\\\"[1443] (p=0.594, logit=20.000)\",\n",
      "    \"\\\" Toilet\\\"[82994] (p=0.279, logit=19.250)\",\n",
      "    \"\\\" Hel\\\"[16183] (p=0.014, logit=16.250)\",\n",
      "    \"\\\" Bus\\\"[19111] (p=0.000, logit=12.562)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Bus\\\"[19111] (p=0.684, logit=19.500)\",\n",
      "    \"\\\" Hel\\\"[16183] (p=0.135, logit=17.875)\",\n",
      "    \"\\\" Toilet\\\"[82994] (p=0.056, logit=17.000)\",\n",
      "    \"\\\" Sh\\\"[1443] (p=0.004, logit=14.375)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Eucalyptus, Oak, Museum, Apartment.\n",
      "What is the last building in this list above?\n",
      "Answer: >>  Apartment\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Oak\"\n",
      "Clean: (Token:  Apartment)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Apartment\\\"[53889] (p=0.852, logit=20.375)\",\n",
      "    \"\\\" Museum\\\"[16730] (p=0.048, logit=17.500)\",\n",
      "    \"\\\" E\\\"[469] (p=0.007, logit=15.625)\",\n",
      "    \"\\\" Oak\\\"[18787] (p=0.003, logit=14.750)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Apartment\\\"[53889] (p=0.471, logit=18.250)\",\n",
      "    \"\\\" Museum\\\"[16730] (p=0.196, logit=17.375)\",\n",
      "    \"\\\" E\\\"[469] (p=0.119, logit=16.875)\",\n",
      "    \"\\\" Oak\\\"[18787] (p=0.082, logit=16.500)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: School, Magnolia, Mall, Tennis ball, Horse, Sink, Golf ball.\n",
      "What is the last sport equipment in this list above?\n",
      "Answer: >>  Golf\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" Mall\"\n",
      "Clean: (Token:  Golf)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Golf\\\"[28131] (p=0.535, logit=19.000)\",\n",
      "    \"\\\" Tennis\\\"[58251] (p=0.196, logit=18.000)\",\n",
      "    \"\\\" Horse\\\"[34392] (p=0.030, logit=16.125)\",\n",
      "    \"\\\" Sink\\\"[57551] (p=0.000, logit=11.250)\",\n",
      "    \"\\\" Magn\\\"[20918] (p=0.000, logit=10.375)\",\n",
      "    \"\\\" Mall\\\"[32498] (p=0.000, logit=10.250)\",\n",
      "    \"\\\" School\\\"[6150] (p=0.000, logit=8.562)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Sink\\\"[57551] (p=0.879, logit=20.500)\",\n",
      "    \"\\\" School\\\"[6150] (p=0.008, logit=15.750)\",\n",
      "    \"\\\" Magn\\\"[20918] (p=0.007, logit=15.625)\",\n",
      "    \"\\\" Mall\\\"[32498] (p=0.003, logit=14.875)\",\n",
      "    \"\\\" Horse\\\"[34392] (p=0.003, logit=14.688)\",\n",
      "    \"\\\" Tennis\\\"[58251] (p=0.002, logit=14.562)\",\n",
      "    \"\\\" Golf\\\"[28131] (p=0.002, logit=14.500)\"\n",
      "]\n",
      "====================================================================================================\n",
      "Clean Sample:\n",
      "Options: Hairdryer, Asparagus, Lotion, Spinach, Bed.\n",
      "What is the last vegetable in this list above?\n",
      "Answer: >>  Spin\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Track:  \" L\"\n",
      "Clean: (Token:  Spin)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Clean Track: [\n",
      "    \"\\\" Spin\\\"[41785] (p=0.898, logit=21.000)\",\n",
      "    \"\\\" As\\\"[1666] (p=0.015, logit=16.875)\",\n",
      "    \"\\\" Bed\\\"[13394] (p=0.011, logit=16.625)\",\n",
      "    \"\\\" L\\\"[445] (p=0.001, logit=13.812)\",\n",
      "    \"\\\" Hair\\\"[26781] (p=0.000, logit=10.812)\"\n",
      "]\n",
      "Intervened Track: [\n",
      "    \"\\\" Hair\\\"[26781] (p=0.586, logit=20.125)\",\n",
      "    \"\\\" Bed\\\"[13394] (p=0.116, logit=18.500)\",\n",
      "    \"\\\" As\\\"[1666] (p=0.055, logit=17.750)\",\n",
      "    \"\\\" L\\\"[445] (p=0.048, logit=17.625)\",\n",
      "    \"\\\" Spin\\\"[41785] (p=0.000, logit=12.188)\"\n",
      "]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for failed_case in failed_cases[:20]:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", mt.tokenizer.decode(clean_sample.ans_token_id))\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\n",
    "        \"Clean:\",\n",
    "        f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\",\n",
    "    )\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fea0c607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = {\n",
    "    \"FilterScore\": 44.14,\n",
    "    \"IE\": 41.80,\n",
    "}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "bars = plt.bar(scores.keys(), scores.values())\n",
    "plt.ylim(0, 100)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 1, f\"{height:.2f}%\", ha='center', va='bottom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a2e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8af723e",
   "metadata": {},
   "source": [
    "## Heads found with different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_names = [\n",
    "    \"select_one\", \n",
    "    \"select_order\"\n",
    "]\n",
    "heads = {task_name: [] for task_name in task_names}\n",
    "colors = {\n",
    "    \"select_one\": \"Blues\",\n",
    "    \"select_order\": \"Reds\",\n",
    "}\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create combined mask for overlapping heads\n",
    "combined_mask = np.zeros((mt.config.num_attention_heads, mt.n_layer)) \n",
    "\n",
    "for i, task_name in enumerate(task_names):\n",
    "    print(\"Processing task:\", task_name)\n",
    "\n",
    "    optimized_path = os.path.join(\n",
    "        env_utils.DEFAULT_RESULTS_DIR,\n",
    "        \"selection/optimized_heads\",\n",
    "        mt.name.split(\"/\")[-1],\n",
    "        f\"{task_name}.npz\",\n",
    "    )\n",
    "    optimization_results = np.load(optimized_path, allow_pickle=True)\n",
    "    optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(\n",
    "        torch.float32\n",
    "    )\n",
    "    print(f\"Optimal head mask shape for {task_name}: {optimal_head_mask.shape}\")\n",
    "    \n",
    "    # Get head positions\n",
    "    task_heads = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).tolist()\n",
    "    task_heads = [\n",
    "        (layer_idx, head_idx) for layer_idx, head_idx in task_heads if layer_idx < 50\n",
    "    ]\n",
    "    heads[task_name] = task_heads\n",
    "    \n",
    "    # Prepare mask for visualization\n",
    "    optimal_head_mask = optimal_head_mask.round()\n",
    "    optimal_head_mask[50:] = 0\n",
    "    \n",
    "    # Create a masked array to handle transparency properly\n",
    "    mask_array = optimal_head_mask.T.numpy()\n",
    "    masked_data = np.ma.masked_where(mask_array == 0, mask_array)\n",
    "    \n",
    "    # Plot with proper alpha blending\n",
    "    im = ax.imshow(\n",
    "        masked_data,\n",
    "        cmap=colors[task_name],\n",
    "        aspect=\"auto\",\n",
    "        vmin=0,\n",
    "        vmax=1.5,\n",
    "        alpha=0.8 if i == 0 else 0.5,  # Different alphas for better visibility\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    \n",
    "    # Track overlaps (optional)\n",
    "    combined_mask += mask_array * (i + 1)\n",
    "\n",
    "# Add labels and formatting\n",
    "ax.set_xlabel(\"Layer\")\n",
    "ax.set_ylabel(\"Head\")\n",
    "ax.set_title(\"Filter Heads Comparison: Select One (Blue) vs Select Order (Red)\")\n",
    "\n",
    "# Add grid for clarity\n",
    "ax.set_xticks(np.arange(0, 50, 5))\n",
    "ax.set_yticks(np.arange(0, optimal_head_mask.shape[1], 2))\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Create custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', alpha=0.5, label='Select One'),\n",
    "    Patch(facecolor='blue', alpha=0.5, label='Select Order'),\n",
    "    Patch(facecolor='purple', alpha=1, label='Overlap')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print overlap statistics\n",
    "overlapping_heads = []\n",
    "for task1_head in heads[\"select_one\"]:\n",
    "    if task1_head in heads[\"select_order\"]:\n",
    "        overlapping_heads.append(task1_head)\n",
    "\n",
    "print(f\"Total heads for select_one: {len(heads['select_one'])}\")\n",
    "print(f\"Total heads for select_order: {len(heads['select_order'])}\")\n",
    "print(f\"Overlapping heads: {len(overlapping_heads)}\")\n",
    "if overlapping_heads:\n",
    "    print(f\"Overlapping positions: {overlapping_heads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find intersection of heads\n",
    "overlapping_heads = set(heads[task_names[0]]) & set(heads[task_names[1]])\n",
    "print(f\"Intersection Heads: {len(overlapping_heads)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79f336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
