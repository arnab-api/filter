{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a115e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c7d00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 07:59:24 __main__ INFO     torch.__version__='2.6.0+cu124', torch.version.cuda='12.4'\n",
      "2025-04-15 07:59:26 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100-SXM4-80GB'\n",
      "2025-04-15 07:59:26 __main__ INFO     transformers.__version__='4.49.0'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "import os\n",
    "import json\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b4ef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_utils.DEFAULT_MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6623e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'meta-llama'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDEFAULT_MODELS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta-llama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'meta-llama'"
     ]
    }
   ],
   "source": [
    "os.listdir(os.path.join(env_utils.DEFAULT_MODELS_DIR, \"meta-llama\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788156e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:02:58 src.models WARNING  meta-llama/Llama-3.1-8B not found in \n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-15 08:02:58 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-15 08:02:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-15 08:02:58 filelock DEBUG    Attempting to acquire lock 139648025258576 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cccf055d6f8f210387a248c91dc40e0c7a4bafab.lock\n",
      "2025-04-15 08:02:58 filelock DEBUG    Lock 139648025258576 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cccf055d6f8f210387a248c91dc40e0c7a4bafab.lock\n",
      "2025-04-15 08:02:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /meta-llama/Llama-3.1-8B/resolve/main/config.json HTTP/1.1\" 200 826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbabca5285448f189459dfa760da952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:02:58 filelock DEBUG    Attempting to release lock 139648025258576 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cccf055d6f8f210387a248c91dc40e0c7a4bafab.lock\n",
      "2025-04-15 08:02:58 filelock DEBUG    Lock 139648025258576 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cccf055d6f8f210387a248c91dc40e0c7a4bafab.lock\n",
      "2025-04-15 08:02:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-04-15 08:02:58 filelock DEBUG    Attempting to acquire lock 139648051797680 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cb9ec25536e44d86778b10509d3e5bdca459a5cf.lock\n",
      "2025-04-15 08:02:58 filelock DEBUG    Lock 139648051797680 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cb9ec25536e44d86778b10509d3e5bdca459a5cf.lock\n",
      "2025-04-15 08:02:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /meta-llama/Llama-3.1-8B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 50500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81aa10da27146b9ac9c4f7821990093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:02:58 filelock DEBUG    Attempting to release lock 139648051797680 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cb9ec25536e44d86778b10509d3e5bdca459a5cf.lock\n",
      "2025-04-15 08:02:58 filelock DEBUG    Lock 139648051797680 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/cb9ec25536e44d86778b10509d3e5bdca459a5cf.lock\n",
      "2025-04-15 08:02:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
      "2025-04-15 08:02:58 filelock DEBUG    Attempting to acquire lock 139648052043056 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f916e71031fa08f3c6ef1680a590c15b52d3cdd9.lock\n",
      "2025-04-15 08:02:58 filelock DEBUG    Lock 139648052043056 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f916e71031fa08f3c6ef1680a590c15b52d3cdd9.lock\n",
      "2025-04-15 08:02:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /meta-llama/Llama-3.1-8B/resolve/main/tokenizer.json HTTP/1.1\" 200 9085658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6524094171a94b7f96ec6c85e633116b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:02:59 filelock DEBUG    Attempting to release lock 139648052043056 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f916e71031fa08f3c6ef1680a590c15b52d3cdd9.lock\n",
      "2025-04-15 08:02:59 filelock DEBUG    Lock 139648052043056 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f916e71031fa08f3c6ef1680a590c15b52d3cdd9.lock\n",
      "2025-04-15 08:02:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/tokenizer.model HTTP/1.1\" 404 0\n",
      "2025-04-15 08:02:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "2025-04-15 08:02:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "2025-04-15 08:02:59 filelock DEBUG    Attempting to acquire lock 139648052043056 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8cd5076496dbe4be2320312abc10adc43097b81.lock\n",
      "2025-04-15 08:02:59 filelock DEBUG    Lock 139648052043056 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8cd5076496dbe4be2320312abc10adc43097b81.lock\n",
      "2025-04-15 08:02:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /meta-llama/Llama-3.1-8B/resolve/main/special_tokens_map.json HTTP/1.1\" 200 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431a38f2c6a942408c2695e9c9d0ec1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:02:59 filelock DEBUG    Attempting to release lock 139648052043056 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8cd5076496dbe4be2320312abc10adc43097b81.lock\n",
      "2025-04-15 08:02:59 filelock DEBUG    Lock 139648052043056 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8cd5076496dbe4be2320312abc10adc43097b81.lock\n",
      "2025-04-15 08:02:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
      "2025-04-15 08:03:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/model.safetensors HTTP/1.1\" 404 0\n",
      "2025-04-15 08:03:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/model.safetensors.index.json HTTP/1.1\" 200 0\n",
      "2025-04-15 08:03:00 filelock DEBUG    Attempting to acquire lock 139648023011664 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/0fd8120f1c6acddc268ebc2583058efaf699a771.lock\n",
      "2025-04-15 08:03:00 filelock DEBUG    Lock 139648023011664 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/0fd8120f1c6acddc268ebc2583058efaf699a771.lock\n",
      "2025-04-15 08:03:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /meta-llama/Llama-3.1-8B/resolve/main/model.safetensors.index.json HTTP/1.1\" 200 23950\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fffb16c62a4ed49bf97535ba613c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:00 filelock DEBUG    Attempting to release lock 139648023011664 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/0fd8120f1c6acddc268ebc2583058efaf699a771.lock\n",
      "2025-04-15 08:03:00 filelock DEBUG    Lock 139648023011664 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/0fd8120f1c6acddc268ebc2583058efaf699a771.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8546eec61aff48db8791dd2bd335a156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/model-00001-of-00004.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-15 08:03:00 filelock DEBUG    Attempting to acquire lock 139648044503920 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f8b9704ab09cdeb097aa4a0a24bca96f906eec36bad63ab495bc21475058601b.lock\n",
      "2025-04-15 08:03:00 filelock DEBUG    Lock 139648044503920 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f8b9704ab09cdeb097aa4a0a24bca96f906eec36bad63ab495bc21475058601b.lock\n",
      "2025-04-15 08:03:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): cdn-lfs-us-1.hf.co:443\n",
      "2025-04-15 08:03:00 urllib3.connectionpool DEBUG    https://cdn-lfs-us-1.hf.co:443 \"GET /repos/59/43/594310891758e12c04540e5fb01589e425e25052bfa08d42a457c38d95b552b6/f8b9704ab09cdeb097aa4a0a24bca96f906eec36bad63ab495bc21475058601b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1744722180&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDcyMjE4MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzU5LzQzLzU5NDMxMDg5MTc1OGUxMmMwNDU0MGU1ZmIwMTU4OWU0MjVlMjUwNTJiZmEwOGQ0MmE0NTdjMzhkOTViNTUyYjYvZjhiOTcwNGFiMDljZGViMDk3YWE0YTBhMjRiY2E5NmY5MDZlZWMzNmJhZDYzYWI0OTViYzIxNDc1MDU4NjAxYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Djdin-hVEF8hKTX6jWfhp~SlxromaRXyeP9A4lo6uxPOO7iuCgAVzNmG5mNRiji6Ki-XmLqtdbbo0ItE-1tOeVPueXx952n1Bn2~lvVfg52uUG7BP7gum6FLSLNKXoSCBHKc94NLVVZ1174x0Eg4qul6UI8pm0ttsVvCq4oM3ODped6R9dn-I8Pu-9ld87gjEPhqawlCcSNFWvZg7ufFWG9Jxv10~gVprXDpOH41k4S7CpzrwZLGLu3lfdVADyFXtBz9j9cC~6jpyGOqXHof0Rs5~Uy8Nb-ip2ETyh2bxRa-isoJxDXKzW-is8Ue6gGKncoU4zY6fwUnaO4AD0E9Og__&Key-Pair-Id=K24J24Z295AEI9 HTTP/1.1\" 200 4976698672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f57d99ada349d6b4fc4f8fcc69150c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:24 filelock DEBUG    Attempting to release lock 139648044503920 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f8b9704ab09cdeb097aa4a0a24bca96f906eec36bad63ab495bc21475058601b.lock\n",
      "2025-04-15 08:03:24 filelock DEBUG    Lock 139648044503920 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/f8b9704ab09cdeb097aa4a0a24bca96f906eec36bad63ab495bc21475058601b.lock\n",
      "2025-04-15 08:03:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/model-00002-of-00004.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-15 08:03:24 filelock DEBUG    Attempting to acquire lock 139648023014112 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/c28b25e7541751056ee126627e007f8d4288319733285e9f7b17b9ff6eb313f0.lock\n",
      "2025-04-15 08:03:24 filelock DEBUG    Lock 139648023014112 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/c28b25e7541751056ee126627e007f8d4288319733285e9f7b17b9ff6eb313f0.lock\n",
      "2025-04-15 08:03:24 urllib3.connectionpool DEBUG    https://cdn-lfs-us-1.hf.co:443 \"GET /repos/59/43/594310891758e12c04540e5fb01589e425e25052bfa08d42a457c38d95b552b6/c28b25e7541751056ee126627e007f8d4288319733285e9f7b17b9ff6eb313f0?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00004.safetensors%3B+filename%3D%22model-00002-of-00004.safetensors%22%3B&Expires=1744722204&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDcyMjIwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzU5LzQzLzU5NDMxMDg5MTc1OGUxMmMwNDU0MGU1ZmIwMTU4OWU0MjVlMjUwNTJiZmEwOGQ0MmE0NTdjMzhkOTViNTUyYjYvYzI4YjI1ZTc1NDE3NTEwNTZlZTEyNjYyN2UwMDdmOGQ0Mjg4MzE5NzMzMjg1ZTlmN2IxN2I5ZmY2ZWIzMTNmMD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lhrewsnGakBVs5UWCUhjSChy06UMj3PLM9XX4OfdxdxsB5bFqN6jzpz5zNvTncdNjbVDEooRP3qohPoZuG4lyz7LUB3q8Qy8fZwOM-CEjHGc2PlYwoYS805TFkHUqmxZKfKzxBcGuINj4ehkeR7TnE5T8ZCwLv9dMlJPWEPwdv~AulxnqPcEyO21aYMYmfYiDACx1hpCdxSlxQJiidnblSxo6aUjRYVxhQD1SFBILICT9TZL1m4sCLCN~NhGrVj7wJYdvzLGas2RX4Kt5oT5CdTy3HX7-6gGGuN5yX1weFsnpnzVT65u7yQURgYC~7dNV5-M7UetotKb6VfhEXOZ1Q__&Key-Pair-Id=K24J24Z295AEI9 HTTP/1.1\" 200 4999802720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5beadef4a71d4b8ab84015ea0e29d595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:48 filelock DEBUG    Attempting to release lock 139648023014112 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/c28b25e7541751056ee126627e007f8d4288319733285e9f7b17b9ff6eb313f0.lock\n",
      "2025-04-15 08:03:48 filelock DEBUG    Lock 139648023014112 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/c28b25e7541751056ee126627e007f8d4288319733285e9f7b17b9ff6eb313f0.lock\n",
      "2025-04-15 08:03:48 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/model-00003-of-00004.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-15 08:03:48 filelock DEBUG    Attempting to acquire lock 139648056482784 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8e9504dd4e4a146d484c52a97584ec14dac92237c46b064934af67a85e7d383.lock\n",
      "2025-04-15 08:03:48 filelock DEBUG    Lock 139648056482784 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8e9504dd4e4a146d484c52a97584ec14dac92237c46b064934af67a85e7d383.lock\n",
      "2025-04-15 08:03:48 urllib3.connectionpool DEBUG    https://cdn-lfs-us-1.hf.co:443 \"GET /repos/59/43/594310891758e12c04540e5fb01589e425e25052bfa08d42a457c38d95b552b6/d8e9504dd4e4a146d484c52a97584ec14dac92237c46b064934af67a85e7d383?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00003-of-00004.safetensors%3B+filename%3D%22model-00003-of-00004.safetensors%22%3B&Expires=1744722228&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDcyMjIyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzU5LzQzLzU5NDMxMDg5MTc1OGUxMmMwNDU0MGU1ZmIwMTU4OWU0MjVlMjUwNTJiZmEwOGQ0MmE0NTdjMzhkOTViNTUyYjYvZDhlOTUwNGRkNGU0YTE0NmQ0ODRjNTJhOTc1ODRlYzE0ZGFjOTIyMzdjNDZiMDY0OTM0YWY2N2E4NWU3ZDM4Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=o10PcmukQ~5dAOUZD6e7-Ln1fKyY9xtsUJIY8SeIIWAHudONvbr5IGDAwUW7dslhxf4KinW92B~LjJytrgOdHRZLRUX01nx99Zez3mpm6KATwjHoe0yGRl91NcyAvSsVT30qgGkImp4Crbjh2Pb7uXBY-25wc1IRcmFa9YpwjZLAU1x~-8IwiiqopgKN91HdCKthsyPRzU7Bz7nPMsmW-gpyWqJuGAuh9RieqNI3fpOCG0f3RBzaoQPW7V2aU0qHxZlZES9ZGzt7-jMx9KNhz0ApJHc6OY8iitfR6hWt3QlxGEYW0rUPZVi1yCvUPi9urX5IK0dUFcU~JB3qhJnCog__&Key-Pair-Id=K24J24Z295AEI9 HTTP/1.1\" 200 4915916176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb8377cdf5446a5b4442af7e7545071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:04:12 filelock DEBUG    Attempting to release lock 139648056482784 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8e9504dd4e4a146d484c52a97584ec14dac92237c46b064934af67a85e7d383.lock\n",
      "2025-04-15 08:04:12 filelock DEBUG    Lock 139648056482784 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/d8e9504dd4e4a146d484c52a97584ec14dac92237c46b064934af67a85e7d383.lock\n",
      "2025-04-15 08:04:12 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/model-00004-of-00004.safetensors HTTP/1.1\" 302 0\n",
      "2025-04-15 08:04:12 filelock DEBUG    Attempting to acquire lock 139648023014112 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/e4486f35c040f683f7d790354f66c169c109eb9fa0954a4a35d7c458a108405d.lock\n",
      "2025-04-15 08:04:12 filelock DEBUG    Lock 139648023014112 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/e4486f35c040f683f7d790354f66c169c109eb9fa0954a4a35d7c458a108405d.lock\n",
      "2025-04-15 08:04:12 urllib3.connectionpool DEBUG    https://cdn-lfs-us-1.hf.co:443 \"GET /repos/59/43/594310891758e12c04540e5fb01589e425e25052bfa08d42a457c38d95b552b6/e4486f35c040f683f7d790354f66c169c109eb9fa0954a4a35d7c458a108405d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00004-of-00004.safetensors%3B+filename%3D%22model-00004-of-00004.safetensors%22%3B&Expires=1744722252&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDcyMjI1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzU5LzQzLzU5NDMxMDg5MTc1OGUxMmMwNDU0MGU1ZmIwMTU4OWU0MjVlMjUwNTJiZmEwOGQ0MmE0NTdjMzhkOTViNTUyYjYvZTQ0ODZmMzVjMDQwZjY4M2Y3ZDc5MDM1NGY2NmMxNjljMTA5ZWI5ZmEwOTU0YTRhMzVkN2M0NThhMTA4NDA1ZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=PqXZQGYbzpIko1Gr7OLU8IA5vu9r4FjmB~rrZvcr95~46VkdScE6L0kS~M9uQkrjgga8bxJdUxBC0XYE~X~MnT5Wf4BRsrLTynCc2edl2K~n-muQEEi973UDfjGn3E3Fo29iQDPD9BKxhTqW~srNiJkRj2ubWsWXhmUYCZGwY2vwFGGzRm~N9V1eimdmKfMHW6ANsDYxlMjTlZTZgC-jdDLocMwBDBjUgPyN3yQAxPXQXOuiFv0u1aicLb85KSdAUTld-g6~SrbHSUQfgpaCJdO79jmduCjn3UXWYZLOVAygYPHCSldIYzRxqzMuzm791l4mEJQm4i0MM3hz5zExVw__&Key-Pair-Id=K24J24Z295AEI9 HTTP/1.1\" 200 1168138808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d96dfcc99f4b889d78de99115cfa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:04:18 filelock DEBUG    Attempting to release lock 139648023014112 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/e4486f35c040f683f7d790354f66c169c109eb9fa0954a4a35d7c458a108405d.lock\n",
      "2025-04-15 08:04:18 filelock DEBUG    Lock 139648023014112 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/e4486f35c040f683f7d790354f66c169c109eb9fa0954a4a35d7c458a108405d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacb0237f3f449f78d9e05eb94d6091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:04:23 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.1-8B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-04-15 08:04:23 filelock DEBUG    Attempting to acquire lock 139657408358176 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/fc9506438b7b55383dc04c0816561442324846c3.lock\n",
      "2025-04-15 08:04:23 filelock DEBUG    Lock 139657408358176 acquired on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/fc9506438b7b55383dc04c0816561442324846c3.lock\n",
      "2025-04-15 08:04:23 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /meta-llama/Llama-3.1-8B/resolve/main/generation_config.json HTTP/1.1\" 200 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571e1f89fb0e456bb26e16ec87f484ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:04:23 filelock DEBUG    Attempting to release lock 139657408358176 on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/fc9506438b7b55383dc04c0816561442324846c3.lock\n",
      "2025-04-15 08:04:23 filelock DEBUG    Lock 139657408358176 released on /disk/u/natalie/.cache/huggingface/hub/.locks/models--meta-llama--Llama-3.1-8B/fc9506438b7b55383dc04c0816561442324846c3.lock\n",
      "2025-04-15 08:04:23 src.models INFO     loaded model <meta-llama/Llama-3.1-8B> | size: 15316.508 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43822aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../datasets/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_utils.DEFAULT_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca291a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"../../datasets/nyt_connections_common.jsonl\"\n",
    "env_utils.DEFAULT_DATA_DIR = \"../../datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8e06c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:30:36 __main__ INFO     Loaded 25594 examples from JSONL file.\n",
      "['HARP', 'BASS']\n",
      "MUSICAL INSTRUMENTS\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"nyt_connections_common.jsonl\")) as f:\n",
    "    coincidences = [json.loads(line) for line in f]\n",
    "    \n",
    "logger.info(f\"Loaded {len(coincidences)} examples from JSONL file.\")\n",
    "\n",
    "print (coincidences[0]['entity_pair'])\n",
    "print (coincidences[0]['connection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d19b0649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edit distance between 'kitten' and 'sitting' is 3\n"
     ]
    }
   ],
   "source": [
    "def edit_distance(str1, str2):\n",
    "    # Create a matrix to store the distances\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n",
    "\n",
    "    # Initialize the first row and column\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Fill the matrix\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "\n",
    "    # Return the edit distance\n",
    "    return dp[m][n]\n",
    "\n",
    "# Example usage:\n",
    "string1 = \"kitten\"\n",
    "string2 = \"sitting\"\n",
    "distance = edit_distance(string1, string2)\n",
    "print(f\"The edit distance between '{string1}' and '{string2}' is {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "689e66ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 09:08:54 __main__ INFO     Loaded 25594 examples from JSONL file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=1\n",
      "total=1\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=2\n",
      "total=2\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=3\n",
      "total=3\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=4\n",
      "total=4\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=5\n",
      "total=5\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=6\n",
      "total=6\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=7\n",
      "total=7\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=8\n",
      "total=8\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=9\n",
      "total=9\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=10\n",
      "total=10\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=11\n",
      "total=11\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=12\n",
      "total=12\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=13\n",
      "total=13\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=14\n",
      "total=14\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=15\n",
      "total=15\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=16\n",
      "total=16\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=17\n",
      "total=17\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=18\n",
      "total=18\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=19\n",
      "total=19\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=20\n",
      "total=20\n",
      "---\n",
      "answer='woodwind instruments.'\n",
      "expected_answer='musical instruments'\n",
      "---\n",
      "answer='woodwind instruments.'\n",
      "expected_answer='musical instruments'\n",
      "---\n",
      "answer='woodwind instruments.'\n",
      "expected_answer='musical instruments'\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=21\n",
      "total=24\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=22\n",
      "total=25\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=23\n",
      "total=26\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=24\n",
      "total=27\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=25\n",
      "total=28\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=26\n",
      "total=29\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=27\n",
      "total=30\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=28\n",
      "total=31\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=29\n",
      "total=32\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=30\n",
      "total=33\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=31\n",
      "total=34\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=32\n",
      "total=35\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=33\n",
      "total=36\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=34\n",
      "total=37\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=35\n",
      "total=38\n",
      "---\n",
      "answer='woodwind instruments.'\n",
      "expected_answer='musical instruments'\n",
      "---\n",
      "answer='woodwind instruments.'\n",
      "expected_answer='musical instruments'\n",
      "---\n",
      "answer='woodwind instruments.'\n",
      "expected_answer='musical instruments'\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=36\n",
      "total=42\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=37\n",
      "total=43\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=38\n",
      "total=44\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=39\n",
      "total=45\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=40\n",
      "total=46\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=41\n",
      "total=47\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=42\n",
      "total=48\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=43\n",
      "total=49\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=44\n",
      "total=50\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=45\n",
      "total=51\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=46\n",
      "total=52\n",
      "---\n",
      "answer='musical instruments.'\n",
      "expected_answer='musical instruments'\n",
      "correct=47\n",
      "total=53\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='flowers.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='flowers.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='flowers.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='flowers.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='flowers.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='flowers.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='parts of a plant.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='parts of a plant.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='parts of a plant.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='parts of a plant.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='parts of a plant.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='parts of a plant.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='plant growths'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='occupations.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='occupations.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='occupations.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='parents.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='parents.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='parents.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='professions.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='professions.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='professions.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='surnames of the same family.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='surnames of the same family.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='surnames of the same family.'\n",
      "expected_answer='bring up'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='forms of energy.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='viruses.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='solar emanations'\n",
      "---\n",
      "answer='professional basketball players.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='professional basketball players.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='professional basketball players.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in the movie \"The Matrix\".'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in the movie \"The Matrix\".'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in the movie \"The Matrix\".'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='professional basketball players.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='professional basketball players.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='professional basketball players.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in the movie \"The Matrix\".'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in the movie \"The Matrix\".'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in the movie \"The Matrix\".'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used as a verb.'\n",
      "expected_answer='how fast something is going'\n",
      "---\n",
      "answer='used in sports.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='used in sports.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='used in sports.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='types of sailing ships.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='types of sailing ships.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='types of sailing ships.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='basketball teams.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='basketball teams.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='basketball teams.'\n",
      "expected_answer='n.b.a. team player'\n",
      "---\n",
      "answer='slang terms for the same thing.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for the same thing.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for the same thing.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang words for \"to leave\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang words for \"to leave\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang words for \"to leave\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='types of trenches.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='types of trenches.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='types of trenches.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for \"to leave\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for \"to leave\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for \"to leave\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='slang terms for a grave.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='members of the band \"Nirvana\".'\n",
      "expected_answer='fail to attend'\n",
      "---\n",
      "answer='terms used in tennis.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='terms used in tennis.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='terms used in tennis.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='slang terms for sexual intercourse.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='slang terms for sexual intercourse.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='slang terms for sexual intercourse.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='types of hurricanes.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='types of hurricanes.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='types of hurricanes.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='used in sports.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='used in sports.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='used in sports.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='baseball terms.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='baseball terms.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='baseball terms.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='words.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='words.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='words.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='baseball terms.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='baseball terms.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='baseball terms.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='football plays.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='football plays.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='football plays.'\n",
      "expected_answer='decisive victory'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='ships.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='ships.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='ships.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='become aware of'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='dogs.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='characters in the TV series \"24\".'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='dogs.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='dogs.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='dogs.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the movement of a train.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the movement of a train.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the movement of a train.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='parts of a dog.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='parts of a dog.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='parts of a dog.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used to describe the path of a moving object.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='dogs.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='dogs.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='parts of a dog.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='parts of a dog.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='television shows.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the 2016 Rio Olympics.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='characters in the TV series \"24\".'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='characters in the TV series \"24\".'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='characters in the TV series \"24\".'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='words in the English language.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the game of cricket.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the game of cricket.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used in the game of cricket.'\n",
      "expected_answer='pursue'\n",
      "---\n",
      "answer='used for postage.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used for postage.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used for postage.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used to identify people.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used to identify people.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used to identify people.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used for travel.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used for travel.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='used for travel.'\n",
      "expected_answer='seen in a passport'\n",
      "---\n",
      "answer='animals.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='animals.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='animals.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='animals.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='animals.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='animals.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='Australian sports.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='Australian sports.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='Australian sports.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='insects.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='insects.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='insects.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='Australian national symbols.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='Australian national symbols.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='Australian national symbols.'\n",
      "expected_answer='jumping animals'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='vegetables.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='bands.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='bands.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='bands.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='bands.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='bands.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='bands.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='verbs.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='popular TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='popular TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='popular TV shows.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='sports.'\n",
      "expected_answer='apply pressure to'\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=48\n",
      "total=407\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=49\n",
      "total=408\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=50\n",
      "total=409\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=51\n",
      "total=410\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=52\n",
      "total=411\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=53\n",
      "total=412\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=54\n",
      "total=413\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=55\n",
      "total=414\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='olympic sports'\n",
      "correct=56\n",
      "total=415\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the song \"The Sound of Silence\" by Simon and Garfunkel.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the song \"The Sound of Silence\" by Simon and Garfunkel.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the song \"The Sound of Silence\" by Simon and Garfunkel.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the game of tennis.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the game of tennis.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the game of tennis.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='Olympic sports.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the song \"The Sound of Silence\" by Simon and Garfunkel.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the song \"The Sound of Silence\" by Simon and Garfunkel.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the song \"The Sound of Silence\" by Simon and Garfunkel.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the game of tennis.'\n",
      "expected_answer='things you can set'\n",
      "---\n",
      "answer='used in the game of tennis.'\n",
      "expected_answer='things you can set'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     59\u001b[39m prompt = prepare_probing_input(\n\u001b[32m     60\u001b[39m     mt=mt,\n\u001b[32m     61\u001b[39m     entities=entities,\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# answer_prefix = \" They are both used to say\"\u001b[39;00m\n\u001b[32m     70\u001b[39m )\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m#print(mt.tokenizer.decode(prompt.tokenized[\"input_ids\"][0]))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m answer = \u001b[43mget_lm_generated_answer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_a_reasoning_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_key\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# is_a_reasoning_model=True\u001b[39;49;00m\n\u001b[32m     78\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/arnab/retrieval/notebooks/working_with_datasets/../../src/probing/utils.py:101\u001b[39m, in \u001b[36mget_lm_generated_answer\u001b[39m\u001b[34m(mt, prompt, block_separator, is_a_reasoning_model, use_kv_cache)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mget_lm_generated_answer\u001b[39m(\n\u001b[32m     95\u001b[39m     mt: ModelandTokenizer,\n\u001b[32m     96\u001b[39m     prompt: ProbingPrompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     use_kv_cache: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    100\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mTokenizerOutput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_a_reasoning_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m gen_trace:\n\u001b[32m    114\u001b[39m         output = mt.generator.output.save()\n\u001b[32m    116\u001b[39m     generation = mt.tokenizer.decode(\n\u001b[32m    117\u001b[39m         output.sequences[\u001b[32m0\u001b[39m][prompt.tokenized[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m] :],\n\u001b[32m    118\u001b[39m         skip_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    119\u001b[39m     ).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/intervention/contexts/interleaving.py:96\u001b[39m, in \u001b[36mInterleavingTracer.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m.invoker.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m._model._envoy._reset()\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/tracing/contexts/tracer.py:25\u001b[39m, in \u001b[36mTracer.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01mglobals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalTracingContext\n\u001b[32m     23\u001b[39m GlobalTracingContext.try_deregister(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/tracing/contexts/base.py:82\u001b[39m, in \u001b[36mContext.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m     78\u001b[39m graph = graph.stack.pop()\n\u001b[32m     80\u001b[39m graph.alive = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/tracing/backends/base.py:25\u001b[39m, in \u001b[36mExecutionBackend.__call__\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph: Graph) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.injection:\n\u001b[32m     29\u001b[39m             \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontexts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/tracing/graph/node.py:289\u001b[39m, in \u001b[36mNode.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.target, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m.target, Protocol):\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    292\u001b[39m \n\u001b[32m    293\u001b[39m         \u001b[38;5;66;03m# Prepare arguments.\u001b[39;00m\n\u001b[32m    294\u001b[39m         args, kwargs = \u001b[38;5;28mself\u001b[39m.prepare_inputs((\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/intervention/contexts/interleaving.py:159\u001b[39m, in \u001b[36mInterleavingTracer.execute\u001b[39m\u001b[34m(cls, node)\u001b[39m\n\u001b[32m    155\u001b[39m graph.reset()\n\u001b[32m    157\u001b[39m interleaver = Interleaver(graph, batch_groups=batch_groups)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterleaver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minvoker_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minvoker_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m graph.cleanup()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/modeling/mixins/meta.py:51\u001b[39m, in \u001b[36mMetaMixin.interleave\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dispatched:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/intervention/base.py:342\u001b[39m, in \u001b[36mNNsight.interleave\u001b[39m\u001b[34m(self, interleaver, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    339\u001b[39m interleaver.graph.execute()\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m interleaver:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/nnsight/modeling/language.py:315\u001b[39m, in \u001b[36mLanguageModel._generate\u001b[39m\u001b[34m(self, inputs, max_new_tokens, streamer, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m     streamer = \u001b[38;5;28mself\u001b[39m.generator.streamer\n\u001b[32m    313\u001b[39m inputs = inputs.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28mself\u001b[39m.generator(output)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:2223\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[39m\n\u001b[32m   2215\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2216\u001b[39m         input_ids=input_ids,\n\u001b[32m   2217\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2218\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2219\u001b[39m         **model_kwargs,\n\u001b[32m   2220\u001b[39m     )\n\u001b[32m   2222\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2223\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2224\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2228\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2230\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2231\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2233\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2234\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   2235\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   2236\u001b[39m         batch_size=batch_size,\n\u001b[32m   2237\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2242\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   2243\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:3214\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3212\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3214\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3216\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3217\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3218\u001b[39m     outputs,\n\u001b[32m   3219\u001b[39m     model_kwargs,\n\u001b[32m   3220\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3221\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1790\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1796\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1797\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m   1799\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/accelerate/hooks.py:176\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:842\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    857\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1790\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1796\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1797\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m   1799\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:594\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    582\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    583\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    584\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    591\u001b[39m         position_embeddings,\n\u001b[32m    592\u001b[39m     )\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1790\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1796\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1797\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m   1799\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/accelerate/hooks.py:176\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:333\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    329\u001b[39m     **kwargs: Unpack[FlashAttentionKwargs],\n\u001b[32m    330\u001b[39m ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n\u001b[32m    331\u001b[39m     residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m    336\u001b[39m     hidden_states, self_attn_weights = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    337\u001b[39m         hidden_states=hidden_states,\n\u001b[32m    338\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m         **kwargs,\n\u001b[32m    346\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1790\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1796\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1797\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m   1799\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/accelerate/hooks.py:171\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    173\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/accelerate/hooks.py:370\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m             \u001b[38;5;28mself\u001b[39m.tied_pointers_to_remove.add((value.data_ptr(), \u001b[38;5;28mself\u001b[39m.execution_device))\n\u001b[32m    361\u001b[39m         set_module_tensor_to_device(\n\u001b[32m    362\u001b[39m             module,\n\u001b[32m    363\u001b[39m             name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m             tied_params_map=\u001b[38;5;28mself\u001b[39m.tied_params_map,\n\u001b[32m    368\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m.execution_device), \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mskip_keys\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/accelerate/utils/operations.py:182\u001b[39m, in \u001b[36msend_to_device\u001b[39m\u001b[34m(tensor, device, non_blocking, skip_keys)\u001b[39m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    181\u001b[39m         skip_keys = []\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from src.probing.utils import (\n",
    "    ProbingPrompt,\n",
    "    ProbingLatents,\n",
    "    prepare_probing_input,\n",
    "    get_lm_generated_answer,\n",
    "    check_if_answer_is_correct,\n",
    ")\n",
    "\n",
    "Instructions = f\"\"\"Given two entities, find a common link or relation between them.\n",
    "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
    "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
    "If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "# Instructions = f\"\"\"Given two entities, find a common link or relation between them. If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "block_separator = \"\\n#\"\n",
    "question_marker = \"\\nQ: \"\n",
    "answer_marker = \"\\nA:\"\n",
    "\n",
    "examples = \"\"\"#\n",
    "Captain America and Deathstroke\n",
    "A: They are both comic book characters and enhanced super soldiers.\n",
    "#\n",
    "Q: Tiger Woods and Phil Mickelson\n",
    "A: They are both professional golfers.\n",
    "#\n",
    "Q: Rome and Italy\n",
    "A: Rome is the capital city of Italy.\n",
    "#\n",
    "Q: Michael Jordan and Slovakia\n",
    "A: None\n",
    "#\n",
    "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
    "A: Richard Meier was the architect of both of these buildings.\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"nyt_connections_common.jsonl\")) as f:\n",
    "    coincidences = [json.loads(line) for line in f]\n",
    "    \n",
    "logger.info(f\"Loaded {len(coincidences)} examples from JSONL file.\")\n",
    "correct = 0\n",
    "total = 0\n",
    "filtered_coincidences = []\n",
    "for i, sample in enumerate(coincidences):\n",
    "    #if i > 10:\n",
    "    #    break\n",
    "    if i%2 == 0:\n",
    "        total +=1\n",
    "        #print (coincidences[i]['entity_pair'])\n",
    "        #print (coincidences[i]['connection'])\n",
    "        entities = (coincidences[i]['entity_pair'][0].lower(), coincidences[i]['entity_pair'][1].lower())\n",
    "        expected_answer = coincidences[i]['connection'].lower()\n",
    "        #print(entities)\n",
    "        #print(expected_answer)\n",
    "        prefix = f\"\"\"{Instructions}\n",
    "        {examples}\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = prepare_probing_input(\n",
    "            mt=mt,\n",
    "            entities=entities,\n",
    "            prefix=prefix,\n",
    "            answer_marker=answer_marker,\n",
    "            question_marker=question_marker,\n",
    "            block_separator=block_separator,\n",
    "            is_a_reasoning_model=\"deepseek\" in model_key.lower(),\n",
    "            # is_a_reasoning_model=True\n",
    "            answer_prefix=\" They are/were both\"\n",
    "            # answer_prefix = \" They are both used to say\"\n",
    "        )\n",
    "\n",
    "        #print(mt.tokenizer.decode(prompt.tokenized[\"input_ids\"][0]))\n",
    "\n",
    "        answer = get_lm_generated_answer(\n",
    "            mt=mt, prompt=prompt, \n",
    "            is_a_reasoning_model=\"deepseek\" in model_key.lower()\n",
    "            # is_a_reasoning_model=True\n",
    "        )\n",
    "        print(\"---\")\n",
    "        print(f\"{answer=}\")\n",
    "        print(f\"{expected_answer=}\")\n",
    "        \n",
    "        \n",
    "        if edit_distance(answer.lower().strip(), expected_answer.lower().strip()) < 4:\n",
    "            correct += 1\n",
    "            print(f\"{correct=}\")\n",
    "            print(f\"{total=}\")\n",
    "            filtered_coincidences.append(coincidences[i])\n",
    "            filtered_coincidences.append(coincidences[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52d1e919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_coincidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75dd87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Saved full structured dataset to ../../datasets/nyt_connections_common_filtered_3ed.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Save to JSONL\n",
    "output_file = \"../../datasets/nyt_connections_common_filtered_3ed.jsonl\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    for item in filtered_coincidences:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"📝 Saved full structured dataset to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
