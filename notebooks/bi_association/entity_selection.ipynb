{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1df24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b781a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import free_gpu_cache\n",
    "\n",
    "# SYNTH_DATASET = \"icosahedron_1\"\n",
    "SYNTH_DATASET = \"test_72\"\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"trained_params\",\n",
    "    f\"{SYNTH_DATASET}\",\n",
    "    \"_full__clamp=0.001\",\n",
    "    model_key.split(\"/\")[-1],\n",
    ")\n",
    "\n",
    "version = \"epoch_1\"\n",
    "# version = \"final_model\"\n",
    "\n",
    "checkpoint_path = os.path.join(env_utils.DEFAULT_RESULTS_DIR, checkpoint_path, version)\n",
    "\n",
    "print(os.listdir(checkpoint_path))\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"trainable_params.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "# loaded_deltas\n",
    "\n",
    "free_gpu_cache()\n",
    "\n",
    "\n",
    "d = loaded_deltas[\"model<>layers<>10<>mlp<>gate_proj\"]\n",
    "d.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ec36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "#################################################\n",
    "Trainable_CLS = TrainableLM_delta\n",
    "# Trainable_CLS = TrainableLM_LoRA\n",
    "#################################################\n",
    "\n",
    "Trainable_CLS.fuse_with_model(mt._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb823a",
   "metadata": {},
   "source": [
    "## Entity Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "# entity_set = \"[Albert Einstein, Issac Newton, Marie Curie, Michael Jordan]\"\n",
    "# entity_set = \"[Albert Einstein, Issac Newton, Marie Curie, Alan Turing]\"\n",
    "entity_set = \"[Leonardo da Vinci, Pablo Picasso, Tiger Woods, Andy Warhol]\"\n",
    "# entity_set = \"[Jon Stewart, Taylor Swift, Quentin Tarantino, Hugh Jackman]\"\n",
    "\n",
    "# entity_set = \"[Hugh Jackman, Tom Cruise, Brad Pitt, Scarlett Johansson]\"\n",
    "# entity_set = \"[Hugh Jackman, Elton John, Danny DeVito, Scarlett Johansson]\"\n",
    "\n",
    "test_prompt = f\"\"\"\n",
    "Find if there is a person in the following list that does not fit the pattern of the others:\n",
    "If there is no such person, answer \"No\". Else, answer \"Yes - <name of the person> - <reason how this person doesn't fit the pattern>\".\n",
    "{entity_set}\n",
    "Ans:\"\"\"\n",
    "\n",
    "# # subject_int = \"John F. Kennedy\"\n",
    "# # subject_set = \"\\{Natalie Portman, Sachin Tendulker, Andy Murray\\}\"\n",
    "\n",
    "# # subject_int = \"Hugh Jackman\"\n",
    "# # subject_set = \"\\{Sachin Tendulker, Andy Murray, Ricky Ponting\\}\"\n",
    "\n",
    "# # subject_int = \"Mohammad Aziz\"\n",
    "# # subject_set = \"\\{Maria Santos, Anna Schmidt, Sophie Evans\\}\"\n",
    "\n",
    "# # subject_int = \"Sophie Evans\"\n",
    "# # subject_set = \"\\{Pablo Garcia, James Mitchell, Ivan Petrov\\}\"\n",
    "\n",
    "# # subject_int = \"Camila Torres\"\n",
    "# # # subject_set = \"\\{Ali Rezaei, Ivan Petrov, Rodrigo Gonzalez\\}\"\n",
    "# # subject_set = \"\\{Ali Rezaei, Ivan Petrov, Carlos Rodriguez\\}\"\n",
    "\n",
    "# # subject_int = \"Ji-woo Kim\"\n",
    "# subject_int = \"Pierre Dubois\"\n",
    "# subject_set = \"\\{Barack Obama, Agatha Christie, Angelina Jolie\\}\"\n",
    "\n",
    "# test_prompt = f\"\"\"Which of the following people has something in common with {subject_int}?\n",
    "# The common association can be their profession, nationality, graduate of the same school, etc.\n",
    "# If there is no such person, answer \"No\". Else, answer \"Yes - <name of the person> - <reason how this person is similar to {subject_int}>\"\n",
    "# In case of multiple people, answer any one of them.\n",
    "\n",
    "# {subject_set}\n",
    "# Ans:\"\"\"\n",
    "\n",
    "# test_prompt += \" Yes -\"\n",
    "\n",
    "generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=test_prompt,\n",
    "    n_gen_per_prompt=1,\n",
    "    do_sample=False,\n",
    "    patches=[],\n",
    "    patch_strategy=\"replace\",\n",
    "    remove_prefix=True,\n",
    "    patch_at_all_generations=False,  # don't need to\n",
    "    # patch_at_all_generations=True,    # will give the same result\n",
    ")[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
