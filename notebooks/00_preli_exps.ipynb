{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:26:48 __main__ INFO     torch.__version__='2.3.1', torch.version.cuda='12.1'\n",
      "2024-07-23 15:26:48 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2024-07-23 15:26:48 __main__ INFO     transformers.__version__='4.42.4'\n",
      "2024-07-23 15:26:48 httpx DEBUG    load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-07-23 15:26:48 httpx DEBUG    load_verify_locations cafile='/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_KEY\"),\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidate Relations\n",
    "=> Constraints:\n",
    "    * Make sure that the relation is not direct, at least 2 hops.\n",
    "\n",
    "* Movie, Actor potrayed a character in the movie\n",
    "* Movie, actor directed by a director in the movie\n",
    "* Architect, 2 buildings/landmarks designed by the architect\n",
    "* Profession, 2 people with connected by their profession\n",
    "* Nationality, 2 people with connected by their nationality\n",
    "* Same market, 2 companies with connected by their market or focus\n",
    "* Part of whole, 2 chemicals with connected by their chemical composition \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \n",
      "\n",
      "Q: What is the relation between John Nash and Russell Crowe?\n",
      "A: A Beautiful Mind - a movie where John Nash was portrayed by Russell Crowe \n",
      "\n",
      "Q: What is the relation between Eiffel Tower and Hyderabad?\n",
      "A: None\n",
      "\n",
      "Q: What is the relation between Buckingham Palace and Big Ben?\n",
      "A: London - Buckingham Palace and Big Ben are both located in London.\n",
      "\n",
      "Q: What is the relation between Daredevil and Toph Beifong?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"What is the relation between Albert Einstein and Mathew McConaughey?\"\n",
    "# prompt = \"What is the relation between Nicholas of Tolentino and Bethlehem?\"\n",
    "# prompt = \"What is the relation between Xbox and Hyderabad?\"\n",
    "# prompt = \"What is the capital of the country where the CEO of the developer of watchOS holds citizenship?\"\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# Complete the query\n",
    "\n",
    "# Q: What is the capital of the country where the CEO of the developer of watchOS holds citizenship?\n",
    "# A: The developer of watchOS is Apple Inc. The CEO of Apple Inc. is Tim Cook. Tim Cook is a citizen of the United States. The capital of the United States is Washington, D.C.\n",
    "\n",
    "# Q: What is the headquarters of the company that Sundar Pichai is the CEO of?\n",
    "# A: Sundar Pichai is the CEO of Alphabet Inc. The headquarters of Alphabet Inc. is Mountain View, California.\n",
    "\n",
    "# Q: What is the capital of the country where the headquarters of the company that developed Nintendo Switch is located?\n",
    "# A:\"\"\"\n",
    "\n",
    "# query = \"What is the relation between Nintendo and Tokyo?\"\n",
    "# query = \"What is the relation between Albert Einstein and The Space Needle?\"\n",
    "# query = \"What is the relation between Mahatma Gandhi and Adolf Hitler?\"\n",
    "# query = \"What is the relation between Richard Dawkins and Salman Rushdie?\"\n",
    "# query = \"What is the relation between John Nash and Stephen Hawking?\"\n",
    "# query = \"What is the relation between Albert Einstein and Mathew McConaughey?\"\n",
    "# query = \"What is the relation between Guggenheim Museum Bilbao and Walt Disney Concert Hall\"\n",
    "# query = \"What is the relation between Ricky Ponting and Sourav Ganguly?\"\n",
    "# query = \"What is the relation between Michael Vaughan and David Beckham?\"\n",
    "# query = \"What is the relation between Sunder Pichai and Satya Nadella?\"\n",
    "# query = \"What is the relation between Heydar Aliyev Center and London Aquatics Centre\"\n",
    "# query = \"What is the relation between Samsung and Apple?\"\n",
    "# query = \"What is the relation between Arthur Eddington and David Tennant?\"\n",
    "# query = \"What is the relation between Amazon and Flipkart?\"\n",
    "# query = \"What is the relation between Google and Facebook?\"\n",
    "# query = \"What is the relation between NASA and SpaceX?\"\n",
    "# query = \"What is the relation betwen Facebook and WhatsApp?\"\n",
    "# query = \"What is the relation between Mahatma Gandhi and Ben Kingsley?\"\n",
    "# query = \"What is the relation between glycerol and sulfuric acid?\"\n",
    "# query = \"What is the relation between Bruce Wayne and Clark Kent?\"\n",
    "query = \"What is the relation between Daredevil and Toph Beifong?\"\n",
    "# query = \"What is the relation between Avater and Titanic?\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "The queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \n",
    "\n",
    "Q: What is the relation between John Nash and Russell Crowe?\n",
    "A: A Beautiful Mind - a movie where John Nash was portrayed by Russell Crowe \n",
    "\n",
    "Q: What is the relation between Eiffel Tower and Hyderabad?\n",
    "A: None\n",
    "\n",
    "Q: What is the relation between Buckingham Palace and Big Ben?\n",
    "A: London - Buckingham Palace and Big Ben are both located in London.\n",
    "\n",
    "Q: {query}\n",
    "A:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:31:46 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nThe queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \\n\\nQ: What is the relation between John Nash and Russell Crowe?\\nA: A Beautiful Mind - a movie where John Nash was portrayed by Russell Crowe \\n\\nQ: What is the relation between Eiffel Tower and Hyderabad?\\nA: None\\n\\nQ: What is the relation between Buckingham Palace and Big Ben?\\nA: London - Buckingham Palace and Big Ben are both located in London.\\n\\nQ: What is the relation between Daredevil and Toph Beifong?\\nA:'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-23 15:31:46 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-23 15:31:46 httpcore.connection DEBUG    close.started\n",
      "2024-07-23 15:31:46 httpcore.connection DEBUG    close.complete\n",
      "2024-07-23 15:31:46 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:31:47 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc42042ae10>\n",
      "2024-07-23 15:31:47 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc420527770> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-23 15:31:47 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc40dd05a50>\n",
      "2024-07-23 15:31:47 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-23 15:31:47 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-23 15:31:47 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-23 15:31:47 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-23 15:31:47 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-23 15:31:49 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 23 Jul 2024 19:31:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'2268'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995853'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_481dbf4a7b72f8a8f925694e6bf06673'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a7e17bade578fd3-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-23 15:31:49 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-23 15:31:49 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-23 15:31:49 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-23 15:31:49 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-23 15:31:49 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-23 15:31:49 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 23 Jul 2024 19:31:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '2268', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995853', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_481dbf4a7b72f8a8f925694e6bf06673', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8a7e17bade578fd3-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-23 15:31:49 openai._base_client DEBUG    request_id: req_481dbf4a7b72f8a8f925694e6bf06673\n",
      "Both are fictional characters who are blind and possess extraordinary abilities - Daredevil is a Marvel superhero with heightened senses, and Toph Beifong is an Earthbender from the animated series \"Avatar: The Last Airbender\" who uses seismic sense to \"see.\"\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nnsight import LanguageModel\n",
    "\n",
    "# lm = LanguageModel(\"/home/local_arnab/Codes/00_MODEL/Qwen/Qwen2-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:26:49 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:26:57 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/meta-llama/Meta-Llama-3-8B-Instruct> | size: 15316.516 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_key = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model_key = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>\n",
      "The queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \n",
      "\n",
      "Q: What is the relation between John Nash and Russell Crowe?\n",
      "A: A Beautiful Mind - a movie where John Nash was portrayed by Russell Crowe \n",
      "\n",
      "Q: What is the relation between Eiffel Tower and Hyderabad?\n",
      "A: None\n",
      "\n",
      "Q: What is the relation between Buckingham Palace and Big Ben?\n",
      "A: London - Buckingham Palace and Big Ben are both located in London.\n",
      "\n",
      "Q: What is the relation between Daredevil and Toph Beifong?\n",
      "A: None\n",
      "\n",
      "Q: What is the relation between Google and YouTube?\n",
      "A: Google - Google owns YouTube\n",
      "\n",
      "Q: What is the relation between NASA and SpaceX?\n",
      "A: NASA - NASA has collaborated with SpaceX\n",
      "\n",
      "Q: What is the relation between Facebook and Instagram?\n",
      "A: Facebook - Facebook owns Instagram\n",
      "\n",
      "Q: What is the relation between Amazon and Whole Foods?\n",
      "A: Amazon - Amazon owns Whole Foods\n",
      "\n",
      "Q: What is the relation between Apple and Beats Electronics?\n",
      "A: Apple - Apple owns\n"
     ]
    }
   ],
   "source": [
    "from src.models import prepare_input\n",
    "\n",
    "# prompt = \"Stephen\"\n",
    "\n",
    "inputs = prepare_input(\n",
    "    prompts = prompt,\n",
    "    tokenizer=mt,\n",
    "    add_bos_token=False\n",
    ")\n",
    "\n",
    "generation = mt._model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    top_k = 1\n",
    ")\n",
    "\n",
    "print(mt.tokenizer.decode(generation[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4986344299918355843"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "\n",
    "ctypes.c_size_t(hash(\"prompt\")).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4986344299918355843"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4ae35dbb42614d2429b7d6d181a950bb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "hashlib.md5(\"prompt\".encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
