{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 16:56:08 __main__ INFO     torch.__version__='2.3.1', torch.version.cuda='12.1'\n",
      "2024-07-12 16:56:08 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2024-07-12 16:56:08 __main__ INFO     transformers.__version__='4.42.3'\n",
      "2024-07-12 16:56:08 httpx DEBUG    load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-07-12 16:56:08 httpx DEBUG    load_verify_locations cafile='/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_KEY\"),\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidate Relations\n",
    "=> Constraints:\n",
    "    * Make sure that the relation is not direct, at least 2 hops.\n",
    "\n",
    "* Movie, Actor potrayed a character in the movie\n",
    "* Movie, actor directed by a director in the movie\n",
    "* Architect, 2 buildings/landmarks designed by the architect\n",
    "* Profession, 2 people with connected by their profession\n",
    "* Nationality, 2 people with connected by their nationality\n",
    "* Same market, 2 companies with connected by their market or focus\n",
    "* Part of whole, 2 chemicals with connected by their chemical composition \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \n",
      "\n",
      "Q: What is the relation between John Nash and Russell Crowe?\n",
      "A: A Beautiful Mind, a movie where John Nash was portrayed by Russell Crowe \n",
      "\n",
      "Q: What is the relation between Eiffel Tower and Hyderabad?\n",
      "A: None\n",
      "\n",
      "Q: What is the relation between Buckingham Palace and Big Ben?\n",
      "A: London, Buckingham Palace and Big Ben are both located in London.\n",
      "\n",
      "Q: What is the relation between Nintendo and Tokyo?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"What is the relation between Albert Einstein and Mathew McConaughey?\"\n",
    "# prompt = \"What is the relation between Nicholas of Tolentino and Bethlehem?\"\n",
    "# prompt = \"What is the relation between Xbox and Hyderabad?\"\n",
    "# prompt = \"What is the capital of the country where the CEO of the developer of watchOS holds citizenship?\"\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# Complete the query\n",
    "\n",
    "# Q: What is the capital of the country where the CEO of the developer of watchOS holds citizenship?\n",
    "# A: The developer of watchOS is Apple Inc. The CEO of Apple Inc. is Tim Cook. Tim Cook is a citizen of the United States. The capital of the United States is Washington, D.C.\n",
    "\n",
    "# Q: What is the headquarters of the company that Sundar Pichai is the CEO of?\n",
    "# A: Sundar Pichai is the CEO of Alphabet Inc. The headquarters of Alphabet Inc. is Mountain View, California.\n",
    "\n",
    "# Q: What is the capital of the country where the headquarters of the company that developed Nintendo Switch is located?\n",
    "# A:\"\"\"\n",
    "\n",
    "# query = \"What is the relation between Nintendo and Tokyo?\"\n",
    "# query = \"What is the relation between Albert Einstein and The Space Needle?\"\n",
    "# query = \"What is the relation between Mahatma Gandhi and Adolf Hitler?\"\n",
    "# query = \"What is the relation between Richard Dawkins and Salman Rushdie?\"\n",
    "# query = \"What is the relation between John Nash and Stephen Hawking?\"\n",
    "# query = \"What is the relation between Albert Einstein and Mathew McConaughey?\"\n",
    "# query = \"What is the relation between Guggenheim Museum Bilbao and Walt Disney Concert Hall\"\n",
    "# query = \"What is the relation between Ricky Ponting and Sourav Ganguly?\"\n",
    "# query = \"What is the relation between Michael Vaughan and David Beckham?\"\n",
    "# query = \"What is the relation between Sunder Pichai and Satya Nadella?\"\n",
    "# query = \"What is the relation between Heydar Aliyev Center and London Aquatics Centre\"\n",
    "# query = \"What is the relation between Samsung and Apple?\"\n",
    "# query = \"What is the relation between Arthur Eddington and David Tennant?\"\n",
    "# query = \"What is the relation between Amazon and Flipkart?\"\n",
    "# query = \"What is the relation between Google and Facebook?\"\n",
    "# query = \"What is the relation between NASA and SpaceX?\"\n",
    "# query = \"What is the relation betwen Facebook and WhatsApp?\"\n",
    "# query = \"What is the relation between Mahatma Gandhi and Ben Kingsley?\"\n",
    "# query = \"What is the relation between glycerol and sulfuric acid?\"\n",
    "query = \"What is the relation between Nintendo and Tokyo?\"\n",
    "# query = \"What is the relation between Bruce Wayne and Clark Kent?\"\n",
    "# query = \"What is the relation between Daredevil and Toph Beifong?\"\n",
    "# query = \"What is the relation between Avater and Titanic?\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "The queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \n",
    "\n",
    "Q: What is the relation between John Nash and Russell Crowe?\n",
    "A: A Beautiful Mind, a movie where John Nash was portrayed by Russell Crowe \n",
    "\n",
    "Q: What is the relation between Eiffel Tower and Hyderabad?\n",
    "A: None\n",
    "\n",
    "Q: What is the relation between Buckingham Palace and Big Ben?\n",
    "A: London, Buckingham Palace and Big Ben are both located in London.\n",
    "\n",
    "Q: {query}\n",
    "A:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 16:57:57 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nThe queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \\n\\nQ: What is the relation between John Nash and Russell Crowe?\\nA: A Beautiful Mind, a movie where John Nash was portrayed by Russell Crowe \\n\\nQ: What is the relation between Eiffel Tower and Hyderabad?\\nA: None\\n\\nQ: What is the relation between Buckingham Palace and Big Ben?\\nA: London, Buckingham Palace and Big Ben are both located in London.\\n\\nQ: What is the relation between Nintendo and Tokyo?\\nA:'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-12 16:57:57 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-12 16:57:57 httpcore.connection DEBUG    close.started\n",
      "2024-07-12 16:57:57 httpcore.connection DEBUG    close.complete\n",
      "2024-07-12 16:57:57 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-12 16:57:57 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1ae89e0a50>\n",
      "2024-07-12 16:57:57 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7f1aec1d4320> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-12 16:57:57 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1ae8949290>\n",
      "2024-07-12 16:57:57 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-12 16:57:57 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-12 16:57:57 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-12 16:57:57 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-12 16:57:57 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-12 16:57:58 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Jul 2024 20:57:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'549'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'22000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'21995856'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_3e2515afe4b1be02afa8328c6b3ce60e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8a23f2d9789f3b99-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-12 16:57:58 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-12 16:57:58 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-12 16:57:58 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-12 16:57:58 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-12 16:57:58 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-12 16:57:58 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Fri, 12 Jul 2024 20:57:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '549', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '22000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '21995856', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_3e2515afe4b1be02afa8328c6b3ce60e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8a23f2d9789f3b99-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-12 16:57:58 openai._base_client DEBUG    request_id: req_3e2515afe4b1be02afa8328c6b3ce60e\n",
      "Kyoto, Nintendo is headquartered in Kyoto, Japan, not Tokyo.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nnsight import LanguageModel\n",
    "\n",
    "# lm = LanguageModel(\"/home/local_arnab/Codes/00_MODEL/Qwen/Qwen2-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-12 16:56:11 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  Qwen2ForCausalLM\n",
      "2024-07-12 16:56:16 src.models ERROR    Unknown model type: Qwen2ForCausalLM. Parsing may fail.\n",
      "2024-07-12 16:56:16 src.models ERROR    Unknown model type: Qwen2ForCausalLM\n",
      "2024-07-12 16:56:16 src.models ERROR    !!! Error (Qwen2ForCausalLM): attn_module_name_format could not be set !!!\n",
      "2024-07-12 16:56:16 src.models ERROR    !!! Error (Qwen2ForCausalLM): mlp_module_name_format could not be set !!!\n",
      "2024-07-12 16:56:16 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/Qwen/Qwen2-7B> | size: 16317.643 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_key = \"meta-llama/Meta-Llama-3-8B\"\n",
    "# model_key = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "model_key = \"Qwen/Qwen2-7B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The queries ask you to find any relation that connects two entities. You should give the answer in the exact format as shown in the examples. \n",
      "\n",
      "Q: What is the relation between John Nash and Russell Crowe?\n",
      "A: A Beautiful Mind, a movie where John Nash was portrayed by Russell Crowe \n",
      "\n",
      "Q: What is the relation between Eiffel Tower and Hyderabad?\n",
      "A: None\n",
      "\n",
      "Q: What is the relation between Buckingham Palace and Big Ben?\n",
      "A: London, Buckingham Palace and Big Ben are both located in London.\n",
      "\n",
      "Q: What is the relation between Nintendo and Tokyo?\n",
      "A: Nintendo is headquartered in Kyoto, Japan, not Tokyo.\n",
      "\n",
      "Q: What is the relation between The Beatles and London?\n",
      "A: The Beatles were a British rock band formed in Liverpool, England, and they are associated with London.\n",
      "\n",
      "Q: What is the relation between The Beatles and London?\n",
      "A: The Beatles were a British rock band formed in Liverpool, England, and they are associated with London.\n",
      "\n",
      "Q: What is the relation between The Beatles and London?\n",
      "A: The Beatles were a British rock band\n"
     ]
    }
   ],
   "source": [
    "from src.models import prepare_input\n",
    "\n",
    "# prompt = \"Stephen\"\n",
    "\n",
    "inputs = prepare_input(\n",
    "    prompts = prompt,\n",
    "    tokenizer=mt,\n",
    "    add_bos_token=False\n",
    ")\n",
    "\n",
    "generation = mt._model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    top_k = 1\n",
    ")\n",
    "\n",
    "print(mt.tokenizer.decode(generation[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
