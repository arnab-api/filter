{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e7c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cd4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:48:51 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-09-16 09:48:52 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-09-16 09:48:52 __main__ INFO     transformers.__version__='4.55.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3b2420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:48:54 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks/checking_head_generalization, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-16 09:48:54 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks/checking_head_generalization, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-16 09:48:55 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-09-16 09:48:55 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b62bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:49:10 src.models WARNING  meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-09-16 09:49:10 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:49:10 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-09-16 09:49:10 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-09-16 09:49:10 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/meta-llama/Llama-3.3-70B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e369badd91442088fad89ba08fba95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-09-16 09:50:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-09-16 09:50:00 src.models INFO     loaded model <meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77abadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectLastTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectLastTask\n",
    "\n",
    "#################################################################################\n",
    "TASK_CLS = SelectLastTask\n",
    "prompt_template_idx = 3\n",
    "N_DISTRACTORS = 5\n",
    "OPTION_STYLE = \"single_line\"\n",
    "#################################################################################\n",
    "\n",
    "optimized_task = TASK_CLS.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(optimized_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da783c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Blueberry, Earring, Grape, Pants, Strawberry, Harp, Tennis ball, Eraser.\n",
      "What is the last fruit in this list above?\n",
      "Answer: >> \" Strawberry\"\n"
     ]
    }
   ],
   "source": [
    "sample = optimized_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    # category=\"actor\",\n",
    "    # category=\"Brazil\"\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=False,\n",
    ")\n",
    "\n",
    "print(sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb708dc",
   "metadata": {},
   "source": [
    "## Loading the heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42843f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:05 matplotlib DEBUG    matplotlib data path: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:05 matplotlib DEBUG    CONFIGDIR=/disk/u/arnab/.config/matplotlib\n",
      "2025-09-16 09:50:05 matplotlib DEBUG    interactive is False\n",
      "2025-09-16 09:50:05 matplotlib DEBUG    platform is linux\n",
      "2025-09-16 09:50:06 matplotlib DEBUG    CACHEDIR=/disk/u/arnab/.cache/matplotlib\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    Using fontManager instance from /disk/u/arnab/.cache/matplotlib/fontlist-v390.json\n",
      "2025-09-16 09:50:06 matplotlib.pyplot DEBUG    Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2025-09-16 09:50:06 matplotlib.pyplot DEBUG    Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_K.otf', name='Linux Biolinum Keyboard O', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-Italic.otf', name='STIX', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-BlackItalic.ttf', name='Lato', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Oblique.ttf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-BoldOblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBassaVah-Regular.ttf', name='Noto Sans Bassa Vah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Regular.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Roman.otf', name='P052', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond-InitialsF2.ttf', name='EB Garamond Initials Fill2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-BoldItalic.ttf', name='Lato', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/rsfs10.ttf', name='rsfs10', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerifItalic.otf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa.ttf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-Bold.otf', name='STIX', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_DR.otf', name='Linux Libertine Display O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono.ttf', name='Go Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasB.ttf', name='Gentium Basic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/batang.ttf', name='Baekmuk Batang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/mry_KacstQurn.ttf', name='mry_KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Regular.ttf', name='Padauk Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-BoldItalic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Regular.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTamil-Bold.ttf', name='Noto Sans Tamil', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-BoldOblique.otf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeThreeSym-Bold.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Navilu/Navilu.ttf', name='Navilu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-BoldItalic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBoldItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMono.otf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-Oblique.otf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramondSC12-Regular.otf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOSsys.ttf', name='Khmer OS System', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-Bold.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-C.ttf', name='Ubuntu Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lao/Phetsarath_OT.ttf', name='Phetsarath OT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-Italic.ttf', name='Cousine', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNaskhArabic-Regular.ttf', name='Noto Naskh Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-Regular.otf', name='Accanthis ADF Std', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-Regular.ttf', name='Caladea', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sahadeva/sahadeva.ttf', name='Sahadeva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee.ttf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Andale_Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldItalic.ttf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstQurn.ttf', name='KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-BoldOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-Bold.ttf', name='Noto Serif Display', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoKufiArabic-Bold.ttf', name='Noto Kufi Arabic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-Regular.otf', name='Accanthis ADF Std No2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGurmukhi-Regular.ttf', name='Noto Serif Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-BoldItalic.ttf', name='Noto Serif Display', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeFourSym-Regular.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhmer-Regular.ttf', name='Noto Sans Khmer', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/comfortaa/Comfortaa-Light.ttf', name='Comfortaa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTibetan-Regular.ttf', name='Noto Serif Tibetan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-Regular.ttf', name='Cousine', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-BoldItalic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/gentiumplus/GentiumPlusCompact-R.ttf', name='Gentium Plus Compact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Oblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-BoldItalic.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/Gentium-I.ttf', name='Gentium', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDuployan-Regular.ttf', name='Noto Sans Duployan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New_Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGurmukhi-Bold.ttf', name='Noto Sans Gurmukhi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter.otf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Regular.ttf', name='Yrsa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-SemiboldItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-guru-extra/Saab.ttf', name='Saab', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhojki-Regular.ttf', name='Noto Sans Khojki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-BoldOblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono-Bold.ttf', name='Go Mono', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Bold.ttf', name='Rachana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-BoldItalic.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMahajani-Regular.ttf', name='Noto Sans Mahajani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Medium.ttf', name='Roboto', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifSinhala-Bold.ttf', name='Noto Serif Sinhala', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-BoldOblique.ttf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New_Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf', name='IPAGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-BoldItalic.ttf', name='Carlito', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma-Oblique.otf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter-Bold.otf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPoster.ttf', name='KacstPoster', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond12-AllSC.otf', name='EB Garamond 12 All SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBhaiksuki-Regular.ttf', name='Noto Sans Bhaiksuki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic/uming.ttc', name='AR PL UMing CN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-Bold.ttf', name='Carlito', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLao-Regular.ttf', name='Noto Sans Lao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasR.ttf', name='Gentium Basic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond08-Italic.otf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSoraSompeng-Regular.ttf', name='Noto Sans Sora Sompeng', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMonoBoldOblique.otf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMendeKikakui-Regular.ttf', name='Noto Sans Mende Kikakui', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstNaskh.ttf', name='KacstNaskh', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeOneSym-Regular.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-Bold.ttf', name='Noto Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-LightItalic.ttf', name='Roboto', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Italic.otf', name='Cabin', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-Italic.otf', name='Accanthis ADF Std No3', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-BoldCond.otf', name='Gillius ADF', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNaskhArabic-Bold.ttf', name='Noto Naskh Arabic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-Regular.otf', name='STIX', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Regular.otf', name='Gillius ADF', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Black.ttf', name='Roboto', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Bold.otf', name='P052', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuMathTeXGyre.ttf', name='DejaVu Math TeX Gyre', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-BoldOblique.otf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCherokee-Bold.ttf', name='Noto Sans Cherokee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/complutum/GFSPolyglot.otf', name='GFS Complutum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHatran-Regular.ttf', name='Noto Sans Hatran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-Regular.ttf', name='Carlito', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLao-Bold.ttf', name='Noto Sans Lao', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/D050000L.otf', name='D050000L', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Italic.ttf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-BoldItalic.otf', name='Cabin', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Tamil.ttf', name='Samyak Tamil', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-kalapi/Kalapi.ttf', name='Kalapi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/hline.ttf', name='Baekmuk Headline', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGurmukhi-Bold.ttf', name='Noto Serif Gurmukhi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond08-Italic.ttf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBoldOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Oblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush.ttf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentiumplus/GentiumPlus-R.ttf', name='Gentium Plus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 1.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSymbols-Bold.ttf', name='Noto Sans Symbols', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramondSC08-Regular.ttf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-malayalam/Lohit-Malayalam.ttf', name='Lohit Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman.ttf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RI.otf', name='Linux Libertine O', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnPilgi.ttf', name='UnPilgi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/comic.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/abyssinica/AbyssinicaSIL-Regular.ttf', name='Abyssinica SIL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-MediumItalic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=500, stretch='condensed', size='scalable')) = 11.344999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/Gentium-R.ttf', name='Gentium', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-R.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne.ttf', name='KacstOne', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/courbi.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeTwoSym-Regular.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf', name='Noto Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifBengali-Bold.ttf', name='Noto Serif Bengali', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-LightItalic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=300, stretch='condensed', size='scalable')) = 11.344999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Bold.ttf', name='Padauk Book', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramondSC08-Regular.otf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-Regular.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerifBold.otf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/aakar-medium.ttf', name='aakar', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Medium.ttf', name='Go Medium', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnVada.ttf', name='UnVada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-BoldCondItalic.otf', name='Gillius ADF', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeThreeSym-Regular.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-Slanted.ttf', name='Amiri', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda-Oblique.otf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-CondItalic.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-Bold.otf', name='Accanthis ADF Std', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifBengali-Regular.ttf', name='Noto Serif Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic/ukai.ttc', name='AR PL UKai CN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraBd.ttf', name='Bitstream Vera Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.2440909090909091\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDotumBold.ttf', name='UnDotum', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDinaruBold.ttf', name='UnDinaru', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 0.5349999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Oblique.ttf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Bold.ttf', name='Open Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasI.ttf', name='Gentium Basic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/chandas1-2.ttf', name='Chandas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSiddham-Regular.ttf', name='Noto Sans Siddham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldItalic.ttf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTakri-Regular.ttf', name='Noto Sans Takri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDeseret-Regular.ttf', name='Noto Sans Deseret', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Chilanka-Regular.otf', name='Chilanka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Suruma.ttf', name='Suruma', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/GentiumAlt-I.ttf', name='GentiumAlt', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf', name='Noto Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Regular.ttf', name='Open Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNewa-Regular.ttf', name='Noto Sans Newa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnGraphicBold.ttf', name='UnGraphic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoNovel.ttf', name='UnJamoNovel', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-R.ttf', name='Ubuntu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTelugu-Regular.ttf', name='Noto Serif Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-BdIta.otf', name='C059', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium/GentiumAlt-R.ttf', name='GentiumAlt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMath-Regular.ttf', name='Noto Sans Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Bold.ttf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush.otf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Regular.ttf', name='Rasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma.otf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldOblique.ttf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/porson/GFSPorson.otf', name='GFS Porson', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-SemiBoldItalic.otf', name='Cabin', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-Bold.otf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Bold.otf', name='Nimbus Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode-BoldItalic.ttf', name='Junicode', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-BoldItalic.otf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-BI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Light.ttf', name='Lato', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Bold.otf', name='Nimbus Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnPenheulim.ttf', name='UnPenheulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnPen.ttf', name='UnPen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Bold.otf', name='Cabin', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-BoldItalic.ttf', name='Tinos', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoDotum.ttf', name='UnJamoDotum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/arialbd.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana_Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-HairlineItalic.ttf', name='Lato', style='italic', variant='normal', weight=100, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCherokee-Regular.ttf', name='Noto Sans Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDevanagari-Bold.ttf', name='Noto Sans Devanagari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldHungarian-Regular.ttf', name='Noto Sans Old Hungarian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidotBold.otf', name='GFS Didot', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-LI.ttf', name='Ubuntu', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-Bold.otf', name='Accanthis ADF Std No3', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma-Bold.otf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-japanese-gothic.ttf', name='IPAexGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-BoldItalic.ttf', name='Noto Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-BoldItalic.otf', name='Accanthis ADF Std No2', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifLao-Regular.ttf', name='Noto Serif Lao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgiab.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebucbd.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerifBoldItalic.otf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSinhala-Regular.ttf', name='Noto Sans Sinhala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter-BoldOblique.otf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi.otf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond-InitialsF1.otf', name='EB Garamond Initials Fill1', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMoBd.ttf', name='Bitstream Vera Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-telugu/Lohit-Telugu.ttf', name='Lohit Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisiaBold.otf', name='GFS Artemisia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-BoldItalic.ttf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Cond.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond08-Regular.otf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Italic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf', name='Ubuntu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMusic-Regular.ttf', name='Noto Music', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/bodoni-classic/GFSBodoniClassic.otf', name='GFS BodoniClassic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-Regular.ttf', name='Amiri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnPilgiBold.ttf', name='UnPilgi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Regular.otf', name='Cabin', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNastaliqUrdu-Regular.ttf', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Light.ttf', name='Roboto', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraSe.ttf', name='Bitstream Vera Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMalayalam-Regular.ttf', name='Noto Sans Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-BoldCondIt.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Carlito-Italic.ttf', name='Carlito', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/AmiriQuranColored.ttf', name='Amiri Quran Colored', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstArt.ttf', name='KacstArt', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOriya-Regular.ttf', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-MediumItalic.ttf', name='Lato', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-CondLightItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=300, stretch='condensed', size='scalable')) = 11.344999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee.otf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-Light.otf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS_Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansModi-Regular.ttf', name='Noto Sans Modi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenicBold.otf', name='GFS Neohellenic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdanab.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDigital.ttf', name='KacstDigital', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond12-Italic.ttf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Semibold.ttf', name='Lato', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/couri.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-BoldOblique.ttf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Light.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMiao-Regular.ttf', name='Noto Sans Miao', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Black.ttf', name='Lato', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Italic.otf', name='Universalis ADF Std', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKannada-Regular.ttf', name='Noto Sans Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldOblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-gbsn00lp/gbsn00lp.ttf', name='AR PL SungtiL GB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-Oblique.otf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifArmenian-Regular.ttf', name='Noto Serif Armenian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gazis/GFSGazis.otf', name='GFS Gazis', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMro-Regular.ttf', name='Noto Sans Mro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-BoldItalic.ttf', name='Arimo', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Medium.ttf', name='Yrsa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSharada-Regular.ttf', name='Noto Sans Sharada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOriya-Bold.ttf', name='Noto Sans Oriya', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTelugu-Bold.ttf', name='Noto Serif Telugu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-Italic.ttf', name='Tinos', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Oblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoNastaliqUrdu-Bold.ttf', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Medium-Italic.ttf', name='Go Medium', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Regular.otf', name='Manjari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-CondItalic.otf', name='Gillius ADF', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree-Oblique.otf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/msbm10.ttf', name='msbm10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-BoldOblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo-Oblique.otf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Thin.otf', name='Gayathri', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari.otf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Bold_Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Bold.ttf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-DemiItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstBook.ttf', name='KacstBook', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RZI.otf', name='Linux Libertine O', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisiaIt.otf', name='GFS Artemisia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgiai.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Bold.ttf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPauCinHau-Regular.ttf', name='Noto Sans Pau Cin Hau', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMono.ttf', name='Bitstream Vera Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMalayalam-Regular.ttf', name='Noto Serif Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-MediumItalic.otf', name='Cabin', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstLetter.ttf', name='KacstLetter', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Bold.ttf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-Medium.otf', name='Cabin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-Regular.ttf', name='Noto Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-B.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-assamese/Lohit-Assamese.ttf', name='Lohit Assamese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman.otf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-BoldItalic.otf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSymbols2-Regular.ttf', name='Noto Sans Symbols2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-BoldItalic.otf', name='Gillius ADF', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MuktiNarrowBold.ttf', name='Mukti Narrow', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/Pothana2000.ttf', name='Pothana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Regular.ttf', name='Rachana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Light.ttf', name='Open Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/font-awesome/FontAwesome.otf', name='FontAwesome', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-kannada/Lohit-Kannada.ttf', name='Lohit Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitleL.ttf', name='KacstTitleL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-Regular.ttf', name='Noto Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-CondItalic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBoldOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypewriter-Oblique.otf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-mincho/ipamp.ttf', name='IPAPMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Oblique.ttf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Dyuthi-Regular.ttf', name='Dyuthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSymbols-Regular.ttf', name='Noto Sans Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTirhuta-Regular.ttf', name='Noto Sans Tirhuta', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXVariants-Regular.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-MI.ttf', name='Ubuntu', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-MediumItalic.ttf', name='Roboto', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Keraleeyam-Regular.ttf', name='Keraleeyam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThaana-Bold.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnGungseo.ttf', name='UnGungseo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/esint10.ttf', name='esint10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipaexfont-gothic/ipaexg.ttf', name='IPAexGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Bold.ttf', name='Yrsa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifEthiopic-Regular.ttf', name='Noto Serif Ethiopic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia_Bold_Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman-Bold.otf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Italic.ttf', name='Go', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Bold.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-BoldItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Meera-Regular.ttf', name='Meera', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi.ttf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMarchen-Regular.ttf', name='Noto Sans Marchen', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansWarangCiti-Regular.ttf', name='Noto Sans Warang Citi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPen.ttf', name='KacstPen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono-Italic.ttf', name='Go Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond-Initials.ttf', name='EB Garamond Initials', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTelugu-Regular.ttf', name='Noto Sans Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/Rekha.ttf', name='Rekha', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Bold.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-Italic.ttf', name='Caladea', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/AnjaliOldLipi-Regular.ttf', name='AnjaliOldLipi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Karumbi-Regular.ttf', name='Karumbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGeorgian-Regular.ttf', name='Noto Sans Georgian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot-classic/GFSDidotClassic.otf', name='GFS Didot Classic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoBatang.ttf', name='UnJamoBatang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Norasi-Italic.otf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-Regular.ttf', name='Tinos', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoKufiArabic-Regular.ttf', name='Noto Kufi Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-Regular.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Bold.ttf', name='Rasa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-Bold.ttf', name='Noto Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-ExtraBold.otf', name='Cantarell', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-BoldCond.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode-Italic.ttf', name='Junicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Regular.otf', name='Nimbus Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-Italic.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana_Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_R.otf', name='Linux Libertine O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MuktiNarrow.ttf', name='Mukti Narrow', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKhmer-Bold.ttf', name='Noto Serif Khmer', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/openoffice/opens___.ttf', name='OpenSymbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGujarati-Regular.ttf', name='Noto Sans Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond08-Regular.ttf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf', name='Noto Sans Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Bold.ttf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraSeBd.ttf', name='Bitstream Vera Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 1.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/comfortaa/Comfortaa-Bold.ttf', name='Comfortaa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGurmukhi-Regular.ttf', name='Noto Sans Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCanadianAboriginal-Bold.ttf', name='Noto Sans Canadian Aboriginal', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Loma-BoldOblique.otf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist-Oblique.otf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeFourSym-Bold.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/ani.ttf', name='Ani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_M.otf', name='Linux Libertine Mono O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeTwoSym-Bold.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-BookOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Oblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond-InitialsF2.otf', name='EB Garamond Initials Fill2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-Regular.otf', name='Accanthis ADF Std No3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBold.ttf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Regular.ttf', name='Padauk', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda.otf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenic.otf', name='GFS Neohellenic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/comicbd.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/ariali.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidotItalic.otf', name='GFS Didot', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenicIt.otf', name='GFS Neohellenic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBasBI.ttf', name='Gentium Basic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-Bold.ttf', name='Noto Sans Display', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia_Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXNonUnicode-Bold.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMayanNumerals-Regular.ttf', name='Noto Sans Mayan Numerals', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-BoldItalic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Semibold.ttf', name='Open Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-BoldItalic.ttf', name='Noto Sans Display', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-Bold.otf', name='Accanthis ADF Std No2', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBold.ttf', name='Yrsa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Regular.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist.otf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMyanmar-Bold.ttf', name='Noto Serif Myanmar', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-Italic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/neohellenic/GFSNeohellenicBoldIt.otf', name='GFS Neohellenic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-BI.ttf', name='Ubuntu', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPahawhHmong-Regular.ttf', name='Noto Sans Pahawh Hmong', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-BoldItalic.ttf', name='Cousine', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUp-Regular.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifEthiopic-Bold.ttf', name='Noto Serif Ethiopic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo.otf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Bold_Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/arialbi.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifArmenian-Bold.ttf', name='Noto Serif Armenian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansEthiopic-Regular.ttf', name='Noto Sans Ethiopic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAdlamUnjoined-Regular.ttf', name='Noto Sans Adlam Unjoined', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-CondBold.ttf', name='Open Sans Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Regular.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/stmary10.ttf', name='stmary10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Bold.ttf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Italic.otf', name='Gillius ADF', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKannada-Regular.ttf', name='Noto Serif Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Bold.ttf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Regular.otf', name='Nimbus Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-ThinItalic.ttf', name='Lato', style='italic', variant='normal', weight=200, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifThai-Regular.ttf', name='Noto Serif Thai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Bold.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-gkai00mp/gkai00mp.ttf', name='AR PL KaitiM GB', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sarai/Sarai.ttf', name='Sarai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldPermic-Regular.ttf', name='Noto Sans Old Permic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Light.otf', name='URW Bookman', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Mono-Bold-Italic.ttf', name='Go Mono', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-BoldItalic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono-Bold.otf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Oblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Book.otf', name='URW Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee-Bold.otf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Bold-Italic.ttf', name='Go', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Comic_Sans_MS_Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Demi.otf', name='URW Bookman', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGeorgian-Bold.ttf', name='Noto Serif Georgian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/olga/GFSOlga.otf', name='GFS Olga', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-LightItalic.ttf', name='Lato', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Regular.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasR.ttf', name='Gentium Book Basic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/Z003-MediumItalic.otf', name='Z003', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGeorgian-Regular.ttf', name='Noto Serif Georgian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGujarati-Bold.ttf', name='Noto Serif Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidot.otf', name='GFS Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-Regular.otf', name='Berenis ADF Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifHebrew-Bold.ttf', name='Noto Serif Hebrew', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Oblique.ttf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIXMath-Regular.otf', name='STIX Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-Regular.ttf', name='Noto Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-BoldItalic.otf', name='P052', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnBatangBold.ttf', name='UnBatang', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda-Bold.otf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMonoBold.otf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpSm-Bold.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-SemiBold.ttf', name='Rasa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/times.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/dotum.ttf', name='Baekmuk Dotum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Bold.ttf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond-Initials.otf', name='EB Garamond Initials', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXVariants-Bold.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Italic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-LightItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-BoldCond.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-orya-extra/utkal.ttf', name='ori1Uni', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_I.otf', name='Linux Libertine Initials O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKannada-Bold.ttf', name='Noto Serif Kannada', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSans.ttf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa-Bold.otf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAdlam-Regular.ttf', name='Noto Sans Adlam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBengali-Bold.ttf', name='Noto Sans Bengali', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArabic-Regular.ttf', name='Noto Sans Arabic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo2-Italic.otf', name='Accanthis ADF Std No2', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSans.otf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Hairline.ttf', name='Lato', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/pagul/Pagul.ttf', name='Pagul', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Italic.ttf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Light.otf', name='Cantarell', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_R.otf', name='Linux Biolinum O', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baskerville/GFSBaskerville.otf', name='GFS Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/eufm10.ttf', name='eufm10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBold.ttf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Light.ttf', name='Yrsa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-gujarati/Lohit-Gujarati.ttf', name='Lohit Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Thin.ttf', name='Lato', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/mitra.ttf', name='Mitra Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnTaza.ttf', name='UnTaza', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma.ttf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-LightOblique.otf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/wasy10.ttf', name='wasy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-BoldOblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMono.ttf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tibetan-machine/TibetanMachineUni.ttf', name='Tibetan Machine Uni', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Bold.ttf', name='Lato', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-LightOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDinaruLight.ttf', name='UnDinaru', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-BoldItalic.ttf', name='Noto Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Regular.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-BoldOblique.otf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansManichaean-Regular.ttf', name='Noto Sans Manichaean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-Italic.otf', name='Accanthis ADF Std', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Courier_New_Bold_Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree.otf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMoIt.ttf', name='Bitstream Vera Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS_Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStd-BoldItalic.otf', name='Accanthis ADF Std', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa-Oblique.otf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Bold.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Regular.ttf', name='Roboto', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsD-Bold.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeMonoOblique.otf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-Bold.otf', name='Berenis ADF Pro', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-ThinItalic.ttf', name='Roboto', style='italic', variant='normal', weight=250, stretch='normal', size='scalable')) = 11.1925\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Bold.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOsage-Regular.ttf', name='Noto Sans Osage', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/didot/GFSDidotBoldItalic.otf', name='GFS Didot', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-oriya/Lohit-Odia.ttf', name='Lohit Odia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/timesi.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnPilgia.ttf', name='UnPilgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-BoldSlanted.ttf', name='Amiri', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSansBoldOblique.otf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSerif.otf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSansOblique.otf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/FoulisGreek.ttf', name='FoulisGreek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/timesbi.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpD-Bold.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix-word/STIX-BoldItalic.otf', name='STIX', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamilSlanted-Bold.ttf', name='Noto Serif Tamil Slanted', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil-classical/Lohit-Tamil-Classical.ttf', name='Lohit Tamil Classical', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Oblique.ttf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf', name='Noto Sans Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMalayalam-Bold.ttf', name='Noto Serif Malayalam', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman-BoldItalic.otf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-BoldItalic.ttf', name='Roboto', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHebrew-Bold.ttf', name='Noto Sans Hebrew', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerif-Italic.ttf', name='Noto Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/Vera.ttf', name='Bitstream Vera Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.9590909090909092\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdanaz.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond-InitialsF1.ttf', name='EB Garamond Initials Fill1', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-DemiOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisiaBoldIt.otf', name='GFS Didot', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak/Samyak-Devanagari.ttf', name='Samyak Devanagari', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/gentiumplus/GentiumPlusCompact-I.ttf', name='Gentium Plus Compact', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-HeavyItalic.ttf', name='Lato', style='italic', variant='normal', weight=800, stretch='normal', size='scalable')) = 11.43\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/asana-math/Asana-Math.otf', name='Asana Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-LightItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Thin.otf', name='Manjari', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa-BoldOblique.otf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTibetan-Bold.ttf', name='Noto Serif Tibetan', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobster/lobster.otf', name='Lobster Two', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Demi.otf', name='URW Gothic', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNabataean-Regular.ttf', name='Noto Sans Nabataean', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Medium.ttf', name='Rasa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-BoldCondItalic.otf', name='Gillius ADF No2', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsD-Regular.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist-Bold.otf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Bold.otf', name='Cantarell', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifThai-Bold.ttf', name='Noto Serif Thai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-bsmi00lp/bsmi00lp.ttf', name='AR PL Mingti2L Big5', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifLao-Bold.ttf', name='Noto Serif Lao', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo-BoldOblique.otf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Bold.otf', name='Manjari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsSm-Regular.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamil-Bold.ttf', name='Noto Serif Tamil', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansJavanese-Bold.ttf', name='Noto Sans Javanese', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTamilSupplement-Regular.ttf', name='Noto Sans Tamil Supplement', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMultani-Regular.ttf', name='Noto Sans Multani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipaexfont-mincho/ipaexm.ttf', name='IPAexMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDevanagari-Regular.ttf', name='Noto Serif Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RB.otf', name='Linux Libertine O', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-ExtraBold.ttf', name='Open Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTangut-Regular.ttf', name='Noto Serif Tangut', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Bold.ttf', name='Padauk', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansElbasan-Regular.ttf', name='Noto Sans Elbasan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeOneSym-Bold.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansSinhala-Bold.ttf', name='Noto Sans Sinhala', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasB.ttf', name='Gentium Book Basic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Italic.ttf', name='Lato', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond12-Italic.otf', name='EB Garamond', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf', name='Droid Sans Fallback', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-Bold.ttf', name='Arimo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Light.ttf', name='Rasa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMyanmar-Regular.ttf', name='Noto Sans Myanmar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Bold.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnYetgul.ttf', name='UnYetgul', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/StandardSymbolsPS.otf', name='Standard Symbols PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-BlackItalic.ttf', name='Roboto', style='italic', variant='normal', weight=900, stretch='normal', size='scalable')) = 11.525\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Thin.ttf', name='Roboto', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Smallcaps-Italic.ttf', name='Go Smallcaps', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCham-Bold.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraIt.ttf', name='Bitstream Vera Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.9590909090909092\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/sinhala/lklug.ttf', name='LKLUG', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansDisplay-Italic.ttf', name='Noto Sans Display', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Italic.otf', name='P052', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/georgiaz.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/arphic-bkai00mp/bkai00mp.ttf', name='AR PL KaitiM Big5', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebucbi.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADFNo2-Bold.otf', name='Gillius ADF No2', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArmenian-Bold.ttf', name='Noto Sans Armenian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Verdana_Bold_Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHanifiRohingya-Regular.ttf', name='Noto Sans Hanifi Rohingya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-Italic.otf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-Italic.otf', name='Lobster Two', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Italic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstFarsi.ttf', name='KacstFarsi', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnShinmun.ttf', name='UnShinmun', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhmer-Bold.ttf', name='Noto Sans Khmer', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-Italic.ttf', name='Arimo', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/timesbd.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-BoldItalic.ttf', name='Caladea', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono-BoldOblique.otf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/UniversalisADFStd-Cond.otf', name='Universalis ADF Std', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Thin.otf', name='Cantarell', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-Italic.otf', name='Berenis ADF Pro', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Italic.otf', name='C059', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari.ttf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RZ.otf', name='Linux Libertine O', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Bold.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXSizeFiveSym-Regular.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerif.ttf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansIndicSiyaqNumbers-Regular.ttf', name='Noto Sans Indic Siyaq Numbers', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/freefont/FreeSansBold.otf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-BoldOblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cabin/Cabin-SemiBold.otf', name='Cabin', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCanadianAboriginal-Regular.ttf', name='Noto Sans Canadian Aboriginal', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee-BoldOblique.otf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstOffice.ttf', name='KacstOffice', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/vemana2000.ttf', name='Vemana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/Amiri-Bold.ttf', name='Amiri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFProMath-Regular.otf', name='Berenis ADF Pro Math', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono.otf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamilSlanted-Regular.ttf', name='Noto Serif Tamil Slanted', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTibetan-Regular.ttf', name='Noto Sans Tibetan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/kalimati.ttf', name='Kalimati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-BoldOblique.ttf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansHebrew-Regular.ttf', name='Noto Sans Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldSogdian-Regular.ttf', name='Noto Sans Old Sogdian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-SemiboldItalic.ttf', name='Lato', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifSinhala-Regular.ttf', name='Noto Serif Sinhala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Heavy.ttf', name='Lato', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifHebrew-Regular.ttf', name='Noto Serif Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/baekmuk/gulim.ttf', name='Baekmuk Gulim', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode-Bold.ttf', name='Junicode', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/font-awesome/fontawesome-webfont.ttf', name='FontAwesome', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Garuda-BoldOblique.otf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Sawasdee-Oblique.otf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Cousine-Bold.ttf', name='Cousine', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Regular.otf', name='Gayathri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasBI.ttf', name='Gentium Book Basic', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf', name='Ubuntu', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-BoldItalic.otf', name='Lobster Two', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-BoldOblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-Regular.otf', name='Lobster Two', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_RI.otf', name='Linux Biolinum O', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTamil-Regular.ttf', name='Noto Sans Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMalayalam-Bold.ttf', name='Noto Sans Malayalam', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnGraphic.ttf', name='UnGraphic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArmenian-Regular.ttf', name='Noto Sans Armenian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Bold.otf', name='Gillius ADF', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifKhmer-Regular.ttf', name='Noto Serif Khmer', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-punjabi/Lohit-Gurmukhi.ttf', name='Lohit Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree.ttf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gargi/Gargi.ttf', name='Gargi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/LikhanNormal.ttf', name='Likhan', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/junicode/Junicode.ttf', name='Junicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond12-AllSC.ttf', name='EB Garamond 12 All SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Arimo-Regular.ttf', name='Arimo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSans-Italic.ttf', name='Noto Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-L.ttf', name='Ubuntu', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/verdanai.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Comic_Sans_MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-CondLight.ttf', name='Open Sans', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Italic.ttf', name='Roboto', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 0.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypo-Bold.otf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraBI.ttf', name='Bitstream Vera Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.244090909090909\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/AccanthisADFStdNo3-BoldItalic.otf', name='Accanthis ADF Std No3', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Bold.otf', name='C059', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsSm-Bold.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/msam10.ttf', name='msam10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebuc.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil/Lohit-Tamil.ttf', name='Lohit Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDinaru.ttf', name='UnDinaru', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda.ttf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPalmyrene-Regular.ttf', name='Noto Sans Palmyrene', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitle.ttf', name='KacstTitle', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDecorative.ttf', name='KacstDecorative', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Bold.otf', name='Gayathri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansPsalterPahlavi-Regular.ttf', name='Noto Sans Psalter Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/samanata.ttf', name='Samanata', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDisplay-Italic.ttf', name='Noto Serif Display', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Bold.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-japanese-mincho.ttf', name='IPAexMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTibetan-Bold.ttf', name='Noto Sans Tibetan', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUp-Bold.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-extra/UnJamoSora.ttf', name='UnJamoSora', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/fonts-hosny-amiri/AmiriQuran.ttf', name='Amiri Quran', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Medium.ttf', name='Lato', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGujarati-Bold.ttf', name='Noto Sans Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-Bold.otf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMyanmar-Bold.ttf', name='Noto Sans Myanmar', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Arial_Black.ttf', name='Arial Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Trebuchet_MS_Bold_Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/solomos/GFSSolomos.otf', name='GFS Solomos', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThai-Regular.ttf', name='Noto Sans Thai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXGeneral-BoldItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-ExtraBoldItalic.ttf', name='Open Sans', style='italic', variant='normal', weight=800, stretch='normal', size='scalable')) = 11.43\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpD-Regular.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifTamil-Regular.ttf', name='Noto Serif Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansTelugu-Bold.ttf', name='Noto Sans Telugu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-BoldOblique.ttf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinBiolinum_RB.otf', name='Linux Biolinum O', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gubbi/Gubbi.ttf', name='Gubbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansAnatolianHieroglyphs-Regular.ttf', name='Noto Sans Anatolian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-bitstream-vera/VeraMoBI.ttf', name='Bitstream Vera Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Oblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDevanagari-Bold.ttf', name='Noto Serif Devanagari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Italic.ttf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Bold.ttf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Light.ttf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstScreen.ttf', name='KacstScreen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Bold.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifMyanmar-Regular.ttf', name='Noto Serif Myanmar', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldNorthArabian-Regular.ttf', name='Noto Sans Old North Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifDogra-Regular.ttf', name='Noto Serif Dogra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/ariblk.ttf', name='Arial Black', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGeorgian-Bold.ttf', name='Noto Sans Georgian', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-RI.ttf', name='Ubuntu', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansEthiopic-Bold.ttf', name='Noto Sans Ethiopic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifAhom-Regular.ttf', name='Noto Serif Ahom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Uroob-Regular.ttf', name='Uroob', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/stix/STIXIntegralsUpSm-Regular.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKhudawadi-Regular.ttf', name='Noto Sans Khudawadi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Bold.1.1.ttf', name='padmaa-Bold.1.1', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/theokritos/GFSTheokritos.otf', name='GFS Theokritos', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-Th.ttf', name='Ubuntu', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman_Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/trebucit.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Kinnari-Bold.otf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Medium-0.5.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramond12-Regular.ttf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/cour.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMeroitic-Regular.ttf', name='Noto Sans Meroitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansArabic-Bold.ttf', name='Noto Sans Arabic', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Smallcaps.ttf', name='Go Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/artemisia/GFSArtemisia.otf', name='GFS Artemisia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Medium.ttf', name='Roboto Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Laksaman-Italic.otf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/RaghuMalayalamSans-Regular.ttf', name='RaghuMalayalamSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lato/Lato-Regular.ttf', name='Lato', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/courbd.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifGujarati-Regular.ttf', name='Noto Serif Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Roman.otf', name='C059', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentiumplus/GentiumPlus-I.ttf', name='Gentium Plus', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lyx/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne-Bold.ttf', name='KacstOne', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Gujarati.ttf', name='Samyak Gujarati', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Nakula/nakula.ttf', name='Nakula', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ebgaramond/EBGaramondSC12-Regular.ttf', name='EB Garamond SC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Oblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-mincho/ipam.ttf', name='IPAMincho', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Purisa.otf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Malayalam.ttf', name='Samyak Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-bengali/Lohit-Bengali.ttf', name='Lohit Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerifCondensed-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Italic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/comfortaa/Comfortaa-Regular.ttf', name='Comfortaa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/Georgia_Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/GilliusADF-Cond.otf', name='Gillius ADF', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/andalemo.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansCaucasianAlbanian-Regular.ttf', name='Noto Sans Caucasian Albanian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoCondensed-Italic.ttf', name='Roboto Condensed', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Oblique.ttf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnBatang.ttf', name='UnBatang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/linux-libertine/LinLibertine_RBI.otf', name='Linux Libertine O', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/lobstertwo/LobsterTwo-Bold.otf', name='Lobster Two', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOS.ttf', name='Khmer OS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/roboto/unhinted/RobotoTTF/Roboto-Bold.ttf', name='Roboto', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/open-sans/OpenSans-Italic.ttf', name='Open Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansKannada-Bold.ttf', name='Noto Sans Kannada', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgMono-Oblique.otf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansGrantha-Regular.ttf', name='Noto Sans Grantha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Bold.ttf', name='Go', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThai-Bold.ttf', name='Noto Sans Thai', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/msttcorefonts/impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/cantarell/Cantarell-Regular.otf', name='Cantarell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansLinearA-Regular.ttf', name='Noto Sans Linear A', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/croscore/Tinos-Bold.ttf', name='Tinos', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/gentium-basic/GenBkBasI.ttf', name='Gentium Book Basic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/TlwgTypist-BoldOblique.otf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ebgaramond/EBGaramond12-Regular.otf', name='EB Garamond', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree-BoldOblique.otf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/unfonts-core/UnDotum.ttf', name='UnDotum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/crosextra/Caladea-Bold.ttf', name='Caladea', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Waree-Bold.otf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf', name='IPAPGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansJavanese-Regular.ttf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-ExtraLight.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 0.24\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/fonts-go/Go-Regular.ttf', name='Go', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-devanagari/Lohit-Devanagari.ttf', name='Lohit Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/adf/BerenisADFPro-BoldItalic.otf', name='Berenis ADF Pro', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/opentype/tlwg/Umpush-Oblique.otf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/JamrulNormal.ttf', name='Jamrul', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145\n",
      "2025-09-16 09:50:06 matplotlib.font_manager DEBUG    findfont: Matching sans\\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"selection/optimized_backup_heads\",\n",
    "#     mt.name.split(\"/\")[-1],\n",
    "#     f\"{select_task.task_name}.npz\"\n",
    "# )\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/optimized_heads\",\n",
    "    model_key.split(\"/\")[-1],\n",
    "    \"distinct_options\",\n",
    "    f\"{optimized_task.task_name}\",\n",
    "    \"legacy\",\n",
    "    \"epoch_10.npz\"\n",
    ")\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"test_opt_code\",\n",
    "#     model_key.split(\"/\")[-1],\n",
    "#     \"distinct_options\",\n",
    "#     f\"{select_task.task_name}\",\n",
    "#     \"legacy\",\n",
    "#     \"epoch_10.npz\"\n",
    "# )\n",
    "\n",
    "optimization_results = np.load(optimized_path, allow_pickle=True)\n",
    "plt.plot(optimization_results[\"losses\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdcc867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(torch.float32)\n",
    "optimal_head_mask[52:, :] = 0.0\n",
    "\n",
    "plt.imshow(\n",
    "    optimal_head_mask.T.numpy(),\n",
    "    cmap=\"Blues\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "optimized_heads = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).tolist()\n",
    "optimized_heads = [\n",
    "    (layer_idx, head_idx) for layer_idx, head_idx in optimized_heads\n",
    "]\n",
    "print(len(optimized_heads))\n",
    "\n",
    "HEADS = optimized_heads\n",
    "\n",
    "(35, 19) in HEADS, (35, 19) in optimized_heads\n",
    "# [(29, 3) in HEADS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb620ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:23 src.selection.functional DEBUG    Predictions: ['\" Strawberry\"[89077] (p=0.471, logit=18.750)', '\" Grape\"[80629] (p=0.173, logit=17.750)', '\" The\"[578] (p=0.093, logit=17.125)', '\" Er\"[9939] (p=0.064, logit=16.750)', '\" There\"[2684] (p=0.018, logit=15.500)']\n",
      "2025-09-16 09:50:23 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cf511b21-0b2e\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cf511b21-0b2e\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Blue\", \"berry\", \",\", \" E\", \"arring\", \",\", \" Grape\", \",\", \" Pants\", \",\", \" Strawberry\", \",\", \" Har\", \"p\", \",\", \" Tennis\", \" ball\", \",\", \" Er\", \"aser\", \".\\n\", \"What\", \" is\", \" the\", \" last\", \" fruit\", \" in\", \" this\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.019243841990828514, 0.0013634136412292719, 0.0029026023112237453, 0.010369143448770046, 0.004353123717010021, 0.0017733557615429163, 0.0048056538216769695, 0.008030871860682964, 0.014418213628232479, 0.010036197490990162, 0.007434305734932423, 0.005936421919614077, 0.056740373373031616, 0.020160499960184097, 0.0058803921565413475, 0.003462922992184758, 0.007672497536987066, 0.006169273052364588, 0.01135377585887909, 0.009215358644723892, 0.007300912868231535, 0.01059517078101635, 0.008864357136189938, 0.0026738853193819523, 0.0024167639203369617, 0.005095560569316149, 0.018098702654242516, 0.09630858153104782, 0.02853330411016941, 0.00564032094553113, 0.017711754888296127, 0.010436153039336205, 0.030604947358369827, 0.014826169237494469, 0.07780035585165024]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f195c196110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.attention import get_attention_matrices\n",
    "from src.selection.functional import (\n",
    "    verify_head_patterns,\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    ")\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=sample.prompt(option_style=\"single_line\"),\n",
    "    options=sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fff0b",
   "metadata": {},
   "source": [
    "# Validating Against Other Reduce Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c517d0",
   "metadata": {},
   "source": [
    "## SelectOne Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257b8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'prompt_templates', 'odd_one_prompt_templates', 'order_prompt_templates', 'count_prompt_templates', 'yes_no_prompt_templates', 'first_item_in_cat_prompt_templates', 'last_item_in_cat_prompt_templates', 'categories', 'exclude_categories']\n",
      "SelectOneTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n",
      "{'fruit': ['flower', 'tree', 'vegetable'], 'flower': ['fruit', 'tree', 'vegetable'], 'tree': ['fruit', 'flower'], 'vegetable': ['fruit', 'flower'], 'electronics': ['kitchen appliance', 'office supply'], 'kitchen appliance': ['electronics', 'office supply'], 'office supply': ['electronics', 'kitchen appliance']}\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample, SelectOneTask\n",
    "\n",
    "select_one_task = SelectOneTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        # \"landmarks.json\"\n",
    "        # \"rhymes.json\"\n",
    "    )\n",
    ")\n",
    "print(select_one_task)\n",
    "print(select_one_task.exclude_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f19a798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Charm, Pressure cooker, Speaker, Pants, Stool, Blueberry.\n",
      "Which among these objects mentioned above is a clothing?\n",
      "Answer: >> \" Pants\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Pants', prob=0.796875, logit=21.625, token_id=67553, metadata=None),\n",
       " PredictedToken(token=' The', prob=0.083984375, logit=19.375, token_id=578, metadata=None),\n",
       " PredictedToken(token=' Among', prob=0.07421875, logit=19.25, token_id=22395, metadata=None),\n",
       " PredictedToken(token=' pants', prob=0.0078125, logit=17.0, token_id=25567, metadata=None),\n",
       " PredictedToken(token=' Pant', prob=0.004730224609375, logit=16.5, token_id=54222, metadata=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = select_one_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    # category=\"fruit\",\n",
    "    # category=\"actor\",\n",
    "    # category=\"United Kingdom\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "# test_sample.prompt_template = \"Recall the nationality of these people:\\n\" + test_sample.prompt_template\n",
    "# test_sample.prompt_template = \"Recall which country these landmarks are located in:\\n\" + test_sample.prompt_template\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fc685a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:33 src.selection.functional DEBUG    Predictions: ['\" Pants\"[67553] (p=0.797, logit=21.625)', '\" The\"[578] (p=0.084, logit=19.375)', '\" Among\"[22395] (p=0.074, logit=19.250)', '\" pants\"[25567] (p=0.008, logit=17.000)', '\" Pant\"[54222] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:50:33 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-93ae8f20-aa49\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-93ae8f20-aa49\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Charm\", \",\", \" Pressure\", \" cooker\", \",\", \" Speaker\", \",\", \" Pants\", \",\", \" St\", \"ool\", \",\", \" Blue\", \"berry\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" clothing\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.02629883773624897, 0.009016257710754871, 0.005433450918644667, 0.0067875268869102, 0.00277409958653152, 0.005378942005336285, 0.015775693580508232, 0.005477753933519125, 0.011000054888427258, 0.06994568556547165, 0.01913062483072281, 0.005213525146245956, 0.011633872985839844, 0.009417606517672539, 0.00401355791836977, 0.006609535310417414, 0.01955355890095234, 0.00829737726598978, 0.013930518180131912, 0.011395220644772053, 0.009545532986521721, 0.007644100114703178, 0.006777417846024036, 0.007836448028683662, 0.007220511790364981, 0.06069459766149521, 0.0682457759976387, 0.027452556416392326, 0.06711968034505844]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7ef8b9d1d790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71509977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_one_task.task_name,\n",
    "    \"objects\",\n",
    "    # \"profession\",\n",
    "    # \"nationality\",\n",
    "    # \"landmarks\"\n",
    "    # \"rhymes\"\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 474\n",
    "start_from = 550\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_one_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_one_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(2, 6)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(\n",
    "            validation_samples_save_path,\n",
    "            f\"{len(validation_set) + start_from - 1:05d}.json\",\n",
    "        ),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f353375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:47 __main__ INFO     Found 1024 sample files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_one_task.task_name,\n",
    "    \"objects\",\n",
    "    # \"profession\",\n",
    "    # \"nationality\"\n",
    "    # \"landmarks\",\n",
    "    # \"rhymes\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "prefix = \"\"\n",
    "# prefix = \"Recall the nationality of these people:\\n\"\n",
    "# prefix = \"Recall which country these landmarks are located in:\\n\"\n",
    "# prefix = \"Think about how these words sound when you say them aloud:\\n\"\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    # cf_pair.patch_sample.default_option_style = \"bulleted\"\n",
    "    # cf_pair.clean_sample.default_option_style = \"bulleted\"\n",
    "\n",
    "    cf_pair.clean_sample.prompt_template = prefix + cf_pair.clean_sample.prompt_template\n",
    "    cf_pair.patch_sample.prompt_template = prefix + cf_pair.patch_sample.prompt_template\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca935a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Scooter, Carrot, Tie, Jasmine.\n",
      "Which among these objects mentioned above is a vegetable?\n",
      "Answer: >>  Car\n",
      "Options: Guitar, Dog, Marigold, Broccoli.\n",
      "Which among these objects mentioned above is a flower?\n",
      "Answer: >>  Mar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6031, ' Bro')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0064aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:53 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:50:53 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:50:53 src.selection.optimization INFO     Verifying head behavior...\n",
      "2025-09-16 09:50:53 src.selection.optimization INFO     Clean Sample >> Ans:  Daisy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:57 src.selection.functional DEBUG    Generated full answer: \" Daisy.\n",
      "Explanation: A daisy is a type of flower. The other options are not flowers. A ruler is a tool used for measuring, a\"\n",
      "2025-09-16 09:50:57 src.selection.functional DEBUG    Predictions: ['\" Daisy\"[71264] (p=0.605, logit=21.125)', '\" The\"[578] (p=0.152, logit=19.750)', '\" A\"[362] (p=0.105, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" d\"[294] (p=0.034, logit=18.250)']\n",
      "2025-09-16 09:50:57 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b728b83d-61e0\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b728b83d-61e0\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" R\", \"uler\", \",\", \" Mirror\", \",\", \" Piano\", \",\", \" Daisy\", \",\", \" Gloves\", \",\", \" Ti\", \"ara\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" flower\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.02677886001765728, 0.006947316695004702, 0.0030851562041789293, 0.004314008168876171, 0.009327171370387077, 0.005205544177442789, 0.004766852129250765, 0.004892740398645401, 0.011405648663640022, 0.055188678205013275, 0.018147919327020645, 0.006997446995228529, 0.012318545021116734, 0.0024246659595519304, 0.006654601078480482, 0.022292327135801315, 0.010590368881821632, 0.015601473860442638, 0.012709722854197025, 0.008951683528721333, 0.011437922716140747, 0.00978812389075756, 0.010073967278003693, 0.008283305913209915, 0.05994925647974014, 0.05993962660431862, 0.032192934304475784, 0.06315591931343079]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7ef8b9d02310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:50:57 src.selection.optimization INFO     Patch Sample >> Ans:  Stap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:51:01 src.selection.functional DEBUG    Generated full answer: \" Stapler.\n",
      "Explanation: A stapler is a common office supply used to attach papers together. The other options are not typically considered office supplies. A\"\n",
      "2025-09-16 09:51:01 src.selection.functional DEBUG    Predictions: ['\" Stap\"[63606] (p=0.641, logit=20.625)', '\" The\"[578] (p=0.126, logit=19.000)', '\" A\"[362] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.059, logit=18.250)', '\" stap\"[36114] (p=0.017, logit=17.000)']\n",
      "2025-09-16 09:51:01 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-494ee3d1-2444\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-494ee3d1-2444\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Ring\", \",\", \" Camera\", \",\", \" Boat\", \",\", \" Tul\", \"ip\", \",\", \" Stap\", \"ler\", \",\", \" Cat\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" office\", \" supply\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.03007686138153076, 0.008368678390979767, 0.010357403196394444, 0.013285761699080467, 0.009248733520507812, 0.009252735413610935, 0.004909384064376354, 0.017651261761784554, 0.002223230665549636, 0.00625027297064662, 0.007233606651425362, 0.026778044179081917, 0.04889195039868355, 0.018887219950556755, 0.009794600307941437, 0.017668448388576508, 0.008347231894731522, 0.009625473991036415, 0.011065029539167881, 0.011049672029912472, 0.0067058103159070015, 0.005500984378159046, 0.007741197943687439, 0.010418280027806759, 0.02539745159447193, 0.04868130013346672, 0.05694587901234627, 0.026313459500670433, 0.06640169769525528]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7ef8b9e421d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:51:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:02 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.641, logit=20.625)', '\" The\"[578] (p=0.126, logit=19.000)', '\" A\"[362] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.059, logit=18.250)', '\" stap\"[36114] (p=0.017, logit=17.000)']\n",
      "2025-09-16 09:51:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:02 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.605, logit=21.125)', '\" The\"[578] (p=0.152, logit=19.750)', '\" A\"[362] (p=0.105, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" d\"[294] (p=0.034, logit=18.250)']\n",
      "2025-09-16 09:51:02 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.60546875, logit=21.125, token_id=71264, metadata=None))), (432, (39, PredictedToken(token=' R', prob=0.00014781951904296875, logit=12.8125, token_id=432, metadata=None))), (23126, (50, PredictedToken(token=' Ti', prob=9.012222290039062e-05, logit=12.3125, token_id=23126, metadata=None))), (34954, (388, PredictedToken(token=' Mirror', prob=2.3990869522094727e-06, logit=8.6875, token_id=34954, metadata=None))), (56491, (631, PredictedToken(token=' Piano', prob=1.2069940567016602e-06, logit=8.0, token_id=56491, metadata=None))), (68554, (2394, PredictedToken(token=' Gloves', prob=2.2258609533309937e-07, logit=6.3125, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:51:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:02 src.selection.functional DEBUG    Predictions: ['\" Mirror\"[34954] (p=0.346, logit=19.750)', '\" The\"[578] (p=0.186, logit=19.125)', '\" R\"[432] (p=0.128, logit=18.750)', '\" Gloves\"[68554] (p=0.112, logit=18.625)', '\" Among\"[22395] (p=0.068, logit=18.125)']\n",
      "2025-09-16 09:51:02 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c4c25e00-d4fd\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c4c25e00-d4fd\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" R\", \"uler\", \",\", \" Mirror\", \",\", \" Piano\", \",\", \" Daisy\", \",\", \" Gloves\", \",\", \" Ti\", \"ara\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" flower\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.0368010438978672, 0.009696605615317822, 0.011205683462321758, 0.024462351575493813, 0.029427213594317436, 0.01428769901394844, 0.014167808927595615, 0.014639828354120255, 0.015647368505597115, 0.00821435172110796, 0.008390804752707481, 0.02505268156528473, 0.01762099377810955, 0.007705932017415762, 0.011743933893740177, 0.021299835294485092, 0.008877438493072987, 0.011760254390537739, 0.015756843611598015, 0.016367129981517792, 0.009094195440411568, 0.0062082866206765175, 0.0094926031306386, 0.018493184819817543, 0.030379338189959526, 0.028753718361258507, 0.02252853475511074, 0.032740268856287]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f195c244210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:51:02 src.selection.optimization INFO     int_prediction=['\" Mirror\"[34954] (p=0.346, logit=19.750)', '\" The\"[578] (p=0.186, logit=19.125)', '\" R\"[432] (p=0.128, logit=18.750)', '\" Gloves\"[68554] (p=0.112, logit=18.625)', '\" Among\"[22395] (p=0.068, logit=18.125)']\n",
      "2025-09-16 09:51:02 src.selection.optimization INFO     int_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.345703125, logit=19.75, token_id=34954, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.1279296875, logit=18.75, token_id=432, metadata=None))), (68554, (4, PredictedToken(token=' Gloves', prob=0.1123046875, logit=18.625, token_id=68554, metadata=None))), (56491, (7, PredictedToken(token=' Piano', prob=0.0220947265625, logit=17.0, token_id=56491, metadata=None))), (23126, (16, PredictedToken(token=' Ti', prob=0.0019378662109375, logit=14.5625, token_id=23126, metadata=None))), (71264, (155, PredictedToken(token=' Daisy', prob=2.5987625122070312e-05, logit=10.25, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:51:02 __main__ DEBUG    clean obj:  Daisy\n",
      "2025-09-16 09:51:02 __main__ DEBUG    target obj:  R\n",
      "2025-09-16 09:51:02 __main__ INFO     Clean Prediction Rank Change: 1 -> 155 | Delta: 154 \n",
      "2025-09-16 09:51:02 __main__ INFO     Target Prediction Rank Change: 39 -> 3 | Delta: -36 \n",
      "2025-09-16 09:51:02 __main__ INFO     Clean Prediction Logit Change: 21.1250 -> 10.2500 | Delta: -10.8750 \n",
      "2025-09-16 09:51:02 __main__ INFO     Target Prediction Logit Change: 12.8125 -> 18.7500 | Delta: 5.9375 \n"
     ]
    }
   ],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "import copy\n",
    "\n",
    "clean, patch = copy.deepcopy(validation_set[5])\n",
    "# failed_case = failed_pos_track[\"patch_obj_idx\"][5]\n",
    "# clean = failed_case[\"clean_sample\"]\n",
    "# patch = failed_case[\"patch_sample\"]\n",
    "# clean.default_option_style=\"numbered\"\n",
    "# patch.default_option_style=\"numbered\"\n",
    "\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    "    patch_args={\n",
    "        \"batch_size\": len(patch.options),\n",
    "        \"distinct_options\": False,\n",
    "        # \"task\": select_task,\n",
    "        # \"prompt_template_idx\": prompt_template_idx,\n",
    "        # \"option_style\": patch.default_option_style,\n",
    "        # \"n_distractors\": N_DISTRACTORS,\n",
    "    },\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f130d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03472d8db87424a80981c57f1109826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:51:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:08 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:51:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:51:09 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.820, logit=21.000)', '\" None\"[2290] (p=0.077, logit=18.625)', '\" The\"[578] (p=0.025, logit=17.500)', '\" There\"[2684] (p=0.013, logit=16.875)', '\" Among\"[22395] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.895, logit=22.625)', '\" Among\"[22395] (p=0.045, logit=19.625)', '\" The\"[578] (p=0.035, logit=19.375)', '\" E\"[469] (p=0.003, logit=16.750)', '\" as\"[439] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.89453125, logit=22.625, token_id=1666, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.0025177001953125, logit=16.75, token_id=469, metadata=None))), (83499, (41, PredictedToken(token=' Tooth', prob=8.058547973632812e-05, logit=13.3125, token_id=83499, metadata=None))), (38930, (371, PredictedToken(token=' Bike', prob=1.1548399925231934e-06, logit=9.0625, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.848, logit=22.125)', '\" The\"[578] (p=0.062, logit=19.500)', '\" Among\"[22395] (p=0.042, logit=19.125)', '\" Option\"[7104] (p=0.006, logit=17.250)', '\" As\"[1666] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.84765625, logit=22.125, token_id=469, metadata=None))), (1666, (5, PredictedToken(token=' As', prob=0.005706787109375, logit=17.125, token_id=1666, metadata=None))), (83499, (75, PredictedToken(token=' Tooth', prob=4.100799560546875e-05, logit=12.1875, token_id=83499, metadata=None))), (38930, (468, PredictedToken(token=' Bike', prob=1.0281801223754883e-06, logit=8.5, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:09 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:09 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:51:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     patch_prediction=['\" Truck\"[34785] (p=0.746, logit=22.125)', '\" The\"[578] (p=0.114, logit=20.250)', '\" A\"[362] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.033, logit=19.000)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     clean_prediction=['\" Fl\"[3061] (p=0.812, logit=22.000)', '\" The\"[578] (p=0.097, logit=19.875)', '\" A\"[362] (p=0.028, logit=18.625)', '\" Among\"[22395] (p=0.013, logit=17.875)', '\" flute\"[96812] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     clean_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.8125, logit=22.0, token_id=3061, metadata=None))), (6914, (21, PredictedToken(token=' Let', prob=0.0003490447998046875, logit=14.25, token_id=6914, metadata=None))), (50159, (136, PredictedToken(token=' Sco', prob=7.748603820800781e-06, logit=10.4375, token_id=50159, metadata=None)))])\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.891, logit=21.750)', '\" The\"[578] (p=0.031, logit=18.375)', '\" A\"[362] (p=0.024, logit=18.125)', '\" Fl\"[3061] (p=0.016, logit=17.750)', '\" (\"[320] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.890625, logit=21.75, token_id=50159, metadata=None))), (3061, (4, PredictedToken(token=' Fl', prob=0.016357421875, logit=17.75, token_id=3061, metadata=None))), (6914, (9, PredictedToken(token=' Let', prob=0.00250244140625, logit=15.875, token_id=6914, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:10 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     patch_prediction=['\" Pendant\"[81501] (p=0.934, logit=22.875)', '\" The\"[578] (p=0.025, logit=19.250)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" A\"[362] (p=0.013, logit=18.625)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.660, logit=22.500)', '\" The\"[578] (p=0.147, logit=21.000)', '\" A\"[362] (p=0.115, logit=20.750)', '\" Among\"[22395] (p=0.048, logit=19.875)', '\" (\"[320] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.66015625, logit=22.5, token_id=34785, metadata=None))), (356, (19, PredictedToken(token=' C', prob=0.000469207763671875, logit=15.25, token_id=356, metadata=None))), (6031, (107, PredictedToken(token=' Bro', prob=1.1742115020751953e-05, logit=11.5625, token_id=6031, metadata=None)))])\n",
      "2025-09-16 09:51:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.793, logit=23.000)', '\" A\"[362] (p=0.083, logit=20.750)', '\" The\"[578] (p=0.074, logit=20.625)', '\" C\"[356] (p=0.016, logit=19.125)', '\" Among\"[22395] (p=0.010, logit=18.625)']\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.79296875, logit=23.0, token_id=6031, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.0164794921875, logit=19.125, token_id=356, metadata=None))), (34785, (6, PredictedToken(token=' Truck', prob=0.004150390625, logit=17.75, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:11 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.832, logit=22.000)', '\" The\"[578] (p=0.060, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=19.125)', '\" A\"[362] (p=0.022, logit=18.375)', '\" Option\"[7104] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     clean_prediction=['\" Mar\"[2947] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.077, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=19.000)', '\" A\"[362] (p=0.022, logit=18.500)', '\" (\"[320] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     clean_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.82421875, logit=22.125, token_id=2947, metadata=None))), (6031, (23, PredictedToken(token=' Bro', prob=0.0004024505615234375, logit=14.5, token_id=6031, metadata=None))), (14588, (115, PredictedToken(token=' Dog', prob=1.2934207916259766e-05, logit=11.0625, token_id=14588, metadata=None))), (47759, (560, PredictedToken(token=' Guitar', prob=7.301568984985352e-07, logit=8.1875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.699, logit=22.000)', '\" Mar\"[2947] (p=0.156, logit=20.500)', '\" The\"[578] (p=0.058, logit=19.500)', '\" Among\"[22395] (p=0.051, logit=19.375)', '\" (\"[320] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.69921875, logit=22.0, token_id=6031, metadata=None))), (2947, (2, PredictedToken(token=' Mar', prob=0.15625, logit=20.5, token_id=2947, metadata=None))), (14588, (13, PredictedToken(token=' Dog', prob=0.0009307861328125, logit=15.375, token_id=14588, metadata=None))), (47759, (1409, PredictedToken(token=' Guitar', prob=2.2817403078079224e-07, logit=7.0625, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:11 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:51:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.684, logit=20.250)', '\" The\"[578] (p=0.092, logit=18.250)', '\" Among\"[22395] (p=0.049, logit=17.625)', '\" Oak\"[18787] (p=0.044, logit=17.500)', '\" None\"[2290] (p=0.021, logit=16.750)']\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.770, logit=21.500)', '\" The\"[578] (p=0.071, logit=19.125)', '\" A\"[362] (p=0.063, logit=19.000)', '\" Among\"[22395] (p=0.049, logit=18.750)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.76953125, logit=21.5, token_id=42609, metadata=None))), (87035, (43, PredictedToken(token=' Onion', prob=0.00013828277587890625, logit=12.875, token_id=87035, metadata=None))), (15429, (80, PredictedToken(token=' Hospital', prob=3.719329833984375e-05, logit=11.5625, token_id=15429, metadata=None))), (27171, (113, PredictedToken(token=' Coffee', prob=1.8715858459472656e-05, logit=10.875, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     int_prediction=['\" Hospital\"[15429] (p=0.816, logit=22.125)', '\" The\"[578] (p=0.046, logit=19.250)', '\" A\"[362] (p=0.036, logit=19.000)', '\" Pine\"[42609] (p=0.031, logit=18.875)', '\" Among\"[22395] (p=0.028, logit=18.750)']\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     int_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.81640625, logit=22.125, token_id=15429, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.031494140625, logit=18.875, token_id=42609, metadata=None))), (27171, (11, PredictedToken(token=' Coffee', prob=0.00201416015625, logit=16.125, token_id=27171, metadata=None))), (87035, (134, PredictedToken(token=' Onion', prob=1.2755393981933594e-05, logit=11.0625, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:12 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:12 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.641, logit=20.625)', '\" The\"[578] (p=0.126, logit=19.000)', '\" A\"[362] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.059, logit=18.250)', '\" stap\"[36114] (p=0.017, logit=17.000)']\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.605, logit=21.125)', '\" The\"[578] (p=0.152, logit=19.750)', '\" A\"[362] (p=0.105, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" d\"[294] (p=0.034, logit=18.250)']\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.60546875, logit=21.125, token_id=71264, metadata=None))), (432, (39, PredictedToken(token=' R', prob=0.00014781951904296875, logit=12.8125, token_id=432, metadata=None))), (23126, (50, PredictedToken(token=' Ti', prob=9.012222290039062e-05, logit=12.3125, token_id=23126, metadata=None))), (34954, (388, PredictedToken(token=' Mirror', prob=2.3990869522094727e-06, logit=8.6875, token_id=34954, metadata=None))), (56491, (631, PredictedToken(token=' Piano', prob=1.2069940567016602e-06, logit=8.0, token_id=56491, metadata=None))), (68554, (2394, PredictedToken(token=' Gloves', prob=2.2258609533309937e-07, logit=6.3125, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:51:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     int_prediction=['\" Mirror\"[34954] (p=0.346, logit=19.750)', '\" The\"[578] (p=0.186, logit=19.125)', '\" R\"[432] (p=0.128, logit=18.750)', '\" Gloves\"[68554] (p=0.112, logit=18.625)', '\" A\"[362] (p=0.068, logit=18.125)']\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     int_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.345703125, logit=19.75, token_id=34954, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.1279296875, logit=18.75, token_id=432, metadata=None))), (68554, (4, PredictedToken(token=' Gloves', prob=0.1123046875, logit=18.625, token_id=68554, metadata=None))), (56491, (7, PredictedToken(token=' Piano', prob=0.0220947265625, logit=17.0, token_id=56491, metadata=None))), (23126, (17, PredictedToken(token=' Ti', prob=0.0019378662109375, logit=14.5625, token_id=23126, metadata=None))), (71264, (156, PredictedToken(token=' Daisy', prob=2.5987625122070312e-05, logit=10.25, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:13 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.746, logit=21.500)', '\" The\"[578] (p=0.089, logit=19.375)', '\" An\"[1556] (p=0.069, logit=19.125)', '\" Among\"[22395] (p=0.037, logit=18.500)', '\" Only\"[8442] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.898, logit=22.000)', '\" None\"[2290] (p=0.031, logit=18.625)', '\" A\"[362] (p=0.016, logit=18.000)', '\" The\"[578] (p=0.013, logit=17.750)', '\" pin\"[9160] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.8984375, logit=22.0, token_id=17929, metadata=None))), (49431, (9, PredictedToken(token=' Rabbit', prob=0.001739501953125, logit=15.75, token_id=49431, metadata=None))), (72392, (14, PredictedToken(token=' Mixer', prob=0.000820159912109375, logit=15.0, token_id=72392, metadata=None)))])\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.648, logit=20.625)', '\" A\"[362] (p=0.145, logit=19.125)', '\" The\"[578] (p=0.060, logit=18.250)', '\" Pin\"[17929] (p=0.042, logit=17.875)', '\" None\"[2290] (p=0.032, logit=17.625)']\n",
      "2025-09-16 09:51:13 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.6484375, logit=20.625, token_id=72392, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.04150390625, logit=17.875, token_id=17929, metadata=None))), (49431, (7, PredictedToken(token=' Rabbit', prob=0.00634765625, logit=16.0, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.758, logit=21.375)', '\" The\"[578] (p=0.090, logit=19.250)', '\" Among\"[22395] (p=0.062, logit=18.875)', '\" A\"[362] (p=0.033, logit=18.250)', '\" strawberry\"[73700] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     clean_prediction=['\" Rose\"[16344] (p=0.777, logit=21.250)', '\" A\"[362] (p=0.072, logit=18.875)', '\" The\"[578] (p=0.056, logit=18.625)', '\" Among\"[22395] (p=0.014, logit=17.250)', '\" None\"[2290] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     clean_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.77734375, logit=21.25, token_id=16344, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0086669921875, logit=16.75, token_id=356, metadata=None))), (41493, (14, PredictedToken(token=' Tow', prob=0.00170135498046875, logit=15.125, token_id=41493, metadata=None))), (10164, (74, PredictedToken(token=' Water', prob=6.198883056640625e-05, logit=11.8125, token_id=10164, metadata=None))), (38258, (1077, PredictedToken(token=' Baseball', prob=7.338821887969971e-07, logit=7.375, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.766, logit=21.750)', '\" Water\"[10164] (p=0.117, logit=19.875)', '\" A\"[362] (p=0.038, logit=18.750)', '\" The\"[578] (p=0.023, logit=18.250)', '\" None\"[2290] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.765625, logit=21.75, token_id=16344, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.1171875, logit=19.875, token_id=10164, metadata=None))), (41493, (9, PredictedToken(token=' Tow', prob=0.0035400390625, logit=16.375, token_id=41493, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.0014801025390625, logit=15.5, token_id=356, metadata=None))), (38258, (1049, PredictedToken(token=' Baseball', prob=5.103647708892822e-07, logit=7.53125, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:14 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-16 09:51:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.785, logit=21.000)', '\" The\"[578] (p=0.083, logit=18.750)', '\" Among\"[22395] (p=0.034, logit=17.875)', '\" A\"[362] (p=0.014, logit=17.000)', '\" l\"[326] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.707, logit=21.125)', '\" The\"[578] (p=0.108, logit=19.250)', '\" Among\"[22395] (p=0.051, logit=18.500)', '\" A\"[362] (p=0.051, logit=18.500)', '\" D\"[423] (p=0.017, logit=17.375)']\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.70703125, logit=21.125, token_id=3816, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.0166015625, logit=17.375, token_id=423, metadata=None))), (34954, (34, PredictedToken(token=' Mirror', prob=0.000324249267578125, logit=13.4375, token_id=34954, metadata=None))), (19176, (40, PredictedToken(token=' Temple', prob=0.0002689361572265625, logit=13.25, token_id=19176, metadata=None))), (1183, (53, PredictedToken(token=' Tr', prob=0.00014400482177734375, logit=12.625, token_id=1183, metadata=None)))])\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.068, logit=19.250)', '\" Among\"[22395] (p=0.022, logit=18.125)', '\" A\"[362] (p=0.020, logit=18.000)', '\" d\"[294] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.83203125, logit=21.75, token_id=423, metadata=None))), (34954, (7, PredictedToken(token=' Mirror', prob=0.00634765625, logit=16.875, token_id=34954, metadata=None))), (1183, (16, PredictedToken(token=' Tr', prob=0.000713348388671875, logit=14.6875, token_id=1183, metadata=None))), (19176, (44, PredictedToken(token=' Temple', prob=0.0001239776611328125, logit=12.9375, token_id=19176, metadata=None))), (3816, (62, PredictedToken(token=' Red', prob=5.507469177246094e-05, logit=12.125, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:15 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:15 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.075, logit=19.250)', '\" A\"[362] (p=0.031, logit=18.375)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" It\"[1102] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:51:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.797, logit=21.875)', '\" The\"[578] (p=0.051, logit=19.125)', '\" A\"[362] (p=0.051, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" Option\"[7104] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.796875, logit=21.875, token_id=16183, metadata=None))), (41445, (29, PredictedToken(token=' Television', prob=0.000499725341796875, logit=14.5, token_id=41445, metadata=None))), (19176, (51, PredictedToken(token=' Temple', prob=0.00011110305786132812, logit=13.0, token_id=19176, metadata=None))), (89077, (283, PredictedToken(token=' Strawberry', prob=3.159046173095703e-06, logit=9.4375, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     int_prediction=['\" Television\"[41445] (p=0.637, logit=20.750)', '\" Temple\"[19176] (p=0.076, logit=18.625)', '\" The\"[578] (p=0.076, logit=18.625)', '\" Among\"[22395] (p=0.041, logit=18.000)', '\" Hel\"[16183] (p=0.036, logit=17.875)']\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     int_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.63671875, logit=20.75, token_id=41445, metadata=None))), (19176, (3, PredictedToken(token=' Temple', prob=0.076171875, logit=18.625, token_id=19176, metadata=None))), (16183, (5, PredictedToken(token=' Hel', prob=0.0361328125, logit=17.875, token_id=16183, metadata=None))), (89077, (25, PredictedToken(token=' Strawberry', prob=0.00139617919921875, logit=14.625, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:16 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.816, logit=22.000)', '\" The\"[578] (p=0.052, logit=19.250)', '\" Among\"[22395] (p=0.041, logit=19.000)', '\" A\"[362] (p=0.028, logit=18.625)', '\" C\"[356] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.805, logit=21.625)', '\" An\"[1556] (p=0.075, logit=19.250)', '\" The\"[578] (p=0.058, logit=19.000)', '\" Among\"[22395] (p=0.024, logit=18.125)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.8046875, logit=21.625, token_id=87035, metadata=None))), (87213, (49, PredictedToken(token=' Oven', prob=8.249282836914062e-05, logit=12.4375, token_id=87213, metadata=None))), (4923, (53, PredictedToken(token=' Sk', prob=7.295608520507812e-05, logit=12.3125, token_id=4923, metadata=None))), (96096, (75, PredictedToken(token=' Dolphin', prob=4.410743713378906e-05, logit=11.8125, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.609, logit=20.625)', '\" Sk\"[4923] (p=0.254, logit=19.750)', '\" The\"[578] (p=0.057, logit=18.250)', '\" Oven\"[87213] (p=0.014, logit=16.875)', '\" Among\"[22395] (p=0.011, logit=16.625)']\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.609375, logit=20.625, token_id=96096, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.25390625, logit=19.75, token_id=4923, metadata=None))), (87213, (4, PredictedToken(token=' Oven', prob=0.01434326171875, logit=16.875, token_id=87213, metadata=None))), (87035, (164, PredictedToken(token=' Onion', prob=1.4841556549072266e-05, logit=10.0, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:16 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:51:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     patch_prediction=['\" Pressure\"[40090] (p=0.688, logit=21.750)', '\" The\"[578] (p=0.105, logit=19.875)', '\" Among\"[22395] (p=0.093, logit=19.750)', '\" A\"[362] (p=0.039, logit=18.875)', '\" Option\"[7104] (p=0.016, logit=18.000)']\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.723, logit=21.375)', '\" The\"[578] (p=0.067, logit=19.000)', '\" Slow\"[39247] (p=0.059, logit=18.875)', '\" A\"[362] (p=0.052, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.500)']\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.72265625, logit=21.375, token_id=5907, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.05908203125, logit=18.875, token_id=39247, metadata=None))), (68027, (53, PredictedToken(token=' Sax', prob=0.0001659393310546875, logit=13.0, token_id=68027, metadata=None))), (91782, (395, PredictedToken(token=' Shorts', prob=2.2351741790771484e-06, logit=8.6875, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.459, logit=20.000)', '\" Shorts\"[91782] (p=0.316, logit=19.625)', '\" The\"[578] (p=0.062, logit=18.000)', '\" Among\"[22395] (p=0.038, logit=17.500)', '\" A\"[362] (p=0.016, logit=16.625)']\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.458984375, logit=20.0, token_id=39247, metadata=None))), (91782, (2, PredictedToken(token=' Shorts', prob=0.31640625, logit=19.625, token_id=91782, metadata=None))), (5907, (19, PredictedToken(token=' Project', prob=0.001373291015625, logit=14.1875, token_id=5907, metadata=None))), (68027, (25, PredictedToken(token=' Sax', prob=0.001068115234375, logit=13.9375, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:17 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:17 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     patch_prediction=['\" Necklace\"[86460] (p=0.871, logit=23.000)', '\" The\"[578] (p=0.056, logit=20.250)', '\" A\"[362] (p=0.038, logit=19.875)', '\" Among\"[22395] (p=0.014, logit=18.875)', '\" It\"[1102] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:51:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     clean_prediction=['\" Magn\"[20918] (p=0.867, logit=22.000)', '\" The\"[578] (p=0.038, logit=18.875)', '\" A\"[362] (p=0.023, logit=18.375)', '\" Among\"[22395] (p=0.016, logit=18.000)', '\" Option\"[7104] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     clean_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.8671875, logit=22.0, token_id=20918, metadata=None))), (426, (17, PredictedToken(token=' B', prob=0.00054168701171875, logit=14.625, token_id=426, metadata=None))), (34046, (72, PredictedToken(token=' Cabinet', prob=3.4809112548828125e-05, logit=11.875, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.852, logit=22.000)', '\" b\"[293] (p=0.029, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.500)', '\" The\"[578] (p=0.023, logit=18.375)', '\" Option\"[7104] (p=0.018, logit=18.125)']\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.8515625, logit=22.0, token_id=426, metadata=None))), (20918, (8, PredictedToken(token=' Magn', prob=0.006500244140625, logit=17.125, token_id=20918, metadata=None))), (34046, (10, PredictedToken(token=' Cabinet', prob=0.002716064453125, logit=16.25, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:18 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.486, logit=20.125)', '\" None\"[2290] (p=0.334, logit=19.750)', '\" The\"[578] (p=0.040, logit=17.625)', '\" A\"[362] (p=0.031, logit=17.375)', '\" There\"[2684] (p=0.019, logit=16.875)']\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.754, logit=22.125)', '\" The\"[578] (p=0.090, logit=20.000)', '\" A\"[362] (p=0.079, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.75390625, logit=22.125, token_id=18343, metadata=None))), (921, (37, PredictedToken(token=' Ch', prob=0.0002231597900390625, logit=14.0, token_id=921, metadata=None))), (10164, (84, PredictedToken(token=' Water', prob=3.0159950256347656e-05, logit=12.0, token_id=10164, metadata=None))), (6150, (155, PredictedToken(token=' School', prob=9.179115295410156e-06, logit=10.8125, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     int_prediction=['\" Ch\"[921] (p=0.707, logit=21.375)', '\" The\"[578] (p=0.108, logit=19.500)', '\" School\"[6150] (p=0.058, logit=18.875)', '\" Among\"[22395] (p=0.045, logit=18.625)', '\" A\"[362] (p=0.019, logit=17.750)']\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     int_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.70703125, logit=21.375, token_id=921, metadata=None))), (6150, (3, PredictedToken(token=' School', prob=0.05810546875, logit=18.875, token_id=6150, metadata=None))), (10164, (14, PredictedToken(token=' Water', prob=0.00164794921875, logit=15.3125, token_id=10164, metadata=None))), (18343, (28, PredictedToken(token=' Paper', prob=0.000881195068359375, logit=14.6875, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:18 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:18 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:51:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.852, logit=21.375)', '\" The\"[578] (p=0.054, logit=18.625)', '\" Among\"[22395] (p=0.020, logit=17.625)', '\" A\"[362] (p=0.012, logit=17.125)', '\" Chain\"[29625] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.777, logit=20.875)', '\" The\"[578] (p=0.072, logit=18.500)', '\" A\"[362] (p=0.050, logit=18.125)', '\" Among\"[22395] (p=0.039, logit=17.875)', '\" Fl\"[3061] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.77734375, logit=20.875, token_id=41342, metadata=None))), (3061, (5, PredictedToken(token=' Fl', prob=0.0086669921875, logit=16.375, token_id=3061, metadata=None))), (6771, (12, PredictedToken(token=' Table', prob=0.0021820068359375, logit=15.0, token_id=6771, metadata=None))), (70762, (23, PredictedToken(token=' Motorcycle', prob=0.0006256103515625, logit=13.75, token_id=70762, metadata=None))), (48390, (34, PredictedToken(token=' Lily', prob=0.0003147125244140625, logit=13.0625, token_id=48390, metadata=None))), (47643, (224, PredictedToken(token=' Cel', prob=8.404254913330078e-06, logit=9.4375, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     int_prediction=['\" Table\"[6771] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.068, logit=18.875)', '\" Among\"[22395] (p=0.020, logit=17.625)', '\" A\"[362] (p=0.013, logit=17.250)', '\" Lily\"[48390] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     int_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.8359375, logit=21.375, token_id=6771, metadata=None))), (48390, (5, PredictedToken(token=' Lily', prob=0.006378173828125, logit=16.5, token_id=48390, metadata=None))), (3061, (7, PredictedToken(token=' Fl', prob=0.00439453125, logit=16.125, token_id=3061, metadata=None))), (41342, (49, PredictedToken(token=' Hockey', prob=0.0001811981201171875, logit=12.9375, token_id=41342, metadata=None))), (47643, (171, PredictedToken(token=' Cel', prob=1.0192394256591797e-05, logit=10.0625, token_id=47643, metadata=None))), (70762, (354, PredictedToken(token=' Motorcycle', prob=2.5779008865356445e-06, logit=8.6875, token_id=70762, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:19 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:19 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:51:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.641, logit=22.500)', '\" An\"[1556] (p=0.143, logit=21.000)', '\" The\"[578] (p=0.143, logit=21.000)', '\" Among\"[22395] (p=0.028, logit=19.375)', '\" It\"[1102] (p=0.012, logit=18.500)']\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.859, logit=22.750)', '\" The\"[578] (p=0.055, logit=20.000)', '\" A\"[362] (p=0.043, logit=19.750)', '\" Among\"[22395] (p=0.016, logit=18.750)', '\" Option\"[7104] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.859375, logit=22.75, token_id=735, metadata=None))), (41785, (12, PredictedToken(token=' Spin', prob=0.0006103515625, logit=15.5, token_id=41785, metadata=None))), (70306, (51, PredictedToken(token=' Brace', prob=5.0067901611328125e-05, logit=13.0, token_id=70306, metadata=None)))])\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.926, logit=23.000)', '\" Brace\"[70306] (p=0.032, logit=19.625)', '\" The\"[578] (p=0.017, logit=19.000)', '\" Among\"[22395] (p=0.005, logit=17.875)', '\" (\"[320] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.92578125, logit=23.0, token_id=41785, metadata=None))), (70306, (2, PredictedToken(token=' Brace', prob=0.03173828125, logit=19.625, token_id=70306, metadata=None))), (735, (29, PredictedToken(token=' K', prob=0.0001373291015625, logit=14.1875, token_id=735, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:20 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.645, logit=20.875)', '\" An\"[1556] (p=0.144, logit=19.375)', '\" The\"[578] (p=0.068, logit=18.625)', '\" Among\"[22395] (p=0.060, logit=18.500)', '\" E\"[469] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.773, logit=20.875)', '\" The\"[578] (p=0.063, logit=18.375)', '\" Among\"[22395] (p=0.056, logit=18.250)', '\" A\"[362] (p=0.030, logit=17.625)', '\" lotion\"[87942] (p=0.011, logit=16.625)']\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.7734375, logit=20.875, token_id=445, metadata=None))), (6031, (38, PredictedToken(token=' Bro', prob=0.0003337860107421875, logit=13.125, token_id=6031, metadata=None))), (24941, (52, PredictedToken(token=' Bear', prob=0.000202178955078125, logit=12.625, token_id=24941, metadata=None))), (6150, (580, PredictedToken(token=' School', prob=1.8030405044555664e-06, logit=7.90625, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.664, logit=20.750)', '\" Bro\"[6031] (p=0.131, logit=19.125)', '\" The\"[578] (p=0.062, logit=18.375)', '\" A\"[362] (p=0.037, logit=17.875)', '\" Among\"[22395] (p=0.026, logit=17.500)']\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.6640625, logit=20.75, token_id=24941, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.130859375, logit=19.125, token_id=6031, metadata=None))), (445, (14, PredictedToken(token=' L', prob=0.001983642578125, logit=14.9375, token_id=445, metadata=None))), (6150, (26, PredictedToken(token=' School', prob=0.001129150390625, logit=14.375, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:20 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:51:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.742, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" A\"[362] (p=0.048, logit=19.125)', '\" Among\"[22395] (p=0.042, logit=19.000)', '\" It\"[1102] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.734, logit=21.500)', '\" The\"[578] (p=0.077, logit=19.250)', '\" C\"[356] (p=0.068, logit=19.125)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" An\"[1556] (p=0.017, logit=17.750)']\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.734375, logit=21.5, token_id=6690, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.068359375, logit=19.125, token_id=356, metadata=None))), (68027, (28, PredictedToken(token=' Sax', prob=0.000667572021484375, logit=14.5, token_id=68027, metadata=None))), (29318, (101, PredictedToken(token=' Dress', prob=2.753734588623047e-05, logit=11.3125, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.688, logit=21.375)', '\" The\"[578] (p=0.093, logit=19.375)', '\" C\"[356] (p=0.064, logit=19.000)', '\" Among\"[22395] (p=0.039, logit=18.500)', '\" (\"[320] (p=0.030, logit=18.250)']\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.6875, logit=21.375, token_id=68027, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.06396484375, logit=19.0, token_id=356, metadata=None))), (29318, (8, PredictedToken(token=' Dress', prob=0.006744384765625, logit=16.75, token_id=29318, metadata=None))), (6690, (216, PredictedToken(token=' Air', prob=6.16908073425293e-06, logit=9.75, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:21 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:51:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.902, logit=21.500)', '\" The\"[578] (p=0.024, logit=17.875)', '\" A\"[362] (p=0.017, logit=17.500)', '\" Among\"[22395] (p=0.011, logit=17.125)', '\" school\"[2978] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.652, logit=20.750)', '\" The\"[578] (p=0.165, logit=19.375)', '\" Among\"[22395] (p=0.069, logit=18.500)', '\" A\"[362] (p=0.037, logit=17.875)', '\" It\"[1102] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.65234375, logit=20.75, token_id=94467, metadata=None))), (79189, (42, PredictedToken(token=' Elephant', prob=0.00023365020751953125, logit=12.8125, token_id=79189, metadata=None))), (38930, (57, PredictedToken(token=' Bike', prob=0.00010347366333007812, logit=12.0, token_id=38930, metadata=None))), (15429, (389, PredictedToken(token=' Hospital', prob=3.3229589462280273e-06, logit=8.5625, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     int_prediction=['\" Hospital\"[15429] (p=0.816, logit=22.125)', '\" The\"[578] (p=0.076, logit=19.750)', '\" Among\"[22395] (p=0.041, logit=19.125)', '\" Option\"[7104] (p=0.013, logit=18.000)', '\" A\"[362] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     int_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.81640625, logit=22.125, token_id=15429, metadata=None))), (94467, (31, PredictedToken(token=' Trom', prob=0.0003986358642578125, logit=14.5, token_id=94467, metadata=None))), (79189, (50, PredictedToken(token=' Elephant', prob=0.0001468658447265625, logit=13.5, token_id=79189, metadata=None))), (38930, (134, PredictedToken(token=' Bike', prob=1.2814998626708984e-05, logit=11.0625, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:22 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:22 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.590, logit=20.875)', '\" The\"[578] (p=0.132, logit=19.375)', '\" Keyboard\"[26698] (p=0.103, logit=19.125)', '\" Among\"[22395] (p=0.048, logit=18.375)', '\" A\"[362] (p=0.026, logit=17.750)']\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.902, logit=22.500)', '\" The\"[578] (p=0.035, logit=19.250)', '\" A\"[362] (p=0.021, logit=18.750)', '\" Among\"[22395] (p=0.013, logit=18.250)', '\" None\"[2290] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.90234375, logit=22.5, token_id=29625, metadata=None))), (31181, (122, PredictedToken(token=' Clar', prob=1.0371208190917969e-05, logit=11.125, token_id=31181, metadata=None))), (16730, (220, PredictedToken(token=' Museum', prob=3.159046173095703e-06, logit=9.9375, token_id=16730, metadata=None))), (97796, (276, PredictedToken(token=' Skate', prob=2.175569534301758e-06, logit=9.5625, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:51:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.914, logit=22.125)', '\" The\"[578] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.019, logit=18.250)', '\" None\"[2290] (p=0.013, logit=17.875)', '\" Among\"[22395] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.9140625, logit=22.125, token_id=31181, metadata=None))), (29625, (30, PredictedToken(token=' Chain', prob=0.00017452239990234375, logit=13.5625, token_id=29625, metadata=None))), (97796, (69, PredictedToken(token=' Skate', prob=4.1484832763671875e-05, logit=12.125, token_id=97796, metadata=None))), (16730, (650, PredictedToken(token=' Museum', prob=7.599592208862305e-07, logit=8.125, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:23 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:23 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     patch_prediction=['\" St\"[800] (p=0.762, logit=22.625)', '\" The\"[578] (p=0.091, logit=20.500)', '\" A\"[362] (p=0.062, logit=20.125)', '\" Among\"[22395] (p=0.055, logit=20.000)', '\" It\"[1102] (p=0.007, logit=17.875)']\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.883, logit=22.375)', '\" The\"[578] (p=0.044, logit=19.375)', '\" A\"[362] (p=0.030, logit=19.000)', '\" dress\"[8679] (p=0.010, logit=17.875)', '\" Among\"[22395] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.8828125, logit=22.375, token_id=29318, metadata=None))), (36358, (75, PredictedToken(token=' Bench', prob=2.9325485229492188e-05, logit=12.0625, token_id=36358, metadata=None))), (17367, (76, PredictedToken(token=' Factory', prob=2.753734588623047e-05, logit=12.0, token_id=17367, metadata=None))), (30173, (79, PredictedToken(token=' Speaker', prob=2.4318695068359375e-05, logit=11.875, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.891, logit=22.000)', '\" Factory\"[17367] (p=0.039, logit=18.875)', '\" The\"[578] (p=0.016, logit=18.000)', '\" A\"[362] (p=0.016, logit=18.000)', '\" None\"[2290] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.890625, logit=22.0, token_id=36358, metadata=None))), (17367, (2, PredictedToken(token=' Factory', prob=0.039306640625, logit=18.875, token_id=17367, metadata=None))), (29318, (11, PredictedToken(token=' Dress', prob=0.0011138916015625, logit=15.3125, token_id=29318, metadata=None))), (30173, (28, PredictedToken(token=' Speaker', prob=0.00019359588623046875, logit=13.5625, token_id=30173, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:23 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:51:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.934, logit=21.250)', '\" The\"[578] (p=0.019, logit=17.375)', '\" A\"[362] (p=0.006, logit=16.250)', '\" Among\"[22395] (p=0.005, logit=15.938)', '\" It\"[1102] (p=0.003, logit=15.625)']\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.664, logit=21.875)', '\" The\"[578] (p=0.148, logit=20.375)', '\" A\"[362] (p=0.080, logit=19.750)', '\" Among\"[22395] (p=0.070, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.6640625, logit=21.875, token_id=8219, metadata=None))), (57915, (40, PredictedToken(token=' Ank', prob=0.00019741058349609375, logit=13.75, token_id=57915, metadata=None))), (2522, (43, PredictedToken(token=' Sc', prob=0.00015354156494140625, logit=13.5, token_id=2522, metadata=None))), (20423, (68, PredictedToken(token=' Amb', prob=4.38690185546875e-05, logit=12.25, token_id=20423, metadata=None))), (15429, (210, PredictedToken(token=' Hospital', prob=4.351139068603516e-06, logit=9.9375, token_id=15429, metadata=None))), (12369, (255, PredictedToken(token=' Food', prob=2.995133399963379e-06, logit=9.5625, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     int_prediction=['\" Food\"[12369] (p=0.668, logit=21.750)', '\" Sc\"[2522] (p=0.191, logit=20.500)', '\" The\"[578] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.023, logit=18.375)', '\" An\"[1556] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     int_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.66796875, logit=21.75, token_id=12369, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.19140625, logit=20.5, token_id=2522, metadata=None))), (15429, (7, PredictedToken(token=' Hospital', prob=0.005096435546875, logit=16.875, token_id=15429, metadata=None))), (57915, (8, PredictedToken(token=' Ank', prob=0.0045166015625, logit=16.75, token_id=57915, metadata=None))), (20423, (41, PredictedToken(token=' Amb', prob=0.000164031982421875, logit=13.4375, token_id=20423, metadata=None))), (8219, (101, PredictedToken(token=' Sun', prob=2.3603439331054688e-05, logit=11.5, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:24 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:24 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.629, logit=20.750)', '\" Comb\"[23262] (p=0.203, logit=19.625)', '\" An\"[1556] (p=0.040, logit=18.000)', '\" The\"[578] (p=0.028, logit=17.625)', '\" Among\"[22395] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     clean_prediction=['\" Shower\"[48471] (p=0.602, logit=20.750)', '\" The\"[578] (p=0.151, logit=19.375)', '\" A\"[362] (p=0.118, logit=19.125)', '\" Among\"[22395] (p=0.056, logit=18.375)', '\" SH\"[6570] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     clean_track=OrderedDict([(48471, (1, PredictedToken(token=' Shower', prob=0.6015625, logit=20.75, token_id=48471, metadata=None))), (63606, (24, PredictedToken(token=' Stap', prob=0.0009002685546875, logit=14.25, token_id=63606, metadata=None))), (20423, (37, PredictedToken(token=' Amb', prob=0.0003757476806640625, logit=13.375, token_id=20423, metadata=None)))])\n",
      "2025-09-16 09:51:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.711, logit=20.875)', '\" The\"[578] (p=0.085, logit=18.750)', '\" A\"[362] (p=0.075, logit=18.625)', '\" Shower\"[48471] (p=0.046, logit=18.125)', '\" Among\"[22395] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.7109375, logit=20.875, token_id=63606, metadata=None))), (48471, (4, PredictedToken(token=' Shower', prob=0.045654296875, logit=18.125, token_id=48471, metadata=None))), (20423, (6, PredictedToken(token=' Amb', prob=0.006988525390625, logit=16.25, token_id=20423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:25 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     patch_prediction=['\" Van\"[13000] (p=0.711, logit=22.125)', '\" The\"[578] (p=0.141, logit=20.500)', '\" A\"[362] (p=0.075, logit=19.875)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" VAN\"[97753] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.840, logit=21.500)', '\" The\"[578] (p=0.061, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.250)', '\" A\"[362] (p=0.015, logit=17.500)', '\" Option\"[7104] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.83984375, logit=21.5, token_id=469, metadata=None))), (58600, (48, PredictedToken(token=' Charm', prob=9.72747802734375e-05, logit=12.4375, token_id=58600, metadata=None))), (78703, (138, PredictedToken(token=' Potato', prob=1.3172626495361328e-05, logit=10.4375, token_id=78703, metadata=None))), (1183, (135, PredictedToken(token=' Tr', prob=1.3172626495361328e-05, logit=10.4375, token_id=1183, metadata=None))), (72392, (2070, PredictedToken(token=' Mixer', prob=1.3783574104309082e-07, logit=5.875, token_id=72392, metadata=None)))])\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.785, logit=21.375)', '\" A\"[362] (p=0.064, logit=18.875)', '\" The\"[578] (p=0.057, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=17.875)', '\" (\"[320] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.78515625, logit=21.375, token_id=1183, metadata=None))), (78703, (7, PredictedToken(token=' Potato', prob=0.0076904296875, logit=16.75, token_id=78703, metadata=None))), (469, (8, PredictedToken(token=' E', prob=0.004669189453125, logit=16.25, token_id=469, metadata=None))), (72392, (23, PredictedToken(token=' Mixer', prob=0.00067138671875, logit=14.3125, token_id=72392, metadata=None))), (58600, (52, PredictedToken(token=' Charm', prob=0.0001697540283203125, logit=12.9375, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:25 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:25 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:51:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.910, logit=22.250)', '\" The\"[578] (p=0.040, logit=19.125)', '\" Among\"[22395] (p=0.017, logit=18.250)', '\" socks\"[40086] (p=0.007, logit=17.375)', '\" (\"[320] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     clean_prediction=['\" Router\"[10777] (p=0.855, logit=21.000)', '\" The\"[578] (p=0.033, logit=17.750)', '\" A\"[362] (p=0.016, logit=17.000)', '\" router\"[9457] (p=0.014, logit=16.875)', '\" (\"[320] (p=0.011, logit=16.625)']\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     clean_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.85546875, logit=21.0, token_id=10777, metadata=None))), (36895, (30, PredictedToken(token=' Eagle', prob=0.000568389892578125, logit=13.6875, token_id=36895, metadata=None))), (29318, (39, PredictedToken(token=' Dress', prob=0.0003681182861328125, logit=13.25, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.656, logit=20.250)', '\" None\"[2290] (p=0.129, logit=18.625)', '\" Router\"[10777] (p=0.069, logit=18.000)', '\" The\"[578] (p=0.022, logit=16.875)', '\" Eagle\"[36895] (p=0.017, logit=16.625)']\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.65625, logit=20.25, token_id=29318, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.0693359375, logit=18.0, token_id=10777, metadata=None))), (36895, (5, PredictedToken(token=' Eagle', prob=0.0174560546875, logit=16.625, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:26 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.680, logit=22.000)', '\" The\"[578] (p=0.118, logit=20.250)', '\" Among\"[22395] (p=0.081, logit=19.875)', '\" A\"[362] (p=0.072, logit=19.750)', '\" (\"[320] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:51:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     clean_prediction=['\" Phone\"[14642] (p=0.824, logit=22.000)', '\" The\"[578] (p=0.060, logit=19.375)', '\" A\"[362] (p=0.036, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.500)', '\" phone\"[4641] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     clean_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.82421875, logit=22.0, token_id=14642, metadata=None))), (469, (14, PredictedToken(token=' E', prob=0.0012359619140625, logit=15.5, token_id=469, metadata=None))), (1901, (36, PredictedToken(token=' Z', prob=0.00031280517578125, logit=14.125, token_id=1901, metadata=None))), (70306, (181, PredictedToken(token=' Brace', prob=7.361173629760742e-06, logit=10.375, token_id=70306, metadata=None))), (57551, (351, PredictedToken(token=' Sink', prob=1.862645149230957e-06, logit=9.0, token_id=57551, metadata=None)))])\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.479, logit=20.375)', '\" E\"[469] (p=0.256, logit=19.750)', '\" The\"[578] (p=0.073, logit=18.500)', '\" A\"[362] (p=0.039, logit=17.875)', '\" Brace\"[70306] (p=0.027, logit=17.500)']\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.478515625, logit=20.375, token_id=1901, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.255859375, logit=19.75, token_id=469, metadata=None))), (70306, (5, PredictedToken(token=' Brace', prob=0.0269775390625, logit=17.5, token_id=70306, metadata=None))), (57551, (7, PredictedToken(token=' Sink', prob=0.014404296875, logit=16.875, token_id=57551, metadata=None))), (14642, (9, PredictedToken(token=' Phone', prob=0.00994873046875, logit=16.5, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:27 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:27 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     patch_prediction=['\" Bench\"[36358] (p=0.770, logit=21.500)', '\" The\"[578] (p=0.081, logit=19.250)', '\" A\"[362] (p=0.043, logit=18.625)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" (\"[320] (p=0.018, logit=17.750)']\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.793, logit=20.125)', '\" The\"[578] (p=0.045, logit=17.250)', '\" A\"[362] (p=0.027, logit=16.750)', '\" Ottoman\"[70110] (p=0.019, logit=16.375)', '\" Among\"[22395] (p=0.010, logit=15.750)']\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.79296875, logit=20.125, token_id=17367, metadata=None))), (70110, (4, PredictedToken(token=' Ottoman', prob=0.0186767578125, logit=16.375, token_id=70110, metadata=None))), (33578, (11, PredictedToken(token=' Palm', prob=0.005340576171875, logit=15.125, token_id=33578, metadata=None))), (91963, (31, PredictedToken(token=' Mango', prob=0.00077056884765625, logit=13.1875, token_id=91963, metadata=None)))])\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     int_prediction=['\" Factory\"[17367] (p=0.820, logit=20.625)', '\" The\"[578] (p=0.036, logit=17.500)', '\" Palm\"[33578] (p=0.025, logit=17.125)', '\" Ottoman\"[70110] (p=0.022, logit=17.000)', '\" A\"[362] (p=0.019, logit=16.875)']\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     int_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.8203125, logit=20.625, token_id=17367, metadata=None))), (33578, (3, PredictedToken(token=' Palm', prob=0.0247802734375, logit=17.125, token_id=33578, metadata=None))), (70110, (4, PredictedToken(token=' Ottoman', prob=0.0218505859375, logit=17.0, token_id=70110, metadata=None))), (91963, (9, PredictedToken(token=' Mango', prob=0.004302978515625, logit=15.375, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:27 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:51:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.508, logit=21.000)', '\" The\"[578] (p=0.271, logit=20.375)', '\" A\"[362] (p=0.088, logit=19.250)', '\" Among\"[22395] (p=0.069, logit=19.000)', '\" It\"[1102] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     clean_prediction=['\" Tennis\"[58251] (p=0.668, logit=20.625)', '\" The\"[578] (p=0.132, logit=19.000)', '\" A\"[362] (p=0.080, logit=18.500)', '\" Among\"[22395] (p=0.038, logit=17.750)', '\" It\"[1102] (p=0.011, logit=16.500)']\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     clean_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.66796875, logit=20.625, token_id=58251, metadata=None))), (46506, (8, PredictedToken(token=' Drum', prob=0.004791259765625, logit=15.6875, token_id=46506, metadata=None))), (22249, (71, PredictedToken(token=' Ring', prob=8.7738037109375e-05, logit=11.6875, token_id=22249, metadata=None))), (48390, (90, PredictedToken(token=' Lily', prob=6.031990051269531e-05, logit=11.3125, token_id=48390, metadata=None))), (11896, (253, PredictedToken(token=' Library', prob=7.68899917602539e-06, logit=9.25, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.664, logit=21.000)', '\" The\"[578] (p=0.102, logit=19.125)', '\" Drum\"[46506] (p=0.055, logit=18.500)', '\" A\"[362] (p=0.055, logit=18.500)', '\" Among\"[22395] (p=0.042, logit=18.250)']\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.6640625, logit=21.0, token_id=22249, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.0546875, logit=18.5, token_id=46506, metadata=None))), (58251, (6, PredictedToken(token=' Tennis', prob=0.02001953125, logit=17.5, token_id=58251, metadata=None))), (48390, (64, PredictedToken(token=' Lily', prob=0.00011920928955078125, logit=12.375, token_id=48390, metadata=None))), (11896, (116, PredictedToken(token=' Library', prob=2.658367156982422e-05, logit=10.875, token_id=11896, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:28 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:51:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.863, logit=22.500)', '\" The\"[578] (p=0.055, logit=19.750)', '\" A\"[362] (p=0.043, logit=19.500)', '\" Among\"[22395] (p=0.016, logit=18.500)', '\" (\"[320] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     clean_prediction=['\" Basketball\"[47589] (p=0.910, logit=22.250)', '\" The\"[578] (p=0.031, logit=18.875)', '\" Among\"[22395] (p=0.009, logit=17.625)', '\" Sc\"[2522] (p=0.009, logit=17.625)', '\" Basket\"[34217] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     clean_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.91015625, logit=22.25, token_id=47589, metadata=None))), (2522, (3, PredictedToken(token=' Sc', prob=0.0089111328125, logit=17.625, token_id=2522, metadata=None))), (3341, (53, PredictedToken(token=' Car', prob=6.389617919921875e-05, logit=12.6875, token_id=3341, metadata=None))), (74574, (207, PredictedToken(token=' Violet', prob=3.844499588012695e-06, logit=9.875, token_id=74574, metadata=None)))])\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.848, logit=21.125)', '\" Basketball\"[47589] (p=0.033, logit=17.875)', '\" The\"[578] (p=0.029, logit=17.750)', '\" Car\"[3341] (p=0.014, logit=17.000)', '\" A\"[362] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.84765625, logit=21.125, token_id=74574, metadata=None))), (47589, (2, PredictedToken(token=' Basketball', prob=0.032958984375, logit=17.875, token_id=47589, metadata=None))), (3341, (4, PredictedToken(token=' Car', prob=0.01373291015625, logit=17.0, token_id=3341, metadata=None))), (2522, (53, PredictedToken(token=' Sc', prob=0.00013446807861328125, logit=12.375, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:29 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:29 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     patch_prediction=['\" Marker\"[40975] (p=0.902, logit=22.250)', '\" The\"[578] (p=0.031, logit=18.875)', '\" Among\"[22395] (p=0.019, logit=18.375)', '\" A\"[362] (p=0.019, logit=18.375)', '\" Harmon\"[40759] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:51:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.887, logit=22.500)', '\" Among\"[22395] (p=0.050, logit=19.625)', '\" The\"[578] (p=0.039, logit=19.375)', '\" It\"[1102] (p=0.005, logit=17.250)', '\" BRO\"[78687] (p=0.002, logit=16.250)']\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.88671875, logit=22.5, token_id=6031, metadata=None))), (79189, (23, PredictedToken(token=' Elephant', prob=0.0002803802490234375, logit=14.4375, token_id=79189, metadata=None))), (432, (38, PredictedToken(token=' R', prob=0.00010967254638671875, logit=13.5, token_id=432, metadata=None))), (2522, (79, PredictedToken(token=' Sc', prob=2.300739288330078e-05, logit=11.9375, token_id=2522, metadata=None))), (27738, (320, PredictedToken(token=' Ward', prob=1.4677643775939941e-06, logit=9.1875, token_id=27738, metadata=None)))])\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     int_prediction=['\" Sc\"[2522] (p=0.848, logit=21.750)', '\" Among\"[22395] (p=0.037, logit=18.625)', '\" The\"[578] (p=0.037, logit=18.625)', '\" Ward\"[27738] (p=0.023, logit=18.125)', '\" R\"[432] (p=0.020, logit=18.000)']\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     int_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.84765625, logit=21.75, token_id=2522, metadata=None))), (27738, (4, PredictedToken(token=' Ward', prob=0.0225830078125, logit=18.125, token_id=27738, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.02001953125, logit=18.0, token_id=432, metadata=None))), (6031, (14, PredictedToken(token=' Bro', prob=0.001129150390625, logit=15.125, token_id=6031, metadata=None))), (79189, (40, PredictedToken(token=' Elephant', prob=0.00017261505126953125, logit=13.25, token_id=79189, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:30 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     patch_prediction=['\" Sc\"[2522] (p=0.742, logit=19.625)', '\" None\"[2290] (p=0.114, logit=17.750)', '\" The\"[578] (p=0.032, logit=16.500)', '\" Among\"[22395] (p=0.016, logit=15.812)', '\" There\"[2684] (p=0.010, logit=15.312)']\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     clean_prediction=['\" Bamboo\"[98028] (p=0.840, logit=21.000)', '\" The\"[578] (p=0.042, logit=18.000)', '\" Among\"[22395] (p=0.025, logit=17.500)', '\" None\"[2290] (p=0.025, logit=17.500)', '\" It\"[1102] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     clean_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.83984375, logit=21.0, token_id=98028, metadata=None))), (63606, (15, PredictedToken(token=' Stap', prob=0.00152587890625, logit=14.6875, token_id=63606, metadata=None))), (30555, (194, PredictedToken(token=' Viol', prob=1.1682510375976562e-05, logit=9.8125, token_id=30555, metadata=None))), (67553, (252, PredictedToken(token=' Pants', prob=7.510185241699219e-06, logit=9.375, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.371, logit=19.500)', '\" Stap\"[63606] (p=0.328, logit=19.375)', '\" None\"[2290] (p=0.083, logit=18.000)', '\" The\"[578] (p=0.073, logit=17.875)', '\" A\"[362] (p=0.044, logit=17.375)']\n",
      "2025-09-16 09:51:30 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.37109375, logit=19.5, token_id=30555, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.328125, logit=19.375, token_id=63606, metadata=None))), (98028, (38, PredictedToken(token=' Bamboo', prob=0.0004634857177734375, logit=12.8125, token_id=98028, metadata=None))), (67553, (46, PredictedToken(token=' Pants', prob=0.0003833770751953125, logit=12.625, token_id=67553, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:30 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:31 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.637, logit=21.500)', '\" The\"[578] (p=0.126, logit=19.875)', '\" A\"[362] (p=0.126, logit=19.875)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" It\"[1102] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.746, logit=21.750)', '\" The\"[578] (p=0.101, logit=19.750)', '\" A\"[362] (p=0.069, logit=19.375)', '\" Among\"[22395] (p=0.048, logit=19.000)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.74609375, logit=21.75, token_id=29318, metadata=None))), (14588, (28, PredictedToken(token=' Dog', prob=0.0002841949462890625, logit=13.875, token_id=14588, metadata=None))), (735, (31, PredictedToken(token=' K', prob=0.0002498626708984375, logit=13.75, token_id=735, metadata=None))), (43316, (35, PredictedToken(token=' Tul', prob=0.00018310546875, logit=13.4375, token_id=43316, metadata=None))), (3061, (101, PredictedToken(token=' Fl', prob=2.0623207092285156e-05, logit=11.25, token_id=3061, metadata=None))), (38930, (103, PredictedToken(token=' Bike', prob=1.9311904907226562e-05, logit=11.1875, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     int_prediction=['\" Fl\"[3061] (p=0.734, logit=21.250)', '\" The\"[578] (p=0.100, logit=19.250)', '\" Among\"[22395] (p=0.060, logit=18.750)', '\" A\"[362] (p=0.032, logit=18.125)', '\" Bike\"[38930] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     int_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.734375, logit=21.25, token_id=3061, metadata=None))), (38930, (5, PredictedToken(token=' Bike', prob=0.00921630859375, logit=16.875, token_id=38930, metadata=None))), (735, (6, PredictedToken(token=' K', prob=0.0081787109375, logit=16.75, token_id=735, metadata=None))), (43316, (53, PredictedToken(token=' Tul', prob=0.00014972686767578125, logit=12.75, token_id=43316, metadata=None))), (14588, (88, PredictedToken(token=' Dog', prob=5.173683166503906e-05, logit=11.6875, token_id=14588, metadata=None))), (29318, (473, PredictedToken(token=' Dress', prob=1.7657876014709473e-06, logit=8.3125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:31 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:31 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:51:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.641, logit=20.500)', '\" The\"[578] (p=0.111, logit=18.750)', '\" Among\"[22395] (p=0.087, logit=18.500)', '\" A\"[362] (p=0.041, logit=17.750)', '\" Sax\"[68027] (p=0.025, logit=17.250)']\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.855, logit=21.875)', '\" A\"[362] (p=0.048, logit=19.000)', '\" The\"[578] (p=0.029, logit=18.500)', '\" Among\"[22395] (p=0.026, logit=18.375)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.85546875, logit=21.875, token_id=23262, metadata=None))), (14937, (31, PredictedToken(token=' Ash', prob=0.0003070831298828125, logit=13.9375, token_id=14937, metadata=None))), (3341, (33, PredictedToken(token=' Car', prob=0.0002536773681640625, logit=13.75, token_id=3341, metadata=None))), (84409, (49, PredictedToken(token=' Plum', prob=0.00015354156494140625, logit=13.25, token_id=84409, metadata=None))), (14669, (174, PredictedToken(token=' Camera', prob=1.1861324310302734e-05, logit=10.6875, token_id=14669, metadata=None))), (24941, (194, PredictedToken(token=' Bear', prob=9.834766387939453e-06, logit=10.5, token_id=24941, metadata=None)))])\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     int_prediction=['\" Camera\"[14669] (p=0.754, logit=21.625)', '\" Comb\"[23262] (p=0.131, logit=19.875)', '\" The\"[578] (p=0.038, logit=18.625)', '\" A\"[362] (p=0.018, logit=17.875)', '\" Among\"[22395] (p=0.014, logit=17.625)']\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     int_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.75390625, logit=21.625, token_id=14669, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.130859375, logit=19.875, token_id=23262, metadata=None))), (3341, (29, PredictedToken(token=' Car', prob=0.0004425048828125, logit=14.1875, token_id=3341, metadata=None))), (24941, (126, PredictedToken(token=' Bear', prob=2.5033950805664062e-05, logit=11.3125, token_id=24941, metadata=None))), (14937, (138, PredictedToken(token=' Ash', prob=2.205371856689453e-05, logit=11.1875, token_id=14937, metadata=None))), (84409, (244, PredictedToken(token=' Plum', prob=7.62939453125e-06, logit=10.125, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:32 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:51:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     patch_prediction=['\" Mouse\"[18191] (p=0.486, logit=20.125)', '\" None\"[2290] (p=0.430, logit=20.000)', '\" There\"[2684] (p=0.015, logit=16.625)', '\" The\"[578] (p=0.013, logit=16.500)', '\" A\"[362] (p=0.008, logit=16.000)']\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.840, logit=22.875)', '\" The\"[578] (p=0.069, logit=20.375)', '\" A\"[362] (p=0.037, logit=19.750)', '\" Among\"[22395] (p=0.029, logit=19.500)', '\" (\"[320] (p=0.004, logit=17.625)']\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.83984375, logit=22.875, token_id=33711, metadata=None))), (11683, (63, PredictedToken(token=' Acc', prob=3.147125244140625e-05, logit=12.6875, token_id=11683, metadata=None))), (14669, (639, PredictedToken(token=' Camera', prob=3.501772880554199e-07, logit=8.1875, token_id=14669, metadata=None))), (41342, (844, PredictedToken(token=' Hockey', prob=2.4028122425079346e-07, logit=7.8125, token_id=41342, metadata=None)))])\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     int_prediction=['\" Acc\"[11683] (p=0.562, logit=20.625)', '\" The\"[578] (p=0.143, logit=19.250)', '\" Camera\"[14669] (p=0.052, logit=18.250)', '\" An\"[1556] (p=0.052, logit=18.250)', '\" Among\"[22395] (p=0.032, logit=17.750)']\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     int_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.5625, logit=20.625, token_id=11683, metadata=None))), (14669, (4, PredictedToken(token=' Camera', prob=0.052490234375, logit=18.25, token_id=14669, metadata=None))), (41342, (9, PredictedToken(token=' Hockey', prob=0.01171875, logit=16.75, token_id=41342, metadata=None))), (33711, (142, PredictedToken(token=' Suit', prob=3.719329833984375e-05, logit=11.0, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:33 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:33 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:51:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.809, logit=22.125)', '\" The\"[578] (p=0.075, logit=19.750)', '\" A\"[362] (p=0.066, logit=19.625)', '\" Among\"[22395] (p=0.013, logit=18.000)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.812, logit=20.625)', '\" None\"[2290] (p=0.041, logit=17.625)', '\" A\"[362] (p=0.041, logit=17.625)', '\" The\"[578] (p=0.031, logit=17.375)', '\" Note\"[7181] (p=0.010, logit=16.250)']\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.8125, logit=20.625, token_id=69755, metadata=None))), (50159, (47, PredictedToken(token=' Sco', prob=0.00018787384033203125, logit=12.25, token_id=50159, metadata=None))), (13394, (83, PredictedToken(token=' Bed', prob=6.914138793945312e-05, logit=11.25, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     int_prediction=['\" Notebook\"[69755] (p=0.699, logit=20.750)', '\" Bed\"[13394] (p=0.094, logit=18.750)', '\" None\"[2290] (p=0.094, logit=18.750)', '\" Sco\"[50159] (p=0.021, logit=17.250)', '\" A\"[362] (p=0.019, logit=17.125)']\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     int_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.69921875, logit=20.75, token_id=69755, metadata=None))), (13394, (3, PredictedToken(token=' Bed', prob=0.09423828125, logit=18.75, token_id=13394, metadata=None))), (50159, (4, PredictedToken(token=' Sco', prob=0.0211181640625, logit=17.25, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:34 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:34 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:51:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.852, logit=22.000)', '\" The\"[578] (p=0.070, logit=19.500)', '\" Among\"[22395] (p=0.033, logit=18.750)', '\" (\"[320] (p=0.005, logit=16.875)', '\" A\"[362] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.770, logit=21.875)', '\" The\"[578] (p=0.072, logit=19.500)', '\" A\"[362] (p=0.063, logit=19.375)', '\" Among\"[22395] (p=0.043, logit=19.000)', '\" slow\"[6435] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.76953125, logit=21.875, token_id=39247, metadata=None))), (6031, (15, PredictedToken(token=' Bro', prob=0.000957489013671875, logit=15.1875, token_id=6031, metadata=None))), (64695, (17, PredictedToken(token=' Peach', prob=0.000701904296875, logit=14.875, token_id=64695, metadata=None))), (432, (25, PredictedToken(token=' R', prob=0.000514984130859375, logit=14.5625, token_id=432, metadata=None))), (70110, (105, PredictedToken(token=' Ottoman', prob=1.8715858459472656e-05, logit=11.25, token_id=70110, metadata=None)))])\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.617, logit=20.875)', '\" Ottoman\"[70110] (p=0.156, logit=19.500)', '\" The\"[578] (p=0.074, logit=18.750)', '\" Among\"[22395] (p=0.065, logit=18.625)', '\" A\"[362] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.6171875, logit=20.875, token_id=432, metadata=None))), (70110, (2, PredictedToken(token=' Ottoman', prob=0.15625, logit=19.5, token_id=70110, metadata=None))), (64695, (6, PredictedToken(token=' Peach', prob=0.0087890625, logit=16.625, token_id=64695, metadata=None))), (6031, (9, PredictedToken(token=' Bro', prob=0.004150390625, logit=15.875, token_id=6031, metadata=None))), (39247, (224, PredictedToken(token=' Slow', prob=8.046627044677734e-06, logit=9.625, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:35 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:35 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     patch_prediction=['\" Rose\"[16344] (p=0.824, logit=22.500)', '\" The\"[578] (p=0.068, logit=20.000)', '\" A\"[362] (p=0.041, logit=19.500)', '\" Among\"[22395] (p=0.028, logit=19.125)', '\" (\"[320] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     clean_prediction=['\" Er\"[9939] (p=0.859, logit=21.500)', '\" An\"[1556] (p=0.048, logit=18.625)', '\" The\"[578] (p=0.029, logit=18.125)', '\" Among\"[22395] (p=0.012, logit=17.250)', '\" er\"[2781] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     clean_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.859375, logit=21.5, token_id=9939, metadata=None))), (2947, (24, PredictedToken(token=' Mar', prob=0.0004749298095703125, logit=14.0, token_id=2947, metadata=None))), (15429, (153, PredictedToken(token=' Hospital', prob=9.834766387939453e-06, logit=10.125, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.883, logit=21.250)', '\" mar\"[3678] (p=0.030, logit=17.875)', '\" The\"[578] (p=0.027, logit=17.750)', '\" Among\"[22395] (p=0.014, logit=17.125)', '\" (\"[320] (p=0.004, logit=15.938)']\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.8828125, logit=21.25, token_id=2947, metadata=None))), (15429, (14, PredictedToken(token=' Hospital', prob=0.00124359130859375, logit=14.6875, token_id=15429, metadata=None))), (9939, (91, PredictedToken(token=' Er', prob=4.00543212890625e-05, logit=11.25, token_id=9939, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:35 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:35 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:51:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.824, logit=22.000)', '\" A\"[362] (p=0.047, logit=19.125)', '\" The\"[578] (p=0.036, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.500)', '\" helicopter\"[36125] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.789, logit=22.375)', '\" An\"[1556] (p=0.107, logit=20.375)', '\" The\"[578] (p=0.044, logit=19.500)', '\" None\"[2290] (p=0.016, logit=18.500)', '\" Among\"[22395] (p=0.014, logit=18.375)']\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.7890625, logit=22.375, token_id=53889, metadata=None))), (57225, (47, PredictedToken(token=' Laptop', prob=8.058547973632812e-05, logit=13.1875, token_id=57225, metadata=None))), (70762, (112, PredictedToken(token=' Motorcycle', prob=1.3172626495361328e-05, logit=11.375, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.906, logit=22.375)', '\" A\"[362] (p=0.024, logit=18.750)', '\" None\"[2290] (p=0.019, logit=18.500)', '\" The\"[578] (p=0.019, logit=18.500)', '\" Laptop\"[57225] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.90625, logit=22.375, token_id=70762, metadata=None))), (57225, (5, PredictedToken(token=' Laptop', prob=0.0089111328125, logit=17.75, token_id=57225, metadata=None))), (53889, (32, PredictedToken(token=' Apartment', prob=0.0001735687255859375, logit=13.8125, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:36 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     patch_prediction=['\" Coat\"[68867] (p=0.812, logit=21.875)', '\" The\"[578] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.052, logit=19.125)', '\" Among\"[22395] (p=0.041, logit=18.875)', '\" coat\"[23724] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.816, logit=22.625)', '\" A\"[362] (p=0.067, logit=20.125)', '\" The\"[578] (p=0.059, logit=20.000)', '\" Among\"[22395] (p=0.028, logit=19.250)', '\" It\"[1102] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.81640625, logit=22.625, token_id=4783, metadata=None))), (72392, (103, PredictedToken(token=' Mixer', prob=1.6450881958007812e-05, logit=11.8125, token_id=72392, metadata=None))), (44570, (133, PredictedToken(token=' Maple', prob=8.761882781982422e-06, logit=11.1875, token_id=44570, metadata=None))), (67553, (323, PredictedToken(token=' Pants', prob=1.1920928955078125e-06, logit=9.1875, token_id=67553, metadata=None))), (47643, (470, PredictedToken(token=' Cel', prob=5.997717380523682e-07, logit=8.5, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.275, logit=18.875)', '\" None\"[2290] (p=0.167, logit=18.375)', '\" The\"[578] (p=0.147, logit=18.250)', '\" Pants\"[67553] (p=0.115, logit=18.000)', '\" Maple\"[44570] (p=0.115, logit=18.000)']\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.275390625, logit=18.875, token_id=47643, metadata=None))), (67553, (5, PredictedToken(token=' Pants', prob=0.11474609375, logit=18.0, token_id=67553, metadata=None))), (44570, (4, PredictedToken(token=' Maple', prob=0.11474609375, logit=18.0, token_id=44570, metadata=None))), (4783, (59, PredictedToken(token=' House', prob=0.0003223419189453125, logit=12.125, token_id=4783, metadata=None))), (72392, (66, PredictedToken(token=' Mixer', prob=0.0002841949462890625, logit=12.0, token_id=72392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:37 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:37 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     patch_prediction=['\" Willow\"[65449] (p=0.879, logit=22.250)', '\" The\"[578] (p=0.034, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.500)', '\" Among\"[22395] (p=0.016, logit=18.250)', '\" (\"[320] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.961, logit=22.125)', '\" The\"[578] (p=0.006, logit=17.000)', '\" Hick\"[79028] (p=0.004, logit=16.625)', '\" violet\"[80836] (p=0.003, logit=16.500)', '\" Mirror\"[34954] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.9609375, logit=22.125, token_id=74574, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.003936767578125, logit=16.625, token_id=79028, metadata=None))), (34954, (4, PredictedToken(token=' Mirror', prob=0.0034637451171875, logit=16.5, token_id=34954, metadata=None)))])\n",
      "2025-09-16 09:51:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.922, logit=21.875)', '\" Hick\"[79028] (p=0.031, logit=18.500)', '\" Mirror\"[34954] (p=0.013, logit=17.625)', '\" The\"[578] (p=0.005, logit=16.750)', '\" (\"[320] (p=0.003, logit=16.000)']\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.921875, logit=21.875, token_id=74574, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.031494140625, logit=18.5, token_id=79028, metadata=None))), (34954, (3, PredictedToken(token=' Mirror', prob=0.01318359375, logit=17.625, token_id=34954, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:38 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     patch_prediction=['\" Plum\"[84409] (p=0.852, logit=21.875)', '\" Among\"[22395] (p=0.048, logit=19.000)', '\" The\"[578] (p=0.048, logit=19.000)', '\" A\"[362] (p=0.007, logit=17.125)', '\" Ash\"[14937] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.883, logit=21.875)', '\" A\"[362] (p=0.034, logit=18.625)', '\" The\"[578] (p=0.027, logit=18.375)', '\" Among\"[22395] (p=0.011, logit=17.500)', '\" watch\"[3821] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.8828125, logit=21.875, token_id=10573, metadata=None))), (1901, (21, PredictedToken(token=' Z', prob=0.0006256103515625, logit=14.625, token_id=1901, metadata=None))), (41785, (28, PredictedToken(token=' Spin', prob=0.0003795623779296875, logit=14.125, token_id=41785, metadata=None))), (91782, (36, PredictedToken(token=' Shorts', prob=0.0002956390380859375, logit=13.875, token_id=91782, metadata=None))), (22725, (67, PredictedToken(token=' Orange', prob=9.584426879882812e-05, logit=12.75, token_id=22725, metadata=None))), (18343, (78, PredictedToken(token=' Paper', prob=6.198883056640625e-05, logit=12.3125, token_id=18343, metadata=None)))])\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.871, logit=21.500)', '\" None\"[2290] (p=0.030, logit=18.125)', '\" The\"[578] (p=0.023, logit=17.875)', '\" A\"[362] (p=0.016, logit=17.500)', '\" Spin\"[41785] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.87109375, logit=21.5, token_id=1901, metadata=None))), (41785, (5, PredictedToken(token=' Spin', prob=0.005889892578125, logit=16.5, token_id=41785, metadata=None))), (91782, (6, PredictedToken(token=' Shorts', prob=0.00457763671875, logit=16.25, token_id=91782, metadata=None))), (10573, (7, PredictedToken(token=' Watch', prob=0.0040283203125, logit=16.125, token_id=10573, metadata=None))), (22725, (15, PredictedToken(token=' Orange', prob=0.00179290771484375, logit=15.3125, token_id=22725, metadata=None))), (18343, (142, PredictedToken(token=' Paper', prob=1.990795135498047e-05, logit=10.8125, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:38 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:51:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.859, logit=21.500)', '\" The\"[578] (p=0.055, logit=18.750)', '\" Among\"[22395] (p=0.026, logit=18.000)', '\" An\"[1556] (p=0.018, logit=17.625)', '\" Sub\"[3804] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.859, logit=21.500)', '\" The\"[578] (p=0.049, logit=18.625)', '\" Among\"[22395] (p=0.033, logit=18.250)', '\" A\"[362] (p=0.012, logit=17.250)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.859375, logit=21.5, token_id=44570, metadata=None))), (29625, (7, PredictedToken(token=' Chain', prob=0.0033111572265625, logit=15.9375, token_id=29625, metadata=None))), (18343, (30, PredictedToken(token=' Paper', prob=0.0003490447998046875, logit=13.6875, token_id=18343, metadata=None))), (40090, (72, PredictedToken(token=' Pressure', prob=5.6743621826171875e-05, logit=11.875, token_id=40090, metadata=None))), (48471, (451, PredictedToken(token=' Shower', prob=1.952052116394043e-06, logit=8.5, token_id=48471, metadata=None))), (13394, (522, PredictedToken(token=' Bed', prob=1.6093254089355469e-06, logit=8.3125, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     int_prediction=['\" Maple\"[44570] (p=0.734, logit=21.375)', '\" Bed\"[13394] (p=0.113, logit=19.500)', '\" The\"[578] (p=0.037, logit=18.375)', '\" Chain\"[29625] (p=0.022, logit=17.875)', '\" A\"[362] (p=0.020, logit=17.750)']\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     int_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.734375, logit=21.375, token_id=44570, metadata=None))), (13394, (2, PredictedToken(token=' Bed', prob=0.11279296875, logit=19.5, token_id=13394, metadata=None))), (29625, (4, PredictedToken(token=' Chain', prob=0.022216796875, logit=17.875, token_id=29625, metadata=None))), (48471, (7, PredictedToken(token=' Shower', prob=0.010498046875, logit=17.125, token_id=48471, metadata=None))), (18343, (8, PredictedToken(token=' Paper', prob=0.0081787109375, logit=16.875, token_id=18343, metadata=None))), (40090, (17, PredictedToken(token=' Pressure', prob=0.0015106201171875, logit=15.1875, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:39 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     patch_prediction=['\" Gir\"[48035] (p=0.793, logit=22.375)', '\" The\"[578] (p=0.107, logit=20.375)', '\" A\"[362] (p=0.035, logit=19.250)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" Option\"[7104] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.898, logit=23.375)', '\" The\"[578] (p=0.051, logit=20.500)', '\" Among\"[22395] (p=0.021, logit=19.625)', '\" A\"[362] (p=0.010, logit=18.875)', '\" d\"[294] (p=0.006, logit=18.375)']\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.8984375, logit=23.375, token_id=423, metadata=None))), (10573, (37, PredictedToken(token=' Watch', prob=4.6253204345703125e-05, logit=13.5, token_id=10573, metadata=None))), (14588, (49, PredictedToken(token=' Dog', prob=2.8014183044433594e-05, logit=13.0, token_id=14588, metadata=None)))])\n",
      "2025-09-16 09:51:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.797, logit=22.750)', '\" The\"[578] (p=0.074, logit=20.375)', '\" D\"[423] (p=0.058, logit=20.125)', '\" Among\"[22395] (p=0.019, logit=19.000)', '\" A\"[362] (p=0.013, logit=18.625)']\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.796875, logit=22.75, token_id=14588, metadata=None))), (423, (3, PredictedToken(token=' D', prob=0.057861328125, logit=20.125, token_id=423, metadata=None))), (10573, (15, PredictedToken(token=' Watch', prob=0.000774383544921875, logit=15.8125, token_id=10573, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:40 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:40 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.707, logit=21.500)', '\" The\"[578] (p=0.108, logit=19.625)', '\" Among\"[22395] (p=0.058, logit=19.000)', '\" A\"[362] (p=0.058, logit=19.000)', '\" Tr\"[1183] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.746, logit=20.875)', '\" The\"[578] (p=0.089, logit=18.750)', '\" Among\"[22395] (p=0.048, logit=18.125)', '\" A\"[362] (p=0.042, logit=18.000)', '\" GRA\"[65120] (p=0.016, logit=17.000)']\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.74609375, logit=20.875, token_id=80629, metadata=None))), (59825, (173, PredictedToken(token=' Tie', prob=1.4126300811767578e-05, logit=10.0, token_id=59825, metadata=None))), (56491, (224, PredictedToken(token=' Piano', prob=8.58306884765625e-06, logit=9.5, token_id=56491, metadata=None))), (34046, (281, PredictedToken(token=' Cabinet', prob=5.900859832763672e-06, logit=9.125, token_id=34046, metadata=None))), (6150, (303, PredictedToken(token=' School', prob=5.185604095458984e-06, logit=9.0, token_id=6150, metadata=None))), (87213, (354, PredictedToken(token=' Oven', prob=4.0531158447265625e-06, logit=8.75, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.738, logit=20.875)', '\" A\"[362] (p=0.078, logit=18.625)', '\" The\"[578] (p=0.069, logit=18.500)', '\" Among\"[22395] (p=0.037, logit=17.875)', '\" \"\"[330] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.73828125, logit=20.875, token_id=59825, metadata=None))), (34046, (6, PredictedToken(token=' Cabinet', prob=0.00927734375, logit=16.5, token_id=34046, metadata=None))), (80629, (7, PredictedToken(token=' Grape', prob=0.007232666015625, logit=16.25, token_id=80629, metadata=None))), (87213, (9, PredictedToken(token=' Oven', prob=0.003875732421875, logit=15.625, token_id=87213, metadata=None))), (6150, (8, PredictedToken(token=' School', prob=0.003875732421875, logit=15.625, token_id=6150, metadata=None))), (56491, (65, PredictedToken(token=' Piano', prob=0.00010967254638671875, logit=12.0625, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:40 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:51:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     patch_prediction=['\" Temple\"[19176] (p=0.793, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" A\"[362] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.015, logit=17.375)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     clean_prediction=['\" Cabinet\"[34046] (p=0.855, logit=21.875)', '\" The\"[578] (p=0.055, logit=19.125)', '\" A\"[362] (p=0.029, logit=18.500)', '\" Among\"[22395] (p=0.023, logit=18.250)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     clean_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.85546875, logit=21.875, token_id=34046, metadata=None))), (38930, (45, PredictedToken(token=' Bike', prob=9.918212890625e-05, logit=12.8125, token_id=38930, metadata=None))), (52466, (54, PredictedToken(token=' Warehouse', prob=6.389617919921875e-05, logit=12.375, token_id=52466, metadata=None))), (26781, (70, PredictedToken(token=' Hair', prob=4.982948303222656e-05, logit=12.125, token_id=26781, metadata=None)))])\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     int_prediction=['\" Cabinet\"[34046] (p=0.828, logit=21.625)', '\" The\"[578] (p=0.047, logit=18.750)', '\" Warehouse\"[52466] (p=0.032, logit=18.375)', '\" Among\"[22395] (p=0.020, logit=17.875)', '\" A\"[362] (p=0.017, logit=17.750)']\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     int_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.828125, logit=21.625, token_id=34046, metadata=None))), (52466, (3, PredictedToken(token=' Warehouse', prob=0.0322265625, logit=18.375, token_id=52466, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.01336669921875, logit=17.5, token_id=38930, metadata=None))), (26781, (153, PredictedToken(token=' Hair', prob=1.2993812561035156e-05, logit=10.5625, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:41 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:41 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     patch_prediction=['\" Mouse\"[18191] (p=0.664, logit=20.750)', '\" Pen\"[13597] (p=0.147, logit=19.250)', '\" mouse\"[8814] (p=0.026, logit=17.500)', '\" Computer\"[17863] (p=0.023, logit=17.375)', '\" None\"[2290] (p=0.023, logit=17.375)']\n",
      "2025-09-16 09:51:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.828, logit=21.375)', '\" The\"[578] (p=0.053, logit=18.625)', '\" A\"[362] (p=0.053, logit=18.625)', '\" Among\"[22395] (p=0.010, logit=17.000)', '\" (\"[320] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.828125, logit=21.375, token_id=69755, metadata=None))), (43316, (11, PredictedToken(token=' Tul', prob=0.0021820068359375, logit=15.4375, token_id=43316, metadata=None))), (16147, (76, PredictedToken(token=' Smart', prob=5.125999450683594e-05, logit=11.6875, token_id=16147, metadata=None)))])\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.883, logit=21.875)', '\" The\"[578] (p=0.039, logit=18.750)', '\" A\"[362] (p=0.024, logit=18.250)', '\" Among\"[22395] (p=0.013, logit=17.625)', '\" smart\"[7941] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.8828125, logit=21.875, token_id=16147, metadata=None))), (43316, (6, PredictedToken(token=' Tul', prob=0.0052490234375, logit=16.75, token_id=43316, metadata=None))), (69755, (169, PredictedToken(token=' Notebook', prob=7.867813110351562e-06, logit=10.25, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:42 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:42 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     patch_prediction=['\" Calculator\"[37128] (p=0.641, logit=19.625)', '\" None\"[2290] (p=0.111, logit=17.875)', '\" The\"[578] (p=0.053, logit=17.125)', '\" A\"[362] (p=0.053, logit=17.125)', '\" Among\"[22395] (p=0.019, logit=16.125)']\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.898, logit=22.000)', '\" The\"[578] (p=0.045, logit=19.000)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" A\"[362] (p=0.006, logit=17.000)', '\" V\"[650] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.8984375, logit=22.0, token_id=74574, metadata=None))), (469, (32, PredictedToken(token=' E', prob=0.00020694732666015625, logit=13.625, token_id=469, metadata=None))), (1050, (50, PredictedToken(token=' Re', prob=6.341934204101562e-05, logit=12.4375, token_id=1050, metadata=None))), (1901, (99, PredictedToken(token=' Z', prob=1.811981201171875e-05, logit=11.1875, token_id=1901, metadata=None))), (18343, (114, PredictedToken(token=' Paper', prob=1.5020370483398438e-05, logit=11.0, token_id=18343, metadata=None))), (67553, (2650, PredictedToken(token=' Pants', prob=9.499490261077881e-08, logit=5.9375, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.609, logit=20.875)', '\" Violet\"[74574] (p=0.137, logit=19.375)', '\" An\"[1556] (p=0.064, logit=18.625)', '\" The\"[578] (p=0.064, logit=18.625)', '\" Re\"[1050] (p=0.050, logit=18.375)']\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.609375, logit=20.875, token_id=469, metadata=None))), (74574, (2, PredictedToken(token=' Violet', prob=0.13671875, logit=19.375, token_id=74574, metadata=None))), (1050, (5, PredictedToken(token=' Re', prob=0.050048828125, logit=18.375, token_id=1050, metadata=None))), (67553, (39, PredictedToken(token=' Pants', prob=0.000316619873046875, logit=13.3125, token_id=67553, metadata=None))), (1901, (76, PredictedToken(token=' Z', prob=7.534027099609375e-05, logit=11.875, token_id=1901, metadata=None))), (18343, (87, PredictedToken(token=' Paper', prob=6.628036499023438e-05, logit=11.75, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:42 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:42 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:51:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.754, logit=20.375)', '\" The\"[578] (p=0.070, logit=18.000)', '\" Among\"[22395] (p=0.048, logit=17.625)', '\" A\"[362] (p=0.029, logit=17.125)', '\" Option\"[7104] (p=0.016, logit=16.500)']\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.828, logit=21.625)', '\" The\"[578] (p=0.060, logit=19.000)', '\" An\"[1556] (p=0.036, logit=18.500)', '\" Among\"[22395] (p=0.025, logit=18.125)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.828125, logit=21.625, token_id=14937, metadata=None))), (58937, (41, PredictedToken(token=' Monkey', prob=0.000179290771484375, logit=13.1875, token_id=58937, metadata=None))), (328, (84, PredictedToken(token=' S', prob=5.14984130859375e-05, logit=11.9375, token_id=328, metadata=None))), (6031, (132, PredictedToken(token=' Bro', prob=2.014636993408203e-05, logit=11.0, token_id=6031, metadata=None))), (16478, (397, PredictedToken(token=' Chair', prob=2.726912498474121e-06, logit=9.0, token_id=16478, metadata=None))), (16488, (515, PredictedToken(token=' Bat', prob=1.8700957298278809e-06, logit=8.625, token_id=16488, metadata=None)))])\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.617, logit=21.000)', '\" A\"[362] (p=0.121, logit=19.375)', '\" Monkey\"[58937] (p=0.094, logit=19.125)', '\" The\"[578] (p=0.057, logit=18.625)', '\" Bro\"[6031] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.6171875, logit=21.0, token_id=16488, metadata=None))), (58937, (3, PredictedToken(token=' Monkey', prob=0.09423828125, logit=19.125, token_id=58937, metadata=None))), (14937, (6, PredictedToken(token=' Ash', prob=0.01446533203125, logit=17.25, token_id=14937, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.01446533203125, logit=17.25, token_id=6031, metadata=None))), (16478, (11, PredictedToken(token=' Chair', prob=0.00469970703125, logit=16.125, token_id=16478, metadata=None))), (328, (34, PredictedToken(token=' S', prob=0.000560760498046875, logit=14.0, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:43 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:51:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.613, logit=21.375)', '\" The\"[578] (p=0.137, logit=19.875)', '\" A\"[362] (p=0.094, logit=19.500)', '\" Among\"[22395] (p=0.073, logit=19.250)', '\" (\"[320] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.734, logit=21.750)', '\" The\"[578] (p=0.113, logit=19.875)', '\" A\"[362] (p=0.099, logit=19.750)', '\" Among\"[22395] (p=0.010, logit=17.500)', '\" (\"[320] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.734375, logit=21.75, token_id=28131, metadata=None))), (34392, (13, PredictedToken(token=' Horse', prob=0.000759124755859375, logit=14.875, token_id=34392, metadata=None))), (3341, (64, PredictedToken(token=' Car', prob=4.839897155761719e-05, logit=12.125, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.812, logit=21.875)', '\" A\"[362] (p=0.059, logit=19.250)', '\" The\"[578] (p=0.046, logit=19.000)', '\" Golf\"[28131] (p=0.028, logit=18.500)', '\" (\"[320] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.8125, logit=21.875, token_id=34392, metadata=None))), (28131, (4, PredictedToken(token=' Golf', prob=0.0277099609375, logit=18.5, token_id=28131, metadata=None))), (3341, (22, PredictedToken(token=' Car', prob=0.0004215240478515625, logit=14.3125, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:44 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:44 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.551, logit=21.375)', '\" A\"[362] (p=0.229, logit=20.500)', '\" The\"[578] (p=0.123, logit=19.875)', '\" Among\"[22395] (p=0.040, logit=18.750)', '\" (\"[320] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.895, logit=21.125)', '\" A\"[362] (p=0.024, logit=17.500)', '\" The\"[578] (p=0.021, logit=17.375)', '\" None\"[2290] (p=0.010, logit=16.625)', '\" CO\"[7432] (p=0.005, logit=15.875)']\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.89453125, logit=21.125, token_id=68867, metadata=None))), (72392, (14, PredictedToken(token=' Mixer', prob=0.00125885009765625, logit=14.5625, token_id=72392, metadata=None))), (61731, (16, PredictedToken(token=' Soap', prob=0.00104522705078125, logit=14.375, token_id=61731, metadata=None)))])\n",
      "2025-09-16 09:51:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.479, logit=19.875)', '\" Soap\"[61731] (p=0.176, logit=18.875)', '\" None\"[2290] (p=0.094, logit=18.250)', '\" A\"[362] (p=0.073, logit=18.000)', '\" Coat\"[68867] (p=0.065, logit=17.875)']\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.478515625, logit=19.875, token_id=72392, metadata=None))), (61731, (2, PredictedToken(token=' Soap', prob=0.17578125, logit=18.875, token_id=61731, metadata=None))), (68867, (5, PredictedToken(token=' Coat', prob=0.06494140625, logit=17.875, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:45 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:45 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.891, logit=21.875)', '\" An\"[1556] (p=0.034, logit=18.625)', '\" The\"[578] (p=0.024, logit=18.250)', '\" Among\"[22395] (p=0.016, logit=17.875)', '\" ank\"[71572] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.648, logit=22.000)', '\" The\"[578] (p=0.145, logit=20.500)', '\" A\"[362] (p=0.113, logit=20.250)', '\" Among\"[22395] (p=0.053, logit=19.500)', '\" Only\"[8442] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6484375, logit=22.0, token_id=27171, metadata=None))), (69755, (33, PredictedToken(token=' Notebook', prob=0.00023174285888671875, logit=14.0625, token_id=69755, metadata=None))), (39247, (35, PredictedToken(token=' Slow', prob=0.0002040863037109375, logit=13.9375, token_id=39247, metadata=None))), (3341, (55, PredictedToken(token=' Car', prob=7.05718994140625e-05, logit=12.875, token_id=3341, metadata=None))), (10573, (178, PredictedToken(token=' Watch', prob=5.781650543212891e-06, logit=10.375, token_id=10573, metadata=None))), (49431, (347, PredictedToken(token=' Rabbit', prob=1.55717134475708e-06, logit=9.0625, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     int_prediction=['\" A\"[362] (p=0.240, logit=20.250)', '\" Watch\"[10573] (p=0.212, logit=20.125)', '\" Notebook\"[69755] (p=0.187, logit=20.000)', '\" Rabbit\"[49431] (p=0.146, logit=19.750)', '\" The\"[578] (p=0.113, logit=19.500)']\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     int_track=OrderedDict([(10573, (2, PredictedToken(token=' Watch', prob=0.2119140625, logit=20.125, token_id=10573, metadata=None))), (69755, (3, PredictedToken(token=' Notebook', prob=0.1865234375, logit=20.0, token_id=69755, metadata=None))), (49431, (4, PredictedToken(token=' Rabbit', prob=0.1455078125, logit=19.75, token_id=49431, metadata=None))), (39247, (7, PredictedToken(token=' Slow', prob=0.0223388671875, logit=17.875, token_id=39247, metadata=None))), (27171, (38, PredictedToken(token=' Coffee', prob=0.0003185272216796875, logit=13.625, token_id=27171, metadata=None))), (3341, (55, PredictedToken(token=' Car', prob=0.00011730194091796875, logit=12.625, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:45 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.750, logit=21.375)', '\" The\"[578] (p=0.090, logit=19.250)', '\" Among\"[22395] (p=0.062, logit=18.875)', '\" A\"[362] (p=0.037, logit=18.375)', '\" Option\"[7104] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.680, logit=22.625)', '\" The\"[578] (p=0.151, logit=21.125)', '\" Among\"[22395] (p=0.072, logit=20.375)', '\" A\"[362] (p=0.063, logit=20.250)', '\" It\"[1102] (p=0.005, logit=17.750)']\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.6796875, logit=22.625, token_id=19111, metadata=None))), (328, (58, PredictedToken(token=' S', prob=3.719329833984375e-05, logit=12.8125, token_id=328, metadata=None))), (57915, (65, PredictedToken(token=' Ank', prob=3.2901763916015625e-05, logit=12.6875, token_id=57915, metadata=None))), (75258, (100, PredictedToken(token=' Refriger', prob=1.4603137969970703e-05, logit=11.875, token_id=75258, metadata=None))), (52882, (155, PredictedToken(token=' Pepper', prob=5.036592483520508e-06, logit=10.8125, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.498, logit=21.250)', '\" The\"[578] (p=0.162, logit=20.125)', '\" A\"[362] (p=0.126, logit=19.875)', '\" Refriger\"[75258] (p=0.077, logit=19.375)', '\" Among\"[22395] (p=0.077, logit=19.375)']\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.498046875, logit=21.25, token_id=52882, metadata=None))), (75258, (5, PredictedToken(token=' Refriger', prob=0.07666015625, logit=19.375, token_id=75258, metadata=None))), (328, (11, PredictedToken(token=' S', prob=0.002044677734375, logit=15.75, token_id=328, metadata=None))), (19111, (36, PredictedToken(token=' Bus', prob=0.000331878662109375, logit=13.9375, token_id=19111, metadata=None))), (57915, (62, PredictedToken(token=' Ank', prob=0.00013065338134765625, logit=13.0, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:46 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:46 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.887, logit=22.750)', '\" The\"[578] (p=0.044, logit=19.750)', '\" A\"[362] (p=0.021, logit=19.000)', '\" Among\"[22395] (p=0.018, logit=18.875)', '\" (\"[320] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     clean_prediction=['\" Camera\"[14669] (p=0.812, logit=21.750)', '\" The\"[578] (p=0.046, logit=18.875)', '\" A\"[362] (p=0.028, logit=18.375)', '\" Among\"[22395] (p=0.019, logit=18.000)', '\" Bus\"[19111] (p=0.017, logit=17.875)']\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     clean_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.8125, logit=21.75, token_id=14669, metadata=None))), (19111, (5, PredictedToken(token=' Bus', prob=0.016845703125, logit=17.875, token_id=19111, metadata=None))), (80629, (102, PredictedToken(token=' Grape', prob=3.457069396972656e-05, logit=11.6875, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:51:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.879, logit=21.625)', '\" A\"[362] (p=0.023, logit=18.000)', '\" grape\"[52252] (p=0.018, logit=17.750)', '\" The\"[578] (p=0.018, logit=17.750)', '\" Camera\"[14669] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.87890625, logit=21.625, token_id=80629, metadata=None))), (14669, (5, PredictedToken(token=' Camera', prob=0.00592041015625, logit=16.625, token_id=14669, metadata=None))), (19111, (194, PredictedToken(token=' Bus', prob=7.867813110351562e-06, logit=10.0, token_id=19111, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:47 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:47 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     patch_prediction=['\" Sc\"[2522] (p=0.613, logit=19.875)', '\" None\"[2290] (p=0.155, logit=18.500)', '\" Mixer\"[72392] (p=0.073, logit=17.750)', '\" The\"[578] (p=0.027, logit=16.750)', '\" Micro\"[18654] (p=0.021, logit=16.500)']\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     clean_prediction=['\" Yoga\"[38673] (p=0.594, logit=19.750)', '\" None\"[2290] (p=0.133, logit=18.250)', '\" Bamboo\"[98028] (p=0.055, logit=17.375)', '\" Tr\"[1183] (p=0.055, logit=17.375)', '\" The\"[578] (p=0.043, logit=17.125)']\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     clean_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.59375, logit=19.75, token_id=38673, metadata=None))), (98028, (4, PredictedToken(token=' Bamboo', prob=0.05517578125, logit=17.375, token_id=98028, metadata=None))), (1183, (3, PredictedToken(token=' Tr', prob=0.05517578125, logit=17.375, token_id=1183, metadata=None))), (40975, (10, PredictedToken(token=' Marker', prob=0.0042724609375, logit=14.8125, token_id=40975, metadata=None))), (76924, (96, PredictedToken(token=' Banana', prob=0.00011348724365234375, logit=11.1875, token_id=76924, metadata=None))), (12369, (443, PredictedToken(token=' Food', prob=6.8247318267822266e-06, logit=8.375, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.910, logit=21.625)', '\" None\"[2290] (p=0.021, logit=17.875)', '\" The\"[578] (p=0.021, logit=17.875)', '\" A\"[362] (p=0.013, logit=17.375)', '\" Yoga\"[38673] (p=0.003, logit=16.000)']\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.91015625, logit=21.625, token_id=40975, metadata=None))), (38673, (5, PredictedToken(token=' Yoga', prob=0.0032806396484375, logit=16.0, token_id=38673, metadata=None))), (98028, (8, PredictedToken(token=' Bamboo', prob=0.002716064453125, logit=15.8125, token_id=98028, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.0006866455078125, logit=14.4375, token_id=1183, metadata=None))), (76924, (84, PredictedToken(token=' Banana', prob=3.647804260253906e-05, logit=11.5, token_id=76924, metadata=None))), (12369, (584, PredictedToken(token=' Food', prob=1.2442469596862793e-06, logit=8.125, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:47 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:51:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     patch_prediction=['\" Spin\"[41785] (p=0.867, logit=22.000)', '\" Among\"[22395] (p=0.049, logit=19.125)', '\" The\"[578] (p=0.049, logit=19.125)', '\" A\"[362] (p=0.005, logit=16.750)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.037, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.500)', '\" Among\"[22395] (p=0.022, logit=18.125)', '\" None\"[2290] (p=0.020, logit=18.000)']\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.8359375, logit=21.75, token_id=10573, metadata=None))), (34785, (29, PredictedToken(token=' Truck', prob=0.00043487548828125, logit=14.1875, token_id=34785, metadata=None))), (1901, (34, PredictedToken(token=' Z', prob=0.0002803802490234375, logit=13.75, token_id=1901, metadata=None))), (14669, (108, PredictedToken(token=' Camera', prob=3.552436828613281e-05, logit=11.6875, token_id=14669, metadata=None))), (87035, (181, PredictedToken(token=' Onion', prob=1.1563301086425781e-05, logit=10.5625, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.672, logit=20.500)', '\" An\"[1556] (p=0.103, logit=18.625)', '\" The\"[578] (p=0.062, logit=18.125)', '\" None\"[2290] (p=0.030, logit=17.375)', '\" Among\"[22395] (p=0.018, logit=16.875)']\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.671875, logit=20.5, token_id=87035, metadata=None))), (1901, (6, PredictedToken(token=' Z', prob=0.013916015625, logit=16.625, token_id=1901, metadata=None))), (34785, (21, PredictedToken(token=' Truck', prob=0.00156402587890625, logit=14.4375, token_id=34785, metadata=None))), (10573, (49, PredictedToken(token=' Watch', prob=0.0003490447998046875, logit=12.9375, token_id=10573, metadata=None))), (14669, (3662, PredictedToken(token=' Camera', prob=2.980232238769531e-07, logit=5.875, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:48 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:48 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     patch_prediction=['\" Orange\"[22725] (p=0.887, logit=22.375)', '\" The\"[578] (p=0.034, logit=19.125)', '\" An\"[1556] (p=0.024, logit=18.750)', '\" Among\"[22395] (p=0.016, logit=18.375)', '\" orange\"[19087] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:51:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.754, logit=21.750)', '\" The\"[578] (p=0.102, logit=19.750)', '\" Among\"[22395] (p=0.055, logit=19.125)', '\" A\"[362] (p=0.029, logit=18.500)', '\" As\"[1666] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.75390625, logit=21.75, token_id=26698, metadata=None))), (1666, (5, PredictedToken(token=' As', prob=0.00738525390625, logit=17.125, token_id=1666, metadata=None))), (356, (38, PredictedToken(token=' C', prob=0.00023746490478515625, logit=13.6875, token_id=356, metadata=None))), (4923, (154, PredictedToken(token=' Sk', prob=1.341104507446289e-05, logit=10.8125, token_id=4923, metadata=None))), (55807, (432, PredictedToken(token=' Shirt', prob=1.817941665649414e-06, logit=8.8125, token_id=55807, metadata=None))), (89077, (984, PredictedToken(token=' Strawberry', prob=5.21540641784668e-07, logit=7.5625, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     int_prediction=['\" Strawberry\"[89077] (p=0.770, logit=21.250)', '\" Among\"[22395] (p=0.056, logit=18.625)', '\" The\"[578] (p=0.056, logit=18.625)', '\" As\"[1666] (p=0.034, logit=18.125)', '\" A\"[362] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     int_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.76953125, logit=21.25, token_id=89077, metadata=None))), (1666, (4, PredictedToken(token=' As', prob=0.03369140625, logit=18.125, token_id=1666, metadata=None))), (356, (70, PredictedToken(token=' C', prob=8.392333984375e-05, logit=12.125, token_id=356, metadata=None))), (26698, (97, PredictedToken(token=' Keyboard', prob=4.220008850097656e-05, logit=11.4375, token_id=26698, metadata=None))), (55807, (198, PredictedToken(token=' Shirt', prob=9.417533874511719e-06, logit=9.9375, token_id=55807, metadata=None))), (4923, (391, PredictedToken(token=' Sk', prob=3.0547380447387695e-06, logit=8.8125, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:49 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:49 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.594, logit=20.750)', '\" The\"[578] (p=0.219, logit=19.750)', '\" A\"[362] (p=0.071, logit=18.625)', '\" Among\"[22395] (p=0.043, logit=18.125)', '\" It\"[1102] (p=0.016, logit=17.125)']\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.688, logit=21.125)', '\" The\"[578] (p=0.120, logit=19.375)', '\" A\"[362] (p=0.082, logit=19.000)', '\" Among\"[22395] (p=0.039, logit=18.250)', '\" It\"[1102] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.6875, logit=21.125, token_id=13597, metadata=None))), (68027, (26, PredictedToken(token=' Sax', prob=0.0006256103515625, logit=14.125, token_id=68027, metadata=None))), (445, (96, PredictedToken(token=' L', prob=5.14984130859375e-05, logit=11.625, token_id=445, metadata=None))), (91297, (112, PredictedToken(token=' Mushroom', prob=3.528594970703125e-05, logit=11.25, token_id=91297, metadata=None)))])\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.547, logit=20.000)', '\" The\"[578] (p=0.156, logit=18.750)', '\" A\"[362] (p=0.107, logit=18.375)', '\" Pen\"[13597] (p=0.051, logit=17.625)', '\" Among\"[22395] (p=0.045, logit=17.500)']\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.546875, logit=20.0, token_id=68027, metadata=None))), (13597, (4, PredictedToken(token=' Pen', prob=0.05078125, logit=17.625, token_id=13597, metadata=None))), (91297, (34, PredictedToken(token=' Mushroom', prob=0.00067901611328125, logit=13.3125, token_id=91297, metadata=None))), (445, (64, PredictedToken(token=' L', prob=0.000171661376953125, logit=11.9375, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:49 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:49 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     patch_prediction=['\" Necklace\"[86460] (p=0.754, logit=22.000)', '\" The\"[578] (p=0.080, logit=19.750)', '\" A\"[362] (p=0.080, logit=19.750)', '\" Among\"[22395] (p=0.043, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     clean_prediction=['\" Y\"[816] (p=0.777, logit=21.750)', '\" A\"[362] (p=0.072, logit=19.375)', '\" The\"[578] (p=0.064, logit=19.250)', '\" Among\"[22395] (p=0.034, logit=18.625)', '\" Option\"[7104] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     clean_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.77734375, logit=21.75, token_id=816, metadata=None))), (393, (9, PredictedToken(token=' P', prob=0.0028076171875, logit=16.125, token_id=393, metadata=None))), (64695, (99, PredictedToken(token=' Peach', prob=2.276897430419922e-05, logit=11.3125, token_id=64695, metadata=None))), (48390, (202, PredictedToken(token=' Lily', prob=5.0961971282958984e-06, logit=9.8125, token_id=48390, metadata=None))), (58600, (220, PredictedToken(token=' Charm', prob=4.231929779052734e-06, logit=9.625, token_id=58600, metadata=None)))])\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.441, logit=20.125)', '\" Charm\"[58600] (p=0.268, logit=19.625)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" The\"[578] (p=0.060, logit=18.125)', '\" Lily\"[48390] (p=0.041, logit=17.750)']\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.44140625, logit=20.125, token_id=64695, metadata=None))), (58600, (2, PredictedToken(token=' Charm', prob=0.267578125, logit=19.625, token_id=58600, metadata=None))), (48390, (5, PredictedToken(token=' Lily', prob=0.041015625, logit=17.75, token_id=48390, metadata=None))), (393, (12, PredictedToken(token=' P', prob=0.003814697265625, logit=15.375, token_id=393, metadata=None))), (816, (70, PredictedToken(token=' Y', prob=0.0001678466796875, logit=12.25, token_id=816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:50 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:50 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:51:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.723, logit=21.500)', '\" The\"[578] (p=0.098, logit=19.500)', '\" A\"[362] (p=0.086, logit=19.375)', '\" Among\"[22395] (p=0.041, logit=18.625)', '\" (\"[320] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.855, logit=22.500)', '\" The\"[578] (p=0.048, logit=19.625)', '\" An\"[1556] (p=0.038, logit=19.375)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" Banana\"[76924] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.85546875, logit=22.5, token_id=6690, metadata=None))), (76924, (5, PredictedToken(token=' Banana', prob=0.005096435546875, logit=17.375, token_id=76924, metadata=None))), (328, (49, PredictedToken(token=' S', prob=6.818771362304688e-05, logit=13.0625, token_id=328, metadata=None))), (83499, (101, PredictedToken(token=' Tooth', prob=1.621246337890625e-05, logit=11.625, token_id=83499, metadata=None))), (97796, (203, PredictedToken(token=' Skate', prob=3.6209821701049805e-06, logit=10.125, token_id=97796, metadata=None))), (14588, (350, PredictedToken(token=' Dog', prob=1.3336539268493652e-06, logit=9.125, token_id=14588, metadata=None)))])\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.887, logit=22.500)', '\" The\"[578] (p=0.030, logit=19.125)', '\" A\"[362] (p=0.021, logit=18.750)', '\" Among\"[22395] (p=0.014, logit=18.375)', '\" Dogs\"[39525] (p=0.011, logit=18.125)']\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.88671875, logit=22.5, token_id=14588, metadata=None))), (328, (16, PredictedToken(token=' S', prob=0.000858306884765625, logit=15.5625, token_id=328, metadata=None))), (83499, (42, PredictedToken(token=' Tooth', prob=0.0001163482666015625, logit=13.5625, token_id=83499, metadata=None))), (76924, (60, PredictedToken(token=' Banana', prob=5.841255187988281e-05, logit=12.875, token_id=76924, metadata=None))), (97796, (62, PredictedToken(token=' Skate', prob=5.507469177246094e-05, logit=12.8125, token_id=97796, metadata=None))), (6690, (307, PredictedToken(token=' Air', prob=1.996755599975586e-06, logit=9.5, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:51 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:51 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.523, logit=20.875)', '\" Pine\"[42609] (p=0.279, logit=20.250)', '\" Among\"[22395] (p=0.062, logit=18.750)', '\" The\"[578] (p=0.055, logit=18.625)', '\" (\"[320] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     clean_prediction=['\" Dolphin\"[96096] (p=0.902, logit=21.875)', '\" The\"[578] (p=0.031, logit=18.500)', '\" Among\"[22395] (p=0.019, logit=18.000)', '\" A\"[362] (p=0.011, logit=17.500)', '\" dolphin\"[99269] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     clean_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.90234375, logit=21.875, token_id=96096, metadata=None))), (19176, (15, PredictedToken(token=' Temple', prob=0.00072479248046875, logit=14.75, token_id=19176, metadata=None))), (84409, (103, PredictedToken(token=' Plum', prob=1.823902130126953e-05, logit=11.0625, token_id=84409, metadata=None))), (67629, (190, PredictedToken(token=' Helmet', prob=5.543231964111328e-06, logit=9.875, token_id=67629, metadata=None)))])\n",
      "2025-09-16 09:51:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.828, logit=21.375)', '\" The\"[578] (p=0.047, logit=18.500)', '\" Among\"[22395] (p=0.028, logit=18.000)', '\" Option\"[7104] (p=0.025, logit=17.875)', '\" A\"[362] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.828125, logit=21.375, token_id=84409, metadata=None))), (96096, (22, PredictedToken(token=' Dolphin', prob=0.000911712646484375, logit=14.5625, token_id=96096, metadata=None))), (19176, (71, PredictedToken(token=' Temple', prob=5.4836273193359375e-05, logit=11.75, token_id=19176, metadata=None))), (67629, (255, PredictedToken(token=' Helmet', prob=5.424022674560547e-06, logit=9.4375, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:52 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     patch_prediction=['\" Y\"[816] (p=0.828, logit=21.375)', '\" A\"[362] (p=0.047, logit=18.500)', '\" The\"[578] (p=0.041, logit=18.375)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" None\"[2290] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     clean_prediction=['\" Let\"[6914] (p=0.812, logit=21.875)', '\" The\"[578] (p=0.097, logit=19.750)', '\" Among\"[22395] (p=0.046, logit=19.000)', '\" A\"[362] (p=0.012, logit=17.625)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     clean_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.8125, logit=21.875, token_id=6914, metadata=None))), (6031, (12, PredictedToken(token=' Bro', prob=0.00107574462890625, logit=15.25, token_id=6031, metadata=None))), (20423, (40, PredictedToken(token=' Amb', prob=0.00014591217041015625, logit=13.25, token_id=20423, metadata=None))), (13120, (93, PredictedToken(token=' Night', prob=2.5272369384765625e-05, logit=11.5, token_id=13120, metadata=None))), (32498, (1196, PredictedToken(token=' Mall', prob=3.0919909477233887e-07, logit=7.09375, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     int_prediction=['\" Amb\"[20423] (p=0.543, logit=21.375)', '\" An\"[1556] (p=0.176, logit=20.250)', '\" Among\"[22395] (p=0.094, logit=19.625)', '\" The\"[578] (p=0.083, logit=19.500)', '\" Let\"[6914] (p=0.065, logit=19.250)']\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     int_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.54296875, logit=21.375, token_id=20423, metadata=None))), (6914, (5, PredictedToken(token=' Let', prob=0.06494140625, logit=19.25, token_id=6914, metadata=None))), (32498, (10, PredictedToken(token=' Mall', prob=0.0020751953125, logit=15.8125, token_id=32498, metadata=None))), (6031, (45, PredictedToken(token=' Bro', prob=0.00014209747314453125, logit=13.125, token_id=6031, metadata=None))), (13120, (119, PredictedToken(token=' Night', prob=2.1696090698242188e-05, logit=11.25, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:52 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:52 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:51:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.680, logit=22.375)', '\" An\"[1556] (p=0.172, logit=21.000)', '\" The\"[578] (p=0.071, logit=20.125)', '\" Among\"[22395] (p=0.049, logit=19.750)', '\" It\"[1102] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.730, logit=20.375)', '\" The\"[578] (p=0.087, logit=18.250)', '\" A\"[362] (p=0.032, logit=17.250)', '\" Among\"[22395] (p=0.022, logit=16.875)', '\" Pine\"[42609] (p=0.015, logit=16.500)']\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.73046875, logit=20.375, token_id=58403, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.01513671875, logit=16.5, token_id=42609, metadata=None))), (11683, (15, PredictedToken(token=' Acc', prob=0.003173828125, logit=14.9375, token_id=11683, metadata=None))), (19111, (35, PredictedToken(token=' Bus', prob=0.000751495361328125, logit=13.5, token_id=19111, metadata=None))), (91297, (377, PredictedToken(token=' Mushroom', prob=7.3909759521484375e-06, logit=8.875, token_id=91297, metadata=None))), (22050, (421, PredictedToken(token=' Hat', prob=6.109476089477539e-06, logit=8.6875, token_id=22050, metadata=None)))])\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.918, logit=21.875)', '\" The\"[578] (p=0.017, logit=17.875)', '\" None\"[2290] (p=0.012, logit=17.500)', '\" Tablet\"[58403] (p=0.007, logit=17.000)', '\" Pine\"[42609] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.91796875, logit=21.875, token_id=19111, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.006988525390625, logit=17.0, token_id=42609, metadata=None))), (58403, (5, PredictedToken(token=' Tablet', prob=0.006988525390625, logit=17.0, token_id=58403, metadata=None))), (22050, (55, PredictedToken(token=' Hat', prob=8.821487426757812e-05, logit=12.625, token_id=22050, metadata=None))), (91297, (258, PredictedToken(token=' Mushroom', prob=3.635883331298828e-06, logit=9.4375, token_id=91297, metadata=None))), (11683, (322, PredictedToken(token=' Acc', prob=2.3543834686279297e-06, logit=9.0, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:53 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.930, logit=23.125)', '\" The\"[578] (p=0.036, logit=19.875)', '\" Among\"[22395] (p=0.019, logit=19.250)', '\" (\"[320] (p=0.004, logit=17.625)', '\" Option\"[7104] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.746, logit=22.000)', '\" The\"[578] (p=0.130, logit=20.250)', '\" A\"[362] (p=0.054, logit=19.375)', '\" Among\"[22395] (p=0.023, logit=18.500)', '\" (\"[320] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.74609375, logit=22.0, token_id=31181, metadata=None))), (6031, (110, PredictedToken(token=' Bro', prob=1.4126300811767578e-05, logit=11.125, token_id=6031, metadata=None))), (84409, (146, PredictedToken(token=' Plum', prob=7.569789886474609e-06, logit=10.5, token_id=84409, metadata=None)))])\n",
      "2025-09-16 09:51:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.781, logit=21.750)', '\" Plum\"[84409] (p=0.064, logit=19.250)', '\" The\"[578] (p=0.064, logit=19.250)', '\" Among\"[22395] (p=0.027, logit=18.375)', '\" Clar\"[31181] (p=0.016, logit=17.875)']\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.78125, logit=21.75, token_id=6031, metadata=None))), (84409, (3, PredictedToken(token=' Plum', prob=0.06396484375, logit=19.25, token_id=84409, metadata=None))), (31181, (5, PredictedToken(token=' Clar', prob=0.0162353515625, logit=17.875, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:51:54 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.738, logit=21.000)', '\" The\"[578] (p=0.100, logit=19.000)', '\" A\"[362] (p=0.078, logit=18.750)', '\" Among\"[22395] (p=0.032, logit=17.875)', '\" stap\"[36114] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     clean_prediction=['\" Blue\"[8868] (p=0.785, logit=22.375)', '\" The\"[578] (p=0.106, logit=20.375)', '\" A\"[362] (p=0.057, logit=19.750)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" Fruit\"[44187] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     clean_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.78515625, logit=22.375, token_id=8868, metadata=None))), (816, (11, PredictedToken(token=' Y', prob=0.00110626220703125, logit=15.8125, token_id=816, metadata=None))), (328, (41, PredictedToken(token=' S', prob=9.107589721679688e-05, logit=13.3125, token_id=328, metadata=None))), (82994, (117, PredictedToken(token=' Toilet', prob=1.0848045349121094e-05, logit=11.1875, token_id=82994, metadata=None))), (36943, (279, PredictedToken(token=' Folder', prob=2.0116567611694336e-06, logit=9.5, token_id=36943, metadata=None))), (53889, (418, PredictedToken(token=' Apartment', prob=9.499490261077881e-07, logit=8.75, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.422, logit=20.375)', '\" Toilet\"[82994] (p=0.176, logit=19.500)', '\" The\"[578] (p=0.176, logit=19.500)', '\" A\"[362] (p=0.094, logit=18.875)', '\" Among\"[22395] (p=0.044, logit=18.125)']\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.421875, logit=20.375, token_id=36943, metadata=None))), (82994, (3, PredictedToken(token=' Toilet', prob=0.17578125, logit=19.5, token_id=82994, metadata=None))), (53889, (7, PredictedToken(token=' Apartment', prob=0.01123046875, logit=16.75, token_id=53889, metadata=None))), (328, (10, PredictedToken(token=' S', prob=0.0032196044921875, logit=15.5, token_id=328, metadata=None))), (816, (48, PredictedToken(token=' Y', prob=0.0002193450927734375, logit=12.8125, token_id=816, metadata=None))), (8868, (97, PredictedToken(token=' Blue', prob=6.29425048828125e-05, logit=11.5625, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:54 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:54 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:51:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.836, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.022, logit=18.625)', '\" A\"[362] (p=0.020, logit=18.500)', '\" Option\"[7104] (p=0.012, logit=18.000)']\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     clean_prediction=['\" Brace\"[70306] (p=0.773, logit=22.125)', '\" A\"[362] (p=0.082, logit=19.875)', '\" The\"[578] (p=0.072, logit=19.750)', '\" Among\"[22395] (p=0.034, logit=19.000)', '\" It\"[1102] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     clean_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.7734375, logit=22.125, token_id=70306, metadata=None))), (5340, (59, PredictedToken(token=' Har', prob=7.009506225585938e-05, logit=12.8125, token_id=5340, metadata=None))), (14937, (75, PredictedToken(token=' Ash', prob=4.2438507080078125e-05, logit=12.3125, token_id=14937, metadata=None))), (97796, (144, PredictedToken(token=' Skate', prob=1.0728836059570312e-05, logit=10.9375, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.715, logit=21.125)', '\" A\"[362] (p=0.075, logit=18.875)', '\" The\"[578] (p=0.066, logit=18.750)', '\" Skate\"[97796] (p=0.031, logit=18.000)', '\" Among\"[22395] (p=0.024, logit=17.750)']\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.71484375, logit=21.125, token_id=5340, metadata=None))), (97796, (4, PredictedToken(token=' Skate', prob=0.031494140625, logit=18.0, token_id=97796, metadata=None))), (14937, (6, PredictedToken(token=' Ash', prob=0.016845703125, logit=17.375, token_id=14937, metadata=None))), (70306, (7, PredictedToken(token=' Brace', prob=0.00897216796875, logit=16.75, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:55 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.820, logit=21.500)', '\" The\"[578] (p=0.067, logit=19.000)', '\" A\"[362] (p=0.036, logit=18.375)', '\" Among\"[22395] (p=0.032, logit=18.250)', '\" cabinet\"[22685] (p=0.003, logit=15.938)']\n",
      "2025-09-16 09:51:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.883, logit=21.750)', '\" The\"[578] (p=0.064, logit=19.125)', '\" Among\"[22395] (p=0.021, logit=18.000)', '\" A\"[362] (p=0.005, logit=16.500)', '\" It\"[1102] (p=0.003, logit=16.125)']\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.8828125, logit=21.75, token_id=72683, metadata=None))), (26781, (37, PredictedToken(token=' Hair', prob=0.000179290771484375, logit=13.25, token_id=26781, metadata=None))), (98028, (38, PredictedToken(token=' Bamboo', prob=0.00016880035400390625, logit=13.1875, token_id=98028, metadata=None))), (70110, (158, PredictedToken(token=' Ottoman', prob=9.5367431640625e-06, logit=10.3125, token_id=70110, metadata=None))), (38571, (373, PredictedToken(token=' Theater', prob=1.996755599975586e-06, logit=8.75, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.727, logit=20.375)', '\" The\"[578] (p=0.098, logit=18.375)', '\" An\"[1556] (p=0.086, logit=18.250)', '\" Among\"[22395] (p=0.015, logit=16.500)', '\" A\"[362] (p=0.006, logit=15.562)']\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.7265625, logit=20.375, token_id=70110, metadata=None))), (38571, (8, PredictedToken(token=' Theater', prob=0.005523681640625, logit=15.5, token_id=38571, metadata=None))), (98028, (12, PredictedToken(token=' Bamboo', prob=0.00179290771484375, logit=14.375, token_id=98028, metadata=None))), (72683, (16, PredictedToken(token=' Boxing', prob=0.001312255859375, logit=14.0625, token_id=72683, metadata=None))), (26781, (169, PredictedToken(token=' Hair', prob=1.8715858459472656e-05, logit=9.8125, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:56 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     patch_prediction=['\" Basketball\"[47589] (p=0.902, logit=22.500)', '\" The\"[578] (p=0.045, logit=19.500)', '\" Among\"[22395] (p=0.013, logit=18.250)', '\" A\"[362] (p=0.013, logit=18.250)', '\" Basket\"[34217] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.641, logit=21.625)', '\" An\"[1556] (p=0.162, logit=20.250)', '\" The\"[578] (p=0.077, logit=19.500)', '\" Among\"[22395] (p=0.053, logit=19.125)', '\" e\"[384] (p=0.025, logit=18.375)']\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.640625, logit=21.625, token_id=469, metadata=None))), (432, (17, PredictedToken(token=' R', prob=0.000965118408203125, logit=15.125, token_id=432, metadata=None))), (921, (19, PredictedToken(token=' Ch', prob=0.000705718994140625, logit=14.8125, token_id=921, metadata=None))), (18787, (53, PredictedToken(token=' Oak', prob=7.915496826171875e-05, logit=12.625, token_id=18787, metadata=None))), (23462, (106, PredictedToken(token=' Stadium', prob=2.4080276489257812e-05, logit=11.4375, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.059, logit=19.250)', '\" Among\"[22395] (p=0.035, logit=18.750)', '\" It\"[1102] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.80859375, logit=21.875, token_id=432, metadata=None))), (469, (21, PredictedToken(token=' E', prob=0.000537872314453125, logit=14.5625, token_id=469, metadata=None))), (23462, (22, PredictedToken(token=' Stadium', prob=0.000507354736328125, logit=14.5, token_id=23462, metadata=None))), (921, (47, PredictedToken(token=' Ch', prob=9.34600830078125e-05, logit=12.8125, token_id=921, metadata=None))), (18787, (309, PredictedToken(token=' Oak', prob=2.205371856689453e-06, logit=9.0625, token_id=18787, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:56 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:56 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:51:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     patch_prediction=['\" Tablet\"[58403] (p=0.629, logit=20.500)', '\" The\"[578] (p=0.124, logit=18.875)', '\" Among\"[22395] (p=0.045, logit=17.875)', '\" A\"[362] (p=0.040, logit=17.750)', '\" C\"[356] (p=0.031, logit=17.500)']\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     clean_prediction=['\" Amb\"[20423] (p=0.680, logit=22.000)', '\" An\"[1556] (p=0.134, logit=20.375)', '\" Among\"[22395] (p=0.072, logit=19.750)', '\" The\"[578] (p=0.043, logit=19.250)', '\" Option\"[7104] (p=0.018, logit=18.375)']\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     clean_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.6796875, logit=22.0, token_id=20423, metadata=None))), (48471, (78, PredictedToken(token=' Shower', prob=3.719329833984375e-05, logit=12.1875, token_id=48471, metadata=None))), (19176, (84, PredictedToken(token=' Temple', prob=2.8967857360839844e-05, logit=11.9375, token_id=19176, metadata=None))), (30173, (88, PredictedToken(token=' Speaker', prob=2.7298927307128906e-05, logit=11.875, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     int_prediction=['\" Shower\"[48471] (p=0.365, logit=19.625)', '\" Speaker\"[30173] (p=0.283, logit=19.375)', '\" The\"[578] (p=0.092, logit=18.250)', '\" A\"[362] (p=0.063, logit=17.875)', '\" None\"[2290] (p=0.034, logit=17.250)']\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     int_track=OrderedDict([(48471, (1, PredictedToken(token=' Shower', prob=0.365234375, logit=19.625, token_id=48471, metadata=None))), (30173, (2, PredictedToken(token=' Speaker', prob=0.283203125, logit=19.375, token_id=30173, metadata=None))), (20423, (16, PredictedToken(token=' Amb', prob=0.00335693359375, logit=14.9375, token_id=20423, metadata=None))), (19176, (41, PredictedToken(token=' Temple', prob=0.000659942626953125, logit=13.3125, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:57 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:57 src.selection.optimization DEBUG    torch.Size([4, 30])\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     patch_prediction=['\" Surf\"[65197] (p=0.467, logit=19.750)', '\" Razor\"[74968] (p=0.221, logit=19.000)', '\" The\"[578] (p=0.092, logit=18.125)', '\" Among\"[22395] (p=0.056, logit=17.625)', '\" A\"[362] (p=0.026, logit=16.875)']\n",
      "2025-09-16 09:51:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.738, logit=21.125)', '\" Among\"[22395] (p=0.088, logit=19.000)', '\" The\"[578] (p=0.088, logit=19.000)', '\" A\"[362] (p=0.014, logit=17.125)', '\" It\"[1102] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.73828125, logit=21.125, token_id=88088, metadata=None))), (4923, (85, PredictedToken(token=' Sk', prob=4.315376281738281e-05, logit=11.375, token_id=4923, metadata=None))), (56491, (155, PredictedToken(token=' Piano', prob=1.4007091522216797e-05, logit=10.25, token_id=56491, metadata=None))), (11896, (179, PredictedToken(token=' Library', prob=1.0907649993896484e-05, logit=10.0, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.750, logit=21.250)', '\" Sk\"[4923] (p=0.079, logit=19.000)', '\" The\"[578] (p=0.062, logit=18.750)', '\" Among\"[22395] (p=0.029, logit=18.000)', '\" Option\"[7104] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.75, logit=21.25, token_id=56491, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.0791015625, logit=19.0, token_id=4923, metadata=None))), (11896, (35, PredictedToken(token=' Library', prob=0.0003662109375, logit=13.625, token_id=11896, metadata=None))), (88088, (59, PredictedToken(token=' Birch', prob=0.0001430511474609375, logit=12.6875, token_id=88088, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:58 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:51:58 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.926, logit=22.250)', '\" Glo\"[25372] (p=0.017, logit=18.250)', '\" The\"[578] (p=0.017, logit=18.250)', '\" Among\"[22395] (p=0.007, logit=17.375)', '\" Let\"[6914] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.895, logit=22.250)', '\" The\"[578] (p=0.035, logit=19.000)', '\" A\"[362] (p=0.016, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.875)', '\" (\"[320] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.89453125, logit=22.25, token_id=5907, metadata=None))), (432, (8, PredictedToken(token=' R', prob=0.004119873046875, logit=16.875, token_id=432, metadata=None))), (4923, (19, PredictedToken(token=' Sk', prob=0.000492095947265625, logit=14.75, token_id=4923, metadata=None)))])\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.633, logit=21.375)', '\" R\"[432] (p=0.232, logit=20.375)', '\" The\"[578] (p=0.041, logit=18.625)', '\" A\"[362] (p=0.022, logit=18.000)', '\" (\"[320] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.6328125, logit=21.375, token_id=4923, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.232421875, logit=20.375, token_id=432, metadata=None))), (5907, (18, PredictedToken(token=' Project', prob=0.000789642333984375, logit=14.6875, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:51:58 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:51:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     patch_prediction=['\" Tie\"[59825] (p=0.809, logit=21.250)', '\" Among\"[22395] (p=0.052, logit=18.500)', '\" The\"[578] (p=0.046, logit=18.375)', '\" A\"[362] (p=0.040, logit=18.250)', '\" It\"[1102] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.918, logit=22.500)', '\" The\"[578] (p=0.028, logit=19.000)', '\" A\"[362] (p=0.022, logit=18.750)', '\" Among\"[22395] (p=0.010, logit=18.000)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.91796875, logit=22.5, token_id=88668, metadata=None))), (1183, (22, PredictedToken(token=' Tr', prob=0.0002899169921875, logit=14.4375, token_id=1183, metadata=None))), (3420, (231, PredictedToken(token=' Trump', prob=2.6673078536987305e-06, logit=9.75, token_id=3420, metadata=None))), (17367, (358, PredictedToken(token=' Factory', prob=1.259148120880127e-06, logit=9.0, token_id=17367, metadata=None))), (22050, (471, PredictedToken(token=' Hat', prob=8.121132850646973e-07, logit=8.5625, token_id=22050, metadata=None)))])\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     int_prediction=['\" Hat\"[22050] (p=0.777, logit=21.500)', '\" The\"[578] (p=0.072, logit=19.125)', '\" A\"[362] (p=0.064, logit=19.000)', '\" Among\"[22395] (p=0.018, logit=17.750)', '\" Blender\"[88668] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     int_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.77734375, logit=21.5, token_id=22050, metadata=None))), (88668, (5, PredictedToken(token=' Blender', prob=0.00762939453125, logit=16.875, token_id=88668, metadata=None))), (1183, (10, PredictedToken(token=' Tr', prob=0.00360107421875, logit=16.125, token_id=1183, metadata=None))), (3420, (49, PredictedToken(token=' Trump', prob=0.0001583099365234375, logit=13.0, token_id=3420, metadata=None))), (17367, (65, PredictedToken(token=' Factory', prob=8.487701416015625e-05, logit=12.375, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:51:59 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:51:59 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:51:59 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     patch_prediction=['\" Book\"[6017] (p=0.820, logit=22.000)', '\" The\"[578] (p=0.067, logit=19.500)', '\" Among\"[22395] (p=0.028, logit=18.625)', '\" A\"[362] (p=0.028, logit=18.625)', '\" (\"[320] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     clean_prediction=['\" Potato\"[78703] (p=0.754, logit=21.750)', '\" The\"[578] (p=0.090, logit=19.625)', '\" A\"[362] (p=0.070, logit=19.375)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     clean_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.75390625, logit=21.75, token_id=78703, metadata=None))), (23262, (39, PredictedToken(token=' Comb', prob=0.0001964569091796875, logit=13.5, token_id=23262, metadata=None))), (18343, (55, PredictedToken(token=' Paper', prob=0.00010538101196289062, logit=12.875, token_id=18343, metadata=None))), (34046, (227, PredictedToken(token=' Cabinet', prob=4.6193599700927734e-06, logit=9.75, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.539, logit=21.000)', '\" Cabinet\"[34046] (p=0.254, logit=20.250)', '\" A\"[362] (p=0.064, logit=18.875)', '\" The\"[578] (p=0.057, logit=18.750)', '\" Among\"[22395] (p=0.034, logit=18.250)']\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.5390625, logit=21.0, token_id=23262, metadata=None))), (34046, (2, PredictedToken(token=' Cabinet', prob=0.25390625, logit=20.25, token_id=34046, metadata=None))), (78703, (28, PredictedToken(token=' Potato', prob=0.000492095947265625, logit=14.0, token_id=78703, metadata=None))), (18343, (38, PredictedToken(token=' Paper', prob=0.0002803802490234375, logit=13.4375, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:00 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:00 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     patch_prediction=['\" Watch\"[10573] (p=0.793, logit=21.375)', '\" A\"[362] (p=0.065, logit=18.875)', '\" The\"[578] (p=0.040, logit=18.375)', '\" Among\"[22395] (p=0.015, logit=17.375)', '\" Y\"[816] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.902, logit=21.375)', '\" None\"[2290] (p=0.027, logit=17.875)', '\" The\"[578] (p=0.024, logit=17.750)', '\" Among\"[22395] (p=0.009, logit=16.750)', '\" A\"[362] (p=0.003, logit=15.562)']\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.90234375, logit=21.375, token_id=58586, metadata=None))), (1443, (13, PredictedToken(token=' Sh', prob=0.00087738037109375, logit=14.4375, token_id=1443, metadata=None))), (8868, (29, PredictedToken(token=' Blue', prob=0.00026702880859375, logit=13.25, token_id=8868, metadata=None))), (72683, (86, PredictedToken(token=' Boxing', prob=4.363059997558594e-05, logit=11.4375, token_id=72683, metadata=None))), (86460, (140, PredictedToken(token=' Necklace', prob=1.823902130126953e-05, logit=10.5625, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.789, logit=21.125)', '\" None\"[2290] (p=0.083, logit=18.875)', '\" The\"[578] (p=0.031, logit=17.875)', '\" A\"[362] (p=0.027, logit=17.750)', '\" Blue\"[8868] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:52:00 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.7890625, logit=21.125, token_id=86460, metadata=None))), (8868, (5, PredictedToken(token=' Blue', prob=0.01129150390625, logit=16.875, token_id=8868, metadata=None))), (1443, (11, PredictedToken(token=' Sh', prob=0.00183868408203125, logit=15.0625, token_id=1443, metadata=None))), (72683, (33, PredictedToken(token=' Boxing', prob=0.0003204345703125, logit=13.3125, token_id=72683, metadata=None))), (58586, (70, PredictedToken(token=' Tape', prob=8.630752563476562e-05, logit=12.0, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:01 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.738, logit=21.750)', '\" The\"[578] (p=0.078, logit=19.500)', '\" Among\"[22395] (p=0.068, logit=19.375)', '\" A\"[362] (p=0.068, logit=19.375)', '\" \"[220] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.645, logit=21.750)', '\" The\"[578] (p=0.163, logit=20.375)', '\" Among\"[22395] (p=0.068, logit=19.500)', '\" A\"[362] (p=0.060, logit=19.375)', '\" It\"[1102] (p=0.015, logit=18.000)']\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.64453125, logit=21.75, token_id=1630, metadata=None))), (1901, (10, PredictedToken(token=' Z', prob=0.00299072265625, logit=16.375, token_id=1901, metadata=None))), (66821, (30, PredictedToken(token=' Iris', prob=0.0003795623779296875, logit=14.3125, token_id=66821, metadata=None))), (3804, (41, PredictedToken(token=' Sub', prob=0.00016880035400390625, logit=13.5, token_id=3804, metadata=None))), (86460, (159, PredictedToken(token=' Necklace', prob=1.0132789611816406e-05, logit=10.6875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.828, logit=21.625)', '\" The\"[578] (p=0.047, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.625)', '\" Z\"[1901] (p=0.019, logit=17.875)', '\" An\"[1556] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.828125, logit=21.625, token_id=66821, metadata=None))), (1901, (4, PredictedToken(token=' Z', prob=0.0194091796875, logit=17.875, token_id=1901, metadata=None))), (3804, (6, PredictedToken(token=' Sub', prob=0.006317138671875, logit=16.75, token_id=3804, metadata=None))), (1630, (59, PredictedToken(token=' X', prob=7.009506225585938e-05, logit=12.25, token_id=1630, metadata=None))), (86460, (605, PredictedToken(token=' Necklace', prob=1.0654330253601074e-06, logit=8.0625, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:01 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:01 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:52:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.926, logit=21.750)', '\" The\"[578] (p=0.025, logit=18.125)', '\" A\"[362] (p=0.007, logit=16.875)', '\" Among\"[22395] (p=0.006, logit=16.625)', '\" tape\"[17401] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     clean_prediction=['\" Elephant\"[79189] (p=0.801, logit=22.250)', '\" An\"[1556] (p=0.095, logit=20.125)', '\" The\"[578] (p=0.051, logit=19.500)', '\" Among\"[22395] (p=0.019, logit=18.500)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     clean_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.80078125, logit=22.25, token_id=79189, metadata=None))), (40975, (34, PredictedToken(token=' Marker', prob=0.0001621246337890625, logit=13.75, token_id=40975, metadata=None))), (29318, (138, PredictedToken(token=' Dress', prob=6.705522537231445e-06, logit=10.5625, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.930, logit=22.750)', '\" The\"[578] (p=0.017, logit=18.750)', '\" A\"[362] (p=0.009, logit=18.125)', '\" Elephant\"[79189] (p=0.008, logit=18.000)', '\" An\"[1556] (p=0.007, logit=17.875)']\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.9296875, logit=22.75, token_id=40975, metadata=None))), (79189, (4, PredictedToken(token=' Elephant', prob=0.008056640625, logit=18.0, token_id=79189, metadata=None))), (29318, (7, PredictedToken(token=' Dress', prob=0.004302978515625, logit=17.375, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:02 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:02 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.742, logit=22.250)', '\" A\"[362] (p=0.088, logit=20.125)', '\" The\"[578] (p=0.078, logit=20.000)', '\" Among\"[22395] (p=0.047, logit=19.500)', '\" It\"[1102] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     clean_prediction=['\" Table\"[6771] (p=0.844, logit=21.875)', '\" The\"[578] (p=0.048, logit=19.000)', '\" A\"[362] (p=0.033, logit=18.625)', '\" Among\"[22395] (p=0.022, logit=18.250)', '\" Monitor\"[24423] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     clean_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.84375, logit=21.875, token_id=6771, metadata=None))), (24423, (5, PredictedToken(token=' Monitor', prob=0.0093994140625, logit=17.375, token_id=24423, metadata=None))), (816, (33, PredictedToken(token=' Y', prob=0.0002498626708984375, logit=13.75, token_id=816, metadata=None))), (445, (36, PredictedToken(token=' L', prob=0.00022029876708984375, logit=13.625, token_id=445, metadata=None))), (40090, (39, PredictedToken(token=' Pressure', prob=0.00020694732666015625, logit=13.5625, token_id=40090, metadata=None))), (16344, (105, PredictedToken(token=' Rose', prob=2.47955322265625e-05, logit=11.4375, token_id=16344, metadata=None)))])\n",
      "2025-09-16 09:52:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     int_prediction=['\" Y\"[816] (p=0.875, logit=21.625)', '\" A\"[362] (p=0.044, logit=18.625)', '\" The\"[578] (p=0.021, logit=17.875)', '\" Among\"[22395] (p=0.013, logit=17.375)', '\" L\"[445] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     int_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.875, logit=21.625, token_id=816, metadata=None))), (445, (5, PredictedToken(token=' L', prob=0.005889892578125, logit=16.625, token_id=445, metadata=None))), (40090, (9, PredictedToken(token=' Pressure', prob=0.002044677734375, logit=15.5625, token_id=40090, metadata=None))), (24423, (17, PredictedToken(token=' Monitor', prob=0.00109100341796875, logit=14.9375, token_id=24423, metadata=None))), (6771, (36, PredictedToken(token=' Table', prob=0.0002288818359375, logit=13.375, token_id=6771, metadata=None))), (16344, (230, PredictedToken(token=' Rose', prob=4.738569259643555e-06, logit=9.5, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:03 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     patch_prediction=['\" Apartment\"[53889] (p=0.754, logit=22.250)', '\" An\"[1556] (p=0.080, logit=20.000)', '\" The\"[578] (p=0.062, logit=19.750)', '\" Among\"[22395] (p=0.054, logit=19.625)', '\" None\"[2290] (p=0.020, logit=18.625)']\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     clean_prediction=['\" Micro\"[18654] (p=0.770, logit=21.375)', '\" The\"[578] (p=0.081, logit=19.125)', '\" Among\"[22395] (p=0.043, logit=18.500)', '\" A\"[362] (p=0.034, logit=18.250)', '\" Only\"[8442] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     clean_track=OrderedDict([(18654, (1, PredictedToken(token=' Micro', prob=0.76953125, logit=21.375, token_id=18654, metadata=None))), (50159, (220, PredictedToken(token=' Sco', prob=7.808208465576172e-06, logit=9.875, token_id=50159, metadata=None))), (16730, (511, PredictedToken(token=' Museum', prob=1.6391277313232422e-06, logit=8.3125, token_id=16730, metadata=None))), (38673, (629, PredictedToken(token=' Yoga', prob=1.1622905731201172e-06, logit=7.96875, token_id=38673, metadata=None))), (94091, (1325, PredictedToken(token=' Tomato', prob=3.762543201446533e-07, logit=6.84375, token_id=94091, metadata=None))), (89077, (1593, PredictedToken(token=' Strawberry', prob=2.849847078323364e-07, logit=6.5625, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.812, logit=21.125)', '\" The\"[578] (p=0.046, logit=18.250)', '\" A\"[362] (p=0.028, logit=17.750)', '\" Among\"[22395] (p=0.017, logit=17.250)', '\" None\"[2290] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.8125, logit=21.125, token_id=16730, metadata=None))), (18654, (7, PredictedToken(token=' Micro', prob=0.0054931640625, logit=16.125, token_id=18654, metadata=None))), (38673, (63, PredictedToken(token=' Yoga', prob=0.00011396408081054688, logit=12.25, token_id=38673, metadata=None))), (94091, (502, PredictedToken(token=' Tomato', prob=2.2202730178833008e-06, logit=8.3125, token_id=94091, metadata=None))), (50159, (820, PredictedToken(token=' Sco', prob=1.080334186553955e-06, logit=7.59375, token_id=50159, metadata=None))), (89077, (2095, PredictedToken(token=' Strawberry', prob=2.998858690261841e-07, logit=6.3125, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:03 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:52:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.891, logit=22.125)', '\" A\"[362] (p=0.044, logit=19.125)', '\" The\"[578] (p=0.034, logit=18.875)', '\" Among\"[22395] (p=0.009, logit=17.500)', '\" MOS\"[74174] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     clean_prediction=['\" Calculator\"[37128] (p=0.566, logit=19.375)', '\" A\"[362] (p=0.126, logit=17.875)', '\" The\"[578] (p=0.111, logit=17.750)', '\" Among\"[22395] (p=0.053, logit=17.000)', '\" It\"[1102] (p=0.012, logit=15.500)']\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     clean_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.56640625, logit=19.375, token_id=37128, metadata=None))), (68027, (33, PredictedToken(token=' Sax', prob=0.00109100341796875, logit=13.125, token_id=68027, metadata=None))), (44570, (42, PredictedToken(token=' Maple', prob=0.00080108642578125, logit=12.8125, token_id=44570, metadata=None))), (66821, (82, PredictedToken(token=' Iris', prob=0.00018978118896484375, logit=11.375, token_id=66821, metadata=None))), (79189, (265, PredictedToken(token=' Elephant', prob=2.1338462829589844e-05, logit=9.1875, token_id=79189, metadata=None))), (16730, (316, PredictedToken(token=' Museum', prob=1.5616416931152344e-05, logit=8.875, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.424, logit=19.375)', '\" Museum\"[16730] (p=0.258, logit=18.875)', '\" Among\"[22395] (p=0.065, logit=17.500)', '\" The\"[578] (p=0.051, logit=17.250)', '\" Elephant\"[79189] (p=0.040, logit=17.000)']\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.423828125, logit=19.375, token_id=66821, metadata=None))), (16730, (2, PredictedToken(token=' Museum', prob=0.2578125, logit=18.875, token_id=16730, metadata=None))), (79189, (5, PredictedToken(token=' Elephant', prob=0.03955078125, logit=17.0, token_id=79189, metadata=None))), (44570, (8, PredictedToken(token=' Maple', prob=0.0087890625, logit=15.5, token_id=44570, metadata=None))), (68027, (2526, PredictedToken(token=' Sax', prob=6.183981895446777e-07, logit=5.9375, token_id=68027, metadata=None))), (37128, (3112, PredictedToken(token=' Calculator', prob=4.5262277126312256e-07, logit=5.625, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:04 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.887, logit=21.750)', '\" The\"[578] (p=0.044, logit=18.750)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" A\"[362] (p=0.007, logit=16.875)', '\" Option\"[7104] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:52:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.855, logit=22.125)', '\" The\"[578] (p=0.070, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=19.000)', '\" A\"[362] (p=0.005, logit=17.000)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.85546875, logit=22.125, token_id=47643, metadata=None))), (18787, (79, PredictedToken(token=' Oak', prob=2.849102020263672e-05, logit=11.8125, token_id=18787, metadata=None))), (5340, (111, PredictedToken(token=' Har', prob=1.519918441772461e-05, logit=11.1875, token_id=5340, metadata=None))), (27171, (450, PredictedToken(token=' Coffee', prob=1.1771917343139648e-06, logit=8.625, token_id=27171, metadata=None))), (88668, (595, PredictedToken(token=' Blender', prob=8.083879947662354e-07, logit=8.25, token_id=88668, metadata=None))), (91782, (1635, PredictedToken(token=' Shorts', prob=1.7974525690078735e-07, logit=6.75, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.660, logit=21.250)', '\" The\"[578] (p=0.101, logit=19.375)', '\" Cel\"[47643] (p=0.089, logit=19.250)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" A\"[362] (p=0.016, logit=17.500)']\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.66015625, logit=21.25, token_id=5340, metadata=None))), (47643, (3, PredictedToken(token=' Cel', prob=0.08935546875, logit=19.25, token_id=47643, metadata=None))), (18787, (7, PredictedToken(token=' Oak', prob=0.013671875, logit=17.375, token_id=18787, metadata=None))), (27171, (749, PredictedToken(token=' Coffee', prob=9.313225746154785e-07, logit=7.78125, token_id=27171, metadata=None))), (91782, (1488, PredictedToken(token=' Shorts', prob=3.427267074584961e-07, logit=6.78125, token_id=91782, metadata=None))), (88668, (2128, PredictedToken(token=' Blender', prob=2.0116567611694336e-07, logit=6.25, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:05 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:05 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     patch_prediction=['\" Fl\"[3061] (p=0.797, logit=22.375)', '\" The\"[578] (p=0.122, logit=20.500)', '\" A\"[362] (p=0.027, logit=19.000)', '\" Among\"[22395] (p=0.015, logit=18.375)', '\" It\"[1102] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.848, logit=21.500)', '\" The\"[578] (p=0.042, logit=18.500)', '\" Among\"[22395] (p=0.029, logit=18.125)', '\" Ski\"[61595] (p=0.023, logit=17.875)', '\" (\"[320] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.84765625, logit=21.5, token_id=4923, metadata=None))), (47759, (28, PredictedToken(token=' Guitar', prob=0.00038909912109375, logit=13.8125, token_id=47759, metadata=None))), (16344, (61, PredictedToken(token=' Rose', prob=8.678436279296875e-05, logit=12.3125, token_id=16344, metadata=None)))])\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.543, logit=20.750)', '\" Guitar\"[47759] (p=0.289, logit=20.125)', '\" The\"[578] (p=0.044, logit=18.250)', '\" A\"[362] (p=0.024, logit=17.625)', '\" (\"[320] (p=0.016, logit=17.250)']\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.54296875, logit=20.75, token_id=16344, metadata=None))), (47759, (2, PredictedToken(token=' Guitar', prob=0.2890625, logit=20.125, token_id=47759, metadata=None))), (4923, (18, PredictedToken(token=' Sk', prob=0.00125885009765625, logit=14.6875, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:05 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:05 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:52:05 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     patch_prediction=['\" Marker\"[40975] (p=0.801, logit=22.125)', '\" The\"[578] (p=0.065, logit=19.625)', '\" A\"[362] (p=0.065, logit=19.625)', '\" Among\"[22395] (p=0.035, logit=19.000)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.777, logit=20.375)', '\" Among\"[22395] (p=0.056, logit=17.750)', '\" The\"[578] (p=0.050, logit=17.625)', '\" A\"[362] (p=0.024, logit=16.875)', '\" lotion\"[87942] (p=0.013, logit=16.250)']\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.77734375, logit=20.375, token_id=445, metadata=None))), (57094, (10, PredictedToken(token=' Highlight', prob=0.004638671875, logit=15.25, token_id=57094, metadata=None))), (1901, (40, PredictedToken(token=' Z', prob=0.00040435791015625, logit=12.8125, token_id=1901, metadata=None))), (81501, (41, PredictedToken(token=' Pendant', prob=0.00040435791015625, logit=12.8125, token_id=81501, metadata=None)))])\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.906, logit=21.875)', '\" Among\"[22395] (p=0.021, logit=18.125)', '\" The\"[578] (p=0.021, logit=18.125)', '\" A\"[362] (p=0.019, logit=18.000)', '\" L\"[445] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.90625, logit=21.875, token_id=57094, metadata=None))), (445, (5, PredictedToken(token=' L', prob=0.0037078857421875, logit=16.375, token_id=445, metadata=None))), (1901, (15, PredictedToken(token=' Z', prob=0.00099945068359375, logit=15.0625, token_id=1901, metadata=None))), (81501, (52, PredictedToken(token=' Pendant', prob=9.298324584960938e-05, logit=12.6875, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:06 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:06 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.898, logit=22.875)', '\" The\"[578] (p=0.039, logit=19.750)', '\" A\"[362] (p=0.027, logit=19.375)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" (\"[320] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:52:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.922, logit=22.875)', '\" The\"[578] (p=0.025, logit=19.250)', '\" A\"[362] (p=0.019, logit=19.000)', '\" laptop\"[21288] (p=0.009, logit=18.250)', '\" Among\"[22395] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.921875, logit=22.875, token_id=57225, metadata=None))), (82994, (72, PredictedToken(token=' Toilet', prob=1.2755393981933594e-05, logit=11.6875, token_id=82994, metadata=None))), (29318, (491, PredictedToken(token=' Dress', prob=4.0978193283081055e-07, logit=8.25, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.797, logit=21.625)', '\" The\"[578] (p=0.074, logit=19.250)', '\" Laptop\"[57225] (p=0.035, logit=18.500)', '\" A\"[362] (p=0.027, logit=18.250)', '\" toilet\"[27306] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.796875, logit=21.625, token_id=82994, metadata=None))), (57225, (3, PredictedToken(token=' Laptop', prob=0.03515625, logit=18.5, token_id=57225, metadata=None))), (29318, (57, PredictedToken(token=' Dress', prob=9.822845458984375e-05, logit=12.625, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:07 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:07 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.844, logit=23.000)', '\" The\"[578] (p=0.078, logit=20.625)', '\" A\"[362] (p=0.033, logit=19.750)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" cat\"[8415] (p=0.008, logit=18.375)']\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     clean_prediction=['\" Ti\"[23126] (p=0.840, logit=22.250)', '\" The\"[578] (p=0.061, logit=19.625)', '\" A\"[362] (p=0.037, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=18.625)', '\" (\"[320] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     clean_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.83984375, logit=22.25, token_id=23126, metadata=None))), (96096, (18, PredictedToken(token=' Dolphin', prob=0.000560760498046875, logit=14.9375, token_id=96096, metadata=None))), (9441, (242, PredictedToken(token=' Church', prob=2.950429916381836e-06, logit=9.6875, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.914, logit=22.250)', '\" The\"[578] (p=0.031, logit=18.875)', '\" A\"[362] (p=0.017, logit=18.250)', '\" dolphin\"[99269] (p=0.008, logit=17.500)', '\" Among\"[22395] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.9140625, logit=22.25, token_id=96096, metadata=None))), (9441, (25, PredictedToken(token=' Church', prob=0.00021076202392578125, logit=13.875, token_id=9441, metadata=None))), (23126, (194, PredictedToken(token=' Ti', prob=3.6209821701049805e-06, logit=9.8125, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:07 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:07 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:52:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.629, logit=20.750)', '\" Among\"[22395] (p=0.096, logit=18.875)', '\" The\"[578] (p=0.096, logit=18.875)', '\" An\"[1556] (p=0.096, logit=18.875)', '\" It\"[1102] (p=0.015, logit=17.000)']\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.586, logit=21.500)', '\" The\"[578] (p=0.148, logit=20.125)', '\" A\"[362] (p=0.148, logit=20.125)', '\" Among\"[22395] (p=0.070, logit=19.375)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.5859375, logit=21.5, token_id=34785, metadata=None))), (27738, (10, PredictedToken(token=' Ward', prob=0.0023956298828125, logit=16.0, token_id=27738, metadata=None))), (39247, (41, PredictedToken(token=' Slow', prob=0.00022220611572265625, logit=13.625, token_id=39247, metadata=None))), (57094, (58, PredictedToken(token=' Highlight', prob=0.00011205673217773438, logit=12.9375, token_id=57094, metadata=None))), (79189, (78, PredictedToken(token=' Elephant', prob=4.38690185546875e-05, logit=12.0, token_id=79189, metadata=None))), (74574, (1281, PredictedToken(token=' Violet', prob=3.4458935260772705e-07, logit=7.15625, token_id=74574, metadata=None)))])\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.699, logit=21.250)', '\" The\"[578] (p=0.138, logit=19.625)', '\" A\"[362] (p=0.065, logit=18.875)', '\" Among\"[22395] (p=0.045, logit=18.500)', '\" Ward\"[27738] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.69921875, logit=21.25, token_id=57094, metadata=None))), (27738, (5, PredictedToken(token=' Ward', prob=0.01275634765625, logit=17.25, token_id=27738, metadata=None))), (39247, (18, PredictedToken(token=' Slow', prob=0.0008697509765625, logit=14.5625, token_id=39247, metadata=None))), (74574, (63, PredictedToken(token=' Violet', prob=9.1552734375e-05, logit=12.3125, token_id=74574, metadata=None))), (34785, (116, PredictedToken(token=' Truck', prob=2.3126602172851562e-05, logit=10.9375, token_id=34785, metadata=None))), (79189, (351, PredictedToken(token=' Elephant', prob=3.129243850708008e-06, logit=8.9375, token_id=79189, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:08 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:08 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.902, logit=22.750)', '\" The\"[578] (p=0.031, logit=19.375)', '\" A\"[362] (p=0.021, logit=19.000)', '\" Among\"[22395] (p=0.019, logit=18.875)', '\" It\"[1102] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:52:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     clean_prediction=['\" Carn\"[32749] (p=0.887, logit=22.500)', '\" The\"[578] (p=0.050, logit=19.625)', '\" A\"[362] (p=0.030, logit=19.125)', '\" Among\"[22395] (p=0.013, logit=18.250)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     clean_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.88671875, logit=22.5, token_id=32749, metadata=None))), (11683, (62, PredictedToken(token=' Acc', prob=2.288818359375e-05, logit=11.9375, token_id=11683, metadata=None))), (81501, (397, PredictedToken(token=' Pendant', prob=8.344650268554688e-07, logit=8.625, token_id=81501, metadata=None))), (50159, (501, PredictedToken(token=' Sco', prob=6.109476089477539e-07, logit=8.3125, token_id=50159, metadata=None))), (26698, (1731, PredictedToken(token=' Keyboard', prob=1.0291114449501038e-07, logit=6.53125, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.820, logit=21.375)', '\" Pendant\"[81501] (p=0.060, logit=18.750)', '\" The\"[578] (p=0.041, logit=18.375)', '\" A\"[362] (p=0.032, logit=18.125)', '\" Among\"[22395] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.8203125, logit=21.375, token_id=50159, metadata=None))), (81501, (2, PredictedToken(token=' Pendant', prob=0.0595703125, logit=18.75, token_id=81501, metadata=None))), (11683, (6, PredictedToken(token=' Acc', prob=0.0048828125, logit=16.25, token_id=11683, metadata=None))), (32749, (31, PredictedToken(token=' Carn', prob=0.0001888275146484375, logit=13.0, token_id=32749, metadata=None))), (26698, (107, PredictedToken(token=' Keyboard', prob=1.7642974853515625e-05, logit=10.625, token_id=26698, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:09 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:09 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.789, logit=20.875)', '\" The\"[578] (p=0.073, logit=18.500)', '\" Among\"[22395] (p=0.031, logit=17.625)', '\" A\"[362] (p=0.021, logit=17.250)', '\" lavender\"[81460] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.828, logit=21.250)', '\" The\"[578] (p=0.060, logit=18.625)', '\" A\"[362] (p=0.036, logit=18.125)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" It\"[1102] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.828125, logit=21.25, token_id=91263, metadata=None))), (86460, (11, PredictedToken(token=' Necklace', prob=0.00141143798828125, logit=14.875, token_id=86460, metadata=None))), (52882, (24, PredictedToken(token=' Pepper', prob=0.00070953369140625, logit=14.1875, token_id=52882, metadata=None))), (48390, (518, PredictedToken(token=' Lily', prob=2.250075340270996e-06, logit=8.4375, token_id=48390, metadata=None)))])\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     int_prediction=['\" Lily\"[48390] (p=0.766, logit=20.750)', '\" The\"[578] (p=0.063, logit=18.250)', '\" Pepper\"[52882] (p=0.038, logit=17.750)', '\" Among\"[22395] (p=0.034, logit=17.625)', '\" A\"[362] (p=0.018, logit=17.000)']\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     int_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.765625, logit=20.75, token_id=48390, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.0380859375, logit=17.75, token_id=52882, metadata=None))), (86460, (36, PredictedToken(token=' Necklace', prob=0.0003509521484375, logit=13.0625, token_id=86460, metadata=None))), (91263, (248, PredictedToken(token=' Binder', prob=9.953975677490234e-06, logit=9.5, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:09 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:52:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     patch_prediction=['\" Scar\"[30760] (p=0.447, logit=20.500)', '\" The\"[578] (p=0.187, logit=19.625)', '\" Among\"[22395] (p=0.145, logit=19.375)', '\" A\"[362] (p=0.145, logit=19.375)', '\" Out\"[4470] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     clean_prediction=['\" Oak\"[18787] (p=0.852, logit=22.250)', '\" The\"[578] (p=0.054, logit=19.500)', '\" Among\"[22395] (p=0.033, logit=19.000)', '\" An\"[1556] (p=0.023, logit=18.625)', '\" Option\"[7104] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     clean_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.8515625, logit=22.25, token_id=18787, metadata=None))), (57915, (14, PredictedToken(token=' Ank', prob=0.000728607177734375, logit=15.1875, token_id=57915, metadata=None))), (328, (68, PredictedToken(token=' S', prob=3.409385681152344e-05, logit=12.125, token_id=328, metadata=None))), (65197, (449, PredictedToken(token=' Surf', prob=1.0281801223754883e-06, logit=8.625, token_id=65197, metadata=None))), (37128, (3833, PredictedToken(token=' Calculator', prob=5.448237061500549e-08, logit=5.6875, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.848, logit=22.000)', '\" The\"[578] (p=0.054, logit=19.250)', '\" Ank\"[57915] (p=0.037, logit=18.875)', '\" Among\"[22395] (p=0.014, logit=17.875)', '\" Option\"[7104] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.84765625, logit=22.0, token_id=328, metadata=None))), (57915, (3, PredictedToken(token=' Ank', prob=0.037353515625, logit=18.875, token_id=57915, metadata=None))), (18787, (11, PredictedToken(token=' Oak', prob=0.0014495849609375, logit=15.625, token_id=18787, metadata=None))), (65197, (144, PredictedToken(token=' Surf', prob=8.106231689453125e-06, logit=10.4375, token_id=65197, metadata=None))), (37128, (6323, PredictedToken(token=' Calculator', prob=2.735760062932968e-08, logit=4.75, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:10 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:52:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.859, logit=21.500)', '\" An\"[1556] (p=0.029, logit=18.125)', '\" The\"[578] (p=0.029, logit=18.125)', '\" Among\"[22395] (p=0.012, logit=17.250)', '\" (\"[320] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.711, logit=20.875)', '\" The\"[578] (p=0.075, logit=18.625)', '\" Mixer\"[72392] (p=0.058, logit=18.375)', '\" A\"[362] (p=0.031, logit=17.750)', '\" (\"[320] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.7109375, logit=20.875, token_id=26698, metadata=None))), (72392, (3, PredictedToken(token=' Mixer', prob=0.058349609375, logit=18.375, token_id=72392, metadata=None))), (6031, (20, PredictedToken(token=' Bro', prob=0.001007080078125, logit=14.3125, token_id=6031, metadata=None)))])\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.871, logit=22.250)', '\" Keyboard\"[26698] (p=0.056, logit=19.500)', '\" The\"[578] (p=0.023, logit=18.625)', '\" A\"[362] (p=0.010, logit=17.750)', '\" (\"[320] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.87109375, logit=22.25, token_id=72392, metadata=None))), (26698, (2, PredictedToken(token=' Keyboard', prob=0.0556640625, logit=19.5, token_id=26698, metadata=None))), (6031, (6, PredictedToken(token=' Bro', prob=0.005859375, logit=17.25, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:11 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:11 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     patch_prediction=['\" Sco\"[50159] (p=0.703, logit=21.500)', '\" A\"[362] (p=0.122, logit=19.750)', '\" The\"[578] (p=0.095, logit=19.500)', '\" Among\"[22395] (p=0.035, logit=18.500)', '\" (\"[320] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.871, logit=22.375)', '\" b\"[293] (p=0.043, logit=19.375)', '\" The\"[578] (p=0.030, logit=19.000)', '\" A\"[362] (p=0.012, logit=18.125)', '\" Among\"[22395] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.87109375, logit=22.375, token_id=426, metadata=None))), (18787, (10, PredictedToken(token=' Oak', prob=0.00148773193359375, logit=16.0, token_id=18787, metadata=None))), (3341, (30, PredictedToken(token=' Car', prob=0.0001773834228515625, logit=13.875, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.867, logit=22.000)', '\" The\"[578] (p=0.026, logit=18.500)', '\" A\"[362] (p=0.016, logit=18.000)', '\" (\"[320] (p=0.016, logit=18.000)', '\" car\"[1841] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.8671875, logit=22.0, token_id=3341, metadata=None))), (18787, (7, PredictedToken(token=' Oak', prob=0.006622314453125, logit=17.125, token_id=18787, metadata=None))), (426, (8, PredictedToken(token=' B', prob=0.005859375, logit=17.0, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:11 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:52:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.727, logit=21.250)', '\" None\"[2290] (p=0.162, logit=19.750)', '\" A\"[362] (p=0.032, logit=18.125)', '\" There\"[2684] (p=0.015, logit=17.375)', '\" The\"[578] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     clean_prediction=['\" Re\"[1050] (p=0.738, logit=21.875)', '\" The\"[578] (p=0.088, logit=19.750)', '\" A\"[362] (p=0.068, logit=19.500)', '\" Among\"[22395] (p=0.047, logit=19.125)', '\" (\"[320] (p=0.013, logit=17.875)']\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     clean_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.73828125, logit=21.875, token_id=1050, metadata=None))), (55405, (28, PredictedToken(token=' Orch', prob=0.000522613525390625, logit=14.625, token_id=55405, metadata=None))), (10573, (55, PredictedToken(token=' Watch', prob=9.107589721679688e-05, logit=12.875, token_id=10573, metadata=None))), (40759, (62, PredictedToken(token=' Harmon', prob=7.05718994140625e-05, logit=12.625, token_id=40759, metadata=None)))])\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.582, logit=21.125)', '\" Watch\"[10573] (p=0.167, logit=19.875)', '\" The\"[578] (p=0.089, logit=19.250)', '\" Among\"[22395] (p=0.033, logit=18.250)', '\" (\"[320] (p=0.026, logit=18.000)']\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.58203125, logit=21.125, token_id=40759, metadata=None))), (10573, (2, PredictedToken(token=' Watch', prob=0.1669921875, logit=19.875, token_id=10573, metadata=None))), (55405, (6, PredictedToken(token=' Orch', prob=0.0198974609375, logit=17.75, token_id=55405, metadata=None))), (1050, (108, PredictedToken(token=' Re', prob=3.838539123535156e-05, logit=11.5, token_id=1050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:12 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:52:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.629, logit=20.875)', '\" The\"[578] (p=0.141, logit=19.375)', '\" A\"[362] (p=0.109, logit=19.125)', '\" Among\"[22395] (p=0.035, logit=18.000)', '\" Sco\"[50159] (p=0.031, logit=17.875)']\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     clean_prediction=['\" Orange\"[22725] (p=0.836, logit=22.375)', '\" The\"[578] (p=0.053, logit=19.625)', '\" An\"[1556] (p=0.047, logit=19.500)', '\" Among\"[22395] (p=0.029, logit=19.000)', '\" orange\"[19087] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     clean_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.8359375, logit=22.375, token_id=22725, metadata=None))), (84008, (91, PredictedToken(token=' Sheep', prob=2.0384788513183594e-05, logit=11.75, token_id=84008, metadata=None))), (38258, (97, PredictedToken(token=' Baseball', prob=1.7881393432617188e-05, logit=11.625, token_id=38258, metadata=None))), (12369, (160, PredictedToken(token=' Food', prob=6.198883056640625e-06, logit=10.5625, token_id=12369, metadata=None))), (16730, (841, PredictedToken(token=' Museum', prob=3.725290298461914e-07, logit=7.75, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     int_prediction=['\" Baseball\"[38258] (p=0.789, logit=21.500)', '\" The\"[578] (p=0.083, logit=19.250)', '\" Among\"[22395] (p=0.065, logit=19.000)', '\" A\"[362] (p=0.008, logit=16.875)', '\" Base\"[5464] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     int_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.7890625, logit=21.5, token_id=38258, metadata=None))), (84008, (17, PredictedToken(token=' Sheep', prob=0.001190185546875, logit=15.0, token_id=84008, metadata=None))), (22725, (26, PredictedToken(token=' Orange', prob=0.000598907470703125, logit=14.3125, token_id=22725, metadata=None))), (16730, (52, PredictedToken(token=' Museum', prob=0.00011777877807617188, logit=12.6875, token_id=16730, metadata=None))), (12369, (112, PredictedToken(token=' Food', prob=2.467632293701172e-05, logit=11.125, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:13 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:13 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.770, logit=22.000)', '\" The\"[578] (p=0.081, logit=19.750)', '\" A\"[362] (p=0.056, logit=19.375)', '\" Among\"[22395] (p=0.049, logit=19.250)', '\" \"[220] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     clean_prediction=['\" Sub\"[3804] (p=0.754, logit=21.500)', '\" A\"[362] (p=0.090, logit=19.375)', '\" The\"[578] (p=0.062, logit=19.000)', '\" Among\"[22395] (p=0.048, logit=18.750)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     clean_track=OrderedDict([(3804, (1, PredictedToken(token=' Sub', prob=0.75390625, logit=21.5, token_id=3804, metadata=None))), (96096, (20, PredictedToken(token=' Dolphin', prob=0.000827789306640625, logit=14.6875, token_id=96096, metadata=None))), (1443, (26, PredictedToken(token=' Sh', prob=0.000415802001953125, logit=14.0, token_id=1443, metadata=None))), (58586, (59, PredictedToken(token=' Tape', prob=9.298324584960938e-05, logit=12.5, token_id=58586, metadata=None))), (6150, (85, PredictedToken(token=' School', prob=4.673004150390625e-05, logit=11.8125, token_id=6150, metadata=None))), (55870, (98, PredictedToken(token=' Jacket', prob=3.218650817871094e-05, logit=11.4375, token_id=55870, metadata=None)))])\n",
      "2025-09-16 09:52:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.723, logit=21.000)', '\" A\"[362] (p=0.098, logit=19.000)', '\" The\"[578] (p=0.041, logit=18.125)', '\" Jacket\"[55870] (p=0.032, logit=17.875)', '\" School\"[6150] (p=0.019, logit=17.375)']\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.72265625, logit=21.0, token_id=96096, metadata=None))), (55870, (4, PredictedToken(token=' Jacket', prob=0.03173828125, logit=17.875, token_id=55870, metadata=None))), (6150, (5, PredictedToken(token=' School', prob=0.019287109375, logit=17.375, token_id=6150, metadata=None))), (58586, (8, PredictedToken(token=' Tape', prob=0.006256103515625, logit=16.25, token_id=58586, metadata=None))), (1443, (28, PredictedToken(token=' Sh', prob=0.00061798095703125, logit=13.9375, token_id=1443, metadata=None))), (3804, (32, PredictedToken(token=' Sub', prob=0.0004253387451171875, logit=13.5625, token_id=3804, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:14 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:14 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.949, logit=23.750)', '\" The\"[578] (p=0.020, logit=19.875)', '\" A\"[362] (p=0.017, logit=19.750)', '\" Among\"[22395] (p=0.004, logit=18.375)', '\" motorcycle\"[35404] (p=0.001, logit=17.250)']\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     clean_prediction=['\" Cat\"[17810] (p=0.809, logit=22.625)', '\" The\"[578] (p=0.096, logit=20.500)', '\" A\"[362] (p=0.031, logit=19.375)', '\" Among\"[22395] (p=0.021, logit=19.000)', '\" cat\"[8415] (p=0.013, logit=18.500)']\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     clean_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.80859375, logit=22.625, token_id=17810, metadata=None))), (13000, (40, PredictedToken(token=' Van', prob=8.7738037109375e-05, logit=13.5, token_id=13000, metadata=None))), (3420, (60, PredictedToken(token=' Trump', prob=3.910064697265625e-05, logit=12.6875, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.891, logit=22.625)', '\" The\"[578] (p=0.050, logit=19.750)', '\" Trump\"[3420] (p=0.014, logit=18.500)', '\" Among\"[22395] (p=0.010, logit=18.125)', '\" A\"[362] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.890625, logit=22.625, token_id=13000, metadata=None))), (3420, (3, PredictedToken(token=' Trump', prob=0.014404296875, logit=18.5, token_id=3420, metadata=None))), (17810, (30, PredictedToken(token=' Cat', prob=0.0001811981201171875, logit=14.125, token_id=17810, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:14 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:14 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:52:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.734, logit=20.875)', '\" The\"[578] (p=0.077, logit=18.625)', '\" A\"[362] (p=0.060, logit=18.375)', '\" Among\"[22395] (p=0.028, logit=17.625)', '\" Option\"[7104] (p=0.022, logit=17.375)']\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.852, logit=21.125)', '\" A\"[362] (p=0.048, logit=18.250)', '\" The\"[578] (p=0.042, logit=18.125)', '\" Among\"[22395] (p=0.016, logit=17.125)', '\" R\"[432] (p=0.005, logit=16.000)']\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.8515625, logit=21.125, token_id=74968, metadata=None))), (328, (43, PredictedToken(token=' S', prob=0.00012683868408203125, logit=12.3125, token_id=328, metadata=None))), (87213, (72, PredictedToken(token=' Oven', prob=6.008148193359375e-05, logit=11.5625, token_id=87213, metadata=None))), (50159, (134, PredictedToken(token=' Sco', prob=1.9431114196777344e-05, logit=10.4375, token_id=50159, metadata=None))), (5250, (452, PredictedToken(token=' Pe', prob=2.3245811462402344e-06, logit=8.3125, token_id=5250, metadata=None))), (72683, (1429, PredictedToken(token=' Boxing', prob=5.699694156646729e-07, logit=6.90625, token_id=72683, metadata=None)))])\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.828, logit=20.750)', '\" Boxing\"[72683] (p=0.060, logit=18.125)', '\" The\"[578] (p=0.028, logit=17.375)', '\" S\"[328] (p=0.017, logit=16.875)', '\" Among\"[22395] (p=0.015, logit=16.750)']\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.828125, logit=20.75, token_id=50159, metadata=None))), (72683, (2, PredictedToken(token=' Boxing', prob=0.06005859375, logit=18.125, token_id=72683, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.0172119140625, logit=16.875, token_id=328, metadata=None))), (74968, (7, PredictedToken(token=' Razor', prob=0.0052490234375, logit=15.6875, token_id=74968, metadata=None))), (87213, (11, PredictedToken(token=' Oven', prob=0.00141143798828125, logit=14.375, token_id=87213, metadata=None))), (5250, (17, PredictedToken(token=' Pe', prob=0.0008544921875, logit=13.875, token_id=5250, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:15 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     patch_prediction=['\" Let\"[6914] (p=0.832, logit=21.500)', '\" The\"[578] (p=0.088, logit=19.250)', '\" Among\"[22395] (p=0.022, logit=17.875)', '\" A\"[362] (p=0.015, logit=17.500)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:52:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.809, logit=22.500)', '\" The\"[578] (p=0.085, logit=20.250)', '\" Among\"[22395] (p=0.059, logit=19.875)', '\" A\"[362] (p=0.028, logit=19.125)', '\" jacket\"[27300] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.80859375, logit=22.5, token_id=55870, metadata=None))), (423, (12, PredictedToken(token=' D', prob=0.00057220458984375, logit=15.25, token_id=423, metadata=None))), (29625, (31, PredictedToken(token=' Chain', prob=0.00017452239990234375, logit=14.0625, token_id=29625, metadata=None))), (52882, (32, PredictedToken(token=' Pepper', prob=0.000164031982421875, logit=14.0, token_id=52882, metadata=None))), (94467, (54, PredictedToken(token=' Trom', prob=4.7206878662109375e-05, logit=12.75, token_id=94467, metadata=None)))])\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.695, logit=21.750)', '\" The\"[578] (p=0.137, logit=20.125)', '\" Among\"[22395] (p=0.106, logit=19.875)', '\" A\"[362] (p=0.016, logit=18.000)', '\" D\"[423] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.6953125, logit=21.75, token_id=52882, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.007720947265625, logit=17.25, token_id=423, metadata=None))), (29625, (12, PredictedToken(token=' Chain', prob=0.00118255615234375, logit=15.375, token_id=29625, metadata=None))), (94467, (19, PredictedToken(token=' Trom', prob=0.0007171630859375, logit=14.875, token_id=94467, metadata=None))), (55870, (21, PredictedToken(token=' Jacket', prob=0.000492095947265625, logit=14.5, token_id=55870, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:16 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     patch_prediction=['\" Grape\"[80629] (p=0.707, logit=20.750)', '\" The\"[578] (p=0.109, logit=18.875)', '\" Among\"[22395] (p=0.051, logit=18.125)', '\" A\"[362] (p=0.051, logit=18.125)', '\" GRA\"[65120] (p=0.013, logit=16.750)']\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.060, logit=19.500)', '\" A\"[362] (p=0.046, logit=19.250)', '\" Among\"[22395] (p=0.022, logit=18.500)', '\" z\"[1167] (p=0.012, logit=17.875)']\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.82421875, logit=22.125, token_id=1901, metadata=None))), (8325, (45, PredictedToken(token=' Apple', prob=8.96453857421875e-05, logit=13.0, token_id=8325, metadata=None))), (10573, (58, PredictedToken(token=' Watch', prob=6.151199340820312e-05, logit=12.625, token_id=10573, metadata=None))), (70110, (70, PredictedToken(token=' Ottoman', prob=4.506111145019531e-05, logit=12.3125, token_id=70110, metadata=None)))])\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.812, logit=21.000)', '\" The\"[578] (p=0.046, logit=18.125)', '\" Among\"[22395] (p=0.025, logit=17.500)', '\" An\"[1556] (p=0.019, logit=17.250)', '\" Watch\"[10573] (p=0.015, logit=17.000)']\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.8125, logit=21.0, token_id=8325, metadata=None))), (10573, (5, PredictedToken(token=' Watch', prob=0.014892578125, logit=17.0, token_id=10573, metadata=None))), (1901, (6, PredictedToken(token=' Z', prob=0.01025390625, logit=16.625, token_id=1901, metadata=None))), (70110, (23, PredictedToken(token=' Ottoman', prob=0.00130462646484375, logit=14.5625, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:16 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:52:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.773, logit=22.125)', '\" A\"[362] (p=0.082, logit=19.875)', '\" The\"[578] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.039, logit=19.125)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.066, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=18.625)', '\" A\"[362] (p=0.021, logit=18.000)', '\" Option\"[7104] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.8046875, logit=21.625, token_id=24423, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.00164794921875, logit=15.4375, token_id=356, metadata=None))), (469, (17, PredictedToken(token=' E', prob=0.00128173828125, logit=15.1875, token_id=469, metadata=None))), (48665, (104, PredictedToken(token=' Raspberry', prob=3.0159950256347656e-05, logit=11.4375, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.805, logit=21.875)', '\" The\"[578] (p=0.051, logit=19.125)', '\" An\"[1556] (p=0.040, logit=18.875)', '\" Among\"[22395] (p=0.024, logit=18.375)', '\" e\"[384] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.8046875, logit=21.875, token_id=469, metadata=None))), (48665, (6, PredictedToken(token=' Raspberry', prob=0.01470947265625, logit=17.875, token_id=48665, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.006134033203125, logit=17.0, token_id=24423, metadata=None))), (356, (19, PredictedToken(token=' C', prob=0.001068115234375, logit=15.25, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:17 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.766, logit=22.500)', '\" An\"[1556] (p=0.118, logit=20.625)', '\" The\"[578] (p=0.071, logit=20.125)', '\" Among\"[22395] (p=0.014, logit=18.500)', '\" (\"[320] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:52:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:18 src.selection.optimization INFO     clean_prediction=['\" Mall\"[32498] (p=0.801, logit=21.375)', '\" A\"[362] (p=0.051, logit=18.625)', '\" The\"[578] (p=0.045, logit=18.500)', '\" None\"[2290] (p=0.035, logit=18.250)', '\" Among\"[22395] (p=0.027, logit=18.000)']\n",
      "2025-09-16 09:52:18 src.selection.optimization INFO     clean_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.80078125, logit=21.375, token_id=32498, metadata=None))), (23126, (9, PredictedToken(token=' Ti', prob=0.0025482177734375, logit=15.625, token_id=23126, metadata=None))), (27217, (10, PredictedToken(token=' Train', prob=0.0025482177734375, logit=15.625, token_id=27217, metadata=None))), (10164, (75, PredictedToken(token=' Water', prob=4.9591064453125e-05, logit=11.6875, token_id=10164, metadata=None))), (49268, (280, PredictedToken(token=' Dish', prob=4.082918167114258e-06, logit=9.1875, token_id=49268, metadata=None)))])\n",
      "2025-09-16 09:52:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:18 src.selection.optimization INFO     int_prediction=['\" Dish\"[49268] (p=0.625, logit=20.750)', '\" Train\"[27217] (p=0.140, logit=19.250)', '\" A\"[362] (p=0.084, logit=18.750)', '\" None\"[2290] (p=0.058, logit=18.375)', '\" The\"[578] (p=0.045, logit=18.125)']\n",
      "2025-09-16 09:52:18 src.selection.optimization INFO     int_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.625, logit=20.75, token_id=49268, metadata=None))), (27217, (2, PredictedToken(token=' Train', prob=0.1396484375, logit=19.25, token_id=27217, metadata=None))), (23126, (8, PredictedToken(token=' Ti', prob=0.00225830078125, logit=15.125, token_id=23126, metadata=None))), (10164, (22, PredictedToken(token=' Water', prob=0.0007781982421875, logit=14.0625, token_id=10164, metadata=None))), (32498, (392, PredictedToken(token=' Mall', prob=3.606081008911133e-06, logit=8.6875, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:18 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:18 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:52:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.707, logit=22.375)', '\" The\"[578] (p=0.123, logit=20.625)', '\" A\"[362] (p=0.084, logit=20.250)', '\" Among\"[22395] (p=0.058, logit=19.875)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.656, logit=21.000)', '\" An\"[1556] (p=0.114, logit=19.250)', '\" The\"[578] (p=0.101, logit=19.125)', '\" Among\"[22395] (p=0.069, logit=18.750)', '\" It\"[1102] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.65625, logit=21.0, token_id=87213, metadata=None))), (11683, (77, PredictedToken(token=' Acc', prob=6.723403930664062e-05, logit=11.8125, token_id=11683, metadata=None))), (47589, (108, PredictedToken(token=' Basketball', prob=3.838539123535156e-05, logit=11.25, token_id=47589, metadata=None))), (74968, (221, PredictedToken(token=' Razor', prob=8.52346420288086e-06, logit=9.75, token_id=74968, metadata=None))), (36895, (522, PredictedToken(token=' Eagle', prob=2.16066837310791e-06, logit=8.375, token_id=36895, metadata=None))), (71264, (634, PredictedToken(token=' Daisy', prob=1.6838312149047852e-06, logit=8.125, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.871, logit=21.750)', '\" The\"[578] (p=0.038, logit=18.625)', '\" D\"[423] (p=0.030, logit=18.375)', '\" DA\"[25561] (p=0.011, logit=17.375)', '\" d\"[294] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.87109375, logit=21.75, token_id=71264, metadata=None))), (11683, (40, PredictedToken(token=' Acc', prob=0.00012969970703125, logit=12.9375, token_id=11683, metadata=None))), (47589, (396, PredictedToken(token=' Basketball', prob=1.9669532775878906e-06, logit=8.75, token_id=47589, metadata=None))), (87213, (449, PredictedToken(token=' Oven', prob=1.6316771507263184e-06, logit=8.5625, token_id=87213, metadata=None))), (36895, (753, PredictedToken(token=' Eagle', prob=8.23289155960083e-07, logit=7.875, token_id=36895, metadata=None))), (74968, (1126, PredictedToken(token=' Razor', prob=5.140900611877441e-07, logit=7.40625, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:19 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     patch_prediction=['\" Mirror\"[34954] (p=0.922, logit=21.625)', '\" The\"[578] (p=0.017, logit=17.625)', '\" Among\"[22395] (p=0.012, logit=17.250)', '\" A\"[362] (p=0.012, logit=17.250)', '\" It\"[1102] (p=0.003, logit=15.938)']\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.777, logit=21.875)', '\" The\"[578] (p=0.119, logit=20.000)', '\" Among\"[22395] (p=0.034, logit=18.750)', '\" A\"[362] (p=0.030, logit=18.625)', '\" (\"[320] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.77734375, logit=21.875, token_id=60413, metadata=None))), (2947, (113, PredictedToken(token=' Mar', prob=1.4662742614746094e-05, logit=11.0, token_id=2947, metadata=None))), (16488, (206, PredictedToken(token=' Bat', prob=5.066394805908203e-06, logit=9.9375, token_id=16488, metadata=None))), (37326, (373, PredictedToken(token=' Swe', prob=1.646578311920166e-06, logit=8.8125, token_id=37326, metadata=None)))])\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.633, logit=21.000)', '\" The\"[578] (p=0.125, logit=19.375)', '\" Among\"[22395] (p=0.076, logit=18.875)', '\" Bat\"[16488] (p=0.041, logit=18.250)', '\" A\"[362] (p=0.036, logit=18.125)']\n",
      "2025-09-16 09:52:19 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.6328125, logit=21.0, token_id=2947, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.04052734375, logit=18.25, token_id=16488, metadata=None))), (60413, (6, PredictedToken(token=' Uk', prob=0.02783203125, logit=17.875, token_id=60413, metadata=None))), (37326, (59, PredictedToken(token=' Swe', prob=0.00012874603271484375, logit=12.5, token_id=37326, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:19 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:20 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     patch_prediction=['\" Shower\"[48471] (p=0.719, logit=20.875)', '\" The\"[578] (p=0.086, logit=18.750)', '\" Among\"[22395] (p=0.067, logit=18.500)', '\" A\"[362] (p=0.041, logit=18.000)', '\" SH\"[6570] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.918, logit=23.375)', '\" The\"[578] (p=0.036, logit=20.125)', '\" A\"[362] (p=0.025, logit=19.750)', '\" Among\"[22395] (p=0.009, logit=18.750)', '\" Motor\"[18079] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.91796875, logit=23.375, token_id=70762, metadata=None))), (17367, (135, PredictedToken(token=' Factory', prob=3.427267074584961e-06, logit=10.875, token_id=17367, metadata=None))), (10164, (246, PredictedToken(token=' Water', prob=1.043081283569336e-06, logit=9.6875, token_id=10164, metadata=None))), (23262, (466, PredictedToken(token=' Comb', prob=3.390014171600342e-07, logit=8.5625, token_id=23262, metadata=None))), (68027, (636, PredictedToken(token=' Sax', prob=2.1886080503463745e-07, logit=8.125, token_id=68027, metadata=None))), (41785, (1608, PredictedToken(token=' Spin', prob=5.704350769519806e-08, logit=6.78125, token_id=41785, metadata=None)))])\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.766, logit=22.125)', '\" The\"[578] (p=0.081, logit=19.875)', '\" A\"[362] (p=0.071, logit=19.750)', '\" Motorcycle\"[70762] (p=0.026, logit=18.750)', '\" Among\"[22395] (p=0.020, logit=18.500)']\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.765625, logit=22.125, token_id=23262, metadata=None))), (70762, (4, PredictedToken(token=' Motorcycle', prob=0.026123046875, logit=18.75, token_id=70762, metadata=None))), (17367, (56, PredictedToken(token=' Factory', prob=8.344650268554688e-05, logit=13.0, token_id=17367, metadata=None))), (68027, (73, PredictedToken(token=' Sax', prob=4.744529724121094e-05, logit=12.4375, token_id=68027, metadata=None))), (10164, (122, PredictedToken(token=' Water', prob=1.537799835205078e-05, logit=11.3125, token_id=10164, metadata=None))), (41785, (134, PredictedToken(token=' Spin', prob=1.2755393981933594e-05, logit=11.125, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:20 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:20 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:52:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     patch_prediction=['\" Book\"[6017] (p=0.805, logit=22.000)', '\" The\"[578] (p=0.066, logit=19.500)', '\" A\"[362] (p=0.058, logit=19.375)', '\" Among\"[22395] (p=0.031, logit=18.750)', '\" C\"[356] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     clean_prediction=['\" Tiger\"[36845] (p=0.828, logit=22.125)', '\" The\"[578] (p=0.077, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=19.250)', '\" A\"[362] (p=0.019, logit=18.375)', '\" (\"[320] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     clean_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.828125, logit=22.125, token_id=36845, metadata=None))), (469, (35, PredictedToken(token=' E', prob=0.00012302398681640625, logit=13.3125, token_id=469, metadata=None))), (90538, (43, PredictedToken(token=' Caul', prob=9.584426879882812e-05, logit=13.0625, token_id=90538, metadata=None))), (1050, (59, PredictedToken(token=' Re', prob=4.5299530029296875e-05, logit=12.3125, token_id=1050, metadata=None))), (53889, (314, PredictedToken(token=' Apartment', prob=1.6540288925170898e-06, logit=9.0, token_id=53889, metadata=None))), (50159, (562, PredictedToken(token=' Sco', prob=6.891787052154541e-07, logit=8.125, token_id=50159, metadata=None)))])\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     int_prediction=['\" Re\"[1050] (p=0.766, logit=21.500)', '\" The\"[578] (p=0.091, logit=19.375)', '\" Among\"[22395] (p=0.043, logit=18.625)', '\" A\"[362] (p=0.034, logit=18.375)', '\" Apartment\"[53889] (p=0.011, logit=17.250)']\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     int_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.765625, logit=21.5, token_id=1050, metadata=None))), (53889, (5, PredictedToken(token=' Apartment', prob=0.01092529296875, logit=17.25, token_id=53889, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.00750732421875, logit=16.875, token_id=469, metadata=None))), (50159, (25, PredictedToken(token=' Sco', prob=0.000698089599609375, logit=14.5, token_id=50159, metadata=None))), (90538, (55, PredictedToken(token=' Caul', prob=0.00011396408081054688, logit=12.6875, token_id=90538, metadata=None))), (36845, (149, PredictedToken(token=' Tiger', prob=1.2040138244628906e-05, logit=10.4375, token_id=36845, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:21 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.770, logit=22.125)', '\" The\"[578] (p=0.104, logit=20.125)', '\" A\"[362] (p=0.043, logit=19.250)', '\" Among\"[22395] (p=0.034, logit=19.000)', '\" cat\"[8415] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.801, logit=21.375)', '\" The\"[578] (p=0.075, logit=19.000)', '\" Among\"[22395] (p=0.035, logit=18.250)', '\" A\"[362] (p=0.031, logit=18.125)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.80078125, logit=21.375, token_id=33578, metadata=None))), (33199, (12, PredictedToken(token=' Lion', prob=0.00186920166015625, logit=15.3125, token_id=33199, metadata=None))), (6031, (25, PredictedToken(token=' Bro', prob=0.0005340576171875, logit=14.0625, token_id=6031, metadata=None))), (65197, (158, PredictedToken(token=' Surf', prob=1.341104507446289e-05, logit=10.375, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:52:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     int_prediction=['\" Lion\"[33199] (p=0.777, logit=21.000)', '\" A\"[362] (p=0.093, logit=18.875)', '\" The\"[578] (p=0.056, logit=18.375)', '\" None\"[2290] (p=0.011, logit=16.750)', '\" Among\"[22395] (p=0.005, logit=16.000)']\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     int_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.77734375, logit=21.0, token_id=33199, metadata=None))), (65197, (12, PredictedToken(token=' Surf', prob=0.0026397705078125, logit=15.3125, token_id=65197, metadata=None))), (33578, (24, PredictedToken(token=' Palm', prob=0.00096893310546875, logit=14.3125, token_id=33578, metadata=None))), (6031, (37, PredictedToken(token=' Bro', prob=0.0003147125244140625, logit=13.1875, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:22 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:22 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     patch_prediction=['\" Brace\"[70306] (p=0.750, logit=21.750)', '\" The\"[578] (p=0.079, logit=19.500)', '\" A\"[362] (p=0.070, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.375)', '\" b\"[293] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.934, logit=22.875)', '\" Among\"[22395] (p=0.025, logit=19.250)', '\" The\"[578] (p=0.025, logit=19.250)', '\" None\"[2290] (p=0.002, logit=16.500)', '\" (\"[320] (p=0.001, logit=16.375)']\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.93359375, logit=22.875, token_id=47643, metadata=None))), (68867, (276, PredictedToken(token=' Coat', prob=1.5422701835632324e-06, logit=9.5625, token_id=68867, metadata=None))), (81501, (356, PredictedToken(token=' Pendant', prob=9.98377799987793e-07, logit=9.125, token_id=81501, metadata=None)))])\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     int_prediction=['\" Pendant\"[81501] (p=0.930, logit=22.250)', '\" The\"[578] (p=0.017, logit=18.250)', '\" A\"[362] (p=0.017, logit=18.250)', '\" Among\"[22395] (p=0.013, logit=18.000)', '\" None\"[2290] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     int_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.9296875, logit=22.25, token_id=81501, metadata=None))), (47643, (10, PredictedToken(token=' Cel', prob=0.00084686279296875, logit=15.25, token_id=47643, metadata=None))), (68867, (22, PredictedToken(token=' Coat', prob=0.0002574920654296875, logit=14.0625, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:22 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-16 09:52:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     patch_prediction=['\" Dolphin\"[96096] (p=0.875, logit=22.000)', '\" The\"[578] (p=0.049, logit=19.125)', '\" A\"[362] (p=0.026, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" dolphin\"[99269] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.828, logit=22.125)', '\" The\"[578] (p=0.068, logit=19.625)', '\" Among\"[22395] (p=0.060, logit=19.500)', '\" A\"[362] (p=0.013, logit=18.000)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.828125, logit=22.125, token_id=65449, metadata=None))), (6771, (30, PredictedToken(token=' Table', prob=0.0002307891845703125, logit=13.9375, token_id=6771, metadata=None))), (58586, (143, PredictedToken(token=' Tape', prob=8.940696716308594e-06, logit=10.6875, token_id=58586, metadata=None))), (49431, (351, PredictedToken(token=' Rabbit', prob=1.6540288925170898e-06, logit=9.0, token_id=49431, metadata=None))), (68554, (837, PredictedToken(token=' Gloves', prob=4.5821070671081543e-07, logit=7.71875, token_id=68554, metadata=None))), (68027, (1848, PredictedToken(token=' Sax', prob=1.5832483768463135e-07, logit=6.65625, token_id=68027, metadata=None)))])\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.387, logit=19.500)', '\" The\"[578] (p=0.235, logit=19.000)', '\" Rabbit\"[49431] (p=0.143, logit=18.500)', '\" Among\"[22395] (p=0.067, logit=17.750)', '\" A\"[362] (p=0.046, logit=17.375)']\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.38671875, logit=19.5, token_id=68027, metadata=None))), (49431, (3, PredictedToken(token=' Rabbit', prob=0.142578125, logit=18.5, token_id=49431, metadata=None))), (6771, (34, PredictedToken(token=' Table', prob=0.000797271728515625, logit=13.3125, token_id=6771, metadata=None))), (65449, (72, PredictedToken(token=' Willow', prob=0.00022792816162109375, logit=12.0625, token_id=65449, metadata=None))), (58586, (86, PredictedToken(token=' Tape', prob=0.0001468658447265625, logit=11.625, token_id=58586, metadata=None))), (68554, (87, PredictedToken(token=' Gloves', prob=0.0001468658447265625, logit=11.625, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:23 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:23 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.965, logit=22.500)', '\" The\"[578] (p=0.009, logit=17.875)', '\" A\"[362] (p=0.009, logit=17.875)', '\" (\"[320] (p=0.003, logit=16.875)', '\" Among\"[22395] (p=0.002, logit=16.500)']\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     clean_prediction=['\" Pe\"[5250] (p=0.707, logit=21.625)', '\" The\"[578] (p=0.140, logit=20.000)', '\" Among\"[22395] (p=0.066, logit=19.250)', '\" A\"[362] (p=0.027, logit=18.375)', '\" (\"[320] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     clean_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.70703125, logit=21.625, token_id=5250, metadata=None))), (23262, (24, PredictedToken(token=' Comb', prob=0.0004711151123046875, logit=14.3125, token_id=23262, metadata=None))), (53889, (206, PredictedToken(token=' Apartment', prob=7.152557373046875e-06, logit=10.125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:52:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.406, logit=20.625)', '\" Pe\"[5250] (p=0.247, logit=20.125)', '\" The\"[578] (p=0.132, logit=19.500)', '\" Among\"[22395] (p=0.091, logit=19.125)', '\" A\"[362] (p=0.043, logit=18.375)']\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.40625, logit=20.625, token_id=23262, metadata=None))), (5250, (2, PredictedToken(token=' Pe', prob=0.2470703125, logit=20.125, token_id=5250, metadata=None))), (53889, (7, PredictedToken(token=' Apartment', prob=0.0074462890625, logit=16.625, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:24 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:24 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.633, logit=21.375)', '\" The\"[578] (p=0.160, logit=20.000)', '\" Among\"[22395] (p=0.066, logit=19.125)', '\" A\"[362] (p=0.066, logit=19.125)', '\" (\"[320] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     clean_prediction=['\" Drum\"[46506] (p=0.828, logit=21.625)', '\" The\"[578] (p=0.068, logit=19.125)', '\" A\"[362] (p=0.032, logit=18.375)', '\" Z\"[1901] (p=0.012, logit=17.375)', '\" Among\"[22395] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     clean_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.828125, logit=21.625, token_id=46506, metadata=None))), (1901, (4, PredictedToken(token=' Z', prob=0.0118408203125, logit=17.375, token_id=1901, metadata=None))), (87035, (169, PredictedToken(token=' Onion', prob=8.940696716308594e-06, logit=10.1875, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.396, logit=20.125)', '\" Z\"[1901] (p=0.350, logit=20.000)', '\" Drum\"[46506] (p=0.088, logit=18.625)', '\" The\"[578] (p=0.061, logit=18.250)', '\" A\"[362] (p=0.015, logit=16.875)']\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.396484375, logit=20.125, token_id=87035, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.349609375, logit=20.0, token_id=1901, metadata=None))), (46506, (3, PredictedToken(token=' Drum', prob=0.08837890625, logit=18.625, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:24 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:24 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:52:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     patch_prediction=['\" Pendant\"[81501] (p=0.871, logit=21.625)', '\" The\"[578] (p=0.026, logit=18.125)', '\" d\"[294] (p=0.023, logit=18.000)', '\" A\"[362] (p=0.018, logit=17.750)', '\" Among\"[22395] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.801, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.045, logit=18.500)', '\" Option\"[7104] (p=0.011, logit=17.125)', '\" jasmine\"[66909] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.80078125, logit=21.375, token_id=82452, metadata=None))), (426, (21, PredictedToken(token=' B', prob=0.00087738037109375, logit=14.5625, token_id=426, metadata=None))), (328, (39, PredictedToken(token=' S', prob=0.0002689361572265625, logit=13.375, token_id=328, metadata=None))), (30616, (89, PredictedToken(token=' Rice', prob=3.409385681152344e-05, logit=11.3125, token_id=30616, metadata=None)))])\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.789, logit=21.875)', '\" The\"[578] (p=0.074, logit=19.500)', '\" S\"[328] (p=0.027, logit=18.500)', '\" b\"[293] (p=0.027, logit=18.500)', '\" Among\"[22395] (p=0.019, logit=18.125)']\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.7890625, logit=21.875, token_id=426, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.027099609375, logit=18.5, token_id=328, metadata=None))), (82452, (6, PredictedToken(token=' Jasmine', prob=0.016357421875, logit=18.0, token_id=82452, metadata=None))), (30616, (50, PredictedToken(token=' Rice', prob=0.00010395050048828125, logit=12.9375, token_id=30616, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:25 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.773, logit=21.250)', '\" The\"[578] (p=0.056, logit=18.625)', '\" A\"[362] (p=0.038, logit=18.250)', '\" Among\"[22395] (p=0.034, logit=18.125)', '\" Harmon\"[40759] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:52:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.707, logit=21.625)', '\" A\"[362] (p=0.096, logit=19.625)', '\" The\"[578] (p=0.084, logit=19.500)', '\" Among\"[22395] (p=0.040, logit=18.750)', '\" It\"[1102] (p=0.017, logit=17.875)']\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.70703125, logit=21.625, token_id=445, metadata=None))), (41493, (16, PredictedToken(token=' Tow', prob=0.00106048583984375, logit=15.125, token_id=41493, metadata=None))), (3816, (25, PredictedToken(token=' Red', prob=0.000606536865234375, logit=14.5625, token_id=3816, metadata=None))), (10777, (69, PredictedToken(token=' Router', prob=6.389617919921875e-05, logit=12.3125, token_id=10777, metadata=None))), (87035, (220, PredictedToken(token=' Onion', prob=5.930662155151367e-06, logit=9.9375, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     int_prediction=['\" Router\"[10777] (p=0.812, logit=21.125)', '\" The\"[578] (p=0.059, logit=18.500)', '\" A\"[362] (p=0.052, logit=18.375)', '\" It\"[1102] (p=0.015, logit=17.125)', '\" Among\"[22395] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     int_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.8125, logit=21.125, token_id=10777, metadata=None))), (41493, (16, PredictedToken(token=' Tow', prob=0.001220703125, logit=14.625, token_id=41493, metadata=None))), (3816, (93, PredictedToken(token=' Red', prob=4.4345855712890625e-05, logit=11.3125, token_id=3816, metadata=None))), (87035, (217, PredictedToken(token=' Onion', prob=9.894371032714844e-06, logit=9.8125, token_id=87035, metadata=None))), (445, (219, PredictedToken(token=' L', prob=9.298324584960938e-06, logit=9.75, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:26 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     patch_prediction=['\" Mirror\"[34954] (p=0.922, logit=21.000)', '\" The\"[578] (p=0.012, logit=16.625)', '\" None\"[2290] (p=0.009, logit=16.375)', '\" Among\"[22395] (p=0.008, logit=16.250)', '\" A\"[362] (p=0.005, logit=15.812)']\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.781, logit=21.875)', '\" The\"[578] (p=0.083, logit=19.625)', '\" A\"[362] (p=0.073, logit=19.500)', '\" Among\"[22395] (p=0.030, logit=18.625)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.78125, logit=21.875, token_id=29318, metadata=None))), (65449, (34, PredictedToken(token=' Willow', prob=0.00015926361083984375, logit=13.375, token_id=65449, metadata=None))), (32498, (190, PredictedToken(token=' Mall', prob=5.453824996948242e-06, logit=10.0, token_id=32498, metadata=None))), (74968, (969, PredictedToken(token=' Razor', prob=3.948807716369629e-07, logit=7.375, token_id=74968, metadata=None))), (30760, (1065, PredictedToken(token=' Scar', prob=3.371387720108032e-07, logit=7.21875, token_id=30760, metadata=None)))])\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.695, logit=21.250)', '\" The\"[578] (p=0.137, logit=19.625)', '\" A\"[362] (p=0.065, logit=18.875)', '\" Among\"[22395] (p=0.031, logit=18.125)', '\" Scar\"[30760] (p=0.024, logit=17.875)']\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.6953125, logit=21.25, token_id=29318, metadata=None))), (30760, (5, PredictedToken(token=' Scar', prob=0.0238037109375, logit=17.875, token_id=30760, metadata=None))), (65449, (13, PredictedToken(token=' Willow', prob=0.001953125, logit=15.375, token_id=65449, metadata=None))), (32498, (219, PredictedToken(token=' Mall', prob=7.510185241699219e-06, logit=9.8125, token_id=32498, metadata=None))), (74968, (339, PredictedToken(token=' Razor', prob=3.3229589462280273e-06, logit=9.0, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:26 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:52:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     patch_prediction=['\" Ash\"[14937] (p=0.805, logit=21.375)', '\" The\"[578] (p=0.058, logit=18.750)', '\" An\"[1556] (p=0.045, logit=18.500)', '\" Among\"[22395] (p=0.019, logit=17.625)', '\" None\"[2290] (p=0.017, logit=17.500)']\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.676, logit=20.375)', '\" The\"[578] (p=0.092, logit=18.375)', '\" A\"[362] (p=0.081, logit=18.250)', '\" Among\"[22395] (p=0.049, logit=17.750)', '\" It\"[1102] (p=0.012, logit=16.375)']\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.67578125, logit=20.375, token_id=69755, metadata=None))), (22050, (8, PredictedToken(token=' Hat', prob=0.00457763671875, logit=15.375, token_id=22050, metadata=None))), (79028, (48, PredictedToken(token=' Hick', prob=0.0003528594970703125, logit=12.8125, token_id=79028, metadata=None))), (8325, (97, PredictedToken(token=' Apple', prob=8.344650268554688e-05, logit=11.375, token_id=8325, metadata=None))), (52882, (182, PredictedToken(token=' Pepper', prob=2.2530555725097656e-05, logit=10.0625, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.369, logit=19.625)', '\" Among\"[22395] (p=0.224, logit=19.125)', '\" Apple\"[8325] (p=0.197, logit=19.000)', '\" The\"[578] (p=0.082, logit=18.125)', '\" Pepper\"[52882] (p=0.034, logit=17.250)']\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.369140625, logit=19.625, token_id=79028, metadata=None))), (8325, (3, PredictedToken(token=' Apple', prob=0.197265625, logit=19.0, token_id=8325, metadata=None))), (52882, (5, PredictedToken(token=' Pepper', prob=0.0341796875, logit=17.25, token_id=52882, metadata=None))), (22050, (29, PredictedToken(token=' Hat', prob=0.000713348388671875, logit=13.375, token_id=22050, metadata=None))), (69755, (246, PredictedToken(token=' Notebook', prob=1.4781951904296875e-05, logit=9.5, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:27 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:27 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     patch_prediction=['\" Television\"[41445] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.075, logit=19.250)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" A\"[362] (p=0.019, logit=17.875)', '\" TV\"[6007] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:52:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.879, logit=21.500)', '\" The\"[578] (p=0.039, logit=18.375)', '\" A\"[362] (p=0.016, logit=17.500)', '\" Acc\"[11683] (p=0.009, logit=16.875)', '\" Note\"[7181] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.87890625, logit=21.5, token_id=69755, metadata=None))), (11683, (4, PredictedToken(token=' Acc', prob=0.00860595703125, logit=16.875, token_id=11683, metadata=None))), (26698, (7, PredictedToken(token=' Keyboard', prob=0.004608154296875, logit=16.25, token_id=26698, metadata=None))), (48665, (201, PredictedToken(token=' Raspberry', prob=9.47713851928711e-06, logit=10.0625, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.754, logit=20.875)', '\" The\"[578] (p=0.055, logit=18.250)', '\" Notebook\"[69755] (p=0.048, logit=18.125)', '\" Acc\"[11683] (p=0.026, logit=17.500)', '\" Raspberry\"[48665] (p=0.020, logit=17.250)']\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.75390625, logit=20.875, token_id=26698, metadata=None))), (69755, (3, PredictedToken(token=' Notebook', prob=0.048095703125, logit=18.125, token_id=69755, metadata=None))), (11683, (4, PredictedToken(token=' Acc', prob=0.0257568359375, logit=17.5, token_id=11683, metadata=None))), (48665, (5, PredictedToken(token=' Raspberry', prob=0.0201416015625, logit=17.25, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:28 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     patch_prediction=['\" Amb\"[20423] (p=0.664, logit=22.250)', '\" An\"[1556] (p=0.148, logit=20.750)', '\" Among\"[22395] (p=0.080, logit=20.125)', '\" The\"[578] (p=0.070, logit=20.000)', '\" Option\"[7104] (p=0.008, logit=17.875)']\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     clean_prediction=['\" Jeans\"[82507] (p=0.844, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" A\"[362] (p=0.009, logit=17.750)', '\" JE\"[71430] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     clean_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.84375, logit=22.25, token_id=82507, metadata=None))), (423, (30, PredictedToken(token=' D', prob=0.0002346038818359375, logit=14.0625, token_id=423, metadata=None))), (16183, (88, PredictedToken(token=' Hel', prob=2.3245811462402344e-05, logit=11.75, token_id=16183, metadata=None))), (16730, (1284, PredictedToken(token=' Museum', prob=1.825392246246338e-07, logit=6.90625, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.852, logit=22.250)', '\" The\"[578] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.033, logit=19.000)', '\" Among\"[22395] (p=0.023, logit=18.625)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.8515625, logit=22.25, token_id=16183, metadata=None))), (423, (25, PredictedToken(token=' D', prob=0.0003910064697265625, logit=14.5625, token_id=423, metadata=None))), (16730, (38, PredictedToken(token=' Museum', prob=0.00014400482177734375, logit=13.5625, token_id=16730, metadata=None))), (82507, (68, PredictedToken(token=' Jeans', prob=4.38690185546875e-05, logit=12.375, token_id=82507, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:28 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:52:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     patch_prediction=['\" Acc\"[11683] (p=0.758, logit=22.500)', '\" The\"[578] (p=0.103, logit=20.500)', '\" An\"[1556] (p=0.080, logit=20.250)', '\" Among\"[22395] (p=0.023, logit=19.000)', '\" It\"[1102] (p=0.010, logit=18.125)']\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     clean_prediction=['\" Ring\"[22249] (p=0.723, logit=22.125)', '\" The\"[578] (p=0.098, logit=20.125)', '\" Among\"[22395] (p=0.067, logit=19.750)', '\" A\"[362] (p=0.067, logit=19.750)', '\" It\"[1102] (p=0.012, logit=18.000)']\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     clean_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.72265625, logit=22.125, token_id=22249, metadata=None))), (1666, (10, PredictedToken(token=' As', prob=0.00148773193359375, logit=15.9375, token_id=1666, metadata=None))), (27217, (92, PredictedToken(token=' Train', prob=2.4080276489257812e-05, logit=11.8125, token_id=27217, metadata=None))), (48035, (137, PredictedToken(token=' Gir', prob=1.0013580322265625e-05, logit=10.9375, token_id=48035, metadata=None))), (30555, (136, PredictedToken(token=' Viol', prob=1.0013580322265625e-05, logit=10.9375, token_id=30555, metadata=None)))])\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.855, logit=21.875)', '\" The\"[578] (p=0.062, logit=19.250)', '\" A\"[362] (p=0.026, logit=18.375)', '\" Among\"[22395] (p=0.014, logit=17.750)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.85546875, logit=21.875, token_id=30555, metadata=None))), (27217, (6, PredictedToken(token=' Train', prob=0.00396728515625, logit=16.5, token_id=27217, metadata=None))), (48035, (7, PredictedToken(token=' Gir', prob=0.003082275390625, logit=16.25, token_id=48035, metadata=None))), (1666, (23, PredictedToken(token=' As', prob=0.0004177093505859375, logit=14.25, token_id=1666, metadata=None))), (22249, (396, PredictedToken(token=' Ring', prob=1.817941665649414e-06, logit=8.8125, token_id=22249, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:29 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:29 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     patch_prediction=['\" Raspberry\"[48665] (p=0.773, logit=21.500)', '\" The\"[578] (p=0.072, logit=19.125)', '\" Among\"[22395] (p=0.063, logit=19.000)', '\" R\"[432] (p=0.023, logit=18.000)', '\" A\"[362] (p=0.013, logit=17.375)']\n",
      "2025-09-16 09:52:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.820, logit=21.125)', '\" The\"[578] (p=0.041, logit=18.125)', '\" A\"[362] (p=0.032, logit=17.875)', '\" Pine\"[42609] (p=0.017, logit=17.250)', '\" Suit\"[33711] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.8203125, logit=21.125, token_id=17929, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.01708984375, logit=17.25, token_id=42609, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.0150146484375, logit=17.125, token_id=33711, metadata=None))), (29318, (43, PredictedToken(token=' Dress', prob=0.00022792816162109375, logit=12.9375, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.727, logit=20.500)', '\" The\"[578] (p=0.098, logit=18.500)', '\" A\"[362] (p=0.052, logit=17.875)', '\" None\"[2290] (p=0.013, logit=16.500)', '\" It\"[1102] (p=0.013, logit=16.500)']\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.7265625, logit=20.5, token_id=42609, metadata=None))), (17929, (8, PredictedToken(token=' Pin', prob=0.008056640625, logit=16.0, token_id=17929, metadata=None))), (33711, (692, PredictedToken(token=' Suit', prob=3.069639205932617e-06, logit=8.125, token_id=33711, metadata=None))), (29318, (1034, PredictedToken(token=' Dress', prob=1.691281795501709e-06, logit=7.53125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:30 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:30 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.863, logit=21.500)', '\" The\"[578] (p=0.049, logit=18.625)', '\" Among\"[22395] (p=0.016, logit=17.500)', '\" Glo\"[25372] (p=0.014, logit=17.375)', '\" Har\"[5340] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.844, logit=22.875)', '\" The\"[578] (p=0.061, logit=20.250)', '\" An\"[1556] (p=0.054, logit=20.125)', '\" Among\"[22395] (p=0.014, logit=18.750)', '\" (\"[320] (p=0.004, logit=17.500)']\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.84375, logit=22.875, token_id=11683, metadata=None))), (33711, (114, PredictedToken(token=' Suit', prob=9.119510650634766e-06, logit=11.4375, token_id=33711, metadata=None))), (38571, (325, PredictedToken(token=' Theater', prob=1.087784767150879e-06, logit=9.3125, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.477, logit=21.250)', '\" Acc\"[11683] (p=0.371, logit=21.000)', '\" The\"[578] (p=0.050, logit=19.000)', '\" An\"[1556] (p=0.027, logit=18.375)', '\" Among\"[22395] (p=0.018, logit=18.000)']\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.4765625, logit=21.25, token_id=33711, metadata=None))), (11683, (2, PredictedToken(token=' Acc', prob=0.37109375, logit=21.0, token_id=11683, metadata=None))), (38571, (6, PredictedToken(token=' Theater', prob=0.0162353515625, logit=17.875, token_id=38571, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:30 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:30 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:52:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.879, logit=22.875)', '\" A\"[362] (p=0.034, logit=19.625)', '\" The\"[578] (p=0.026, logit=19.375)', '\" cow\"[19923] (p=0.023, logit=19.250)', '\" Among\"[22395] (p=0.011, logit=18.500)']\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.863, logit=21.875)', '\" None\"[2290] (p=0.033, logit=18.625)', '\" An\"[1556] (p=0.033, logit=18.625)', '\" The\"[578] (p=0.023, logit=18.250)', '\" Among\"[22395] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.86328125, logit=21.875, token_id=53889, metadata=None))), (91263, (6, PredictedToken(token=' Binder', prob=0.003997802734375, logit=16.5, token_id=91263, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.0022735595703125, logit=15.9375, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.918, logit=22.250)', '\" The\"[578] (p=0.022, logit=18.500)', '\" A\"[362] (p=0.019, logit=18.375)', '\" None\"[2290] (p=0.013, logit=18.000)', '\" dolphin\"[99269] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.91796875, logit=22.25, token_id=96096, metadata=None))), (53889, (258, PredictedToken(token=' Apartment', prob=2.8312206268310547e-06, logit=9.5625, token_id=53889, metadata=None))), (91263, (1336, PredictedToken(token=' Binder', prob=2.477318048477173e-07, logit=7.125, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:31 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:31 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.906, logit=21.875)', '\" The\"[578] (p=0.019, logit=18.000)', '\" Among\"[22395] (p=0.015, logit=17.750)', '\" Tape\"[58586] (p=0.011, logit=17.500)', '\" A\"[362] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:52:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.609, logit=20.375)', '\" A\"[362] (p=0.136, logit=18.875)', '\" The\"[578] (p=0.120, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=17.125)', '\" Note\"[7181] (p=0.018, logit=16.875)']\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.609375, logit=20.375, token_id=69755, metadata=None))), (445, (15, PredictedToken(token=' L', prob=0.00182342529296875, logit=14.5625, token_id=445, metadata=None))), (72683, (235, PredictedToken(token=' Boxing', prob=1.3947486877441406e-05, logit=9.6875, token_id=72683, metadata=None)))])\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.680, logit=20.750)', '\" The\"[578] (p=0.118, logit=19.000)', '\" A\"[362] (p=0.043, logit=18.000)', '\" Notebook\"[69755] (p=0.030, logit=17.625)', '\" Among\"[22395] (p=0.026, logit=17.500)']\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.6796875, logit=20.75, token_id=445, metadata=None))), (69755, (4, PredictedToken(token=' Notebook', prob=0.0299072265625, logit=17.625, token_id=69755, metadata=None))), (72683, (12, PredictedToken(token=' Boxing', prob=0.00457763671875, logit=15.75, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:32 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:32 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.879, logit=22.500)', '\" The\"[578] (p=0.039, logit=19.375)', '\" A\"[362] (p=0.034, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=18.750)', '\" (\"[320] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.566, logit=22.250)', '\" The\"[578] (p=0.235, logit=21.375)', '\" A\"[362] (p=0.111, logit=20.625)', '\" Among\"[22395] (p=0.046, logit=19.750)', '\" It\"[1102] (p=0.008, logit=18.000)']\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.56640625, logit=22.25, token_id=3341, metadata=None))), (27171, (65, PredictedToken(token=' Coffee', prob=4.220008850097656e-05, logit=12.75, token_id=27171, metadata=None))), (94467, (549, PredictedToken(token=' Trom', prob=5.662441253662109e-07, logit=8.4375, token_id=94467, metadata=None)))])\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.703, logit=22.000)', '\" The\"[578] (p=0.157, logit=20.500)', '\" A\"[362] (p=0.074, logit=19.750)', '\" Among\"[22395] (p=0.015, logit=18.125)', '\" Car\"[3341] (p=0.013, logit=18.000)']\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.703125, logit=22.0, token_id=27171, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.01287841796875, logit=18.0, token_id=3341, metadata=None))), (94467, (10, PredictedToken(token=' Trom', prob=0.0019683837890625, logit=16.125, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:32 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:32 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     patch_prediction=['\" Gir\"[48035] (p=0.746, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" A\"[362] (p=0.061, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.500)', '\" (\"[320] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.508, logit=20.250)', '\" The\"[578] (p=0.271, logit=19.625)', '\" A\"[362] (p=0.078, logit=18.375)', '\" Among\"[22395] (p=0.061, logit=18.125)', '\" It\"[1102] (p=0.022, logit=17.125)']\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.5078125, logit=20.25, token_id=94467, metadata=None))), (49431, (203, PredictedToken(token=' Rabbit', prob=1.233816146850586e-05, logit=9.625, token_id=49431, metadata=None))), (27171, (462, PredictedToken(token=' Coffee', prob=3.3080577850341797e-06, logit=8.3125, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.391, logit=19.875)', '\" The\"[578] (p=0.237, logit=19.375)', '\" Trom\"[94467] (p=0.163, logit=19.000)', '\" A\"[362] (p=0.068, logit=18.125)', '\" Among\"[22395] (p=0.053, logit=17.875)']\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.390625, logit=19.875, token_id=49431, metadata=None))), (94467, (3, PredictedToken(token=' Trom', prob=0.1630859375, logit=19.0, token_id=94467, metadata=None))), (27171, (304, PredictedToken(token=' Coffee', prob=7.3909759521484375e-06, logit=9.0, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:33 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:33 src.selection.optimization DEBUG    torch.Size([6, 35])\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.801, logit=20.875)', '\" The\"[578] (p=0.066, logit=18.375)', '\" Among\"[22395] (p=0.035, logit=17.750)', '\" A\"[362] (p=0.017, logit=17.000)', '\" Option\"[7104] (p=0.015, logit=16.875)']\n",
      "2025-09-16 09:52:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.801, logit=22.500)', '\" The\"[578] (p=0.123, logit=20.625)', '\" A\"[362] (p=0.031, logit=19.250)', '\" Among\"[22395] (p=0.019, logit=18.750)', '\" It\"[1102] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.80078125, logit=22.5, token_id=3420, metadata=None))), (41445, (43, PredictedToken(token=' Television', prob=7.2479248046875e-05, logit=13.1875, token_id=41445, metadata=None))), (3816, (58, PredictedToken(token=' Red', prob=3.409385681152344e-05, logit=12.4375, token_id=3816, metadata=None))), (6771, (85, PredictedToken(token=' Table', prob=1.9431114196777344e-05, logit=11.875, token_id=6771, metadata=None))), (735, (125, PredictedToken(token=' K', prob=8.106231689453125e-06, logit=11.0, token_id=735, metadata=None))), (37128, (267, PredictedToken(token=' Calculator', prob=1.6987323760986328e-06, logit=9.4375, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     int_prediction=['\" Red\"[3816] (p=0.832, logit=21.625)', '\" The\"[578] (p=0.078, logit=19.250)', '\" Among\"[22395] (p=0.020, logit=17.875)', '\" A\"[362] (p=0.012, logit=17.375)', '\" Table\"[6771] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     int_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.83203125, logit=21.625, token_id=3816, metadata=None))), (6771, (5, PredictedToken(token=' Table', prob=0.010498046875, logit=17.25, token_id=6771, metadata=None))), (37128, (6, PredictedToken(token=' Calculator', prob=0.0072021484375, logit=16.875, token_id=37128, metadata=None))), (3420, (18, PredictedToken(token=' Trump', prob=0.00091552734375, logit=14.8125, token_id=3420, metadata=None))), (735, (27, PredictedToken(token=' K', prob=0.00035858154296875, logit=13.875, token_id=735, metadata=None))), (41445, (126, PredictedToken(token=' Television', prob=1.7881393432617188e-05, logit=10.875, token_id=41445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:34 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.676, logit=21.125)', '\" The\"[578] (p=0.171, logit=19.750)', '\" A\"[362] (p=0.056, logit=18.625)', '\" Among\"[22395] (p=0.043, logit=18.375)', '\" It\"[1102] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.891, logit=21.875)', '\" The\"[578] (p=0.039, logit=18.750)', '\" Among\"[22395] (p=0.035, logit=18.625)', '\" A\"[362] (p=0.002, logit=15.875)', '\" (\"[320] (p=0.002, logit=15.875)']\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.890625, logit=21.875, token_id=72683, metadata=None))), (24941, (17, PredictedToken(token=' Bear', prob=0.000675201416015625, logit=14.6875, token_id=24941, metadata=None))), (45332, (31, PredictedToken(token=' Boat', prob=0.0002994537353515625, logit=13.875, token_id=45332, metadata=None))), (47759, (45, PredictedToken(token=' Guitar', prob=0.0001811981201171875, logit=13.375, token_id=47759, metadata=None))), (3816, (72, PredictedToken(token=' Red', prob=6.67572021484375e-05, logit=12.375, token_id=3816, metadata=None))), (48665, (215, PredictedToken(token=' Raspberry', prob=4.827976226806641e-06, logit=9.75, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     int_prediction=['\" Guitar\"[47759] (p=0.594, logit=20.250)', '\" Boxing\"[72683] (p=0.117, logit=18.625)', '\" The\"[578] (p=0.117, logit=18.625)', '\" A\"[362] (p=0.043, logit=17.625)', '\" Among\"[22395] (p=0.033, logit=17.375)']\n",
      "2025-09-16 09:52:34 src.selection.optimization INFO     int_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.59375, logit=20.25, token_id=47759, metadata=None))), (72683, (3, PredictedToken(token=' Boxing', prob=0.1171875, logit=18.625, token_id=72683, metadata=None))), (24941, (8, PredictedToken(token=' Bear', prob=0.004547119140625, logit=15.375, token_id=24941, metadata=None))), (45332, (9, PredictedToken(token=' Boat', prob=0.004547119140625, logit=15.375, token_id=45332, metadata=None))), (3816, (13, PredictedToken(token=' Red', prob=0.003326416015625, logit=15.0625, token_id=3816, metadata=None))), (48665, (32, PredictedToken(token=' Raspberry', prob=0.0008392333984375, logit=13.6875, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:35 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.867, logit=21.750)', '\" Among\"[22395] (p=0.026, logit=18.250)', '\" A\"[362] (p=0.026, logit=18.250)', '\" The\"[578] (p=0.026, logit=18.250)', '\" (\"[320] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.664, logit=20.500)', '\" The\"[578] (p=0.102, logit=18.625)', '\" A\"[362] (p=0.090, logit=18.500)', '\" Among\"[22395] (p=0.048, logit=17.875)', '\" It\"[1102] (p=0.016, logit=16.750)']\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.6640625, logit=20.5, token_id=69755, metadata=None))), (445, (34, PredictedToken(token=' L', prob=0.000644683837890625, logit=13.5625, token_id=445, metadata=None))), (44570, (39, PredictedToken(token=' Maple', prob=0.0004711151123046875, logit=13.25, token_id=44570, metadata=None))), (82507, (252, PredictedToken(token=' Jeans', prob=1.1086463928222656e-05, logit=9.5, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.715, logit=20.500)', '\" Maple\"[44570] (p=0.075, logit=18.250)', '\" The\"[578] (p=0.075, logit=18.250)', '\" Among\"[22395] (p=0.031, logit=17.375)', '\" A\"[362] (p=0.012, logit=16.375)']\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.71484375, logit=20.5, token_id=445, metadata=None))), (44570, (3, PredictedToken(token=' Maple', prob=0.0751953125, logit=18.25, token_id=44570, metadata=None))), (82507, (7, PredictedToken(token=' Jeans', prob=0.006561279296875, logit=15.8125, token_id=82507, metadata=None))), (69755, (47, PredictedToken(token=' Notebook', prob=0.0003719329833984375, logit=12.9375, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:35 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:52:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.859, logit=21.875)', '\" The\"[578] (p=0.055, logit=19.125)', '\" Among\"[22395] (p=0.029, logit=18.500)', '\" A\"[362] (p=0.010, logit=17.375)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.762, logit=21.250)', '\" The\"[578] (p=0.080, logit=19.000)', '\" A\"[362] (p=0.062, logit=18.750)', '\" Among\"[22395] (p=0.049, logit=18.500)', '\" It\"[1102] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.76171875, logit=21.25, token_id=83499, metadata=None))), (4923, (46, PredictedToken(token=' Sk', prob=0.00017547607421875, logit=12.875, token_id=4923, metadata=None))), (30555, (61, PredictedToken(token=' Viol', prob=0.00010633468627929688, logit=12.375, token_id=30555, metadata=None))), (65197, (123, PredictedToken(token=' Surf', prob=3.0517578125e-05, logit=11.125, token_id=65197, metadata=None))), (65329, (194, PredictedToken(token=' Elm', prob=1.1920928955078125e-05, logit=10.1875, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.613, logit=20.125)', '\" Sk\"[4923] (p=0.106, logit=18.375)', '\" The\"[578] (p=0.083, logit=18.125)', '\" Viol\"[30555] (p=0.064, logit=17.875)', '\" Among\"[22395] (p=0.024, logit=16.875)']\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.61328125, logit=20.125, token_id=65329, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.1064453125, logit=18.375, token_id=4923, metadata=None))), (30555, (4, PredictedToken(token=' Viol', prob=0.064453125, logit=17.875, token_id=30555, metadata=None))), (65197, (7, PredictedToken(token=' Surf', prob=0.0126953125, logit=16.25, token_id=65197, metadata=None))), (83499, (1151, PredictedToken(token=' Tooth', prob=1.5720725059509277e-06, logit=7.25, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:36 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:36 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     patch_prediction=['\" Project\"[5907] (p=0.887, logit=22.750)', '\" The\"[578] (p=0.044, logit=19.750)', '\" A\"[362] (p=0.030, logit=19.375)', '\" Among\"[22395] (p=0.013, logit=18.500)', '\" It\"[1102] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.875, logit=22.625)', '\" The\"[578] (p=0.056, logit=19.875)', '\" Among\"[22395] (p=0.038, logit=19.500)', '\" A\"[362] (p=0.011, logit=18.250)', '\" (\"[320] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.875, logit=22.625, token_id=64695, metadata=None))), (4923, (48, PredictedToken(token=' Sk', prob=4.220008850097656e-05, logit=12.6875, token_id=4923, metadata=None))), (57225, (273, PredictedToken(token=' Laptop', prob=1.5422701835632324e-06, logit=9.375, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:52:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     int_prediction=['\" Laptop\"[57225] (p=0.895, logit=22.625)', '\" The\"[578] (p=0.031, logit=19.250)', '\" Among\"[22395] (p=0.019, logit=18.750)', '\" Sk\"[4923] (p=0.019, logit=18.750)', '\" A\"[362] (p=0.010, logit=18.125)']\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     int_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.89453125, logit=22.625, token_id=57225, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.0185546875, logit=18.75, token_id=4923, metadata=None))), (64695, (34, PredictedToken(token=' Peach', prob=9.72747802734375e-05, logit=13.5, token_id=64695, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:37 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.746, logit=21.750)', '\" The\"[578] (p=0.115, logit=19.875)', '\" A\"[362] (p=0.048, logit=19.000)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" B\"[426] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.723, logit=21.375)', '\" The\"[578] (p=0.098, logit=19.375)', '\" A\"[362] (p=0.067, logit=19.000)', '\" Among\"[22395] (p=0.028, logit=18.125)', '\" Harmon\"[40759] (p=0.019, logit=17.750)']\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.72265625, logit=21.375, token_id=28131, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.019287109375, logit=17.75, token_id=40759, metadata=None))), (16183, (9, PredictedToken(token=' Hel', prob=0.0033416748046875, logit=16.0, token_id=16183, metadata=None))), (10164, (129, PredictedToken(token=' Water', prob=1.8715858459472656e-05, logit=10.8125, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.914, logit=22.125)', '\" Among\"[22395] (p=0.024, logit=18.500)', '\" The\"[578] (p=0.021, logit=18.375)', '\" A\"[362] (p=0.009, logit=17.500)', '\" water\"[3090] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.9140625, logit=22.125, token_id=10164, metadata=None))), (40759, (26, PredictedToken(token=' Harmon', prob=0.0003261566162109375, logit=14.1875, token_id=40759, metadata=None))), (16183, (25, PredictedToken(token=' Hel', prob=0.0003261566162109375, logit=14.1875, token_id=16183, metadata=None))), (28131, (27, PredictedToken(token=' Golf', prob=0.0003070831298828125, logit=14.125, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:37 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:52:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     patch_prediction=['\" Chair\"[16478] (p=0.816, logit=22.875)', '\" The\"[578] (p=0.076, logit=20.500)', '\" A\"[362] (p=0.067, logit=20.375)', '\" Among\"[22395] (p=0.015, logit=18.875)', '\" It\"[1102] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.061, logit=19.250)', '\" A\"[362] (p=0.025, logit=18.375)', '\" Among\"[22395] (p=0.022, logit=18.250)', '\" dress\"[8679] (p=0.017, logit=18.000)']\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.8359375, logit=21.875, token_id=29318, metadata=None))), (65449, (27, PredictedToken(token=' Willow', prob=0.0003376007080078125, logit=14.0625, token_id=65449, metadata=None))), (27738, (39, PredictedToken(token=' Ward', prob=0.000141143798828125, logit=13.1875, token_id=27738, metadata=None))), (57225, (53, PredictedToken(token=' Laptop', prob=8.535385131835938e-05, logit=12.6875, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     int_prediction=['\" Ward\"[27738] (p=0.859, logit=21.750)', '\" The\"[578] (p=0.055, logit=19.000)', '\" Among\"[22395] (p=0.026, logit=18.250)', '\" Willow\"[65449] (p=0.012, logit=17.500)', '\" A\"[362] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     int_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.859375, logit=21.75, token_id=27738, metadata=None))), (65449, (4, PredictedToken(token=' Willow', prob=0.01226806640625, logit=17.5, token_id=65449, metadata=None))), (29318, (27, PredictedToken(token=' Dress', prob=0.0005035400390625, logit=14.3125, token_id=29318, metadata=None))), (57225, (277, PredictedToken(token=' Laptop', prob=3.3974647521972656e-06, logit=9.3125, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:38 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:38 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.918, logit=23.000)', '\" The\"[578] (p=0.028, logit=19.500)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" A\"[362] (p=0.006, logit=18.000)', '\" (\"[320] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.691, logit=22.250)', '\" The\"[578] (p=0.154, logit=20.750)', '\" A\"[362] (p=0.083, logit=20.125)', '\" Among\"[22395] (p=0.030, logit=19.125)', '\" It\"[1102] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.69140625, logit=22.25, token_id=27171, metadata=None))), (34392, (21, PredictedToken(token=' Horse', prob=0.000461578369140625, logit=14.9375, token_id=34392, metadata=None))), (8868, (66, PredictedToken(token=' Blue', prob=3.790855407714844e-05, logit=12.4375, token_id=8868, metadata=None)))])\n",
      "2025-09-16 09:52:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.863, logit=22.500)', '\" The\"[578] (p=0.071, logit=20.000)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" A\"[362] (p=0.016, logit=18.500)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.86328125, logit=22.5, token_id=8868, metadata=None))), (27171, (30, PredictedToken(token=' Coffee', prob=0.00017547607421875, logit=14.0, token_id=27171, metadata=None))), (34392, (42, PredictedToken(token=' Horse', prob=8.296966552734375e-05, logit=13.25, token_id=34392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:39 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:39 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     patch_prediction=['\" Swe\"[37326] (p=0.699, logit=22.000)', '\" The\"[578] (p=0.122, logit=20.250)', '\" A\"[362] (p=0.095, logit=20.000)', '\" Among\"[22395] (p=0.051, logit=19.375)', '\" sweater\"[61221] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     clean_prediction=['\" Table\"[6771] (p=0.824, logit=22.375)', '\" The\"[578] (p=0.077, logit=20.000)', '\" A\"[362] (p=0.036, logit=19.250)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" It\"[1102] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     clean_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.82421875, logit=22.375, token_id=6771, metadata=None))), (20918, (22, PredictedToken(token=' Magn', prob=0.00054931640625, logit=15.0625, token_id=20918, metadata=None))), (34785, (37, PredictedToken(token=' Truck', prob=0.000202178955078125, logit=14.0625, token_id=34785, metadata=None))), (68554, (96, PredictedToken(token=' Gloves', prob=2.1338462829589844e-05, logit=11.8125, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.941, logit=21.500)', '\" The\"[578] (p=0.017, logit=17.500)', '\" None\"[2290] (p=0.003, logit=15.812)', '\" Truck\"[34785] (p=0.003, logit=15.750)', '\" It\"[1102] (p=0.003, logit=15.688)']\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.94140625, logit=21.5, token_id=68554, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.00299072265625, logit=15.75, token_id=34785, metadata=None))), (20918, (40, PredictedToken(token=' Magn', prob=0.00014019012451171875, logit=12.6875, token_id=20918, metadata=None))), (6771, (57, PredictedToken(token=' Table', prob=7.05718994140625e-05, logit=12.0, token_id=6771, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:39 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:39 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:52:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     patch_prediction=['\" Tablet\"[58403] (p=0.377, logit=19.750)', '\" The\"[578] (p=0.201, logit=19.125)', '\" Food\"[12369] (p=0.108, logit=18.500)', '\" Among\"[22395] (p=0.095, logit=18.375)', '\" A\"[362] (p=0.058, logit=17.875)']\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     clean_prediction=['\" Blue\"[8868] (p=0.715, logit=21.750)', '\" The\"[578] (p=0.141, logit=20.125)', '\" Among\"[22395] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.046, logit=19.000)', '\" It\"[1102] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     clean_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.71484375, logit=21.75, token_id=8868, metadata=None))), (55807, (99, PredictedToken(token=' Shirt', prob=2.2292137145996094e-05, logit=11.375, token_id=55807, metadata=None))), (58937, (261, PredictedToken(token=' Monkey', prob=3.635883331298828e-06, logit=9.5625, token_id=58937, metadata=None))), (14669, (458, PredictedToken(token=' Camera', prob=1.259148120880127e-06, logit=8.5, token_id=14669, metadata=None))), (47759, (1170, PredictedToken(token=' Guitar', prob=3.594905138015747e-07, logit=7.25, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     int_prediction=['\" Camera\"[14669] (p=0.543, logit=21.125)', '\" The\"[578] (p=0.176, logit=20.000)', '\" Shirt\"[55807] (p=0.094, logit=19.375)', '\" Among\"[22395] (p=0.065, logit=19.000)', '\" A\"[362] (p=0.057, logit=18.875)']\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     int_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.54296875, logit=21.125, token_id=14669, metadata=None))), (55807, (3, PredictedToken(token=' Shirt', prob=0.09423828125, logit=19.375, token_id=55807, metadata=None))), (47759, (11, PredictedToken(token=' Guitar', prob=0.0023651123046875, logit=15.6875, token_id=47759, metadata=None))), (8868, (225, PredictedToken(token=' Blue', prob=7.510185241699219e-06, logit=9.9375, token_id=8868, metadata=None))), (58937, (1314, PredictedToken(token=' Monkey', prob=5.438923835754395e-07, logit=7.3125, token_id=58937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:40 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.523, logit=20.875)', '\" The\"[578] (p=0.279, logit=20.250)', '\" A\"[362] (p=0.071, logit=18.875)', '\" Among\"[22395] (p=0.062, logit=18.750)', '\" It\"[1102] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.781, logit=22.000)', '\" The\"[578] (p=0.083, logit=19.750)', '\" A\"[362] (p=0.064, logit=19.500)', '\" Among\"[22395] (p=0.034, logit=18.875)', '\" It\"[1102] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.78125, logit=22.0, token_id=1183, metadata=None))), (4923, (53, PredictedToken(token=' Sk', prob=9.059906005859375e-05, logit=12.9375, token_id=4923, metadata=None))), (10573, (64, PredictedToken(token=' Watch', prob=5.841255187988281e-05, logit=12.5, token_id=10573, metadata=None))), (46506, (271, PredictedToken(token=' Drum', prob=2.562999725341797e-06, logit=9.375, token_id=46506, metadata=None))), (65329, (300, PredictedToken(token=' Elm', prob=2.130866050720215e-06, logit=9.1875, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:52:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     int_prediction=['\" Drum\"[46506] (p=0.652, logit=20.625)', '\" The\"[578] (p=0.128, logit=19.000)', '\" Watch\"[10573] (p=0.047, logit=18.000)', '\" Among\"[22395] (p=0.042, logit=17.875)', '\" A\"[362] (p=0.017, logit=17.000)']\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     int_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.65234375, logit=20.625, token_id=46506, metadata=None))), (10573, (3, PredictedToken(token=' Watch', prob=0.047119140625, logit=18.0, token_id=10573, metadata=None))), (65329, (6, PredictedToken(token=' Elm', prob=0.0135498046875, logit=16.75, token_id=65329, metadata=None))), (4923, (18, PredictedToken(token=' Sk', prob=0.00250244140625, logit=15.0625, token_id=4923, metadata=None))), (1183, (40, PredictedToken(token=' Tr', prob=0.000408172607421875, logit=13.25, token_id=1183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:41 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.742, logit=22.125)', '\" The\"[578] (p=0.114, logit=20.250)', '\" Among\"[22395] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.054, logit=19.500)', '\" It\"[1102] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.770, logit=21.375)', '\" The\"[578] (p=0.072, logit=19.000)', '\" A\"[362] (p=0.072, logit=19.000)', '\" Among\"[22395] (p=0.043, logit=18.500)', '\" It\"[1102] (p=0.003, logit=15.750)']\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.76953125, logit=21.375, token_id=68867, metadata=None))), (921, (34, PredictedToken(token=' Ch', prob=0.000293731689453125, logit=13.5, token_id=921, metadata=None))), (4923, (42, PredictedToken(token=' Sk', prob=0.00016689300537109375, logit=12.9375, token_id=4923, metadata=None))), (16488, (48, PredictedToken(token=' Bat', prob=0.00013828277587890625, logit=12.75, token_id=16488, metadata=None))), (44570, (167, PredictedToken(token=' Maple', prob=1.138448715209961e-05, logit=10.25, token_id=44570, metadata=None))), (56491, (268, PredictedToken(token=' Piano', prob=4.4405460357666016e-06, logit=9.3125, token_id=56491, metadata=None)))])\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.914, logit=21.875)', '\" The\"[578] (p=0.019, logit=18.000)', '\" Among\"[22395] (p=0.017, logit=17.875)', '\" A\"[362] (p=0.012, logit=17.500)', '\" None\"[2290] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.9140625, logit=21.875, token_id=4923, metadata=None))), (921, (9, PredictedToken(token=' Ch', prob=0.00177001953125, logit=15.625, token_id=921, metadata=None))), (16488, (11, PredictedToken(token=' Bat', prob=0.001373291015625, logit=15.375, token_id=16488, metadata=None))), (68867, (1017, PredictedToken(token=' Coat', prob=5.21540641784668e-07, logit=7.5, token_id=68867, metadata=None))), (44570, (1150, PredictedToken(token=' Maple', prob=4.33996319770813e-07, logit=7.3125, token_id=44570, metadata=None))), (56491, (1722, PredictedToken(token=' Piano', prob=2.4028122425079346e-07, logit=6.71875, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:41 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:52:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.512, logit=20.625)', '\" The\"[578] (p=0.214, logit=19.750)', '\" A\"[362] (p=0.130, logit=19.250)', '\" Among\"[22395] (p=0.061, logit=18.500)', '\" \"[220] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.723, logit=21.875)', '\" The\"[578] (p=0.111, logit=20.000)', '\" A\"[362] (p=0.059, logit=19.375)', '\" Among\"[22395] (p=0.052, logit=19.250)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.72265625, logit=21.875, token_id=19111, metadata=None))), (14588, (38, PredictedToken(token=' Dog', prob=0.00022792816162109375, logit=13.8125, token_id=14588, metadata=None))), (5907, (127, PredictedToken(token=' Project', prob=1.1324882507324219e-05, logit=10.8125, token_id=5907, metadata=None))), (28131, (180, PredictedToken(token=' Golf', prob=6.079673767089844e-06, logit=10.1875, token_id=28131, metadata=None))), (37128, (242, PredictedToken(token=' Calculator', prob=3.4570693969726562e-06, logit=9.625, token_id=37128, metadata=None))), (91963, (446, PredictedToken(token=' Mango', prob=1.125037670135498e-06, logit=8.5, token_id=91963, metadata=None)))])\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.719, logit=21.375)', '\" The\"[578] (p=0.085, logit=19.250)', '\" A\"[362] (p=0.085, logit=19.250)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" Bus\"[19111] (p=0.022, logit=17.875)']\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.71875, logit=21.375, token_id=14588, metadata=None))), (19111, (5, PredictedToken(token=' Bus', prob=0.0216064453125, logit=17.875, token_id=19111, metadata=None))), (28131, (23, PredictedToken(token=' Golf', prob=0.000949859619140625, logit=14.75, token_id=28131, metadata=None))), (91963, (28, PredictedToken(token=' Mango', prob=0.00045013427734375, logit=14.0, token_id=91963, metadata=None))), (37128, (58, PredictedToken(token=' Calculator', prob=9.393692016601562e-05, logit=12.4375, token_id=37128, metadata=None))), (5907, (189, PredictedToken(token=' Project', prob=7.271766662597656e-06, logit=9.875, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:42 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.828, logit=21.750)', '\" The\"[578] (p=0.047, logit=18.875)', '\" A\"[362] (p=0.047, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.250)', '\" None\"[2290] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:52:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     clean_prediction=['\" Book\"[6017] (p=0.789, logit=21.875)', '\" The\"[578] (p=0.074, logit=19.500)', '\" Among\"[22395] (p=0.045, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.625)', '\" Bro\"[6031] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     clean_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.7890625, logit=21.875, token_id=6017, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.0087890625, logit=17.375, token_id=6031, metadata=None))), (469, (19, PredictedToken(token=' E', prob=0.0010528564453125, logit=15.25, token_id=469, metadata=None))), (19176, (27, PredictedToken(token=' Temple', prob=0.000560760498046875, logit=14.625, token_id=19176, metadata=None))), (47643, (138, PredictedToken(token=' Cel', prob=1.239776611328125e-05, logit=10.8125, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.781, logit=21.875)', '\" Book\"[6017] (p=0.094, logit=19.750)', '\" The\"[578] (p=0.030, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" Bro\"[6031] (p=0.021, logit=18.250)']\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.78125, logit=21.875, token_id=19176, metadata=None))), (6017, (2, PredictedToken(token=' Book', prob=0.09375, logit=19.75, token_id=6017, metadata=None))), (6031, (4, PredictedToken(token=' Bro', prob=0.0208740234375, logit=18.25, token_id=6031, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.005279541015625, logit=16.875, token_id=469, metadata=None))), (47643, (33, PredictedToken(token=' Cel', prob=0.0002803802490234375, logit=13.9375, token_id=47643, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:43 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:43 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     patch_prediction=['\" Camera\"[14669] (p=0.570, logit=20.375)', '\" Refriger\"[75258] (p=0.099, logit=18.625)', '\" Among\"[22395] (p=0.099, logit=18.625)', '\" The\"[578] (p=0.077, logit=18.375)', '\" A\"[362] (p=0.028, logit=17.375)']\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     clean_prediction=['\" Rice\"[30616] (p=0.734, logit=21.625)', '\" The\"[578] (p=0.087, logit=19.500)', '\" A\"[362] (p=0.087, logit=19.500)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     clean_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.734375, logit=21.625, token_id=30616, metadata=None))), (426, (28, PredictedToken(token=' B', prob=0.0003566741943359375, logit=14.0, token_id=426, metadata=None))), (90538, (53, PredictedToken(token=' Caul', prob=9.059906005859375e-05, logit=12.625, token_id=90538, metadata=None))), (58403, (425, PredictedToken(token=' Tablet', prob=1.3709068298339844e-06, logit=8.4375, token_id=58403, metadata=None))), (52466, (638, PredictedToken(token=' Warehouse', prob=7.599592208862305e-07, logit=7.84375, token_id=52466, metadata=None))), (16478, (1735, PredictedToken(token=' Chair', prob=1.9744038581848145e-07, logit=6.5, token_id=16478, metadata=None)))])\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.322, logit=20.125)', '\" Tablet\"[58403] (p=0.285, logit=20.000)', '\" The\"[578] (p=0.152, logit=19.375)', '\" A\"[362] (p=0.105, logit=19.000)', '\" Among\"[22395] (p=0.056, logit=18.375)']\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.322265625, logit=20.125, token_id=30616, metadata=None))), (58403, (2, PredictedToken(token=' Tablet', prob=0.28515625, logit=20.0, token_id=58403, metadata=None))), (426, (29, PredictedToken(token=' B', prob=0.00058746337890625, logit=13.8125, token_id=426, metadata=None))), (90538, (208, PredictedToken(token=' Caul', prob=1.1444091796875e-05, logit=9.875, token_id=90538, metadata=None))), (52466, (232, PredictedToken(token=' Warehouse', prob=8.881092071533203e-06, logit=9.625, token_id=52466, metadata=None))), (16478, (718, PredictedToken(token=' Chair', prob=1.4528632164001465e-06, logit=7.8125, token_id=16478, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:43 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:52:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.758, logit=22.250)', '\" The\"[578] (p=0.116, logit=20.375)', '\" A\"[362] (p=0.062, logit=19.750)', '\" Among\"[22395] (p=0.038, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     clean_prediction=['\" School\"[6150] (p=0.586, logit=21.000)', '\" None\"[2290] (p=0.314, logit=20.375)', '\" The\"[578] (p=0.026, logit=17.875)', '\" There\"[2684] (p=0.012, logit=17.125)', '\" Among\"[22395] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     clean_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.5859375, logit=21.0, token_id=6150, metadata=None))), (41493, (14, PredictedToken(token=' Tow', prob=0.001129150390625, logit=14.75, token_id=41493, metadata=None))), (55405, (21, PredictedToken(token=' Orch', prob=0.0006866455078125, logit=14.25, token_id=55405, metadata=None))), (6690, (33, PredictedToken(token=' Air', prob=0.0003452301025390625, logit=13.5625, token_id=6690, metadata=None))), (65197, (66, PredictedToken(token=' Surf', prob=9.870529174804688e-05, logit=12.3125, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     int_prediction=['\" Orch\"[55405] (p=0.484, logit=20.250)', '\" None\"[2290] (p=0.260, logit=19.625)', '\" An\"[1556] (p=0.095, logit=18.625)', '\" The\"[578] (p=0.051, logit=18.000)', '\" There\"[2684] (p=0.021, logit=17.125)']\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     int_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.484375, logit=20.25, token_id=55405, metadata=None))), (41493, (17, PredictedToken(token=' Tow', prob=0.0015411376953125, logit=14.5, token_id=41493, metadata=None))), (6150, (260, PredictedToken(token=' School', prob=1.0371208190917969e-05, logit=9.5, token_id=6150, metadata=None))), (6690, (345, PredictedToken(token=' Air', prob=6.288290023803711e-06, logit=9.0, token_id=6690, metadata=None))), (65197, (544, PredictedToken(token=' Surf', prob=3.159046173095703e-06, logit=8.3125, token_id=65197, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:44 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:44 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.926, logit=23.000)', '\" The\"[578] (p=0.028, logit=19.500)', '\" Among\"[22395] (p=0.012, logit=18.625)', '\" water\"[3090] (p=0.006, logit=18.000)', '\" A\"[362] (p=0.005, logit=17.750)']\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     clean_prediction=['\" Tomato\"[94091] (p=0.695, logit=21.125)', '\" None\"[2290] (p=0.176, logit=19.750)', '\" Bat\"[16488] (p=0.035, logit=18.125)', '\" The\"[578] (p=0.027, logit=17.875)', '\" A\"[362] (p=0.019, logit=17.500)']\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     clean_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.6953125, logit=21.125, token_id=94091, metadata=None))), (16488, (3, PredictedToken(token=' Bat', prob=0.03466796875, logit=18.125, token_id=16488, metadata=None))), (8325, (70, PredictedToken(token=' Apple', prob=7.581710815429688e-05, logit=12.0, token_id=8325, metadata=None)))])\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     int_prediction=['\" Tomato\"[94091] (p=0.594, logit=21.125)', '\" None\"[2290] (p=0.247, logit=20.250)', '\" Apple\"[8325] (p=0.062, logit=18.875)', '\" There\"[2684] (p=0.023, logit=17.875)', '\" The\"[578] (p=0.016, logit=17.500)']\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     int_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.59375, logit=21.125, token_id=94091, metadata=None))), (8325, (3, PredictedToken(token=' Apple', prob=0.0625, logit=18.875, token_id=8325, metadata=None))), (16488, (9, PredictedToken(token=' Bat', prob=0.0035247802734375, logit=16.0, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:45 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     patch_prediction=['\" Dolphin\"[96096] (p=0.906, logit=22.250)', '\" The\"[578] (p=0.035, logit=19.000)', '\" A\"[362] (p=0.015, logit=18.125)', '\" Among\"[22395] (p=0.013, logit=18.000)', '\" Option\"[7104] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     clean_prediction=['\" Mango\"[91963] (p=0.926, logit=23.000)', '\" The\"[578] (p=0.025, logit=19.375)', '\" Among\"[22395] (p=0.019, logit=19.125)', '\" Option\"[7104] (p=0.007, logit=18.125)', '\" (\"[320] (p=0.006, logit=18.000)']\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     clean_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.92578125, logit=23.0, token_id=91963, metadata=None))), (16488, (39, PredictedToken(token=' Bat', prob=8.344650268554688e-05, logit=13.6875, token_id=16488, metadata=None))), (1901, (41, PredictedToken(token=' Z', prob=6.914138793945312e-05, logit=13.5, token_id=1901, metadata=None)))])\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.797, logit=22.375)', '\" The\"[578] (p=0.065, logit=19.875)', '\" Z\"[1901] (p=0.058, logit=19.750)', '\" Among\"[22395] (p=0.027, logit=19.000)', '\" (\"[320] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.796875, logit=22.375, token_id=16488, metadata=None))), (1901, (3, PredictedToken(token=' Z', prob=0.057861328125, logit=19.75, token_id=1901, metadata=None))), (91963, (7, PredictedToken(token=' Mango', prob=0.00537109375, logit=17.375, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:45 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:52:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     patch_prediction=['\" Basketball\"[47589] (p=0.844, logit=21.750)', '\" The\"[578] (p=0.054, logit=19.000)', '\" Among\"[22395] (p=0.037, logit=18.625)', '\" A\"[362] (p=0.025, logit=18.250)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     clean_prediction=['\" Ottoman\"[70110] (p=0.887, logit=22.125)', '\" The\"[578] (p=0.044, logit=19.125)', '\" An\"[1556] (p=0.027, logit=18.625)', '\" Among\"[22395] (p=0.016, logit=18.125)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     clean_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.88671875, logit=22.125, token_id=70110, metadata=None))), (44570, (39, PredictedToken(token=' Maple', prob=0.00010967254638671875, logit=13.125, token_id=44570, metadata=None))), (22410, (76, PredictedToken(token=' Ju', prob=2.765655517578125e-05, logit=11.75, token_id=22410, metadata=None))), (10164, (171, PredictedToken(token=' Water', prob=5.811452865600586e-06, logit=10.1875, token_id=10164, metadata=None))), (16488, (207, PredictedToken(token=' Bat', prob=3.993511199951172e-06, logit=9.8125, token_id=16488, metadata=None)))])\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.848, logit=22.500)', '\" The\"[578] (p=0.054, logit=19.750)', '\" A\"[362] (p=0.029, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" Water\"[10164] (p=0.011, logit=18.125)']\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.84765625, logit=22.5, token_id=16488, metadata=None))), (10164, (5, PredictedToken(token=' Water', prob=0.01068115234375, logit=18.125, token_id=10164, metadata=None))), (22410, (33, PredictedToken(token=' Ju', prob=0.0001621246337890625, logit=13.9375, token_id=22410, metadata=None))), (44570, (827, PredictedToken(token=' Maple', prob=3.762543201446533e-07, logit=7.875, token_id=44570, metadata=None))), (70110, (3406, PredictedToken(token=' Ottoman', prob=4.936009645462036e-08, logit=5.84375, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:46 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:46 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:52:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     patch_prediction=['\" Keyboard\"[26698] (p=0.680, logit=21.000)', '\" The\"[578] (p=0.134, logit=19.375)', '\" Among\"[22395] (p=0.056, logit=18.500)', '\" A\"[362] (p=0.026, logit=17.750)', '\" keyboard\"[13939] (p=0.018, logit=17.375)']\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.836, logit=21.500)', '\" The\"[578] (p=0.061, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.250)', '\" A\"[362] (p=0.029, logit=18.125)', '\" MAP\"[28322] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.8359375, logit=21.5, token_id=44570, metadata=None))), (1050, (63, PredictedToken(token=' Re', prob=8.0108642578125e-05, logit=12.25, token_id=1050, metadata=None))), (63606, (325, PredictedToken(token=' Stap', prob=3.11434268951416e-06, logit=9.0, token_id=63606, metadata=None))), (18654, (519, PredictedToken(token=' Micro', prob=1.4677643775939941e-06, logit=8.25, token_id=18654, metadata=None))), (49431, (544, PredictedToken(token=' Rabbit', prob=1.3783574104309082e-06, logit=8.1875, token_id=49431, metadata=None))), (47589, (689, PredictedToken(token=' Basketball', prob=1.043081283569336e-06, logit=7.90625, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     int_prediction=['\" Maple\"[44570] (p=0.352, logit=20.125)', '\" Micro\"[18654] (p=0.213, logit=19.625)', '\" A\"[362] (p=0.188, logit=19.500)', '\" Stap\"[63606] (p=0.079, logit=18.625)', '\" The\"[578] (p=0.061, logit=18.375)']\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     int_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.3515625, logit=20.125, token_id=44570, metadata=None))), (18654, (2, PredictedToken(token=' Micro', prob=0.212890625, logit=19.625, token_id=18654, metadata=None))), (63606, (4, PredictedToken(token=' Stap', prob=0.07861328125, logit=18.625, token_id=63606, metadata=None))), (1050, (7, PredictedToken(token=' Re', prob=0.01361083984375, logit=16.875, token_id=1050, metadata=None))), (47589, (85, PredictedToken(token=' Basketball', prob=8.106231689453125e-05, logit=11.75, token_id=47589, metadata=None))), (49431, (1407, PredictedToken(token=' Rabbit', prob=6.593763828277588e-07, logit=6.9375, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:47 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.746, logit=22.250)', '\" A\"[362] (p=0.101, logit=20.250)', '\" The\"[578] (p=0.089, logit=20.125)', '\" Among\"[22395] (p=0.033, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.746, logit=21.375)', '\" A\"[362] (p=0.069, logit=19.000)', '\" The\"[578] (p=0.054, logit=18.750)', '\" Among\"[22395] (p=0.037, logit=18.375)', '\" None\"[2290] (p=0.023, logit=17.875)']\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.74609375, logit=21.375, token_id=16730, metadata=None))), (1050, (6, PredictedToken(token=' Re', prob=0.0198974609375, logit=17.75, token_id=1050, metadata=None))), (27217, (43, PredictedToken(token=' Train', prob=0.0002079010009765625, logit=13.1875, token_id=27217, metadata=None))), (86460, (127, PredictedToken(token=' Necklace', prob=1.9311904907226562e-05, logit=10.8125, token_id=86460, metadata=None))), (32749, (228, PredictedToken(token=' Carn', prob=7.569789886474609e-06, logit=9.875, token_id=32749, metadata=None)))])\n",
      "2025-09-16 09:52:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.855, logit=22.375)', '\" The\"[578] (p=0.048, logit=19.500)', '\" A\"[362] (p=0.048, logit=19.500)', '\" Among\"[22395] (p=0.014, logit=18.250)', '\" None\"[2290] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.85546875, logit=22.375, token_id=27217, metadata=None))), (1050, (20, PredictedToken(token=' Re', prob=0.000568389892578125, logit=15.0625, token_id=1050, metadata=None))), (16730, (173, PredictedToken(token=' Museum', prob=6.735324859619141e-06, logit=10.625, token_id=16730, metadata=None))), (32749, (1383, PredictedToken(token=' Carn', prob=2.0954757928848267e-07, logit=7.15625, token_id=32749, metadata=None))), (86460, (3129, PredictedToken(token=' Necklace', prob=6.379559636116028e-08, logit=5.96875, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:48 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:48 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     patch_prediction=['\" Speaker\"[30173] (p=0.840, logit=21.625)', '\" The\"[578] (p=0.037, logit=18.500)', '\" A\"[362] (p=0.029, logit=18.250)', '\" speaker\"[19114] (p=0.022, logit=18.000)', '\" (\"[320] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.871, logit=23.125)', '\" The\"[578] (p=0.056, logit=20.375)', '\" Among\"[22395] (p=0.034, logit=19.875)', '\" A\"[362] (p=0.016, logit=19.125)', '\" socks\"[40086] (p=0.004, logit=17.750)']\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.87109375, logit=23.125, token_id=328, metadata=None))), (11452, (9, PredictedToken(token=' Head', prob=0.00148773193359375, logit=16.75, token_id=11452, metadata=None))), (34046, (306, PredictedToken(token=' Cabinet', prob=8.754432201385498e-07, logit=9.3125, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     int_prediction=['\" Head\"[11452] (p=0.898, logit=22.500)', '\" The\"[578] (p=0.051, logit=19.625)', '\" headphones\"[44101] (p=0.013, logit=18.250)', '\" Among\"[22395] (p=0.009, logit=17.875)', '\" (\"[320] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     int_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.8984375, logit=22.5, token_id=11452, metadata=None))), (328, (6, PredictedToken(token=' S', prob=0.00286865234375, logit=16.75, token_id=328, metadata=None))), (34046, (17, PredictedToken(token=' Cabinet', prob=0.000637054443359375, logit=15.25, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:48 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:48 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:52:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.922, logit=22.875)', '\" Among\"[22395] (p=0.025, logit=19.250)', '\" The\"[578] (p=0.025, logit=19.250)', '\" A\"[362] (p=0.005, logit=17.625)', '\" (\"[320] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     clean_prediction=['\" Hat\"[22050] (p=0.734, logit=21.375)', '\" The\"[578] (p=0.088, logit=19.250)', '\" A\"[362] (p=0.077, logit=19.125)', '\" Among\"[22395] (p=0.037, logit=18.375)', '\" hat\"[9072] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     clean_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.734375, logit=21.375, token_id=22050, metadata=None))), (3816, (57, PredictedToken(token=' Red', prob=9.632110595703125e-05, logit=12.4375, token_id=3816, metadata=None))), (38571, (59, PredictedToken(token=' Theater', prob=9.632110595703125e-05, logit=12.4375, token_id=38571, metadata=None))), (45805, (495, PredictedToken(token=' Cherry', prob=1.7657876014709473e-06, logit=8.4375, token_id=45805, metadata=None)))])\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     int_prediction=['\" Cherry\"[45805] (p=0.680, logit=20.625)', '\" Red\"[3816] (p=0.172, logit=19.250)', '\" The\"[578] (p=0.049, logit=18.000)', '\" Among\"[22395] (p=0.021, logit=17.125)', '\" A\"[362] (p=0.011, logit=16.500)']\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     int_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.6796875, logit=20.625, token_id=45805, metadata=None))), (3816, (2, PredictedToken(token=' Red', prob=0.171875, logit=19.25, token_id=3816, metadata=None))), (38571, (6, PredictedToken(token=' Theater', prob=0.0096435546875, logit=16.375, token_id=38571, metadata=None))), (22050, (52, PredictedToken(token=' Hat', prob=0.0001888275146484375, logit=12.4375, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:49 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:49 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.551, logit=20.625)', '\" The\"[578] (p=0.158, logit=19.375)', '\" A\"[362] (p=0.123, logit=19.125)', '\" Among\"[22395] (p=0.075, logit=18.625)', '\" sheep\"[33012] (p=0.013, logit=16.875)']\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.918, logit=22.125)', '\" The\"[578] (p=0.017, logit=18.125)', '\" A\"[362] (p=0.013, logit=17.875)', '\" None\"[2290] (p=0.012, logit=17.750)', '\" Among\"[22395] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.91796875, logit=22.125, token_id=33711, metadata=None))), (24941, (6, PredictedToken(token=' Bear', prob=0.004241943359375, logit=16.75, token_id=24941, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.0029144287109375, logit=16.375, token_id=469, metadata=None))), (5340, (11, PredictedToken(token=' Har', prob=0.00146484375, logit=15.6875, token_id=5340, metadata=None))), (48390, (20, PredictedToken(token=' Lily', prob=0.000652313232421875, logit=14.875, token_id=48390, metadata=None)))])\n",
      "2025-09-16 09:52:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.902, logit=21.750)', '\" None\"[2290] (p=0.024, logit=18.125)', '\" The\"[578] (p=0.015, logit=17.625)', '\" There\"[2684] (p=0.008, logit=17.000)', '\" Suit\"[33711] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.90234375, logit=21.75, token_id=24941, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.006866455078125, logit=16.875, token_id=33711, metadata=None))), (5340, (10, PredictedToken(token=' Har', prob=0.0027008056640625, logit=15.9375, token_id=5340, metadata=None))), (48390, (15, PredictedToken(token=' Lily', prob=0.0013580322265625, logit=15.25, token_id=48390, metadata=None))), (469, (127, PredictedToken(token=' E', prob=2.193450927734375e-05, logit=11.125, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:50 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     patch_prediction=['\" B\"[426] (p=0.719, logit=21.875)', '\" b\"[293] (p=0.076, logit=19.625)', '\" A\"[362] (p=0.067, logit=19.500)', '\" The\"[578] (p=0.059, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=18.750)']\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     clean_prediction=['\" Microwave\"[98641] (p=0.883, logit=21.625)', '\" The\"[578] (p=0.039, logit=18.500)', '\" Among\"[22395] (p=0.023, logit=18.000)', '\" A\"[362] (p=0.009, logit=17.000)', '\" Ring\"[22249] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     clean_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.8828125, logit=21.625, token_id=98641, metadata=None))), (22249, (5, PredictedToken(token=' Ring', prob=0.004608154296875, logit=16.375, token_id=22249, metadata=None))), (26781, (23, PredictedToken(token=' Hair', prob=0.00058746337890625, logit=14.3125, token_id=26781, metadata=None))), (469, (31, PredictedToken(token=' E', prob=0.0003795623779296875, logit=13.875, token_id=469, metadata=None))), (38571, (729, PredictedToken(token=' Theater', prob=9.126961231231689e-07, logit=7.84375, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.906, logit=21.500)', '\" The\"[578] (p=0.021, logit=17.750)', '\" Among\"[22395] (p=0.011, logit=17.125)', '\" Option\"[7104] (p=0.009, logit=16.875)', '\" A\"[362] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.90625, logit=21.5, token_id=469, metadata=None))), (22249, (6, PredictedToken(token=' Ring', prob=0.006927490234375, logit=16.625, token_id=22249, metadata=None))), (38571, (20, PredictedToken(token=' Theater', prob=0.000881195068359375, logit=14.5625, token_id=38571, metadata=None))), (98641, (24, PredictedToken(token=' Microwave', prob=0.000499725341796875, logit=14.0, token_id=98641, metadata=None))), (26781, (239, PredictedToken(token=' Hair', prob=4.9173831939697266e-06, logit=9.375, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:50 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:50 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:52:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.785, logit=22.250)', '\" The\"[578] (p=0.094, logit=20.125)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.625)', '\" c\"[272] (p=0.014, logit=18.250)']\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     clean_prediction=['\" Phone\"[14642] (p=0.723, logit=21.500)', '\" The\"[578] (p=0.125, logit=19.750)', '\" Among\"[22395] (p=0.041, logit=18.625)', '\" A\"[362] (p=0.041, logit=18.625)', '\" phone\"[4641] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     clean_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.72265625, logit=21.5, token_id=14642, metadata=None))), (5340, (6, PredictedToken(token=' Har', prob=0.007080078125, logit=16.875, token_id=5340, metadata=None))), (32749, (212, PredictedToken(token=' Carn', prob=7.3015689849853516e-06, logit=10.0, token_id=32749, metadata=None))), (29318, (216, PredictedToken(token=' Dress', prob=6.884336471557617e-06, logit=9.9375, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.754, logit=21.625)', '\" Dress\"[29318] (p=0.070, logit=19.250)', '\" The\"[578] (p=0.055, logit=19.000)', '\" A\"[362] (p=0.055, logit=19.000)', '\" Among\"[22395] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.75390625, logit=21.625, token_id=5340, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.0703125, logit=19.25, token_id=29318, metadata=None))), (32749, (7, PredictedToken(token=' Carn', prob=0.00653076171875, logit=16.875, token_id=32749, metadata=None))), (14642, (38, PredictedToken(token=' Phone', prob=0.000209808349609375, logit=13.4375, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:51 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     patch_prediction=['\" Train\"[27217] (p=0.703, logit=22.000)', '\" The\"[578] (p=0.122, logit=20.250)', '\" A\"[362] (p=0.084, logit=19.875)', '\" Among\"[22395] (p=0.051, logit=19.375)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.840, logit=21.375)', '\" The\"[578] (p=0.042, logit=18.375)', '\" A\"[362] (p=0.029, logit=18.000)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" D\"[423] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.83984375, logit=21.375, token_id=47033, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.01055908203125, logit=17.0, token_id=423, metadata=None))), (40759, (14, PredictedToken(token=' Harmon', prob=0.00142669677734375, logit=15.0, token_id=40759, metadata=None))), (17929, (16, PredictedToken(token=' Pin', prob=0.00118255615234375, logit=14.8125, token_id=17929, metadata=None))), (36358, (21, PredictedToken(token=' Bench', prob=0.000675201416015625, logit=14.25, token_id=36358, metadata=None))), (70762, (34, PredictedToken(token=' Motorcycle', prob=0.000362396240234375, logit=13.625, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:52:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.957, logit=22.500)', '\" The\"[578] (p=0.011, logit=18.000)', '\" A\"[362] (p=0.005, logit=17.250)', '\" D\"[423] (p=0.004, logit=17.000)', '\" Motorola\"[63590] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.95703125, logit=22.5, token_id=70762, metadata=None))), (423, (4, PredictedToken(token=' D', prob=0.00390625, logit=17.0, token_id=423, metadata=None))), (47033, (13, PredictedToken(token=' Printer', prob=0.000820159912109375, logit=15.4375, token_id=47033, metadata=None))), (36358, (17, PredictedToken(token=' Bench', prob=0.0003414154052734375, logit=14.5625, token_id=36358, metadata=None))), (17929, (164, PredictedToken(token=' Pin', prob=4.291534423828125e-06, logit=10.1875, token_id=17929, metadata=None))), (40759, (2581, PredictedToken(token=' Harmon', prob=6.938353180885315e-08, logit=6.0625, token_id=40759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:52 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.852, logit=22.375)', '\" Among\"[22395] (p=0.070, logit=19.875)', '\" The\"[578] (p=0.054, logit=19.625)', '\" It\"[1102] (p=0.003, logit=16.750)', '\" Option\"[7104] (p=0.002, logit=16.500)']\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.785, logit=22.500)', '\" The\"[578] (p=0.121, logit=20.625)', '\" Among\"[22395] (p=0.027, logit=19.125)', '\" A\"[362] (p=0.024, logit=19.000)', '\" It\"[1102] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.78515625, logit=22.5, token_id=30555, metadata=None))), (393, (68, PredictedToken(token=' P', prob=2.956390380859375e-05, logit=12.3125, token_id=393, metadata=None))), (94091, (154, PredictedToken(token=' Tomato', prob=4.827976226806641e-06, logit=10.5, token_id=94091, metadata=None))), (37326, (189, PredictedToken(token=' Swe', prob=3.3229589462280273e-06, logit=10.125, token_id=37326, metadata=None)))])\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     int_prediction=['\" Tomato\"[94091] (p=0.330, logit=20.000)', '\" The\"[578] (p=0.258, logit=19.750)', '\" P\"[393] (p=0.138, logit=19.125)', '\" Among\"[22395] (p=0.083, logit=18.625)', '\" A\"[362] (p=0.051, logit=18.125)']\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     int_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.330078125, logit=20.0, token_id=94091, metadata=None))), (393, (3, PredictedToken(token=' P', prob=0.1376953125, logit=19.125, token_id=393, metadata=None))), (37326, (6, PredictedToken(token=' Swe', prob=0.027099609375, logit=17.5, token_id=37326, metadata=None))), (30555, (8, PredictedToken(token=' Viol', prob=0.0128173828125, logit=16.75, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:52 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:52 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:52:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     patch_prediction=['\" Razor\"[74968] (p=0.867, logit=21.750)', '\" A\"[362] (p=0.038, logit=18.625)', '\" The\"[578] (p=0.034, logit=18.500)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" (\"[320] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.852, logit=21.750)', '\" The\"[578] (p=0.037, logit=18.625)', '\" (\"[320] (p=0.026, logit=18.250)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" Option\"[7104] (p=0.020, logit=18.000)']\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.8515625, logit=21.75, token_id=82452, metadata=None))), (61731, (13, PredictedToken(token=' Soap', prob=0.00164031982421875, logit=15.5, token_id=61731, metadata=None))), (36943, (260, PredictedToken(token=' Folder', prob=3.814697265625e-06, logit=9.4375, token_id=36943, metadata=None)))])\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.949, logit=22.625)', '\" The\"[578] (p=0.011, logit=18.125)', '\" (\"[320] (p=0.011, logit=18.125)', '\" Folder\"[36943] (p=0.006, logit=17.625)', '\" Option\"[7104] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.94921875, logit=22.625, token_id=61731, metadata=None))), (36943, (4, PredictedToken(token=' Folder', prob=0.00640869140625, logit=17.625, token_id=36943, metadata=None))), (82452, (15, PredictedToken(token=' Jasmine', prob=0.0004634857177734375, logit=15.0, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:53 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.797, logit=22.875)', '\" The\"[578] (p=0.084, logit=20.625)', '\" A\"[362] (p=0.065, logit=20.375)', '\" Among\"[22395] (p=0.027, logit=19.500)', '\" It\"[1102] (p=0.004, logit=17.500)']\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.926, logit=22.625)', '\" The\"[578] (p=0.017, logit=18.625)', '\" Among\"[22395] (p=0.012, logit=18.250)', '\" A\"[362] (p=0.010, logit=18.125)', '\" (\"[320] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.92578125, logit=22.625, token_id=59825, metadata=None))), (6690, (9, PredictedToken(token=' Air', prob=0.00179290771484375, logit=16.375, token_id=6690, metadata=None))), (426, (17, PredictedToken(token=' B', prob=0.000545501708984375, logit=15.1875, token_id=426, metadata=None)))])\n",
      "2025-09-16 09:52:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.953, logit=23.250)', '\" airplane\"[44024] (p=0.014, logit=19.000)', '\" The\"[578] (p=0.008, logit=18.500)', '\" An\"[1556] (p=0.003, logit=17.625)', '\" (\"[320] (p=0.003, logit=17.500)']\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.953125, logit=23.25, token_id=6690, metadata=None))), (59825, (13, PredictedToken(token=' Tie', prob=0.000675201416015625, logit=16.0, token_id=59825, metadata=None))), (426, (58, PredictedToken(token=' B', prob=2.7894973754882812e-05, logit=12.8125, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:54 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     patch_prediction=['\" Sink\"[57551] (p=0.852, logit=21.375)', '\" The\"[578] (p=0.048, logit=18.500)', '\" A\"[362] (p=0.029, logit=18.000)', '\" Among\"[22395] (p=0.018, logit=17.500)', '\" S\"[328] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     clean_prediction=['\" Dog\"[14588] (p=0.711, logit=21.750)', '\" The\"[578] (p=0.096, logit=19.750)', '\" A\"[362] (p=0.075, logit=19.500)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" B\"[426] (p=0.028, logit=18.500)']\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     clean_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.7109375, logit=21.75, token_id=14588, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.027587890625, logit=18.5, token_id=426, metadata=None))), (921, (78, PredictedToken(token=' Ch', prob=3.886222839355469e-05, logit=11.9375, token_id=921, metadata=None))), (31181, (229, PredictedToken(token=' Clar', prob=4.351139068603516e-06, logit=9.75, token_id=31181, metadata=None))), (82994, (300, PredictedToken(token=' Toilet', prob=2.4884939193725586e-06, logit=9.1875, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.467, logit=20.750)', '\" B\"[426] (p=0.320, logit=20.375)', '\" The\"[578] (p=0.063, logit=18.750)', '\" A\"[362] (p=0.049, logit=18.500)', '\" Among\"[22395] (p=0.034, logit=18.125)']\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.466796875, logit=20.75, token_id=82994, metadata=None))), (426, (2, PredictedToken(token=' B', prob=0.3203125, logit=20.375, token_id=426, metadata=None))), (14588, (15, PredictedToken(token=' Dog', prob=0.00122833251953125, logit=14.8125, token_id=14588, metadata=None))), (921, (35, PredictedToken(token=' Ch', prob=0.0002918243408203125, logit=13.375, token_id=921, metadata=None))), (31181, (304, PredictedToken(token=' Clar', prob=4.708766937255859e-06, logit=9.25, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:54 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:52:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     patch_prediction=['\" Drum\"[46506] (p=0.680, logit=21.375)', '\" The\"[578] (p=0.151, logit=19.875)', '\" A\"[362] (p=0.072, logit=19.125)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" It\"[1102] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.793, logit=20.750)', '\" Gloves\"[68554] (p=0.057, logit=18.125)', '\" Plum\"[84409] (p=0.040, logit=17.750)', '\" None\"[2290] (p=0.027, logit=17.375)', '\" The\"[578] (p=0.021, logit=17.125)']\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.79296875, logit=20.75, token_id=432, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.057373046875, logit=18.125, token_id=68554, metadata=None))), (84409, (3, PredictedToken(token=' Plum', prob=0.03955078125, logit=17.75, token_id=84409, metadata=None))), (3420, (10, PredictedToken(token=' Trump', prob=0.002685546875, logit=15.0625, token_id=3420, metadata=None))), (87035, (133, PredictedToken(token=' Onion', prob=3.3855438232421875e-05, logit=10.6875, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.906, logit=22.000)', '\" Plum\"[84409] (p=0.051, logit=19.125)', '\" The\"[578] (p=0.011, logit=17.625)', '\" None\"[2290] (p=0.009, logit=17.375)', '\" A\"[362] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.90625, logit=22.0, token_id=432, metadata=None))), (84409, (2, PredictedToken(token=' Plum', prob=0.051025390625, logit=19.125, token_id=84409, metadata=None))), (3420, (12, PredictedToken(token=' Trump', prob=0.000823974609375, logit=15.0, token_id=3420, metadata=None))), (68554, (13, PredictedToken(token=' Gloves', prob=0.000823974609375, logit=15.0, token_id=68554, metadata=None))), (87035, (75, PredictedToken(token=' Onion', prob=2.8252601623535156e-05, logit=11.625, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:55 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.789, logit=22.250)', '\" The\"[578] (p=0.073, logit=19.875)', '\" A\"[362] (p=0.057, logit=19.625)', '\" Among\"[22395] (p=0.050, logit=19.500)', '\" jacket\"[27300] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:52:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.785, logit=20.875)', '\" The\"[578] (p=0.083, logit=18.625)', '\" A\"[362] (p=0.030, logit=17.625)', '\" Among\"[22395] (p=0.021, logit=17.250)', '\" It\"[1102] (p=0.007, logit=16.125)']\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.78515625, logit=20.875, token_id=67629, metadata=None))), (46506, (9, PredictedToken(token=' Drum', prob=0.00439453125, logit=15.6875, token_id=46506, metadata=None))), (469, (18, PredictedToken(token=' E', prob=0.001251220703125, logit=14.4375, token_id=469, metadata=None))), (4923, (31, PredictedToken(token=' Sk', prob=0.000713348388671875, logit=13.875, token_id=4923, metadata=None)))])\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.648, logit=20.625)', '\" The\"[578] (p=0.100, logit=18.750)', '\" Helmet\"[67629] (p=0.078, logit=18.500)', '\" A\"[362] (p=0.042, logit=17.875)', '\" Among\"[22395] (p=0.025, logit=17.375)']\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.6484375, logit=20.625, token_id=4923, metadata=None))), (67629, (3, PredictedToken(token=' Helmet', prob=0.07763671875, logit=18.5, token_id=67629, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.022216796875, logit=17.25, token_id=469, metadata=None))), (46506, (18, PredictedToken(token=' Drum', prob=0.00160980224609375, logit=14.625, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:56 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:56 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.859, logit=22.375)', '\" A\"[362] (p=0.055, logit=19.625)', '\" The\"[578] (p=0.049, logit=19.500)', '\" Among\"[22395] (p=0.014, logit=18.250)', '\" MOS\"[74174] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.730, logit=21.750)', '\" The\"[578] (p=0.087, logit=19.625)', '\" A\"[362] (p=0.087, logit=19.625)', '\" Among\"[22395] (p=0.047, logit=19.000)', '\" tractor\"[59785] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.73046875, logit=21.75, token_id=1183, metadata=None))), (469, (12, PredictedToken(token=' E', prob=0.0021820068359375, logit=15.9375, token_id=469, metadata=None))), (24423, (76, PredictedToken(token=' Monitor', prob=4.5299530029296875e-05, logit=12.0625, token_id=24423, metadata=None))), (14588, (236, PredictedToken(token=' Dog', prob=3.9637088775634766e-06, logit=9.625, token_id=14588, metadata=None))), (38673, (420, PredictedToken(token=' Yoga', prob=1.1324882507324219e-06, logit=8.375, token_id=38673, metadata=None))), (9441, (624, PredictedToken(token=' Church', prob=6.444752216339111e-07, logit=7.8125, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.648, logit=21.125)', '\" The\"[578] (p=0.100, logit=19.250)', '\" A\"[362] (p=0.100, logit=19.250)', '\" E\"[469] (p=0.042, logit=18.375)', '\" Among\"[22395] (p=0.029, logit=18.000)']\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.6484375, logit=21.125, token_id=9441, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.04150390625, logit=18.375, token_id=469, metadata=None))), (14588, (6, PredictedToken(token=' Dog', prob=0.010498046875, logit=17.0, token_id=14588, metadata=None))), (1183, (26, PredictedToken(token=' Tr', prob=0.0008087158203125, logit=14.4375, token_id=1183, metadata=None))), (38673, (32, PredictedToken(token=' Yoga', prob=0.000713348388671875, logit=14.3125, token_id=38673, metadata=None))), (24423, (89, PredictedToken(token=' Monitor', prob=5.8650970458984375e-05, logit=11.8125, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:56 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:52:56 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:52:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.762, logit=21.625)', '\" The\"[578] (p=0.071, logit=19.250)', '\" A\"[362] (p=0.049, logit=18.875)', '\" None\"[2290] (p=0.038, logit=18.625)', '\" Among\"[22395] (p=0.030, logit=18.375)']\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.820, logit=21.875)', '\" The\"[578] (p=0.067, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.625)', '\" Only\"[8442] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.8203125, logit=21.875, token_id=38930, metadata=None))), (18787, (54, PredictedToken(token=' Oak', prob=8.392333984375e-05, logit=12.6875, token_id=18787, metadata=None))), (69755, (172, PredictedToken(token=' Notebook', prob=6.467103958129883e-06, logit=10.125, token_id=69755, metadata=None))), (34046, (307, PredictedToken(token=' Cabinet', prob=2.1010637283325195e-06, logit=9.0, token_id=34046, metadata=None))), (15429, (390, PredictedToken(token=' Hospital', prob=1.3560056686401367e-06, logit=8.5625, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     int_prediction=['\" Cabinet\"[34046] (p=0.789, logit=21.500)', '\" Hospital\"[15429] (p=0.064, logit=19.000)', '\" None\"[2290] (p=0.035, logit=18.375)', '\" The\"[578] (p=0.031, logit=18.250)', '\" A\"[362] (p=0.016, logit=17.625)']\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     int_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.7890625, logit=21.5, token_id=34046, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.064453125, logit=19.0, token_id=15429, metadata=None))), (18787, (33, PredictedToken(token=' Oak', prob=0.000385284423828125, logit=13.875, token_id=18787, metadata=None))), (38930, (66, PredictedToken(token=' Bike', prob=6.29425048828125e-05, logit=12.0625, token_id=38930, metadata=None))), (69755, (385, PredictedToken(token=' Notebook', prob=2.1457672119140625e-06, logit=8.6875, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:52:57 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:52:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     patch_prediction=['\" Har\"[5340] (p=0.805, logit=22.000)', '\" The\"[578] (p=0.096, logit=19.875)', '\" A\"[362] (p=0.031, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=18.500)', '\" It\"[1102] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     clean_prediction=['\" Bench\"[36358] (p=0.758, logit=21.875)', '\" The\"[578] (p=0.080, logit=19.625)', '\" A\"[362] (p=0.080, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=18.875)', '\" B\"[426] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     clean_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.7578125, logit=21.875, token_id=36358, metadata=None))), (1183, (22, PredictedToken(token=' Tr', prob=0.000392913818359375, logit=14.3125, token_id=1183, metadata=None))), (445, (29, PredictedToken(token=' L', prob=0.000270843505859375, logit=13.9375, token_id=445, metadata=None))), (1630, (36, PredictedToken(token=' X', prob=0.00017452239990234375, logit=13.5, token_id=1630, metadata=None))), (8868, (164, PredictedToken(token=' Blue', prob=7.212162017822266e-06, logit=10.3125, token_id=8868, metadata=None))), (91782, (578, PredictedToken(token=' Shorts', prob=9.164214134216309e-07, logit=8.25, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.727, logit=21.750)', '\" The\"[578] (p=0.098, logit=19.750)', '\" A\"[362] (p=0.076, logit=19.500)', '\" Among\"[22395] (p=0.046, logit=19.000)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.7265625, logit=21.75, token_id=1630, metadata=None))), (445, (9, PredictedToken(token=' L', prob=0.00335693359375, logit=16.375, token_id=445, metadata=None))), (8868, (19, PredictedToken(token=' Blue', prob=0.0009613037109375, logit=15.125, token_id=8868, metadata=None))), (36358, (28, PredictedToken(token=' Bench', prob=0.000400543212890625, logit=14.25, token_id=36358, metadata=None))), (1183, (38, PredictedToken(token=' Tr', prob=0.00024318695068359375, logit=13.75, token_id=1183, metadata=None))), (91782, (373, PredictedToken(token=' Shorts', prob=1.5422701835632324e-06, logit=8.6875, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:58 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:52:58 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.859, logit=22.125)', '\" The\"[578] (p=0.049, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.625)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.824, logit=22.250)', '\" The\"[578] (p=0.067, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=19.125)', '\" A\"[362] (p=0.032, logit=19.000)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.82421875, logit=22.25, token_id=38930, metadata=None))), (16488, (18, PredictedToken(token=' Bat', prob=0.000514984130859375, logit=14.875, token_id=16488, metadata=None))), (61948, (216, PredictedToken(token=' Sofa', prob=2.8759241104125977e-06, logit=9.6875, token_id=61948, metadata=None))), (26698, (462, PredictedToken(token=' Keyboard', prob=7.301568984985352e-07, logit=8.3125, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:52:58 src.selection.optimization INFO     int_prediction=['\" Sofa\"[61948] (p=0.486, logit=20.000)', '\" The\"[578] (p=0.202, logit=19.125)', '\" A\"[362] (p=0.139, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=17.000)', '\" It\"[1102] (p=0.019, logit=16.750)']\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     int_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.486328125, logit=20.0, token_id=61948, metadata=None))), (38930, (7, PredictedToken(token=' Bike', prob=0.01141357421875, logit=16.25, token_id=38930, metadata=None))), (26698, (15, PredictedToken(token=' Keyboard', prob=0.00347900390625, logit=15.0625, token_id=26698, metadata=None))), (16488, (234, PredictedToken(token=' Bat', prob=1.424551010131836e-05, logit=9.5625, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:52:59 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:52:59 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     patch_prediction=['\" Bamboo\"[98028] (p=0.699, logit=20.750)', '\" None\"[2290] (p=0.200, logit=19.500)', '\" The\"[578] (p=0.019, logit=17.125)', '\" Spin\"[41785] (p=0.011, logit=16.625)', '\" There\"[2684] (p=0.011, logit=16.625)']\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.902, logit=22.375)', '\" The\"[578] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.625)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" horse\"[15580] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.90234375, logit=22.375, token_id=34392, metadata=None))), (42609, (17, PredictedToken(token=' Pine', prob=0.000530242919921875, logit=14.9375, token_id=42609, metadata=None))), (38258, (77, PredictedToken(token=' Baseball', prob=2.3365020751953125e-05, logit=11.8125, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:52:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.730, logit=21.125)', '\" Pine\"[42609] (p=0.145, logit=19.500)', '\" The\"[578] (p=0.032, logit=18.000)', '\" Among\"[22395] (p=0.015, logit=17.250)', '\" horse\"[15580] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.73046875, logit=21.125, token_id=34392, metadata=None))), (42609, (2, PredictedToken(token=' Pine', prob=0.14453125, logit=19.5, token_id=42609, metadata=None))), (38258, (27, PredictedToken(token=' Baseball', prob=0.0006256103515625, logit=14.0625, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:00 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.742, logit=20.250)', '\" The\"[578] (p=0.078, logit=18.000)', '\" A\"[362] (p=0.061, logit=17.750)', '\" Among\"[22395] (p=0.022, logit=16.750)', '\" Note\"[7181] (p=0.015, logit=16.375)']\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.586, logit=20.750)', '\" The\"[578] (p=0.190, logit=19.625)', '\" A\"[362] (p=0.080, logit=18.750)', '\" Among\"[22395] (p=0.070, logit=18.625)', '\" It\"[1102] (p=0.016, logit=17.125)']\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.5859375, logit=20.75, token_id=94467, metadata=None))), (86460, (28, PredictedToken(token=' Necklace', prob=0.0005035400390625, logit=13.6875, token_id=86460, metadata=None))), (432, (38, PredictedToken(token=' R', prob=0.000286102294921875, logit=13.125, token_id=432, metadata=None))), (52466, (653, PredictedToken(token=' Warehouse', prob=1.5050172805786133e-06, logit=7.875, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.746, logit=21.875)', '\" The\"[578] (p=0.089, logit=19.750)', '\" A\"[362] (p=0.079, logit=19.625)', '\" Among\"[22395] (p=0.042, logit=19.000)', '\" Necklace\"[86460] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.74609375, logit=21.875, token_id=432, metadata=None))), (86460, (5, PredictedToken(token=' Necklace', prob=0.007293701171875, logit=17.25, token_id=86460, metadata=None))), (94467, (12, PredictedToken(token=' Trom', prob=0.0012664794921875, logit=15.5, token_id=94467, metadata=None))), (52466, (59, PredictedToken(token=' Warehouse', prob=6.29425048828125e-05, logit=12.5, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:00 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:00 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:53:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.809, logit=22.500)', '\" The\"[578] (p=0.109, logit=20.500)', '\" A\"[362] (p=0.031, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=18.875)', '\" Option\"[7104] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     clean_prediction=['\" Lav\"[43950] (p=0.836, logit=21.500)', '\" The\"[578] (p=0.069, logit=19.000)', '\" Among\"[22395] (p=0.047, logit=18.625)', '\" lavender\"[81460] (p=0.005, logit=16.375)', '\" Option\"[7104] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     clean_track=OrderedDict([(43950, (1, PredictedToken(token=' Lav', prob=0.8359375, logit=21.5, token_id=43950, metadata=None))), (59825, (39, PredictedToken(token=' Tie', prob=0.00017070770263671875, logit=13.0, token_id=59825, metadata=None))), (31181, (151, PredictedToken(token=' Clar', prob=1.233816146850586e-05, logit=10.375, token_id=31181, metadata=None))), (34046, (273, PredictedToken(token=' Cabinet', prob=4.26173210144043e-06, logit=9.3125, token_id=34046, metadata=None))), (23462, (583, PredictedToken(token=' Stadium', prob=1.385807991027832e-06, logit=8.1875, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.812, logit=21.250)', '\" The\"[578] (p=0.059, logit=18.625)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" A\"[362] (p=0.025, logit=17.750)', '\" None\"[2290] (p=0.017, logit=17.375)']\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.8125, logit=21.25, token_id=31181, metadata=None))), (34046, (6, PredictedToken(token=' Cabinet', prob=0.01019287109375, logit=16.875, token_id=34046, metadata=None))), (23462, (14, PredictedToken(token=' Stadium', prob=0.00147247314453125, logit=14.9375, token_id=23462, metadata=None))), (59825, (63, PredictedToken(token=' Tie', prob=0.00012874603271484375, logit=12.5, token_id=59825, metadata=None))), (43950, (291, PredictedToken(token=' Lav', prob=4.976987838745117e-06, logit=9.25, token_id=43950, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:01 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:01 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.938, logit=22.250)', '\" The\"[578] (p=0.020, logit=18.375)', '\" Among\"[22395] (p=0.006, logit=17.250)', '\" football\"[9141] (p=0.005, logit=17.000)', '\" Option\"[7104] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:53:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.812, logit=22.875)', '\" A\"[362] (p=0.076, logit=20.500)', '\" The\"[578] (p=0.067, logit=20.375)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" It\"[1102] (p=0.003, logit=17.375)']\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.8125, logit=22.875, token_id=6031, metadata=None))), (57094, (23, PredictedToken(token=' Highlight', prob=0.00019931793212890625, logit=14.5625, token_id=57094, metadata=None))), (97796, (149, PredictedToken(token=' Skate', prob=3.904104232788086e-06, logit=10.625, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.652, logit=21.750)', '\" A\"[362] (p=0.113, logit=20.000)', '\" Bro\"[6031] (p=0.088, logit=19.750)', '\" The\"[578] (p=0.078, logit=19.625)', '\" Among\"[22395] (p=0.020, logit=18.250)']\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.65234375, logit=21.75, token_id=97796, metadata=None))), (6031, (3, PredictedToken(token=' Bro', prob=0.08837890625, logit=19.75, token_id=6031, metadata=None))), (57094, (6, PredictedToken(token=' Highlight', prob=0.019775390625, logit=18.25, token_id=57094, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:02 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:02 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.820, logit=21.750)', '\" The\"[578] (p=0.076, logit=19.375)', '\" A\"[362] (p=0.041, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=18.250)', '\" stap\"[36114] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.879, logit=23.000)', '\" The\"[578] (p=0.044, logit=20.000)', '\" A\"[362] (p=0.044, logit=20.000)', '\" Among\"[22395] (p=0.014, logit=18.875)', '\" necklace\"[55547] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.87890625, logit=23.0, token_id=86460, metadata=None))), (432, (24, PredictedToken(token=' R', prob=0.00015735626220703125, logit=14.375, token_id=432, metadata=None))), (19111, (79, PredictedToken(token=' Bus', prob=1.7642974853515625e-05, logit=12.1875, token_id=19111, metadata=None)))])\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.867, logit=22.875)', '\" The\"[578] (p=0.043, logit=19.875)', '\" A\"[362] (p=0.038, logit=19.750)', '\" R\"[432] (p=0.014, logit=18.750)', '\" Among\"[22395] (p=0.012, logit=18.625)']\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.8671875, logit=22.875, token_id=19111, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.01397705078125, logit=18.75, token_id=432, metadata=None))), (86460, (111, PredictedToken(token=' Necklace', prob=1.1265277862548828e-05, logit=11.625, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:02 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.605, logit=20.375)', '\" Among\"[22395] (p=0.082, logit=18.375)', '\" The\"[578] (p=0.072, logit=18.250)', '\" A\"[362] (p=0.056, logit=18.000)', '\" Skate\"[97796] (p=0.034, logit=17.500)']\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.609, logit=21.875)', '\" The\"[578] (p=0.175, logit=20.625)', '\" A\"[362] (p=0.094, logit=20.000)', '\" Among\"[22395] (p=0.064, logit=19.625)', '\" Bus\"[19111] (p=0.018, logit=18.375)']\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.609375, logit=21.875, token_id=55807, metadata=None))), (19111, (5, PredictedToken(token=' Bus', prob=0.0184326171875, logit=18.375, token_id=19111, metadata=None))), (8868, (138, PredictedToken(token=' Blue', prob=1.0848045349121094e-05, logit=10.9375, token_id=8868, metadata=None))), (36845, (163, PredictedToken(token=' Tiger', prob=7.450580596923828e-06, logit=10.5625, token_id=36845, metadata=None))), (8219, (205, PredictedToken(token=' Sun', prob=4.827976226806641e-06, logit=10.125, token_id=8219, metadata=None)))])\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.637, logit=21.875)', '\" The\"[578] (p=0.161, logit=20.500)', '\" Tiger\"[36845] (p=0.076, logit=19.750)', '\" Among\"[22395] (p=0.067, logit=19.625)', '\" A\"[362] (p=0.022, logit=18.500)']\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.63671875, logit=21.875, token_id=19111, metadata=None))), (36845, (3, PredictedToken(token=' Tiger', prob=0.076171875, logit=19.75, token_id=36845, metadata=None))), (8219, (10, PredictedToken(token=' Sun', prob=0.00139617919921875, logit=15.75, token_id=8219, metadata=None))), (55807, (34, PredictedToken(token=' Shirt', prob=0.000213623046875, logit=13.875, token_id=55807, metadata=None))), (8868, (290, PredictedToken(token=' Blue', prob=2.682209014892578e-06, logit=9.5, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:03 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:03 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.879, logit=22.750)', '\" The\"[578] (p=0.039, logit=19.625)', '\" A\"[362] (p=0.023, logit=19.125)', '\" Among\"[22395] (p=0.018, logit=18.875)', '\" (\"[320] (p=0.008, logit=18.000)']\n",
      "2025-09-16 09:53:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.891, logit=22.250)', '\" The\"[578] (p=0.031, logit=18.875)', '\" Option\"[7104] (p=0.016, logit=18.250)', '\" A\"[362] (p=0.016, logit=18.250)', '\" Among\"[22395] (p=0.014, logit=18.125)']\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.890625, logit=22.25, token_id=33578, metadata=None))), (6914, (14, PredictedToken(token=' Let', prob=0.000812530517578125, logit=15.25, token_id=6914, metadata=None))), (48035, (18, PredictedToken(token=' Gir', prob=0.000492095947265625, logit=14.75, token_id=48035, metadata=None)))])\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     int_prediction=['\" Gir\"[48035] (p=0.863, logit=21.750)', '\" The\"[578] (p=0.038, logit=18.625)', '\" A\"[362] (p=0.038, logit=18.625)', '\" Option\"[7104] (p=0.012, logit=17.500)', '\" (\"[320] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     int_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.86328125, logit=21.75, token_id=48035, metadata=None))), (6914, (8, PredictedToken(token=' Let', prob=0.0035247802734375, logit=16.25, token_id=6914, metadata=None))), (33578, (22, PredictedToken(token=' Palm', prob=0.0004482269287109375, logit=14.1875, token_id=33578, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:04 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:04 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     patch_prediction=['\" Scar\"[30760] (p=0.523, logit=21.000)', '\" The\"[578] (p=0.149, logit=19.750)', '\" A\"[362] (p=0.132, logit=19.625)', '\" Among\"[22395] (p=0.117, logit=19.500)', '\" scarf\"[68371] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.684, logit=20.875)', '\" Among\"[22395] (p=0.135, logit=19.250)', '\" The\"[578] (p=0.092, logit=18.875)', '\" Option\"[7104] (p=0.013, logit=16.875)', '\" It\"[1102] (p=0.013, logit=16.875)']\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.68359375, logit=20.875, token_id=88088, metadata=None))), (90538, (12, PredictedToken(token=' Caul', prob=0.00262451171875, logit=15.3125, token_id=90538, metadata=None))), (11896, (75, PredictedToken(token=' Library', prob=6.961822509765625e-05, logit=11.6875, token_id=11896, metadata=None))), (55807, (419, PredictedToken(token=' Shirt', prob=3.069639205932617e-06, logit=8.5625, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.812, logit=21.500)', '\" The\"[578] (p=0.052, logit=18.750)', '\" A\"[362] (p=0.041, logit=18.500)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" Option\"[7104] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.8125, logit=21.5, token_id=55807, metadata=None))), (90538, (8, PredictedToken(token=' Caul', prob=0.004852294921875, logit=16.375, token_id=90538, metadata=None))), (88088, (97, PredictedToken(token=' Birch', prob=3.695487976074219e-05, logit=11.5, token_id=88088, metadata=None))), (11896, (106, PredictedToken(token=' Library', prob=3.266334533691406e-05, logit=11.375, token_id=11896, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:04 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:04 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-16 09:53:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.758, logit=22.000)', '\" The\"[578] (p=0.070, logit=19.625)', '\" A\"[362] (p=0.070, logit=19.625)', '\" Among\"[22395] (p=0.048, logit=19.250)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.855, logit=22.250)', '\" The\"[578] (p=0.048, logit=19.375)', '\" A\"[362] (p=0.023, logit=18.625)', '\" Among\"[22395] (p=0.020, logit=18.500)', '\" dress\"[8679] (p=0.014, logit=18.125)']\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.85546875, logit=22.25, token_id=29318, metadata=None))), (445, (16, PredictedToken(token=' L', prob=0.00083160400390625, logit=15.3125, token_id=445, metadata=None))), (45805, (61, PredictedToken(token=' Cherry', prob=4.696846008300781e-05, logit=12.4375, token_id=45805, metadata=None))), (98028, (75, PredictedToken(token=' Bamboo', prob=3.218650817871094e-05, logit=12.0625, token_id=98028, metadata=None)))])\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     int_prediction=['\" Bamboo\"[98028] (p=0.520, logit=19.875)', '\" L\"[445] (p=0.246, logit=19.125)', '\" None\"[2290] (p=0.048, logit=17.500)', '\" The\"[578] (p=0.048, logit=17.500)', '\" (\"[320] (p=0.012, logit=16.125)']\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     int_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.51953125, logit=19.875, token_id=98028, metadata=None))), (445, (2, PredictedToken(token=' L', prob=0.24609375, logit=19.125, token_id=445, metadata=None))), (45805, (12, PredictedToken(token=' Cherry', prob=0.004241943359375, logit=15.0625, token_id=45805, metadata=None))), (29318, (14, PredictedToken(token=' Dress', prob=0.00372314453125, logit=14.9375, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:05 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:05 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     patch_prediction=['\" Potato\"[78703] (p=0.719, logit=22.125)', '\" The\"[578] (p=0.125, logit=20.375)', '\" Among\"[22395] (p=0.067, logit=19.750)', '\" A\"[362] (p=0.059, logit=19.625)', '\" Pot\"[14020] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:53:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.793, logit=21.500)', '\" The\"[578] (p=0.095, logit=19.375)', '\" Among\"[22395] (p=0.039, logit=18.500)', '\" Motorcycle\"[70762] (p=0.010, logit=17.125)', '\" headphones\"[44101] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.79296875, logit=21.5, token_id=11452, metadata=None))), (70762, (4, PredictedToken(token=' Motorcycle', prob=0.00994873046875, logit=17.125, token_id=70762, metadata=None))), (55405, (247, PredictedToken(token=' Orch', prob=6.258487701416016e-06, logit=9.75, token_id=55405, metadata=None))), (29318, (438, PredictedToken(token=' Dress', prob=2.0265579223632812e-06, logit=8.625, token_id=29318, metadata=None))), (90538, (630, PredictedToken(token=' Caul', prob=1.0505318641662598e-06, logit=7.96875, token_id=90538, metadata=None))), (36845, (731, PredictedToken(token=' Tiger', prob=8.195638656616211e-07, logit=7.71875, token_id=36845, metadata=None)))])\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     int_prediction=['\" Caul\"[90538] (p=0.953, logit=22.375)', '\" The\"[578] (p=0.025, logit=18.750)', '\" Among\"[22395] (p=0.004, logit=17.000)', '\" It\"[1102] (p=0.002, logit=15.938)', '\" (\"[320] (p=0.001, logit=15.750)']\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     int_track=OrderedDict([(90538, (1, PredictedToken(token=' Caul', prob=0.953125, logit=22.375, token_id=90538, metadata=None))), (55405, (21, PredictedToken(token=' Orch', prob=0.000171661376953125, logit=13.75, token_id=55405, metadata=None))), (11452, (117, PredictedToken(token=' Head', prob=7.063150405883789e-06, logit=10.5625, token_id=11452, metadata=None))), (29318, (137, PredictedToken(token=' Dress', prob=5.513429641723633e-06, logit=10.3125, token_id=29318, metadata=None))), (36845, (183, PredictedToken(token=' Tiger', prob=3.337860107421875e-06, logit=9.8125, token_id=36845, metadata=None))), (70762, (404, PredictedToken(token=' Motorcycle', prob=9.5367431640625e-07, logit=8.5625, token_id=70762, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:06 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.559, logit=20.500)', '\" The\"[578] (p=0.160, logit=19.250)', '\" Among\"[22395] (p=0.110, logit=18.875)', '\" A\"[362] (p=0.066, logit=18.375)', '\" Option\"[7104] (p=0.012, logit=16.625)']\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.816, logit=21.875)', '\" An\"[1556] (p=0.041, logit=18.875)', '\" The\"[578] (p=0.041, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" None\"[2290] (p=0.025, logit=18.375)']\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.81640625, logit=21.875, token_id=53889, metadata=None))), (30173, (19, PredictedToken(token=' Speaker', prob=0.00084686279296875, logit=15.0, token_id=30173, metadata=None))), (14588, (103, PredictedToken(token=' Dog', prob=2.5510787963867188e-05, logit=11.5, token_id=14588, metadata=None))), (87035, (380, PredictedToken(token=' Onion', prob=2.2351741790771484e-06, logit=9.0625, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.770, logit=21.625)', '\" The\"[578] (p=0.063, logit=19.125)', '\" A\"[362] (p=0.056, logit=19.000)', '\" Onion\"[87035] (p=0.026, logit=18.250)', '\" None\"[2290] (p=0.014, logit=17.625)']\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.76953125, logit=21.625, token_id=14588, metadata=None))), (87035, (4, PredictedToken(token=' Onion', prob=0.0263671875, logit=18.25, token_id=87035, metadata=None))), (53889, (49, PredictedToken(token=' Apartment', prob=0.00020122528076171875, logit=13.375, token_id=53889, metadata=None))), (30173, (678, PredictedToken(token=' Speaker', prob=1.125037670135498e-06, logit=8.1875, token_id=30173, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:06 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:06 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.891, logit=22.125)', '\" None\"[2290] (p=0.044, logit=19.125)', '\" The\"[578] (p=0.011, logit=17.750)', '\" A\"[362] (p=0.011, logit=17.750)', '\" school\"[2978] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.914, logit=22.625)', '\" The\"[578] (p=0.028, logit=19.125)', '\" A\"[362] (p=0.021, logit=18.875)', '\" projector\"[69085] (p=0.005, logit=17.500)', '\" (\"[320] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.9140625, logit=22.625, token_id=5907, metadata=None))), (13000, (97, PredictedToken(token=' Van', prob=1.2695789337158203e-05, logit=11.4375, token_id=13000, metadata=None))), (52466, (208, PredictedToken(token=' Warehouse', prob=3.0100345611572266e-06, logit=10.0, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     int_prediction=['\" Warehouse\"[52466] (p=0.613, logit=21.500)', '\" Van\"[13000] (p=0.256, logit=20.625)', '\" The\"[578] (p=0.039, logit=18.750)', '\" (\"[320] (p=0.014, logit=17.750)', '\" Project\"[5907] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     int_track=OrderedDict([(52466, (1, PredictedToken(token=' Warehouse', prob=0.61328125, logit=21.5, token_id=52466, metadata=None))), (13000, (2, PredictedToken(token=' Van', prob=0.255859375, logit=20.625, token_id=13000, metadata=None))), (5907, (5, PredictedToken(token=' Project', prob=0.01123046875, logit=17.5, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:07 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:07 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.711, logit=21.500)', '\" The\"[578] (p=0.109, logit=19.625)', '\" Among\"[22395] (p=0.066, logit=19.125)', '\" A\"[362] (p=0.052, logit=18.875)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:53:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.766, logit=22.000)', '\" The\"[578] (p=0.081, logit=19.750)', '\" A\"[362] (p=0.081, logit=19.750)', '\" Among\"[22395] (p=0.023, logit=18.500)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.765625, logit=22.0, token_id=16183, metadata=None))), (75258, (17, PredictedToken(token=' Refriger', prob=0.000843048095703125, logit=15.1875, token_id=75258, metadata=None))), (100031, (76, PredictedToken(token=' Mosque', prob=4.744529724121094e-05, logit=12.3125, token_id=100031, metadata=None))), (30173, (246, PredictedToken(token=' Speaker', prob=3.6656856536865234e-06, logit=9.75, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.582, logit=20.875)', '\" The\"[578] (p=0.166, logit=19.625)', '\" A\"[362] (p=0.130, logit=19.375)', '\" Refriger\"[75258] (p=0.020, logit=17.500)', '\" Among\"[22395] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.58203125, logit=20.875, token_id=30173, metadata=None))), (75258, (4, PredictedToken(token=' Refriger', prob=0.0198974609375, logit=17.5, token_id=75258, metadata=None))), (100031, (14, PredictedToken(token=' Mosque', prob=0.00286865234375, logit=15.5625, token_id=100031, metadata=None))), (16183, (23, PredictedToken(token=' Hel', prob=0.001190185546875, logit=14.6875, token_id=16183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:08 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:08 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.750, logit=21.375)', '\" The\"[578] (p=0.070, logit=19.000)', '\" Glo\"[25372] (p=0.054, logit=18.750)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" A\"[362] (p=0.033, logit=18.250)']\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.879, logit=21.625)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" An\"[1556] (p=0.026, logit=18.125)', '\" The\"[578] (p=0.021, logit=17.875)', '\" ank\"[71572] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.87890625, logit=21.625, token_id=57915, metadata=None))), (22050, (11, PredictedToken(token=' Hat', prob=0.001495361328125, logit=15.25, token_id=22050, metadata=None))), (88088, (32, PredictedToken(token=' Birch', prob=0.0002288818359375, logit=13.375, token_id=88088, metadata=None))), (84008, (71, PredictedToken(token=' Sheep', prob=6.151199340820312e-05, logit=12.0625, token_id=84008, metadata=None))), (82994, (75, PredictedToken(token=' Toilet', prob=5.435943603515625e-05, logit=11.9375, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     int_prediction=['\" Ank\"[57915] (p=0.494, logit=20.250)', '\" Hat\"[22050] (p=0.182, logit=19.250)', '\" Among\"[22395] (p=0.097, logit=18.625)', '\" The\"[578] (p=0.067, logit=18.250)', '\" Birch\"[88088] (p=0.028, logit=17.375)']\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     int_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.494140625, logit=20.25, token_id=57915, metadata=None))), (22050, (2, PredictedToken(token=' Hat', prob=0.181640625, logit=19.25, token_id=22050, metadata=None))), (88088, (5, PredictedToken(token=' Birch', prob=0.0279541015625, logit=17.375, token_id=88088, metadata=None))), (84008, (47, PredictedToken(token=' Sheep', prob=0.00037384033203125, logit=13.0625, token_id=84008, metadata=None))), (82994, (51, PredictedToken(token=' Toilet', prob=0.0003509521484375, logit=13.0, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:08 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:08 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     patch_prediction=['\" Shower\"[48471] (p=0.812, logit=21.375)', '\" The\"[578] (p=0.046, logit=18.500)', '\" A\"[362] (p=0.046, logit=18.500)', '\" Among\"[22395] (p=0.040, logit=18.375)', '\" Option\"[7104] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     clean_prediction=['\" Router\"[10777] (p=0.777, logit=21.250)', '\" The\"[578] (p=0.072, logit=18.875)', '\" Among\"[22395] (p=0.030, logit=18.000)', '\" A\"[362] (p=0.026, logit=17.875)', '\" (\"[320] (p=0.023, logit=17.750)']\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     clean_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.77734375, logit=21.25, token_id=10777, metadata=None))), (61731, (51, PredictedToken(token=' Soap', prob=0.0001678466796875, logit=12.8125, token_id=61731, metadata=None))), (91782, (110, PredictedToken(token=' Shorts', prob=2.7418136596679688e-05, logit=11.0, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.750, logit=20.250)', '\" The\"[578] (p=0.048, logit=17.500)', '\" (\"[320] (p=0.042, logit=17.375)', '\" Soap\"[61731] (p=0.026, logit=16.875)', '\" None\"[2290] (p=0.018, logit=16.500)']\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.75, logit=20.25, token_id=91782, metadata=None))), (61731, (4, PredictedToken(token=' Soap', prob=0.025634765625, logit=16.875, token_id=61731, metadata=None))), (10777, (34, PredictedToken(token=' Router', prob=0.000640869140625, logit=13.1875, token_id=10777, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:09 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:09 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.598, logit=21.250)', '\" The\"[578] (p=0.194, logit=20.125)', '\" A\"[362] (p=0.134, logit=19.750)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" It\"[1102] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:53:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     clean_prediction=['\" To\"[2057] (p=0.695, logit=21.625)', '\" The\"[578] (p=0.137, logit=20.000)', '\" A\"[362] (p=0.073, logit=19.375)', '\" Among\"[22395] (p=0.039, logit=18.750)', '\" It\"[1102] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     clean_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.6953125, logit=21.625, token_id=2057, metadata=None))), (16488, (8, PredictedToken(token=' Bat', prob=0.004119873046875, logit=16.5, token_id=16488, metadata=None))), (38673, (55, PredictedToken(token=' Yoga', prob=9.72747802734375e-05, logit=12.75, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     int_prediction=['\" Yoga\"[38673] (p=0.625, logit=20.250)', '\" A\"[362] (p=0.123, logit=18.625)', '\" The\"[578] (p=0.084, logit=18.250)', '\" Among\"[22395] (p=0.051, logit=17.750)', '\" Option\"[7104] (p=0.015, logit=16.500)']\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     int_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.625, logit=20.25, token_id=38673, metadata=None))), (16488, (12, PredictedToken(token=' Bat', prob=0.003936767578125, logit=15.1875, token_id=16488, metadata=None))), (2057, (26, PredictedToken(token=' To', prob=0.00128173828125, logit=14.0625, token_id=2057, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:10 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:10 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.680, logit=20.875)', '\" Ski\"[61595] (p=0.081, logit=18.750)', '\" The\"[578] (p=0.081, logit=18.750)', '\" Among\"[22395] (p=0.043, logit=18.125)', '\" A\"[362] (p=0.043, logit=18.125)']\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     clean_prediction=['\" Soap\"[61731] (p=0.840, logit=21.625)', '\" The\"[578] (p=0.061, logit=19.000)', '\" Among\"[22395] (p=0.054, logit=18.875)', '\" SOAP\"[64332] (p=0.007, logit=16.875)', '\" A\"[362] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     clean_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.83984375, logit=21.625, token_id=61731, metadata=None))), (59825, (39, PredictedToken(token=' Tie', prob=0.00017070770263671875, logit=13.125, token_id=59825, metadata=None))), (30616, (75, PredictedToken(token=' Rice', prob=3.5762786865234375e-05, logit=11.5625, token_id=30616, metadata=None))), (58251, (263, PredictedToken(token=' Tennis', prob=3.769993782043457e-06, logit=9.3125, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.844, logit=21.375)', '\" The\"[578] (p=0.061, logit=18.750)', '\" A\"[362] (p=0.037, logit=18.250)', '\" Among\"[22395] (p=0.020, logit=17.625)', '\" (\"[320] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.84375, logit=21.375, token_id=58251, metadata=None))), (30616, (30, PredictedToken(token=' Rice', prob=0.0003204345703125, logit=13.5, token_id=30616, metadata=None))), (61731, (87, PredictedToken(token=' Soap', prob=3.814697265625e-05, logit=11.375, token_id=61731, metadata=None))), (59825, (86, PredictedToken(token=' Tie', prob=3.814697265625e-05, logit=11.375, token_id=59825, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:10 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.809, logit=22.000)', '\" A\"[362] (p=0.085, logit=19.750)', '\" The\"[578] (p=0.059, logit=19.375)', '\" Among\"[22395] (p=0.015, logit=18.000)', '\" (\"[320] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.648, logit=20.750)', '\" The\"[578] (p=0.088, logit=18.750)', '\" A\"[362] (p=0.088, logit=18.750)', '\" Among\"[22395] (p=0.047, logit=18.125)', '\" Soap\"[61731] (p=0.022, logit=17.375)']\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.6484375, logit=20.75, token_id=23462, metadata=None))), (61731, (5, PredictedToken(token=' Soap', prob=0.022216796875, logit=17.375, token_id=61731, metadata=None))), (6690, (6, PredictedToken(token=' Air', prob=0.013427734375, logit=16.875, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.938, logit=22.125)', '\" None\"[2290] (p=0.015, logit=18.000)', '\" The\"[578] (p=0.015, logit=18.000)', '\" A\"[362] (p=0.007, logit=17.250)', '\" (\"[320] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.9375, logit=22.125, token_id=61731, metadata=None))), (6690, (18, PredictedToken(token=' Air', prob=0.000457763671875, logit=14.5, token_id=6690, metadata=None))), (23462, (33, PredictedToken(token=' Stadium', prob=0.00014019012451171875, logit=13.3125, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:11 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:11 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     patch_prediction=['\" To\"[2057] (p=0.641, logit=22.125)', '\" The\"[578] (p=0.162, logit=20.750)', '\" A\"[362] (p=0.144, logit=20.625)', '\" Among\"[22395] (p=0.022, logit=18.750)', '\" It\"[1102] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:53:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     clean_prediction=['\" Caul\"[90538] (p=0.953, logit=23.250)', '\" The\"[578] (p=0.025, logit=19.625)', '\" Among\"[22395] (p=0.011, logit=18.750)', '\" It\"[1102] (p=0.002, logit=17.125)', '\" (\"[320] (p=0.002, logit=16.875)']\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     clean_track=OrderedDict([(90538, (1, PredictedToken(token=' Caul', prob=0.953125, logit=23.25, token_id=90538, metadata=None))), (75258, (61, PredictedToken(token=' Refriger', prob=1.5854835510253906e-05, logit=12.25, token_id=75258, metadata=None))), (10777, (125, PredictedToken(token=' Router', prob=3.546476364135742e-06, logit=10.75, token_id=10777, metadata=None)))])\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     int_prediction=['\" Refriger\"[75258] (p=0.301, logit=20.000)', '\" Caul\"[90538] (p=0.207, logit=19.625)', '\" Router\"[10777] (p=0.183, logit=19.500)', '\" The\"[578] (p=0.111, logit=19.000)', '\" A\"[362] (p=0.076, logit=18.625)']\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     int_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.30078125, logit=20.0, token_id=75258, metadata=None))), (90538, (2, PredictedToken(token=' Caul', prob=0.20703125, logit=19.625, token_id=90538, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.1826171875, logit=19.5, token_id=10777, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:12 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:12 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.887, logit=23.250)', '\" The\"[578] (p=0.057, logit=20.500)', '\" Among\"[22395] (p=0.024, logit=19.625)', '\" A\"[362] (p=0.013, logit=19.000)', '\" Tow\"[41493] (p=0.004, logit=17.875)']\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.898, logit=21.625)', '\" The\"[578] (p=0.045, logit=18.625)', '\" Among\"[22395] (p=0.010, logit=17.125)', '\" Option\"[7104] (p=0.005, logit=16.500)', '\" A\"[362] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.8984375, logit=21.625, token_id=82994, metadata=None))), (64695, (22, PredictedToken(token=' Peach', prob=0.000560760498046875, logit=14.25, token_id=64695, metadata=None))), (41785, (41, PredictedToken(token=' Spin', prob=0.0002498626708984375, logit=13.4375, token_id=41785, metadata=None)))])\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.598, logit=21.250)', '\" Spin\"[41785] (p=0.320, logit=20.625)', '\" The\"[578] (p=0.030, logit=18.250)', '\" None\"[2290] (p=0.012, logit=17.375)', '\" Among\"[22395] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.59765625, logit=21.25, token_id=64695, metadata=None))), (41785, (2, PredictedToken(token=' Spin', prob=0.3203125, logit=20.625, token_id=41785, metadata=None))), (82994, (143, PredictedToken(token=' Toilet', prob=1.7523765563964844e-05, logit=10.8125, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:12 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:12 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.898, logit=21.875)', '\" The\"[578] (p=0.040, logit=18.750)', '\" Among\"[22395] (p=0.019, logit=18.000)', '\" An\"[1556] (p=0.009, logit=17.250)', '\" Palm\"[33578] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     clean_prediction=['\" Speaker\"[30173] (p=0.738, logit=21.000)', '\" The\"[578] (p=0.088, logit=18.875)', '\" A\"[362] (p=0.061, logit=18.500)', '\" Among\"[22395] (p=0.042, logit=18.125)', '\" It\"[1102] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     clean_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.73828125, logit=21.0, token_id=30173, metadata=None))), (800, (29, PredictedToken(token=' St', prob=0.0005950927734375, logit=13.875, token_id=800, metadata=None))), (20918, (33, PredictedToken(token=' Magn', prob=0.000408172607421875, logit=13.5, token_id=20918, metadata=None))), (445, (53, PredictedToken(token=' L', prob=0.00014972686767578125, logit=12.5, token_id=445, metadata=None))), (45332, (140, PredictedToken(token=' Boat', prob=2.1576881408691406e-05, logit=10.5625, token_id=45332, metadata=None))), (41342, (234, PredictedToken(token=' Hockey', prob=7.927417755126953e-06, logit=9.5625, token_id=41342, metadata=None)))])\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     int_prediction=['\" St\"[800] (p=0.793, logit=21.625)', '\" A\"[362] (p=0.065, logit=19.125)', '\" The\"[578] (p=0.051, logit=18.875)', '\" Speaker\"[30173] (p=0.031, logit=18.375)', '\" Among\"[22395] (p=0.024, logit=18.125)']\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     int_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.79296875, logit=21.625, token_id=800, metadata=None))), (30173, (4, PredictedToken(token=' Speaker', prob=0.03076171875, logit=18.375, token_id=30173, metadata=None))), (445, (49, PredictedToken(token=' L', prob=8.630752563476562e-05, logit=12.5, token_id=445, metadata=None))), (45332, (54, PredictedToken(token=' Boat', prob=8.106231689453125e-05, logit=12.4375, token_id=45332, metadata=None))), (20918, (101, PredictedToken(token=' Magn', prob=2.47955322265625e-05, logit=11.25, token_id=20918, metadata=None))), (41342, (512, PredictedToken(token=' Hockey', prob=1.1548399925231934e-06, logit=8.1875, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:13 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.820, logit=20.750)', '\" None\"[2290] (p=0.060, logit=18.125)', '\" Mall\"[32498] (p=0.025, logit=17.250)', '\" The\"[578] (p=0.015, logit=16.750)', '\" (\"[320] (p=0.012, logit=16.500)']\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     clean_prediction=['\" Mouse\"[18191] (p=0.914, logit=22.625)', '\" The\"[578] (p=0.028, logit=19.125)', '\" A\"[362] (p=0.019, logit=18.750)', '\" mouse\"[8814] (p=0.008, logit=17.875)', '\" Among\"[22395] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     clean_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.9140625, logit=22.625, token_id=18191, metadata=None))), (1050, (16, PredictedToken(token=' Re', prob=0.0004749298095703125, logit=15.0625, token_id=1050, metadata=None))), (52882, (25, PredictedToken(token=' Pepper', prob=0.0002384185791015625, logit=14.375, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.633, logit=21.375)', '\" Mouse\"[18191] (p=0.233, logit=20.375)', '\" None\"[2290] (p=0.028, logit=18.250)', '\" The\"[578] (p=0.025, logit=18.125)', '\" pepper\"[25349] (p=0.015, logit=17.625)']\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.6328125, logit=21.375, token_id=52882, metadata=None))), (18191, (2, PredictedToken(token=' Mouse', prob=0.2333984375, logit=20.375, token_id=18191, metadata=None))), (1050, (7, PredictedToken(token=' Re', prob=0.009033203125, logit=17.125, token_id=1050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.543, logit=21.125)', '\" The\"[578] (p=0.200, logit=20.125)', '\" Among\"[22395] (p=0.107, logit=19.500)', '\" A\"[362] (p=0.074, logit=19.125)', '\" (\"[320] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     clean_prediction=['\" None\"[2290] (p=0.762, logit=20.125)', '\" Mouse\"[18191] (p=0.150, logit=18.500)', '\" There\"[2684] (p=0.026, logit=16.750)', '\" The\"[578] (p=0.006, logit=15.250)', '\" none\"[7000] (p=0.004, logit=14.938)']\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     clean_track=OrderedDict([(18191, (2, PredictedToken(token=' Mouse', prob=0.150390625, logit=18.5, token_id=18191, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.0031280517578125, logit=14.625, token_id=469, metadata=None))), (36358, (9, PredictedToken(token=' Bench', prob=0.0029296875, logit=14.5625, token_id=36358, metadata=None))), (66821, (13, PredictedToken(token=' Iris', prob=0.00167083740234375, logit=14.0, token_id=66821, metadata=None))), (84008, (32, PredictedToken(token=' Sheep', prob=0.0003509521484375, logit=12.4375, token_id=84008, metadata=None)))])\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.629, logit=21.125)', '\" Iris\"[66821] (p=0.262, logit=20.250)', '\" There\"[2684] (p=0.040, logit=18.375)', '\" none\"[7000] (p=0.012, logit=17.125)', '\" IR\"[16646] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:53:14 src.selection.optimization INFO     int_track=OrderedDict([(66821, (2, PredictedToken(token=' Iris', prob=0.26171875, logit=20.25, token_id=66821, metadata=None))), (469, (9, PredictedToken(token=' E', prob=0.00213623046875, logit=15.4375, token_id=469, metadata=None))), (18191, (93, PredictedToken(token=' Mouse', prob=3.24249267578125e-05, logit=11.25, token_id=18191, metadata=None))), (84008, (156, PredictedToken(token=' Sheep', prob=1.1920928955078125e-05, logit=10.25, token_id=84008, metadata=None))), (36358, (230, PredictedToken(token=' Bench', prob=5.990266799926758e-06, logit=9.5625, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:15 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.699, logit=21.000)', '\" Notebook\"[69755] (p=0.074, logit=18.750)', '\" An\"[1556] (p=0.065, logit=18.625)', '\" The\"[578] (p=0.065, logit=18.625)', '\" Among\"[22395] (p=0.027, logit=17.750)']\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.805, logit=22.875)', '\" The\"[578] (p=0.075, logit=20.500)', '\" A\"[362] (p=0.075, logit=20.500)', '\" Among\"[22395] (p=0.027, logit=19.500)', '\" SU\"[15857] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.8046875, logit=22.875, token_id=33711, metadata=None))), (13394, (126, PredictedToken(token=' Bed', prob=5.9604644775390625e-06, logit=11.0625, token_id=13394, metadata=None))), (97796, (148, PredictedToken(token=' Skate', prob=4.351139068603516e-06, logit=10.75, token_id=97796, metadata=None))), (22410, (1068, PredictedToken(token=' Ju', prob=1.695007085800171e-07, logit=7.5, token_id=22410, metadata=None))), (78703, (1720, PredictedToken(token=' Potato', prob=8.754432201385498e-08, logit=6.84375, token_id=78703, metadata=None)))])\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     int_prediction=['\" Bed\"[13394] (p=0.672, logit=21.875)', '\" Suit\"[33711] (p=0.117, logit=20.125)', '\" The\"[578] (p=0.080, logit=19.750)', '\" A\"[362] (p=0.055, logit=19.375)', '\" Among\"[22395] (p=0.030, logit=18.750)']\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     int_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.671875, logit=21.875, token_id=13394, metadata=None))), (33711, (2, PredictedToken(token=' Suit', prob=0.11669921875, logit=20.125, token_id=33711, metadata=None))), (97796, (6, PredictedToken(token=' Skate', prob=0.007476806640625, logit=17.375, token_id=97796, metadata=None))), (22410, (21, PredictedToken(token=' Ju', prob=0.0008392333984375, logit=15.1875, token_id=22410, metadata=None))), (78703, (163, PredictedToken(token=' Potato', prob=1.055002212524414e-05, logit=10.8125, token_id=78703, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:15 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:53:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.699, logit=20.750)', '\" Among\"[22395] (p=0.083, logit=18.625)', '\" The\"[578] (p=0.065, logit=18.375)', '\" An\"[1556] (p=0.031, logit=17.625)', '\" A\"[362] (p=0.031, logit=17.625)']\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.809, logit=21.750)', '\" The\"[578] (p=0.096, logit=19.625)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" Out\"[4470] (p=0.004, logit=16.375)', '\" (\"[320] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.80859375, logit=21.75, token_id=82994, metadata=None))), (23462, (60, PredictedToken(token=' Stadium', prob=7.295608520507812e-05, logit=12.4375, token_id=23462, metadata=None))), (1901, (109, PredictedToken(token=' Z', prob=1.8477439880371094e-05, logit=11.0625, token_id=1901, metadata=None))), (97796, (153, PredictedToken(token=' Skate', prob=1.1146068572998047e-05, logit=10.5625, token_id=97796, metadata=None))), (6690, (178, PredictedToken(token=' Air', prob=8.165836334228516e-06, logit=10.25, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.684, logit=21.375)', '\" The\"[578] (p=0.152, logit=19.875)', '\" A\"[362] (p=0.056, logit=18.875)', '\" Among\"[22395] (p=0.050, logit=18.750)', '\" Option\"[7104] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.68359375, logit=21.375, token_id=23462, metadata=None))), (6690, (29, PredictedToken(token=' Air', prob=0.000354766845703125, logit=13.8125, token_id=6690, metadata=None))), (82994, (45, PredictedToken(token=' Toilet', prob=0.00017833709716796875, logit=13.125, token_id=82994, metadata=None))), (1901, (52, PredictedToken(token=' Z', prob=0.0001392364501953125, logit=12.875, token_id=1901, metadata=None))), (97796, (80, PredictedToken(token=' Skate', prob=5.459785461425781e-05, logit=11.9375, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:16 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.668, logit=21.000)', '\" Among\"[22395] (p=0.090, logit=19.000)', '\" The\"[578] (p=0.090, logit=19.000)', '\" An\"[1556] (p=0.070, logit=18.750)', '\" Option\"[7104] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     clean_prediction=['\" Mar\"[2947] (p=0.840, logit=22.375)', '\" The\"[578] (p=0.069, logit=19.875)', '\" Among\"[22395] (p=0.029, logit=19.000)', '\" A\"[362] (p=0.012, logit=18.125)', '\" Option\"[7104] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     clean_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.83984375, logit=22.375, token_id=2947, metadata=None))), (426, (32, PredictedToken(token=' B', prob=0.0002651214599609375, logit=14.3125, token_id=426, metadata=None))), (14642, (176, PredictedToken(token=' Phone', prob=4.559755325317383e-06, logit=10.25, token_id=14642, metadata=None))), (55807, (358, PredictedToken(token=' Shirt', prob=1.2218952178955078e-06, logit=8.9375, token_id=55807, metadata=None))), (49268, (528, PredictedToken(token=' Dish', prob=6.556510925292969e-07, logit=8.3125, token_id=49268, metadata=None)))])\n",
      "2025-09-16 09:53:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     int_prediction=['\" Dish\"[49268] (p=0.578, logit=20.500)', '\" The\"[578] (p=0.129, logit=19.000)', '\" A\"[362] (p=0.101, logit=18.750)', '\" Shirt\"[55807] (p=0.054, logit=18.125)', '\" Among\"[22395] (p=0.037, logit=17.750)']\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     int_track=OrderedDict([(49268, (1, PredictedToken(token=' Dish', prob=0.578125, logit=20.5, token_id=49268, metadata=None))), (55807, (4, PredictedToken(token=' Shirt', prob=0.0537109375, logit=18.125, token_id=55807, metadata=None))), (426, (6, PredictedToken(token=' B', prob=0.015380859375, logit=16.875, token_id=426, metadata=None))), (14642, (10, PredictedToken(token=' Phone', prob=0.00531005859375, logit=15.8125, token_id=14642, metadata=None))), (2947, (92, PredictedToken(token=' Mar', prob=5.555152893066406e-05, logit=11.25, token_id=2947, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:17 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:17 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     patch_prediction=['\" Onion\"[87035] (p=0.824, logit=21.250)', '\" The\"[578] (p=0.052, logit=18.500)', '\" Among\"[22395] (p=0.046, logit=18.375)', '\" An\"[1556] (p=0.012, logit=17.000)', '\" On\"[1952] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.742, logit=22.000)', '\" The\"[578] (p=0.101, logit=20.000)', '\" A\"[362] (p=0.054, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=19.250)', '\" It\"[1102] (p=0.014, logit=18.000)']\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.7421875, logit=22.0, token_id=56491, metadata=None))), (3341, (29, PredictedToken(token=' Car', prob=0.00028228759765625, logit=14.125, token_id=3341, metadata=None))), (432, (43, PredictedToken(token=' R', prob=0.000133514404296875, logit=13.375, token_id=432, metadata=None))), (30558, (82, PredictedToken(token=' Ki', prob=2.7894973754882812e-05, logit=11.8125, token_id=30558, metadata=None)))])\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.801, logit=21.625)', '\" The\"[578] (p=0.058, logit=19.000)', '\" A\"[362] (p=0.040, logit=18.625)', '\" Car\"[3341] (p=0.027, logit=18.250)', '\" Among\"[22395] (p=0.024, logit=18.125)']\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.80078125, logit=21.625, token_id=432, metadata=None))), (3341, (4, PredictedToken(token=' Car', prob=0.0274658203125, logit=18.25, token_id=3341, metadata=None))), (30558, (7, PredictedToken(token=' Ki', prob=0.006927490234375, logit=16.875, token_id=30558, metadata=None))), (56491, (22, PredictedToken(token=' Piano', prob=0.0005035400390625, logit=14.25, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:17 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:17 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:53:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     patch_prediction=['\" Dolphin\"[96096] (p=0.840, logit=21.875)', '\" The\"[578] (p=0.061, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" A\"[362] (p=0.020, logit=18.125)', '\" Option\"[7104] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.848, logit=21.500)', '\" The\"[578] (p=0.037, logit=18.375)', '\" A\"[362] (p=0.033, logit=18.250)', '\" None\"[2290] (p=0.023, logit=17.875)', '\" Among\"[22395] (p=0.018, logit=17.625)']\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.84765625, logit=21.5, token_id=33578, metadata=None))), (6914, (12, PredictedToken(token=' Let', prob=0.00119781494140625, logit=14.9375, token_id=6914, metadata=None))), (735, (26, PredictedToken(token=' K', prob=0.0004138946533203125, logit=13.875, token_id=735, metadata=None))), (58937, (27, PredictedToken(token=' Monkey', prob=0.0004138946533203125, logit=13.875, token_id=58937, metadata=None))), (6771, (91, PredictedToken(token=' Table', prob=3.838539123535156e-05, logit=11.5, token_id=6771, metadata=None))), (34785, (139, PredictedToken(token=' Truck', prob=1.704692840576172e-05, logit=10.6875, token_id=34785, metadata=None)))])\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     int_prediction=['\" Monkey\"[58937] (p=0.785, logit=21.750)', '\" Palm\"[33578] (p=0.083, logit=19.500)', '\" A\"[362] (p=0.050, logit=19.000)', '\" The\"[578] (p=0.030, logit=18.500)', '\" None\"[2290] (p=0.018, logit=18.000)']\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     int_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.78515625, logit=21.75, token_id=58937, metadata=None))), (33578, (2, PredictedToken(token=' Palm', prob=0.08251953125, logit=19.5, token_id=33578, metadata=None))), (6914, (10, PredictedToken(token=' Let', prob=0.00171661376953125, logit=15.625, token_id=6914, metadata=None))), (735, (25, PredictedToken(token=' K', prob=0.000461578369140625, logit=14.3125, token_id=735, metadata=None))), (6771, (244, PredictedToken(token=' Table', prob=4.827976226806641e-06, logit=9.75, token_id=6771, metadata=None))), (34785, (346, PredictedToken(token=' Truck', prob=2.9206275939941406e-06, logit=9.25, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:18 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.883, logit=22.000)', '\" The\"[578] (p=0.050, logit=19.125)', '\" Among\"[22395] (p=0.034, logit=18.750)', '\" It\"[1102] (p=0.006, logit=17.000)', '\" Option\"[7104] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.805, logit=21.000)', '\" The\"[578] (p=0.075, logit=18.625)', '\" Among\"[22395] (p=0.058, logit=18.375)', '\" Option\"[7104] (p=0.005, logit=16.000)', '\" toilet\"[27306] (p=0.005, logit=15.938)']\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.8046875, logit=21.0, token_id=82994, metadata=None))), (6031, (15, PredictedToken(token=' Bro', prob=0.00121307373046875, logit=14.5, token_id=6031, metadata=None))), (9939, (16, PredictedToken(token=' Er', prob=0.00113677978515625, logit=14.4375, token_id=9939, metadata=None))), (40090, (34, PredictedToken(token=' Pressure', prob=0.0004444122314453125, logit=13.5, token_id=40090, metadata=None))), (64695, (54, PredictedToken(token=' Peach', prob=0.000164031982421875, logit=12.5, token_id=64695, metadata=None)))])\n",
      "2025-09-16 09:53:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.914, logit=21.875)', '\" The\"[578] (p=0.035, logit=18.625)', '\" Among\"[22395] (p=0.019, logit=18.000)', '\" Out\"[4470] (p=0.003, logit=16.000)', '\" (\"[320] (p=0.002, logit=15.938)']\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.9140625, logit=21.875, token_id=6031, metadata=None))), (64695, (8, PredictedToken(token=' Peach', prob=0.00146484375, logit=15.4375, token_id=64695, metadata=None))), (9939, (25, PredictedToken(token=' Er', prob=0.00023937225341796875, logit=13.625, token_id=9939, metadata=None))), (40090, (97, PredictedToken(token=' Pressure', prob=2.372264862060547e-05, logit=11.3125, token_id=40090, metadata=None))), (82994, (429, PredictedToken(token=' Toilet', prob=1.7136335372924805e-06, logit=8.6875, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:19 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:19 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.633, logit=21.125)', '\" The\"[578] (p=0.182, logit=19.875)', '\" Among\"[22395] (p=0.076, logit=19.000)', '\" A\"[362] (p=0.052, logit=18.625)', '\" It\"[1102] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.746, logit=22.125)', '\" The\"[578] (p=0.089, logit=20.000)', '\" A\"[362] (p=0.089, logit=20.000)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.74609375, logit=22.125, token_id=16183, metadata=None))), (1630, (34, PredictedToken(token=' X', prob=0.000194549560546875, logit=13.875, token_id=1630, metadata=None))), (42609, (77, PredictedToken(token=' Pine', prob=3.838539123535156e-05, logit=12.25, token_id=42609, metadata=None))), (49431, (645, PredictedToken(token=' Rabbit', prob=6.183981895446777e-07, logit=8.125, token_id=49431, metadata=None))), (39794, (1094, PredictedToken(token=' Desk', prob=2.8312206268310547e-07, logit=7.34375, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.688, logit=21.500)', '\" A\"[362] (p=0.093, logit=19.500)', '\" The\"[578] (p=0.082, logit=19.375)', '\" Among\"[22395] (p=0.056, logit=19.000)', '\" An\"[1556] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.6875, logit=21.5, token_id=1630, metadata=None))), (42609, (6, PredictedToken(token=' Pine', prob=0.0086669921875, logit=17.125, token_id=42609, metadata=None))), (16183, (13, PredictedToken(token=' Hel', prob=0.0024871826171875, logit=15.875, token_id=16183, metadata=None))), (49431, (17, PredictedToken(token=' Rabbit', prob=0.00170135498046875, logit=15.5, token_id=49431, metadata=None))), (39794, (329, PredictedToken(token=' Desk', prob=2.726912498474121e-06, logit=9.0625, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:19 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:19 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.859, logit=21.500)', '\" The\"[578] (p=0.048, logit=18.625)', '\" Among\"[22395] (p=0.029, logit=18.125)', '\" A\"[362] (p=0.014, logit=17.375)', '\" Option\"[7104] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.863, logit=22.000)', '\" The\"[578] (p=0.043, logit=19.000)', '\" A\"[362] (p=0.038, logit=18.875)', '\" Among\"[22395] (p=0.033, logit=18.750)', '\" (\"[320] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.86328125, logit=22.0, token_id=59825, metadata=None))), (34954, (54, PredictedToken(token=' Mirror', prob=5.698204040527344e-05, logit=12.375, token_id=34954, metadata=None))), (3341, (78, PredictedToken(token=' Car', prob=2.5272369384765625e-05, logit=11.5625, token_id=3341, metadata=None))), (8219, (173, PredictedToken(token=' Sun', prob=5.304813385009766e-06, logit=10.0, token_id=8219, metadata=None))), (89077, (904, PredictedToken(token=' Strawberry', prob=4.4889748096466064e-07, logit=7.53125, token_id=89077, metadata=None))), (12369, (916, PredictedToken(token=' Food', prob=4.3585896492004395e-07, logit=7.5, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     int_prediction=['\" Mirror\"[34954] (p=0.930, logit=22.000)', '\" The\"[578] (p=0.025, logit=18.375)', '\" A\"[362] (p=0.010, logit=17.500)', '\" Among\"[22395] (p=0.009, logit=17.375)', '\" (\"[320] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     int_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.9296875, logit=22.0, token_id=34954, metadata=None))), (59825, (8, PredictedToken(token=' Tie', prob=0.002166748046875, logit=15.9375, token_id=59825, metadata=None))), (8219, (10, PredictedToken(token=' Sun', prob=0.00115966796875, logit=15.3125, token_id=8219, metadata=None))), (12369, (16, PredictedToken(token=' Food', prob=0.000545501708984375, logit=14.5625, token_id=12369, metadata=None))), (89077, (26, PredictedToken(token=' Strawberry', prob=0.0002422332763671875, logit=13.75, token_id=89077, metadata=None))), (3341, (228, PredictedToken(token=' Car', prob=4.172325134277344e-06, logit=9.6875, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:20 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:20 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.859, logit=21.875)', '\" The\"[578] (p=0.049, logit=19.000)', '\" An\"[1556] (p=0.043, logit=18.875)', '\" Among\"[22395] (p=0.020, logit=18.125)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:53:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.883, logit=21.625)', '\" The\"[578] (p=0.064, logit=19.000)', '\" Among\"[22395] (p=0.014, logit=17.500)', '\" A\"[362] (p=0.006, logit=16.625)', '\" TA\"[39991] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.8828125, logit=21.625, token_id=58586, metadata=None))), (800, (6, PredictedToken(token=' St', prob=0.003173828125, logit=16.0, token_id=800, metadata=None))), (356, (11, PredictedToken(token=' C', prob=0.0010986328125, logit=14.9375, token_id=356, metadata=None))), (4923, (32, PredictedToken(token=' Sk', prob=0.00022983551025390625, logit=13.375, token_id=4923, metadata=None))), (445, (94, PredictedToken(token=' L', prob=2.753734588623047e-05, logit=11.25, token_id=445, metadata=None))), (100031, (250, PredictedToken(token=' Mosque', prob=5.0961971282958984e-06, logit=9.5625, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     int_prediction=['\" St\"[800] (p=0.781, logit=21.625)', '\" The\"[578] (p=0.093, logit=19.500)', '\" A\"[362] (p=0.050, logit=18.875)', '\" Sk\"[4923] (p=0.016, logit=17.750)', '\" Among\"[22395] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     int_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.78125, logit=21.625, token_id=800, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.0162353515625, logit=17.75, token_id=4923, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.00762939453125, logit=17.0, token_id=356, metadata=None))), (100031, (23, PredictedToken(token=' Mosque', prob=0.0006256103515625, logit=14.5, token_id=100031, metadata=None))), (445, (41, PredictedToken(token=' L', prob=0.0002040863037109375, logit=13.375, token_id=445, metadata=None))), (58586, (121, PredictedToken(token=' Tape', prob=1.895427703857422e-05, logit=11.0, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:21 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:21 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.820, logit=21.000)', '\" Among\"[22395] (p=0.059, logit=18.375)', '\" The\"[578] (p=0.041, logit=18.000)', '\" Library\"[11896] (p=0.012, logit=16.750)', '\" toilet\"[27306] (p=0.005, logit=15.875)']\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.941, logit=22.375)', '\" The\"[578] (p=0.017, logit=18.375)', '\" A\"[362] (p=0.008, logit=17.625)', '\" Among\"[22395] (p=0.005, logit=17.125)', '\" E\"[469] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.94140625, logit=22.375, token_id=29625, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.00384521484375, logit=16.875, token_id=469, metadata=None))), (91263, (6, PredictedToken(token=' Binder', prob=0.003387451171875, logit=16.75, token_id=91263, metadata=None))), (3420, (16, PredictedToken(token=' Trump', prob=0.000591278076171875, logit=15.0, token_id=3420, metadata=None))), (15429, (31, PredictedToken(token=' Hospital', prob=0.00019168853759765625, logit=13.875, token_id=15429, metadata=None))), (48471, (137, PredictedToken(token=' Shower', prob=9.5367431640625e-06, logit=10.875, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     int_prediction=['\" Chain\"[29625] (p=0.961, logit=23.375)', '\" Hospital\"[15429] (p=0.009, logit=18.750)', '\" The\"[578] (p=0.007, logit=18.500)', '\" A\"[362] (p=0.006, logit=18.250)', '\" E\"[469] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     int_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.9609375, logit=23.375, token_id=29625, metadata=None))), (15429, (2, PredictedToken(token=' Hospital', prob=0.00946044921875, logit=18.75, token_id=15429, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.00164031982421875, logit=17.0, token_id=469, metadata=None))), (91263, (7, PredictedToken(token=' Binder', prob=0.00127410888671875, logit=16.75, token_id=91263, metadata=None))), (48471, (130, PredictedToken(token=' Shower', prob=4.9173831939697266e-06, logit=11.1875, token_id=48471, metadata=None))), (3420, (1452, PredictedToken(token=' Trump', prob=8.42846930027008e-08, logit=7.125, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:21 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:53:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.820, logit=21.500)', '\" The\"[578] (p=0.059, logit=18.875)', '\" Among\"[22395] (p=0.041, logit=18.500)', '\" A\"[362] (p=0.028, logit=18.125)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.688, logit=21.125)', '\" The\"[578] (p=0.105, logit=19.250)', '\" A\"[362] (p=0.064, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.625)', '\" Option\"[7104] (p=0.021, logit=17.625)']\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.6875, logit=21.125, token_id=48035, metadata=None))), (18343, (34, PredictedToken(token=' Paper', prob=0.00058746337890625, logit=14.0625, token_id=18343, metadata=None))), (20918, (46, PredictedToken(token=' Magn', prob=0.0002765655517578125, logit=13.3125, token_id=20918, metadata=None))), (23462, (254, PredictedToken(token=' Stadium', prob=6.139278411865234e-06, logit=9.5, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.715, logit=21.000)', '\" Among\"[22395] (p=0.085, logit=18.875)', '\" Magn\"[20918] (p=0.052, logit=18.375)', '\" The\"[578] (p=0.052, logit=18.375)', '\" Option\"[7104] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.71484375, logit=21.0, token_id=23462, metadata=None))), (20918, (4, PredictedToken(token=' Magn', prob=0.0517578125, logit=18.375, token_id=20918, metadata=None))), (18343, (20, PredictedToken(token=' Paper', prob=0.00156402587890625, logit=14.875, token_id=18343, metadata=None))), (48035, (224, PredictedToken(token=' Gir', prob=9.894371032714844e-06, logit=9.8125, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:22 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:22 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-16 09:53:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.613, logit=22.500)', '\" The\"[578] (p=0.199, logit=21.375)', '\" A\"[362] (p=0.106, logit=20.750)', '\" Among\"[22395] (p=0.044, logit=19.875)', '\" It\"[1102] (p=0.010, logit=18.375)']\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     clean_prediction=['\" Let\"[6914] (p=0.820, logit=22.000)', '\" The\"[578] (p=0.086, logit=19.750)', '\" Among\"[22395] (p=0.052, logit=19.250)', '\" It\"[1102] (p=0.006, logit=17.000)', '\" Tr\"[1183] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     clean_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.8203125, logit=22.0, token_id=6914, metadata=None))), (1183, (5, PredictedToken(token=' Tr', prob=0.0037841796875, logit=16.625, token_id=1183, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.0026092529296875, logit=16.25, token_id=356, metadata=None))), (57748, (622, PredictedToken(token=' Cedar', prob=7.264316082000732e-07, logit=8.0625, token_id=57748, metadata=None)))])\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.828, logit=22.625)', '\" The\"[578] (p=0.077, logit=20.250)', '\" A\"[362] (p=0.041, logit=19.625)', '\" Among\"[22395] (p=0.013, logit=18.500)', '\" It\"[1102] (p=0.008, logit=18.000)']\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.828125, logit=22.625, token_id=356, metadata=None))), (1183, (7, PredictedToken(token=' Tr', prob=0.00494384765625, logit=17.5, token_id=1183, metadata=None))), (6914, (12, PredictedToken(token=' Let', prob=0.000804901123046875, logit=15.6875, token_id=6914, metadata=None))), (57748, (37, PredictedToken(token=' Cedar', prob=0.000148773193359375, logit=14.0, token_id=57748, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:23 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:23 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.715, logit=21.500)', '\" A\"[362] (p=0.125, logit=19.750)', '\" The\"[578] (p=0.097, logit=19.500)', '\" Among\"[22395] (p=0.022, logit=18.000)', '\" It\"[1102] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     clean_prediction=['\" Rabbit\"[49431] (p=0.578, logit=21.000)', '\" The\"[578] (p=0.165, logit=19.750)', '\" Among\"[22395] (p=0.114, logit=19.375)', '\" A\"[362] (p=0.069, logit=18.875)', '\" (\"[320] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     clean_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.578125, logit=21.0, token_id=49431, metadata=None))), (57551, (172, PredictedToken(token=' Sink', prob=1.1622905731201172e-05, logit=10.1875, token_id=57551, metadata=None))), (44570, (183, PredictedToken(token=' Maple', prob=9.655952453613281e-06, logit=10.0, token_id=44570, metadata=None))), (67553, (385, PredictedToken(token=' Pants', prob=2.592802047729492e-06, logit=8.6875, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     int_prediction=['\" Sink\"[57551] (p=0.625, logit=20.625)', '\" Pants\"[67553] (p=0.179, logit=19.375)', '\" The\"[578] (p=0.075, logit=18.500)', '\" Among\"[22395] (p=0.051, logit=18.125)', '\" A\"[362] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:53:23 src.selection.optimization INFO     int_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.625, logit=20.625, token_id=57551, metadata=None))), (67553, (2, PredictedToken(token=' Pants', prob=0.1787109375, logit=19.375, token_id=67553, metadata=None))), (49431, (28, PredictedToken(token=' Rabbit', prob=0.000606536865234375, logit=13.6875, token_id=49431, metadata=None))), (44570, (605, PredictedToken(token=' Maple', prob=1.9222497940063477e-06, logit=7.9375, token_id=44570, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:24 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.645, logit=20.500)', '\" The\"[578] (p=0.112, logit=18.750)', '\" A\"[362] (p=0.077, logit=18.375)', '\" Among\"[22395] (p=0.053, logit=18.000)', '\" Option\"[7104] (p=0.020, logit=17.000)']\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.816, logit=22.500)', '\" The\"[578] (p=0.086, logit=20.250)', '\" Among\"[22395] (p=0.036, logit=19.375)', '\" A\"[362] (p=0.036, logit=19.375)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.81640625, logit=22.5, token_id=3341, metadata=None))), (432, (71, PredictedToken(token=' R', prob=2.2530555725097656e-05, logit=12.0, token_id=432, metadata=None))), (10573, (95, PredictedToken(token=' Watch', prob=1.3649463653564453e-05, logit=11.5, token_id=10573, metadata=None))), (34046, (151, PredictedToken(token=' Cabinet', prob=5.334615707397461e-06, logit=10.5625, token_id=34046, metadata=None))), (47759, (717, PredictedToken(token=' Guitar', prob=3.632158041000366e-07, logit=7.875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.609, logit=21.625)', '\" The\"[578] (p=0.120, logit=20.000)', '\" Watch\"[10573] (p=0.083, logit=19.625)', '\" A\"[362] (p=0.073, logit=19.500)', '\" Among\"[22395] (p=0.039, logit=18.875)']\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.609375, logit=21.625, token_id=432, metadata=None))), (10573, (3, PredictedToken(token=' Watch', prob=0.08251953125, logit=19.625, token_id=10573, metadata=None))), (3341, (6, PredictedToken(token=' Car', prob=0.034423828125, logit=18.75, token_id=3341, metadata=None))), (47759, (32, PredictedToken(token=' Guitar', prob=0.000316619873046875, logit=14.0625, token_id=47759, metadata=None))), (34046, (216, PredictedToken(token=' Cabinet', prob=4.500150680541992e-06, logit=9.8125, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:24 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:24 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.719, logit=21.750)', '\" The\"[578] (p=0.125, logit=20.000)', '\" Among\"[22395] (p=0.076, logit=19.500)', '\" A\"[362] (p=0.019, logit=18.125)', '\" (\"[320] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.762, logit=21.500)', '\" The\"[578] (p=0.080, logit=19.250)', '\" A\"[362] (p=0.038, logit=18.500)', '\" Among\"[22395] (p=0.030, logit=18.250)', '\" keyboard\"[13939] (p=0.030, logit=18.250)']\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.76171875, logit=21.5, token_id=26698, metadata=None))), (4923, (22, PredictedToken(token=' Sk', prob=0.000652313232421875, logit=14.4375, token_id=4923, metadata=None))), (74574, (160, PredictedToken(token=' Violet', prob=1.1205673217773438e-05, logit=10.375, token_id=74574, metadata=None)))])\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.949, logit=22.875)', '\" violet\"[80836] (p=0.020, logit=19.000)', '\" The\"[578] (p=0.007, logit=18.000)', '\" Sk\"[4923] (p=0.003, logit=17.250)', '\" (\"[320] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.94921875, logit=22.875, token_id=74574, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.00341796875, logit=17.25, token_id=4923, metadata=None))), (26698, (54, PredictedToken(token=' Keyboard', prob=2.777576446533203e-05, logit=12.4375, token_id=26698, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:25 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.746, logit=20.000)', '\" The\"[578] (p=0.069, logit=17.625)', '\" Among\"[22395] (p=0.037, logit=17.000)', '\" Hick\"[79028] (p=0.015, logit=16.125)', '\" Short\"[10928] (p=0.012, logit=15.875)']\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.832, logit=21.875)', '\" Among\"[22395] (p=0.047, logit=19.000)', '\" The\"[578] (p=0.042, logit=18.875)', '\" A\"[362] (p=0.042, logit=18.875)', '\" (\"[320] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.83203125, logit=21.875, token_id=23262, metadata=None))), (88088, (13, PredictedToken(token=' Birch', prob=0.00110626220703125, logit=15.25, token_id=88088, metadata=None))), (19111, (51, PredictedToken(token=' Bus', prob=0.00010967254638671875, logit=12.9375, token_id=19111, metadata=None))), (6690, (174, PredictedToken(token=' Air', prob=9.000301361083984e-06, logit=10.4375, token_id=6690, metadata=None))), (55807, (198, PredictedToken(token=' Shirt', prob=6.586313247680664e-06, logit=10.125, token_id=55807, metadata=None))), (38673, (634, PredictedToken(token=' Yoga', prob=1.0058283805847168e-06, logit=8.25, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:53:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.613, logit=21.000)', '\" Bus\"[19111] (p=0.226, logit=20.000)', '\" The\"[578] (p=0.035, logit=18.125)', '\" Among\"[22395] (p=0.031, logit=18.000)', '\" A\"[362] (p=0.027, logit=17.875)']\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.61328125, logit=21.0, token_id=55807, metadata=None))), (19111, (2, PredictedToken(token=' Bus', prob=0.2255859375, logit=20.0, token_id=19111, metadata=None))), (88088, (10, PredictedToken(token=' Birch', prob=0.0038909912109375, logit=15.9375, token_id=88088, metadata=None))), (38673, (12, PredictedToken(token=' Yoga', prob=0.0020751953125, logit=15.3125, token_id=38673, metadata=None))), (6690, (14, PredictedToken(token=' Air', prob=0.0017242431640625, logit=15.125, token_id=6690, metadata=None))), (23262, (50, PredictedToken(token=' Comb', prob=0.00018215179443359375, logit=12.875, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:26 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.766, logit=21.750)', '\" The\"[578] (p=0.071, logit=19.375)', '\" A\"[362] (p=0.063, logit=19.250)', '\" Among\"[22395] (p=0.043, logit=18.875)', '\" C\"[356] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     clean_prediction=['\" Lily\"[48390] (p=0.645, logit=21.375)', '\" The\"[578] (p=0.185, logit=20.125)', '\" Among\"[22395] (p=0.077, logit=19.250)', '\" A\"[362] (p=0.032, logit=18.375)', '\" It\"[1102] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     clean_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.64453125, logit=21.375, token_id=48390, metadata=None))), (34392, (18, PredictedToken(token=' Horse', prob=0.000911712646484375, logit=14.8125, token_id=34392, metadata=None))), (23262, (146, PredictedToken(token=' Comb', prob=1.150369644165039e-05, logit=10.4375, token_id=23262, metadata=None))), (27217, (765, PredictedToken(token=' Train', prob=7.82310962677002e-07, logit=7.75, token_id=27217, metadata=None))), (47589, (1239, PredictedToken(token=' Basketball', prob=4.0605664253234863e-07, logit=7.09375, token_id=47589, metadata=None))), (34046, (1695, PredictedToken(token=' Cabinet', prob=2.6263296604156494e-07, logit=6.65625, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.602, logit=21.250)', '\" Lily\"[48390] (p=0.173, logit=20.000)', '\" The\"[578] (p=0.119, logit=19.625)', '\" Among\"[22395] (p=0.044, logit=18.625)', '\" A\"[362] (p=0.023, logit=18.000)']\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.6015625, logit=21.25, token_id=34392, metadata=None))), (48390, (2, PredictedToken(token=' Lily', prob=0.1728515625, logit=20.0, token_id=48390, metadata=None))), (47589, (40, PredictedToken(token=' Basketball', prob=0.0001392364501953125, logit=12.875, token_id=47589, metadata=None))), (27217, (44, PredictedToken(token=' Train', prob=0.0001220703125, logit=12.75, token_id=27217, metadata=None))), (23262, (47, PredictedToken(token=' Comb', prob=0.00011491775512695312, logit=12.6875, token_id=23262, metadata=None))), (34046, (623, PredictedToken(token=' Cabinet', prob=1.0579824447631836e-06, logit=8.0, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:26 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:53:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     patch_prediction=['\" Theater\"[38571] (p=0.742, logit=21.500)', '\" The\"[578] (p=0.114, logit=19.625)', '\" A\"[362] (p=0.054, logit=18.875)', '\" Among\"[22395] (p=0.047, logit=18.750)', '\" Theatre\"[27315] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.840, logit=21.500)', '\" The\"[578] (p=0.069, logit=19.000)', '\" A\"[362] (p=0.037, logit=18.375)', '\" Among\"[22395] (p=0.022, logit=17.875)', '\" It\"[1102] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.83984375, logit=21.5, token_id=423, metadata=None))), (72392, (24, PredictedToken(token=' Mixer', prob=0.0002994537353515625, logit=13.5625, token_id=72392, metadata=None))), (59825, (58, PredictedToken(token=' Tie', prob=5.555152893066406e-05, logit=11.875, token_id=59825, metadata=None))), (82994, (160, PredictedToken(token=' Toilet', prob=8.52346420288086e-06, logit=10.0, token_id=82994, metadata=None))), (61948, (383, PredictedToken(token=' Sofa', prob=1.6763806343078613e-06, logit=8.375, token_id=61948, metadata=None))), (16730, (551, PredictedToken(token=' Museum', prob=9.275972843170166e-07, logit=7.78125, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.738, logit=20.750)', '\" The\"[578] (p=0.069, logit=18.375)', '\" Mixer\"[72392] (p=0.053, logit=18.125)', '\" A\"[362] (p=0.042, logit=17.875)', '\" Among\"[22395] (p=0.029, logit=17.500)']\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.73828125, logit=20.75, token_id=16730, metadata=None))), (72392, (3, PredictedToken(token=' Mixer', prob=0.053466796875, logit=18.125, token_id=72392, metadata=None))), (423, (20, PredictedToken(token=' D', prob=0.000919342041015625, logit=14.0625, token_id=423, metadata=None))), (61948, (28, PredictedToken(token=' Sofa', prob=0.00067138671875, logit=13.75, token_id=61948, metadata=None))), (59825, (297, PredictedToken(token=' Tie', prob=6.198883056640625e-06, logit=9.0625, token_id=59825, metadata=None))), (82994, (299, PredictedToken(token=' Toilet', prob=6.198883056640625e-06, logit=9.0625, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:27 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     patch_prediction=['\" Brace\"[70306] (p=0.637, logit=21.500)', '\" A\"[362] (p=0.142, logit=20.000)', '\" The\"[578] (p=0.125, logit=19.875)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:53:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.605, logit=21.000)', '\" The\"[578] (p=0.105, logit=19.250)', '\" A\"[362] (p=0.082, logit=19.000)', '\" Pin\"[17929] (p=0.063, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.625)']\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.60546875, logit=21.0, token_id=13597, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.0634765625, logit=18.75, token_id=17929, metadata=None))), (6031, (7, PredictedToken(token=' Bro', prob=0.01104736328125, logit=17.0, token_id=6031, metadata=None))), (328, (64, PredictedToken(token=' S', prob=0.00013065338134765625, logit=12.5625, token_id=328, metadata=None))), (22725, (87, PredictedToken(token=' Orange', prob=8.96453857421875e-05, logit=12.1875, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.754, logit=21.250)', '\" The\"[578] (p=0.090, logit=19.125)', '\" Among\"[22395] (p=0.048, logit=18.500)', '\" Pin\"[17929] (p=0.043, logit=18.375)', '\" A\"[362] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.75390625, logit=21.25, token_id=328, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.042724609375, logit=18.375, token_id=17929, metadata=None))), (6031, (6, PredictedToken(token=' Bro', prob=0.005096435546875, logit=16.25, token_id=6031, metadata=None))), (13597, (19, PredictedToken(token=' Pen', prob=0.001068115234375, logit=14.6875, token_id=13597, metadata=None))), (22725, (44, PredictedToken(token=' Orange', prob=0.0002689361572265625, logit=13.3125, token_id=22725, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:28 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:28 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.875, logit=22.125)', '\" A\"[362] (p=0.039, logit=19.000)', '\" The\"[578] (p=0.034, logit=18.875)', '\" (\"[320] (p=0.008, logit=17.375)', '\" Among\"[22395] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     clean_prediction=['\" Tiger\"[36845] (p=0.914, logit=22.500)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" The\"[578] (p=0.021, logit=18.750)', '\" A\"[362] (p=0.008, logit=17.750)', '\" (\"[320] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     clean_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.9140625, logit=22.5, token_id=36845, metadata=None))), (65449, (13, PredictedToken(token=' Willow', prob=0.000782012939453125, logit=15.4375, token_id=65449, metadata=None))), (14669, (250, PredictedToken(token=' Camera', prob=1.9371509552001953e-06, logit=9.4375, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     int_prediction=['\" Camera\"[14669] (p=0.887, logit=21.875)', '\" The\"[578] (p=0.021, logit=18.125)', '\" (\"[320] (p=0.016, logit=17.875)', '\" Option\"[7104] (p=0.011, logit=17.500)', '\" A\"[362] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     int_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.88671875, logit=21.875, token_id=14669, metadata=None))), (36845, (9, PredictedToken(token=' Tiger', prob=0.0028228759765625, logit=16.125, token_id=36845, metadata=None))), (65449, (20, PredictedToken(token=' Willow', prob=0.00086212158203125, logit=14.9375, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:28 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:28 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     patch_prediction=['\" Iris\"[66821] (p=0.898, logit=22.250)', '\" The\"[578] (p=0.040, logit=19.125)', '\" Among\"[22395] (p=0.016, logit=18.250)', '\" An\"[1556] (p=0.011, logit=17.875)', '\" (\"[320] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.871, logit=22.750)', '\" The\"[578] (p=0.049, logit=19.875)', '\" An\"[1556] (p=0.030, logit=19.375)', '\" Among\"[22395] (p=0.011, logit=18.375)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.87109375, logit=22.75, token_id=11683, metadata=None))), (55405, (9, PredictedToken(token=' Orch', prob=0.0024566650390625, logit=16.875, token_id=55405, metadata=None))), (14642, (44, PredictedToken(token=' Phone', prob=8.916854858398438e-05, logit=13.5625, token_id=14642, metadata=None)))])\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     int_prediction=['\" Orch\"[55405] (p=0.902, logit=22.125)', '\" An\"[1556] (p=0.027, logit=18.625)', '\" The\"[578] (p=0.021, logit=18.375)', '\" Acc\"[11683] (p=0.007, logit=17.250)', '\" Option\"[7104] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     int_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.90234375, logit=22.125, token_id=55405, metadata=None))), (11683, (5, PredictedToken(token=' Acc', prob=0.00689697265625, logit=17.25, token_id=11683, metadata=None))), (14642, (25, PredictedToken(token=' Phone', prob=0.0003032684326171875, logit=14.125, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:29 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:29 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.809, logit=22.250)', '\" An\"[1556] (p=0.085, logit=20.000)', '\" The\"[578] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:53:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     clean_prediction=['\" Raspberry\"[48665] (p=0.641, logit=21.125)', '\" The\"[578] (p=0.162, logit=19.750)', '\" Among\"[22395] (p=0.077, logit=19.000)', '\" A\"[362] (p=0.047, logit=18.500)', '\" R\"[432] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     clean_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.640625, logit=21.125, token_id=48665, metadata=None))), (1183, (51, PredictedToken(token=' Tr', prob=0.0001392364501953125, logit=12.6875, token_id=1183, metadata=None))), (65197, (434, PredictedToken(token=' Surf', prob=2.3990869522094727e-06, logit=8.625, token_id=65197, metadata=None))), (39794, (1901, PredictedToken(token=' Desk', prob=3.241002559661865e-07, logit=6.625, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.762, logit=22.000)', '\" The\"[578] (p=0.132, logit=20.250)', '\" Among\"[22395] (p=0.038, logit=19.000)', '\" A\"[362] (p=0.026, logit=18.625)', '\" Surf\"[65197] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.76171875, logit=22.0, token_id=1183, metadata=None))), (65197, (5, PredictedToken(token=' Surf', prob=0.00579833984375, logit=17.125, token_id=65197, metadata=None))), (39794, (115, PredictedToken(token=' Desk', prob=1.537799835205078e-05, logit=11.1875, token_id=39794, metadata=None))), (48665, (285, PredictedToken(token=' Raspberry', prob=2.3543834686279297e-06, logit=9.3125, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:30 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.762, logit=21.000)', '\" The\"[578] (p=0.091, logit=18.875)', '\" Among\"[22395] (p=0.038, logit=18.000)', '\" A\"[362] (p=0.033, logit=17.875)', '\" Option\"[7104] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.844, logit=22.000)', '\" The\"[578] (p=0.061, logit=19.375)', '\" A\"[362] (p=0.042, logit=19.000)', '\" Among\"[22395] (p=0.015, logit=18.000)', '\" printer\"[23185] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.84375, logit=22.0, token_id=47033, metadata=None))), (445, (90, PredictedToken(token=' L', prob=2.6345252990722656e-05, logit=11.625, token_id=445, metadata=None))), (24941, (212, PredictedToken(token=' Bear', prob=4.559755325317383e-06, logit=9.875, token_id=24941, metadata=None))), (67553, (1492, PredictedToken(token=' Pants', prob=2.5890767574310303e-07, logit=7.0, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.824, logit=21.500)', '\" The\"[578] (p=0.053, logit=18.750)', '\" Pants\"[67553] (p=0.028, logit=18.125)', '\" A\"[362] (p=0.025, logit=18.000)', '\" Among\"[22395] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.82421875, logit=21.5, token_id=47033, metadata=None))), (67553, (3, PredictedToken(token=' Pants', prob=0.0283203125, logit=18.125, token_id=67553, metadata=None))), (24941, (8, PredictedToken(token=' Bear', prob=0.004913330078125, logit=16.375, token_id=24941, metadata=None))), (445, (7, PredictedToken(token=' L', prob=0.004913330078125, logit=16.375, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:30 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:30 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:53:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.855, logit=21.750)', '\" The\"[578] (p=0.055, logit=19.000)', '\" Among\"[22395] (p=0.033, logit=18.500)', '\" A\"[362] (p=0.020, logit=18.000)', '\" tiger\"[52835] (p=0.003, logit=15.938)']\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.801, logit=21.750)', '\" The\"[578] (p=0.074, logit=19.375)', '\" Among\"[22395] (p=0.051, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.500)', '\" pressure\"[7410] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.80078125, logit=21.75, token_id=40090, metadata=None))), (79028, (9, PredictedToken(token=' Hick', prob=0.00164031982421875, logit=15.5625, token_id=79028, metadata=None))), (6031, (25, PredictedToken(token=' Bro', prob=0.0005340576171875, logit=14.4375, token_id=6031, metadata=None))), (66821, (34, PredictedToken(token=' Iris', prob=0.000324249267578125, logit=13.9375, token_id=66821, metadata=None))), (22725, (61, PredictedToken(token=' Orange', prob=7.200241088867188e-05, logit=12.4375, token_id=22725, metadata=None))), (17810, (192, PredictedToken(token=' Cat', prob=5.930662155151367e-06, logit=9.9375, token_id=17810, metadata=None)))])\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.428, logit=20.375)', '\" Cat\"[17810] (p=0.295, logit=20.000)', '\" Among\"[22395] (p=0.084, logit=18.750)', '\" The\"[578] (p=0.074, logit=18.625)', '\" Hick\"[79028] (p=0.024, logit=17.500)']\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.427734375, logit=20.375, token_id=66821, metadata=None))), (17810, (2, PredictedToken(token=' Cat', prob=0.294921875, logit=20.0, token_id=17810, metadata=None))), (79028, (5, PredictedToken(token=' Hick', prob=0.024169921875, logit=17.5, token_id=79028, metadata=None))), (6031, (7, PredictedToken(token=' Bro', prob=0.01141357421875, logit=16.75, token_id=6031, metadata=None))), (22725, (51, PredictedToken(token=' Orange', prob=0.0003452301025390625, logit=13.25, token_id=22725, metadata=None))), (40090, (319, PredictedToken(token=' Pressure', prob=5.930662155151367e-06, logit=9.1875, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:31 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:31 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     patch_prediction=['\" To\"[2057] (p=0.770, logit=22.375)', '\" The\"[578] (p=0.104, logit=20.375)', '\" A\"[362] (p=0.072, logit=20.000)', '\" Among\"[22395] (p=0.021, logit=18.750)', '\" Printer\"[47033] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:53:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.816, logit=22.125)', '\" The\"[578] (p=0.110, logit=20.125)', '\" A\"[362] (p=0.025, logit=18.625)', '\" Among\"[22395] (p=0.022, logit=18.500)', '\" It\"[1102] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.81640625, logit=22.125, token_id=3420, metadata=None))), (98028, (18, PredictedToken(token=' Bamboo', prob=0.00045013427734375, logit=14.625, token_id=98028, metadata=None))), (30616, (223, PredictedToken(token=' Rice', prob=3.6656856536865234e-06, logit=9.8125, token_id=30616, metadata=None)))])\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     int_prediction=['\" Bamboo\"[98028] (p=0.785, logit=21.000)', '\" The\"[578] (p=0.073, logit=18.625)', '\" Rice\"[30616] (p=0.050, logit=18.250)', '\" Among\"[22395] (p=0.024, logit=17.500)', '\" A\"[362] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     int_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.78515625, logit=21.0, token_id=98028, metadata=None))), (30616, (3, PredictedToken(token=' Rice', prob=0.050048828125, logit=18.25, token_id=30616, metadata=None))), (3420, (918, PredictedToken(token=' Trump', prob=1.214444637298584e-06, logit=7.625, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:32 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:32 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     patch_prediction=['\" Mushroom\"[91297] (p=0.855, logit=21.250)', '\" The\"[578] (p=0.038, logit=18.125)', '\" None\"[2290] (p=0.020, logit=17.500)', '\" A\"[362] (p=0.018, logit=17.375)', '\" Among\"[22395] (p=0.014, logit=17.125)']\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     clean_prediction=['\" Micro\"[18654] (p=0.742, logit=21.250)', '\" The\"[578] (p=0.078, logit=19.000)', '\" A\"[362] (p=0.061, logit=18.750)', '\" Among\"[22395] (p=0.037, logit=18.250)', '\" It\"[1102] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     clean_track=OrderedDict([(18654, (1, PredictedToken(token=' Micro', prob=0.7421875, logit=21.25, token_id=18654, metadata=None))), (1901, (79, PredictedToken(token=' Z', prob=5.91278076171875e-05, logit=11.8125, token_id=1901, metadata=None))), (84008, (198, PredictedToken(token=' Sheep', prob=1.0967254638671875e-05, logit=10.125, token_id=84008, metadata=None)))])\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.895, logit=22.250)', '\" The\"[578] (p=0.045, logit=19.250)', '\" Among\"[22395] (p=0.016, logit=18.250)', '\" z\"[1167] (p=0.007, logit=17.375)', '\" None\"[2290] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.89453125, logit=22.25, token_id=1901, metadata=None))), (18654, (20, PredictedToken(token=' Micro', prob=0.00052642822265625, logit=14.8125, token_id=18654, metadata=None))), (84008, (36, PredictedToken(token=' Sheep', prob=0.0001506805419921875, logit=13.5625, token_id=84008, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:32 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:32 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.805, logit=22.875)', '\" The\"[578] (p=0.075, logit=20.500)', '\" A\"[362] (p=0.075, logit=20.500)', '\" Among\"[22395] (p=0.017, logit=19.000)', '\" Dress\"[29318] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.060, logit=19.125)', '\" A\"[362] (p=0.037, logit=18.625)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" It\"[1102] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.83203125, logit=21.75, token_id=432, metadata=None))), (8325, (40, PredictedToken(token=' Apple', prob=0.00015926361083984375, logit=13.1875, token_id=8325, metadata=None))), (29318, (89, PredictedToken(token=' Dress', prob=3.337860107421875e-05, logit=11.625, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.871, logit=21.875)', '\" The\"[578] (p=0.049, logit=19.000)', '\" Among\"[22395] (p=0.014, logit=17.750)', '\" Apple\"[8325] (p=0.012, logit=17.625)', '\" A\"[362] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.87109375, logit=21.875, token_id=29318, metadata=None))), (8325, (4, PredictedToken(token=' Apple', prob=0.01239013671875, logit=17.625, token_id=8325, metadata=None))), (432, (16, PredictedToken(token=' R', prob=0.0014801025390625, logit=15.5, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:33 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:33 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.730, logit=21.500)', '\" An\"[1556] (p=0.112, logit=19.625)', '\" The\"[578] (p=0.068, logit=19.125)', '\" Among\"[22395] (p=0.032, logit=18.375)', '\" Only\"[8442] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:53:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     clean_prediction=['\" Ch\"[921] (p=0.766, logit=22.500)', '\" The\"[578] (p=0.117, logit=20.625)', '\" A\"[362] (p=0.049, logit=19.750)', '\" Among\"[22395] (p=0.043, logit=19.625)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     clean_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.765625, logit=22.5, token_id=921, metadata=None))), (816, (40, PredictedToken(token=' Y', prob=8.869171142578125e-05, logit=13.4375, token_id=816, metadata=None))), (33199, (80, PredictedToken(token=' Lion', prob=1.8596649169921875e-05, logit=11.875, token_id=33199, metadata=None))), (27171, (102, PredictedToken(token=' Coffee', prob=9.953975677490234e-06, logit=11.25, token_id=27171, metadata=None))), (38673, (290, PredictedToken(token=' Yoga', prob=1.3485550880432129e-06, logit=9.25, token_id=38673, metadata=None))), (10777, (2305, PredictedToken(token=' Router', prob=4.912726581096649e-08, logit=5.9375, token_id=10777, metadata=None)))])\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     int_prediction=['\" Lion\"[33199] (p=0.734, logit=22.000)', '\" The\"[578] (p=0.112, logit=20.125)', '\" A\"[362] (p=0.077, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     int_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.734375, logit=22.0, token_id=33199, metadata=None))), (816, (10, PredictedToken(token=' Y', prob=0.0020599365234375, logit=16.125, token_id=816, metadata=None))), (921, (14, PredictedToken(token=' Ch', prob=0.000713348388671875, logit=15.0625, token_id=921, metadata=None))), (38673, (58, PredictedToken(token=' Yoga', prob=4.839897155761719e-05, logit=12.375, token_id=38673, metadata=None))), (27171, (210, PredictedToken(token=' Coffee', prob=3.0994415283203125e-06, logit=9.625, token_id=27171, metadata=None))), (10777, (523, PredictedToken(token=' Router', prob=7.82310962677002e-07, logit=8.25, token_id=10777, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:34 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:34 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.680, logit=21.875)', '\" The\"[578] (p=0.134, logit=20.250)', '\" A\"[362] (p=0.092, logit=19.875)', '\" Among\"[22395] (p=0.049, logit=19.250)', '\" \"[220] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.498, logit=21.125)', '\" The\"[578] (p=0.235, logit=20.375)', '\" A\"[362] (p=0.184, logit=20.125)', '\" Among\"[22395] (p=0.036, logit=18.500)', '\" It\"[1102] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.498046875, logit=21.125, token_id=28131, metadata=None))), (47759, (14, PredictedToken(token=' Guitar', prob=0.00115966796875, logit=15.0625, token_id=47759, metadata=None))), (49431, (149, PredictedToken(token=' Rabbit', prob=1.3709068298339844e-05, logit=10.625, token_id=49431, metadata=None))), (13120, (171, PredictedToken(token=' Night', prob=1.0073184967041016e-05, logit=10.3125, token_id=13120, metadata=None))), (82994, (229, PredictedToken(token=' Toilet', prob=5.7220458984375e-06, logit=9.75, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.691, logit=21.250)', '\" The\"[578] (p=0.120, logit=19.500)', '\" A\"[362] (p=0.120, logit=19.500)', '\" Among\"[22395] (p=0.024, logit=17.875)', '\" Rab\"[36824] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.69140625, logit=21.25, token_id=49431, metadata=None))), (28131, (6, PredictedToken(token=' Golf', prob=0.00408935546875, logit=16.125, token_id=28131, metadata=None))), (13120, (20, PredictedToken(token=' Night', prob=0.000667572021484375, logit=14.3125, token_id=13120, metadata=None))), (47759, (40, PredictedToken(token=' Guitar', prob=0.00018024444580078125, logit=13.0, token_id=47759, metadata=None))), (82994, (168, PredictedToken(token=' Toilet', prob=1.150369644165039e-05, logit=10.25, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:34 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:53:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.758, logit=22.125)', '\" The\"[578] (p=0.080, logit=19.875)', '\" A\"[362] (p=0.080, logit=19.875)', '\" Among\"[22395] (p=0.049, logit=19.375)', '\" Only\"[8442] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.734, logit=21.000)', '\" The\"[578] (p=0.100, logit=19.000)', '\" A\"[362] (p=0.060, logit=18.500)', '\" Among\"[22395] (p=0.042, logit=18.125)', '\" Option\"[7104] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.734375, logit=21.0, token_id=28131, metadata=None))), (49431, (25, PredictedToken(token=' Rabbit', prob=0.000591278076171875, logit=13.875, token_id=49431, metadata=None))), (10777, (29, PredictedToken(token=' Router', prob=0.000522613525390625, logit=13.75, token_id=10777, metadata=None))), (83499, (45, PredictedToken(token=' Tooth', prob=0.0002460479736328125, logit=13.0, token_id=83499, metadata=None))), (18787, (147, PredictedToken(token=' Oak', prob=1.5735626220703125e-05, logit=10.25, token_id=18787, metadata=None))), (34046, (246, PredictedToken(token=' Cabinet', prob=6.16908073425293e-06, logit=9.3125, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     int_prediction=['\" Cabinet\"[34046] (p=0.879, logit=21.125)', '\" The\"[578] (p=0.044, logit=18.125)', '\" Oak\"[18787] (p=0.014, logit=17.000)', '\" A\"[362] (p=0.010, logit=16.625)', '\" (\"[320] (p=0.007, logit=16.250)']\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     int_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.87890625, logit=21.125, token_id=34046, metadata=None))), (18787, (3, PredictedToken(token=' Oak', prob=0.01416015625, logit=17.0, token_id=18787, metadata=None))), (28131, (24, PredictedToken(token=' Golf', prob=0.00054931640625, logit=13.75, token_id=28131, metadata=None))), (10777, (50, PredictedToken(token=' Router', prob=0.0001392364501953125, logit=12.375, token_id=10777, metadata=None))), (83499, (66, PredictedToken(token=' Tooth', prob=6.580352783203125e-05, logit=11.625, token_id=83499, metadata=None))), (49431, (183, PredictedToken(token=' Rabbit', prob=8.344650268554688e-06, logit=9.5625, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:35 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:35 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.805, logit=21.750)', '\" The\"[578] (p=0.075, logit=19.375)', '\" A\"[362] (p=0.045, logit=18.875)', '\" Among\"[22395] (p=0.040, logit=18.750)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     clean_prediction=['\" Mar\"[2947] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.087, logit=19.875)', '\" Among\"[22395] (p=0.025, logit=18.625)', '\" A\"[362] (p=0.025, logit=18.625)', '\" MAR\"[38599] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     clean_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.82421875, logit=22.125, token_id=2947, metadata=None))), (328, (58, PredictedToken(token=' S', prob=3.981590270996094e-05, logit=12.1875, token_id=328, metadata=None))), (2057, (62, PredictedToken(token=' To', prob=3.314018249511719e-05, logit=12.0, token_id=2057, metadata=None))), (38673, (400, PredictedToken(token=' Yoga', prob=1.1324882507324219e-06, logit=8.625, token_id=38673, metadata=None))), (68027, (437, PredictedToken(token=' Sax', prob=9.98377799987793e-07, logit=8.5, token_id=68027, metadata=None))), (49431, (626, PredictedToken(token=' Rabbit', prob=5.513429641723633e-07, logit=7.90625, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     int_prediction=['\" To\"[2057] (p=0.602, logit=20.625)', '\" The\"[578] (p=0.151, logit=19.250)', '\" A\"[362] (p=0.118, logit=19.000)', '\" Mar\"[2947] (p=0.026, logit=17.500)', '\" Among\"[22395] (p=0.021, logit=17.250)']\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     int_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.6015625, logit=20.625, token_id=2057, metadata=None))), (2947, (4, PredictedToken(token=' Mar', prob=0.0263671875, logit=17.5, token_id=2947, metadata=None))), (328, (6, PredictedToken(token=' S', prob=0.0181884765625, logit=17.125, token_id=328, metadata=None))), (68027, (11, PredictedToken(token=' Sax', prob=0.0026092529296875, logit=15.1875, token_id=68027, metadata=None))), (38673, (30, PredictedToken(token=' Yoga', prob=0.0004825592041015625, logit=13.5, token_id=38673, metadata=None))), (49431, (93, PredictedToken(token=' Rabbit', prob=5.1021575927734375e-05, logit=11.25, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:36 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:36 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.938, logit=22.000)', '\" The\"[578] (p=0.015, logit=17.875)', '\" Razor\"[74968] (p=0.012, logit=17.625)', '\" Among\"[22395] (p=0.006, logit=16.875)', '\" football\"[9141] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     clean_prediction=['\" Tul\"[43316] (p=0.875, logit=21.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" (\"[320] (p=0.016, logit=17.625)', '\" A\"[362] (p=0.014, logit=17.500)', '\" D\"[423] (p=0.011, logit=17.250)']\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     clean_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.875, logit=21.625, token_id=43316, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.01104736328125, logit=17.25, token_id=423, metadata=None))), (10777, (235, PredictedToken(token=' Router', prob=5.3942203521728516e-06, logit=9.625, token_id=10777, metadata=None)))])\n",
      "2025-09-16 09:53:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     int_prediction=['\" Router\"[10777] (p=0.727, logit=20.375)', '\" A\"[362] (p=0.067, logit=18.000)', '\" The\"[578] (p=0.052, logit=17.750)', '\" Tul\"[43316] (p=0.041, logit=17.500)', '\" (\"[320] (p=0.017, logit=16.625)']\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     int_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.7265625, logit=20.375, token_id=10777, metadata=None))), (43316, (4, PredictedToken(token=' Tul', prob=0.041015625, logit=17.5, token_id=43316, metadata=None))), (423, (11, PredictedToken(token=' D', prob=0.00457763671875, logit=15.3125, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:37 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.672, logit=21.625)', '\" The\"[578] (p=0.117, logit=19.875)', '\" A\"[362] (p=0.091, logit=19.625)', '\" Among\"[22395] (p=0.071, logit=19.375)', '\" It\"[1102] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     clean_prediction=['\" Amb\"[20423] (p=0.738, logit=22.500)', '\" Among\"[22395] (p=0.078, logit=20.250)', '\" An\"[1556] (p=0.078, logit=20.250)', '\" The\"[578] (p=0.053, logit=19.875)', '\" Option\"[7104] (p=0.013, logit=18.500)']\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     clean_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.73828125, logit=22.5, token_id=20423, metadata=None))), (445, (11, PredictedToken(token=' L', prob=0.00160980224609375, logit=16.375, token_id=445, metadata=None))), (15883, (17, PredictedToken(token=' Spr', prob=0.000812530517578125, logit=15.6875, token_id=15883, metadata=None))), (28131, (55, PredictedToken(token=' Golf', prob=5.53131103515625e-05, logit=13.0, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     int_prediction=['\" Spr\"[15883] (p=0.922, logit=22.125)', '\" The\"[578] (p=0.025, logit=18.500)', '\" Among\"[22395] (p=0.009, logit=17.500)', '\" L\"[445] (p=0.008, logit=17.375)', '\" Option\"[7104] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     int_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.921875, logit=22.125, token_id=15883, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.00799560546875, logit=17.375, token_id=445, metadata=None))), (20423, (121, PredictedToken(token=' Amb', prob=1.2755393981933594e-05, logit=10.9375, token_id=20423, metadata=None))), (28131, (206, PredictedToken(token=' Golf', prob=4.708766937255859e-06, logit=9.9375, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:37 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:37 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:53:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.938, logit=22.750)', '\" The\"[578] (p=0.017, logit=18.750)', '\" Among\"[22395] (p=0.009, logit=18.125)', '\" blue\"[6437] (p=0.006, logit=17.625)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.957, logit=23.000)', '\" The\"[578] (p=0.015, logit=18.875)', '\" Among\"[22395] (p=0.009, logit=18.375)', '\" violet\"[80836] (p=0.003, logit=17.125)', '\" Option\"[7104] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.95703125, logit=23.0, token_id=74574, metadata=None))), (10164, (36, PredictedToken(token=' Water', prob=7.152557373046875e-05, logit=13.5, token_id=10164, metadata=None))), (65197, (117, PredictedToken(token=' Surf', prob=5.513429641723633e-06, logit=10.9375, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.719, logit=21.500)', '\" Water\"[10164] (p=0.160, logit=20.000)', '\" Surf\"[65197] (p=0.028, logit=18.250)', '\" None\"[2290] (p=0.022, logit=18.000)', '\" The\"[578] (p=0.022, logit=18.000)']\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.71875, logit=21.5, token_id=74574, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.16015625, logit=20.0, token_id=10164, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.02783203125, logit=18.25, token_id=65197, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:38 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.910, logit=23.750)', '\" The\"[578] (p=0.040, logit=20.625)', '\" A\"[362] (p=0.028, logit=20.250)', '\" Among\"[22395] (p=0.010, logit=19.250)', '\" Motor\"[18079] (p=0.002, logit=17.375)']\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     clean_prediction=['\" Rose\"[16344] (p=0.684, logit=22.250)', '\" The\"[578] (p=0.119, logit=20.500)', '\" A\"[362] (p=0.105, logit=20.375)', '\" Among\"[22395] (p=0.050, logit=19.625)', '\" It\"[1102] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     clean_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.68359375, logit=22.25, token_id=16344, metadata=None))), (3804, (20, PredictedToken(token=' Sub', prob=0.000377655029296875, logit=14.75, token_id=3804, metadata=None))), (4923, (44, PredictedToken(token=' Sk', prob=0.00010204315185546875, logit=13.4375, token_id=4923, metadata=None))), (11896, (172, PredictedToken(token=' Library', prob=4.470348358154297e-06, logit=10.3125, token_id=11896, metadata=None))), (86460, (214, PredictedToken(token=' Necklace', prob=3.069639205932617e-06, logit=9.9375, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.742, logit=21.750)', '\" Sub\"[3804] (p=0.114, logit=19.875)', '\" The\"[578] (p=0.069, logit=19.375)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" Option\"[7104] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.7421875, logit=21.75, token_id=4923, metadata=None))), (3804, (2, PredictedToken(token=' Sub', prob=0.11376953125, logit=19.875, token_id=3804, metadata=None))), (86460, (66, PredictedToken(token=' Necklace', prob=4.601478576660156e-05, logit=12.0625, token_id=86460, metadata=None))), (11896, (122, PredictedToken(token=' Library', prob=9.655952453613281e-06, logit=10.5, token_id=11896, metadata=None))), (16344, (233, PredictedToken(token=' Rose', prob=3.129243850708008e-06, logit=9.375, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:39 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:39 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.840, logit=21.000)', '\" Mixer\"[72392] (p=0.037, logit=17.875)', '\" The\"[578] (p=0.037, logit=17.875)', '\" Among\"[22395] (p=0.017, logit=17.125)', '\" A\"[362] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:53:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.781, logit=20.875)', '\" The\"[578] (p=0.064, logit=18.375)', '\" A\"[362] (p=0.057, logit=18.250)', '\" Among\"[22395] (p=0.034, logit=17.750)', '\" It\"[1102] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.78125, logit=20.875, token_id=42609, metadata=None))), (41342, (13, PredictedToken(token=' Hockey', prob=0.001708984375, logit=14.75, token_id=41342, metadata=None))), (31181, (129, PredictedToken(token=' Clar', prob=2.288818359375e-05, logit=10.4375, token_id=31181, metadata=None))), (18191, (197, PredictedToken(token=' Mouse', prob=1.150369644165039e-05, logit=9.75, token_id=18191, metadata=None))), (19111, (243, PredictedToken(token=' Bus', prob=7.927417755126953e-06, logit=9.375, token_id=19111, metadata=None))), (63606, (528, PredictedToken(token=' Stap', prob=2.2649765014648438e-06, logit=8.125, token_id=63606, metadata=None)))])\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.523, logit=20.250)', '\" Hockey\"[41342] (p=0.169, logit=19.125)', '\" The\"[578] (p=0.116, logit=18.750)', '\" A\"[362] (p=0.080, logit=18.375)', '\" Among\"[22395] (p=0.029, logit=17.375)']\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.5234375, logit=20.25, token_id=31181, metadata=None))), (41342, (2, PredictedToken(token=' Hockey', prob=0.1689453125, logit=19.125, token_id=41342, metadata=None))), (63606, (6, PredictedToken(token=' Stap', prob=0.01226806640625, logit=16.5, token_id=63606, metadata=None))), (19111, (8, PredictedToken(token=' Bus', prob=0.00543212890625, logit=15.6875, token_id=19111, metadata=None))), (18191, (91, PredictedToken(token=' Mouse', prob=6.866455078125e-05, logit=11.3125, token_id=18191, metadata=None))), (42609, (2125, PredictedToken(token=' Pine', prob=4.917383193969727e-07, logit=6.375, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:40 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:40 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.805, logit=20.875)', '\" None\"[2290] (p=0.052, logit=18.125)', '\" The\"[578] (p=0.045, logit=18.000)', '\" Among\"[22395] (p=0.028, logit=17.500)', '\" A\"[362] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.875, logit=22.125)', '\" An\"[1556] (p=0.038, logit=19.000)', '\" The\"[578] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.023, logit=18.500)', '\" ank\"[71572] (p=0.014, logit=18.000)']\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.875, logit=22.125, token_id=57915, metadata=None))), (15883, (19, PredictedToken(token=' Spr', prob=0.0003528594970703125, logit=14.3125, token_id=15883, metadata=None))), (82452, (94, PredictedToken(token=' Jasmine', prob=1.990795135498047e-05, logit=11.4375, token_id=82452, metadata=None))), (100031, (314, PredictedToken(token=' Mosque', prob=1.7434358596801758e-06, logit=9.0, token_id=100031, metadata=None))), (13120, (323, PredictedToken(token=' Night', prob=1.6391277313232422e-06, logit=8.9375, token_id=13120, metadata=None))), (74968, (336, PredictedToken(token=' Razor', prob=1.5422701835632324e-06, logit=8.875, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     int_prediction=['\" Night\"[13120] (p=0.902, logit=21.875)', '\" Among\"[22395] (p=0.027, logit=18.375)', '\" The\"[578] (p=0.021, logit=18.125)', '\" night\"[3814] (p=0.011, logit=17.500)', '\" A\"[362] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     int_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.90234375, logit=21.875, token_id=13120, metadata=None))), (15883, (6, PredictedToken(token=' Spr', prob=0.003692626953125, logit=16.375, token_id=15883, metadata=None))), (100031, (30, PredictedToken(token=' Mosque', prob=0.00022125244140625, logit=13.5625, token_id=100031, metadata=None))), (74968, (139, PredictedToken(token=' Razor', prob=9.119510650634766e-06, logit=10.375, token_id=74968, metadata=None))), (82452, (234, PredictedToken(token=' Jasmine', prob=3.814697265625e-06, logit=9.5, token_id=82452, metadata=None))), (57915, (277, PredictedToken(token=' Ank', prob=2.6226043701171875e-06, logit=9.125, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:40 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:53:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.723, logit=21.875)', '\" The\"[578] (p=0.126, logit=20.125)', '\" Among\"[22395] (p=0.052, logit=19.250)', '\" A\"[362] (p=0.052, logit=19.250)', '\" dress\"[8679] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.941, logit=21.875)', '\" The\"[578] (p=0.017, logit=17.875)', '\" Among\"[22395] (p=0.012, logit=17.500)', '\" A\"[362] (p=0.003, logit=16.000)', '\" It\"[1102] (p=0.002, logit=15.625)']\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.94140625, logit=21.875, token_id=72683, metadata=None))), (8325, (10, PredictedToken(token=' Apple', prob=0.0013275146484375, logit=15.3125, token_id=8325, metadata=None))), (79028, (13, PredictedToken(token=' Hick', prob=0.000972747802734375, logit=15.0, token_id=79028, metadata=None))), (328, (12, PredictedToken(token=' S', prob=0.000972747802734375, logit=15.0, token_id=328, metadata=None))), (24423, (22, PredictedToken(token=' Monitor', prob=0.000431060791015625, logit=14.1875, token_id=24423, metadata=None)))])\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.914, logit=21.500)', '\" None\"[2290] (p=0.021, logit=17.750)', '\" The\"[578] (p=0.021, logit=17.750)', '\" Among\"[22395] (p=0.005, logit=16.375)', '\" socks\"[40086] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.9140625, logit=21.5, token_id=328, metadata=None))), (79028, (9, PredictedToken(token=' Hick', prob=0.0019989013671875, logit=15.375, token_id=79028, metadata=None))), (8325, (42, PredictedToken(token=' Apple', prob=0.000164031982421875, logit=12.875, token_id=8325, metadata=None))), (72683, (49, PredictedToken(token=' Boxing', prob=0.0001277923583984375, logit=12.625, token_id=72683, metadata=None))), (24423, (148, PredictedToken(token=' Monitor', prob=1.3470649719238281e-05, logit=10.375, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:41 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     patch_prediction=['\" Chain\"[29625] (p=0.910, logit=22.875)', '\" The\"[578] (p=0.027, logit=19.375)', '\" A\"[362] (p=0.021, logit=19.125)', '\" None\"[2290] (p=0.011, logit=18.500)', '\" Among\"[22395] (p=0.010, logit=18.375)']\n",
      "2025-09-16 09:53:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.707, logit=21.875)', '\" The\"[578] (p=0.108, logit=20.000)', '\" A\"[362] (p=0.084, logit=19.750)', '\" Among\"[22395] (p=0.045, logit=19.125)', '\" It\"[1102] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.70703125, logit=21.875, token_id=12369, metadata=None))), (445, (14, PredictedToken(token=' L', prob=0.00093841552734375, logit=15.25, token_id=445, metadata=None))), (6914, (17, PredictedToken(token=' Let', prob=0.000881195068359375, logit=15.1875, token_id=6914, metadata=None))), (6690, (23, PredictedToken(token=' Air', prob=0.000728607177734375, logit=15.0, token_id=6690, metadata=None))), (33711, (26, PredictedToken(token=' Suit', prob=0.000568389892578125, logit=14.75, token_id=33711, metadata=None)))])\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.727, logit=21.500)', '\" The\"[578] (p=0.077, logit=19.250)', '\" Among\"[22395] (p=0.068, logit=19.125)', '\" A\"[362] (p=0.036, logit=18.500)', '\" Suit\"[33711] (p=0.022, logit=18.000)']\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.7265625, logit=21.5, token_id=445, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.02197265625, logit=18.0, token_id=33711, metadata=None))), (6914, (6, PredictedToken(token=' Let', prob=0.0133056640625, logit=17.5, token_id=6914, metadata=None))), (6690, (51, PredictedToken(token=' Air', prob=0.00013065338134765625, logit=12.875, token_id=6690, metadata=None))), (12369, (104, PredictedToken(token=' Food', prob=3.314018249511719e-05, logit=11.5, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:42 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:42 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.918, logit=22.625)', '\" None\"[2290] (p=0.019, logit=18.750)', '\" The\"[578] (p=0.017, logit=18.625)', '\" Among\"[22395] (p=0.015, logit=18.500)', '\" A\"[362] (p=0.012, logit=18.250)']\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.785, logit=21.375)', '\" The\"[578] (p=0.064, logit=18.875)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.027, logit=18.000)', '\" F\"[435] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.78515625, logit=21.375, token_id=75258, metadata=None))), (48471, (67, PredictedToken(token=' Shower', prob=9.059906005859375e-05, logit=12.3125, token_id=48471, metadata=None))), (30760, (119, PredictedToken(token=' Scar', prob=2.5987625122070312e-05, logit=11.0625, token_id=30760, metadata=None)))])\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     int_prediction=['\" Scar\"[30760] (p=0.609, logit=20.125)', '\" The\"[578] (p=0.120, logit=18.500)', '\" Among\"[22395] (p=0.064, logit=17.875)', '\" None\"[2290] (p=0.050, logit=17.625)', '\" A\"[362] (p=0.050, logit=17.625)']\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     int_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.609375, logit=20.125, token_id=30760, metadata=None))), (48471, (9, PredictedToken(token=' Shower', prob=0.005279541015625, logit=15.375, token_id=48471, metadata=None))), (75258, (86, PredictedToken(token=' Refriger', prob=0.0001239776611328125, logit=11.625, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:42 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:53:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.699, logit=20.875)', '\" The\"[578] (p=0.107, logit=19.000)', '\" headphones\"[44101] (p=0.051, logit=18.250)', '\" Among\"[22395] (p=0.045, logit=18.125)', '\" (\"[320] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.734, logit=22.125)', '\" The\"[578] (p=0.128, logit=20.375)', '\" Among\"[22395] (p=0.047, logit=19.375)', '\" A\"[362] (p=0.042, logit=19.250)', '\" dress\"[8679] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.734375, logit=22.125, token_id=29318, metadata=None))), (84409, (7, PredictedToken(token=' Plum', prob=0.0038604736328125, logit=16.875, token_id=84409, metadata=None))), (14642, (113, PredictedToken(token=' Phone', prob=1.3053417205810547e-05, logit=11.1875, token_id=14642, metadata=None))), (3420, (152, PredictedToken(token=' Trump', prob=6.16908073425293e-06, logit=10.4375, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.691, logit=21.500)', '\" Trump\"[3420] (p=0.175, logit=20.125)', '\" The\"[578] (p=0.064, logit=19.125)', '\" Among\"[22395] (p=0.016, logit=17.750)', '\" A\"[362] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.69140625, logit=21.5, token_id=14642, metadata=None))), (3420, (2, PredictedToken(token=' Trump', prob=0.1748046875, logit=20.125, token_id=3420, metadata=None))), (84409, (63, PredictedToken(token=' Plum', prob=8.535385131835938e-05, logit=12.5, token_id=84409, metadata=None))), (29318, (260, PredictedToken(token=' Dress', prob=4.26173210144043e-06, logit=9.5, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:43 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:43 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.059, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=18.625)', '\" tooth\"[26588] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:53:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     clean_prediction=['\" Cherry\"[45805] (p=0.766, logit=21.625)', '\" The\"[578] (p=0.091, logit=19.500)', '\" Among\"[22395] (p=0.055, logit=19.000)', '\" A\"[362] (p=0.038, logit=18.625)', '\" (\"[320] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     clean_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.765625, logit=21.625, token_id=45805, metadata=None))), (40759, (46, PredictedToken(token=' Harmon', prob=0.0001468658447265625, logit=13.0625, token_id=40759, metadata=None))), (61731, (64, PredictedToken(token=' Soap', prob=5.745887756347656e-05, logit=12.125, token_id=61731, metadata=None))), (40975, (201, PredictedToken(token=' Marker', prob=6.0498714447021484e-06, logit=9.875, token_id=40975, metadata=None)))])\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.738, logit=21.500)', '\" The\"[578] (p=0.061, logit=19.000)', '\" A\"[362] (p=0.053, logit=18.875)', '\" Soap\"[61731] (p=0.047, logit=18.750)', '\" Among\"[22395] (p=0.047, logit=18.750)']\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.73828125, logit=21.5, token_id=40759, metadata=None))), (61731, (5, PredictedToken(token=' Soap', prob=0.047119140625, logit=18.75, token_id=61731, metadata=None))), (40975, (6, PredictedToken(token=' Marker', prob=0.00927734375, logit=17.125, token_id=40975, metadata=None))), (45805, (39, PredictedToken(token=' Cherry', prob=0.0002803802490234375, logit=13.625, token_id=45805, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:44 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:44 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.598, logit=20.000)', '\" Among\"[22395] (p=0.104, logit=18.250)', '\" The\"[578] (p=0.104, logit=18.250)', '\" A\"[362] (p=0.071, logit=17.875)', '\" None\"[2290] (p=0.020, logit=16.625)']\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.895, logit=22.750)', '\" The\"[578] (p=0.051, logit=19.875)', '\" Among\"[22395] (p=0.027, logit=19.250)', '\" z\"[1167] (p=0.005, logit=17.500)', '\" \"[220] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.89453125, logit=22.75, token_id=1901, metadata=None))), (50159, (54, PredictedToken(token=' Sco', prob=4.315376281738281e-05, logit=12.8125, token_id=50159, metadata=None))), (32498, (100, PredictedToken(token=' Mall', prob=1.0907649993896484e-05, logit=11.4375, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     int_prediction=['\" Mall\"[32498] (p=0.883, logit=21.875)', '\" The\"[578] (p=0.034, logit=18.625)', '\" A\"[362] (p=0.018, logit=18.000)', '\" Among\"[22395] (p=0.016, logit=17.875)', '\" None\"[2290] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     int_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.8828125, logit=21.875, token_id=32498, metadata=None))), (50159, (7, PredictedToken(token=' Sco', prob=0.00408935546875, logit=16.5, token_id=50159, metadata=None))), (1901, (58, PredictedToken(token=' Z', prob=5.14984130859375e-05, logit=12.125, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:44 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:53:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     patch_prediction=['\" Bus\"[19111] (p=0.734, logit=22.250)', '\" The\"[578] (p=0.113, logit=20.375)', '\" Among\"[22395] (p=0.060, logit=19.750)', '\" A\"[362] (p=0.053, logit=19.625)', '\" It\"[1102] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.664, logit=21.500)', '\" The\"[578] (p=0.148, logit=20.000)', '\" A\"[362] (p=0.131, logit=19.875)', '\" Among\"[22395] (p=0.023, logit=18.125)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.6640625, logit=21.5, token_id=28131, metadata=None))), (1183, (63, PredictedToken(token=' Tr', prob=5.2928924560546875e-05, logit=12.0625, token_id=1183, metadata=None))), (43316, (73, PredictedToken(token=' Tul', prob=3.8623809814453125e-05, logit=11.75, token_id=43316, metadata=None))), (26781, (148, PredictedToken(token=' Hair', prob=1.043081283569336e-05, logit=10.4375, token_id=26781, metadata=None))), (24941, (255, PredictedToken(token=' Bear', prob=3.591179847717285e-06, logit=9.375, token_id=24941, metadata=None))), (58403, (430, PredictedToken(token=' Tablet', prob=1.5944242477416992e-06, logit=8.5625, token_id=58403, metadata=None)))])\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.734, logit=21.375)', '\" A\"[362] (p=0.099, logit=19.375)', '\" The\"[578] (p=0.087, logit=19.250)', '\" Among\"[22395] (p=0.020, logit=17.750)', '\" Golf\"[28131] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.734375, logit=21.375, token_id=1183, metadata=None))), (28131, (5, PredictedToken(token=' Golf', prob=0.0118408203125, logit=17.25, token_id=28131, metadata=None))), (26781, (7, PredictedToken(token=' Hair', prob=0.00494384765625, logit=16.375, token_id=26781, metadata=None))), (24941, (9, PredictedToken(token=' Bear', prob=0.0031890869140625, logit=15.9375, token_id=24941, metadata=None))), (58403, (12, PredictedToken(token=' Tablet', prob=0.0013275146484375, logit=15.0625, token_id=58403, metadata=None))), (43316, (17, PredictedToken(token=' Tul', prob=0.000804901123046875, logit=14.5625, token_id=43316, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:45 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.891, logit=21.625)', '\" The\"[578] (p=0.024, logit=18.000)', '\" Brace\"[70306] (p=0.021, logit=17.875)', '\" helmet\"[32635] (p=0.008, logit=16.875)', '\" A\"[362] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.848, logit=22.750)', '\" A\"[362] (p=0.054, logit=20.000)', '\" The\"[578] (p=0.042, logit=19.750)', '\" Among\"[22395] (p=0.023, logit=19.125)', '\" cuff\"[75523] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.84765625, logit=22.75, token_id=356, metadata=None))), (432, (22, PredictedToken(token=' R', prob=0.0003223419189453125, logit=14.875, token_id=432, metadata=None))), (1901, (34, PredictedToken(token=' Z', prob=0.0001430511474609375, logit=14.0625, token_id=1901, metadata=None)))])\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.469, logit=21.750)', '\" R\"[432] (p=0.365, logit=21.500)', '\" The\"[578] (p=0.050, logit=19.500)', '\" A\"[362] (p=0.044, logit=19.375)', '\" Among\"[22395] (p=0.030, logit=19.000)']\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.46875, logit=21.75, token_id=356, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.365234375, logit=21.5, token_id=432, metadata=None))), (1901, (21, PredictedToken(token=' Z', prob=0.00066375732421875, logit=15.1875, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:46 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:46 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.875, logit=21.625)', '\" Among\"[22395] (p=0.030, logit=18.250)', '\" The\"[578] (p=0.030, logit=18.250)', '\" Option\"[7104] (p=0.009, logit=17.000)', '\" tooth\"[26588] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.668, logit=21.750)', '\" The\"[578] (p=0.148, logit=20.250)', '\" A\"[362] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.048, logit=19.125)', '\" Dress\"[29318] (p=0.020, logit=18.250)']\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.66796875, logit=21.75, token_id=55807, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.0201416015625, logit=18.25, token_id=29318, metadata=None))), (61731, (45, PredictedToken(token=' Soap', prob=0.00015354156494140625, logit=13.375, token_id=61731, metadata=None))), (3420, (62, PredictedToken(token=' Trump', prob=9.918212890625e-05, logit=12.9375, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:53:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.523, logit=21.500)', '\" Shirt\"[55807] (p=0.246, logit=20.750)', '\" The\"[578] (p=0.132, logit=20.125)', '\" Among\"[22395] (p=0.038, logit=18.875)', '\" A\"[362] (p=0.020, logit=18.250)']\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.5234375, logit=21.5, token_id=61731, metadata=None))), (55807, (2, PredictedToken(token=' Shirt', prob=0.24609375, logit=20.75, token_id=55807, metadata=None))), (3420, (49, PredictedToken(token=' Trump', prob=9.393692016601562e-05, logit=12.875, token_id=3420, metadata=None))), (29318, (104, PredictedToken(token=' Dress', prob=2.682209014892578e-05, logit=11.625, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:47 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.879, logit=21.750)', '\" A\"[362] (p=0.034, logit=18.500)', '\" The\"[578] (p=0.026, logit=18.250)', '\" Among\"[22395] (p=0.008, logit=17.000)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.828, logit=21.375)', '\" The\"[578] (p=0.068, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.125)', '\" A\"[362] (p=0.017, logit=17.500)', '\" Option\"[7104] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.828125, logit=21.375, token_id=82994, metadata=None))), (445, (8, PredictedToken(token=' L', prob=0.003387451171875, logit=15.875, token_id=445, metadata=None))), (4783, (31, PredictedToken(token=' House', prob=0.00040435791015625, logit=13.75, token_id=4783, metadata=None))), (91297, (178, PredictedToken(token=' Mushroom', prob=1.3828277587890625e-05, logit=10.375, token_id=91297, metadata=None))), (10777, (189, PredictedToken(token=' Router', prob=1.2218952178955078e-05, logit=10.25, token_id=10777, metadata=None)))])\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.867, logit=21.500)', '\" The\"[578] (p=0.043, logit=18.500)', '\" Among\"[22395] (p=0.018, logit=17.625)', '\" A\"[362] (p=0.018, logit=17.625)', '\" (\"[320] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.8671875, logit=21.5, token_id=445, metadata=None))), (10777, (8, PredictedToken(token=' Router', prob=0.0040283203125, logit=16.125, token_id=10777, metadata=None))), (91297, (10, PredictedToken(token=' Mushroom', prob=0.0021514892578125, logit=15.5, token_id=91297, metadata=None))), (82994, (11, PredictedToken(token=' Toilet', prob=0.00189971923828125, logit=15.375, token_id=82994, metadata=None))), (4783, (109, PredictedToken(token=' House', prob=3.075599670410156e-05, logit=11.25, token_id=4783, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:47 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:47 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     patch_prediction=['\" Raspberry\"[48665] (p=0.750, logit=21.125)', '\" The\"[578] (p=0.090, logit=19.000)', '\" Among\"[22395] (p=0.070, logit=18.750)', '\" R\"[432] (p=0.020, logit=17.500)', '\" A\"[362] (p=0.018, logit=17.375)']\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.750, logit=21.375)', '\" The\"[578] (p=0.102, logit=19.375)', '\" Among\"[22395] (p=0.062, logit=18.875)', '\" An\"[1556] (p=0.042, logit=18.500)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.75, logit=21.375, token_id=66821, metadata=None))), (89077, (29, PredictedToken(token=' Strawberry', prob=0.000286102294921875, logit=13.5, token_id=89077, metadata=None))), (816, (89, PredictedToken(token=' Y', prob=3.1948089599609375e-05, logit=11.3125, token_id=816, metadata=None))), (16488, (176, PredictedToken(token=' Bat', prob=9.179115295410156e-06, logit=10.0625, token_id=16488, metadata=None))), (65197, (867, PredictedToken(token=' Surf', prob=7.525086402893066e-07, logit=7.5625, token_id=65197, metadata=None))), (61948, (3881, PredictedToken(token=' Sofa', prob=9.872019290924072e-08, logit=5.53125, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     int_prediction=['\" Strawberry\"[89077] (p=0.637, logit=21.000)', '\" The\"[578] (p=0.161, logit=19.625)', '\" Among\"[22395] (p=0.086, logit=19.000)', '\" Iris\"[66821] (p=0.032, logit=18.000)', '\" A\"[362] (p=0.032, logit=18.000)']\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     int_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.63671875, logit=21.0, token_id=89077, metadata=None))), (66821, (5, PredictedToken(token=' Iris', prob=0.03173828125, logit=18.0, token_id=66821, metadata=None))), (816, (114, PredictedToken(token=' Y', prob=2.7179718017578125e-05, logit=10.9375, token_id=816, metadata=None))), (65197, (287, PredictedToken(token=' Surf', prob=5.364418029785156e-06, logit=9.3125, token_id=65197, metadata=None))), (16488, (691, PredictedToken(token=' Bat', prob=1.4454126358032227e-06, logit=8.0, token_id=16488, metadata=None))), (61948, (2679, PredictedToken(token=' Sofa', prob=2.421438694000244e-07, logit=6.21875, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:48 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:48 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.883, logit=21.500)', '\" The\"[578] (p=0.027, logit=18.000)', '\" Among\"[22395] (p=0.016, logit=17.500)', '\" Cherry\"[45805] (p=0.014, logit=17.375)', '\" A\"[362] (p=0.014, logit=17.375)']\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     clean_prediction=['\" Hat\"[22050] (p=0.590, logit=21.375)', '\" The\"[578] (p=0.191, logit=20.250)', '\" Among\"[22395] (p=0.090, logit=19.500)', '\" A\"[362] (p=0.070, logit=19.250)', '\" hat\"[9072] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     clean_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.58984375, logit=21.375, token_id=22050, metadata=None))), (65329, (68, PredictedToken(token=' Elm', prob=8.249282836914062e-05, logit=12.5, token_id=65329, metadata=None))), (34785, (81, PredictedToken(token=' Truck', prob=5.316734313964844e-05, logit=12.0625, token_id=34785, metadata=None))), (47759, (135, PredictedToken(token=' Guitar', prob=1.8358230590820312e-05, logit=11.0, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:53:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.746, logit=20.875)', '\" The\"[578] (p=0.115, logit=19.000)', '\" Among\"[22395] (p=0.054, logit=18.250)', '\" It\"[1102] (p=0.008, logit=16.375)', '\" elm\"[43305] (p=0.006, logit=16.000)']\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.74609375, logit=20.875, token_id=65329, metadata=None))), (34785, (63, PredictedToken(token=' Truck', prob=0.00013446807861328125, logit=12.25, token_id=34785, metadata=None))), (22050, (246, PredictedToken(token=' Hat', prob=1.0371208190917969e-05, logit=9.6875, token_id=22050, metadata=None))), (47759, (450, PredictedToken(token=' Guitar', prob=3.5762786865234375e-06, logit=8.625, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:49 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:49 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.898, logit=22.000)', '\" A\"[362] (p=0.024, logit=18.375)', '\" The\"[578] (p=0.021, logit=18.250)', '\" Among\"[22395] (p=0.015, logit=17.875)', '\" (\"[320] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     clean_prediction=['\" Drum\"[46506] (p=0.773, logit=22.000)', '\" The\"[578] (p=0.104, logit=20.000)', '\" A\"[362] (p=0.063, logit=19.500)', '\" Among\"[22395] (p=0.016, logit=18.125)', '\" It\"[1102] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     clean_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.7734375, logit=22.0, token_id=46506, metadata=None))), (83499, (48, PredictedToken(token=' Tooth', prob=0.00010776519775390625, logit=13.125, token_id=83499, metadata=None))), (6150, (76, PredictedToken(token=' School', prob=3.504753112792969e-05, logit=12.0, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.562, logit=20.750)', '\" Tooth\"[83499] (p=0.234, logit=19.875)', '\" The\"[578] (p=0.076, logit=18.750)', '\" None\"[2290] (p=0.028, logit=17.750)', '\" Among\"[22395] (p=0.019, logit=17.375)']\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.5625, logit=20.75, token_id=6150, metadata=None))), (83499, (2, PredictedToken(token=' Tooth', prob=0.234375, logit=19.875, token_id=83499, metadata=None))), (46506, (28, PredictedToken(token=' Drum', prob=0.0007476806640625, logit=14.125, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:49 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:53:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.656, logit=21.375)', '\" The\"[578] (p=0.166, logit=20.000)', '\" Among\"[22395] (p=0.129, logit=19.750)', '\" P\"[393] (p=0.004, logit=16.375)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.688, logit=21.125)', '\" The\"[578] (p=0.093, logit=19.125)', '\" A\"[362] (p=0.093, logit=19.125)', '\" Among\"[22395] (p=0.064, logit=18.750)', '\" F\"[435] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.6875, logit=21.125, token_id=75258, metadata=None))), (423, (24, PredictedToken(token=' D', prob=0.000667572021484375, logit=14.1875, token_id=423, metadata=None))), (3341, (28, PredictedToken(token=' Car', prob=0.00058746337890625, logit=14.0625, token_id=3341, metadata=None))), (33711, (59, PredictedToken(token=' Suit', prob=0.00014019012451171875, logit=12.625, token_id=33711, metadata=None))), (34392, (79, PredictedToken(token=' Horse', prob=6.198883056640625e-05, logit=11.8125, token_id=34392, metadata=None))), (47759, (573, PredictedToken(token=' Guitar', prob=1.6540288925170898e-06, logit=8.1875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.762, logit=21.375)', '\" The\"[578] (p=0.071, logit=19.000)', '\" Car\"[3341] (p=0.030, logit=18.125)', '\" A\"[362] (p=0.030, logit=18.125)', '\" Among\"[22395] (p=0.020, logit=17.750)']\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.76171875, logit=21.375, token_id=33711, metadata=None))), (3341, (4, PredictedToken(token=' Car', prob=0.029541015625, logit=18.125, token_id=3341, metadata=None))), (34392, (7, PredictedToken(token=' Horse', prob=0.0179443359375, logit=17.625, token_id=34392, metadata=None))), (47759, (10, PredictedToken(token=' Guitar', prob=0.0033111572265625, logit=15.9375, token_id=47759, metadata=None))), (423, (15, PredictedToken(token=' D', prob=0.00156402587890625, logit=15.1875, token_id=423, metadata=None))), (75258, (838, PredictedToken(token=' Refriger', prob=8.940696716308594e-07, logit=7.71875, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:50 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:50 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     patch_prediction=['\" Refriger\"[75258] (p=0.424, logit=20.125)', '\" Potato\"[78703] (p=0.330, logit=19.875)', '\" The\"[578] (p=0.065, logit=18.250)', '\" A\"[362] (p=0.057, logit=18.125)', '\" Among\"[22395] (p=0.024, logit=17.250)']\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.746, logit=21.750)', '\" The\"[578] (p=0.089, logit=19.625)', '\" A\"[362] (p=0.079, logit=19.500)', '\" Among\"[22395] (p=0.048, logit=19.000)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.74609375, logit=21.75, token_id=29318, metadata=None))), (432, (13, PredictedToken(token=' R', prob=0.00112152099609375, logit=15.25, token_id=432, metadata=None))), (40090, (150, PredictedToken(token=' Pressure', prob=8.046627044677734e-06, logit=10.3125, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:53:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.723, logit=22.000)', '\" The\"[578] (p=0.076, logit=19.750)', '\" Dress\"[29318] (p=0.059, logit=19.500)', '\" A\"[362] (p=0.046, logit=19.250)', '\" Among\"[22395] (p=0.041, logit=19.125)']\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.72265625, logit=22.0, token_id=40090, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.059326171875, logit=19.5, token_id=29318, metadata=None))), (432, (7, PredictedToken(token=' R', prob=0.006256103515625, logit=17.25, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:51 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:51 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.914, logit=22.375)', '\" The\"[578] (p=0.019, logit=18.500)', '\" Among\"[22395] (p=0.017, logit=18.375)', '\" None\"[2290] (p=0.017, logit=18.375)', '\" (\"[320] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.816, logit=22.250)', '\" The\"[578] (p=0.076, logit=19.875)', '\" A\"[362] (p=0.036, logit=19.125)', '\" Option\"[7104] (p=0.015, logit=18.250)', '\" Among\"[22395] (p=0.013, logit=18.125)']\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.81640625, logit=22.25, token_id=356, metadata=None))), (1901, (24, PredictedToken(token=' Z', prob=0.0004520416259765625, logit=14.75, token_id=1901, metadata=None))), (16344, (215, PredictedToken(token=' Rose', prob=3.6656856536865234e-06, logit=9.9375, token_id=16344, metadata=None)))])\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.840, logit=21.750)', '\" The\"[578] (p=0.033, logit=18.500)', '\" Among\"[22395] (p=0.022, logit=18.125)', '\" C\"[356] (p=0.022, logit=18.125)', '\" None\"[2290] (p=0.017, logit=17.875)']\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.83984375, logit=21.75, token_id=1901, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.0224609375, logit=18.125, token_id=356, metadata=None))), (16344, (6, PredictedToken(token=' Rose', prob=0.01202392578125, logit=17.5, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:51 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:53:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.789, logit=20.500)', '\" Among\"[22395] (p=0.065, logit=18.000)', '\" The\"[578] (p=0.044, logit=17.625)', '\" E\"[469] (p=0.016, logit=16.625)', '\" LOT\"[54460] (p=0.005, logit=15.438)']\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.080, logit=19.125)', '\" A\"[362] (p=0.062, logit=18.875)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" None\"[2290] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.75390625, logit=21.375, token_id=38930, metadata=None))), (79028, (20, PredictedToken(token=' Hick', prob=0.000942230224609375, logit=14.6875, token_id=79028, metadata=None))), (328, (42, PredictedToken(token=' S', prob=0.000209808349609375, logit=13.1875, token_id=328, metadata=None))), (1443, (130, PredictedToken(token=' Sh', prob=1.621246337890625e-05, logit=10.625, token_id=1443, metadata=None))), (63606, (160, PredictedToken(token=' Stap', prob=1.1146068572998047e-05, logit=10.25, token_id=63606, metadata=None))), (66821, (350, PredictedToken(token=' Iris', prob=2.637505531311035e-06, logit=8.8125, token_id=66821, metadata=None)))])\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     int_prediction=['\" Sh\"[1443] (p=0.766, logit=20.875)', '\" The\"[578] (p=0.063, logit=18.375)', '\" Among\"[22395] (p=0.049, logit=18.125)', '\" S\"[328] (p=0.026, logit=17.500)', '\" Stap\"[63606] (p=0.020, logit=17.250)']\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     int_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.765625, logit=20.875, token_id=1443, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.026123046875, logit=17.5, token_id=328, metadata=None))), (63606, (5, PredictedToken(token=' Stap', prob=0.0203857421875, logit=17.25, token_id=63606, metadata=None))), (38930, (34, PredictedToken(token=' Bike', prob=0.00054168701171875, logit=13.625, token_id=38930, metadata=None))), (79028, (47, PredictedToken(token=' Hick', prob=0.00022602081298828125, logit=12.75, token_id=79028, metadata=None))), (66821, (76, PredictedToken(token=' Iris', prob=9.441375732421875e-05, logit=11.875, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:52 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:52 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     patch_prediction=['\" Chain\"[29625] (p=0.941, logit=22.875)', '\" The\"[578] (p=0.012, logit=18.500)', '\" chain\"[8957] (p=0.007, logit=18.000)', '\" A\"[362] (p=0.007, logit=18.000)', '\" (\"[320] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:53:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.914, logit=22.875)', '\" The\"[578] (p=0.031, logit=19.500)', '\" A\"[362] (p=0.017, logit=18.875)', '\" Among\"[22395] (p=0.010, logit=18.375)', '\" laptop\"[21288] (p=0.008, logit=18.125)']\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.9140625, logit=22.875, token_id=57225, metadata=None))), (17929, (6, PredictedToken(token=' Pin', prob=0.0032958984375, logit=17.25, token_id=17929, metadata=None))), (6031, (55, PredictedToken(token=' Bro', prob=2.3603439331054688e-05, logit=12.3125, token_id=6031, metadata=None)))])\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.887, logit=22.250)', '\" The\"[578] (p=0.034, logit=19.000)', '\" Laptop\"[57225] (p=0.018, logit=18.375)', '\" A\"[362] (p=0.016, logit=18.250)', '\" pin\"[9160] (p=0.011, logit=17.875)']\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.88671875, logit=22.25, token_id=17929, metadata=None))), (57225, (3, PredictedToken(token=' Laptop', prob=0.0184326171875, logit=18.375, token_id=57225, metadata=None))), (6031, (25, PredictedToken(token=' Bro', prob=0.000278472900390625, logit=14.1875, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:53 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:53 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     patch_prediction=['\" Mar\"[2947] (p=0.824, logit=21.625)', '\" The\"[578] (p=0.068, logit=19.125)', '\" Among\"[22395] (p=0.047, logit=18.750)', '\" A\"[362] (p=0.009, logit=17.125)', '\" mar\"[3678] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     clean_prediction=['\" Desk\"[39794] (p=0.809, logit=22.125)', '\" The\"[578] (p=0.075, logit=19.750)', '\" A\"[362] (p=0.040, logit=19.125)', '\" Among\"[22395] (p=0.028, logit=18.750)', '\" d\"[294] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     clean_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.80859375, logit=22.125, token_id=39794, metadata=None))), (16344, (19, PredictedToken(token=' Rose', prob=0.001007080078125, logit=15.4375, token_id=16344, metadata=None))), (30760, (533, PredictedToken(token=' Scar', prob=9.760260581970215e-07, logit=8.5, token_id=30760, metadata=None))), (80629, (1219, PredictedToken(token=' Grape', prob=3.166496753692627e-07, logit=7.375, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     int_prediction=['\" Scar\"[30760] (p=0.283, logit=19.125)', '\" Grape\"[80629] (p=0.221, logit=18.875)', '\" The\"[578] (p=0.172, logit=18.625)', '\" A\"[362] (p=0.081, logit=17.875)', '\" Among\"[22395] (p=0.056, logit=17.500)']\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     int_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.283203125, logit=19.125, token_id=30760, metadata=None))), (80629, (2, PredictedToken(token=' Grape', prob=0.220703125, logit=18.875, token_id=80629, metadata=None))), (16344, (6, PredictedToken(token=' Rose', prob=0.0205078125, logit=16.5, token_id=16344, metadata=None))), (39794, (1417, PredictedToken(token=' Desk', prob=1.7955899238586426e-06, logit=7.15625, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:53 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:53:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.852, logit=21.750)', '\" The\"[578] (p=0.062, logit=19.125)', '\" Among\"[22395] (p=0.029, logit=18.375)', '\" (\"[320] (p=0.009, logit=17.250)', '\" A\"[362] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.730, logit=22.750)', '\" An\"[1556] (p=0.112, logit=20.875)', '\" The\"[578] (p=0.099, logit=20.750)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" e\"[384] (p=0.010, logit=18.500)']\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.73046875, logit=22.75, token_id=469, metadata=None))), (65449, (25, PredictedToken(token=' Willow', prob=0.00021648406982421875, logit=14.625, token_id=65449, metadata=None))), (97796, (134, PredictedToken(token=' Skate', prob=6.139278411865234e-06, logit=11.0625, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.883, logit=22.250)', '\" The\"[578] (p=0.050, logit=19.375)', '\" Among\"[22395] (p=0.018, logit=18.375)', '\" A\"[362] (p=0.011, logit=17.875)', '\" will\"[690] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.8828125, logit=22.25, token_id=65449, metadata=None))), (469, (10, PredictedToken(token=' E', prob=0.0019378662109375, logit=16.125, token_id=469, metadata=None))), (97796, (38, PredictedToken(token=' Skate', prob=0.00010919570922851562, logit=13.25, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:54 src.selection.optimization DEBUG    torch.Size([6, 35])\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     patch_prediction=['\" Fl\"[3061] (p=0.703, logit=21.250)', '\" The\"[578] (p=0.157, logit=19.750)', '\" Among\"[22395] (p=0.051, logit=18.625)', '\" A\"[362] (p=0.031, logit=18.125)', '\" It\"[1102] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:53:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     clean_prediction=['\" Calculator\"[37128] (p=0.660, logit=20.500)', '\" The\"[578] (p=0.101, logit=18.625)', '\" A\"[362] (p=0.089, logit=18.500)', '\" Among\"[22395] (p=0.042, logit=17.750)', '\" It\"[1102] (p=0.018, logit=16.875)']\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     clean_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.66015625, logit=20.5, token_id=37128, metadata=None))), (469, (10, PredictedToken(token=' E', prob=0.0032501220703125, logit=15.1875, token_id=469, metadata=None))), (3420, (56, PredictedToken(token=' Trump', prob=0.00025177001953125, logit=12.625, token_id=3420, metadata=None))), (3341, (111, PredictedToken(token=' Car', prob=5.9604644775390625e-05, logit=11.1875, token_id=3341, metadata=None))), (61731, (188, PredictedToken(token=' Soap', prob=2.193450927734375e-05, logit=10.1875, token_id=61731, metadata=None))), (13394, (223, PredictedToken(token=' Bed', prob=1.609325408935547e-05, logit=9.875, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.883, logit=22.000)', '\" The\"[578] (p=0.030, logit=18.625)', '\" E\"[469] (p=0.021, logit=18.250)', '\" None\"[2290] (p=0.011, logit=17.625)', '\" A\"[362] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.8828125, logit=22.0, token_id=3420, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.020751953125, logit=18.25, token_id=469, metadata=None))), (3341, (86, PredictedToken(token=' Car', prob=2.9325485229492188e-05, logit=11.6875, token_id=3341, metadata=None))), (61731, (106, PredictedToken(token=' Soap', prob=1.895427703857422e-05, logit=11.25, token_id=61731, metadata=None))), (37128, (141, PredictedToken(token=' Calculator', prob=1.2218952178955078e-05, logit=10.8125, token_id=37128, metadata=None))), (13394, (313, PredictedToken(token=' Bed', prob=2.726912498474121e-06, logit=9.3125, token_id=13394, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:55 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:55 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.781, logit=21.375)', '\" The\"[578] (p=0.073, logit=19.000)', '\" A\"[362] (p=0.057, logit=18.750)', '\" Among\"[22395] (p=0.034, logit=18.250)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     clean_prediction=['\" Gloves\"[68554] (p=0.812, logit=21.750)', '\" The\"[578] (p=0.085, logit=19.500)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" Glo\"[25372] (p=0.013, logit=17.625)', '\" A\"[362] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     clean_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.8125, logit=21.75, token_id=68554, metadata=None))), (393, (23, PredictedToken(token=' P', prob=0.000476837158203125, logit=14.3125, token_id=393, metadata=None))), (33199, (29, PredictedToken(token=' Lion', prob=0.000308990478515625, logit=13.875, token_id=33199, metadata=None))), (6690, (69, PredictedToken(token=' Air', prob=5.364418029785156e-05, logit=12.125, token_id=6690, metadata=None))), (10164, (126, PredictedToken(token=' Water', prob=1.1920928955078125e-05, logit=10.625, token_id=10164, metadata=None))), (30555, (285, PredictedToken(token=' Viol', prob=3.2186508178710938e-06, logit=9.3125, token_id=30555, metadata=None)))])\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.891, logit=22.625)', '\" The\"[578] (p=0.050, logit=19.750)', '\" A\"[362] (p=0.031, logit=19.250)', '\" Among\"[22395] (p=0.008, logit=17.875)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.890625, logit=22.625, token_id=393, metadata=None))), (68554, (47, PredictedToken(token=' Gloves', prob=6.246566772460938e-05, logit=13.0625, token_id=68554, metadata=None))), (30555, (333, PredictedToken(token=' Viol', prob=1.1473894119262695e-06, logit=9.0625, token_id=30555, metadata=None))), (6690, (430, PredictedToken(token=' Air', prob=7.897615432739258e-07, logit=8.6875, token_id=6690, metadata=None))), (10164, (522, PredictedToken(token=' Water', prob=5.774199962615967e-07, logit=8.375, token_id=10164, metadata=None))), (33199, (3075, PredictedToken(token=' Lion', prob=3.934837877750397e-08, logit=5.6875, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:55 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:53:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     patch_prediction=['\" Sh\"[1443] (p=0.809, logit=21.125)', '\" Among\"[22395] (p=0.075, logit=18.750)', '\" The\"[578] (p=0.040, logit=18.125)', '\" Option\"[7104] (p=0.010, logit=16.750)', '\" Out\"[4470] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.727, logit=20.500)', '\" The\"[578] (p=0.053, logit=17.875)', '\" Pin\"[17929] (p=0.046, logit=17.750)', '\" A\"[362] (p=0.046, logit=17.750)', '\" Among\"[22395] (p=0.032, logit=17.375)']\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.7265625, logit=20.5, token_id=69755, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.04638671875, logit=17.75, token_id=17929, metadata=None))), (4923, (12, PredictedToken(token=' Sk', prob=0.003814697265625, logit=15.25, token_id=4923, metadata=None))), (74968, (13, PredictedToken(token=' Razor', prob=0.0029754638671875, logit=15.0, token_id=74968, metadata=None))), (19176, (260, PredictedToken(token=' Temple', prob=1.2159347534179688e-05, logit=9.5, token_id=19176, metadata=None)))])\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.824, logit=21.375)', '\" Razor\"[74968] (p=0.041, logit=18.375)', '\" The\"[578] (p=0.032, logit=18.125)', '\" A\"[362] (p=0.022, logit=17.750)', '\" Sk\"[4923] (p=0.019, logit=17.625)']\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.82421875, logit=21.375, token_id=17929, metadata=None))), (74968, (2, PredictedToken(token=' Razor', prob=0.041015625, logit=18.375, token_id=74968, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.0194091796875, logit=17.625, token_id=4923, metadata=None))), (69755, (49, PredictedToken(token=' Notebook', prob=0.00017833709716796875, logit=12.9375, token_id=69755, metadata=None))), (19176, (176, PredictedToken(token=' Temple', prob=1.3768672943115234e-05, logit=10.375, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:56 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:56 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.891, logit=21.750)', '\" The\"[578] (p=0.044, logit=18.750)', '\" A\"[362] (p=0.014, logit=17.625)', '\" Among\"[22395] (p=0.009, logit=17.125)', '\" Keyboard\"[26698] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.855, logit=22.000)', '\" The\"[578] (p=0.038, logit=18.875)', '\" A\"[362] (p=0.033, logit=18.750)', '\" (\"[320] (p=0.016, logit=18.000)', '\" Among\"[22395] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.85546875, logit=22.0, token_id=5907, metadata=None))), (57094, (10, PredictedToken(token=' Highlight', prob=0.0023956298828125, logit=16.125, token_id=57094, metadata=None))), (68554, (147, PredictedToken(token=' Gloves', prob=9.775161743164062e-06, logit=10.625, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.902, logit=22.375)', '\" Project\"[5907] (p=0.017, logit=18.375)', '\" The\"[578] (p=0.017, logit=18.375)', '\" A\"[362] (p=0.015, logit=18.250)', '\" (\"[320] (p=0.011, logit=18.000)']\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.90234375, logit=22.375, token_id=57094, metadata=None))), (5907, (3, PredictedToken(token=' Project', prob=0.0166015625, logit=18.375, token_id=5907, metadata=None))), (68554, (7, PredictedToken(token=' Gloves', prob=0.004180908203125, logit=17.0, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:53:57 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.617, logit=22.250)', '\" The\"[578] (p=0.177, logit=21.000)', '\" A\"[362] (p=0.122, logit=20.625)', '\" Among\"[22395] (p=0.051, logit=19.750)', '\" D\"[423] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.816, logit=22.000)', '\" The\"[578] (p=0.059, logit=19.375)', '\" A\"[362] (p=0.052, logit=19.250)', '\" Among\"[22395] (p=0.036, logit=18.875)', '\" (\"[320] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.81640625, logit=22.0, token_id=16183, metadata=None))), (41445, (23, PredictedToken(token=' Television', prob=0.00048065185546875, logit=14.5625, token_id=41445, metadata=None))), (57748, (34, PredictedToken(token=' Cedar', prob=0.0002574920654296875, logit=13.9375, token_id=57748, metadata=None))), (55870, (48, PredictedToken(token=' Jacket', prob=0.00011396408081054688, logit=13.125, token_id=55870, metadata=None))), (13597, (140, PredictedToken(token=' Pen', prob=9.953975677490234e-06, logit=10.6875, token_id=13597, metadata=None))), (89077, (256, PredictedToken(token=' Strawberry', prob=3.2335519790649414e-06, logit=9.5625, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:53:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     int_prediction=['\" Jacket\"[55870] (p=0.449, logit=19.875)', '\" The\"[578] (p=0.146, logit=18.750)', '\" A\"[362] (p=0.088, logit=18.250)', '\" Strawberry\"[89077] (p=0.061, logit=17.875)', '\" Among\"[22395] (p=0.061, logit=17.875)']\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     int_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.44921875, logit=19.875, token_id=55870, metadata=None))), (89077, (5, PredictedToken(token=' Strawberry', prob=0.060791015625, logit=17.875, token_id=89077, metadata=None))), (41445, (6, PredictedToken(token=' Television', prob=0.0252685546875, logit=17.0, token_id=41445, metadata=None))), (13597, (9, PredictedToken(token=' Pen', prob=0.0196533203125, logit=16.75, token_id=13597, metadata=None))), (57748, (53, PredictedToken(token=' Cedar', prob=0.0003833770751953125, logit=12.8125, token_id=57748, metadata=None))), (16183, (230, PredictedToken(token=' Hel', prob=1.5854835510253906e-05, logit=9.625, token_id=16183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:58 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:53:58 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.797, logit=21.625)', '\" The\"[578] (p=0.107, logit=19.625)', '\" Among\"[22395] (p=0.035, logit=18.500)', '\" headphones\"[44101] (p=0.008, logit=17.000)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.852, logit=21.375)', '\" The\"[578] (p=0.048, logit=18.500)', '\" A\"[362] (p=0.037, logit=18.250)', '\" Among\"[22395] (p=0.018, logit=17.500)', '\" Option\"[7104] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.8515625, logit=21.375, token_id=91263, metadata=None))), (6017, (21, PredictedToken(token=' Book', prob=0.000728607177734375, logit=14.3125, token_id=6017, metadata=None))), (23910, (57, PredictedToken(token=' Pear', prob=9.870529174804688e-05, logit=12.3125, token_id=23910, metadata=None))), (5907, (71, PredictedToken(token=' Project', prob=5.984306335449219e-05, logit=11.8125, token_id=5907, metadata=None)))])\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     int_prediction=['\" Project\"[5907] (p=0.840, logit=21.750)', '\" The\"[578] (p=0.042, logit=18.750)', '\" Book\"[6017] (p=0.032, logit=18.500)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" A\"[362] (p=0.017, logit=17.875)']\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     int_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.83984375, logit=21.75, token_id=5907, metadata=None))), (6017, (3, PredictedToken(token=' Book', prob=0.032470703125, logit=18.5, token_id=6017, metadata=None))), (91263, (6, PredictedToken(token=' Binder', prob=0.00933837890625, logit=17.25, token_id=91263, metadata=None))), (23910, (49, PredictedToken(token=' Pear', prob=0.0001811981201171875, logit=13.3125, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:53:58 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:53:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.773, logit=21.625)', '\" The\"[578] (p=0.093, logit=19.500)', '\" Among\"[22395] (p=0.044, logit=18.750)', '\" A\"[362] (p=0.030, logit=18.375)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.809, logit=22.750)', '\" The\"[578] (p=0.075, logit=20.375)', '\" Among\"[22395] (p=0.046, logit=19.875)', '\" A\"[362] (p=0.040, logit=19.750)', '\" Option\"[7104] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.80859375, logit=22.75, token_id=38930, metadata=None))), (393, (91, PredictedToken(token=' P', prob=1.1920928955078125e-05, logit=11.625, token_id=393, metadata=None))), (14642, (163, PredictedToken(token=' Phone', prob=3.203749656677246e-06, logit=10.3125, token_id=14642, metadata=None))), (37326, (232, PredictedToken(token=' Swe', prob=1.5124678611755371e-06, logit=9.5625, token_id=37326, metadata=None))), (86460, (270, PredictedToken(token=' Necklace', prob=1.1101365089416504e-06, logit=9.25, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.637, logit=21.750)', '\" The\"[578] (p=0.125, logit=20.125)', '\" A\"[362] (p=0.110, logit=20.000)', '\" Among\"[22395] (p=0.041, logit=19.000)', '\" P\"[393] (p=0.022, logit=18.375)']\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.63671875, logit=21.75, token_id=14642, metadata=None))), (393, (5, PredictedToken(token=' P', prob=0.021728515625, logit=18.375, token_id=393, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.009033203125, logit=17.5, token_id=38930, metadata=None))), (37326, (8, PredictedToken(token=' Swe', prob=0.0054931640625, logit=17.0, token_id=37326, metadata=None))), (86460, (311, PredictedToken(token=' Necklace', prob=2.3692846298217773e-06, logit=9.25, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:53:59 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:53:59 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.922, logit=21.750)', '\" The\"[578] (p=0.015, logit=17.625)', '\" Among\"[22395] (p=0.010, logit=17.250)', '\" soap\"[27883] (p=0.008, logit=17.000)', '\" (\"[320] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.797, logit=22.000)', '\" None\"[2290] (p=0.051, logit=19.250)', '\" An\"[1556] (p=0.051, logit=19.250)', '\" The\"[578] (p=0.035, logit=18.875)', '\" Among\"[22395] (p=0.024, logit=18.500)']\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.796875, logit=22.0, token_id=53889, metadata=None))), (16488, (12, PredictedToken(token=' Bat', prob=0.0015411376953125, logit=15.75, token_id=16488, metadata=None))), (1901, (19, PredictedToken(token=' Z', prob=0.00087738037109375, logit=15.1875, token_id=1901, metadata=None)))])\n",
      "2025-09-16 09:53:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.828, logit=22.375)', '\" None\"[2290] (p=0.047, logit=19.500)', '\" The\"[578] (p=0.036, logit=19.250)', '\" A\"[362] (p=0.032, logit=19.125)', '\" Z\"[1901] (p=0.022, logit=18.750)']\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.828125, logit=22.375, token_id=16488, metadata=None))), (1901, (5, PredictedToken(token=' Z', prob=0.02197265625, logit=18.75, token_id=1901, metadata=None))), (53889, (61, PredictedToken(token=' Apartment', prob=5.125999450683594e-05, logit=12.6875, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:00 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:00 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.660, logit=20.000)', '\" Sco\"[50159] (p=0.079, logit=17.875)', '\" The\"[578] (p=0.069, logit=17.750)', '\" Among\"[22395] (p=0.054, logit=17.500)', '\" A\"[362] (p=0.023, logit=16.625)']\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.766, logit=21.250)', '\" The\"[578] (p=0.081, logit=19.000)', '\" Among\"[22395] (p=0.055, logit=18.625)', '\" A\"[362] (p=0.043, logit=18.375)', '\" Out\"[4470] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.765625, logit=21.25, token_id=57551, metadata=None))), (13597, (11, PredictedToken(token=' Pen', prob=0.002593994140625, logit=15.5625, token_id=13597, metadata=None))), (356, (20, PredictedToken(token=' C', prob=0.000896453857421875, logit=14.5, token_id=356, metadata=None))), (18654, (181, PredictedToken(token=' Micro', prob=1.1265277862548828e-05, logit=10.125, token_id=18654, metadata=None))), (5250, (233, PredictedToken(token=' Pe', prob=6.8247318267822266e-06, logit=9.625, token_id=5250, metadata=None))), (58251, (647, PredictedToken(token=' Tennis', prob=1.430511474609375e-06, logit=8.0625, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.742, logit=20.875)', '\" The\"[578] (p=0.061, logit=18.375)', '\" Among\"[22395] (p=0.054, logit=18.250)', '\" Micro\"[18654] (p=0.048, logit=18.125)', '\" A\"[362] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.7421875, logit=20.875, token_id=58251, metadata=None))), (18654, (4, PredictedToken(token=' Micro', prob=0.047607421875, logit=18.125, token_id=18654, metadata=None))), (13597, (6, PredictedToken(token=' Pen', prob=0.00933837890625, logit=16.5, token_id=13597, metadata=None))), (356, (24, PredictedToken(token=' C', prob=0.0008697509765625, logit=14.125, token_id=356, metadata=None))), (5250, (43, PredictedToken(token=' Pe', prob=0.0003414154052734375, logit=13.1875, token_id=5250, metadata=None))), (57551, (155, PredictedToken(token=' Sink', prob=2.6226043701171875e-05, logit=10.625, token_id=57551, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:00 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.754, logit=22.375)', '\" A\"[362] (p=0.090, logit=20.250)', '\" The\"[578] (p=0.080, logit=20.125)', '\" Among\"[22395] (p=0.042, logit=19.500)', '\" Only\"[8442] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.891, logit=22.125)', '\" The\"[578] (p=0.044, logit=19.125)', '\" Among\"[22395] (p=0.031, logit=18.750)', '\" Option\"[7104] (p=0.005, logit=16.875)', '\" It\"[1102] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.890625, logit=22.125, token_id=47643, metadata=None))), (5907, (22, PredictedToken(token=' Project', prob=0.0003604888916015625, logit=14.3125, token_id=5907, metadata=None))), (22410, (42, PredictedToken(token=' Ju', prob=0.00013256072998046875, logit=13.3125, token_id=22410, metadata=None))), (58600, (70, PredictedToken(token=' Charm', prob=5.1975250244140625e-05, logit=12.375, token_id=58600, metadata=None)))])\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     int_prediction=['\" Ju\"[22410] (p=0.350, logit=19.625)', '\" Charm\"[58600] (p=0.165, logit=18.875)', '\" Project\"[5907] (p=0.128, logit=18.625)', '\" The\"[578] (p=0.100, logit=18.375)', '\" A\"[362] (p=0.088, logit=18.250)']\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     int_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.349609375, logit=19.625, token_id=22410, metadata=None))), (58600, (2, PredictedToken(token=' Charm', prob=0.1650390625, logit=18.875, token_id=58600, metadata=None))), (5907, (3, PredictedToken(token=' Project', prob=0.1279296875, logit=18.625, token_id=5907, metadata=None))), (47643, (51, PredictedToken(token=' Cel', prob=0.0002994537353515625, logit=12.5625, token_id=47643, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:01 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:01 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     patch_prediction=['\" Magn\"[20918] (p=0.805, logit=21.375)', '\" Among\"[22395] (p=0.066, logit=18.875)', '\" The\"[578] (p=0.058, logit=18.750)', '\" A\"[362] (p=0.017, logit=17.500)', '\" Option\"[7104] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.824, logit=21.250)', '\" The\"[578] (p=0.060, logit=18.625)', '\" Among\"[22395] (p=0.022, logit=17.625)', '\" A\"[362] (p=0.022, logit=17.625)', '\" Bike\"[38930] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.82421875, logit=21.25, token_id=16488, metadata=None))), (38930, (5, PredictedToken(token=' Bike', prob=0.0103759765625, logit=16.875, token_id=38930, metadata=None))), (42609, (35, PredictedToken(token=' Pine', prob=0.000377655029296875, logit=13.5625, token_id=42609, metadata=None))), (48665, (578, PredictedToken(token=' Raspberry', prob=1.3634562492370605e-06, logit=7.9375, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:54:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.574, logit=19.625)', '\" Raspberry\"[48665] (p=0.146, logit=18.250)', '\" None\"[2290] (p=0.061, logit=17.375)', '\" The\"[578] (p=0.053, logit=17.250)', '\" Bat\"[16488] (p=0.032, logit=16.750)']\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.57421875, logit=19.625, token_id=42609, metadata=None))), (48665, (2, PredictedToken(token=' Raspberry', prob=0.1455078125, logit=18.25, token_id=48665, metadata=None))), (16488, (5, PredictedToken(token=' Bat', prob=0.032470703125, logit=16.75, token_id=16488, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.0126953125, logit=15.8125, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:02 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:02 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.895, logit=22.125)', '\" The\"[578] (p=0.024, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=18.375)', '\" A\"[362] (p=0.019, logit=18.250)', '\" jacket\"[27300] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.781, logit=20.875)', '\" A\"[362] (p=0.073, logit=18.500)', '\" The\"[578] (p=0.050, logit=18.125)', '\" Among\"[22395] (p=0.027, logit=17.500)', '\" None\"[2290] (p=0.013, logit=16.750)']\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.78125, logit=20.875, token_id=432, metadata=None))), (68554, (7, PredictedToken(token=' Gloves', prob=0.003631591796875, logit=15.5, token_id=68554, metadata=None))), (30555, (11, PredictedToken(token=' Viol', prob=0.002197265625, logit=15.0, token_id=30555, metadata=None))), (469, (13, PredictedToken(token=' E', prob=0.00160980224609375, logit=14.6875, token_id=469, metadata=None))), (22249, (51, PredictedToken(token=' Ring', prob=0.0001697540283203125, logit=12.4375, token_id=22249, metadata=None))), (16488, (53, PredictedToken(token=' Bat', prob=0.00015926361083984375, logit=12.375, token_id=16488, metadata=None)))])\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.562, logit=20.000)', '\" Bat\"[16488] (p=0.098, logit=18.250)', '\" A\"[362] (p=0.076, logit=18.000)', '\" None\"[2290] (p=0.067, logit=17.875)', '\" The\"[578] (p=0.052, logit=17.625)']\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.5625, logit=20.0, token_id=22249, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.09814453125, logit=18.25, token_id=16488, metadata=None))), (68554, (6, PredictedToken(token=' Gloves', prob=0.0247802734375, logit=16.875, token_id=68554, metadata=None))), (469, (19, PredictedToken(token=' E', prob=0.00168609619140625, logit=14.1875, token_id=469, metadata=None))), (432, (30, PredictedToken(token=' R', prob=0.0009613037109375, logit=13.625, token_id=432, metadata=None))), (30555, (207, PredictedToken(token=' Viol', prob=2.1219253540039062e-05, logit=9.8125, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:02 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:54:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.734, logit=21.750)', '\" The\"[578] (p=0.112, logit=19.875)', '\" A\"[362] (p=0.077, logit=19.500)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" \"[220] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.645, logit=20.500)', '\" The\"[578] (p=0.144, logit=19.000)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" Short\"[10928] (p=0.017, logit=16.875)', '\" A\"[362] (p=0.015, logit=16.750)']\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.64453125, logit=20.5, token_id=91782, metadata=None))), (16344, (14, PredictedToken(token=' Rose', prob=0.004608154296875, logit=15.5625, token_id=16344, metadata=None))), (16488, (96, PredictedToken(token=' Bat', prob=7.915496826171875e-05, logit=11.5, token_id=16488, metadata=None))), (17810, (106, PredictedToken(token=' Cat', prob=5.793571472167969e-05, logit=11.1875, token_id=17810, metadata=None))), (3420, (309, PredictedToken(token=' Trump', prob=7.3909759521484375e-06, logit=9.125, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.738, logit=21.625)', '\" Cat\"[17810] (p=0.128, logit=19.875)', '\" The\"[578] (p=0.042, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=18.250)', '\" A\"[362] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.73828125, logit=21.625, token_id=16488, metadata=None))), (17810, (2, PredictedToken(token=' Cat', prob=0.1279296875, logit=19.875, token_id=17810, metadata=None))), (3420, (163, PredictedToken(token=' Trump', prob=1.0192394256591797e-05, logit=10.4375, token_id=3420, metadata=None))), (16344, (231, PredictedToken(token=' Rose', prob=5.811452865600586e-06, logit=9.875, token_id=16344, metadata=None))), (91782, (1483, PredictedToken(token=' Shorts', prob=3.390014171600342e-07, logit=7.03125, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:03 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.660, logit=21.500)', '\" An\"[1556] (p=0.167, logit=20.125)', '\" The\"[578] (p=0.079, logit=19.375)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" E\"[469] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:54:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.855, logit=21.125)', '\" The\"[578] (p=0.055, logit=18.375)', '\" Among\"[22395] (p=0.029, logit=17.750)', '\" A\"[362] (p=0.011, logit=16.750)', '\" It\"[1102] (p=0.005, logit=16.000)']\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.85546875, logit=21.125, token_id=58586, metadata=None))), (34392, (55, PredictedToken(token=' Horse', prob=0.0001125335693359375, logit=12.1875, token_id=34392, metadata=None))), (13000, (127, PredictedToken(token=' Van', prob=2.5153160095214844e-05, logit=10.6875, token_id=13000, metadata=None))), (52882, (151, PredictedToken(token=' Pepper', prob=1.728534698486328e-05, logit=10.3125, token_id=52882, metadata=None))), (89077, (237, PredictedToken(token=' Strawberry', prob=8.165836334228516e-06, logit=9.5625, token_id=89077, metadata=None))), (8219, (433, PredictedToken(token=' Sun', prob=2.816319465637207e-06, logit=8.5, token_id=8219, metadata=None)))])\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.793, logit=21.000)', '\" Horse\"[34392] (p=0.057, logit=18.375)', '\" The\"[578] (p=0.051, logit=18.250)', '\" Among\"[22395] (p=0.013, logit=16.875)', '\" A\"[362] (p=0.013, logit=16.875)']\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.79296875, logit=21.0, token_id=8219, metadata=None))), (34392, (2, PredictedToken(token=' Horse', prob=0.057373046875, logit=18.375, token_id=34392, metadata=None))), (89077, (9, PredictedToken(token=' Strawberry', prob=0.004425048828125, logit=15.8125, token_id=89077, metadata=None))), (52882, (45, PredictedToken(token=' Pepper', prob=0.0002651214599609375, logit=13.0, token_id=52882, metadata=None))), (13000, (81, PredictedToken(token=' Van', prob=9.202957153320312e-05, logit=11.9375, token_id=13000, metadata=None))), (58586, (834, PredictedToken(token=' Tape', prob=1.3113021850585938e-06, logit=7.6875, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:04 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:04 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     patch_prediction=['\" None\"[2290] (p=0.523, logit=20.000)', '\" Yoga\"[38673] (p=0.170, logit=18.875)', '\" C\"[356] (p=0.117, logit=18.500)', '\" Mouse\"[18191] (p=0.062, logit=17.875)', '\" The\"[578] (p=0.026, logit=17.000)']\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.676, logit=21.750)', '\" The\"[578] (p=0.170, logit=20.375)', '\" A\"[362] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.043, logit=19.000)', '\" It\"[1102] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.67578125, logit=21.75, token_id=60413, metadata=None))), (2057, (38, PredictedToken(token=' To', prob=0.0001373291015625, logit=13.25, token_id=2057, metadata=None))), (58251, (159, PredictedToken(token=' Tennis', prob=9.357929229736328e-06, logit=10.5625, token_id=58251, metadata=None))), (82994, (249, PredictedToken(token=' Toilet', prob=3.904104232788086e-06, logit=9.6875, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     int_prediction=['\" Uk\"[60413] (p=0.691, logit=21.250)', '\" The\"[578] (p=0.154, logit=19.750)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.039, logit=18.375)', '\" Tennis\"[58251] (p=0.014, logit=17.375)']\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     int_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.69140625, logit=21.25, token_id=60413, metadata=None))), (58251, (5, PredictedToken(token=' Tennis', prob=0.01434326171875, logit=17.375, token_id=58251, metadata=None))), (82994, (18, PredictedToken(token=' Toilet', prob=0.000858306884765625, logit=14.5625, token_id=82994, metadata=None))), (2057, (34, PredictedToken(token=' To', prob=0.0004062652587890625, logit=13.8125, token_id=2057, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:04 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.645, logit=21.000)', '\" The\"[578] (p=0.163, logit=19.625)', '\" Among\"[22395] (p=0.087, logit=19.000)', '\" A\"[362] (p=0.047, logit=18.375)', '\" Option\"[7104] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     clean_prediction=['\" Shower\"[48471] (p=0.613, logit=20.250)', '\" The\"[578] (p=0.121, logit=18.625)', '\" Among\"[22395] (p=0.106, logit=18.500)', '\" A\"[362] (p=0.057, logit=17.875)', '\" Option\"[7104] (p=0.016, logit=16.625)']\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     clean_track=OrderedDict([(48471, (1, PredictedToken(token=' Shower', prob=0.61328125, logit=20.25, token_id=48471, metadata=None))), (43316, (71, PredictedToken(token=' Tul', prob=0.00016021728515625, logit=12.0, token_id=43316, metadata=None))), (27217, (78, PredictedToken(token=' Train', prob=0.00013256072998046875, logit=11.8125, token_id=27217, metadata=None))), (26698, (243, PredictedToken(token=' Keyboard', prob=1.233816146850586e-05, logit=9.4375, token_id=26698, metadata=None))), (16730, (375, PredictedToken(token=' Museum', prob=5.841255187988281e-06, logit=8.6875, token_id=16730, metadata=None))), (65329, (2375, PredictedToken(token=' Elm', prob=5.103647708892822e-07, logit=6.25, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.820, logit=20.625)', '\" The\"[578] (p=0.052, logit=17.875)', '\" Among\"[22395] (p=0.025, logit=17.125)', '\" Tul\"[43316] (p=0.017, logit=16.750)', '\" (\"[320] (p=0.013, logit=16.500)']\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.8203125, logit=20.625, token_id=65329, metadata=None))), (43316, (4, PredictedToken(token=' Tul', prob=0.0169677734375, logit=16.75, token_id=43316, metadata=None))), (16730, (848, PredictedToken(token=' Museum', prob=2.0265579223632812e-06, logit=7.71875, token_id=16730, metadata=None))), (27217, (1754, PredictedToken(token=' Train', prob=8.23289155960083e-07, logit=6.8125, token_id=27217, metadata=None))), (48471, (2133, PredictedToken(token=' Shower', prob=6.407499313354492e-07, logit=6.5625, token_id=48471, metadata=None))), (26698, (3858, PredictedToken(token=' Keyboard', prob=2.8312206268310547e-07, logit=5.75, token_id=26698, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:05 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:05 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:54:05 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     patch_prediction=['\" Mushroom\"[91297] (p=0.805, logit=20.875)', '\" None\"[2290] (p=0.084, logit=18.625)', '\" The\"[578] (p=0.024, logit=17.375)', '\" A\"[362] (p=0.017, logit=17.000)', '\" There\"[2684] (p=0.008, logit=16.250)']\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.910, logit=23.250)', '\" The\"[578] (p=0.035, logit=20.000)', '\" A\"[362] (p=0.031, logit=19.875)', '\" Among\"[22395] (p=0.010, logit=18.750)', '\" Motor\"[18079] (p=0.002, logit=17.125)']\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.91015625, logit=23.25, token_id=70762, metadata=None))), (23126, (104, PredictedToken(token=' Ti', prob=7.18235969543457e-06, logit=11.5, token_id=23126, metadata=None))), (41785, (495, PredictedToken(token=' Spin', prob=3.3527612686157227e-07, logit=8.4375, token_id=41785, metadata=None))), (23910, (639, PredictedToken(token=' Pear', prob=2.300366759300232e-07, logit=8.0625, token_id=23910, metadata=None)))])\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.895, logit=22.250)', '\" The\"[578] (p=0.050, logit=19.375)', '\" Among\"[22395] (p=0.021, logit=18.500)', '\" A\"[362] (p=0.005, logit=17.000)', '\" (\"[320] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.89453125, logit=22.25, token_id=41785, metadata=None))), (23910, (9, PredictedToken(token=' Pear', prob=0.001953125, logit=16.125, token_id=23910, metadata=None))), (70762, (23, PredictedToken(token=' Motorcycle', prob=0.0002651214599609375, logit=14.125, token_id=70762, metadata=None))), (23126, (44, PredictedToken(token=' Ti', prob=0.00011730194091796875, logit=13.3125, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:06 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.613, logit=22.125)', '\" The\"[578] (p=0.176, logit=20.875)', '\" A\"[362] (p=0.137, logit=20.625)', '\" Among\"[22395] (p=0.039, logit=19.375)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     clean_prediction=['\" Calculator\"[37128] (p=0.594, logit=20.500)', '\" The\"[578] (p=0.150, logit=19.125)', '\" A\"[362] (p=0.091, logit=18.625)', '\" Among\"[22395] (p=0.043, logit=17.875)', '\" It\"[1102] (p=0.016, logit=16.875)']\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     clean_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.59375, logit=20.5, token_id=37128, metadata=None))), (469, (8, PredictedToken(token=' E', prob=0.005828857421875, logit=15.875, token_id=469, metadata=None))), (3341, (11, PredictedToken(token=' Car', prob=0.004547119140625, logit=15.625, token_id=3341, metadata=None))), (1050, (61, PredictedToken(token=' Re', prob=0.00022602081298828125, logit=12.625, token_id=1050, metadata=None)))])\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.844, logit=21.875)', '\" The\"[578] (p=0.042, logit=18.875)', '\" None\"[2290] (p=0.022, logit=18.250)', '\" A\"[362] (p=0.020, logit=18.125)', '\" Re\"[1050] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.84375, logit=21.875, token_id=3341, metadata=None))), (1050, (5, PredictedToken(token=' Re', prob=0.01544189453125, logit=17.875, token_id=1050, metadata=None))), (469, (7, PredictedToken(token=' E', prob=0.007293701171875, logit=17.125, token_id=469, metadata=None))), (37128, (181, PredictedToken(token=' Calculator', prob=8.52346420288086e-06, logit=10.375, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:06 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:06 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:54:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.922, logit=22.000)', '\" The\"[578] (p=0.025, logit=18.375)', '\" cabinet\"[22685] (p=0.009, logit=17.375)', '\" (\"[320] (p=0.007, logit=17.125)', '\" A\"[362] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.867, logit=22.625)', '\" The\"[578] (p=0.071, logit=20.125)', '\" Among\"[22395] (p=0.034, logit=19.375)', '\" It\"[1102] (p=0.007, logit=17.750)', '\" A\"[362] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.8671875, logit=22.625, token_id=6031, metadata=None))), (70762, (148, PredictedToken(token=' Motorcycle', prob=5.334615707397461e-06, logit=10.625, token_id=70762, metadata=None))), (36358, (280, PredictedToken(token=' Bench', prob=1.8402934074401855e-06, logit=9.5625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.621, logit=21.250)', '\" The\"[578] (p=0.139, logit=19.750)', '\" A\"[362] (p=0.065, logit=19.000)', '\" Among\"[22395] (p=0.051, logit=18.750)', '\" Bro\"[6031] (p=0.045, logit=18.625)']\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.62109375, logit=21.25, token_id=36358, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.044921875, logit=18.625, token_id=6031, metadata=None))), (70762, (6, PredictedToken(token=' Motorcycle', prob=0.0240478515625, logit=18.0, token_id=70762, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:07 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:07 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:54:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     patch_prediction=['\" Printer\"[47033] (p=0.863, logit=22.125)', '\" The\"[578] (p=0.055, logit=19.375)', '\" A\"[362] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.012, logit=17.875)', '\" printer\"[23185] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     clean_prediction=['\" Potato\"[78703] (p=0.875, logit=21.875)', '\" The\"[578] (p=0.038, logit=18.750)', '\" Among\"[22395] (p=0.018, logit=18.000)', '\" A\"[362] (p=0.016, logit=17.875)', '\" (\"[320] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     clean_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.875, logit=21.875, token_id=78703, metadata=None))), (18191, (31, PredictedToken(token=' Mouse', prob=0.00024318695068359375, logit=13.6875, token_id=18191, metadata=None))), (65449, (41, PredictedToken(token=' Willow', prob=0.00013065338134765625, logit=13.0625, token_id=65449, metadata=None)))])\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     int_prediction=['\" Mouse\"[18191] (p=0.910, logit=22.000)', '\" A\"[362] (p=0.019, logit=18.125)', '\" None\"[2290] (p=0.015, logit=17.875)', '\" Potato\"[78703] (p=0.013, logit=17.750)', '\" The\"[578] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     int_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.91015625, logit=22.0, token_id=18191, metadata=None))), (78703, (4, PredictedToken(token=' Potato', prob=0.012939453125, logit=17.75, token_id=78703, metadata=None))), (65449, (124, PredictedToken(token=' Willow', prob=1.621246337890625e-05, logit=11.0625, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:08 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.766, logit=21.125)', '\" The\"[578] (p=0.071, logit=18.750)', '\" A\"[362] (p=0.049, logit=18.375)', '\" Among\"[22395] (p=0.043, logit=18.250)', '\" Ward\"[27738] (p=0.020, logit=17.500)']\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     clean_prediction=['\" Hospital\"[15429] (p=0.918, logit=22.625)', '\" The\"[578] (p=0.028, logit=19.125)', '\" A\"[362] (p=0.024, logit=19.000)', '\" Among\"[22395] (p=0.009, logit=18.000)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     clean_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.91796875, logit=22.625, token_id=15429, metadata=None))), (18654, (25, PredictedToken(token=' Micro', prob=0.00023937225341796875, logit=14.375, token_id=18654, metadata=None))), (9939, (44, PredictedToken(token=' Er', prob=6.866455078125e-05, logit=13.125, token_id=9939, metadata=None))), (59825, (321, PredictedToken(token=' Tie', prob=1.5124678611755371e-06, logit=9.3125, token_id=59825, metadata=None))), (83499, (335, PredictedToken(token=' Tooth', prob=1.4230608940124512e-06, logit=9.25, token_id=83499, metadata=None))), (47759, (367, PredictedToken(token=' Guitar', prob=1.259148120880127e-06, logit=9.125, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:08 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.785, logit=21.750)', '\" A\"[362] (p=0.094, logit=19.625)', '\" The\"[578] (p=0.050, logit=19.000)', '\" Guitar\"[47759] (p=0.024, logit=18.250)', '\" None\"[2290] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.78515625, logit=21.75, token_id=59825, metadata=None))), (47759, (4, PredictedToken(token=' Guitar', prob=0.023681640625, logit=18.25, token_id=47759, metadata=None))), (83499, (14, PredictedToken(token=' Tooth', prob=0.00104522705078125, logit=15.125, token_id=83499, metadata=None))), (9939, (25, PredictedToken(token=' Er', prob=0.000492095947265625, logit=14.375, token_id=9939, metadata=None))), (18654, (56, PredictedToken(token=' Micro', prob=7.534027099609375e-05, logit=12.5, token_id=18654, metadata=None))), (15429, (557, PredictedToken(token=' Hospital', prob=1.385807991027832e-06, logit=8.5, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:09 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:09 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     patch_prediction=['\" St\"[800] (p=0.809, logit=22.375)', '\" The\"[578] (p=0.066, logit=19.875)', '\" A\"[362] (p=0.059, logit=19.750)', '\" Among\"[22395] (p=0.031, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.785, logit=21.875)', '\" The\"[578] (p=0.073, logit=19.500)', '\" Among\"[22395] (p=0.039, logit=18.875)', '\" A\"[362] (p=0.039, logit=18.875)', '\" Option\"[7104] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.78515625, logit=21.875, token_id=40090, metadata=None))), (16488, (17, PredictedToken(token=' Bat', prob=0.00110626220703125, logit=15.3125, token_id=16488, metadata=None))), (1050, (26, PredictedToken(token=' Re', prob=0.000522613525390625, logit=14.5625, token_id=1050, metadata=None))), (22725, (62, PredictedToken(token=' Orange', prob=5.8650970458984375e-05, logit=12.375, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     int_prediction=['\" Re\"[1050] (p=0.789, logit=21.625)', '\" The\"[578] (p=0.044, logit=18.750)', '\" Among\"[22395] (p=0.035, logit=18.500)', '\" A\"[362] (p=0.031, logit=18.375)', '\" Orange\"[22725] (p=0.027, logit=18.250)']\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     int_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.7890625, logit=21.625, token_id=1050, metadata=None))), (22725, (5, PredictedToken(token=' Orange', prob=0.0269775390625, logit=18.25, token_id=22725, metadata=None))), (16488, (7, PredictedToken(token=' Bat', prob=0.01123046875, logit=17.375, token_id=16488, metadata=None))), (40090, (42, PredictedToken(token=' Pressure', prob=0.00020599365234375, logit=13.375, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:09 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:09 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:54:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     patch_prediction=['\" Surf\"[65197] (p=0.664, logit=20.875)', '\" The\"[578] (p=0.116, logit=19.125)', '\" A\"[362] (p=0.116, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.000)', '\" It\"[1102] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     clean_prediction=['\" Pepper\"[52882] (p=0.879, logit=21.500)', '\" The\"[578] (p=0.039, logit=18.375)', '\" Binder\"[91263] (p=0.014, logit=17.375)', '\" None\"[2290] (p=0.013, logit=17.250)', '\" A\"[362] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     clean_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.87890625, logit=21.5, token_id=52882, metadata=None))), (91263, (3, PredictedToken(token=' Binder', prob=0.01422119140625, logit=17.375, token_id=91263, metadata=None))), (3816, (22, PredictedToken(token=' Red', prob=0.00054931640625, logit=14.125, token_id=3816, metadata=None))), (79189, (96, PredictedToken(token=' Elephant', prob=4.5299530029296875e-05, logit=11.625, token_id=79189, metadata=None))), (10777, (203, PredictedToken(token=' Router', prob=9.47713851928711e-06, logit=10.0625, token_id=10777, metadata=None))), (67629, (328, PredictedToken(token=' Helmet', prob=4.202127456665039e-06, logit=9.25, token_id=67629, metadata=None)))])\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.539, logit=20.000)', '\" A\"[362] (p=0.175, logit=18.875)', '\" Router\"[10777] (p=0.083, logit=18.125)', '\" The\"[578] (p=0.073, logit=18.000)', '\" None\"[2290] (p=0.044, logit=17.500)']\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.5390625, logit=20.0, token_id=52882, metadata=None))), (10777, (3, PredictedToken(token=' Router', prob=0.08251953125, logit=18.125, token_id=10777, metadata=None))), (3816, (21, PredictedToken(token=' Red', prob=0.0014190673828125, logit=14.0625, token_id=3816, metadata=None))), (79189, (78, PredictedToken(token=' Elephant', prob=0.00014972686767578125, logit=11.8125, token_id=79189, metadata=None))), (91263, (86, PredictedToken(token=' Binder', prob=0.00011682510375976562, logit=11.5625, token_id=91263, metadata=None))), (67629, (98, PredictedToken(token=' Helmet', prob=9.107589721679688e-05, logit=11.3125, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:10 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:10 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.754, logit=21.125)', '\" A\"[362] (p=0.070, logit=18.750)', '\" The\"[578] (p=0.062, logit=18.625)', '\" Among\"[22395] (p=0.055, logit=18.500)', '\" Out\"[4470] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.053, logit=19.000)', '\" A\"[362] (p=0.037, logit=18.625)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" house\"[3838] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.8359375, logit=21.75, token_id=4783, metadata=None))), (61731, (22, PredictedToken(token=' Soap', prob=0.000812530517578125, logit=14.8125, token_id=61731, metadata=None))), (5907, (21, PredictedToken(token=' Project', prob=0.000812530517578125, logit=14.8125, token_id=5907, metadata=None))), (65329, (74, PredictedToken(token=' Elm', prob=6.67572021484375e-05, logit=12.3125, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:54:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.574, logit=20.000)', '\" Elm\"[65329] (p=0.164, logit=18.750)', '\" The\"[578] (p=0.088, logit=18.125)', '\" Project\"[5907] (p=0.037, logit=17.250)', '\" (\"[320] (p=0.015, logit=16.375)']\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.57421875, logit=20.0, token_id=61731, metadata=None))), (65329, (2, PredictedToken(token=' Elm', prob=0.1640625, logit=18.75, token_id=65329, metadata=None))), (5907, (4, PredictedToken(token=' Project', prob=0.03662109375, logit=17.25, token_id=5907, metadata=None))), (4783, (89, PredictedToken(token=' House', prob=0.0001163482666015625, logit=11.5, token_id=4783, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:11 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.691, logit=22.250)', '\" An\"[1556] (p=0.154, logit=20.750)', '\" The\"[578] (p=0.064, logit=19.875)', '\" Among\"[22395] (p=0.050, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.871, logit=21.500)', '\" The\"[578] (p=0.034, logit=18.250)', '\" A\"[362] (p=0.034, logit=18.250)', '\" Among\"[22395] (p=0.021, logit=17.750)', '\" R\"[432] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.87109375, logit=21.5, token_id=74968, metadata=None))), (356, (19, PredictedToken(token=' C', prob=0.000659942626953125, logit=14.3125, token_id=356, metadata=None))), (27217, (39, PredictedToken(token=' Train', prob=0.0001888275146484375, logit=13.0625, token_id=27217, metadata=None))), (91263, (57, PredictedToken(token=' Binder', prob=0.0001010894775390625, logit=12.4375, token_id=91263, metadata=None))), (34392, (97, PredictedToken(token=' Horse', prob=3.4809112548828125e-05, logit=11.375, token_id=34392, metadata=None))), (6150, (168, PredictedToken(token=' School', prob=1.2040138244628906e-05, logit=10.3125, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.895, logit=22.000)', '\" The\"[578] (p=0.035, logit=18.750)', '\" Among\"[22395] (p=0.019, logit=18.125)', '\" A\"[362] (p=0.014, logit=17.875)', '\" None\"[2290] (p=0.003, logit=16.125)']\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.89453125, logit=22.0, token_id=27217, metadata=None))), (34392, (6, PredictedToken(token=' Horse', prob=0.0025177001953125, logit=16.125, token_id=34392, metadata=None))), (91263, (7, PredictedToken(token=' Binder', prob=0.001953125, logit=15.875, token_id=91263, metadata=None))), (356, (17, PredictedToken(token=' C', prob=0.00104522705078125, logit=15.25, token_id=356, metadata=None))), (74968, (76, PredictedToken(token=' Razor', prob=3.814697265625e-05, logit=11.9375, token_id=74968, metadata=None))), (6150, (180, PredictedToken(token=' School', prob=7.063150405883789e-06, logit=10.25, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:11 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:11 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:54:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     patch_prediction=['\" Marker\"[40975] (p=0.871, logit=22.250)', '\" The\"[578] (p=0.043, logit=19.250)', '\" A\"[362] (p=0.034, logit=19.000)', '\" Among\"[22395] (p=0.021, logit=18.500)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.734, logit=22.125)', '\" The\"[578] (p=0.087, logit=20.000)', '\" A\"[362] (p=0.087, logit=20.000)', '\" Among\"[22395] (p=0.032, logit=19.000)', '\" Binder\"[91263] (p=0.022, logit=18.625)']\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.734375, logit=22.125, token_id=34785, metadata=None))), (91263, (5, PredictedToken(token=' Binder', prob=0.0220947265625, logit=18.625, token_id=91263, metadata=None))), (15429, (38, PredictedToken(token=' Hospital', prob=0.00021648406982421875, logit=14.0, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     int_prediction=['\" Binder\"[91263] (p=0.891, logit=22.625)', '\" The\"[578] (p=0.035, logit=19.375)', '\" A\"[362] (p=0.035, logit=19.375)', '\" Truck\"[34785] (p=0.011, logit=18.250)', '\" Among\"[22395] (p=0.007, logit=17.750)']\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     int_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.890625, logit=22.625, token_id=91263, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.01123046875, logit=18.25, token_id=34785, metadata=None))), (15429, (11, PredictedToken(token=' Hospital', prob=0.000865936279296875, logit=15.6875, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:12 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:12 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     patch_prediction=['\" Project\"[5907] (p=0.738, logit=21.000)', '\" The\"[578] (p=0.069, logit=18.625)', '\" Among\"[22395] (p=0.053, logit=18.375)', '\" Pepper\"[52882] (p=0.037, logit=18.000)', '\" A\"[362] (p=0.029, logit=17.750)']\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.738, logit=22.000)', '\" The\"[578] (p=0.146, logit=20.375)', '\" A\"[362] (p=0.047, logit=19.250)', '\" Among\"[22395] (p=0.032, logit=18.875)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.73828125, logit=22.0, token_id=31181, metadata=None))), (16183, (113, PredictedToken(token=' Hel', prob=1.3172626495361328e-05, logit=11.0625, token_id=16183, metadata=None))), (17929, (174, PredictedToken(token=' Pin', prob=5.4836273193359375e-06, logit=10.1875, token_id=17929, metadata=None))), (11896, (286, PredictedToken(token=' Library', prob=2.1457672119140625e-06, logit=9.25, token_id=11896, metadata=None))), (57225, (628, PredictedToken(token=' Laptop', prob=6.146728992462158e-07, logit=8.0, token_id=57225, metadata=None))), (38258, (643, PredictedToken(token=' Baseball', prob=5.960464477539062e-07, logit=7.96875, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:54:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     int_prediction=['\" Laptop\"[57225] (p=0.336, logit=20.125)', '\" Clar\"[31181] (p=0.203, logit=19.625)', '\" The\"[578] (p=0.140, logit=19.250)', '\" Hel\"[16183] (p=0.123, logit=19.125)', '\" Among\"[22395] (p=0.075, logit=18.625)']\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     int_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.3359375, logit=20.125, token_id=57225, metadata=None))), (31181, (2, PredictedToken(token=' Clar', prob=0.203125, logit=19.625, token_id=31181, metadata=None))), (16183, (4, PredictedToken(token=' Hel', prob=0.123046875, logit=19.125, token_id=16183, metadata=None))), (11896, (12, PredictedToken(token=' Library', prob=0.00225830078125, logit=15.125, token_id=11896, metadata=None))), (38258, (188, PredictedToken(token=' Baseball', prob=1.519918441772461e-05, logit=10.125, token_id=38258, metadata=None))), (17929, (214, PredictedToken(token=' Pin', prob=1.043081283569336e-05, logit=9.75, token_id=17929, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:13 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.789, logit=22.000)', '\" The\"[578] (p=0.106, logit=20.000)', '\" Among\"[22395] (p=0.031, logit=18.750)', '\" A\"[362] (p=0.031, logit=18.750)', '\" It\"[1102] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.812, logit=21.625)', '\" An\"[1556] (p=0.052, logit=18.875)', '\" The\"[578] (p=0.046, logit=18.750)', '\" Among\"[22395] (p=0.022, logit=18.000)', '\" Ch\"[921] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.8125, logit=21.625, token_id=6690, metadata=None))), (921, (5, PredictedToken(token=' Ch', prob=0.0115966796875, logit=17.375, token_id=921, metadata=None))), (46506, (13, PredictedToken(token=' Drum', prob=0.002288818359375, logit=15.75, token_id=46506, metadata=None)))])\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     int_prediction=['\" Ch\"[921] (p=0.758, logit=21.500)', '\" Drum\"[46506] (p=0.116, logit=19.625)', '\" The\"[578] (p=0.033, logit=18.375)', '\" Among\"[22395] (p=0.026, logit=18.125)', '\" (\"[320] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     int_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.7578125, logit=21.5, token_id=921, metadata=None))), (46506, (2, PredictedToken(token=' Drum', prob=0.1162109375, logit=19.625, token_id=46506, metadata=None))), (6690, (45, PredictedToken(token=' Air', prob=0.00017452239990234375, logit=13.125, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:13 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:54:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     patch_prediction=['\" Paper\"[18343] (p=0.902, logit=21.500)', '\" paper\"[5684] (p=0.021, logit=17.750)', '\" The\"[578] (p=0.021, logit=17.750)', '\" A\"[362] (p=0.009, logit=16.875)', '\" Among\"[22395] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.953, logit=22.500)', '\" The\"[578] (p=0.009, logit=17.875)', '\" violet\"[80836] (p=0.008, logit=17.750)', '\" (\"[320] (p=0.006, logit=17.500)', '\" Among\"[22395] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.953125, logit=22.5, token_id=74574, metadata=None))), (432, (9, PredictedToken(token=' R', prob=0.00125885009765625, logit=15.875, token_id=432, metadata=None))), (17367, (157, PredictedToken(token=' Factory', prob=4.26173210144043e-06, logit=10.1875, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.961, logit=22.750)', '\" R\"[432] (p=0.011, logit=18.250)', '\" The\"[578] (p=0.006, logit=17.750)', '\" violet\"[80836] (p=0.006, logit=17.625)', '\" (\"[320] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.9609375, logit=22.75, token_id=74574, metadata=None))), (432, (2, PredictedToken(token=' R', prob=0.01068115234375, logit=18.25, token_id=432, metadata=None))), (17367, (19, PredictedToken(token=' Factory', prob=0.00019550323486328125, logit=14.25, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:14 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:14 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.621, logit=21.375)', '\" The\"[578] (p=0.157, logit=20.000)', '\" A\"[362] (p=0.122, logit=19.750)', '\" Among\"[22395] (p=0.027, logit=18.250)', '\" It\"[1102] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     clean_prediction=['\" Jeans\"[82507] (p=0.762, logit=21.625)', '\" The\"[578] (p=0.104, logit=19.625)', '\" Among\"[22395] (p=0.062, logit=19.125)', '\" Ank\"[57915] (p=0.010, logit=17.250)', '\" JE\"[71430] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     clean_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.76171875, logit=21.625, token_id=82507, metadata=None))), (57915, (4, PredictedToken(token=' Ank', prob=0.00958251953125, logit=17.25, token_id=57915, metadata=None))), (3341, (46, PredictedToken(token=' Car', prob=0.00021266937255859375, logit=13.4375, token_id=3341, metadata=None))), (47589, (200, PredictedToken(token=' Basketball', prob=6.8247318267822266e-06, logit=10.0, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:54:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.836, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" A\"[362] (p=0.014, logit=18.125)', '\" Car\"[3341] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.8359375, logit=22.25, token_id=47589, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.004974365234375, logit=17.125, token_id=3341, metadata=None))), (82507, (22, PredictedToken(token=' Jeans', prob=0.0005950927734375, logit=15.0, token_id=82507, metadata=None))), (57915, (25, PredictedToken(token=' Ank', prob=0.00055694580078125, logit=14.9375, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:15 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:15 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.789, logit=21.625)', '\" The\"[578] (p=0.073, logit=19.250)', '\" A\"[362] (p=0.050, logit=18.875)', '\" Among\"[22395] (p=0.044, logit=18.750)', '\" Option\"[7104] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     clean_prediction=['\" Tennis\"[58251] (p=0.746, logit=21.375)', '\" The\"[578] (p=0.101, logit=19.375)', '\" A\"[362] (p=0.089, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.000)', '\" It\"[1102] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     clean_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.74609375, logit=21.375, token_id=58251, metadata=None))), (40975, (26, PredictedToken(token=' Marker', prob=0.0003643035888671875, logit=13.75, token_id=40975, metadata=None))), (469, (37, PredictedToken(token=' E', prob=0.00018310546875, logit=13.0625, token_id=469, metadata=None))), (79189, (366, PredictedToken(token=' Elephant', prob=2.3096799850463867e-06, logit=8.6875, token_id=79189, metadata=None))), (87213, (382, PredictedToken(token=' Oven', prob=2.16066837310791e-06, logit=8.625, token_id=87213, metadata=None))), (80629, (499, PredictedToken(token=' Grape', prob=1.4901161193847656e-06, logit=8.25, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.594, logit=20.500)', '\" An\"[1556] (p=0.150, logit=19.125)', '\" The\"[578] (p=0.081, logit=18.500)', '\" Tennis\"[58251] (p=0.055, logit=18.125)', '\" Marker\"[40975] (p=0.026, logit=17.375)']\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.59375, logit=20.5, token_id=87213, metadata=None))), (58251, (4, PredictedToken(token=' Tennis', prob=0.05517578125, logit=18.125, token_id=58251, metadata=None))), (40975, (5, PredictedToken(token=' Marker', prob=0.026123046875, logit=17.375, token_id=40975, metadata=None))), (469, (11, PredictedToken(token=' E', prob=0.0033111572265625, logit=15.3125, token_id=469, metadata=None))), (80629, (163, PredictedToken(token=' Grape', prob=1.8477439880371094e-05, logit=10.125, token_id=80629, metadata=None))), (79189, (271, PredictedToken(token=' Elephant', prob=7.748603820800781e-06, logit=9.25, token_id=79189, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:15 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:15 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:54:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.891, logit=22.000)', '\" The\"[578] (p=0.034, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=18.375)', '\" (\"[320] (p=0.009, logit=17.375)', '\" Option\"[7104] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.844, logit=22.000)', '\" The\"[578] (p=0.054, logit=19.250)', '\" Among\"[22395] (p=0.033, logit=18.750)', '\" A\"[362] (p=0.023, logit=18.375)', '\" plum\"[42272] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.84375, logit=22.0, token_id=84409, metadata=None))), (15883, (20, PredictedToken(token=' Spr', prob=0.000640869140625, logit=14.8125, token_id=15883, metadata=None))), (57225, (572, PredictedToken(token=' Laptop', prob=7.972121238708496e-07, logit=8.125, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     int_prediction=['\" Spr\"[15883] (p=0.758, logit=22.250)', '\" Plum\"[84409] (p=0.132, logit=20.500)', '\" The\"[578] (p=0.048, logit=19.500)', '\" Among\"[22395] (p=0.023, logit=18.750)', '\" Option\"[7104] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     int_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.7578125, logit=22.25, token_id=15883, metadata=None))), (84409, (2, PredictedToken(token=' Plum', prob=0.1318359375, logit=20.5, token_id=84409, metadata=None))), (57225, (2829, PredictedToken(token=' Laptop', prob=7.078051567077637e-08, logit=6.0625, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:16 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.820, logit=21.250)', '\" An\"[1556] (p=0.067, logit=18.750)', '\" The\"[578] (p=0.041, logit=18.250)', '\" Among\"[22395] (p=0.022, logit=17.625)', '\" It\"[1102] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:54:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.836, logit=21.250)', '\" The\"[578] (p=0.068, logit=18.750)', '\" Among\"[22395] (p=0.042, logit=18.250)', '\" toilet\"[27306] (p=0.005, logit=16.125)', '\" A\"[362] (p=0.004, logit=15.875)']\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.8359375, logit=21.25, token_id=82994, metadata=None))), (97796, (64, PredictedToken(token=' Skate', prob=0.000102996826171875, logit=12.25, token_id=97796, metadata=None))), (3061, (152, PredictedToken(token=' Fl', prob=1.5735626220703125e-05, logit=10.375, token_id=3061, metadata=None))), (58937, (232, PredictedToken(token=' Monkey', prob=7.450580596923828e-06, logit=9.625, token_id=58937, metadata=None))), (50159, (283, PredictedToken(token=' Sco', prob=4.827976226806641e-06, logit=9.1875, token_id=50159, metadata=None))), (71264, (715, PredictedToken(token=' Daisy', prob=1.214444637298584e-06, logit=7.8125, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.812, logit=21.375)', '\" The\"[578] (p=0.076, logit=19.000)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" A\"[362] (p=0.019, logit=17.625)', '\" d\"[294] (p=0.017, logit=17.500)']\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.8125, logit=21.375, token_id=71264, metadata=None))), (3061, (20, PredictedToken(token=' Fl', prob=0.00054168701171875, logit=14.0625, token_id=3061, metadata=None))), (58937, (23, PredictedToken(token=' Monkey', prob=0.000423431396484375, logit=13.8125, token_id=58937, metadata=None))), (82994, (76, PredictedToken(token=' Toilet', prob=4.1961669921875e-05, logit=11.5, token_id=82994, metadata=None))), (97796, (327, PredictedToken(token=' Skate', prob=3.2335519790649414e-06, logit=8.9375, token_id=97796, metadata=None))), (50159, (1002, PredictedToken(token=' Sco', prob=6.966292858123779e-07, logit=7.40625, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:17 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:17 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     patch_prediction=['\" Yoga\"[38673] (p=0.676, logit=20.375)', '\" The\"[578] (p=0.081, logit=18.250)', '\" A\"[362] (p=0.081, logit=18.250)', '\" Among\"[22395] (p=0.030, logit=17.250)', '\" None\"[2290] (p=0.026, logit=17.125)']\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     clean_prediction=['\" Phone\"[14642] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.116, logit=19.500)', '\" Among\"[22395] (p=0.038, logit=18.375)', '\" A\"[362] (p=0.026, logit=18.000)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     clean_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.75390625, logit=21.375, token_id=14642, metadata=None))), (97796, (41, PredictedToken(token=' Skate', prob=0.0002689361572265625, logit=13.4375, token_id=97796, metadata=None))), (38571, (66, PredictedToken(token=' Theater', prob=9.298324584960938e-05, logit=12.375, token_id=38571, metadata=None))), (87035, (216, PredictedToken(token=' Onion', prob=7.62939453125e-06, logit=9.875, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.883, logit=21.625)', '\" The\"[578] (p=0.044, logit=18.625)', '\" A\"[362] (p=0.014, logit=17.500)', '\" Among\"[22395] (p=0.011, logit=17.250)', '\" \"[220] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.8828125, logit=21.625, token_id=97796, metadata=None))), (38571, (55, PredictedToken(token=' Theater', prob=0.00014019012451171875, logit=12.875, token_id=38571, metadata=None))), (14642, (67, PredictedToken(token=' Phone', prob=7.486343383789062e-05, logit=12.25, token_id=14642, metadata=None))), (87035, (137, PredictedToken(token=' Onion', prob=1.6689300537109375e-05, logit=10.75, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:17 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:17 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:54:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     patch_prediction=['\" Folder\"[36943] (p=0.762, logit=20.750)', '\" The\"[578] (p=0.071, logit=18.375)', '\" A\"[362] (p=0.071, logit=18.375)', '\" Among\"[22395] (p=0.014, logit=16.750)', '\" Let\"[6914] (p=0.014, logit=16.750)']\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     clean_prediction=['\" Mushroom\"[91297] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.047, logit=18.500)', '\" A\"[362] (p=0.037, logit=18.250)', '\" None\"[2290] (p=0.020, logit=17.625)', '\" There\"[2684] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     clean_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.8359375, logit=21.375, token_id=91297, metadata=None))), (57094, (15, PredictedToken(token=' Highlight', prob=0.000812530517578125, logit=14.4375, token_id=57094, metadata=None))), (18191, (25, PredictedToken(token=' Mouse', prob=0.000408172607421875, logit=13.75, token_id=18191, metadata=None))), (432, (36, PredictedToken(token=' R', prob=0.00021839141845703125, logit=13.125, token_id=432, metadata=None))), (48035, (125, PredictedToken(token=' Gir', prob=1.800060272216797e-05, logit=10.625, token_id=48035, metadata=None))), (6690, (153, PredictedToken(token=' Air', prob=1.3947486877441406e-05, logit=10.375, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     int_prediction=['\" Mouse\"[18191] (p=0.566, logit=21.125)', '\" Highlight\"[57094] (p=0.209, logit=20.125)', '\" None\"[2290] (p=0.077, logit=19.125)', '\" A\"[362] (p=0.053, logit=18.750)', '\" The\"[578] (p=0.041, logit=18.500)']\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     int_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.56640625, logit=21.125, token_id=18191, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.208984375, logit=20.125, token_id=57094, metadata=None))), (91297, (8, PredictedToken(token=' Mushroom', prob=0.0033721923828125, logit=16.0, token_id=91297, metadata=None))), (432, (9, PredictedToken(token=' R', prob=0.0029754638671875, logit=15.875, token_id=432, metadata=None))), (6690, (267, PredictedToken(token=' Air', prob=5.3942203521728516e-06, logit=9.5625, token_id=6690, metadata=None))), (48035, (3456, PredictedToken(token=' Gir', prob=1.4435499906539917e-07, logit=5.9375, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:18 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.824, logit=22.250)', '\" The\"[578] (p=0.041, logit=19.250)', '\" None\"[2290] (p=0.032, logit=19.000)', '\" A\"[362] (p=0.032, logit=19.000)', '\" Among\"[22395] (p=0.028, logit=18.875)']\n",
      "2025-09-16 09:54:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     clean_prediction=['\" Lily\"[48390] (p=0.730, logit=21.625)', '\" The\"[578] (p=0.127, logit=19.875)', '\" Among\"[22395] (p=0.077, logit=19.375)', '\" A\"[362] (p=0.020, logit=18.000)', '\" l\"[326] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     clean_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.73046875, logit=21.625, token_id=48390, metadata=None))), (33199, (29, PredictedToken(token=' Lion', prob=0.000335693359375, logit=13.9375, token_id=33199, metadata=None))), (39247, (30, PredictedToken(token=' Slow', prob=0.0003147125244140625, logit=13.875, token_id=39247, metadata=None))), (9441, (212, PredictedToken(token=' Church', prob=4.798173904418945e-06, logit=9.6875, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.723, logit=21.625)', '\" The\"[578] (p=0.143, logit=20.000)', '\" Among\"[22395] (p=0.059, logit=19.125)', '\" A\"[362] (p=0.019, logit=18.000)', '\" Lily\"[48390] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.72265625, logit=21.625, token_id=9441, metadata=None))), (48390, (5, PredictedToken(token=' Lily', prob=0.008056640625, logit=17.125, token_id=48390, metadata=None))), (33199, (60, PredictedToken(token=' Lion', prob=0.00010776519775390625, logit=12.8125, token_id=33199, metadata=None))), (39247, (71, PredictedToken(token=' Slow', prob=7.390975952148438e-05, logit=12.4375, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:19 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:19 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.840, logit=21.875)', '\" The\"[578] (p=0.054, logit=19.125)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" A\"[362] (p=0.033, logit=18.625)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.656, logit=20.250)', '\" The\"[578] (p=0.129, logit=18.625)', '\" Among\"[22395] (p=0.089, logit=18.250)', '\" shorts\"[36876] (p=0.012, logit=16.250)', '\" \"\"[330] (p=0.011, logit=16.125)']\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.65625, logit=20.25, token_id=91782, metadata=None))), (3816, (89, PredictedToken(token=' Red', prob=8.058547973632812e-05, logit=11.25, token_id=3816, metadata=None))), (36943, (93, PredictedToken(token=' Folder', prob=7.581710815429688e-05, logit=11.1875, token_id=36943, metadata=None))), (6771, (118, PredictedToken(token=' Table', prob=5.221366882324219e-05, logit=10.8125, token_id=6771, metadata=None))), (16730, (139, PredictedToken(token=' Museum', prob=3.361701965332031e-05, logit=10.375, token_id=16730, metadata=None))), (26698, (157, PredictedToken(token=' Keyboard', prob=2.6226043701171875e-05, logit=10.125, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.621, logit=20.375)', '\" The\"[578] (p=0.139, logit=18.875)', '\" A\"[362] (p=0.058, logit=18.000)', '\" Red\"[3816] (p=0.051, logit=17.875)', '\" Among\"[22395] (p=0.031, logit=17.375)']\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.62109375, logit=20.375, token_id=26698, metadata=None))), (3816, (4, PredictedToken(token=' Red', prob=0.051025390625, logit=17.875, token_id=3816, metadata=None))), (36943, (6, PredictedToken(token=' Folder', prob=0.01287841796875, logit=16.5, token_id=36943, metadata=None))), (6771, (14, PredictedToken(token=' Table', prob=0.003265380859375, logit=15.125, token_id=6771, metadata=None))), (16730, (70, PredictedToken(token=' Museum', prob=0.000152587890625, logit=12.0625, token_id=16730, metadata=None))), (91782, (448, PredictedToken(token=' Shorts', prob=4.32133674621582e-06, logit=8.5, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:19 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:19 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:54:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     patch_prediction=['\" Clar\"[31181] (p=0.816, logit=21.875)', '\" The\"[578] (p=0.067, logit=19.375)', '\" A\"[362] (p=0.028, logit=18.500)', '\" Spr\"[15883] (p=0.025, logit=18.375)', '\" Among\"[22395] (p=0.013, logit=17.750)']\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.855, logit=21.750)', '\" The\"[578] (p=0.055, logit=19.000)', '\" A\"[362] (p=0.026, logit=18.250)', '\" None\"[2290] (p=0.018, logit=17.875)', '\" Among\"[22395] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.85546875, logit=21.75, token_id=33578, metadata=None))), (40759, (34, PredictedToken(token=' Harmon', prob=0.00019741058349609375, logit=13.375, token_id=40759, metadata=None))), (38258, (223, PredictedToken(token=' Baseball', prob=6.765127182006836e-06, logit=10.0, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     int_prediction=['\" Harmon\"[40759] (p=0.879, logit=22.000)', '\" The\"[578] (p=0.039, logit=18.875)', '\" A\"[362] (p=0.034, logit=18.750)', '\" None\"[2290] (p=0.010, logit=17.500)', '\" Palm\"[33578] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     int_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.87890625, logit=22.0, token_id=40759, metadata=None))), (33578, (5, PredictedToken(token=' Palm', prob=0.00860595703125, logit=17.375, token_id=33578, metadata=None))), (38258, (44, PredictedToken(token=' Baseball', prob=0.00012302398681640625, logit=13.125, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:20 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:54:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     patch_prediction=['\" Swe\"[37326] (p=0.738, logit=21.375)', '\" The\"[578] (p=0.088, logit=19.250)', '\" A\"[362] (p=0.078, logit=19.125)', '\" Among\"[22395] (p=0.042, logit=18.500)', '\" sweater\"[61221] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.867, logit=22.375)', '\" The\"[578] (p=0.043, logit=19.375)', '\" A\"[362] (p=0.034, logit=19.125)', '\" Among\"[22395] (p=0.018, logit=18.500)', '\" chain\"[8957] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.8671875, logit=22.375, token_id=29625, metadata=None))), (6914, (16, PredictedToken(token=' Let', prob=0.000743865966796875, logit=15.3125, token_id=6914, metadata=None))), (29318, (67, PredictedToken(token=' Dress', prob=4.744529724121094e-05, logit=12.5625, token_id=29318, metadata=None))), (11896, (98, PredictedToken(token=' Library', prob=1.9788742065429688e-05, logit=11.6875, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.902, logit=22.625)', '\" A\"[362] (p=0.031, logit=19.250)', '\" The\"[578] (p=0.019, logit=18.750)', '\" Library\"[11896] (p=0.009, logit=18.000)', '\" Let\"[6914] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.90234375, logit=22.625, token_id=29318, metadata=None))), (11896, (4, PredictedToken(token=' Library', prob=0.00885009765625, logit=18.0, token_id=11896, metadata=None))), (6914, (5, PredictedToken(token=' Let', prob=0.006072998046875, logit=17.625, token_id=6914, metadata=None))), (29625, (6, PredictedToken(token=' Chain', prob=0.006072998046875, logit=17.625, token_id=29625, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:21 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:21 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.777, logit=20.875)', '\" The\"[578] (p=0.063, logit=18.375)', '\" A\"[362] (p=0.063, logit=18.375)', '\" Among\"[22395] (p=0.030, logit=17.625)', '\" Razor\"[74968] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.891, logit=22.500)', '\" Among\"[22395] (p=0.050, logit=19.625)', '\" The\"[578] (p=0.039, logit=19.375)', '\" It\"[1102] (p=0.003, logit=16.625)', '\" \"[220] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.890625, logit=22.5, token_id=1666, metadata=None))), (16183, (13, PredictedToken(token=' Hel', prob=0.000492095947265625, logit=15.0, token_id=16183, metadata=None))), (23262, (31, PredictedToken(token=' Comb', prob=0.0001811981201171875, logit=14.0, token_id=23262, metadata=None))), (6017, (82, PredictedToken(token=' Book', prob=2.0265579223632812e-05, logit=11.8125, token_id=6017, metadata=None))), (67629, (296, PredictedToken(token=' Helmet', prob=1.8849968910217285e-06, logit=9.4375, token_id=67629, metadata=None))), (9441, (1690, PredictedToken(token=' Church', prob=1.210719347000122e-07, logit=6.6875, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:21 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.432, logit=20.500)', '\" Comb\"[23262] (p=0.124, logit=19.250)', '\" The\"[578] (p=0.124, logit=19.250)', '\" A\"[362] (p=0.096, logit=19.000)', '\" Among\"[22395] (p=0.085, logit=18.875)']\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.431640625, logit=20.5, token_id=16183, metadata=None))), (23262, (3, PredictedToken(token=' Comb', prob=0.12353515625, logit=19.25, token_id=23262, metadata=None))), (67629, (6, PredictedToken(token=' Helmet', prob=0.06591796875, logit=18.625, token_id=67629, metadata=None))), (1666, (7, PredictedToken(token=' As', prob=0.0069580078125, logit=16.375, token_id=1666, metadata=None))), (6017, (88, PredictedToken(token=' Book', prob=8.249282836914062e-05, logit=11.9375, token_id=6017, metadata=None))), (9441, (271, PredictedToken(token=' Church', prob=8.165836334228516e-06, logit=9.625, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:22 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:22 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     patch_prediction=['\" Daisy\"[71264] (p=0.660, logit=21.375)', '\" The\"[578] (p=0.147, logit=19.875)', '\" Among\"[22395] (p=0.061, logit=19.000)', '\" A\"[362] (p=0.054, logit=18.875)', '\" d\"[294] (p=0.026, logit=18.125)']\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     clean_prediction=['\" Ti\"[23126] (p=0.867, logit=21.500)', '\" The\"[578] (p=0.030, logit=18.125)', '\" Among\"[22395] (p=0.020, logit=17.750)', '\" A\"[362] (p=0.018, logit=17.625)', '\" (\"[320] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     clean_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.8671875, logit=21.5, token_id=23126, metadata=None))), (43316, (10, PredictedToken(token=' Tul', prob=0.0031280517578125, logit=15.875, token_id=43316, metadata=None))), (42609, (42, PredictedToken(token=' Pine', prob=0.0001659393310546875, logit=12.9375, token_id=42609, metadata=None))), (91297, (89, PredictedToken(token=' Mushroom', prob=3.933906555175781e-05, logit=11.5, token_id=91297, metadata=None)))])\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     int_prediction=['\" Ti\"[23126] (p=0.438, logit=20.000)', '\" Pine\"[42609] (p=0.342, logit=19.750)', '\" Tul\"[43316] (p=0.067, logit=18.125)', '\" The\"[578] (p=0.032, logit=17.375)', '\" (\"[320] (p=0.015, logit=16.625)']\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     int_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.4375, logit=20.0, token_id=23126, metadata=None))), (42609, (2, PredictedToken(token=' Pine', prob=0.341796875, logit=19.75, token_id=42609, metadata=None))), (43316, (3, PredictedToken(token=' Tul', prob=0.06689453125, logit=18.125, token_id=43316, metadata=None))), (91297, (13, PredictedToken(token=' Mushroom', prob=0.0040283203125, logit=15.3125, token_id=91297, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:22 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:54:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.801, logit=22.000)', '\" The\"[578] (p=0.075, logit=19.625)', '\" A\"[362] (p=0.051, logit=19.250)', '\" Among\"[22395] (p=0.035, logit=18.875)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     clean_prediction=['\" Ki\"[30558] (p=0.887, logit=22.625)', '\" The\"[578] (p=0.050, logit=19.750)', '\" Among\"[22395] (p=0.030, logit=19.250)', '\" A\"[362] (p=0.013, logit=18.375)', '\" ki\"[20548] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     clean_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.88671875, logit=22.625, token_id=30558, metadata=None))), (356, (18, PredictedToken(token=' C', prob=0.000431060791015625, logit=15.0, token_id=356, metadata=None))), (22050, (168, PredictedToken(token=' Hat', prob=3.7401914596557617e-06, logit=10.25, token_id=22050, metadata=None))), (11896, (296, PredictedToken(token=' Library', prob=1.2889504432678223e-06, logit=9.1875, token_id=11896, metadata=None))), (81501, (616, PredictedToken(token=' Pendant', prob=3.9301812648773193e-07, logit=8.0, token_id=81501, metadata=None))), (45332, (717, PredictedToken(token=' Boat', prob=3.166496753692627e-07, logit=7.78125, token_id=45332, metadata=None)))])\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.637, logit=21.250)', '\" The\"[578] (p=0.098, logit=19.375)', '\" Among\"[22395] (p=0.067, logit=19.000)', '\" Ki\"[30558] (p=0.067, logit=19.000)', '\" A\"[362] (p=0.059, logit=18.875)']\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.63671875, logit=21.25, token_id=11896, metadata=None))), (30558, (4, PredictedToken(token=' Ki', prob=0.06689453125, logit=19.0, token_id=30558, metadata=None))), (45332, (6, PredictedToken(token=' Boat', prob=0.01165771484375, logit=17.25, token_id=45332, metadata=None))), (22050, (8, PredictedToken(token=' Hat', prob=0.0062255859375, logit=16.625, token_id=22050, metadata=None))), (356, (22, PredictedToken(token=' C', prob=0.000843048095703125, logit=14.625, token_id=356, metadata=None))), (81501, (67, PredictedToken(token=' Pendant', prob=0.00010061264038085938, logit=12.5, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:23 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     patch_prediction=['\" Harmon\"[40759] (p=0.855, logit=22.875)', '\" The\"[578] (p=0.080, logit=20.500)', '\" A\"[362] (p=0.023, logit=19.250)', '\" Among\"[22395] (p=0.018, logit=19.000)', '\" It\"[1102] (p=0.006, logit=17.875)']\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.820, logit=21.250)', '\" The\"[578] (p=0.059, logit=18.625)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" A\"[362] (p=0.025, logit=17.750)', '\" It\"[1102] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.8203125, logit=21.25, token_id=38258, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.003570556640625, logit=15.8125, token_id=356, metadata=None))), (23262, (32, PredictedToken(token=' Comb', prob=0.000583648681640625, logit=14.0, token_id=23262, metadata=None))), (76924, (35, PredictedToken(token=' Banana', prob=0.000514984130859375, logit=13.875, token_id=76924, metadata=None))), (91263, (108, PredictedToken(token=' Binder', prob=4.220008850097656e-05, logit=11.375, token_id=91263, metadata=None)))])\n",
      "2025-09-16 09:54:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.303, logit=19.250)', '\" Banana\"[76924] (p=0.162, logit=18.625)', '\" None\"[2290] (p=0.127, logit=18.375)', '\" C\"[356] (p=0.087, logit=18.000)', '\" The\"[578] (p=0.077, logit=17.875)']\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.302734375, logit=19.25, token_id=23262, metadata=None))), (76924, (2, PredictedToken(token=' Banana', prob=0.162109375, logit=18.625, token_id=76924, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.0869140625, logit=18.0, token_id=356, metadata=None))), (38258, (9, PredictedToken(token=' Baseball', prob=0.01513671875, logit=16.25, token_id=38258, metadata=None))), (91263, (10, PredictedToken(token=' Binder', prob=0.01513671875, logit=16.25, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:24 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:24 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     patch_prediction=['\" Book\"[6017] (p=0.828, logit=22.000)', '\" The\"[578] (p=0.047, logit=19.125)', '\" A\"[362] (p=0.047, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=18.375)', '\" Coat\"[68867] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.844, logit=21.875)', '\" A\"[362] (p=0.048, logit=19.000)', '\" The\"[578] (p=0.037, logit=18.750)', '\" Dress\"[29318] (p=0.015, logit=17.875)', '\" Among\"[22395] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.84375, logit=21.875, token_id=17367, metadata=None))), (29318, (4, PredictedToken(token=' Dress', prob=0.01544189453125, logit=17.875, token_id=29318, metadata=None))), (328, (7, PredictedToken(token=' S', prob=0.004425048828125, logit=16.625, token_id=328, metadata=None)))])\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.828, logit=22.125)', '\" S\"[328] (p=0.068, logit=19.625)', '\" The\"[578] (p=0.028, logit=18.750)', '\" A\"[362] (p=0.028, logit=18.750)', '\" None\"[2290] (p=0.017, logit=18.250)']\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.828125, logit=22.125, token_id=29318, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.06787109375, logit=19.625, token_id=328, metadata=None))), (17367, (23, PredictedToken(token=' Factory', prob=0.000431060791015625, logit=14.5625, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:24 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:54:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.777, logit=21.500)', '\" The\"[578] (p=0.093, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.750)', '\" headphones\"[44101] (p=0.011, logit=17.250)', '\" It\"[1102] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.812, logit=21.875)', '\" The\"[578] (p=0.076, logit=19.500)', '\" Among\"[22395] (p=0.041, logit=18.875)', '\" A\"[362] (p=0.025, logit=18.375)', '\" It\"[1102] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.8125, logit=21.875, token_id=42609, metadata=None))), (469, (12, PredictedToken(token=' E', prob=0.00130462646484375, logit=15.4375, token_id=469, metadata=None))), (16147, (50, PredictedToken(token=' Smart', prob=7.82012939453125e-05, logit=12.625, token_id=16147, metadata=None))), (22050, (348, PredictedToken(token=' Hat', prob=1.952052116394043e-06, logit=8.9375, token_id=22050, metadata=None))), (3420, (833, PredictedToken(token=' Trump', prob=5.587935447692871e-07, logit=7.6875, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.773, logit=22.125)', '\" The\"[578] (p=0.072, logit=19.750)', '\" E\"[469] (p=0.038, logit=19.125)', '\" A\"[362] (p=0.030, logit=18.875)', '\" Smart\"[16147] (p=0.021, logit=18.500)']\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.7734375, logit=22.125, token_id=3420, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.038330078125, logit=19.125, token_id=469, metadata=None))), (16147, (5, PredictedToken(token=' Smart', prob=0.0205078125, logit=18.5, token_id=16147, metadata=None))), (22050, (144, PredictedToken(token=' Hat', prob=1.138448715209961e-05, logit=11.0, token_id=22050, metadata=None))), (42609, (1763, PredictedToken(token=' Pine', prob=1.8347054719924927e-07, logit=6.875, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:25 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     patch_prediction=['\" Mango\"[91963] (p=0.863, logit=22.000)', '\" The\"[578] (p=0.055, logit=19.250)', '\" Among\"[22395] (p=0.038, logit=18.875)', '\" A\"[362] (p=0.016, logit=18.000)', '\" Option\"[7104] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     clean_prediction=['\" Highlight\"[57094] (p=0.809, logit=21.750)', '\" The\"[578] (p=0.066, logit=19.250)', '\" A\"[362] (p=0.046, logit=18.875)', '\" Among\"[22395] (p=0.040, logit=18.750)', '\" Comb\"[23262] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     clean_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.80859375, logit=21.75, token_id=57094, metadata=None))), (23262, (5, PredictedToken(token=' Comb', prob=0.004791259765625, logit=16.625, token_id=23262, metadata=None))), (45332, (48, PredictedToken(token=' Boat', prob=9.965896606445312e-05, logit=12.75, token_id=45332, metadata=None))), (8868, (99, PredictedToken(token=' Blue', prob=2.86102294921875e-05, logit=11.5, token_id=8868, metadata=None))), (22607, (835, PredictedToken(token=' Cow', prob=7.860362529754639e-07, logit=7.90625, token_id=22607, metadata=None))), (47589, (862, PredictedToken(token=' Basketball', prob=7.599592208862305e-07, logit=7.875, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.887, logit=22.250)', '\" The\"[578] (p=0.044, logit=19.250)', '\" A\"[362] (p=0.030, logit=18.875)', '\" Among\"[22395] (p=0.014, logit=18.125)', '\" \"[220] (p=0.002, logit=16.250)']\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.88671875, logit=22.25, token_id=8868, metadata=None))), (57094, (29, PredictedToken(token=' Highlight', prob=0.0002040863037109375, logit=13.875, token_id=57094, metadata=None))), (23262, (54, PredictedToken(token=' Comb', prob=4.863739013671875e-05, logit=12.4375, token_id=23262, metadata=None))), (22607, (107, PredictedToken(token=' Cow', prob=1.4781951904296875e-05, logit=11.25, token_id=22607, metadata=None))), (47589, (156, PredictedToken(token=' Basketball', prob=7.927417755126953e-06, logit=10.625, token_id=47589, metadata=None))), (45332, (331, PredictedToken(token=' Boat', prob=1.7657876014709473e-06, logit=9.125, token_id=45332, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:26 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:26 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.789, logit=22.250)', '\" The\"[578] (p=0.073, logit=19.875)', '\" A\"[362] (p=0.065, logit=19.750)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" z\"[1167] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:54:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.793, logit=21.250)', '\" The\"[578] (p=0.074, logit=18.875)', '\" An\"[1556] (p=0.057, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=17.625)', '\" It\"[1102] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.79296875, logit=21.25, token_id=87035, metadata=None))), (79189, (7, PredictedToken(token=' Elephant', prob=0.00323486328125, logit=15.75, token_id=79189, metadata=None))), (61948, (301, PredictedToken(token=' Sofa', prob=4.291534423828125e-06, logit=9.125, token_id=61948, metadata=None))), (56491, (423, PredictedToken(token=' Piano', prob=2.60770320892334e-06, logit=8.625, token_id=56491, metadata=None)))])\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     int_prediction=['\" Elephant\"[79189] (p=0.559, logit=20.250)', '\" An\"[1556] (p=0.141, logit=18.875)', '\" Onion\"[87035] (p=0.125, logit=18.750)', '\" The\"[578] (p=0.075, logit=18.250)', '\" It\"[1102] (p=0.015, logit=16.625)']\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     int_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.55859375, logit=20.25, token_id=79189, metadata=None))), (87035, (3, PredictedToken(token=' Onion', prob=0.12451171875, logit=18.75, token_id=87035, metadata=None))), (61948, (10, PredictedToken(token=' Sofa', prob=0.00274658203125, logit=14.9375, token_id=61948, metadata=None))), (56491, (45, PredictedToken(token=' Piano', prob=0.0004215240478515625, logit=13.0625, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:27 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:27 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.676, logit=21.625)', '\" The\"[578] (p=0.117, logit=19.875)', '\" Among\"[22395] (p=0.081, logit=19.500)', '\" A\"[362] (p=0.063, logit=19.250)', '\" Option\"[7104] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.723, logit=21.000)', '\" The\"[578] (p=0.126, logit=19.250)', '\" A\"[362] (p=0.041, logit=18.125)', '\" Among\"[22395] (p=0.032, logit=17.875)', '\" d\"[294] (p=0.019, logit=17.375)']\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.72265625, logit=21.0, token_id=71264, metadata=None))), (22050, (53, PredictedToken(token=' Hat', prob=8.916854858398438e-05, logit=12.0, token_id=22050, metadata=None))), (27738, (120, PredictedToken(token=' Ward', prob=2.396106719970703e-05, logit=10.6875, token_id=27738, metadata=None))), (98641, (647, PredictedToken(token=' Microwave', prob=1.4901161193847656e-06, logit=7.90625, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     int_prediction=['\" Microwave\"[98641] (p=0.785, logit=21.250)', '\" The\"[578] (p=0.057, logit=18.625)', '\" A\"[362] (p=0.050, logit=18.500)', '\" Ward\"[27738] (p=0.039, logit=18.250)', '\" Hat\"[22050] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     int_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.78515625, logit=21.25, token_id=98641, metadata=None))), (27738, (4, PredictedToken(token=' Ward', prob=0.0390625, logit=18.25, token_id=27738, metadata=None))), (22050, (5, PredictedToken(token=' Hat', prob=0.01116943359375, logit=17.0, token_id=22050, metadata=None))), (71264, (10, PredictedToken(token=' Daisy', prob=0.003204345703125, logit=15.75, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:27 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:54:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     patch_prediction=['\" Mirror\"[34954] (p=0.961, logit=22.125)', '\" None\"[2290] (p=0.008, logit=17.375)', '\" The\"[578] (p=0.007, logit=17.250)', '\" Cedar\"[57748] (p=0.004, logit=16.625)', '\" Car\"[3341] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.801, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.058, logit=18.750)', '\" A\"[362] (p=0.027, logit=18.000)', '\" It\"[1102] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.80078125, logit=21.375, token_id=42609, metadata=None))), (63606, (43, PredictedToken(token=' Stap', prob=0.000152587890625, logit=12.8125, token_id=63606, metadata=None))), (47643, (61, PredictedToken(token=' Cel', prob=7.677078247070312e-05, logit=12.125, token_id=47643, metadata=None))), (53889, (76, PredictedToken(token=' Apartment', prob=4.9591064453125e-05, logit=11.6875, token_id=53889, metadata=None))), (74968, (1151, PredictedToken(token=' Razor', prob=5.029141902923584e-07, logit=7.09375, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.318, logit=19.375)', '\" Stap\"[63606] (p=0.219, logit=19.000)', '\" Pine\"[42609] (p=0.103, logit=18.250)', '\" The\"[578] (p=0.103, logit=18.250)', '\" Among\"[22395] (p=0.091, logit=18.125)']\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.318359375, logit=19.375, token_id=47643, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.21875, logit=19.0, token_id=63606, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.10302734375, logit=18.25, token_id=42609, metadata=None))), (53889, (7, PredictedToken(token=' Apartment', prob=0.029541015625, logit=17.0, token_id=53889, metadata=None))), (74968, (10, PredictedToken(token=' Razor', prob=0.007476806640625, logit=15.625, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:28 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     patch_prediction=['\" Dish\"[49268] (p=0.695, logit=21.500)', '\" The\"[578] (p=0.121, logit=19.750)', '\" A\"[362] (p=0.083, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.875)', '\" It\"[1102] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:54:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     clean_prediction=['\" Hair\"[26781] (p=0.617, logit=20.500)', '\" None\"[2290] (p=0.227, logit=19.500)', '\" Let\"[6914] (p=0.027, logit=17.375)', '\" D\"[423] (p=0.027, logit=17.375)', '\" The\"[578] (p=0.019, logit=17.000)']\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     clean_track=OrderedDict([(26781, (1, PredictedToken(token=' Hair', prob=0.6171875, logit=20.5, token_id=26781, metadata=None))), (423, (3, PredictedToken(token=' D', prob=0.027099609375, logit=17.375, token_id=423, metadata=None))), (6914, (4, PredictedToken(token=' Let', prob=0.027099609375, logit=17.375, token_id=6914, metadata=None))), (98641, (10, PredictedToken(token=' Microwave', prob=0.00390625, logit=15.4375, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.393, logit=19.875)', '\" D\"[423] (p=0.348, logit=19.750)', '\" Microwave\"[98641] (p=0.128, logit=18.750)', '\" The\"[578] (p=0.025, logit=17.125)', '\" There\"[2684] (p=0.022, logit=17.000)']\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     int_track=OrderedDict([(423, (2, PredictedToken(token=' D', prob=0.34765625, logit=19.75, token_id=423, metadata=None))), (98641, (3, PredictedToken(token=' Microwave', prob=0.1279296875, logit=18.75, token_id=98641, metadata=None))), (26781, (7, PredictedToken(token=' Hair', prob=0.01190185546875, logit=16.375, token_id=26781, metadata=None))), (6914, (21, PredictedToken(token=' Let', prob=0.0011749267578125, logit=14.0625, token_id=6914, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:29 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:29 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.820, logit=22.250)', '\" The\"[578] (p=0.052, logit=19.500)', '\" A\"[362] (p=0.052, logit=19.500)', '\" Among\"[22395] (p=0.025, logit=18.750)', '\" C\"[356] (p=0.015, logit=18.250)']\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.918, logit=21.375)', '\" The\"[578] (p=0.019, logit=17.500)', '\" Among\"[22395] (p=0.013, logit=17.125)', '\" A\"[362] (p=0.007, logit=16.500)', '\" R\"[432] (p=0.003, logit=15.750)']\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.91796875, logit=21.375, token_id=74968, metadata=None))), (36845, (6, PredictedToken(token=' Tiger', prob=0.0033111572265625, logit=15.75, token_id=36845, metadata=None))), (14937, (10, PredictedToken(token=' Ash', prob=0.0022735595703125, logit=15.375, token_id=14937, metadata=None))), (24423, (31, PredictedToken(token=' Monitor', prob=0.0002880096435546875, logit=13.3125, token_id=24423, metadata=None))), (98641, (117, PredictedToken(token=' Microwave', prob=2.5272369384765625e-05, logit=10.875, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     int_prediction=['\" Razor\"[74968] (p=0.559, logit=20.000)', '\" Ash\"[14937] (p=0.206, logit=19.000)', '\" Tiger\"[36845] (p=0.125, logit=18.500)', '\" The\"[578] (p=0.028, logit=17.000)', '\" None\"[2290] (p=0.007, logit=15.562)']\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     int_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.55859375, logit=20.0, token_id=74968, metadata=None))), (14937, (2, PredictedToken(token=' Ash', prob=0.2060546875, logit=19.0, token_id=14937, metadata=None))), (36845, (3, PredictedToken(token=' Tiger', prob=0.125, logit=18.5, token_id=36845, metadata=None))), (24423, (11, PredictedToken(token=' Monitor', prob=0.0027618408203125, logit=14.6875, token_id=24423, metadata=None))), (98641, (28, PredictedToken(token=' Microwave', prob=0.000896453857421875, logit=13.5625, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:29 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:29 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.773, logit=21.625)', '\" The\"[578] (p=0.072, logit=19.250)', '\" A\"[362] (p=0.063, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=18.125)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.762, logit=21.500)', '\" The\"[578] (p=0.117, logit=19.625)', '\" Among\"[22395] (p=0.043, logit=18.625)', '\" headphones\"[44101] (p=0.012, logit=17.375)', '\" It\"[1102] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.76171875, logit=21.5, token_id=11452, metadata=None))), (1443, (78, PredictedToken(token=' Sh', prob=5.340576171875e-05, logit=11.9375, token_id=1443, metadata=None))), (30760, (108, PredictedToken(token=' Scar', prob=3.039836883544922e-05, logit=11.375, token_id=30760, metadata=None))), (86460, (165, PredictedToken(token=' Necklace', prob=1.3530254364013672e-05, logit=10.5625, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.785, logit=21.625)', '\" The\"[578] (p=0.083, logit=19.375)', '\" A\"[362] (p=0.057, logit=19.000)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" Option\"[7104] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.78515625, logit=21.625, token_id=86460, metadata=None))), (11452, (14, PredictedToken(token=' Head', prob=0.00194549560546875, logit=15.625, token_id=11452, metadata=None))), (30760, (20, PredictedToken(token=' Scar', prob=0.000812530517578125, logit=14.75, token_id=30760, metadata=None))), (1443, (45, PredictedToken(token=' Sh', prob=0.0001811981201171875, logit=13.25, token_id=1443, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:30 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.750, logit=21.250)', '\" The\"[578] (p=0.079, logit=19.000)', '\" A\"[362] (p=0.070, logit=18.875)', '\" Among\"[22395] (p=0.042, logit=18.375)', '\" It\"[1102] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:54:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     clean_prediction=['\" Hair\"[26781] (p=0.797, logit=22.000)', '\" The\"[578] (p=0.074, logit=19.625)', '\" A\"[362] (p=0.074, logit=19.625)', '\" Among\"[22395] (p=0.021, logit=18.375)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     clean_track=OrderedDict([(26781, (1, PredictedToken(token=' Hair', prob=0.796875, logit=22.0, token_id=26781, metadata=None))), (13597, (8, PredictedToken(token=' Pen', prob=0.001739501953125, logit=15.875, token_id=13597, metadata=None))), (13394, (96, PredictedToken(token=' Bed', prob=2.47955322265625e-05, logit=11.625, token_id=13394, metadata=None))), (41445, (133, PredictedToken(token=' Television', prob=1.4126300811767578e-05, logit=11.0625, token_id=41445, metadata=None)))])\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.777, logit=21.750)', '\" The\"[578] (p=0.072, logit=19.375)', '\" A\"[362] (p=0.050, logit=19.000)', '\" Among\"[22395] (p=0.039, logit=18.750)', '\" Hair\"[26781] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.77734375, logit=21.75, token_id=13597, metadata=None))), (26781, (5, PredictedToken(token=' Hair', prob=0.01422119140625, logit=17.75, token_id=26781, metadata=None))), (13394, (18, PredictedToken(token=' Bed', prob=0.00096893310546875, logit=15.0625, token_id=13394, metadata=None))), (41445, (36, PredictedToken(token=' Television', prob=0.00022983551025390625, logit=13.625, token_id=41445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:31 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:31 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     patch_prediction=['\" Pine\"[42609] (p=0.910, logit=22.375)', '\" The\"[578] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.015, logit=18.250)', '\" A\"[362] (p=0.010, logit=17.875)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.867, logit=21.750)', '\" None\"[2290] (p=0.034, logit=18.500)', '\" The\"[578] (p=0.034, logit=18.500)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" Only\"[8442] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.8671875, logit=21.75, token_id=47643, metadata=None))), (29318, (6, PredictedToken(token=' Dress', prob=0.005828857421875, logit=16.75, token_id=29318, metadata=None))), (76924, (61, PredictedToken(token=' Banana', prob=8.869171142578125e-05, logit=12.5625, token_id=76924, metadata=None)))])\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.664, logit=21.125)', '\" None\"[2290] (p=0.148, logit=19.625)', '\" Banana\"[76924] (p=0.079, logit=19.000)', '\" The\"[578] (p=0.029, logit=18.000)', '\" A\"[362] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.6640625, logit=21.125, token_id=47643, metadata=None))), (76924, (3, PredictedToken(token=' Banana', prob=0.0791015625, logit=19.0, token_id=76924, metadata=None))), (29318, (8, PredictedToken(token=' Dress', prob=0.0057373046875, logit=16.375, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:31 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:31 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     patch_prediction=['\" Apartment\"[53889] (p=0.812, logit=22.375)', '\" An\"[1556] (p=0.085, logit=20.125)', '\" The\"[578] (p=0.036, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=19.125)', '\" None\"[2290] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.684, logit=22.750)', '\" An\"[1556] (p=0.172, logit=21.375)', '\" The\"[578] (p=0.082, logit=20.625)', '\" Among\"[22395] (p=0.034, logit=19.750)', '\" airplane\"[44024] (p=0.004, logit=17.500)']\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.68359375, logit=22.75, token_id=6690, metadata=None))), (356, (19, PredictedToken(token=' C', prob=0.000514984130859375, logit=15.5625, token_id=356, metadata=None))), (432, (45, PredictedToken(token=' R', prob=7.43865966796875e-05, logit=13.625, token_id=432, metadata=None))), (38571, (290, PredictedToken(token=' Theater', prob=1.4454126358032227e-06, logit=9.6875, token_id=38571, metadata=None))), (41785, (1006, PredictedToken(token=' Spin', prob=1.434236764907837e-07, logit=7.375, token_id=41785, metadata=None))), (38673, (1444, PredictedToken(token=' Yoga', prob=7.916241884231567e-08, logit=6.78125, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.602, logit=21.500)', '\" The\"[578] (p=0.134, logit=20.000)', '\" A\"[362] (p=0.072, logit=19.375)', '\" Among\"[22395] (p=0.063, logit=19.250)', '\" Air\"[6690] (p=0.034, logit=18.625)']\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.6015625, logit=21.5, token_id=38571, metadata=None))), (6690, (5, PredictedToken(token=' Air', prob=0.033935546875, logit=18.625, token_id=6690, metadata=None))), (432, (8, PredictedToken(token=' R', prob=0.006683349609375, logit=17.0, token_id=432, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.0027923583984375, logit=16.125, token_id=356, metadata=None))), (38673, (16, PredictedToken(token=' Yoga', prob=0.0024566650390625, logit=16.0, token_id=38673, metadata=None))), (41785, (228, PredictedToken(token=' Spin', prob=5.7220458984375e-06, logit=9.9375, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:32 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:54:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.875, logit=22.750)', '\" The\"[578] (p=0.056, logit=20.000)', '\" Among\"[22395] (p=0.049, logit=19.875)', '\" It\"[1102] (p=0.004, logit=17.250)', '\" \"[220] (p=0.001, logit=16.375)']\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.754, logit=22.375)', '\" The\"[578] (p=0.102, logit=20.375)', '\" A\"[362] (p=0.070, logit=20.000)', '\" Among\"[22395] (p=0.042, logit=19.500)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.75390625, logit=22.375, token_id=16183, metadata=None))), (11683, (21, PredictedToken(token=' Acc', prob=0.0004425048828125, logit=14.9375, token_id=11683, metadata=None))), (1901, (44, PredictedToken(token=' Z', prob=0.00011205673217773438, logit=13.5625, token_id=1901, metadata=None))), (98641, (100, PredictedToken(token=' Microwave', prob=1.609325408935547e-05, logit=11.625, token_id=98641, metadata=None))), (69755, (364, PredictedToken(token=' Notebook', prob=1.2442469596862793e-06, logit=9.0625, token_id=69755, metadata=None)))])\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.844, logit=22.375)', '\" The\"[578] (p=0.069, logit=19.875)', '\" Among\"[22395] (p=0.018, logit=18.500)', '\" A\"[362] (p=0.015, logit=18.375)', '\" Notebook\"[69755] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.84375, logit=22.375, token_id=1901, metadata=None))), (69755, (5, PredictedToken(token=' Notebook', prob=0.0093994140625, logit=17.875, token_id=69755, metadata=None))), (11683, (55, PredictedToken(token=' Acc', prob=7.62939453125e-05, logit=13.0625, token_id=11683, metadata=None))), (16183, (89, PredictedToken(token=' Hel', prob=2.6345252990722656e-05, logit=12.0, token_id=16183, metadata=None))), (98641, (2228, PredictedToken(token=' Microwave', prob=7.404014468193054e-08, logit=6.125, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:33 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:33 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.789, logit=21.250)', '\" The\"[578] (p=0.083, logit=19.000)', '\" Among\"[22395] (p=0.044, logit=18.375)', '\" Option\"[7104] (p=0.013, logit=17.125)', '\" (\"[320] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     clean_prediction=['\" Mosque\"[100031] (p=0.887, logit=22.625)', '\" The\"[578] (p=0.044, logit=19.625)', '\" A\"[362] (p=0.039, logit=19.500)', '\" Among\"[22395] (p=0.011, logit=18.250)', '\" MOS\"[74174] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     clean_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.88671875, logit=22.625, token_id=100031, metadata=None))), (328, (105, PredictedToken(token=' S', prob=7.927417755126953e-06, logit=11.0, token_id=328, metadata=None))), (97796, (152, PredictedToken(token=' Skate', prob=4.231929779052734e-06, logit=10.375, token_id=97796, metadata=None))), (49431, (338, PredictedToken(token=' Rabbit', prob=1.0058283805847168e-06, logit=8.9375, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:54:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.543, logit=21.000)', '\" S\"[328] (p=0.226, logit=20.125)', '\" The\"[578] (p=0.106, logit=19.375)', '\" A\"[362] (p=0.064, logit=18.875)', '\" Among\"[22395] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.54296875, logit=21.0, token_id=97796, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.2255859375, logit=20.125, token_id=328, metadata=None))), (49431, (11, PredictedToken(token=' Rabbit', prob=0.0018310546875, logit=15.3125, token_id=49431, metadata=None))), (100031, (19, PredictedToken(token=' Mosque', prob=0.00098419189453125, logit=14.6875, token_id=100031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:34 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.883, logit=21.000)', '\" Among\"[22395] (p=0.030, logit=17.625)', '\" The\"[578] (p=0.030, logit=17.625)', '\" A\"[362] (p=0.007, logit=16.125)', '\" None\"[2290] (p=0.006, logit=16.000)']\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.742, logit=20.500)', '\" A\"[362] (p=0.078, logit=18.250)', '\" The\"[578] (p=0.061, logit=18.000)', '\" Among\"[22395] (p=0.033, logit=17.375)', '\" Mirror\"[34954] (p=0.014, logit=16.500)']\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.7421875, logit=20.5, token_id=432, metadata=None))), (34954, (5, PredictedToken(token=' Mirror', prob=0.01361083984375, logit=16.5, token_id=34954, metadata=None))), (328, (9, PredictedToken(token=' S', prob=0.0030364990234375, logit=15.0, token_id=328, metadata=None))), (76924, (31, PredictedToken(token=' Banana', prob=0.000637054443359375, logit=13.4375, token_id=76924, metadata=None))), (94467, (32, PredictedToken(token=' Trom', prob=0.000637054443359375, logit=13.4375, token_id=94467, metadata=None))), (98028, (48, PredictedToken(token=' Bamboo', prob=0.000247955322265625, logit=12.5, token_id=98028, metadata=None)))])\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     int_prediction=['\" Bamboo\"[98028] (p=0.629, logit=19.750)', '\" Mirror\"[34954] (p=0.066, logit=17.500)', '\" The\"[578] (p=0.066, logit=17.500)', '\" Among\"[22395] (p=0.066, logit=17.500)', '\" Banana\"[76924] (p=0.031, logit=16.750)']\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     int_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.62890625, logit=19.75, token_id=98028, metadata=None))), (34954, (4, PredictedToken(token=' Mirror', prob=0.06640625, logit=17.5, token_id=34954, metadata=None))), (76924, (5, PredictedToken(token=' Banana', prob=0.03125, logit=16.75, token_id=76924, metadata=None))), (328, (50, PredictedToken(token=' S', prob=0.00041961669921875, logit=12.4375, token_id=328, metadata=None))), (432, (83, PredictedToken(token=' R', prob=0.00014495849609375, logit=11.375, token_id=432, metadata=None))), (94467, (177, PredictedToken(token=' Trom', prob=3.910064697265625e-05, logit=10.0625, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:34 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     patch_prediction=['\" Surf\"[65197] (p=0.633, logit=20.125)', '\" The\"[578] (p=0.125, logit=18.500)', '\" Among\"[22395] (p=0.059, logit=17.750)', '\" A\"[362] (p=0.059, logit=17.750)', '\" (\"[320] (p=0.015, logit=16.375)']\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.797, logit=21.125)', '\" The\"[578] (p=0.065, logit=18.625)', '\" An\"[1556] (p=0.035, logit=18.000)', '\" Among\"[22395] (p=0.027, logit=17.750)', '\" It\"[1102] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.796875, logit=21.125, token_id=14937, metadata=None))), (68867, (87, PredictedToken(token=' Coat', prob=6.771087646484375e-05, logit=11.75, token_id=68867, metadata=None))), (58403, (188, PredictedToken(token=' Tablet', prob=1.329183578491211e-05, logit=10.125, token_id=58403, metadata=None))), (41342, (235, PredictedToken(token=' Hockey', prob=9.119510650634766e-06, logit=9.75, token_id=41342, metadata=None)))])\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.746, logit=20.875)', '\" A\"[362] (p=0.130, logit=19.125)', '\" The\"[578] (p=0.042, logit=18.000)', '\" Among\"[22395] (p=0.011, logit=16.625)', '\" Tablet\"[58403] (p=0.008, logit=16.375)']\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.74609375, logit=20.875, token_id=41342, metadata=None))), (58403, (5, PredictedToken(token=' Tablet', prob=0.00830078125, logit=16.375, token_id=58403, metadata=None))), (68867, (62, PredictedToken(token=' Coat', prob=0.00011110305786132812, logit=12.0625, token_id=68867, metadata=None))), (14937, (88, PredictedToken(token=' Ash', prob=5.5789947509765625e-05, logit=11.375, token_id=14937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:35 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.746, logit=22.500)', '\" The\"[578] (p=0.114, logit=20.625)', '\" A\"[362] (p=0.061, logit=20.000)', '\" Among\"[22395] (p=0.048, logit=19.750)', '\" It\"[1102] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.805, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" A\"[362] (p=0.028, logit=18.875)', '\" Among\"[22395] (p=0.024, logit=18.750)', '\" It\"[1102] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8046875, logit=22.25, token_id=40759, metadata=None))), (43316, (67, PredictedToken(token=' Tul', prob=3.886222839355469e-05, logit=12.3125, token_id=43316, metadata=None))), (57915, (336, PredictedToken(token=' Ank', prob=1.5124678611755371e-06, logit=9.0625, token_id=57915, metadata=None))), (53889, (2564, PredictedToken(token=' Apartment', prob=8.242204785346985e-08, logit=6.15625, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:54:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     int_prediction=['\" Tul\"[43316] (p=0.668, logit=20.875)', '\" Harmon\"[40759] (p=0.090, logit=18.875)', '\" The\"[578] (p=0.090, logit=18.875)', '\" A\"[362] (p=0.033, logit=17.875)', '\" Among\"[22395] (p=0.026, logit=17.625)']\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     int_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.66796875, logit=20.875, token_id=43316, metadata=None))), (40759, (3, PredictedToken(token=' Harmon', prob=0.09033203125, logit=18.875, token_id=40759, metadata=None))), (57915, (21, PredictedToken(token=' Ank', prob=0.00136566162109375, logit=14.6875, token_id=57915, metadata=None))), (53889, (126, PredictedToken(token=' Apartment', prob=2.6702880859375e-05, logit=10.75, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:36 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:36 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.816, logit=22.500)', '\" The\"[578] (p=0.067, logit=20.000)', '\" A\"[362] (p=0.059, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=18.875)', '\" slow\"[6435] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.867, logit=22.000)', '\" The\"[578] (p=0.055, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.500)', '\" A\"[362] (p=0.020, logit=18.250)', '\" peach\"[73188] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.8671875, logit=22.0, token_id=64695, metadata=None))), (60413, (87, PredictedToken(token=' Uk', prob=1.5497207641601562e-05, logit=11.0625, token_id=60413, metadata=None))), (40090, (190, PredictedToken(token=' Pressure', prob=4.1425228118896484e-06, logit=9.75, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.551, logit=21.500)', '\" Peach\"[64695] (p=0.295, logit=20.875)', '\" The\"[578] (p=0.066, logit=19.375)', '\" Among\"[22395] (p=0.031, logit=18.625)', '\" A\"[362] (p=0.021, logit=18.250)']\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.55078125, logit=21.5, token_id=40090, metadata=None))), (64695, (2, PredictedToken(token=' Peach', prob=0.294921875, logit=20.875, token_id=64695, metadata=None))), (60413, (15, PredictedToken(token=' Uk', prob=0.000732421875, logit=14.875, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:36 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:54:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.734, logit=21.250)', '\" Ki\"[30558] (p=0.100, logit=19.250)', '\" The\"[578] (p=0.042, logit=18.375)', '\" Among\"[22395] (p=0.037, logit=18.250)', '\" A\"[362] (p=0.032, logit=18.125)']\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.824, logit=21.000)', '\" The\"[578] (p=0.047, logit=18.125)', '\" Among\"[22395] (p=0.036, logit=17.875)', '\" A\"[362] (p=0.025, logit=17.500)', '\" Option\"[7104] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.82421875, logit=21.0, token_id=57551, metadata=None))), (24423, (19, PredictedToken(token=' Monitor', prob=0.00080108642578125, logit=14.0625, token_id=24423, metadata=None))), (42609, (20, PredictedToken(token=' Pine', prob=0.000705718994140625, logit=13.9375, token_id=42609, metadata=None))), (22607, (66, PredictedToken(token=' Cow', prob=0.00011539459228515625, logit=12.125, token_id=22607, metadata=None))), (41342, (258, PredictedToken(token=' Hockey', prob=6.943941116333008e-06, logit=9.3125, token_id=41342, metadata=None)))])\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.859, logit=21.500)', '\" Pine\"[42609] (p=0.070, logit=19.000)', '\" The\"[578] (p=0.016, logit=17.500)', '\" A\"[362] (p=0.014, logit=17.375)', '\" Among\"[22395] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.859375, logit=21.5, token_id=22607, metadata=None))), (42609, (2, PredictedToken(token=' Pine', prob=0.0703125, logit=19.0, token_id=42609, metadata=None))), (57551, (30, PredictedToken(token=' Sink', prob=0.0002384185791015625, logit=13.3125, token_id=57551, metadata=None))), (41342, (574, PredictedToken(token=' Hockey', prob=1.3336539268493652e-06, logit=8.125, token_id=41342, metadata=None))), (24423, (2201, PredictedToken(token=' Monitor', prob=2.2444874048233032e-07, logit=6.34375, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:37 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:37 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.855, logit=22.500)', '\" The\"[578] (p=0.080, logit=20.125)', '\" Among\"[22395] (p=0.033, logit=19.250)', '\" A\"[362] (p=0.009, logit=18.000)', '\" water\"[3090] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.938, logit=21.625)', '\" Among\"[22395] (p=0.012, logit=17.250)', '\" The\"[578] (p=0.012, logit=17.250)', '\" D\"[423] (p=0.006, logit=16.500)', '\" None\"[2290] (p=0.003, logit=15.875)']\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.9375, logit=21.625, token_id=83499, metadata=None))), (423, (4, PredictedToken(token=' D', prob=0.00555419921875, logit=16.5, token_id=423, metadata=None))), (91782, (15, PredictedToken(token=' Shorts', prob=0.00080108642578125, logit=14.5625, token_id=91782, metadata=None))), (89077, (22, PredictedToken(token=' Strawberry', prob=0.000518798828125, logit=14.125, token_id=89077, metadata=None))), (30173, (28, PredictedToken(token=' Speaker', prob=0.0002956390380859375, logit=13.5625, token_id=30173, metadata=None))), (23462, (32, PredictedToken(token=' Stadium', prob=0.0002155303955078125, logit=13.25, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:54:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     int_prediction=['\" Strawberry\"[89077] (p=0.891, logit=21.125)', '\" The\"[578] (p=0.024, logit=17.500)', '\" A\"[362] (p=0.013, logit=16.875)', '\" Among\"[22395] (p=0.011, logit=16.750)', '\" D\"[423] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     int_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.890625, logit=21.125, token_id=89077, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.0098876953125, logit=16.625, token_id=423, metadata=None))), (91782, (48, PredictedToken(token=' Shorts', prob=0.00015926361083984375, logit=12.5, token_id=91782, metadata=None))), (83499, (152, PredictedToken(token=' Tooth', prob=1.7881393432617188e-05, logit=10.3125, token_id=83499, metadata=None))), (23462, (290, PredictedToken(token=' Stadium', prob=5.811452865600586e-06, logit=9.1875, token_id=23462, metadata=None))), (30173, (4132, PredictedToken(token=' Speaker', prob=1.601874828338623e-07, logit=5.59375, token_id=30173, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:38 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     patch_prediction=['\" Sofa\"[61948] (p=0.602, logit=21.250)', '\" The\"[578] (p=0.172, logit=20.000)', '\" Among\"[22395] (p=0.082, logit=19.250)', '\" A\"[362] (p=0.082, logit=19.250)', '\" SO\"[5745] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     clean_prediction=['\" Van\"[13000] (p=0.793, logit=21.875)', '\" The\"[578] (p=0.074, logit=19.500)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" A\"[362] (p=0.040, logit=18.875)', '\" VAN\"[97753] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     clean_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.79296875, logit=21.875, token_id=13000, metadata=None))), (5907, (7, PredictedToken(token=' Project', prob=0.005340576171875, logit=16.875, token_id=5907, metadata=None))), (423, (28, PredictedToken(token=' D', prob=0.0003204345703125, logit=14.0625, token_id=423, metadata=None))), (432, (41, PredictedToken(token=' R', prob=0.0001430511474609375, logit=13.25, token_id=432, metadata=None))), (3816, (86, PredictedToken(token=' Red', prob=3.3855438232421875e-05, logit=11.8125, token_id=3816, metadata=None))), (36358, (97, PredictedToken(token=' Bench', prob=2.6345252990722656e-05, logit=11.5625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.559, logit=20.875)', '\" The\"[578] (p=0.142, logit=19.500)', '\" A\"[362] (p=0.097, logit=19.125)', '\" Among\"[22395] (p=0.086, logit=19.000)', '\" B\"[426] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.55859375, logit=20.875, token_id=36358, metadata=None))), (13000, (6, PredictedToken(token=' Van', prob=0.0115966796875, logit=17.0, token_id=13000, metadata=None))), (5907, (8, PredictedToken(token=' Project', prob=0.00799560546875, logit=16.625, token_id=5907, metadata=None))), (423, (11, PredictedToken(token=' D', prob=0.0054931640625, logit=16.25, token_id=423, metadata=None))), (432, (17, PredictedToken(token=' R', prob=0.002593994140625, logit=15.5, token_id=432, metadata=None))), (3816, (75, PredictedToken(token=' Red', prob=7.343292236328125e-05, logit=11.9375, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:38 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.812, logit=21.625)', '\" The\"[578] (p=0.066, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=18.625)', '\" A\"[362] (p=0.031, logit=18.375)', '\" (\"[320] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.762, logit=21.875)', '\" The\"[578] (p=0.103, logit=19.875)', '\" Among\"[22395] (p=0.071, logit=19.500)', '\" A\"[362] (p=0.026, logit=18.500)', '\" Option\"[7104] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.76171875, logit=21.875, token_id=84409, metadata=None))), (2057, (47, PredictedToken(token=' To', prob=0.00012063980102539062, logit=13.125, token_id=2057, metadata=None))), (23126, (253, PredictedToken(token=' Ti', prob=3.0249357223510742e-06, logit=9.4375, token_id=23126, metadata=None))), (16478, (397, PredictedToken(token=' Chair', prob=1.4230608940124512e-06, logit=8.6875, token_id=16478, metadata=None)))])\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.543, logit=21.250)', '\" Among\"[22395] (p=0.121, logit=19.750)', '\" The\"[578] (p=0.121, logit=19.750)', '\" Ti\"[23126] (p=0.065, logit=19.125)', '\" A\"[362] (p=0.057, logit=19.000)']\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.54296875, logit=21.25, token_id=16478, metadata=None))), (23126, (4, PredictedToken(token=' Ti', prob=0.06494140625, logit=19.125, token_id=23126, metadata=None))), (2057, (6, PredictedToken(token=' To', prob=0.0269775390625, logit=18.25, token_id=2057, metadata=None))), (84409, (8, PredictedToken(token=' Plum', prob=0.0087890625, logit=17.125, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:39 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:39 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.812, logit=21.875)', '\" The\"[578] (p=0.076, logit=19.500)', '\" Among\"[22395] (p=0.052, logit=19.125)', '\" A\"[362] (p=0.012, logit=17.625)', '\" It\"[1102] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:54:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.734, logit=20.750)', '\" The\"[578] (p=0.088, logit=18.625)', '\" Among\"[22395] (p=0.047, logit=18.000)', '\" A\"[362] (p=0.028, logit=17.500)', '\" Option\"[7104] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.734375, logit=20.75, token_id=80629, metadata=None))), (17929, (13, PredictedToken(token=' Pin', prob=0.00408935546875, logit=15.5625, token_id=17929, metadata=None))), (53889, (182, PredictedToken(token=' Apartment', prob=1.5735626220703125e-05, logit=10.0, token_id=53889, metadata=None))), (65449, (189, PredictedToken(token=' Willow', prob=1.4781951904296875e-05, logit=9.9375, token_id=65449, metadata=None)))])\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.656, logit=20.500)', '\" The\"[578] (p=0.089, logit=18.500)', '\" Among\"[22395] (p=0.069, logit=18.250)', '\" Pin\"[17929] (p=0.054, logit=18.000)', '\" Grape\"[80629] (p=0.025, logit=17.250)']\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.65625, logit=20.5, token_id=65449, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.0537109375, logit=18.0, token_id=17929, metadata=None))), (80629, (5, PredictedToken(token=' Grape', prob=0.025390625, logit=17.25, token_id=80629, metadata=None))), (53889, (60, PredictedToken(token=' Apartment', prob=0.0002498626708984375, logit=12.625, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:40 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:40 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     patch_prediction=['\" Yoga\"[38673] (p=0.703, logit=19.125)', '\" None\"[2290] (p=0.074, logit=16.875)', '\" Ward\"[27738] (p=0.040, logit=16.250)', '\" The\"[578] (p=0.026, logit=15.812)', '\" (\"[320] (p=0.016, logit=15.375)']\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     clean_prediction=['\" Bed\"[13394] (p=0.906, logit=22.625)', '\" The\"[578] (p=0.031, logit=19.250)', '\" A\"[362] (p=0.015, logit=18.500)', '\" Among\"[22395] (p=0.010, logit=18.125)', '\" bed\"[4950] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     clean_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.90625, logit=22.625, token_id=13394, metadata=None))), (30555, (173, PredictedToken(token=' Viol', prob=3.814697265625e-06, logit=10.25, token_id=30555, metadata=None))), (21424, (186, PredictedToken(token=' Football', prob=3.3676624298095703e-06, logit=10.125, token_id=21424, metadata=None)))])\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.859, logit=22.375)', '\" Football\"[21424] (p=0.090, logit=20.125)', '\" The\"[578] (p=0.016, logit=18.375)', '\" (\"[320] (p=0.007, logit=17.500)', '\" violin\"[63137] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.859375, logit=22.375, token_id=30555, metadata=None))), (21424, (2, PredictedToken(token=' Football', prob=0.09033203125, logit=20.125, token_id=21424, metadata=None))), (13394, (29, PredictedToken(token=' Bed', prob=0.0002880096435546875, logit=14.375, token_id=13394, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:40 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.703, logit=21.500)', '\" The\"[578] (p=0.122, logit=19.750)', '\" Among\"[22395] (p=0.065, logit=19.125)', '\" A\"[362] (p=0.051, logit=18.875)', '\" B\"[426] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     clean_prediction=['\" Rabbit\"[49431] (p=0.680, logit=20.750)', '\" The\"[578] (p=0.092, logit=18.750)', '\" Among\"[22395] (p=0.072, logit=18.500)', '\" A\"[362] (p=0.043, logit=18.000)', '\" rabbit\"[39824] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     clean_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.6796875, logit=20.75, token_id=49431, metadata=None))), (84409, (26, PredictedToken(token=' Plum', prob=0.00122833251953125, logit=14.4375, token_id=84409, metadata=None))), (48471, (61, PredictedToken(token=' Shower', prob=0.00013828277587890625, logit=12.25, token_id=48471, metadata=None))), (52882, (107, PredictedToken(token=' Pepper', prob=4.482269287109375e-05, logit=11.125, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.820, logit=21.375)', '\" Plum\"[84409] (p=0.046, logit=18.500)', '\" Among\"[22395] (p=0.036, logit=18.250)', '\" The\"[578] (p=0.028, logit=18.000)', '\" pepper\"[25349] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.8203125, logit=21.375, token_id=52882, metadata=None))), (84409, (2, PredictedToken(token=' Plum', prob=0.04638671875, logit=18.5, token_id=84409, metadata=None))), (48471, (9, PredictedToken(token=' Shower', prob=0.002960205078125, logit=15.75, token_id=48471, metadata=None))), (49431, (59, PredictedToken(token=' Rabbit', prob=0.00011491775512695312, logit=12.5, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:41 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:41 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     patch_prediction=['\" Rice\"[30616] (p=0.742, logit=21.625)', '\" The\"[578] (p=0.088, logit=19.500)', '\" A\"[362] (p=0.069, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" C\"[356] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:54:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.852, logit=20.875)', '\" The\"[578] (p=0.033, logit=17.625)', '\" Among\"[22395] (p=0.020, logit=17.125)', '\" A\"[362] (p=0.016, logit=16.875)', '\" sink\"[19868] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.8515625, logit=20.875, token_id=57551, metadata=None))), (33711, (12, PredictedToken(token=' Suit', prob=0.002716064453125, logit=15.125, token_id=33711, metadata=None))), (40090, (34, PredictedToken(token=' Pressure', prob=0.000415802001953125, logit=13.25, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.875, logit=21.000)', '\" None\"[2290] (p=0.026, logit=17.500)', '\" The\"[578] (p=0.021, logit=17.250)', '\" Among\"[22395] (p=0.014, logit=16.875)', '\" A\"[362] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.875, logit=21.0, token_id=40090, metadata=None))), (57551, (7, PredictedToken(token=' Sink', prob=0.005889892578125, logit=16.0, token_id=57551, metadata=None))), (33711, (13, PredictedToken(token=' Suit', prob=0.001312255859375, logit=14.5, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:42 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.551, logit=20.625)', '\" The\"[578] (p=0.202, logit=19.625)', '\" A\"[362] (p=0.108, logit=19.000)', '\" Among\"[22395] (p=0.058, logit=18.375)', '\" It\"[1102] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.805, logit=22.875)', '\" The\"[578] (p=0.109, logit=20.875)', '\" Among\"[22395] (p=0.045, logit=20.000)', '\" A\"[362] (p=0.021, logit=19.250)', '\" \"[220] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.8046875, logit=22.875, token_id=1901, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0025634765625, logit=17.125, token_id=356, metadata=None))), (30616, (185, PredictedToken(token=' Rice', prob=2.637505531311035e-06, logit=10.25, token_id=30616, metadata=None))), (67553, (1416, PredictedToken(token=' Pants', prob=8.242204785346985e-08, logit=6.78125, token_id=67553, metadata=None))), (28131, (3084, PredictedToken(token=' Golf', prob=2.3632310330867767e-08, logit=5.53125, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.742, logit=22.750)', '\" The\"[578] (p=0.146, logit=21.125)', '\" A\"[362] (p=0.061, logit=20.250)', '\" Among\"[22395] (p=0.025, logit=19.375)', '\" Z\"[1901] (p=0.006, logit=17.875)']\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.7421875, logit=22.75, token_id=356, metadata=None))), (1901, (5, PredictedToken(token=' Z', prob=0.00567626953125, logit=17.875, token_id=1901, metadata=None))), (28131, (11, PredictedToken(token=' Golf', prob=0.0008697509765625, logit=16.0, token_id=28131, metadata=None))), (30616, (57, PredictedToken(token=' Rice', prob=3.814697265625e-05, logit=12.875, token_id=30616, metadata=None))), (67553, (152, PredictedToken(token=' Pants', prob=4.559755325317383e-06, logit=10.75, token_id=67553, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:42 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:54:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.660, logit=21.250)', '\" An\"[1556] (p=0.115, logit=19.500)', '\" The\"[578] (p=0.102, logit=19.375)', '\" Among\"[22395] (p=0.070, logit=19.000)', '\" A\"[362] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.789, logit=21.500)', '\" The\"[578] (p=0.073, logit=19.125)', '\" A\"[362] (p=0.065, logit=19.000)', '\" Among\"[22395] (p=0.024, logit=18.000)', '\" BAT\"[79081] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.7890625, logit=21.5, token_id=16488, metadata=None))), (22410, (13, PredictedToken(token=' Ju', prob=0.0011138916015625, logit=14.9375, token_id=22410, metadata=None))), (356, (17, PredictedToken(token=' C', prob=0.000865936279296875, logit=14.6875, token_id=356, metadata=None))), (74574, (370, PredictedToken(token=' Violet', prob=2.294778823852539e-06, logit=8.75, token_id=74574, metadata=None))), (47759, (378, PredictedToken(token=' Guitar', prob=2.1457672119140625e-06, logit=8.6875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     int_prediction=['\" Ju\"[22410] (p=0.664, logit=20.875)', '\" A\"[362] (p=0.168, logit=19.500)', '\" The\"[578] (p=0.079, logit=18.750)', '\" Among\"[22395] (p=0.018, logit=17.250)', '\" It\"[1102] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     int_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.6640625, logit=20.875, token_id=22410, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.00738525390625, logit=16.375, token_id=356, metadata=None))), (16488, (140, PredictedToken(token=' Bat', prob=2.3484230041503906e-05, logit=10.625, token_id=16488, metadata=None))), (47759, (1774, PredictedToken(token=' Guitar', prob=5.178153514862061e-07, logit=6.8125, token_id=47759, metadata=None))), (74574, (2705, PredictedToken(token=' Violet', prob=2.9616057872772217e-07, logit=6.25, token_id=74574, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:43 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:43 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.641, logit=21.250)', '\" The\"[578] (p=0.184, logit=20.000)', '\" Among\"[22395] (p=0.086, logit=19.250)', '\" A\"[362] (p=0.046, logit=18.625)', '\" strawberry\"[73700] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:54:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     clean_prediction=['\" Bed\"[13394] (p=0.867, logit=22.625)', '\" The\"[578] (p=0.049, logit=19.750)', '\" Among\"[22395] (p=0.026, logit=19.125)', '\" A\"[362] (p=0.026, logit=19.125)', '\" BED\"[83364] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     clean_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.8671875, logit=22.625, token_id=13394, metadata=None))), (58403, (18, PredictedToken(token=' Tablet', prob=0.000743865966796875, logit=15.5625, token_id=58403, metadata=None))), (14588, (34, PredictedToken(token=' Dog', prob=0.0001659393310546875, logit=14.0625, token_id=14588, metadata=None))), (52466, (43, PredictedToken(token=' Warehouse', prob=9.441375732421875e-05, logit=13.5, token_id=52466, metadata=None))), (1901, (263, PredictedToken(token=' Z', prob=2.2202730178833008e-06, logit=9.75, token_id=1901, metadata=None))), (76924, (663, PredictedToken(token=' Banana', prob=4.954636096954346e-07, logit=8.25, token_id=76924, metadata=None)))])\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     int_prediction=['\" Banana\"[76924] (p=0.750, logit=21.000)', '\" Z\"[1901] (p=0.070, logit=18.625)', '\" The\"[578] (p=0.062, logit=18.500)', '\" Among\"[22395] (p=0.026, logit=17.625)', '\" A\"[362] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     int_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.75, logit=21.0, token_id=76924, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.06982421875, logit=18.625, token_id=1901, metadata=None))), (14588, (41, PredictedToken(token=' Dog', prob=0.00038909912109375, logit=13.4375, token_id=14588, metadata=None))), (58403, (58, PredictedToken(token=' Tablet', prob=0.0002079010009765625, logit=12.8125, token_id=58403, metadata=None))), (13394, (263, PredictedToken(token=' Bed', prob=8.58306884765625e-06, logit=9.625, token_id=13394, metadata=None))), (52466, (2860, PredictedToken(token=' Warehouse', prob=2.849847078323364e-07, logit=6.21875, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:44 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.373, logit=19.500)', '\" Calculator\"[37128] (p=0.176, logit=18.750)', '\" Among\"[22395] (p=0.155, logit=18.625)', '\" The\"[578] (p=0.083, logit=18.000)', '\" To\"[2057] (p=0.035, logit=17.125)']\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.887, logit=22.125)', '\" The\"[578] (p=0.044, logit=19.125)', '\" Among\"[22395] (p=0.030, logit=18.750)', '\" A\"[362] (p=0.014, logit=18.000)', '\" PE\"[22557] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.88671875, logit=22.125, token_id=64695, metadata=None))), (13394, (14, PredictedToken(token=' Bed', prob=0.000629425048828125, logit=14.875, token_id=13394, metadata=None))), (5907, (113, PredictedToken(token=' Project', prob=1.150369644165039e-05, logit=10.875, token_id=5907, metadata=None))), (24941, (146, PredictedToken(token=' Bear', prob=7.450580596923828e-06, logit=10.4375, token_id=24941, metadata=None))), (22249, (295, PredictedToken(token=' Ring', prob=2.130866050720215e-06, logit=9.1875, token_id=22249, metadata=None))), (68867, (954, PredictedToken(token=' Coat', prob=4.079192876815796e-07, logit=7.53125, token_id=68867, metadata=None)))])\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     int_prediction=['\" Project\"[5907] (p=0.852, logit=22.500)', '\" A\"[362] (p=0.054, logit=19.750)', '\" The\"[578] (p=0.048, logit=19.625)', '\" Among\"[22395] (p=0.020, logit=18.750)', '\" Peach\"[64695] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     int_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.8515625, logit=22.5, token_id=5907, metadata=None))), (64695, (5, PredictedToken(token=' Peach', prob=0.002716064453125, logit=16.75, token_id=64695, metadata=None))), (22249, (11, PredictedToken(token=' Ring', prob=0.00099945068359375, logit=15.75, token_id=22249, metadata=None))), (24941, (29, PredictedToken(token=' Bear', prob=0.00023651123046875, logit=14.3125, token_id=24941, metadata=None))), (68867, (129, PredictedToken(token=' Coat', prob=1.043081283569336e-05, logit=11.1875, token_id=68867, metadata=None))), (13394, (189, PredictedToken(token=' Bed', prob=4.6193599700927734e-06, logit=10.375, token_id=13394, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:44 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:54:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     patch_prediction=['\" To\"[2057] (p=0.703, logit=21.875)', '\" The\"[578] (p=0.123, logit=20.125)', '\" A\"[362] (p=0.095, logit=19.875)', '\" Among\"[22395] (p=0.040, logit=19.000)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     clean_prediction=['\" Gloves\"[68554] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.077, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" Glo\"[25372] (p=0.008, logit=17.125)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     clean_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.83203125, logit=21.75, token_id=68554, metadata=None))), (16183, (13, PredictedToken(token=' Hel', prob=0.00141143798828125, logit=15.375, token_id=16183, metadata=None))), (29318, (39, PredictedToken(token=' Dress', prob=0.00019168853759765625, logit=13.375, token_id=29318, metadata=None))), (16344, (47, PredictedToken(token=' Rose', prob=0.00014019012451171875, logit=13.0625, token_id=16344, metadata=None))), (87213, (238, PredictedToken(token=' Oven', prob=4.500150680541992e-06, logit=9.625, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.793, logit=21.250)', '\" The\"[578] (p=0.058, logit=18.625)', '\" An\"[1556] (p=0.035, logit=18.125)', '\" Among\"[22395] (p=0.027, logit=17.875)', '\" Dress\"[29318] (p=0.019, logit=17.500)']\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.79296875, logit=21.25, token_id=87213, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.0186767578125, logit=17.5, token_id=29318, metadata=None))), (16183, (15, PredictedToken(token=' Hel', prob=0.0018463134765625, logit=15.1875, token_id=16183, metadata=None))), (68554, (28, PredictedToken(token=' Gloves', prob=0.000637054443359375, logit=14.125, token_id=68554, metadata=None))), (16344, (37, PredictedToken(token=' Rose', prob=0.0004119873046875, logit=13.6875, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:45 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.648, logit=21.500)', '\" The\"[578] (p=0.127, logit=19.875)', '\" A\"[362] (p=0.112, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" Building\"[17283] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     clean_prediction=['\" Orange\"[22725] (p=0.906, logit=22.250)', '\" The\"[578] (p=0.027, logit=18.750)', '\" Among\"[22395] (p=0.008, logit=17.500)', '\" Option\"[7104] (p=0.008, logit=17.500)', '\" An\"[1556] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     clean_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.90625, logit=22.25, token_id=22725, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.006927490234375, logit=17.375, token_id=356, metadata=None))), (34392, (52, PredictedToken(token=' Horse', prob=8.153915405273438e-05, logit=12.9375, token_id=34392, metadata=None))), (52466, (117, PredictedToken(token=' Warehouse', prob=1.5139579772949219e-05, logit=11.25, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     int_prediction=['\" Warehouse\"[52466] (p=0.855, logit=21.875)', '\" The\"[578] (p=0.026, logit=18.375)', '\" A\"[362] (p=0.020, logit=18.125)', '\" Orange\"[22725] (p=0.018, logit=18.000)', '\" None\"[2290] (p=0.018, logit=18.000)']\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     int_track=OrderedDict([(52466, (1, PredictedToken(token=' Warehouse', prob=0.85546875, logit=21.875, token_id=52466, metadata=None))), (22725, (5, PredictedToken(token=' Orange', prob=0.017822265625, logit=18.0, token_id=22725, metadata=None))), (34392, (6, PredictedToken(token=' Horse', prob=0.00836181640625, logit=17.25, token_id=34392, metadata=None))), (356, (9, PredictedToken(token=' C', prob=0.00653076171875, logit=17.0, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:46 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:46 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     patch_prediction=['\" Library\"[11896] (p=0.812, logit=22.125)', '\" The\"[578] (p=0.067, logit=19.625)', '\" A\"[362] (p=0.052, logit=19.375)', '\" Among\"[22395] (p=0.015, logit=18.125)', '\" None\"[2290] (p=0.012, logit=17.875)']\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.637, logit=20.125)', '\" C\"[356] (p=0.125, logit=18.500)', '\" Temple\"[19176] (p=0.059, logit=17.750)', '\" Drum\"[46506] (p=0.052, logit=17.625)', '\" The\"[578] (p=0.032, logit=17.125)']\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.63671875, logit=20.125, token_id=79028, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.125, logit=18.5, token_id=356, metadata=None))), (19176, (3, PredictedToken(token=' Temple', prob=0.059326171875, logit=17.75, token_id=19176, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.05224609375, logit=17.625, token_id=46506, metadata=None)))])\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.742, logit=20.750)', '\" C\"[356] (p=0.101, logit=18.750)', '\" Hick\"[79028] (p=0.033, logit=17.625)', '\" The\"[578] (p=0.029, logit=17.500)', '\" Drum\"[46506] (p=0.025, logit=17.375)']\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.7421875, logit=20.75, token_id=19176, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.1005859375, logit=18.75, token_id=356, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.03271484375, logit=17.625, token_id=79028, metadata=None))), (46506, (5, PredictedToken(token=' Drum', prob=0.025390625, logit=17.375, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:46 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:54:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.621, logit=22.250)', '\" An\"[1556] (p=0.178, logit=21.000)', '\" The\"[578] (p=0.122, logit=20.625)', '\" Among\"[22395] (p=0.040, logit=19.500)', '\" e\"[384] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     clean_prediction=['\" Y\"[816] (p=0.656, logit=21.750)', '\" A\"[362] (p=0.146, logit=20.250)', '\" The\"[578] (p=0.101, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=18.875)', '\" None\"[2290] (p=0.017, logit=18.125)']\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     clean_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.65625, logit=21.75, token_id=816, metadata=None))), (57094, (50, PredictedToken(token=' Highlight', prob=0.000110626220703125, logit=13.0625, token_id=57094, metadata=None))), (41785, (203, PredictedToken(token=' Spin', prob=5.841255187988281e-06, logit=10.125, token_id=41785, metadata=None))), (86460, (272, PredictedToken(token=' Necklace', prob=3.129243850708008e-06, logit=9.5, token_id=86460, metadata=None))), (47759, (342, PredictedToken(token=' Guitar', prob=1.8998980522155762e-06, logit=9.0, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.766, logit=22.250)', '\" A\"[362] (p=0.133, logit=20.500)', '\" The\"[578] (p=0.038, logit=19.250)', '\" Highlight\"[57094] (p=0.026, logit=18.875)', '\" None\"[2290] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.765625, logit=22.25, token_id=86460, metadata=None))), (57094, (4, PredictedToken(token=' Highlight', prob=0.026123046875, logit=18.875, token_id=57094, metadata=None))), (816, (42, PredictedToken(token=' Y', prob=0.0001068115234375, logit=13.375, token_id=816, metadata=None))), (41785, (279, PredictedToken(token=' Spin', prob=2.518296241760254e-06, logit=9.625, token_id=41785, metadata=None))), (47759, (702, PredictedToken(token=' Guitar', prob=5.960464477539062e-07, logit=8.1875, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:47 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:54:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.895, logit=21.375)', '\" The\"[578] (p=0.051, logit=18.500)', '\" A\"[362] (p=0.009, logit=16.750)', '\" SK\"[12343] (p=0.005, logit=16.125)', '\" Hick\"[79028] (p=0.003, logit=15.750)']\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     clean_prediction=['\" Dolphin\"[96096] (p=0.836, logit=21.500)', '\" The\"[578] (p=0.068, logit=19.000)', '\" A\"[362] (p=0.029, logit=18.125)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" D\"[423] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     clean_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.8359375, logit=21.5, token_id=96096, metadata=None))), (22050, (20, PredictedToken(token=' Hat', prob=0.00067138671875, logit=14.375, token_id=22050, metadata=None))), (41493, (83, PredictedToken(token=' Tow', prob=3.337860107421875e-05, logit=11.375, token_id=41493, metadata=None))), (24423, (242, PredictedToken(token=' Monitor', prob=4.5299530029296875e-06, logit=9.375, token_id=24423, metadata=None))), (36943, (828, PredictedToken(token=' Folder', prob=6.92903995513916e-07, logit=7.5, token_id=36943, metadata=None)))])\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.582, logit=20.875)', '\" Folder\"[36943] (p=0.147, logit=19.500)', '\" The\"[578] (p=0.101, logit=19.125)', '\" A\"[362] (p=0.054, logit=18.500)', '\" Dolphin\"[96096] (p=0.037, logit=18.125)']\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.58203125, logit=20.875, token_id=41493, metadata=None))), (36943, (2, PredictedToken(token=' Folder', prob=0.1474609375, logit=19.5, token_id=36943, metadata=None))), (96096, (5, PredictedToken(token=' Dolphin', prob=0.037353515625, logit=18.125, token_id=96096, metadata=None))), (24423, (8, PredictedToken(token=' Monitor', prob=0.00445556640625, logit=16.0, token_id=24423, metadata=None))), (22050, (30, PredictedToken(token=' Hat', prob=0.00060272216796875, logit=14.0, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:48 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.820, logit=21.500)', '\" The\"[578] (p=0.052, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.500)', '\" A\"[362] (p=0.041, logit=18.500)', '\" (\"[320] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.691, logit=20.750)', '\" The\"[578] (p=0.120, logit=19.000)', '\" Among\"[22395] (p=0.083, logit=18.625)', '\" A\"[362] (p=0.024, logit=17.375)', '\" B\"[426] (p=0.013, logit=16.750)']\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.69140625, logit=20.75, token_id=88088, metadata=None))), (81501, (13, PredictedToken(token=' Pendant', prob=0.00142669677734375, logit=14.5625, token_id=81501, metadata=None))), (41493, (40, PredictedToken(token=' Tow', prob=0.0003376007080078125, logit=13.125, token_id=41493, metadata=None))), (22410, (167, PredictedToken(token=' Ju', prob=1.5854835510253906e-05, logit=10.0625, token_id=22410, metadata=None))), (27217, (925, PredictedToken(token=' Train', prob=1.296401023864746e-06, logit=7.5625, token_id=27217, metadata=None)))])\n",
      "2025-09-16 09:54:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.887, logit=21.625)', '\" The\"[578] (p=0.044, logit=18.625)', '\" A\"[362] (p=0.030, logit=18.250)', '\" Ju\"[22410] (p=0.005, logit=16.500)', '\" Among\"[22395] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.88671875, logit=21.625, token_id=41493, metadata=None))), (22410, (5, PredictedToken(token=' Ju', prob=0.005279541015625, logit=16.5, token_id=22410, metadata=None))), (88088, (7, PredictedToken(token=' Birch', prob=0.002655029296875, logit=15.8125, token_id=88088, metadata=None))), (81501, (8, PredictedToken(token=' Pendant', prob=0.0020599365234375, logit=15.5625, token_id=81501, metadata=None))), (27217, (17, PredictedToken(token=' Train', prob=0.000461578369140625, logit=14.0625, token_id=27217, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:49 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:49 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     patch_prediction=['\" Har\"[5340] (p=0.750, logit=22.000)', '\" The\"[578] (p=0.115, logit=20.125)', '\" A\"[362] (p=0.070, logit=19.625)', '\" Among\"[22395] (p=0.018, logit=18.250)', '\" It\"[1102] (p=0.009, logit=17.625)']\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     clean_prediction=['\" Soap\"[61731] (p=0.875, logit=21.625)', '\" Among\"[22395] (p=0.038, logit=18.500)', '\" The\"[578] (p=0.038, logit=18.500)', '\" A\"[362] (p=0.006, logit=16.625)', '\" SOAP\"[64332] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     clean_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.875, logit=21.625, token_id=61731, metadata=None))), (30555, (51, PredictedToken(token=' Viol', prob=8.96453857421875e-05, logit=12.4375, token_id=30555, metadata=None))), (21424, (185, PredictedToken(token=' Football', prob=7.808208465576172e-06, logit=10.0, token_id=21424, metadata=None))), (75258, (202, PredictedToken(token=' Refriger', prob=6.079673767089844e-06, logit=9.75, token_id=75258, metadata=None)))])\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.867, logit=21.500)', '\" The\"[578] (p=0.034, logit=18.250)', '\" Among\"[22395] (p=0.026, logit=18.000)', '\" Soap\"[61731] (p=0.014, logit=17.375)', '\" A\"[362] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.8671875, logit=21.5, token_id=30555, metadata=None))), (61731, (4, PredictedToken(token=' Soap', prob=0.0140380859375, logit=17.375, token_id=61731, metadata=None))), (21424, (49, PredictedToken(token=' Football', prob=0.0001373291015625, logit=12.75, token_id=21424, metadata=None))), (75258, (1217, PredictedToken(token=' Refriger', prob=5.140900611877441e-07, logit=7.15625, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:49 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:49 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:54:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.891, logit=21.875)', '\" The\"[578] (p=0.039, logit=18.750)', '\" None\"[2290] (p=0.027, logit=18.375)', '\" A\"[362] (p=0.007, logit=17.000)', '\" Tow\"[41493] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.777, logit=21.125)', '\" The\"[578] (p=0.082, logit=18.875)', '\" A\"[362] (p=0.064, logit=18.625)', '\" Note\"[7181] (p=0.011, logit=16.875)', '\" Among\"[22395] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.77734375, logit=21.125, token_id=69755, metadata=None))), (8868, (36, PredictedToken(token=' Blue', prob=0.0003566741943359375, logit=13.4375, token_id=8868, metadata=None))), (1901, (55, PredictedToken(token=' Z', prob=0.0001316070556640625, logit=12.4375, token_id=1901, metadata=None)))])\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.812, logit=21.375)', '\" Z\"[1901] (p=0.076, logit=19.000)', '\" The\"[578] (p=0.046, logit=18.500)', '\" Among\"[22395] (p=0.010, logit=17.000)', '\" A\"[362] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.8125, logit=21.375, token_id=8868, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.07568359375, logit=19.0, token_id=1901, metadata=None))), (69755, (19, PredictedToken(token=' Notebook', prob=0.00107574462890625, logit=14.75, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:50 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:50 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.746, logit=21.875)', '\" The\"[578] (p=0.089, logit=19.750)', '\" A\"[362] (p=0.069, logit=19.500)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" \"[220] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     clean_prediction=['\" Guitar\"[47759] (p=0.594, logit=21.250)', '\" The\"[578] (p=0.218, logit=20.250)', '\" A\"[362] (p=0.080, logit=19.250)', '\" Among\"[22395] (p=0.043, logit=18.625)', '\" It\"[1102] (p=0.016, logit=17.625)']\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     clean_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.59375, logit=21.25, token_id=47759, metadata=None))), (94091, (86, PredictedToken(token=' Tomato', prob=3.910064697265625e-05, logit=11.625, token_id=94091, metadata=None))), (47589, (172, PredictedToken(token=' Basketball', prob=8.702278137207031e-06, logit=10.125, token_id=47589, metadata=None))), (84008, (402, PredictedToken(token=' Sheep', prob=1.952052116394043e-06, logit=8.625, token_id=84008, metadata=None)))])\n",
      "2025-09-16 09:54:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     int_prediction=['\" Sheep\"[84008] (p=0.660, logit=20.500)', '\" The\"[578] (p=0.189, logit=19.250)', '\" Among\"[22395] (p=0.029, logit=17.375)', '\" A\"[362] (p=0.029, logit=17.375)', '\" It\"[1102] (p=0.011, logit=16.375)']\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     int_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.66015625, logit=20.5, token_id=84008, metadata=None))), (94091, (6, PredictedToken(token=' Tomato', prob=0.01068115234375, logit=16.375, token_id=94091, metadata=None))), (47759, (12, PredictedToken(token=' Guitar', prob=0.003692626953125, logit=15.3125, token_id=47759, metadata=None))), (47589, (63, PredictedToken(token=' Basketball', prob=0.0001430511474609375, logit=12.0625, token_id=47589, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:51 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.443, logit=19.750)', '\" To\"[2057] (p=0.270, logit=19.250)', '\" Among\"[22395] (p=0.087, logit=18.125)', '\" The\"[578] (p=0.068, logit=17.875)', '\" A\"[362] (p=0.032, logit=17.125)']\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.832, logit=21.500)', '\" The\"[578] (p=0.053, logit=18.750)', '\" An\"[1556] (p=0.042, logit=18.500)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" IR\"[16646] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.83203125, logit=21.5, token_id=66821, metadata=None))), (13000, (39, PredictedToken(token=' Van', prob=0.00014972686767578125, logit=12.875, token_id=13000, metadata=None))), (14588, (128, PredictedToken(token=' Dog', prob=1.4841556549072266e-05, logit=10.5625, token_id=14588, metadata=None))), (36943, (134, PredictedToken(token=' Folder', prob=1.3947486877441406e-05, logit=10.5, token_id=36943, metadata=None))), (26698, (536, PredictedToken(token=' Keyboard', prob=1.296401023864746e-06, logit=8.125, token_id=26698, metadata=None))), (29318, (799, PredictedToken(token=' Dress', prob=7.599592208862305e-07, logit=7.59375, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.789, logit=21.000)', '\" The\"[578] (p=0.094, logit=18.875)', '\" A\"[362] (p=0.035, logit=17.875)', '\" Among\"[22395] (p=0.014, logit=17.000)', '\" Key\"[5422] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.7890625, logit=21.0, token_id=26698, metadata=None))), (36943, (13, PredictedToken(token=' Folder', prob=0.00183868408203125, logit=14.9375, token_id=36943, metadata=None))), (29318, (75, PredictedToken(token=' Dress', prob=8.58306884765625e-05, logit=11.875, token_id=29318, metadata=None))), (66821, (164, PredictedToken(token=' Iris', prob=1.6927719116210938e-05, logit=10.25, token_id=66821, metadata=None))), (13000, (424, PredictedToken(token=' Van', prob=3.337860107421875e-06, logit=8.625, token_id=13000, metadata=None))), (14588, (684, PredictedToken(token=' Dog', prob=1.7285346984863281e-06, logit=7.96875, token_id=14588, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:51 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:54:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     patch_prediction=['\" Desk\"[39794] (p=0.820, logit=21.875)', '\" The\"[578] (p=0.067, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.625)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.777, logit=20.625)', '\" The\"[578] (p=0.063, logit=18.125)', '\" A\"[362] (p=0.056, logit=18.000)', '\" Among\"[22395] (p=0.039, logit=17.625)', '\" Note\"[7181] (p=0.008, logit=16.000)']\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.77734375, logit=20.625, token_id=69755, metadata=None))), (30760, (36, PredictedToken(token=' Scar', prob=0.000354766845703125, logit=12.9375, token_id=30760, metadata=None))), (48390, (37, PredictedToken(token=' Lily', prob=0.000354766845703125, logit=12.9375, token_id=48390, metadata=None))), (36845, (118, PredictedToken(token=' Tiger', prob=3.981590270996094e-05, logit=10.75, token_id=36845, metadata=None))), (16488, (134, PredictedToken(token=' Bat', prob=3.0994415283203125e-05, logit=10.5, token_id=16488, metadata=None))), (36358, (306, PredictedToken(token=' Bench', prob=7.3909759521484375e-06, logit=9.0625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.711, logit=20.500)', '\" Among\"[22395] (p=0.075, logit=18.250)', '\" The\"[578] (p=0.075, logit=18.250)', '\" A\"[362] (p=0.035, logit=17.500)', '\" Bat\"[16488] (p=0.028, logit=17.250)']\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.7109375, logit=20.5, token_id=36358, metadata=None))), (16488, (5, PredictedToken(token=' Bat', prob=0.027587890625, logit=17.25, token_id=16488, metadata=None))), (30760, (6, PredictedToken(token=' Scar', prob=0.0074462890625, logit=15.9375, token_id=30760, metadata=None))), (69755, (26, PredictedToken(token=' Notebook', prob=0.000782012939453125, logit=13.6875, token_id=69755, metadata=None))), (48390, (36, PredictedToken(token=' Lily', prob=0.00057220458984375, logit=13.375, token_id=48390, metadata=None))), (36845, (41, PredictedToken(token=' Tiger', prob=0.0004749298095703125, logit=13.1875, token_id=36845, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:52 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:52 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.809, logit=21.250)', '\" The\"[578] (p=0.066, logit=18.750)', '\" A\"[362] (p=0.045, logit=18.375)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" It\"[1102] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:54:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     clean_prediction=['\" Micro\"[18654] (p=0.789, logit=21.375)', '\" The\"[578] (p=0.065, logit=18.875)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.031, logit=18.125)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     clean_track=OrderedDict([(18654, (1, PredictedToken(token=' Micro', prob=0.7890625, logit=21.375, token_id=18654, metadata=None))), (423, (16, PredictedToken(token=' D', prob=0.00104522705078125, logit=14.75, token_id=423, metadata=None))), (83499, (45, PredictedToken(token=' Tooth', prob=0.00016021728515625, logit=12.875, token_id=83499, metadata=None))), (74574, (103, PredictedToken(token=' Violet', prob=3.147125244140625e-05, logit=11.25, token_id=74574, metadata=None))), (22725, (147, PredictedToken(token=' Orange', prob=1.800060272216797e-05, logit=10.6875, token_id=22725, metadata=None))), (91782, (1101, PredictedToken(token=' Shorts', prob=4.954636096954346e-07, logit=7.09375, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.867, logit=21.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" None\"[2290] (p=0.030, logit=18.250)', '\" A\"[362] (p=0.012, logit=17.375)', '\" Among\"[22395] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.8671875, logit=21.625, token_id=423, metadata=None))), (91782, (8, PredictedToken(token=' Shorts', prob=0.0035552978515625, logit=16.125, token_id=91782, metadata=None))), (83499, (27, PredictedToken(token=' Tooth', prob=0.0003986358642578125, logit=13.9375, token_id=83499, metadata=None))), (18654, (80, PredictedToken(token=' Micro', prob=3.933906555175781e-05, logit=11.625, token_id=18654, metadata=None))), (22725, (216, PredictedToken(token=' Orange', prob=5.692243576049805e-06, logit=9.6875, token_id=22725, metadata=None))), (74574, (556, PredictedToken(token=' Violet', prob=1.0207295417785645e-06, logit=7.96875, token_id=74574, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:53 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     patch_prediction=['\" Pendant\"[81501] (p=0.934, logit=22.875)', '\" The\"[578] (p=0.019, logit=19.000)', '\" A\"[362] (p=0.019, logit=19.000)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" It\"[1102] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     clean_prediction=['\" Ki\"[30558] (p=0.871, logit=22.250)', '\" The\"[578] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.023, logit=18.625)', '\" A\"[362] (p=0.018, logit=18.375)', '\" ki\"[20548] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     clean_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.87109375, logit=22.25, token_id=30558, metadata=None))), (72392, (21, PredictedToken(token=' Mixer', prob=0.000274658203125, logit=14.1875, token_id=72392, metadata=None))), (10573, (180, PredictedToken(token=' Watch', prob=4.172325134277344e-06, logit=10.0, token_id=10573, metadata=None))), (30555, (205, PredictedToken(token=' Viol', prob=3.248453140258789e-06, logit=9.75, token_id=30555, metadata=None))), (82994, (347, PredictedToken(token=' Toilet', prob=1.2740492820739746e-06, logit=8.8125, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     int_prediction=['\" Ki\"[30558] (p=0.859, logit=22.000)', '\" The\"[578] (p=0.055, logit=19.250)', '\" Mixer\"[72392] (p=0.026, logit=18.500)', '\" Among\"[22395] (p=0.023, logit=18.375)', '\" Watch\"[10573] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     int_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.859375, logit=22.0, token_id=30558, metadata=None))), (72392, (3, PredictedToken(token=' Mixer', prob=0.02587890625, logit=18.5, token_id=72392, metadata=None))), (10573, (5, PredictedToken(token=' Watch', prob=0.0084228515625, logit=17.375, token_id=10573, metadata=None))), (30555, (18, PredictedToken(token=' Viol', prob=0.0005035400390625, logit=14.5625, token_id=30555, metadata=None))), (82994, (58, PredictedToken(token=' Toilet', prob=3.647804260253906e-05, logit=11.9375, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:53 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:53 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.750, logit=22.125)', '\" The\"[578] (p=0.115, logit=20.250)', '\" Among\"[22395] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.048, logit=19.375)', '\" Pearl\"[37343] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     clean_prediction=['\" Scar\"[30760] (p=0.391, logit=20.375)', '\" The\"[578] (p=0.209, logit=19.750)', '\" A\"[362] (p=0.185, logit=19.625)', '\" Among\"[22395] (p=0.144, logit=19.375)', '\" Out\"[4470] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     clean_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.390625, logit=20.375, token_id=30760, metadata=None))), (63606, (35, PredictedToken(token=' Stap', prob=0.0003337860107421875, logit=13.3125, token_id=63606, metadata=None))), (91963, (57, PredictedToken(token=' Mango', prob=0.00013065338134765625, logit=12.375, token_id=91963, metadata=None))), (58251, (196, PredictedToken(token=' Tennis', prob=1.0728836059570312e-05, logit=9.875, token_id=58251, metadata=None))), (12369, (301, PredictedToken(token=' Food', prob=5.066394805908203e-06, logit=9.125, token_id=12369, metadata=None))), (14669, (1123, PredictedToken(token=' Camera', prob=6.854534149169922e-07, logit=7.125, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     int_prediction=['\" Mango\"[91963] (p=0.855, logit=21.875)', '\" The\"[578] (p=0.043, logit=18.875)', '\" A\"[362] (p=0.033, logit=18.625)', '\" Among\"[22395] (p=0.029, logit=18.500)', '\" Food\"[12369] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     int_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.85546875, logit=21.875, token_id=91963, metadata=None))), (12369, (5, PredictedToken(token=' Food', prob=0.00396728515625, logit=16.5, token_id=12369, metadata=None))), (58251, (69, PredictedToken(token=' Tennis', prob=4.410743713378906e-05, logit=12.0, token_id=58251, metadata=None))), (63606, (700, PredictedToken(token=' Stap', prob=7.562339305877686e-07, logit=7.9375, token_id=63606, metadata=None))), (14669, (2310, PredictedToken(token=' Camera', prob=1.5925616025924683e-07, logit=6.375, token_id=14669, metadata=None))), (30760, (3077, PredictedToken(token=' Scar', prob=1.0570511221885681e-07, logit=5.96875, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:54 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:54 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.785, logit=21.375)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" The\"[578] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.039, logit=18.375)', '\" z\"[1167] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:54:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.789, logit=21.250)', '\" The\"[578] (p=0.074, logit=18.875)', '\" Among\"[22395] (p=0.057, logit=18.625)', '\" An\"[1556] (p=0.019, logit=17.500)', '\" It\"[1102] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.7890625, logit=21.25, token_id=66821, metadata=None))), (14588, (100, PredictedToken(token=' Dog', prob=2.7894973754882812e-05, logit=11.0, token_id=14588, metadata=None))), (26781, (317, PredictedToken(token=' Hair', prob=3.7848949432373047e-06, logit=9.0, token_id=26781, metadata=None))), (38673, (430, PredictedToken(token=' Yoga', prob=2.294778823852539e-06, logit=8.5, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.637, logit=20.875)', '\" The\"[578] (p=0.142, logit=19.375)', '\" Iris\"[66821] (p=0.067, logit=18.625)', '\" A\"[362] (p=0.052, logit=18.375)', '\" Among\"[22395] (p=0.028, logit=17.750)']\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.63671875, logit=20.875, token_id=14588, metadata=None))), (66821, (3, PredictedToken(token=' Iris', prob=0.06689453125, logit=18.625, token_id=66821, metadata=None))), (38673, (101, PredictedToken(token=' Yoga', prob=3.9577484130859375e-05, logit=11.1875, token_id=38673, metadata=None))), (26781, (244, PredictedToken(token=' Hair', prob=6.854534149169922e-06, logit=9.4375, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:55 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.766, logit=20.750)', '\" Ring\"[22249] (p=0.043, logit=17.875)', '\" The\"[578] (p=0.043, logit=17.875)', '\" An\"[1556] (p=0.043, logit=17.875)', '\" Among\"[22395] (p=0.026, logit=17.375)']\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.777, logit=22.125)', '\" The\"[578] (p=0.064, logit=19.625)', '\" A\"[362] (p=0.056, logit=19.500)', '\" b\"[293] (p=0.034, logit=19.000)', '\" Among\"[22395] (p=0.030, logit=18.875)']\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.77734375, logit=22.125, token_id=426, metadata=None))), (34046, (39, PredictedToken(token=' Cabinet', prob=0.0001316070556640625, logit=13.4375, token_id=34046, metadata=None))), (24941, (67, PredictedToken(token=' Bear', prob=4.8160552978515625e-05, logit=12.4375, token_id=24941, metadata=None))), (63606, (83, PredictedToken(token=' Stap', prob=2.753734588623047e-05, logit=11.875, token_id=63606, metadata=None)))])\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.738, logit=21.250)', '\" The\"[578] (p=0.078, logit=19.000)', '\" A\"[362] (p=0.069, logit=18.875)', '\" Among\"[22395] (p=0.037, logit=18.250)', '\" B\"[426] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.73828125, logit=21.25, token_id=63606, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.011962890625, logit=17.125, token_id=426, metadata=None))), (34046, (15, PredictedToken(token=' Cabinet', prob=0.000865936279296875, logit=14.5, token_id=34046, metadata=None))), (24941, (125, PredictedToken(token=' Bear', prob=1.800060272216797e-05, logit=10.625, token_id=24941, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:54:55 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:54:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.777, logit=21.750)', '\" The\"[578] (p=0.072, logit=19.375)', '\" A\"[362] (p=0.072, logit=19.375)', '\" Among\"[22395] (p=0.023, logit=18.250)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.840, logit=22.000)', '\" The\"[578] (p=0.061, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=19.125)', '\" A\"[362] (p=0.015, logit=18.000)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.83984375, logit=22.0, token_id=15883, metadata=None))), (4923, (14, PredictedToken(token=' Sk', prob=0.000762939453125, logit=15.0, token_id=4923, metadata=None))), (432, (16, PredictedToken(token=' R', prob=0.00063323974609375, logit=14.8125, token_id=432, metadata=None))), (56491, (329, PredictedToken(token=' Piano', prob=2.0116567611694336e-06, logit=9.0625, token_id=56491, metadata=None)))])\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.633, logit=21.125)', '\" Piano\"[56491] (p=0.160, logit=19.750)', '\" The\"[578] (p=0.067, logit=18.875)', '\" A\"[362] (p=0.059, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=17.875)']\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.6328125, logit=21.125, token_id=432, metadata=None))), (56491, (2, PredictedToken(token=' Piano', prob=0.16015625, logit=19.75, token_id=56491, metadata=None))), (15883, (7, PredictedToken(token=' Spr', prob=0.004852294921875, logit=16.25, token_id=15883, metadata=None))), (4923, (10, PredictedToken(token=' Sk', prob=0.002593994140625, logit=15.625, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:56 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:54:56 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     patch_prediction=['\" To\"[2057] (p=0.695, logit=22.500)', '\" The\"[578] (p=0.154, logit=21.000)', '\" A\"[362] (p=0.106, logit=20.625)', '\" Among\"[22395] (p=0.018, logit=18.875)', '\" It\"[1102] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:54:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.547, logit=22.000)', '\" The\"[578] (p=0.258, logit=21.250)', '\" A\"[362] (p=0.138, logit=20.625)', '\" Among\"[22395] (p=0.031, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.546875, logit=22.0, token_id=29318, metadata=None))), (97796, (92, PredictedToken(token=' Skate', prob=1.704692840576172e-05, logit=11.625, token_id=97796, metadata=None))), (30616, (233, PredictedToken(token=' Rice', prob=2.771615982055664e-06, logit=9.8125, token_id=30616, metadata=None)))])\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.633, logit=21.625)', '\" The\"[578] (p=0.160, logit=20.250)', '\" A\"[362] (p=0.110, logit=19.875)', '\" Among\"[22395] (p=0.028, logit=18.500)', '\" Skate\"[97796] (p=0.022, logit=18.250)']\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.6328125, logit=21.625, token_id=30616, metadata=None))), (97796, (5, PredictedToken(token=' Skate', prob=0.0216064453125, logit=18.25, token_id=97796, metadata=None))), (29318, (37, PredictedToken(token=' Dress', prob=0.0003490447998046875, logit=14.125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:57 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     patch_prediction=['\" Train\"[27217] (p=0.711, logit=22.250)', '\" The\"[578] (p=0.109, logit=20.375)', '\" Among\"[22395] (p=0.075, logit=20.000)', '\" A\"[362] (p=0.066, logit=19.875)', '\" (\"[320] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     clean_prediction=['\" Scar\"[30760] (p=0.363, logit=20.125)', '\" The\"[578] (p=0.250, logit=19.750)', '\" A\"[362] (p=0.151, logit=19.250)', '\" Among\"[22395] (p=0.134, logit=19.125)', '\" Tape\"[58586] (p=0.021, logit=17.250)']\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     clean_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.36328125, logit=20.125, token_id=30760, metadata=None))), (58586, (5, PredictedToken(token=' Tape', prob=0.0205078125, logit=17.25, token_id=58586, metadata=None))), (16488, (238, PredictedToken(token=' Bat', prob=1.0013580322265625e-05, logit=9.625, token_id=16488, metadata=None))), (22725, (253, PredictedToken(token=' Orange', prob=9.417533874511719e-06, logit=9.5625, token_id=22725, metadata=None))), (38930, (616, PredictedToken(token=' Bike', prob=2.3692846298217773e-06, logit=8.1875, token_id=38930, metadata=None))), (27171, (1377, PredictedToken(token=' Coffee', prob=7.711350917816162e-07, logit=7.0625, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.910, logit=22.875)', '\" The\"[578] (p=0.040, logit=19.750)', '\" A\"[362] (p=0.024, logit=19.250)', '\" Among\"[22395] (p=0.010, logit=18.375)', '\" It\"[1102] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.91015625, logit=22.875, token_id=38930, metadata=None))), (16488, (14, PredictedToken(token=' Bat', prob=0.0003452301025390625, logit=15.0, token_id=16488, metadata=None))), (27171, (171, PredictedToken(token=' Coffee', prob=3.1888484954833984e-06, logit=10.3125, token_id=27171, metadata=None))), (30760, (463, PredictedToken(token=' Scar', prob=5.885958671569824e-07, logit=8.625, token_id=30760, metadata=None))), (22725, (923, PredictedToken(token=' Orange', prob=2.3096799850463867e-07, logit=7.6875, token_id=22725, metadata=None))), (58586, (1382, PredictedToken(token=' Tape', prob=1.3597309589385986e-07, logit=7.15625, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:57 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:54:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     patch_prediction=['\" Train\"[27217] (p=0.758, logit=22.250)', '\" The\"[578] (p=0.090, logit=20.125)', '\" A\"[362] (p=0.080, logit=20.000)', '\" Among\"[22395] (p=0.043, logit=19.375)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.672, logit=22.250)', '\" The\"[578] (p=0.150, logit=20.750)', '\" Among\"[22395] (p=0.071, logit=20.000)', '\" A\"[362] (p=0.071, logit=20.000)', '\" It\"[1102] (p=0.010, logit=18.000)']\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.671875, logit=22.25, token_id=8219, metadata=None))), (28131, (222, PredictedToken(token=' Golf', prob=3.427267074584961e-06, logit=10.0625, token_id=28131, metadata=None))), (33199, (267, PredictedToken(token=' Lion', prob=2.205371856689453e-06, logit=9.625, token_id=33199, metadata=None))), (87213, (274, PredictedToken(token=' Oven', prob=2.0712614059448242e-06, logit=9.5625, token_id=87213, metadata=None))), (34785, (440, PredictedToken(token=' Truck', prob=9.201467037200928e-07, logit=8.75, token_id=34785, metadata=None)))])\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     int_prediction=['\" Truck\"[34785] (p=0.738, logit=21.750)', '\" The\"[578] (p=0.100, logit=19.750)', '\" A\"[362] (p=0.068, logit=19.375)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" Out\"[4470] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     int_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.73828125, logit=21.75, token_id=34785, metadata=None))), (33199, (6, PredictedToken(token=' Lion', prob=0.005615234375, logit=16.875, token_id=33199, metadata=None))), (28131, (33, PredictedToken(token=' Golf', prob=0.00029754638671875, logit=13.9375, token_id=28131, metadata=None))), (87213, (73, PredictedToken(token=' Oven', prob=4.57763671875e-05, logit=12.0625, token_id=87213, metadata=None))), (8219, (95, PredictedToken(token=' Sun', prob=2.5987625122070312e-05, logit=11.5, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:58 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:54:58 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:54:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.816, logit=21.625)', '\" A\"[362] (p=0.076, logit=19.250)', '\" The\"[578] (p=0.036, logit=18.500)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.793, logit=21.875)', '\" The\"[578] (p=0.083, logit=19.625)', '\" Among\"[22395] (p=0.065, logit=19.375)', '\" A\"[362] (p=0.024, logit=18.375)', '\" socks\"[40086] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.79296875, logit=21.875, token_id=328, metadata=None))), (4923, (17, PredictedToken(token=' Sk', prob=0.000560760498046875, logit=14.625, token_id=4923, metadata=None))), (432, (36, PredictedToken(token=' R', prob=0.00018215179443359375, logit=13.5, token_id=432, metadata=None))), (1443, (74, PredictedToken(token=' Sh', prob=3.814697265625e-05, logit=11.9375, token_id=1443, metadata=None))), (45332, (294, PredictedToken(token=' Boat', prob=2.16066837310791e-06, logit=9.0625, token_id=45332, metadata=None))), (33199, (364, PredictedToken(token=' Lion', prob=1.4826655387878418e-06, logit=8.6875, token_id=33199, metadata=None)))])\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.805, logit=22.000)', '\" The\"[578] (p=0.045, logit=19.125)', '\" A\"[362] (p=0.045, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=19.000)', '\" Boat\"[45332] (p=0.013, logit=17.875)']\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.8046875, logit=22.0, token_id=4923, metadata=None))), (45332, (5, PredictedToken(token=' Boat', prob=0.01300048828125, logit=17.875, token_id=45332, metadata=None))), (1443, (6, PredictedToken(token=' Sh', prob=0.0069580078125, logit=17.25, token_id=1443, metadata=None))), (328, (9, PredictedToken(token=' S', prob=0.0037384033203125, logit=16.625, token_id=328, metadata=None))), (33199, (63, PredictedToken(token=' Lion', prob=6.818771362304688e-05, logit=12.625, token_id=33199, metadata=None))), (432, (79, PredictedToken(token=' R', prob=4.1484832763671875e-05, logit=12.125, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:54:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:54:59 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.848, logit=22.250)', '\" Among\"[22395] (p=0.054, logit=19.500)', '\" The\"[578] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.008, logit=17.625)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.855, logit=21.500)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" The\"[578] (p=0.042, logit=18.500)', '\" jasmine\"[66909] (p=0.007, logit=16.750)', '\" Option\"[7104] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.85546875, logit=21.5, token_id=82452, metadata=None))), (45805, (13, PredictedToken(token=' Cherry', prob=0.00186920166015625, logit=15.375, token_id=45805, metadata=None))), (328, (41, PredictedToken(token=' S', prob=0.0001964569091796875, logit=13.125, token_id=328, metadata=None))), (58600, (83, PredictedToken(token=' Charm', prob=4.673004150390625e-05, logit=11.6875, token_id=58600, metadata=None))), (94467, (137, PredictedToken(token=' Trom', prob=1.621246337890625e-05, logit=10.625, token_id=94467, metadata=None)))])\n",
      "2025-09-16 09:54:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.848, logit=21.125)', '\" The\"[578] (p=0.037, logit=18.000)', '\" Among\"[22395] (p=0.026, logit=17.625)', '\" Cherry\"[45805] (p=0.020, logit=17.375)', '\" S\"[328] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.84765625, logit=21.125, token_id=82452, metadata=None))), (45805, (4, PredictedToken(token=' Cherry', prob=0.0198974609375, logit=17.375, token_id=45805, metadata=None))), (328, (5, PredictedToken(token=' S', prob=0.01068115234375, logit=16.75, token_id=328, metadata=None))), (58600, (97, PredictedToken(token=' Charm', prob=4.649162292480469e-05, logit=11.3125, token_id=58600, metadata=None))), (94467, (393, PredictedToken(token=' Trom', prob=3.5762786865234375e-06, logit=8.75, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:00 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     patch_prediction=['\" Project\"[5907] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.061, logit=19.125)', '\" A\"[362] (p=0.029, logit=18.375)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" It\"[1102] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     clean_prediction=['\" Yoga\"[38673] (p=0.680, logit=20.500)', '\" A\"[362] (p=0.092, logit=18.500)', '\" The\"[578] (p=0.081, logit=18.375)', '\" Among\"[22395] (p=0.034, logit=17.500)', '\" None\"[2290] (p=0.030, logit=17.375)']\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     clean_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.6796875, logit=20.5, token_id=38673, metadata=None))), (30558, (46, PredictedToken(token=' Ki', prob=0.000331878662109375, logit=12.875, token_id=30558, metadata=None))), (14642, (87, PredictedToken(token=' Phone', prob=7.867813110351562e-05, logit=11.4375, token_id=14642, metadata=None))), (86460, (99, PredictedToken(token=' Necklace', prob=6.532669067382812e-05, logit=11.25, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.609, logit=20.375)', '\" None\"[2290] (p=0.153, logit=19.000)', '\" The\"[578] (p=0.050, logit=17.875)', '\" A\"[362] (p=0.050, logit=17.875)', '\" Among\"[22395] (p=0.024, logit=17.125)']\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.609375, logit=20.375, token_id=14642, metadata=None))), (38673, (6, PredictedToken(token=' Yoga', prob=0.0235595703125, logit=17.125, token_id=38673, metadata=None))), (30558, (7, PredictedToken(token=' Ki', prob=0.01263427734375, logit=16.5, token_id=30558, metadata=None))), (86460, (48, PredictedToken(token=' Necklace', prob=0.000316619873046875, logit=12.8125, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:00 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:00 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:55:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     patch_prediction=['\" P\"[393] (p=0.773, logit=20.750)', '\" The\"[578] (p=0.072, logit=18.375)', '\" A\"[362] (p=0.049, logit=18.000)', '\" Among\"[22395] (p=0.039, logit=17.750)', '\" It\"[1102] (p=0.006, logit=15.812)']\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.832, logit=21.875)', '\" The\"[578] (p=0.068, logit=19.375)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" A\"[362] (p=0.028, logit=18.500)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.83203125, logit=21.875, token_id=15883, metadata=None))), (33199, (90, PredictedToken(token=' Lion', prob=2.4437904357910156e-05, logit=11.4375, token_id=33199, metadata=None))), (18654, (177, PredictedToken(token=' Micro', prob=6.16908073425293e-06, logit=10.0625, token_id=18654, metadata=None))), (97796, (1208, PredictedToken(token=' Skate', prob=3.166496753692627e-07, logit=7.09375, token_id=97796, metadata=None))), (37128, (1789, PredictedToken(token=' Calculator', prob=1.862645149230957e-07, logit=6.5625, token_id=37128, metadata=None))), (49268, (2079, PredictedToken(token=' Dish', prob=1.4994293451309204e-07, logit=6.34375, token_id=49268, metadata=None)))])\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     int_prediction=['\" Micro\"[18654] (p=0.198, logit=19.250)', '\" Spr\"[15883] (p=0.198, logit=19.250)', '\" A\"[362] (p=0.198, logit=19.250)', '\" Calculator\"[37128] (p=0.154, logit=19.000)', '\" The\"[578] (p=0.137, logit=18.875)']\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     int_track=OrderedDict([(15883, (2, PredictedToken(token=' Spr', prob=0.1982421875, logit=19.25, token_id=15883, metadata=None))), (18654, (3, PredictedToken(token=' Micro', prob=0.1982421875, logit=19.25, token_id=18654, metadata=None))), (37128, (4, PredictedToken(token=' Calculator', prob=0.154296875, logit=19.0, token_id=37128, metadata=None))), (97796, (35, PredictedToken(token=' Skate', prob=0.0005950927734375, logit=13.4375, token_id=97796, metadata=None))), (49268, (354, PredictedToken(token=' Dish', prob=5.811452865600586e-06, logit=8.8125, token_id=49268, metadata=None))), (33199, (1489, PredictedToken(token=' Lion', prob=8.940696716308594e-07, logit=6.9375, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:01 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.738, logit=21.500)', '\" The\"[578] (p=0.100, logit=19.500)', '\" A\"[362] (p=0.088, logit=19.375)', '\" Among\"[22395] (p=0.013, logit=17.500)', '\" Option\"[7104] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.719, logit=21.750)', '\" The\"[578] (p=0.142, logit=20.125)', '\" Among\"[22395] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.052, logit=19.125)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.71875, logit=21.75, token_id=42609, metadata=None))), (11452, (26, PredictedToken(token=' Head', prob=0.00022602081298828125, logit=13.6875, token_id=11452, metadata=None))), (432, (91, PredictedToken(token=' R', prob=2.09808349609375e-05, logit=11.3125, token_id=432, metadata=None))), (58600, (479, PredictedToken(token=' Charm', prob=1.1846423149108887e-06, logit=8.4375, token_id=58600, metadata=None))), (34785, (565, PredictedToken(token=' Truck', prob=9.834766387939453e-07, logit=8.25, token_id=34785, metadata=None)))])\n",
      "2025-09-16 09:55:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.707, logit=21.875)', '\" The\"[578] (p=0.140, logit=20.250)', '\" A\"[362] (p=0.066, logit=19.500)', '\" Among\"[22395] (p=0.051, logit=19.250)', '\" Pine\"[42609] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.70703125, logit=21.875, token_id=432, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.004791259765625, logit=16.875, token_id=42609, metadata=None))), (11452, (22, PredictedToken(token=' Head', prob=0.0003681182861328125, logit=14.3125, token_id=11452, metadata=None))), (34785, (27, PredictedToken(token=' Truck', prob=0.0002689361572265625, logit=14.0, token_id=34785, metadata=None))), (58600, (201, PredictedToken(token=' Charm', prob=3.844499588012695e-06, logit=9.75, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:02 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:02 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.945, logit=22.750)', '\" An\"[1556] (p=0.017, logit=18.750)', '\" The\"[578] (p=0.009, logit=18.125)', '\" Among\"[22395] (p=0.008, logit=18.000)', '\" ank\"[71572] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.688, logit=20.750)', '\" Among\"[22395] (p=0.105, logit=18.875)', '\" The\"[578] (p=0.105, logit=18.875)', '\" Ski\"[61595] (p=0.018, logit=17.125)', '\" It\"[1102] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.6875, logit=20.75, token_id=4923, metadata=None))), (5340, (13, PredictedToken(token=' Har', prob=0.0028076171875, logit=15.25, token_id=5340, metadata=None))), (22050, (50, PredictedToken(token=' Hat', prob=0.0002956390380859375, logit=13.0, token_id=22050, metadata=None))), (53889, (127, PredictedToken(token=' Apartment', prob=2.4318695068359375e-05, logit=10.5, token_id=53889, metadata=None))), (86460, (251, PredictedToken(token=' Necklace', prob=6.5267086029052734e-06, logit=9.1875, token_id=86460, metadata=None))), (16344, (821, PredictedToken(token=' Rose', prob=9.126961231231689e-07, logit=7.21875, token_id=16344, metadata=None)))])\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.895, logit=21.875)', '\" The\"[578] (p=0.044, logit=18.875)', '\" A\"[362] (p=0.014, logit=17.750)', '\" Among\"[22395] (p=0.013, logit=17.625)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.89453125, logit=21.875, token_id=86460, metadata=None))), (22050, (6, PredictedToken(token=' Hat', prob=0.003662109375, logit=16.375, token_id=22050, metadata=None))), (5340, (8, PredictedToken(token=' Har', prob=0.00162506103515625, logit=15.5625, token_id=5340, metadata=None))), (16344, (38, PredictedToken(token=' Rose', prob=0.00016021728515625, logit=13.25, token_id=16344, metadata=None))), (53889, (117, PredictedToken(token=' Apartment', prob=1.800060272216797e-05, logit=11.0625, token_id=53889, metadata=None))), (4923, (874, PredictedToken(token=' Sk', prob=6.146728992462158e-07, logit=7.6875, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:02 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:02 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     patch_prediction=['\" B\"[426] (p=0.730, logit=22.500)', '\" b\"[293] (p=0.099, logit=20.500)', '\" A\"[362] (p=0.068, logit=20.125)', '\" The\"[578] (p=0.047, logit=19.750)', '\" Among\"[22395] (p=0.013, logit=18.500)']\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.848, logit=21.750)', '\" The\"[578] (p=0.042, logit=18.750)', '\" A\"[362] (p=0.033, logit=18.500)', '\" pressure\"[7410] (p=0.020, logit=18.000)', '\" Among\"[22395] (p=0.016, logit=17.750)']\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.84765625, logit=21.75, token_id=40090, metadata=None))), (8868, (6, PredictedToken(token=' Blue', prob=0.00732421875, logit=17.0, token_id=8868, metadata=None))), (57915, (20, PredictedToken(token=' Ank', prob=0.000530242919921875, logit=14.375, token_id=57915, metadata=None)))])\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     int_prediction=['\" Ank\"[57915] (p=0.945, logit=22.625)', '\" ank\"[71572] (p=0.012, logit=18.250)', '\" An\"[1556] (p=0.008, logit=17.875)', '\" The\"[578] (p=0.007, logit=17.750)', '\" Blue\"[8868] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     int_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.9453125, logit=22.625, token_id=57915, metadata=None))), (8868, (5, PredictedToken(token=' Blue', prob=0.00634765625, logit=17.625, token_id=8868, metadata=None))), (40090, (82, PredictedToken(token=' Pressure', prob=1.3053417205810547e-05, logit=11.4375, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:03 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     patch_prediction=['\" Y\"[816] (p=0.797, logit=21.875)', '\" The\"[578] (p=0.058, logit=19.250)', '\" A\"[362] (p=0.058, logit=19.250)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" (\"[320] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:55:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.746, logit=22.250)', '\" The\"[578] (p=0.129, logit=20.500)', '\" An\"[1556] (p=0.061, logit=19.750)', '\" Among\"[22395] (p=0.026, logit=18.875)', '\" It\"[1102] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.74609375, logit=22.25, token_id=11683, metadata=None))), (79189, (38, PredictedToken(token=' Elephant', prob=0.000125885009765625, logit=13.5625, token_id=79189, metadata=None))), (47643, (52, PredictedToken(token=' Cel', prob=8.630752563476562e-05, logit=13.1875, token_id=47643, metadata=None))), (1183, (120, PredictedToken(token=' Tr', prob=1.3232231140136719e-05, logit=11.3125, token_id=1183, metadata=None))), (82994, (384, PredictedToken(token=' Toilet', prob=1.3113021850585938e-06, logit=9.0, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.844, logit=22.000)', '\" The\"[578] (p=0.079, logit=19.625)', '\" Among\"[22395] (p=0.022, logit=18.375)', '\" A\"[362] (p=0.012, logit=17.750)', '\" Toilet\"[82994] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.84375, logit=22.0, token_id=1183, metadata=None))), (82994, (5, PredictedToken(token=' Toilet', prob=0.00830078125, logit=17.375, token_id=82994, metadata=None))), (47643, (6, PredictedToken(token=' Cel', prob=0.003448486328125, logit=16.5, token_id=47643, metadata=None))), (79189, (33, PredictedToken(token=' Elephant', prob=0.0002346038818359375, logit=13.8125, token_id=79189, metadata=None))), (11683, (72, PredictedToken(token=' Acc', prob=4.3392181396484375e-05, logit=12.125, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:04 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:04 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     patch_prediction=['\" St\"[800] (p=0.871, logit=22.875)', '\" A\"[362] (p=0.056, logit=20.125)', '\" The\"[578] (p=0.038, logit=19.750)', '\" Among\"[22395] (p=0.007, logit=18.000)', '\" stool\"[64172] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.832, logit=20.875)', '\" The\"[578] (p=0.053, logit=18.125)', '\" Among\"[22395] (p=0.041, logit=17.875)', '\" lotion\"[87942] (p=0.009, logit=16.375)', '\" A\"[362] (p=0.006, logit=15.938)']\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.83203125, logit=20.875, token_id=445, metadata=None))), (70110, (16, PredictedToken(token=' Ottoman', prob=0.0010986328125, logit=14.25, token_id=70110, metadata=None))), (72683, (95, PredictedToken(token=' Boxing', prob=6.198883056640625e-05, logit=11.375, token_id=72683, metadata=None)))])\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.416, logit=19.875)', '\" Boxing\"[72683] (p=0.416, logit=19.875)', '\" The\"[578] (p=0.050, logit=17.750)', '\" Among\"[22395] (p=0.027, logit=17.125)', '\" None\"[2290] (p=0.011, logit=16.250)']\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     int_track=OrderedDict([(72683, (2, PredictedToken(token=' Boxing', prob=0.416015625, logit=19.875, token_id=72683, metadata=None))), (70110, (1, PredictedToken(token=' Ottoman', prob=0.416015625, logit=19.875, token_id=70110, metadata=None))), (445, (27, PredictedToken(token=' L', prob=0.0006256103515625, logit=13.375, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:04 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:55:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.816, logit=21.500)', '\" The\"[578] (p=0.067, logit=19.000)', '\" Among\"[22395] (p=0.041, logit=18.500)', '\" A\"[362] (p=0.025, logit=18.000)', '\" strawberry\"[73700] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.629, logit=20.125)', '\" The\"[578] (p=0.109, logit=18.375)', '\" A\"[362] (p=0.097, logit=18.250)', '\" Among\"[22395] (p=0.059, logit=17.750)', '\" Note\"[7181] (p=0.009, logit=15.875)']\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.62890625, logit=20.125, token_id=69755, metadata=None))), (15883, (8, PredictedToken(token=' Spr', prob=0.00579833984375, logit=15.4375, token_id=15883, metadata=None))), (57915, (19, PredictedToken(token=' Ank', prob=0.0019989013671875, logit=14.375, token_id=57915, metadata=None))), (60413, (57, PredictedToken(token=' Uk', prob=0.00023937225341796875, logit=12.25, token_id=60413, metadata=None))), (328, (71, PredictedToken(token=' S', prob=0.00014495849609375, logit=11.75, token_id=328, metadata=None))), (8868, (82, PredictedToken(token=' Blue', prob=0.00011301040649414062, logit=11.5, token_id=8868, metadata=None)))])\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.883, logit=21.375)', '\" The\"[578] (p=0.044, logit=18.375)', '\" Among\"[22395] (p=0.016, logit=17.375)', '\" blue\"[6437] (p=0.005, logit=16.250)', '\" A\"[362] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.8828125, logit=21.375, token_id=8868, metadata=None))), (15883, (9, PredictedToken(token=' Spr', prob=0.0028076171875, logit=15.625, token_id=15883, metadata=None))), (328, (44, PredictedToken(token=' S', prob=0.00016880035400390625, logit=12.8125, token_id=328, metadata=None))), (57915, (85, PredictedToken(token=' Ank', prob=4.839897155761719e-05, logit=11.5625, token_id=57915, metadata=None))), (60413, (112, PredictedToken(token=' Uk', prob=3.123283386230469e-05, logit=11.125, token_id=60413, metadata=None))), (69755, (1866, PredictedToken(token=' Notebook', prob=2.7008354663848877e-07, logit=6.375, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:05 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:05 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:05 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     patch_prediction=['\" Tul\"[43316] (p=0.836, logit=21.000)', '\" The\"[578] (p=0.053, logit=18.250)', '\" Among\"[22395] (p=0.042, logit=18.000)', '\" A\"[362] (p=0.013, logit=16.875)', '\" Grape\"[80629] (p=0.007, logit=16.250)']\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.734, logit=21.875)', '\" The\"[578] (p=0.100, logit=19.875)', '\" A\"[362] (p=0.078, logit=19.625)', '\" Among\"[22395] (p=0.053, logit=19.250)', '\" CO\"[7432] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.734375, logit=21.875, token_id=68867, metadata=None))), (1443, (33, PredictedToken(token=' Sh', prob=0.0002040863037109375, logit=13.6875, token_id=1443, metadata=None))), (65197, (46, PredictedToken(token=' Surf', prob=0.00010919570922851562, logit=13.0625, token_id=65197, metadata=None))), (16344, (88, PredictedToken(token=' Rose', prob=3.337860107421875e-05, logit=11.875, token_id=16344, metadata=None))), (44570, (151, PredictedToken(token=' Maple', prob=1.0848045349121094e-05, logit=10.75, token_id=44570, metadata=None))), (14642, (356, PredictedToken(token=' Phone', prob=1.7657876014709473e-06, logit=8.9375, token_id=14642, metadata=None)))])\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.820, logit=21.500)', '\" A\"[362] (p=0.060, logit=18.875)', '\" The\"[578] (p=0.041, logit=18.500)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" Maple\"[44570] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.8203125, logit=21.5, token_id=16344, metadata=None))), (44570, (5, PredictedToken(token=' Maple', prob=0.005523681640625, logit=16.5, token_id=44570, metadata=None))), (1443, (13, PredictedToken(token=' Sh', prob=0.00115966796875, logit=14.9375, token_id=1443, metadata=None))), (65197, (25, PredictedToken(token=' Surf', prob=0.000621795654296875, logit=14.3125, token_id=65197, metadata=None))), (68867, (412, PredictedToken(token=' Coat', prob=2.1010637283325195e-06, logit=8.625, token_id=68867, metadata=None))), (14642, (931, PredictedToken(token=' Phone', prob=6.817281246185303e-07, logit=7.5, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:06 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.742, logit=22.625)', '\" The\"[578] (p=0.165, logit=21.125)', '\" A\"[362] (p=0.047, logit=19.875)', '\" Among\"[22395] (p=0.020, logit=19.000)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.738, logit=21.875)', '\" The\"[578] (p=0.088, logit=19.750)', '\" Among\"[22395] (p=0.078, logit=19.625)', '\" A\"[362] (p=0.053, logit=19.250)', '\" slow\"[6435] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.73828125, logit=21.875, token_id=39247, metadata=None))), (20423, (30, PredictedToken(token=' Amb', prob=0.0003376007080078125, logit=14.1875, token_id=20423, metadata=None))), (23910, (32, PredictedToken(token=' Pear', prob=0.00029754638671875, logit=14.0625, token_id=23910, metadata=None))), (94467, (36, PredictedToken(token=' Trom', prob=0.000263214111328125, logit=13.9375, token_id=94467, metadata=None))), (53889, (90, PredictedToken(token=' Apartment', prob=3.147125244140625e-05, logit=11.8125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:55:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     int_prediction=['\" Trom\"[94467] (p=0.416, logit=19.750)', '\" The\"[578] (p=0.152, logit=18.750)', '\" Among\"[22395] (p=0.135, logit=18.625)', '\" Pear\"[23910] (p=0.093, logit=18.250)', '\" A\"[362] (p=0.093, logit=18.250)']\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     int_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.416015625, logit=19.75, token_id=94467, metadata=None))), (23910, (5, PredictedToken(token=' Pear', prob=0.0927734375, logit=18.25, token_id=23910, metadata=None))), (20423, (77, PredictedToken(token=' Amb', prob=0.0001583099365234375, logit=11.875, token_id=20423, metadata=None))), (39247, (262, PredictedToken(token=' Slow', prob=1.4662742614746094e-05, logit=9.5, token_id=39247, metadata=None))), (53889, (275, PredictedToken(token=' Apartment', prob=1.3768672943115234e-05, logit=9.4375, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:07 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.684, logit=20.875)', '\" Horse\"[34392] (p=0.063, logit=18.500)', '\" A\"[362] (p=0.056, logit=18.375)', '\" The\"[578] (p=0.050, logit=18.250)', '\" Among\"[22395] (p=0.044, logit=18.125)']\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.797, logit=21.625)', '\" The\"[578] (p=0.065, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=18.625)', '\" A\"[362] (p=0.040, logit=18.625)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.796875, logit=21.625, token_id=9441, metadata=None))), (81501, (24, PredictedToken(token=' Pendant', prob=0.000774383544921875, logit=14.6875, token_id=81501, metadata=None))), (24423, (31, PredictedToken(token=' Monitor', prob=0.0004138946533203125, logit=14.0625, token_id=24423, metadata=None))), (33711, (41, PredictedToken(token=' Suit', prob=0.00022125244140625, logit=13.4375, token_id=33711, metadata=None))), (45332, (69, PredictedToken(token=' Boat', prob=6.341934204101562e-05, logit=12.1875, token_id=45332, metadata=None)))])\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     int_prediction=['\" Boat\"[45332] (p=0.711, logit=21.375)', '\" Monitor\"[24423] (p=0.109, logit=19.500)', '\" The\"[578] (p=0.052, logit=18.750)', '\" A\"[362] (p=0.031, logit=18.250)', '\" Pendant\"[81501] (p=0.027, logit=18.125)']\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     int_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.7109375, logit=21.375, token_id=45332, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.10888671875, logit=19.5, token_id=24423, metadata=None))), (81501, (5, PredictedToken(token=' Pendant', prob=0.0274658203125, logit=18.125, token_id=81501, metadata=None))), (33711, (14, PredictedToken(token=' Suit', prob=0.00176239013671875, logit=15.375, token_id=33711, metadata=None))), (9441, (287, PredictedToken(token=' Church', prob=4.649162292480469e-06, logit=9.4375, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:07 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     patch_prediction=['\" Daisy\"[71264] (p=0.723, logit=21.000)', '\" The\"[578] (p=0.111, logit=19.125)', '\" Among\"[22395] (p=0.046, logit=18.250)', '\" A\"[362] (p=0.046, logit=18.250)', '\" d\"[294] (p=0.019, logit=17.375)']\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     clean_prediction=['\" Oak\"[18787] (p=0.789, logit=22.000)', '\" The\"[578] (p=0.073, logit=19.625)', '\" Among\"[22395] (p=0.057, logit=19.375)', '\" An\"[1556] (p=0.027, logit=18.625)', '\" Option\"[7104] (p=0.011, logit=17.750)']\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     clean_track=OrderedDict([(18787, (1, PredictedToken(token=' Oak', prob=0.7890625, logit=22.0, token_id=18787, metadata=None))), (5250, (8, PredictedToken(token=' Pe', prob=0.0028533935546875, logit=16.375, token_id=5250, metadata=None))), (6771, (62, PredictedToken(token=' Table', prob=5.221366882324219e-05, logit=12.375, token_id=6771, metadata=None))), (69755, (811, PredictedToken(token=' Notebook', prob=5.103647708892822e-07, logit=7.75, token_id=69755, metadata=None))), (47759, (1251, PredictedToken(token=' Guitar', prob=2.8312206268310547e-07, logit=7.15625, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     int_prediction=['\" Pe\"[5250] (p=0.668, logit=21.125)', '\" The\"[578] (p=0.149, logit=19.625)', '\" Among\"[22395] (p=0.070, logit=18.875)', '\" A\"[362] (p=0.043, logit=18.375)', '\" (\"[320] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     int_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.66796875, logit=21.125, token_id=5250, metadata=None))), (6771, (7, PredictedToken(token=' Table', prob=0.005096435546875, logit=16.25, token_id=6771, metadata=None))), (18787, (144, PredictedToken(token=' Oak', prob=1.8477439880371094e-05, logit=10.625, token_id=18787, metadata=None))), (69755, (388, PredictedToken(token=' Notebook', prob=3.0100345611572266e-06, logit=8.8125, token_id=69755, metadata=None))), (47759, (479, PredictedToken(token=' Guitar', prob=2.205371856689453e-06, logit=8.5, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:08 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     patch_prediction=['\" Boat\"[45332] (p=0.762, logit=22.000)', '\" A\"[362] (p=0.091, logit=19.875)', '\" The\"[578] (p=0.071, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=19.000)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.809, logit=21.500)', '\" None\"[2290] (p=0.097, logit=19.375)', '\" The\"[578] (p=0.028, logit=18.125)', '\" There\"[2684] (p=0.013, logit=17.375)', '\" Among\"[22395] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.80859375, logit=21.5, token_id=44570, metadata=None))), (6031, (11, PredictedToken(token=' Bro', prob=0.0016632080078125, logit=15.3125, token_id=6031, metadata=None))), (13000, (12, PredictedToken(token=' Van', prob=0.0016632080078125, logit=15.3125, token_id=13000, metadata=None))), (34954, (19, PredictedToken(token=' Mirror', prob=0.000888824462890625, logit=14.6875, token_id=34954, metadata=None))), (87213, (302, PredictedToken(token=' Oven', prob=4.649162292480469e-06, logit=9.4375, token_id=87213, metadata=None))), (67553, (657, PredictedToken(token=' Pants', prob=1.2516975402832031e-06, logit=8.125, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:55:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.852, logit=22.250)', '\" None\"[2290] (p=0.079, logit=19.875)', '\" The\"[578] (p=0.018, logit=18.375)', '\" A\"[362] (p=0.016, logit=18.250)', '\" VAN\"[97753] (p=0.011, logit=17.875)']\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.8515625, logit=22.25, token_id=13000, metadata=None))), (87213, (25, PredictedToken(token=' Oven', prob=0.0002689361572265625, logit=14.1875, token_id=87213, metadata=None))), (44570, (31, PredictedToken(token=' Maple', prob=0.0001964569091796875, logit=13.875, token_id=44570, metadata=None))), (67553, (41, PredictedToken(token=' Pants', prob=0.00012683868408203125, logit=13.4375, token_id=67553, metadata=None))), (6031, (53, PredictedToken(token=' Bro', prob=6.771087646484375e-05, logit=12.8125, token_id=6031, metadata=None))), (34954, (58, PredictedToken(token=' Mirror', prob=5.626678466796875e-05, logit=12.625, token_id=34954, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:09 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:09 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     patch_prediction=['\" House\"[4783] (p=0.793, logit=22.250)', '\" A\"[362] (p=0.084, logit=20.000)', '\" The\"[578] (p=0.065, logit=19.750)', '\" Among\"[22395] (p=0.021, logit=18.625)', '\" It\"[1102] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.797, logit=21.500)', '\" The\"[578] (p=0.084, logit=19.250)', '\" A\"[362] (p=0.045, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" It\"[1102] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.796875, logit=21.5, token_id=16488, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.004180908203125, logit=16.25, token_id=356, metadata=None))), (18343, (58, PredictedToken(token=' Paper', prob=0.00010442733764648438, logit=12.5625, token_id=18343, metadata=None))), (53889, (367, PredictedToken(token=' Apartment', prob=2.4586915969848633e-06, logit=8.8125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     int_prediction=['\" Apartment\"[53889] (p=0.844, logit=21.375)', '\" The\"[578] (p=0.054, logit=18.625)', '\" An\"[1556] (p=0.015, logit=17.375)', '\" Paper\"[18343] (p=0.014, logit=17.250)', '\" Among\"[22395] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     int_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.84375, logit=21.375, token_id=53889, metadata=None))), (18343, (4, PredictedToken(token=' Paper', prob=0.01361083984375, logit=17.25, token_id=18343, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.007293701171875, logit=16.625, token_id=356, metadata=None))), (16488, (25, PredictedToken(token=' Bat', prob=0.000560760498046875, logit=14.0625, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:09 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.738, logit=22.250)', '\" The\"[578] (p=0.113, logit=20.375)', '\" A\"[362] (p=0.061, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=19.500)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     clean_prediction=['\" Stap\"[63606] (p=0.742, logit=20.875)', '\" The\"[578] (p=0.088, logit=18.750)', '\" A\"[362] (p=0.069, logit=18.500)', '\" Among\"[22395] (p=0.037, logit=17.875)', '\" stap\"[36114] (p=0.012, logit=16.750)']\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     clean_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.7421875, logit=20.875, token_id=63606, metadata=None))), (30760, (43, PredictedToken(token=' Scar', prob=0.0002193450927734375, logit=12.75, token_id=30760, metadata=None))), (70110, (87, PredictedToken(token=' Ottoman', prob=5.91278076171875e-05, logit=11.4375, token_id=70110, metadata=None))), (8868, (180, PredictedToken(token=' Blue', prob=1.3172626495361328e-05, logit=9.9375, token_id=8868, metadata=None))), (71264, (970, PredictedToken(token=' Daisy', prob=1.080334186553955e-06, logit=7.4375, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.373, logit=19.125)', '\" The\"[578] (p=0.227, logit=18.625)', '\" Daisy\"[71264] (p=0.107, logit=17.875)', '\" Among\"[22395] (p=0.051, logit=17.125)', '\" d\"[294] (p=0.031, logit=16.625)']\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.373046875, logit=19.125, token_id=70110, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.10693359375, logit=17.875, token_id=71264, metadata=None))), (63606, (6, PredictedToken(token=' Stap', prob=0.027099609375, logit=16.5, token_id=63606, metadata=None))), (30760, (10, PredictedToken(token=' Scar', prob=0.00823974609375, logit=15.3125, token_id=30760, metadata=None))), (8868, (17, PredictedToken(token=' Blue', prob=0.004425048828125, logit=14.6875, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:10 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:10 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.750, logit=20.375)', '\" The\"[578] (p=0.102, logit=18.375)', '\" Among\"[22395] (p=0.029, logit=17.125)', '\" A\"[362] (p=0.029, logit=17.125)', '\" None\"[2290] (p=0.016, logit=16.500)']\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.746, logit=21.000)', '\" The\"[578] (p=0.089, logit=18.875)', '\" An\"[1556] (p=0.042, logit=18.125)', '\" Among\"[22395] (p=0.037, logit=18.000)', '\" Only\"[8442] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.74609375, logit=21.0, token_id=87213, metadata=None))), (14937, (29, PredictedToken(token=' Ash', prob=0.00049591064453125, logit=13.6875, token_id=14937, metadata=None))), (89077, (140, PredictedToken(token=' Strawberry', prob=2.8014183044433594e-05, logit=10.8125, token_id=89077, metadata=None))), (50159, (165, PredictedToken(token=' Sco', prob=2.0503997802734375e-05, logit=10.5, token_id=50159, metadata=None))), (97796, (1198, PredictedToken(token=' Skate', prob=9.015202522277832e-07, logit=7.375, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:55:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.945, logit=22.500)', '\" Sco\"[50159] (p=0.017, logit=18.500)', '\" The\"[578] (p=0.013, logit=18.250)', '\" A\"[362] (p=0.004, logit=17.125)', '\" Among\"[22395] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.9453125, logit=22.5, token_id=97796, metadata=None))), (50159, (2, PredictedToken(token=' Sco', prob=0.017333984375, logit=18.5, token_id=50159, metadata=None))), (87213, (33, PredictedToken(token=' Oven', prob=9.679794311523438e-05, logit=13.3125, token_id=87213, metadata=None))), (14937, (341, PredictedToken(token=' Ash', prob=1.0728836059570312e-06, logit=8.8125, token_id=14937, metadata=None))), (89077, (1223, PredictedToken(token=' Strawberry', prob=1.8719583749771118e-07, logit=7.0625, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:11 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.840, logit=21.125)', '\" The\"[578] (p=0.054, logit=18.375)', '\" Among\"[22395] (p=0.025, logit=17.625)', '\" Mouse\"[18191] (p=0.022, logit=17.500)', '\" A\"[362] (p=0.017, logit=17.250)']\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     clean_prediction=['\" Mirror\"[34954] (p=0.875, logit=21.500)', '\" Highlight\"[57094] (p=0.038, logit=18.375)', '\" A\"[362] (p=0.018, logit=17.625)', '\" None\"[2290] (p=0.012, logit=17.250)', '\" The\"[578] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     clean_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.875, logit=21.5, token_id=34954, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.038330078125, logit=18.375, token_id=57094, metadata=None))), (6914, (7, PredictedToken(token=' Let', prob=0.006683349609375, logit=16.625, token_id=6914, metadata=None))), (4923, (30, PredictedToken(token=' Sk', prob=0.0002593994140625, logit=13.375, token_id=4923, metadata=None))), (89077, (35, PredictedToken(token=' Strawberry', prob=0.00021457672119140625, logit=13.1875, token_id=89077, metadata=None))), (82507, (75, PredictedToken(token=' Jeans', prob=5.7697296142578125e-05, logit=11.875, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.406, logit=20.000)', '\" Let\"[6914] (p=0.357, logit=19.875)', '\" None\"[2290] (p=0.149, logit=19.000)', '\" The\"[578] (p=0.020, logit=17.000)', '\" A\"[362] (p=0.007, logit=16.000)']\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.40625, logit=20.0, token_id=57094, metadata=None))), (6914, (2, PredictedToken(token=' Let', prob=0.357421875, logit=19.875, token_id=6914, metadata=None))), (34954, (7, PredictedToken(token=' Mirror', prob=0.005096435546875, logit=15.625, token_id=34954, metadata=None))), (82507, (12, PredictedToken(token=' Jeans', prob=0.001556396484375, logit=14.4375, token_id=82507, metadata=None))), (89077, (28, PredictedToken(token=' Strawberry', prob=0.00057220458984375, logit=13.4375, token_id=89077, metadata=None))), (4923, (136, PredictedToken(token=' Sk', prob=2.849102020263672e-05, logit=10.4375, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:11 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:11 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:55:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.867, logit=21.500)', '\" The\"[578] (p=0.038, logit=18.375)', '\" A\"[362] (p=0.034, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.125)', '\" factory\"[8803] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     clean_prediction=['\" Bamboo\"[98028] (p=0.879, logit=21.750)', '\" None\"[2290] (p=0.026, logit=18.250)', '\" The\"[578] (p=0.026, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.375)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     clean_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.87890625, logit=21.75, token_id=98028, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.004058837890625, logit=16.375, token_id=4923, metadata=None))), (800, (15, PredictedToken(token=' St', prob=0.00159454345703125, logit=15.4375, token_id=800, metadata=None)))])\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     int_prediction=['\" St\"[800] (p=0.438, logit=21.500)', '\" Sk\"[4923] (p=0.438, logit=21.500)', '\" None\"[2290] (p=0.028, logit=18.750)', '\" The\"[578] (p=0.028, logit=18.750)', '\" A\"[362] (p=0.022, logit=18.500)']\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     int_track=OrderedDict([(4923, (2, PredictedToken(token=' Sk', prob=0.4375, logit=21.5, token_id=4923, metadata=None))), (800, (1, PredictedToken(token=' St', prob=0.4375, logit=21.5, token_id=800, metadata=None))), (98028, (10, PredictedToken(token=' Bamboo', prob=0.002288818359375, logit=16.25, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:12 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:12 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.844, logit=22.125)', '\" Among\"[22395] (p=0.089, logit=19.875)', '\" The\"[578] (p=0.037, logit=19.000)', '\" Cherry\"[45805] (p=0.003, logit=16.375)', '\" as\"[439] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     clean_prediction=['\" Water\"[10164] (p=0.867, logit=22.750)', '\" The\"[578] (p=0.056, logit=20.000)', '\" Among\"[22395] (p=0.038, logit=19.625)', '\" A\"[362] (p=0.011, logit=18.375)', '\" water\"[3090] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     clean_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.8671875, logit=22.75, token_id=10164, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.000545501708984375, logit=15.375, token_id=1183, metadata=None))), (41785, (19, PredictedToken(token=' Spin', prob=0.00051116943359375, logit=15.3125, token_id=41785, metadata=None))), (61731, (66, PredictedToken(token=' Soap', prob=2.8848648071289062e-05, logit=12.4375, token_id=61731, metadata=None))), (735, (99, PredictedToken(token=' K', prob=1.3649463653564453e-05, logit=11.6875, token_id=735, metadata=None))), (53889, (396, PredictedToken(token=' Apartment', prob=7.674098014831543e-07, logit=8.8125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.504, logit=21.500)', '\" Water\"[10164] (p=0.346, logit=21.125)', '\" The\"[578] (p=0.060, logit=19.375)', '\" Among\"[22395] (p=0.041, logit=19.000)', '\" Soap\"[61731] (p=0.020, logit=18.250)']\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.50390625, logit=21.5, token_id=41785, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.345703125, logit=21.125, token_id=10164, metadata=None))), (61731, (5, PredictedToken(token=' Soap', prob=0.01953125, logit=18.25, token_id=61731, metadata=None))), (1183, (34, PredictedToken(token=' Tr', prob=0.00016880035400390625, logit=13.5, token_id=1183, metadata=None))), (735, (56, PredictedToken(token=' K', prob=8.487701416015625e-05, logit=12.8125, token_id=735, metadata=None))), (53889, (1349, PredictedToken(token=' Apartment', prob=2.775341272354126e-07, logit=7.09375, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:13 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.902, logit=23.125)', '\" The\"[578] (p=0.040, logit=20.000)', '\" Among\"[22395] (p=0.031, logit=19.750)', '\" A\"[362] (p=0.006, logit=18.125)', '\" water\"[3090] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.797, logit=22.625)', '\" The\"[578] (p=0.095, logit=20.500)', '\" A\"[362] (p=0.027, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=19.000)', '\" c\"[272] (p=0.015, logit=18.625)']\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.796875, logit=22.625, token_id=356, metadata=None))), (445, (31, PredictedToken(token=' L', prob=0.000152587890625, logit=14.0625, token_id=445, metadata=None))), (22725, (712, PredictedToken(token=' Orange', prob=2.4400651454925537e-07, logit=7.625, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     int_prediction=['\" Orange\"[22725] (p=0.719, logit=22.000)', '\" An\"[1556] (p=0.067, logit=19.625)', '\" The\"[578] (p=0.059, logit=19.500)', '\" Option\"[7104] (p=0.041, logit=19.125)', '\" L\"[445] (p=0.028, logit=18.750)']\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     int_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.71875, logit=22.0, token_id=22725, metadata=None))), (445, (5, PredictedToken(token=' L', prob=0.02783203125, logit=18.75, token_id=445, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0191650390625, logit=18.375, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.754, logit=22.250)', '\" The\"[578] (p=0.115, logit=20.375)', '\" Among\"[22395] (p=0.054, logit=19.625)', '\" A\"[362] (p=0.033, logit=19.125)', '\" B\"[426] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.836, logit=22.500)', '\" The\"[578] (p=0.068, logit=20.000)', '\" Among\"[22395] (p=0.042, logit=19.500)', '\" A\"[362] (p=0.032, logit=19.250)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.8359375, logit=22.5, token_id=356, metadata=None))), (4923, (71, PredictedToken(token=' Sk', prob=2.6106834411621094e-05, logit=12.125, token_id=4923, metadata=None))), (48665, (177, PredictedToken(token=' Raspberry', prob=4.5299530029296875e-06, logit=10.375, token_id=48665, metadata=None))), (40975, (227, PredictedToken(token=' Marker', prob=2.9206275939941406e-06, logit=9.9375, token_id=40975, metadata=None))), (6150, (408, PredictedToken(token=' School', prob=9.499490261077881e-07, logit=8.8125, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     int_prediction=['\" Raspberry\"[48665] (p=0.457, logit=20.750)', '\" C\"[356] (p=0.277, logit=20.250)', '\" The\"[578] (p=0.090, logit=19.125)', '\" Among\"[22395] (p=0.048, logit=18.500)', '\" A\"[362] (p=0.042, logit=18.375)']\n",
      "2025-09-16 09:55:14 src.selection.optimization INFO     int_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.45703125, logit=20.75, token_id=48665, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.27734375, logit=20.25, token_id=356, metadata=None))), (40975, (75, PredictedToken(token=' Marker', prob=6.818771362304688e-05, logit=11.9375, token_id=40975, metadata=None))), (4923, (89, PredictedToken(token=' Sk', prob=4.673004150390625e-05, logit=11.5625, token_id=4923, metadata=None))), (6150, (163, PredictedToken(token=' School', prob=1.5139579772949219e-05, logit=10.4375, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:15 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:15 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.789, logit=21.625)', '\" The\"[578] (p=0.083, logit=19.375)', '\" A\"[362] (p=0.039, logit=18.625)', '\" Among\"[22395] (p=0.035, logit=18.500)', '\" (\"[320] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.750, logit=20.625)', '\" The\"[578] (p=0.070, logit=18.250)', '\" An\"[1556] (p=0.048, logit=17.875)', '\" Among\"[22395] (p=0.029, logit=17.375)', '\" It\"[1102] (p=0.011, logit=16.375)']\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.75, logit=20.625, token_id=87213, metadata=None))), (45805, (6, PredictedToken(token=' Cherry', prob=0.00836181640625, logit=16.125, token_id=45805, metadata=None))), (91782, (368, PredictedToken(token=' Shorts', prob=6.318092346191406e-06, logit=8.9375, token_id=91782, metadata=None))), (28131, (1651, PredictedToken(token=' Golf', prob=7.7858567237854e-07, logit=6.84375, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     int_prediction=['\" Golf\"[28131] (p=0.299, logit=18.875)', '\" Shorts\"[91782] (p=0.205, logit=18.500)', '\" Cherry\"[45805] (p=0.205, logit=18.500)', '\" None\"[2290] (p=0.052, logit=17.125)', '\" The\"[578] (p=0.052, logit=17.125)']\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     int_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.298828125, logit=18.875, token_id=28131, metadata=None))), (45805, (2, PredictedToken(token=' Cherry', prob=0.205078125, logit=18.5, token_id=45805, metadata=None))), (91782, (3, PredictedToken(token=' Shorts', prob=0.205078125, logit=18.5, token_id=91782, metadata=None))), (87213, (6, PredictedToken(token=' Oven', prob=0.031494140625, logit=16.625, token_id=87213, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:15 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:15 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:55:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     patch_prediction=['\" Television\"[41445] (p=0.520, logit=20.125)', '\" Microwave\"[98641] (p=0.191, logit=19.125)', '\" Among\"[22395] (p=0.090, logit=18.375)', '\" The\"[578] (p=0.062, logit=18.000)', '\" A\"[362] (p=0.018, logit=16.750)']\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.824, logit=21.375)', '\" None\"[2290] (p=0.068, logit=18.875)', '\" The\"[578] (p=0.032, logit=18.125)', '\" A\"[362] (p=0.019, logit=17.625)', '\" There\"[2684] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.82421875, logit=21.375, token_id=33578, metadata=None))), (1630, (10, PredictedToken(token=' X', prob=0.0023193359375, logit=15.5, token_id=1630, metadata=None))), (445, (12, PredictedToken(token=' L', prob=0.001922607421875, logit=15.3125, token_id=445, metadata=None))), (33711, (14, PredictedToken(token=' Suit', prob=0.00124359130859375, logit=14.875, token_id=33711, metadata=None))), (14642, (45, PredictedToken(token=' Phone', prob=0.000148773193359375, logit=12.75, token_id=14642, metadata=None))), (82994, (120, PredictedToken(token=' Toilet', prob=2.276897430419922e-05, logit=10.875, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.820, logit=22.125)', '\" The\"[578] (p=0.052, logit=19.375)', '\" A\"[362] (p=0.046, logit=19.250)', '\" None\"[2290] (p=0.022, logit=18.500)', '\" Phone\"[14642] (p=0.019, logit=18.375)']\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.8203125, logit=22.125, token_id=1630, metadata=None))), (14642, (5, PredictedToken(token=' Phone', prob=0.019287109375, logit=18.375, token_id=14642, metadata=None))), (445, (15, PredictedToken(token=' L', prob=0.00122833251953125, logit=15.625, token_id=445, metadata=None))), (33711, (51, PredictedToken(token=' Suit', prob=0.0001220703125, logit=13.3125, token_id=33711, metadata=None))), (82994, (80, PredictedToken(token=' Toilet', prob=5.078315734863281e-05, logit=12.4375, token_id=82994, metadata=None))), (33578, (103, PredictedToken(token=' Palm', prob=3.2901763916015625e-05, logit=12.0, token_id=33578, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:16 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.852, logit=21.000)', '\" The\"[578] (p=0.048, logit=18.125)', '\" A\"[362] (p=0.026, logit=17.500)', '\" Among\"[22395] (p=0.020, logit=17.250)', '\" None\"[2290] (p=0.008, logit=16.375)']\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.633, logit=22.375)', '\" The\"[578] (p=0.159, logit=21.000)', '\" A\"[362] (p=0.125, logit=20.750)', '\" Among\"[22395] (p=0.046, logit=19.750)', '\" It\"[1102] (p=0.008, logit=18.000)']\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.6328125, logit=22.375, token_id=3341, metadata=None))), (14937, (41, PredictedToken(token=' Ash', prob=0.00012063980102539062, logit=13.8125, token_id=14937, metadata=None))), (735, (58, PredictedToken(token=' K', prob=5.030632019042969e-05, logit=12.9375, token_id=735, metadata=None))), (16488, (103, PredictedToken(token=' Bat', prob=1.7404556274414062e-05, logit=11.875, token_id=16488, metadata=None))), (6031, (266, PredictedToken(token=' Bro', prob=2.0712614059448242e-06, logit=9.75, token_id=6031, metadata=None))), (23910, (1558, PredictedToken(token=' Pear', prob=1.0337680578231812e-07, logit=6.75, token_id=23910, metadata=None)))])\n",
      "2025-09-16 09:55:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     int_prediction=['\" Pear\"[23910] (p=0.730, logit=21.375)', '\" The\"[578] (p=0.099, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=18.625)', '\" Ash\"[14937] (p=0.032, logit=18.250)', '\" It\"[1102] (p=0.017, logit=17.625)']\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     int_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.73046875, logit=21.375, token_id=23910, metadata=None))), (14937, (4, PredictedToken(token=' Ash', prob=0.0322265625, logit=18.25, token_id=14937, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.00634765625, logit=16.625, token_id=6031, metadata=None))), (3341, (57, PredictedToken(token=' Car', prob=0.0001583099365234375, logit=12.9375, token_id=3341, metadata=None))), (735, (117, PredictedToken(token=' K', prob=2.586841583251953e-05, logit=11.125, token_id=735, metadata=None))), (16488, (203, PredictedToken(token=' Bat', prob=8.940696716308594e-06, logit=10.0625, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:17 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.512, logit=20.750)', '\" The\"[578] (p=0.166, logit=19.625)', '\" A\"[362] (p=0.166, logit=19.625)', '\" Among\"[22395] (p=0.101, logit=19.125)', '\" \"[220] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.703, logit=20.375)', '\" The\"[578] (p=0.107, logit=18.500)', '\" Among\"[22395] (p=0.045, logit=17.625)', '\" A\"[362] (p=0.031, logit=17.250)', '\" B\"[426] (p=0.013, logit=16.375)']\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.703125, logit=20.375, token_id=67629, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.0128173828125, logit=16.375, token_id=426, metadata=None))), (57225, (40, PredictedToken(token=' Laptop', prob=0.000499725341796875, logit=13.125, token_id=57225, metadata=None))), (36943, (81, PredictedToken(token=' Folder', prob=8.630752563476562e-05, logit=11.375, token_id=36943, metadata=None))), (30616, (327, PredictedToken(token=' Rice', prob=7.092952728271484e-06, logit=8.875, token_id=30616, metadata=None)))])\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.820, logit=20.375)', '\" The\"[578] (p=0.060, logit=17.750)', '\" Among\"[22395] (p=0.025, logit=16.875)', '\" It\"[1102] (p=0.010, logit=15.938)', '\" Sport\"[18707] (p=0.009, logit=15.875)']\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.8203125, logit=20.375, token_id=30616, metadata=None))), (426, (20, PredictedToken(token=' B', prob=0.00115966796875, logit=13.8125, token_id=426, metadata=None))), (67629, (84, PredictedToken(token=' Helmet', prob=7.915496826171875e-05, logit=11.125, token_id=67629, metadata=None))), (36943, (2550, PredictedToken(token=' Folder', prob=3.334134817123413e-07, logit=5.65625, token_id=36943, metadata=None))), (57225, (2678, PredictedToken(token=' Laptop', prob=3.129243850708008e-07, logit=5.59375, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:17 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:17 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:55:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     patch_prediction=['\" Tennis\"[58251] (p=0.727, logit=20.875)', '\" The\"[578] (p=0.086, logit=18.750)', '\" A\"[362] (p=0.052, logit=18.250)', '\" Among\"[22395] (p=0.032, logit=17.750)', '\" Option\"[7104] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.812, logit=22.625)', '\" The\"[578] (p=0.076, logit=20.250)', '\" A\"[362] (p=0.059, logit=20.000)', '\" Among\"[22395] (p=0.031, logit=19.375)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.8125, logit=22.625, token_id=3341, metadata=None))), (57551, (83, PredictedToken(token=' Sink', prob=1.3589859008789062e-05, logit=11.625, token_id=57551, metadata=None))), (38673, (102, PredictedToken(token=' Yoga', prob=9.298324584960938e-06, logit=11.25, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.844, logit=22.125)', '\" The\"[578] (p=0.061, logit=19.500)', '\" A\"[362] (p=0.037, logit=19.000)', '\" Among\"[22395] (p=0.026, logit=18.625)', '\" Yoga\"[38673] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.84375, logit=22.125, token_id=3341, metadata=None))), (38673, (5, PredictedToken(token=' Yoga', prob=0.004425048828125, logit=16.875, token_id=38673, metadata=None))), (57551, (6, PredictedToken(token=' Sink', prob=0.003448486328125, logit=16.625, token_id=57551, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:18 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:18 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.840, logit=22.625)', '\" A\"[362] (p=0.078, logit=20.250)', '\" The\"[578] (p=0.042, logit=19.625)', '\" Among\"[22395] (p=0.017, logit=18.750)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.867, logit=22.750)', '\" The\"[578] (p=0.071, logit=20.250)', '\" An\"[1556] (p=0.020, logit=19.000)', '\" Among\"[22395] (p=0.011, logit=18.375)', '\" Accord\"[80657] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.8671875, logit=22.75, token_id=11683, metadata=None))), (6150, (138, PredictedToken(token=' School', prob=6.854534149169922e-06, logit=11.0, token_id=6150, metadata=None))), (74968, (142, PredictedToken(token=' Razor', prob=6.4373016357421875e-06, logit=10.9375, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:55:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.910, logit=21.875)', '\" The\"[578] (p=0.024, logit=18.250)', '\" Razor\"[74968] (p=0.017, logit=17.875)', '\" Among\"[22395] (p=0.005, logit=16.625)', '\" A\"[362] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.91015625, logit=21.875, token_id=6150, metadata=None))), (74968, (3, PredictedToken(token=' Razor', prob=0.0167236328125, logit=17.875, token_id=74968, metadata=None))), (11683, (35, PredictedToken(token=' Acc', prob=0.000209808349609375, logit=13.5, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:19 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:19 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.836, logit=22.875)', '\" The\"[578] (p=0.078, logit=20.500)', '\" A\"[362] (p=0.042, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" (\"[320] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.754, logit=22.125)', '\" The\"[578] (p=0.131, logit=20.375)', '\" A\"[362] (p=0.048, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.750)', '\" (\"[320] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.75390625, logit=22.125, token_id=31181, metadata=None))), (6914, (49, PredictedToken(token=' Let', prob=8.726119995117188e-05, logit=13.0625, token_id=6914, metadata=None))), (23910, (81, PredictedToken(token=' Pear', prob=2.6702880859375e-05, logit=11.875, token_id=23910, metadata=None)))])\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.871, logit=22.000)', '\" The\"[578] (p=0.049, logit=19.125)', '\" Pear\"[23910] (p=0.026, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" (\"[320] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.87109375, logit=22.0, token_id=6914, metadata=None))), (23910, (3, PredictedToken(token=' Pear', prob=0.0262451171875, logit=18.5, token_id=23910, metadata=None))), (31181, (121, PredictedToken(token=' Clar', prob=1.2814998626708984e-05, logit=10.875, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:19 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:55:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.859, logit=21.250)', '\" The\"[578] (p=0.043, logit=18.250)', '\" A\"[362] (p=0.033, logit=18.000)', '\" Among\"[22395] (p=0.016, logit=17.250)', '\" hair\"[7013] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.848, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.042, logit=19.250)', '\" socks\"[40086] (p=0.004, logit=17.000)', '\" A\"[362] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.84765625, logit=22.25, token_id=328, metadata=None))), (469, (8, PredictedToken(token=' E', prob=0.00238037109375, logit=16.375, token_id=469, metadata=None))), (41342, (39, PredictedToken(token=' Hockey', prob=0.00015163421630859375, logit=13.625, token_id=41342, metadata=None))), (82994, (102, PredictedToken(token=' Toilet', prob=1.9311904907226562e-05, logit=11.5625, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.416, logit=21.000)', '\" E\"[469] (p=0.285, logit=20.625)', '\" The\"[578] (p=0.152, logit=20.000)', '\" An\"[1556] (p=0.050, logit=18.875)', '\" Among\"[22395] (p=0.034, logit=18.500)']\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.416015625, logit=21.0, token_id=82994, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.28515625, logit=20.625, token_id=469, metadata=None))), (328, (22, PredictedToken(token=' S', prob=0.00090789794921875, logit=14.875, token_id=328, metadata=None))), (41342, (92, PredictedToken(token=' Hockey', prob=4.2438507080078125e-05, logit=11.8125, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:20 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:20 src.selection.optimization DEBUG    torch.Size([3, 27])\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.840, logit=21.625)', '\" The\"[578] (p=0.054, logit=18.875)', '\" None\"[2290] (p=0.029, logit=18.250)', '\" Option\"[7104] (p=0.012, logit=17.375)', '\" Among\"[22395] (p=0.011, logit=17.250)']\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.789, logit=22.125)', '\" b\"[293] (p=0.083, logit=19.875)', '\" A\"[362] (p=0.035, logit=19.000)', '\" The\"[578] (p=0.027, logit=18.750)', '\" (\"[320] (p=0.021, logit=18.500)']\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.7890625, logit=22.125, token_id=426, metadata=None))), (55405, (11, PredictedToken(token=' Orch', prob=0.001953125, logit=16.125, token_id=55405, metadata=None))), (65329, (251, PredictedToken(token=' Elm', prob=2.1457672119140625e-06, logit=9.3125, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:55:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     int_prediction=['\" Orch\"[55405] (p=0.699, logit=20.375)', '\" Elm\"[65329] (p=0.065, logit=18.000)', '\" The\"[578] (p=0.035, logit=17.375)', '\" (\"[320] (p=0.035, logit=17.375)', '\" orch\"[41245] (p=0.031, logit=17.250)']\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     int_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.69921875, logit=20.375, token_id=55405, metadata=None))), (65329, (2, PredictedToken(token=' Elm', prob=0.06494140625, logit=18.0, token_id=65329, metadata=None))), (426, (7, PredictedToken(token=' B', prob=0.016357421875, logit=16.625, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:21 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.824, logit=22.500)', '\" The\"[578] (p=0.077, logit=20.125)', '\" Among\"[22395] (p=0.068, logit=20.000)', '\" A\"[362] (p=0.005, logit=17.375)', '\" z\"[1167] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     clean_prediction=['\" Soap\"[61731] (p=0.863, logit=21.750)', '\" Among\"[22395] (p=0.049, logit=18.875)', '\" The\"[578] (p=0.043, logit=18.750)', '\" SOAP\"[64332] (p=0.007, logit=17.000)', '\" Out\"[4470] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     clean_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.86328125, logit=21.75, token_id=61731, metadata=None))), (4923, (16, PredictedToken(token=' Sk', prob=0.000614166259765625, logit=14.5, token_id=4923, metadata=None))), (41785, (31, PredictedToken(token=' Spin', prob=0.000255584716796875, logit=13.625, token_id=41785, metadata=None))), (66821, (77, PredictedToken(token=' Iris', prob=5.030632019042969e-05, logit=12.0, token_id=66821, metadata=None))), (10164, (76, PredictedToken(token=' Water', prob=5.030632019042969e-05, logit=12.0, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.902, logit=21.750)', '\" Among\"[22395] (p=0.021, logit=18.000)', '\" The\"[578] (p=0.019, logit=17.875)', '\" Iris\"[66821] (p=0.010, logit=17.250)', '\" Spin\"[41785] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.90234375, logit=21.75, token_id=10164, metadata=None))), (66821, (4, PredictedToken(token=' Iris', prob=0.01007080078125, logit=17.25, token_id=66821, metadata=None))), (41785, (5, PredictedToken(token=' Spin', prob=0.00689697265625, logit=16.875, token_id=41785, metadata=None))), (4923, (18, PredictedToken(token=' Sk', prob=0.000934600830078125, logit=14.875, token_id=4923, metadata=None))), (61731, (83, PredictedToken(token=' Soap', prob=4.649162292480469e-05, logit=11.875, token_id=61731, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:21 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:21 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:55:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.664, logit=21.875)', '\" The\"[578] (p=0.147, logit=20.375)', '\" Among\"[22395] (p=0.090, logit=19.875)', '\" A\"[362] (p=0.062, logit=19.500)', '\" sun\"[7160] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.797, logit=22.500)', '\" A\"[362] (p=0.065, logit=20.000)', '\" The\"[578] (p=0.058, logit=19.875)', '\" Among\"[22395] (p=0.045, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.796875, logit=22.5, token_id=45332, metadata=None))), (15429, (6, PredictedToken(token=' Hospital', prob=0.003692626953125, logit=17.125, token_id=15429, metadata=None))), (17810, (120, PredictedToken(token=' Cat', prob=1.2516975402832031e-05, logit=11.4375, token_id=17810, metadata=None))), (55870, (181, PredictedToken(token=' Jacket', prob=4.887580871582031e-06, logit=10.5, token_id=55870, metadata=None))), (47759, (200, PredictedToken(token=' Guitar', prob=4.32133674621582e-06, logit=10.375, token_id=47759, metadata=None))), (66821, (423, PredictedToken(token=' Iris', prob=1.0281801223754883e-06, logit=8.9375, token_id=66821, metadata=None)))])\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.895, logit=22.500)', '\" Cat\"[17810] (p=0.031, logit=19.125)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" The\"[578] (p=0.019, logit=18.625)', '\" An\"[1556] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.89453125, logit=22.5, token_id=66821, metadata=None))), (17810, (2, PredictedToken(token=' Cat', prob=0.0306396484375, logit=19.125, token_id=17810, metadata=None))), (55870, (18, PredictedToken(token=' Jacket', prob=0.00052642822265625, logit=15.0625, token_id=55870, metadata=None))), (45332, (72, PredictedToken(token=' Boat', prob=2.7894973754882812e-05, logit=12.125, token_id=45332, metadata=None))), (47759, (128, PredictedToken(token=' Guitar', prob=7.987022399902344e-06, logit=10.875, token_id=47759, metadata=None))), (15429, (279, PredictedToken(token=' Hospital', prob=1.780688762664795e-06, logit=9.375, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:22 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:22 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     patch_prediction=['\" Chain\"[29625] (p=0.863, logit=22.125)', '\" The\"[578] (p=0.049, logit=19.250)', '\" A\"[362] (p=0.033, logit=18.875)', '\" Among\"[22395] (p=0.018, logit=18.250)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:55:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.676, logit=21.250)', '\" The\"[578] (p=0.104, logit=19.375)', '\" A\"[362] (p=0.091, logit=19.250)', '\" Among\"[22395] (p=0.055, logit=18.750)', '\" Option\"[7104] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.67578125, logit=21.25, token_id=27171, metadata=None))), (58600, (22, PredictedToken(token=' Charm', prob=0.000789642333984375, logit=14.5, token_id=58600, metadata=None))), (1901, (47, PredictedToken(token=' Z', prob=0.0002002716064453125, logit=13.125, token_id=1901, metadata=None))), (98028, (94, PredictedToken(token=' Bamboo', prob=4.458427429199219e-05, logit=11.625, token_id=98028, metadata=None)))])\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.531, logit=20.375)', '\" Charm\"[58600] (p=0.119, logit=18.875)', '\" Bamboo\"[98028] (p=0.093, logit=18.625)', '\" Among\"[22395] (p=0.072, logit=18.375)', '\" The\"[578] (p=0.072, logit=18.375)']\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.53125, logit=20.375, token_id=1901, metadata=None))), (58600, (2, PredictedToken(token=' Charm', prob=0.11865234375, logit=18.875, token_id=58600, metadata=None))), (98028, (3, PredictedToken(token=' Bamboo', prob=0.0927734375, logit=18.625, token_id=98028, metadata=None))), (27171, (324, PredictedToken(token=' Coffee', prob=6.9141387939453125e-06, logit=9.125, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:23 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:23 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.805, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" A\"[362] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.027, logit=18.875)', '\" Option\"[7104] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.793, logit=22.000)', '\" The\"[578] (p=0.065, logit=19.500)', '\" A\"[362] (p=0.065, logit=19.500)', '\" Among\"[22395] (p=0.035, logit=18.875)', '\" Option\"[7104] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.79296875, logit=22.0, token_id=356, metadata=None))), (74574, (11, PredictedToken(token=' Violet', prob=0.0018463134765625, logit=15.9375, token_id=74574, metadata=None))), (91263, (15, PredictedToken(token=' Binder', prob=0.0009918212890625, logit=15.3125, token_id=91263, metadata=None))), (2057, (22, PredictedToken(token=' To', prob=0.000598907470703125, logit=14.8125, token_id=2057, metadata=None)))])\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.957, logit=22.625)', '\" The\"[578] (p=0.012, logit=18.250)', '\" Among\"[22395] (p=0.009, logit=18.000)', '\" A\"[362] (p=0.003, logit=16.750)', '\" violet\"[80836] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.95703125, logit=22.625, token_id=74574, metadata=None))), (91263, (9, PredictedToken(token=' Binder', prob=0.00144195556640625, logit=16.125, token_id=91263, metadata=None))), (2057, (10, PredictedToken(token=' To', prob=0.00077056884765625, logit=15.5, token_id=2057, metadata=None))), (356, (29, PredictedToken(token=' C', prob=0.00011110305786132812, logit=13.5625, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:23 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.789, logit=21.125)', '\" None\"[2290] (p=0.073, logit=18.750)', '\" A\"[362] (p=0.039, logit=18.125)', '\" The\"[578] (p=0.024, logit=17.625)', '\" PIN\"[28228] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.781, logit=20.750)', '\" The\"[578] (p=0.073, logit=18.375)', '\" Among\"[22395] (p=0.034, logit=17.625)', '\" A\"[362] (p=0.021, logit=17.125)', '\" Option\"[7104] (p=0.009, logit=16.250)']\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.78125, logit=20.75, token_id=67629, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.00677490234375, logit=16.0, token_id=23262, metadata=None))), (426, (24, PredictedToken(token=' B', prob=0.00103759765625, logit=14.125, token_id=426, metadata=None))), (37326, (74, PredictedToken(token=' Swe', prob=8.535385131835938e-05, logit=11.625, token_id=37326, metadata=None))), (48665, (637, PredictedToken(token=' Raspberry', prob=2.205371856689453e-06, logit=7.96875, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.887, logit=21.875)', '\" The\"[578] (p=0.030, logit=18.500)', '\" A\"[362] (p=0.016, logit=17.875)', '\" Among\"[22395] (p=0.014, logit=17.750)', '\" b\"[293] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.88671875, logit=21.875, token_id=426, metadata=None))), (23262, (6, PredictedToken(token=' Comb', prob=0.007659912109375, logit=17.125, token_id=23262, metadata=None))), (37326, (7, PredictedToken(token=' Swe', prob=0.00408935546875, logit=16.5, token_id=37326, metadata=None))), (67629, (11, PredictedToken(token=' Helmet', prob=0.00182342529296875, logit=15.6875, token_id=67629, metadata=None))), (48665, (83, PredictedToken(token=' Raspberry', prob=3.790855407714844e-05, logit=11.8125, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:24 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     patch_prediction=['\" Refriger\"[75258] (p=0.598, logit=21.500)', '\" The\"[578] (p=0.150, logit=20.125)', '\" A\"[362] (p=0.150, logit=20.125)', '\" Among\"[22395] (p=0.049, logit=19.000)', '\" F\"[435] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:55:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.867, logit=22.125)', '\" The\"[578] (p=0.049, logit=19.250)', '\" Among\"[22395] (p=0.034, logit=18.875)', '\" A\"[362] (p=0.023, logit=18.500)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.8671875, logit=22.125, token_id=356, metadata=None))), (79028, (11, PredictedToken(token=' Hick', prob=0.001220703125, logit=15.5625, token_id=79028, metadata=None))), (800, (13, PredictedToken(token=' St', prob=0.0008392333984375, logit=15.1875, token_id=800, metadata=None))), (37326, (14, PredictedToken(token=' Swe', prob=0.000789642333984375, logit=15.125, token_id=37326, metadata=None))), (88668, (92, PredictedToken(token=' Blender', prob=2.2411346435546875e-05, logit=11.5625, token_id=88668, metadata=None)))])\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     int_prediction=['\" Blender\"[88668] (p=0.381, logit=19.750)', '\" St\"[800] (p=0.231, logit=19.250)', '\" Hick\"[79028] (p=0.085, logit=18.250)', '\" The\"[578] (p=0.075, logit=18.125)', '\" A\"[362] (p=0.066, logit=18.000)']\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     int_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.380859375, logit=19.75, token_id=88668, metadata=None))), (800, (2, PredictedToken(token=' St', prob=0.2314453125, logit=19.25, token_id=800, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.0849609375, logit=18.25, token_id=79028, metadata=None))), (37326, (6, PredictedToken(token=' Swe', prob=0.04541015625, logit=17.625, token_id=37326, metadata=None))), (356, (32, PredictedToken(token=' C', prob=0.0006103515625, logit=13.3125, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:25 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.891, logit=22.000)', '\" The\"[578] (p=0.039, logit=18.875)', '\" Among\"[22395] (p=0.030, logit=18.625)', '\" A\"[362] (p=0.010, logit=17.500)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     clean_prediction=['\" Mall\"[32498] (p=0.773, logit=21.750)', '\" The\"[578] (p=0.082, logit=19.500)', '\" A\"[362] (p=0.082, logit=19.500)', '\" Among\"[22395] (p=0.026, logit=18.375)', '\" None\"[2290] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     clean_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.7734375, logit=21.75, token_id=32498, metadata=None))), (393, (92, PredictedToken(token=' P', prob=2.7298927307128906e-05, logit=11.5, token_id=393, metadata=None))), (20918, (110, PredictedToken(token=' Magn', prob=2.002716064453125e-05, logit=11.1875, token_id=20918, metadata=None))), (47589, (180, PredictedToken(token=' Basketball', prob=6.9141387939453125e-06, logit=10.125, token_id=47589, metadata=None))), (22607, (258, PredictedToken(token=' Cow', prob=3.471970558166504e-06, logit=9.4375, token_id=22607, metadata=None)))])\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     int_prediction=['\" Magn\"[20918] (p=0.824, logit=21.625)', '\" The\"[578] (p=0.067, logit=19.125)', '\" A\"[362] (p=0.025, logit=18.125)', '\" Among\"[22395] (p=0.017, logit=17.750)', '\" None\"[2290] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     int_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.82421875, logit=21.625, token_id=20918, metadata=None))), (32498, (11, PredictedToken(token=' Mall', prob=0.002960205078125, logit=16.0, token_id=32498, metadata=None))), (393, (13, PredictedToken(token=' P', prob=0.0027923583984375, logit=15.9375, token_id=393, metadata=None))), (22607, (107, PredictedToken(token=' Cow', prob=2.9087066650390625e-05, logit=11.375, token_id=22607, metadata=None))), (47589, (324, PredictedToken(token=' Basketball', prob=3.2633543014526367e-06, logit=9.1875, token_id=47589, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:25 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:55:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.816, logit=22.375)', '\" The\"[578] (p=0.086, logit=20.125)', '\" A\"[362] (p=0.036, logit=19.250)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" d\"[294] (p=0.013, logit=18.250)']\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.781, logit=21.875)', '\" The\"[578] (p=0.073, logit=19.500)', '\" A\"[362] (p=0.056, logit=19.250)', '\" Among\"[22395] (p=0.034, logit=18.750)', '\" C\"[356] (p=0.013, logit=17.750)']\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.78125, logit=21.875, token_id=22607, metadata=None))), (469, (22, PredictedToken(token=' E', prob=0.000431060791015625, logit=14.375, token_id=469, metadata=None))), (43950, (70, PredictedToken(token=' Lav', prob=4.267692565917969e-05, logit=12.0625, token_id=43950, metadata=None))), (16183, (142, PredictedToken(token=' Hel', prob=9.5367431640625e-06, logit=10.5625, token_id=16183, metadata=None))), (65197, (208, PredictedToken(token=' Surf', prob=4.500150680541992e-06, logit=9.8125, token_id=65197, metadata=None))), (39794, (1508, PredictedToken(token=' Desk', prob=2.384185791015625e-07, logit=6.875, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.379, logit=19.750)', '\" Lav\"[43950] (p=0.260, logit=19.375)', '\" The\"[578] (p=0.139, logit=18.750)', '\" A\"[362] (p=0.051, logit=17.750)', '\" Among\"[22395] (p=0.040, logit=17.500)']\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.37890625, logit=19.75, token_id=22607, metadata=None))), (43950, (2, PredictedToken(token=' Lav', prob=0.259765625, logit=19.375, token_id=43950, metadata=None))), (469, (12, PredictedToken(token=' E', prob=0.00506591796875, logit=15.4375, token_id=469, metadata=None))), (16183, (562, PredictedToken(token=' Hel', prob=2.9802322387695312e-06, logit=8.0, token_id=16183, metadata=None))), (65197, (1764, PredictedToken(token=' Surf', prob=6.668269634246826e-07, logit=6.5, token_id=65197, metadata=None))), (39794, (2235, PredictedToken(token=' Desk', prob=4.7124922275543213e-07, logit=6.15625, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:26 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.859, logit=22.000)', '\" A\"[362] (p=0.055, logit=19.250)', '\" The\"[578] (p=0.043, logit=19.000)', '\" Among\"[22395] (p=0.016, logit=18.000)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.637, logit=21.625)', '\" The\"[578] (p=0.143, logit=20.125)', '\" Among\"[22395] (p=0.098, logit=19.750)', '\" A\"[362] (p=0.067, logit=19.375)', '\" C\"[356] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.63671875, logit=21.625, token_id=27171, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.00799560546875, logit=17.25, token_id=356, metadata=None))), (8868, (43, PredictedToken(token=' Blue', prob=0.0001468658447265625, logit=13.25, token_id=8868, metadata=None))), (50159, (49, PredictedToken(token=' Sco', prob=0.00011444091796875, logit=13.0, token_id=50159, metadata=None))), (4923, (54, PredictedToken(token=' Sk', prob=8.916854858398438e-05, logit=12.75, token_id=4923, metadata=None))), (11896, (139, PredictedToken(token=' Library', prob=1.1324882507324219e-05, logit=10.6875, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.812, logit=22.125)', '\" The\"[578] (p=0.097, logit=20.000)', '\" Among\"[22395] (p=0.028, logit=18.750)', '\" A\"[362] (p=0.019, logit=18.375)', '\" Sco\"[50159] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.8125, logit=22.125, token_id=11896, metadata=None))), (50159, (5, PredictedToken(token=' Sco', prob=0.0062255859375, logit=17.25, token_id=50159, metadata=None))), (27171, (23, PredictedToken(token=' Coffee', prob=0.0004787445068359375, logit=14.6875, token_id=27171, metadata=None))), (356, (25, PredictedToken(token=' C', prob=0.000396728515625, logit=14.5, token_id=356, metadata=None))), (4923, (39, PredictedToken(token=' Sk', prob=0.00018787384033203125, logit=13.75, token_id=4923, metadata=None))), (8868, (449, PredictedToken(token=' Blue', prob=1.1175870895385742e-06, logit=8.625, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:27 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:27 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.711, logit=21.000)', '\" The\"[578] (p=0.109, logit=19.125)', '\" Among\"[22395] (p=0.066, logit=18.625)', '\" A\"[362] (p=0.035, logit=18.000)', '\" B\"[426] (p=0.017, logit=17.250)']\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.902, logit=22.500)', '\" Among\"[22395] (p=0.027, logit=19.000)', '\" The\"[578] (p=0.024, logit=18.875)', '\" None\"[2290] (p=0.015, logit=18.375)', '\" There\"[2684] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.90234375, logit=22.5, token_id=41785, metadata=None))), (6690, (7, PredictedToken(token=' Air', prob=0.0032501220703125, logit=16.875, token_id=6690, metadata=None))), (432, (36, PredictedToken(token=' R', prob=0.00011157989501953125, logit=13.5, token_id=432, metadata=None))), (20918, (64, PredictedToken(token=' Magn', prob=3.8623809814453125e-05, logit=12.4375, token_id=20918, metadata=None))), (68554, (334, PredictedToken(token=' Gloves', prob=1.5869736671447754e-06, logit=9.25, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:55:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     int_prediction=['\" Magn\"[20918] (p=0.746, logit=21.875)', '\" Spin\"[41785] (p=0.069, logit=19.500)', '\" None\"[2290] (p=0.069, logit=19.500)', '\" The\"[578] (p=0.037, logit=18.875)', '\" Among\"[22395] (p=0.022, logit=18.375)']\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     int_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.74609375, logit=21.875, token_id=20918, metadata=None))), (41785, (3, PredictedToken(token=' Spin', prob=0.0693359375, logit=19.5, token_id=41785, metadata=None))), (6690, (32, PredictedToken(token=' Air', prob=0.0003204345703125, logit=14.125, token_id=6690, metadata=None))), (432, (35, PredictedToken(token=' R', prob=0.00028228759765625, logit=14.0, token_id=432, metadata=None))), (68554, (111, PredictedToken(token=' Gloves', prob=2.47955322265625e-05, logit=11.5625, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:28 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.676, logit=21.125)', '\" An\"[1556] (p=0.117, logit=19.375)', '\" The\"[578] (p=0.091, logit=19.125)', '\" Among\"[22395] (p=0.043, logit=18.375)', '\" E\"[469] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.746, logit=21.625)', '\" A\"[362] (p=0.089, logit=19.500)', '\" The\"[578] (p=0.069, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" Only\"[8442] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.74609375, logit=21.625, token_id=356, metadata=None))), (98028, (102, PredictedToken(token=' Bamboo', prob=2.47955322265625e-05, logit=11.3125, token_id=98028, metadata=None))), (36943, (161, PredictedToken(token=' Folder', prob=8.52346420288086e-06, logit=10.25, token_id=36943, metadata=None))), (91782, (441, PredictedToken(token=' Shorts', prob=1.3932585716247559e-06, logit=8.4375, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.625, logit=20.500)', '\" The\"[578] (p=0.096, logit=18.625)', '\" A\"[362] (p=0.096, logit=18.625)', '\" Among\"[22395] (p=0.045, logit=17.875)', '\" Shorts\"[91782] (p=0.027, logit=17.375)']\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.625, logit=20.5, token_id=36943, metadata=None))), (91782, (5, PredictedToken(token=' Shorts', prob=0.0274658203125, logit=17.375, token_id=91782, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.024169921875, logit=17.25, token_id=356, metadata=None))), (98028, (35, PredictedToken(token=' Bamboo', prob=0.000606536865234375, logit=13.5625, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:28 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.570, logit=22.375)', '\" The\"[578] (p=0.210, logit=21.375)', '\" A\"[362] (p=0.128, logit=20.875)', '\" Among\"[22395] (p=0.053, logit=20.000)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     clean_prediction=['\" Strawberry\"[89077] (p=0.602, logit=21.250)', '\" The\"[578] (p=0.194, logit=20.125)', '\" Among\"[22395] (p=0.081, logit=19.250)', '\" A\"[362] (p=0.072, logit=19.125)', '\" strawberry\"[73700] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     clean_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.6015625, logit=21.25, token_id=89077, metadata=None))), (445, (29, PredictedToken(token=' L', prob=0.000331878662109375, logit=13.75, token_id=445, metadata=None))), (3420, (108, PredictedToken(token=' Trump', prob=2.2530555725097656e-05, logit=11.0625, token_id=3420, metadata=None))), (11452, (135, PredictedToken(token=' Head', prob=1.5497207641601562e-05, logit=10.6875, token_id=11452, metadata=None))), (13000, (321, PredictedToken(token=' Van', prob=3.0547380447387695e-06, logit=9.0625, token_id=13000, metadata=None)))])\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.844, logit=22.625)', '\" The\"[578] (p=0.089, logit=20.375)', '\" Among\"[22395] (p=0.022, logit=19.000)', '\" A\"[362] (p=0.009, logit=18.125)', '\" VAN\"[97753] (p=0.007, logit=17.875)']\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.84375, logit=22.625, token_id=13000, metadata=None))), (11452, (6, PredictedToken(token=' Head', prob=0.00567626953125, logit=17.625, token_id=11452, metadata=None))), (3420, (7, PredictedToken(token=' Trump', prob=0.0030364990234375, logit=17.0, token_id=3420, metadata=None))), (445, (9, PredictedToken(token=' L', prob=0.00162506103515625, logit=16.375, token_id=445, metadata=None))), (89077, (86, PredictedToken(token=' Strawberry', prob=1.6927719116210938e-05, logit=11.8125, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:29 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:29 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.645, logit=21.625)', '\" The\"[578] (p=0.162, logit=20.250)', '\" A\"[362] (p=0.099, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=18.750)', '\" \"[220] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.871, logit=21.500)', '\" The\"[578] (p=0.026, logit=18.000)', '\" Spr\"[15883] (p=0.023, logit=17.875)', '\" Cat\"[17810] (p=0.016, logit=17.500)', '\" monitor\"[8891] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.87109375, logit=21.5, token_id=24423, metadata=None))), (15883, (3, PredictedToken(token=' Spr', prob=0.023193359375, logit=17.875, token_id=15883, metadata=None))), (17810, (4, PredictedToken(token=' Cat', prob=0.0159912109375, logit=17.5, token_id=17810, metadata=None)))])\n",
      "2025-09-16 09:55:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     int_prediction=['\" Cat\"[17810] (p=0.773, logit=22.000)', '\" Monitor\"[24423] (p=0.152, logit=20.375)', '\" Spr\"[15883] (p=0.014, logit=18.000)', '\" None\"[2290] (p=0.013, logit=17.875)', '\" The\"[578] (p=0.013, logit=17.875)']\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     int_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.7734375, logit=22.0, token_id=17810, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.15234375, logit=20.375, token_id=24423, metadata=None))), (15883, (3, PredictedToken(token=' Spr', prob=0.01416015625, logit=18.0, token_id=15883, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:30 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     patch_prediction=['\" None\"[2290] (p=0.531, logit=19.750)', '\" Yoga\"[38673] (p=0.252, logit=19.000)', '\" Z\"[1901] (p=0.082, logit=17.875)', '\" Comb\"[23262] (p=0.021, logit=16.500)', '\" The\"[578] (p=0.018, logit=16.375)']\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.758, logit=21.250)', '\" The\"[578] (p=0.091, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.250)', '\" A\"[362] (p=0.033, logit=18.125)', '\" It\"[1102] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.7578125, logit=21.25, token_id=26698, metadata=None))), (21424, (32, PredictedToken(token=' Football', prob=0.000507354736328125, logit=13.9375, token_id=21424, metadata=None))), (34785, (165, PredictedToken(token=' Truck', prob=1.436471939086914e-05, logit=10.375, token_id=34785, metadata=None))), (8219, (319, PredictedToken(token=' Sun', prob=4.112720489501953e-06, logit=9.125, token_id=8219, metadata=None)))])\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     int_prediction=['\" Football\"[21424] (p=0.311, logit=19.500)', '\" Keyboard\"[26698] (p=0.311, logit=19.500)', '\" Sun\"[8219] (p=0.101, logit=18.375)', '\" The\"[578] (p=0.079, logit=18.125)', '\" None\"[2290] (p=0.033, logit=17.250)']\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     int_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.310546875, logit=19.5, token_id=21424, metadata=None))), (26698, (2, PredictedToken(token=' Keyboard', prob=0.310546875, logit=19.5, token_id=26698, metadata=None))), (8219, (3, PredictedToken(token=' Sun', prob=0.10107421875, logit=18.375, token_id=8219, metadata=None))), (34785, (8, PredictedToken(token=' Truck', prob=0.01202392578125, logit=16.25, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:30 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:30 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:55:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.680, logit=21.000)', '\" The\"[578] (p=0.172, logit=19.625)', '\" Among\"[22395] (p=0.049, logit=18.375)', '\" A\"[362] (p=0.049, logit=18.375)', '\" It\"[1102] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.629, logit=22.000)', '\" The\"[578] (p=0.159, logit=20.625)', '\" A\"[362] (p=0.124, logit=20.375)', '\" Among\"[22395] (p=0.040, logit=19.250)', '\" It\"[1102] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.62890625, logit=22.0, token_id=27171, metadata=None))), (5340, (28, PredictedToken(token=' Har', prob=0.000370025634765625, logit=14.5625, token_id=5340, metadata=None))), (8868, (36, PredictedToken(token=' Blue', prob=0.00021076202392578125, logit=14.0, token_id=8868, metadata=None)))])\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.859, logit=22.500)', '\" The\"[578] (p=0.062, logit=19.875)', '\" A\"[362] (p=0.038, logit=19.375)', '\" Among\"[22395] (p=0.012, logit=18.250)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.859375, logit=22.5, token_id=5340, metadata=None))), (27171, (8, PredictedToken(token=' Coffee', prob=0.0018768310546875, logit=16.375, token_id=27171, metadata=None))), (8868, (12, PredictedToken(token=' Blue', prob=0.00121307373046875, logit=15.9375, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:31 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:31 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.672, logit=21.625)', '\" The\"[578] (p=0.170, logit=20.250)', '\" A\"[362] (p=0.062, logit=19.250)', '\" Among\"[22395] (p=0.043, logit=18.875)', '\" (\"[320] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.789, logit=21.375)', '\" The\"[578] (p=0.051, logit=18.625)', '\" A\"[362] (p=0.039, logit=18.375)', '\" Among\"[22395] (p=0.024, logit=17.875)', '\" pen\"[5869] (p=0.016, logit=17.500)']\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.7890625, logit=21.375, token_id=13597, metadata=None))), (52882, (16, PredictedToken(token=' Pepper', prob=0.00173187255859375, logit=15.25, token_id=52882, metadata=None))), (82452, (349, PredictedToken(token=' Jasmine', prob=3.56137752532959e-06, logit=9.0625, token_id=82452, metadata=None)))])\n",
      "2025-09-16 09:55:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.770, logit=20.500)', '\" The\"[578] (p=0.038, logit=17.500)', '\" Option\"[7104] (p=0.030, logit=17.250)', '\" Among\"[22395] (p=0.026, logit=17.125)', '\" jasmine\"[66909] (p=0.021, logit=16.875)']\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.76953125, logit=20.5, token_id=82452, metadata=None))), (13597, (54, PredictedToken(token=' Pen', prob=0.000213623046875, logit=12.3125, token_id=13597, metadata=None))), (52882, (60, PredictedToken(token=' Pepper', prob=0.000156402587890625, logit=12.0, token_id=52882, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:32 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.734, logit=21.000)', '\" An\"[1556] (p=0.087, logit=18.875)', '\" The\"[578] (p=0.077, logit=18.750)', '\" Among\"[22395] (p=0.037, logit=18.000)', '\" It\"[1102] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.812, logit=22.250)', '\" The\"[578] (p=0.086, logit=20.000)', '\" A\"[362] (p=0.041, logit=19.250)', '\" Among\"[22395] (p=0.028, logit=18.875)', '\" It\"[1102] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8125, logit=22.25, token_id=40759, metadata=None))), (18654, (9, PredictedToken(token=' Micro', prob=0.0015716552734375, logit=16.0, token_id=18654, metadata=None))), (57094, (13, PredictedToken(token=' Highlight', prob=0.000896453857421875, logit=15.4375, token_id=57094, metadata=None))), (445, (98, PredictedToken(token=' L', prob=1.6450881958007812e-05, logit=11.4375, token_id=445, metadata=None))), (68554, (200, PredictedToken(token=' Gloves', prob=3.904104232788086e-06, logit=10.0, token_id=68554, metadata=None))), (39794, (1197, PredictedToken(token=' Desk', prob=2.337619662284851e-07, logit=7.1875, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.494, logit=20.625)', '\" Harmon\"[40759] (p=0.142, logit=19.375)', '\" The\"[578] (p=0.097, logit=19.000)', '\" Among\"[22395] (p=0.086, logit=18.875)', '\" Micro\"[18654] (p=0.059, logit=18.500)']\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.494140625, logit=20.625, token_id=57094, metadata=None))), (40759, (2, PredictedToken(token=' Harmon', prob=0.1416015625, logit=19.375, token_id=40759, metadata=None))), (18654, (5, PredictedToken(token=' Micro', prob=0.05908203125, logit=18.5, token_id=18654, metadata=None))), (68554, (6, PredictedToken(token=' Gloves', prob=0.035888671875, logit=18.0, token_id=68554, metadata=None))), (445, (10, PredictedToken(token=' L', prob=0.0029449462890625, logit=15.5, token_id=445, metadata=None))), (39794, (69, PredictedToken(token=' Desk', prob=0.00011396408081054688, logit=12.25, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:32 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.855, logit=22.250)', '\" Among\"[22395] (p=0.042, logit=19.250)', '\" The\"[578] (p=0.042, logit=19.250)', '\" A\"[362] (p=0.033, logit=19.000)', '\" Option\"[7104] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.812, logit=21.625)', '\" None\"[2290] (p=0.067, logit=19.125)', '\" The\"[578] (p=0.028, logit=18.250)', '\" A\"[362] (p=0.022, logit=18.000)', '\" There\"[2684] (p=0.017, logit=17.750)']\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.8125, logit=21.625, token_id=1901, metadata=None))), (39794, (15, PredictedToken(token=' Desk', prob=0.00101470947265625, logit=14.9375, token_id=39794, metadata=None))), (816, (22, PredictedToken(token=' Y', prob=0.00054168701171875, logit=14.3125, token_id=816, metadata=None))), (88668, (123, PredictedToken(token=' Blender', prob=2.110004425048828e-05, logit=11.0625, token_id=88668, metadata=None))), (42609, (175, PredictedToken(token=' Pine', prob=1.0609626770019531e-05, logit=10.375, token_id=42609, metadata=None))), (100031, (346, PredictedToken(token=' Mosque', prob=2.8461217880249023e-06, logit=9.0625, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     int_prediction=['\" Mosque\"[100031] (p=0.941, logit=22.500)', '\" None\"[2290] (p=0.013, logit=18.250)', '\" A\"[362] (p=0.013, logit=18.250)', '\" The\"[578] (p=0.010, logit=18.000)', '\" There\"[2684] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     int_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.94140625, logit=22.5, token_id=100031, metadata=None))), (816, (83, PredictedToken(token=' Y', prob=1.3887882232666016e-05, logit=11.375, token_id=816, metadata=None))), (1901, (139, PredictedToken(token=' Z', prob=4.798173904418945e-06, logit=10.3125, token_id=1901, metadata=None))), (42609, (1374, PredictedToken(token=' Pine', prob=1.8067657947540283e-07, logit=7.03125, token_id=42609, metadata=None))), (39794, (3147, PredictedToken(token=' Desk', prob=6.612390279769897e-08, logit=6.03125, token_id=39794, metadata=None))), (88668, (5335, PredictedToken(token=' Blender', prob=3.4458935260772705e-08, logit=5.375, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:33 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.621, logit=20.250)', '\" The\"[578] (p=0.108, logit=18.500)', '\" Short\"[10928] (p=0.065, logit=18.000)', '\" Among\"[22395] (p=0.058, logit=17.875)', '\" A\"[362] (p=0.051, logit=17.750)']\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     clean_prediction=['\" Water\"[10164] (p=0.812, logit=22.750)', '\" The\"[578] (p=0.086, logit=20.500)', '\" Among\"[22395] (p=0.059, logit=20.125)', '\" A\"[362] (p=0.012, logit=18.500)', '\" water\"[3090] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     clean_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.8125, logit=22.75, token_id=10164, metadata=None))), (41445, (79, PredictedToken(token=' Television', prob=1.8596649169921875e-05, logit=12.0625, token_id=41445, metadata=None))), (17810, (118, PredictedToken(token=' Cat', prob=7.271766662597656e-06, logit=11.125, token_id=17810, metadata=None))), (38673, (182, PredictedToken(token=' Yoga', prob=3.2335519790649414e-06, logit=10.3125, token_id=38673, metadata=None))), (29318, (280, PredictedToken(token=' Dress', prob=1.430511474609375e-06, logit=9.5, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:55:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.539, logit=21.500)', '\" The\"[578] (p=0.199, logit=20.500)', '\" Among\"[22395] (p=0.073, logit=19.500)', '\" A\"[362] (p=0.064, logit=19.375)', '\" Cat\"[17810] (p=0.050, logit=19.125)']\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.5390625, logit=21.5, token_id=29318, metadata=None))), (17810, (5, PredictedToken(token=' Cat', prob=0.05029296875, logit=19.125, token_id=17810, metadata=None))), (38673, (7, PredictedToken(token=' Yoga', prob=0.007720947265625, logit=17.25, token_id=38673, metadata=None))), (41445, (32, PredictedToken(token=' Television', prob=0.00052642822265625, logit=14.5625, token_id=41445, metadata=None))), (10164, (136, PredictedToken(token=' Water', prob=1.4007091522216797e-05, logit=10.9375, token_id=10164, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:34 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     patch_prediction=['\" Harmon\"[40759] (p=0.828, logit=22.125)', '\" The\"[578] (p=0.077, logit=19.750)', '\" A\"[362] (p=0.036, logit=19.000)', '\" Among\"[22395] (p=0.025, logit=18.625)', '\" It\"[1102] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.910, logit=21.250)', '\" The\"[578] (p=0.035, logit=18.000)', '\" IR\"[16646] (p=0.005, logit=16.125)', '\" An\"[1556] (p=0.004, logit=15.750)', '\" It\"[1102] (p=0.003, logit=15.688)']\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.91015625, logit=21.25, token_id=66821, metadata=None))), (30555, (7, PredictedToken(token=' Viol', prob=0.002410888671875, logit=15.3125, token_id=30555, metadata=None))), (17929, (11, PredictedToken(token=' Pin', prob=0.00165557861328125, logit=14.9375, token_id=17929, metadata=None))), (19176, (32, PredictedToken(token=' Temple', prob=0.00030517578125, logit=13.25, token_id=19176, metadata=None))), (18191, (36, PredictedToken(token=' Mouse', prob=0.0002536773681640625, logit=13.0625, token_id=18191, metadata=None))), (74968, (143, PredictedToken(token=' Razor', prob=1.8358230590820312e-05, logit=10.4375, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.266, logit=18.500)', '\" Iris\"[66821] (p=0.183, logit=18.125)', '\" Viol\"[30555] (p=0.143, logit=17.875)', '\" The\"[578] (p=0.126, logit=17.750)', '\" Razor\"[74968] (p=0.059, logit=17.000)']\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.265625, logit=18.5, token_id=19176, metadata=None))), (66821, (2, PredictedToken(token=' Iris', prob=0.1826171875, logit=18.125, token_id=66821, metadata=None))), (30555, (3, PredictedToken(token=' Viol', prob=0.142578125, logit=17.875, token_id=30555, metadata=None))), (74968, (5, PredictedToken(token=' Razor', prob=0.059326171875, logit=17.0, token_id=74968, metadata=None))), (18191, (6, PredictedToken(token=' Mouse', prob=0.03173828125, logit=16.375, token_id=18191, metadata=None))), (17929, (8, PredictedToken(token=' Pin', prob=0.0169677734375, logit=15.75, token_id=17929, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:34 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:34 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.840, logit=22.875)', '\" The\"[578] (p=0.078, logit=20.500)', '\" A\"[362] (p=0.020, logit=19.125)', '\" Among\"[22395] (p=0.017, logit=19.000)', '\" (\"[320] (p=0.008, logit=18.250)']\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.832, logit=21.875)', '\" The\"[578] (p=0.060, logit=19.250)', '\" A\"[362] (p=0.053, logit=19.125)', '\" Among\"[22395] (p=0.013, logit=17.750)', '\" (\"[320] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.83203125, logit=21.875, token_id=41342, metadata=None))), (60413, (86, PredictedToken(token=' Uk', prob=2.014636993408203e-05, logit=11.25, token_id=60413, metadata=None))), (9939, (198, PredictedToken(token=' Er', prob=4.231929779052734e-06, logit=9.6875, token_id=9939, metadata=None)))])\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     int_prediction=['\" Uk\"[60413] (p=0.773, logit=21.250)', '\" The\"[578] (p=0.063, logit=18.750)', '\" Hockey\"[41342] (p=0.039, logit=18.250)', '\" A\"[362] (p=0.030, logit=18.000)', '\" Among\"[22395] (p=0.021, logit=17.625)']\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     int_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.7734375, logit=21.25, token_id=60413, metadata=None))), (41342, (3, PredictedToken(token=' Hockey', prob=0.03857421875, logit=18.25, token_id=41342, metadata=None))), (9939, (22, PredictedToken(token=' Er', prob=0.000705718994140625, logit=14.25, token_id=9939, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:35 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.746, logit=22.500)', '\" The\"[578] (p=0.114, logit=20.625)', '\" A\"[362] (p=0.069, logit=20.125)', '\" Among\"[22395] (p=0.033, logit=19.375)', '\" \"[220] (p=0.007, logit=17.875)']\n",
      "2025-09-16 09:55:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.668, logit=20.875)', '\" The\"[578] (p=0.191, logit=19.625)', '\" Among\"[22395] (p=0.055, logit=18.375)', '\" A\"[362] (p=0.026, logit=17.625)', '\" TO\"[5257] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.66796875, logit=20.875, token_id=82994, metadata=None))), (13597, (49, PredictedToken(token=' Pen', prob=0.00017452239990234375, logit=12.625, token_id=13597, metadata=None))), (34392, (63, PredictedToken(token=' Horse', prob=0.00011968612670898438, logit=12.25, token_id=34392, metadata=None))), (60413, (89, PredictedToken(token=' Uk', prob=5.6743621826171875e-05, logit=11.5, token_id=60413, metadata=None)))])\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.637, logit=20.250)', '\" The\"[578] (p=0.125, logit=18.625)', '\" Uk\"[60413] (p=0.111, logit=18.500)', '\" A\"[362] (p=0.017, logit=16.625)', '\" Among\"[22395] (p=0.015, logit=16.500)']\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.63671875, logit=20.25, token_id=34392, metadata=None))), (60413, (3, PredictedToken(token=' Uk', prob=0.11083984375, logit=18.5, token_id=60413, metadata=None))), (82994, (8, PredictedToken(token=' Toilet', prob=0.007080078125, logit=15.75, token_id=82994, metadata=None))), (13597, (10, PredictedToken(token=' Pen', prob=0.00457763671875, logit=15.3125, token_id=13597, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:36 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.664, logit=22.125)', '\" The\"[578] (p=0.168, logit=20.750)', '\" A\"[362] (p=0.080, logit=20.000)', '\" Among\"[22395] (p=0.048, logit=19.500)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.840, logit=21.875)', '\" A\"[362] (p=0.069, logit=19.375)', '\" The\"[578] (p=0.032, logit=18.625)', '\" Ring\"[22249] (p=0.015, logit=17.875)', '\" Among\"[22395] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.83984375, logit=21.875, token_id=23262, metadata=None))), (22249, (4, PredictedToken(token=' Ring', prob=0.015380859375, logit=17.875, token_id=22249, metadata=None))), (49268, (38, PredictedToken(token=' Dish', prob=0.00019359588623046875, logit=13.5, token_id=49268, metadata=None))), (13120, (125, PredictedToken(token=' Night', prob=2.0384788513183594e-05, logit=11.25, token_id=13120, metadata=None)))])\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.543, logit=20.250)', '\" Dish\"[49268] (p=0.258, logit=19.500)', '\" The\"[578] (p=0.051, logit=17.875)', '\" A\"[362] (p=0.039, logit=17.625)', '\" None\"[2290] (p=0.019, logit=16.875)']\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.54296875, logit=20.25, token_id=22249, metadata=None))), (49268, (2, PredictedToken(token=' Dish', prob=0.2578125, logit=19.5, token_id=49268, metadata=None))), (13120, (6, PredictedToken(token=' Night', prob=0.0128173828125, logit=16.5, token_id=13120, metadata=None))), (23262, (8, PredictedToken(token=' Comb', prob=0.00469970703125, logit=15.5, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:36 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:36 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:55:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     patch_prediction=['\" P\"[393] (p=0.773, logit=21.250)', '\" The\"[578] (p=0.072, logit=18.875)', '\" A\"[362] (p=0.050, logit=18.500)', '\" Among\"[22395] (p=0.039, logit=18.250)', '\" Comb\"[23262] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.727, logit=21.500)', '\" The\"[578] (p=0.111, logit=19.625)', '\" A\"[362] (p=0.067, logit=19.125)', '\" Among\"[22395] (p=0.052, logit=18.875)', '\" GRA\"[65120] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.7265625, logit=21.5, token_id=80629, metadata=None))), (13120, (61, PredictedToken(token=' Night', prob=6.532669067382812e-05, logit=12.1875, token_id=13120, metadata=None))), (36895, (93, PredictedToken(token=' Eagle', prob=2.4080276489257812e-05, logit=11.1875, token_id=36895, metadata=None))), (63606, (179, PredictedToken(token=' Stap', prob=7.808208465576172e-06, logit=10.0625, token_id=63606, metadata=None))), (21424, (276, PredictedToken(token=' Football', prob=3.471970558166504e-06, logit=9.25, token_id=21424, metadata=None))), (26698, (1507, PredictedToken(token=' Keyboard', prob=3.129243850708008e-07, logit=6.84375, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.287, logit=19.750)', '\" The\"[578] (p=0.254, logit=19.625)', '\" Stap\"[63606] (p=0.224, logit=19.500)', '\" Among\"[22395] (p=0.093, logit=18.625)', '\" A\"[362] (p=0.073, logit=18.375)']\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.287109375, logit=19.75, token_id=26698, metadata=None))), (63606, (3, PredictedToken(token=' Stap', prob=0.2236328125, logit=19.5, token_id=63606, metadata=None))), (80629, (6, PredictedToken(token=' Grape', prob=0.006744384765625, logit=16.0, token_id=80629, metadata=None))), (36895, (12, PredictedToken(token=' Eagle', prob=0.0023345947265625, logit=14.9375, token_id=36895, metadata=None))), (21424, (32, PredictedToken(token=' Football', prob=0.000667572021484375, logit=13.6875, token_id=21424, metadata=None))), (13120, (171, PredictedToken(token=' Night', prob=2.014636993408203e-05, logit=10.1875, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:37 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:37 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.867, logit=22.500)', '\" The\"[578] (p=0.043, logit=19.500)', '\" A\"[362] (p=0.026, logit=19.000)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" bike\"[13260] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:55:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.699, logit=21.750)', '\" The\"[578] (p=0.138, logit=20.125)', '\" A\"[362] (p=0.074, logit=19.500)', '\" Among\"[22395] (p=0.045, logit=19.000)', '\" \"[220] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.69921875, logit=21.75, token_id=48035, metadata=None))), (23910, (19, PredictedToken(token=' Pear', prob=0.000926971435546875, logit=15.125, token_id=23910, metadata=None))), (6690, (119, PredictedToken(token=' Air', prob=1.4960765838623047e-05, logit=11.0, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.887, logit=22.625)', '\" The\"[578] (p=0.044, logit=19.625)', '\" An\"[1556] (p=0.034, logit=19.375)', '\" Among\"[22395] (p=0.011, logit=18.250)', '\" airplane\"[44024] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.88671875, logit=22.625, token_id=6690, metadata=None))), (48035, (32, PredictedToken(token=' Gir', prob=0.00014972686767578125, logit=13.9375, token_id=48035, metadata=None))), (23910, (156, PredictedToken(token=' Pear', prob=5.0961971282958984e-06, logit=10.5625, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:38 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     patch_prediction=['\" Pine\"[42609] (p=0.824, logit=21.750)', '\" The\"[578] (p=0.087, logit=19.500)', '\" Among\"[22395] (p=0.046, logit=18.875)', '\" A\"[362] (p=0.010, logit=17.375)', '\" \"[220] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     clean_prediction=['\" Magn\"[20918] (p=0.820, logit=21.625)', '\" Among\"[22395] (p=0.067, logit=19.125)', '\" The\"[578] (p=0.052, logit=18.875)', '\" A\"[362] (p=0.012, logit=17.375)', '\" Option\"[7104] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     clean_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.8203125, logit=21.625, token_id=20918, metadata=None))), (30558, (27, PredictedToken(token=' Ki', prob=0.000400543212890625, logit=14.0, token_id=30558, metadata=None))), (34954, (48, PredictedToken(token=' Mirror', prob=0.00012969970703125, logit=12.875, token_id=34954, metadata=None))), (56491, (306, PredictedToken(token=' Piano', prob=3.0547380447387695e-06, logit=9.125, token_id=56491, metadata=None)))])\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     int_prediction=['\" Ki\"[30558] (p=0.938, logit=22.375)', '\" The\"[578] (p=0.019, logit=18.500)', '\" Among\"[22395] (p=0.009, logit=17.750)', '\" A\"[362] (p=0.006, logit=17.375)', '\" ki\"[20548] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     int_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.9375, logit=22.375, token_id=30558, metadata=None))), (20918, (14, PredictedToken(token=' Magn', prob=0.0006256103515625, logit=15.0625, token_id=20918, metadata=None))), (34954, (32, PredictedToken(token=' Mirror', prob=0.00013065338134765625, logit=13.5, token_id=34954, metadata=None))), (56491, (135, PredictedToken(token=' Piano', prob=8.404254913330078e-06, logit=10.75, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:38 src.selection.optimization DEBUG    torch.Size([6, 36])\n",
      "2025-09-16 09:55:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.809, logit=22.000)', '\" The\"[578] (p=0.075, logit=19.625)', '\" A\"[362] (p=0.040, logit=19.000)', '\" Among\"[22395] (p=0.035, logit=18.875)', '\" D\"[423] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.758, logit=21.875)', '\" The\"[578] (p=0.116, logit=20.000)', '\" Among\"[22395] (p=0.043, logit=19.000)', '\" A\"[362] (p=0.038, logit=18.875)', '\" It\"[1102] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.7578125, logit=21.875, token_id=56491, metadata=None))), (52466, (96, PredictedToken(token=' Warehouse', prob=2.3603439331054688e-05, logit=11.5, token_id=52466, metadata=None))), (8219, (165, PredictedToken(token=' Sun', prob=7.212162017822266e-06, logit=10.3125, token_id=8219, metadata=None))), (48035, (261, PredictedToken(token=' Gir', prob=3.0100345611572266e-06, logit=9.4375, token_id=48035, metadata=None))), (34785, (279, PredictedToken(token=' Truck', prob=2.652406692504883e-06, logit=9.3125, token_id=34785, metadata=None))), (3341, (288, PredictedToken(token=' Car', prob=2.339482307434082e-06, logit=9.1875, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     int_prediction=['\" Gir\"[48035] (p=0.844, logit=21.750)', '\" The\"[578] (p=0.069, logit=19.250)', '\" A\"[362] (p=0.048, logit=18.875)', '\" Among\"[22395] (p=0.011, logit=17.375)', '\" (\"[320] (p=0.003, logit=16.000)']\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     int_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.84375, logit=21.75, token_id=48035, metadata=None))), (3341, (23, PredictedToken(token=' Car', prob=0.0002498626708984375, logit=13.625, token_id=3341, metadata=None))), (56491, (76, PredictedToken(token=' Piano', prob=4.076957702636719e-05, logit=11.8125, token_id=56491, metadata=None))), (34785, (79, PredictedToken(token=' Truck', prob=3.838539123535156e-05, logit=11.75, token_id=34785, metadata=None))), (52466, (102, PredictedToken(token=' Warehouse', prob=1.9311904907226562e-05, logit=11.0625, token_id=52466, metadata=None))), (8219, (123, PredictedToken(token=' Sun', prob=1.245737075805664e-05, logit=10.625, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:39 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:55:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.934, logit=23.125)', '\" The\"[578] (p=0.025, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" Option\"[7104] (p=0.003, logit=17.500)', '\" (\"[320] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.770, logit=21.250)', '\" The\"[578] (p=0.082, logit=19.000)', '\" A\"[362] (p=0.063, logit=18.750)', '\" None\"[2290] (p=0.011, logit=17.000)', '\" F\"[435] (p=0.009, logit=16.750)']\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.76953125, logit=21.25, token_id=36943, metadata=None))), (1630, (20, PredictedToken(token=' X', prob=0.0009613037109375, logit=14.5625, token_id=1630, metadata=None))), (4923, (25, PredictedToken(token=' Sk', prob=0.000659942626953125, logit=14.1875, token_id=4923, metadata=None)))])\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.727, logit=21.000)', '\" The\"[578] (p=0.087, logit=18.875)', '\" X\"[1630] (p=0.041, logit=18.125)', '\" A\"[362] (p=0.036, logit=18.000)', '\" None\"[2290] (p=0.028, logit=17.750)']\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.7265625, logit=21.0, token_id=4923, metadata=None))), (1630, (3, PredictedToken(token=' X', prob=0.041015625, logit=18.125, token_id=1630, metadata=None))), (36943, (6, PredictedToken(token=' Folder', prob=0.02490234375, logit=17.625, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:40 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:40 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.859, logit=22.750)', '\" The\"[578] (p=0.070, logit=20.250)', '\" Among\"[22395] (p=0.038, logit=19.625)', '\" A\"[362] (p=0.014, logit=18.625)', '\" \"[220] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.789, logit=22.000)', '\" The\"[578] (p=0.074, logit=19.625)', '\" Among\"[22395] (p=0.051, logit=19.250)', '\" A\"[362] (p=0.051, logit=19.250)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.7890625, logit=22.0, token_id=9441, metadata=None))), (1666, (9, PredictedToken(token=' As', prob=0.00162506103515625, logit=15.8125, token_id=1666, metadata=None))), (36845, (24, PredictedToken(token=' Tiger', prob=0.00052642822265625, logit=14.6875, token_id=36845, metadata=None))), (13000, (57, PredictedToken(token=' Van', prob=7.152557373046875e-05, logit=12.6875, token_id=13000, metadata=None))), (58251, (104, PredictedToken(token=' Tennis', prob=1.800060272216797e-05, logit=11.3125, token_id=58251, metadata=None))), (59825, (142, PredictedToken(token=' Tie', prob=9.059906005859375e-06, logit=10.625, token_id=59825, metadata=None)))])\n",
      "2025-09-16 09:55:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     int_prediction=['\" As\"[1666] (p=0.906, logit=22.125)', '\" The\"[578] (p=0.031, logit=18.750)', '\" Among\"[22395] (p=0.019, logit=18.250)', '\" Tennis\"[58251] (p=0.013, logit=17.875)', '\" (\"[320] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     int_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.90625, logit=22.125, token_id=1666, metadata=None))), (58251, (4, PredictedToken(token=' Tennis', prob=0.012939453125, logit=17.875, token_id=58251, metadata=None))), (36845, (63, PredictedToken(token=' Tiger', prob=4.9591064453125e-05, logit=12.3125, token_id=36845, metadata=None))), (59825, (121, PredictedToken(token=' Tie', prob=1.5139579772949219e-05, logit=11.125, token_id=59825, metadata=None))), (13000, (552, PredictedToken(token=' Van', prob=8.530914783477783e-07, logit=8.25, token_id=13000, metadata=None))), (9441, (1375, PredictedToken(token=' Church', prob=2.1606683731079102e-07, logit=6.875, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:41 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.957, logit=23.000)', '\" The\"[578] (p=0.020, logit=19.125)', '\" Among\"[22395] (p=0.012, logit=18.625)', '\" It\"[1102] (p=0.001, logit=16.500)', '\" A\"[362] (p=0.001, logit=16.500)']\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.918, logit=23.125)', '\" The\"[578] (p=0.028, logit=19.625)', '\" A\"[362] (p=0.024, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" Motor\"[18079] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.91796875, logit=23.125, token_id=70762, metadata=None))), (1901, (138, PredictedToken(token=' Z', prob=3.635883331298828e-06, logit=10.6875, token_id=1901, metadata=None))), (48665, (309, PredictedToken(token=' Raspberry', prob=8.121132850646973e-07, logit=9.1875, token_id=48665, metadata=None))), (58600, (480, PredictedToken(token=' Charm', prob=3.8370490074157715e-07, logit=8.4375, token_id=58600, metadata=None))), (36358, (982, PredictedToken(token=' Bench', prob=1.4156103134155273e-07, logit=7.4375, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.844, logit=22.000)', '\" The\"[578] (p=0.061, logit=19.375)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" A\"[362] (p=0.004, logit=16.750)', '\" Out\"[4470] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.84375, logit=22.0, token_id=1901, metadata=None))), (48665, (7, PredictedToken(token=' Raspberry', prob=0.0023651123046875, logit=16.125, token_id=48665, metadata=None))), (58600, (10, PredictedToken(token=' Charm', prob=0.0018463134765625, logit=15.875, token_id=58600, metadata=None))), (70762, (73, PredictedToken(token=' Motorcycle', prob=4.076957702636719e-05, logit=12.0625, token_id=70762, metadata=None))), (36358, (84, PredictedToken(token=' Bench', prob=3.170967102050781e-05, logit=11.8125, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:41 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:41 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:55:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     patch_prediction=['\" Speaker\"[30173] (p=0.715, logit=21.000)', '\" The\"[578] (p=0.125, logit=19.250)', '\" Among\"[22395] (p=0.046, logit=18.250)', '\" A\"[362] (p=0.031, logit=17.875)', '\" speaker\"[19114] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     clean_prediction=['\" Warehouse\"[52466] (p=0.809, logit=21.125)', '\" None\"[2290] (p=0.058, logit=18.500)', '\" The\"[578] (p=0.035, logit=18.000)', '\" Phone\"[14642] (p=0.024, logit=17.625)', '\" A\"[362] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     clean_track=OrderedDict([(52466, (1, PredictedToken(token=' Warehouse', prob=0.80859375, logit=21.125, token_id=52466, metadata=None))), (14642, (4, PredictedToken(token=' Phone', prob=0.0244140625, logit=17.625, token_id=14642, metadata=None))), (84409, (22, PredictedToken(token=' Plum', prob=0.000835418701171875, logit=14.25, token_id=84409, metadata=None))), (3341, (33, PredictedToken(token=' Car', prob=0.0003070831298828125, logit=13.25, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.797, logit=21.625)', '\" None\"[2290] (p=0.058, logit=19.000)', '\" A\"[362] (p=0.058, logit=19.000)', '\" The\"[578] (p=0.040, logit=18.625)', '\" There\"[2684] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.796875, logit=21.625, token_id=14642, metadata=None))), (3341, (22, PredictedToken(token=' Car', prob=0.000640869140625, logit=14.5, token_id=3341, metadata=None))), (52466, (90, PredictedToken(token=' Warehouse', prob=4.649162292480469e-05, logit=11.875, token_id=52466, metadata=None))), (84409, (147, PredictedToken(token=' Plum', prob=1.704692840576172e-05, logit=10.875, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:42 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.832, logit=21.375)', '\" The\"[578] (p=0.060, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.375)', '\" A\"[362] (p=0.010, logit=17.000)', '\" l\"[326] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.648, logit=20.625)', '\" The\"[578] (p=0.145, logit=19.125)', '\" Among\"[22395] (p=0.088, logit=18.625)', '\" shorts\"[36876] (p=0.017, logit=17.000)', '\" Short\"[10928] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.6484375, logit=20.625, token_id=91782, metadata=None))), (816, (15, PredictedToken(token=' Y', prob=0.0023345947265625, logit=15.0, token_id=816, metadata=None))), (5250, (47, PredictedToken(token=' Pe', prob=0.0003376007080078125, logit=13.0625, token_id=5250, metadata=None))), (47643, (85, PredictedToken(token=' Cel', prob=0.000102996826171875, logit=11.875, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:55:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     int_prediction=['\" Pe\"[5250] (p=0.695, logit=21.250)', '\" The\"[578] (p=0.121, logit=19.500)', '\" Among\"[22395] (p=0.073, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.125)', '\" (\"[320] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     int_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.6953125, logit=21.25, token_id=5250, metadata=None))), (47643, (6, PredictedToken(token=' Cel', prob=0.007720947265625, logit=16.75, token_id=47643, metadata=None))), (816, (9, PredictedToken(token=' Y', prob=0.004150390625, logit=16.125, token_id=816, metadata=None))), (91782, (871, PredictedToken(token=' Shorts', prob=9.238719940185547e-07, logit=7.71875, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:43 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.816, logit=22.500)', '\" The\"[578] (p=0.086, logit=20.250)', '\" Among\"[22395] (p=0.067, logit=20.000)', '\" socks\"[40086] (p=0.004, logit=17.125)', '\" A\"[362] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.707, logit=21.625)', '\" The\"[578] (p=0.096, logit=19.625)', '\" Among\"[22395] (p=0.084, logit=19.500)', '\" A\"[362] (p=0.058, logit=19.125)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.70703125, logit=21.625, token_id=27171, metadata=None))), (3804, (12, PredictedToken(token=' Sub', prob=0.0022430419921875, logit=15.875, token_id=3804, metadata=None))), (432, (33, PredictedToken(token=' R', prob=0.0004711151123046875, logit=14.3125, token_id=432, metadata=None))), (37326, (68, PredictedToken(token=' Swe', prob=6.771087646484375e-05, logit=12.375, token_id=37326, metadata=None))), (17810, (112, PredictedToken(token=' Cat', prob=2.3484230041503906e-05, logit=11.3125, token_id=17810, metadata=None)))])\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.789, logit=21.750)', '\" A\"[362] (p=0.094, logit=19.625)', '\" The\"[578] (p=0.044, logit=18.875)', '\" Among\"[22395] (p=0.019, logit=18.000)', '\" Cat\"[17810] (p=0.016, logit=17.875)']\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.7890625, logit=21.75, token_id=37326, metadata=None))), (17810, (5, PredictedToken(token=' Cat', prob=0.016357421875, logit=17.875, token_id=17810, metadata=None))), (3804, (6, PredictedToken(token=' Sub', prob=0.00872802734375, logit=17.25, token_id=3804, metadata=None))), (432, (10, PredictedToken(token=' R', prob=0.0017242431640625, logit=15.625, token_id=432, metadata=None))), (27171, (222, PredictedToken(token=' Coffee', prob=4.827976226806641e-06, logit=9.75, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:43 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:43 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.961, logit=22.375)', '\" Among\"[22395] (p=0.009, logit=17.750)', '\" The\"[578] (p=0.009, logit=17.750)', '\" A\"[362] (p=0.005, logit=17.125)', '\" None\"[2290] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.770, logit=22.125)', '\" The\"[578] (p=0.092, logit=20.000)', '\" Among\"[22395] (p=0.063, logit=19.625)', '\" A\"[362] (p=0.034, logit=19.000)', '\" School\"[6150] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.76953125, logit=22.125, token_id=19111, metadata=None))), (6150, (5, PredictedToken(token=' School', prob=0.005859375, logit=17.25, token_id=6150, metadata=None))), (74968, (48, PredictedToken(token=' Razor', prob=9.489059448242188e-05, logit=13.125, token_id=74968, metadata=None))), (59825, (182, PredictedToken(token=' Tie', prob=5.692243576049805e-06, logit=10.3125, token_id=59825, metadata=None))), (74574, (298, PredictedToken(token=' Violet', prob=2.1010637283325195e-06, logit=9.3125, token_id=74574, metadata=None))), (61948, (531, PredictedToken(token=' Sofa', prob=8.195638656616211e-07, logit=8.375, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.832, logit=21.500)', '\" The\"[578] (p=0.042, logit=18.500)', '\" School\"[6150] (p=0.037, logit=18.375)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" A\"[362] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.83203125, logit=21.5, token_id=74574, metadata=None))), (6150, (3, PredictedToken(token=' School', prob=0.03662109375, logit=18.375, token_id=6150, metadata=None))), (61948, (6, PredictedToken(token=' Sofa', prob=0.010498046875, logit=17.125, token_id=61948, metadata=None))), (59825, (13, PredictedToken(token=' Tie', prob=0.0018157958984375, logit=15.375, token_id=59825, metadata=None))), (19111, (14, PredictedToken(token=' Bus', prob=0.0016021728515625, logit=15.25, token_id=19111, metadata=None))), (74968, (41, PredictedToken(token=' Razor', prob=0.00019168853759765625, logit=13.125, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:44 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     patch_prediction=['\" Tie\"[59825] (p=0.773, logit=21.125)', '\" The\"[578] (p=0.072, logit=18.750)', '\" A\"[362] (p=0.056, logit=18.500)', '\" Among\"[22395] (p=0.044, logit=18.250)', '\" T\"[350] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:55:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.824, logit=21.375)', '\" The\"[578] (p=0.067, logit=18.875)', '\" A\"[362] (p=0.036, logit=18.250)', '\" Among\"[22395] (p=0.028, logit=18.000)', '\" Out\"[4470] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.82421875, logit=21.375, token_id=83499, metadata=None))), (3804, (31, PredictedToken(token=' Sub', prob=0.0002765655517578125, logit=13.375, token_id=3804, metadata=None))), (2947, (39, PredictedToken(token=' Mar', prob=0.00024318695068359375, logit=13.25, token_id=2947, metadata=None))), (17810, (70, PredictedToken(token=' Cat', prob=8.440017700195312e-05, logit=12.1875, token_id=17810, metadata=None))), (69755, (209, PredictedToken(token=' Notebook', prob=8.881092071533203e-06, logit=9.9375, token_id=69755, metadata=None))), (30760, (327, PredictedToken(token=' Scar', prob=3.6954879760742188e-06, logit=9.0625, token_id=30760, metadata=None)))])\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     int_prediction=['\" Scar\"[30760] (p=0.668, logit=20.500)', '\" The\"[578] (p=0.090, logit=18.500)', '\" Tooth\"[83499] (p=0.070, logit=18.250)', '\" A\"[362] (p=0.048, logit=17.875)', '\" Among\"[22395] (p=0.043, logit=17.750)']\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     int_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.66796875, logit=20.5, token_id=30760, metadata=None))), (83499, (3, PredictedToken(token=' Tooth', prob=0.0703125, logit=18.25, token_id=83499, metadata=None))), (2947, (12, PredictedToken(token=' Mar', prob=0.0021209716796875, logit=14.75, token_id=2947, metadata=None))), (3804, (29, PredictedToken(token=' Sub', prob=0.00064849853515625, logit=13.5625, token_id=3804, metadata=None))), (17810, (33, PredictedToken(token=' Cat', prob=0.00057220458984375, logit=13.4375, token_id=17810, metadata=None))), (69755, (177, PredictedToken(token=' Notebook', prob=2.5033950805664062e-05, logit=10.3125, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:45 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.859, logit=21.250)', '\" The\"[578] (p=0.055, logit=18.500)', '\" Among\"[22395] (p=0.020, logit=17.500)', '\" A\"[362] (p=0.018, logit=17.375)', '\" None\"[2290] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     clean_prediction=['\" Ju\"[22410] (p=0.617, logit=21.000)', '\" A\"[362] (p=0.155, logit=19.625)', '\" The\"[578] (p=0.107, logit=19.250)', '\" Among\"[22395] (p=0.051, logit=18.500)', '\" (\"[320] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     clean_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.6171875, logit=21.0, token_id=22410, metadata=None))), (88088, (20, PredictedToken(token=' Birch', prob=0.001434326171875, logit=14.9375, token_id=88088, metadata=None))), (34392, (21, PredictedToken(token=' Horse', prob=0.00135040283203125, logit=14.875, token_id=34392, metadata=None)))])\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     int_prediction=['\" Birch\"[88088] (p=0.953, logit=22.625)', '\" The\"[578] (p=0.014, logit=18.375)', '\" Among\"[22395] (p=0.011, logit=18.125)', '\" B\"[426] (p=0.004, logit=17.125)', '\" bir\"[15606] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     int_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.953125, logit=22.625, token_id=88088, metadata=None))), (34392, (163, PredictedToken(token=' Horse', prob=3.7848949432373047e-06, logit=10.1875, token_id=34392, metadata=None))), (22410, (221, PredictedToken(token=' Ju', prob=2.294778823852539e-06, logit=9.6875, token_id=22410, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:45 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:55:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     patch_prediction=['\" Shower\"[48471] (p=0.531, logit=20.375)', '\" The\"[578] (p=0.173, logit=19.250)', '\" A\"[362] (p=0.135, logit=19.000)', '\" Among\"[22395] (p=0.082, logit=18.500)', '\" It\"[1102] (p=0.007, logit=16.000)']\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.773, logit=21.250)', '\" The\"[578] (p=0.072, logit=18.875)', '\" Among\"[22395] (p=0.044, logit=18.375)', '\" A\"[362] (p=0.044, logit=18.375)', '\" bear\"[11984] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.7734375, logit=21.25, token_id=24941, metadata=None))), (65449, (15, PredictedToken(token=' Willow', prob=0.002044677734375, logit=15.3125, token_id=65449, metadata=None))), (328, (21, PredictedToken(token=' S', prob=0.00080108642578125, logit=14.375, token_id=328, metadata=None))), (1443, (28, PredictedToken(token=' Sh', prob=0.00058746337890625, logit=14.0625, token_id=1443, metadata=None))), (80629, (332, PredictedToken(token=' Grape', prob=4.470348358154297e-06, logit=9.1875, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     int_prediction=['\" Sh\"[1443] (p=0.855, logit=21.000)', '\" The\"[578] (p=0.038, logit=17.875)', '\" Among\"[22395] (p=0.026, logit=17.500)', '\" S\"[328] (p=0.007, logit=16.250)', '\" Option\"[7104] (p=0.005, logit=15.875)']\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     int_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.85546875, logit=21.0, token_id=1443, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.007415771484375, logit=16.25, token_id=328, metadata=None))), (24941, (40, PredictedToken(token=' Bear', prob=0.0002880096435546875, logit=13.0, token_id=24941, metadata=None))), (65449, (112, PredictedToken(token=' Willow', prob=3.886222839355469e-05, logit=11.0, token_id=65449, metadata=None))), (80629, (512, PredictedToken(token=' Grape', prob=2.652406692504883e-06, logit=8.3125, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:46 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:46 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.898, logit=22.500)', '\" The\"[578] (p=0.035, logit=19.250)', '\" Among\"[22395] (p=0.027, logit=19.000)', '\" A\"[362] (p=0.010, logit=18.000)', '\" Option\"[7104] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:55:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.781, logit=21.500)', '\" The\"[578] (p=0.073, logit=19.125)', '\" A\"[362] (p=0.073, logit=19.125)', '\" Among\"[22395] (p=0.018, logit=17.750)', '\" (\"[320] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.78125, logit=21.5, token_id=432, metadata=None))), (45805, (27, PredictedToken(token=' Cherry', prob=0.0004062652587890625, logit=13.9375, token_id=45805, metadata=None))), (96096, (281, PredictedToken(token=' Dolphin', prob=3.516674041748047e-06, logit=9.1875, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     int_prediction=['\" Cherry\"[45805] (p=0.914, logit=21.625)', '\" The\"[578] (p=0.024, logit=18.000)', '\" Dolphin\"[96096] (p=0.013, logit=17.375)', '\" A\"[362] (p=0.009, logit=17.000)', '\" (\"[320] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     int_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.9140625, logit=21.625, token_id=45805, metadata=None))), (96096, (3, PredictedToken(token=' Dolphin', prob=0.0130615234375, logit=17.375, token_id=96096, metadata=None))), (432, (8, PredictedToken(token=' R', prob=0.0019989013671875, logit=15.5, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:47 src.selection.optimization DEBUG    torch.Size([3, 27])\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.887, logit=22.125)', '\" None\"[2290] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.024, logit=18.500)', '\" The\"[578] (p=0.024, logit=18.500)', '\" Among\"[22395] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.742, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" A\"[362] (p=0.061, logit=19.375)', '\" Among\"[22395] (p=0.015, logit=18.000)', '\" Option\"[7104] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.7421875, logit=21.875, token_id=1630, metadata=None))), (23262, (30, PredictedToken(token=' Comb', prob=0.000339508056640625, logit=14.1875, token_id=23262, metadata=None))), (32498, (44, PredictedToken(token=' Mall', prob=0.00014209747314453125, logit=13.3125, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     int_prediction=['\" Mall\"[32498] (p=0.859, logit=21.625)', '\" The\"[578] (p=0.043, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.125)', '\" Among\"[22395] (p=0.014, logit=17.500)', '\" None\"[2290] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     int_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.859375, logit=21.625, token_id=32498, metadata=None))), (23262, (24, PredictedToken(token=' Comb', prob=0.00064849853515625, logit=14.4375, token_id=23262, metadata=None))), (1630, (66, PredictedToken(token=' X', prob=6.866455078125e-05, logit=12.1875, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:47 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.719, logit=22.000)', '\" The\"[578] (p=0.142, logit=20.375)', '\" A\"[362] (p=0.067, logit=19.625)', '\" Among\"[22395] (p=0.031, logit=18.875)', '\" (\"[320] (p=0.009, logit=17.625)']\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.832, logit=23.250)', '\" The\"[578] (p=0.068, logit=20.750)', '\" Among\"[22395] (p=0.037, logit=20.125)', '\" A\"[362] (p=0.032, logit=20.000)', '\" (\"[320] (p=0.003, logit=17.750)']\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.83203125, logit=23.25, token_id=19111, metadata=None))), (3341, (10, PredictedToken(token=' Car', prob=0.0020599365234375, logit=17.25, token_id=3341, metadata=None))), (8219, (96, PredictedToken(token=' Sun', prob=1.0192394256591797e-05, logit=11.9375, token_id=8219, metadata=None)))])\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.945, logit=23.000)', '\" The\"[578] (p=0.022, logit=19.250)', '\" A\"[362] (p=0.006, logit=18.000)', '\" sun\"[7160] (p=0.006, logit=17.875)', '\" Among\"[22395] (p=0.003, logit=17.375)']\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.9453125, logit=23.0, token_id=8219, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.00182342529296875, logit=16.75, token_id=3341, metadata=None))), (19111, (469, PredictedToken(token=' Bus', prob=6.51925802230835e-07, logit=8.8125, token_id=19111, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:48 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:48 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.855, logit=22.625)', '\" The\"[578] (p=0.070, logit=20.125)', '\" Among\"[22395] (p=0.042, logit=19.625)', '\" A\"[362] (p=0.008, logit=18.000)', '\" water\"[3090] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:55:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     clean_prediction=['\" Bench\"[36358] (p=0.734, logit=21.750)', '\" The\"[578] (p=0.088, logit=19.625)', '\" Among\"[22395] (p=0.068, logit=19.375)', '\" A\"[362] (p=0.060, logit=19.250)', '\" B\"[426] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     clean_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.734375, logit=21.75, token_id=36358, metadata=None))), (1630, (8, PredictedToken(token=' X', prob=0.0030059814453125, logit=16.25, token_id=1630, metadata=None))), (68867, (11, PredictedToken(token=' Coat', prob=0.0023345947265625, logit=16.0, token_id=68867, metadata=None))), (10777, (53, PredictedToken(token=' Router', prob=9.059906005859375e-05, logit=12.75, token_id=10777, metadata=None))), (50159, (178, PredictedToken(token=' Sco', prob=7.450580596923828e-06, logit=10.25, token_id=50159, metadata=None))), (8325, (204, PredictedToken(token=' Apple', prob=5.453824996948242e-06, logit=9.9375, token_id=8325, metadata=None)))])\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.855, logit=22.125)', '\" The\"[578] (p=0.048, logit=19.250)', '\" Among\"[22395] (p=0.038, logit=19.000)', '\" An\"[1556] (p=0.023, logit=18.500)', '\" It\"[1102] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.85546875, logit=22.125, token_id=8325, metadata=None))), (1630, (53, PredictedToken(token=' X', prob=8.20159912109375e-05, logit=12.875, token_id=1630, metadata=None))), (68867, (75, PredictedToken(token=' Coat', prob=4.124641418457031e-05, logit=12.1875, token_id=68867, metadata=None))), (50159, (397, PredictedToken(token=' Sco', prob=1.5050172805786133e-06, logit=8.875, token_id=50159, metadata=None))), (10777, (2396, PredictedToken(token=' Router', prob=9.592622518539429e-08, logit=6.125, token_id=10777, metadata=None))), (36358, (2460, PredictedToken(token=' Bench', prob=9.313225746154785e-08, logit=6.09375, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:49 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:55:49 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     patch_prediction=['\" Bamboo\"[98028] (p=0.844, logit=21.375)', '\" The\"[578] (p=0.048, logit=18.500)', '\" A\"[362] (p=0.029, logit=18.000)', '\" Among\"[22395] (p=0.020, logit=17.625)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     clean_prediction=['\" Ottoman\"[70110] (p=0.879, logit=21.000)', '\" The\"[578] (p=0.027, logit=17.500)', '\" (\"[320] (p=0.021, logit=17.250)', '\" d\"[294] (p=0.009, logit=16.375)', '\" Among\"[22395] (p=0.006, logit=15.938)']\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     clean_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.87890625, logit=21.0, token_id=70110, metadata=None))), (18343, (11, PredictedToken(token=' Paper', prob=0.0026397705078125, logit=15.1875, token_id=18343, metadata=None))), (3816, (23, PredictedToken(token=' Red', prob=0.00075531005859375, logit=13.9375, token_id=3816, metadata=None))), (8325, (34, PredictedToken(token=' Apple', prob=0.00040435791015625, logit=13.3125, token_id=8325, metadata=None)))])\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.453, logit=20.250)', '\" Red\"[3816] (p=0.275, logit=19.750)', '\" Ottoman\"[70110] (p=0.069, logit=18.375)', '\" Paper\"[18343] (p=0.054, logit=18.125)', '\" (\"[320] (p=0.029, logit=17.500)']\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.453125, logit=20.25, token_id=8325, metadata=None))), (3816, (2, PredictedToken(token=' Red', prob=0.275390625, logit=19.75, token_id=3816, metadata=None))), (70110, (3, PredictedToken(token=' Ottoman', prob=0.0693359375, logit=18.375, token_id=70110, metadata=None))), (18343, (4, PredictedToken(token=' Paper', prob=0.05419921875, logit=18.125, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:49 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:55:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.871, logit=23.000)', '\" A\"[362] (p=0.049, logit=20.125)', '\" The\"[578] (p=0.043, logit=20.000)', '\" Among\"[22395] (p=0.018, logit=19.125)', '\" Option\"[7104] (p=0.002, logit=17.125)']\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     clean_prediction=['\" Elm\"[65329] (p=0.785, logit=21.125)', '\" Among\"[22395] (p=0.064, logit=18.625)', '\" The\"[578] (p=0.064, logit=18.625)', '\" An\"[1556] (p=0.027, logit=17.750)', '\" E\"[469] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     clean_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.78515625, logit=21.125, token_id=65329, metadata=None))), (38571, (39, PredictedToken(token=' Theater', prob=0.0001811981201171875, logit=12.75, token_id=38571, metadata=None))), (9939, (227, PredictedToken(token=' Er', prob=7.4803829193115234e-06, logit=9.5625, token_id=9939, metadata=None))), (70306, (307, PredictedToken(token=' Brace', prob=4.5299530029296875e-06, logit=9.0625, token_id=70306, metadata=None))), (33199, (462, PredictedToken(token=' Lion', prob=2.2798776626586914e-06, logit=8.375, token_id=33199, metadata=None))), (74968, (3759, PredictedToken(token=' Razor', prob=1.601874828338623e-07, logit=5.71875, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.578, logit=20.125)', '\" The\"[578] (p=0.166, logit=18.875)', '\" Among\"[22395] (p=0.101, logit=18.375)', '\" Brace\"[70306] (p=0.029, logit=17.125)', '\" A\"[362] (p=0.029, logit=17.125)']\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.578125, logit=20.125, token_id=38571, metadata=None))), (70306, (5, PredictedToken(token=' Brace', prob=0.02880859375, logit=17.125, token_id=70306, metadata=None))), (65329, (6, PredictedToken(token=' Elm', prob=0.00933837890625, logit=16.0, token_id=65329, metadata=None))), (9939, (628, PredictedToken(token=' Er', prob=3.039836883544922e-06, logit=7.96875, token_id=9939, metadata=None))), (74968, (998, PredictedToken(token=' Razor', prob=1.6316771507263184e-06, logit=7.34375, token_id=74968, metadata=None))), (33199, (5349, PredictedToken(token=' Lion', prob=1.7136335372924805e-07, logit=5.09375, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:50 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:50 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:55:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.078, logit=19.500)', '\" Among\"[22395] (p=0.020, logit=18.125)', '\" A\"[362] (p=0.020, logit=18.125)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.855, logit=22.375)', '\" The\"[578] (p=0.042, logit=19.375)', '\" A\"[362] (p=0.042, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.875)', '\" (\"[320] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.85546875, logit=22.375, token_id=88668, metadata=None))), (32749, (34, PredictedToken(token=' Carn', prob=0.00015354156494140625, logit=13.75, token_id=32749, metadata=None))), (38673, (86, PredictedToken(token=' Yoga', prob=1.621246337890625e-05, logit=11.5, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     int_prediction=['\" Yoga\"[38673] (p=0.727, logit=20.875)', '\" The\"[578] (p=0.077, logit=18.625)', '\" Among\"[22395] (p=0.036, logit=17.875)', '\" (\"[320] (p=0.036, logit=17.875)', '\" A\"[362] (p=0.028, logit=17.625)']\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     int_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.7265625, logit=20.875, token_id=38673, metadata=None))), (32749, (7, PredictedToken(token=' Carn', prob=0.0133056640625, logit=16.875, token_id=32749, metadata=None))), (88668, (30, PredictedToken(token=' Blender', prob=0.000705718994140625, logit=13.9375, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:51 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.801, logit=21.250)', '\" None\"[2290] (p=0.096, logit=19.125)', '\" The\"[578] (p=0.019, logit=17.500)', '\" A\"[362] (p=0.015, logit=17.250)', '\" Among\"[22395] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.828, logit=21.125)', '\" The\"[578] (p=0.047, logit=18.250)', '\" Among\"[22395] (p=0.036, logit=18.000)', '\" A\"[362] (p=0.028, logit=17.750)', '\" Stap\"[63606] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.828125, logit=21.125, token_id=27738, metadata=None))), (63606, (5, PredictedToken(token=' Stap', prob=0.007171630859375, logit=16.375, token_id=63606, metadata=None))), (58403, (16, PredictedToken(token=' Tablet', prob=0.0013275146484375, logit=14.6875, token_id=58403, metadata=None))), (38571, (20, PredictedToken(token=' Theater', prob=0.0008544921875, logit=14.25, token_id=38571, metadata=None))), (67629, (22, PredictedToken(token=' Helmet', prob=0.000804901123046875, logit=14.1875, token_id=67629, metadata=None))), (91297, (123, PredictedToken(token=' Mushroom', prob=2.753734588623047e-05, logit=10.8125, token_id=91297, metadata=None)))])\n",
      "2025-09-16 09:55:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.816, logit=21.375)', '\" The\"[578] (p=0.052, logit=18.625)', '\" Helmet\"[67629] (p=0.041, logit=18.375)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" A\"[362] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.81640625, logit=21.375, token_id=38571, metadata=None))), (67629, (3, PredictedToken(token=' Helmet', prob=0.040771484375, logit=18.375, token_id=67629, metadata=None))), (27738, (24, PredictedToken(token=' Ward', prob=0.000743865966796875, logit=14.375, token_id=27738, metadata=None))), (58403, (40, PredictedToken(token=' Tablet', prob=0.000274658203125, logit=13.375, token_id=58403, metadata=None))), (63606, (250, PredictedToken(token=' Stap', prob=6.4373016357421875e-06, logit=9.625, token_id=63606, metadata=None))), (91297, (578, PredictedToken(token=' Mushroom', prob=1.4379620552062988e-06, logit=8.125, token_id=91297, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:52 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.809, logit=22.125)', '\" The\"[578] (p=0.097, logit=20.000)', '\" Among\"[22395] (p=0.040, logit=19.125)', '\" A\"[362] (p=0.022, logit=18.500)', '\" \"[220] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     clean_prediction=['\" Mar\"[2947] (p=0.824, logit=22.000)', '\" The\"[578] (p=0.077, logit=19.625)', '\" A\"[362] (p=0.032, logit=18.750)', '\" Among\"[22395] (p=0.028, logit=18.625)', '\" mar\"[3678] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     clean_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.82421875, logit=22.0, token_id=2947, metadata=None))), (13000, (28, PredictedToken(token=' Van', prob=0.0002765655517578125, logit=14.0, token_id=13000, metadata=None))), (48035, (32, PredictedToken(token=' Gir', prob=0.00022983551025390625, logit=13.8125, token_id=48035, metadata=None))), (63606, (160, PredictedToken(token=' Stap', prob=7.3909759521484375e-06, logit=10.375, token_id=63606, metadata=None))), (48471, (423, PredictedToken(token=' Shower', prob=1.3634562492370605e-06, logit=8.6875, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.543, logit=20.500)', '\" Shower\"[48471] (p=0.156, logit=19.250)', '\" The\"[578] (p=0.138, logit=19.125)', '\" A\"[362] (p=0.057, logit=18.250)', '\" Among\"[22395] (p=0.045, logit=18.000)']\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.54296875, logit=20.5, token_id=63606, metadata=None))), (48471, (2, PredictedToken(token=' Shower', prob=0.15625, logit=19.25, token_id=48471, metadata=None))), (13000, (29, PredictedToken(token=' Van', prob=0.00049591064453125, logit=13.5, token_id=13000, metadata=None))), (2947, (88, PredictedToken(token=' Mar', prob=6.29425048828125e-05, logit=11.4375, token_id=2947, metadata=None))), (48035, (1541, PredictedToken(token=' Gir', prob=6.370246410369873e-07, logit=6.84375, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:52 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:55:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.793, logit=21.375)', '\" The\"[578] (p=0.107, logit=19.375)', '\" Among\"[22395] (p=0.045, logit=18.500)', '\" A\"[362] (p=0.010, logit=17.000)', '\" It\"[1102] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.781, logit=22.625)', '\" The\"[578] (p=0.094, logit=20.500)', '\" A\"[362] (p=0.057, logit=20.000)', '\" Among\"[22395] (p=0.030, logit=19.375)', '\" HOUSE\"[69461] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.78125, logit=22.625, token_id=4783, metadata=None))), (19111, (24, PredictedToken(token=' Bus', prob=0.000522613525390625, logit=15.3125, token_id=19111, metadata=None))), (14642, (82, PredictedToken(token=' Phone', prob=3.147125244140625e-05, logit=12.5, token_id=14642, metadata=None))), (66821, (88, PredictedToken(token=' Iris', prob=2.5987625122070312e-05, logit=12.3125, token_id=66821, metadata=None))), (94467, (180, PredictedToken(token=' Trom', prob=4.5299530029296875e-06, logit=10.5625, token_id=94467, metadata=None)))])\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.840, logit=21.750)', '\" The\"[578] (p=0.061, logit=19.125)', '\" Among\"[22395] (p=0.025, logit=18.250)', '\" An\"[1556] (p=0.025, logit=18.250)', '\" (\"[320] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.83984375, logit=21.75, token_id=66821, metadata=None))), (4783, (13, PredictedToken(token=' House', prob=0.0012664794921875, logit=15.25, token_id=4783, metadata=None))), (94467, (45, PredictedToken(token=' Trom', prob=0.00014209747314453125, logit=13.0625, token_id=94467, metadata=None))), (19111, (96, PredictedToken(token=' Bus', prob=2.968311309814453e-05, logit=11.5, token_id=19111, metadata=None))), (14642, (178, PredictedToken(token=' Phone', prob=7.063150405883789e-06, logit=10.0625, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:53 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     patch_prediction=['\" Basketball\"[47589] (p=0.910, logit=22.375)', '\" The\"[578] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.017, logit=18.375)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" Basket\"[34217] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     clean_prediction=['\" Marker\"[40975] (p=0.871, logit=21.750)', '\" The\"[578] (p=0.043, logit=18.750)', '\" A\"[362] (p=0.030, logit=18.375)', '\" Among\"[22395] (p=0.016, logit=17.750)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     clean_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.87109375, logit=21.75, token_id=40975, metadata=None))), (41342, (52, PredictedToken(token=' Hockey', prob=8.344650268554688e-05, logit=12.5, token_id=41342, metadata=None))), (96096, (80, PredictedToken(token=' Dolphin', prob=3.9577484130859375e-05, logit=11.75, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:55:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.848, logit=21.250)', '\" The\"[578] (p=0.048, logit=18.375)', '\" A\"[362] (p=0.033, logit=18.000)', '\" Among\"[22395] (p=0.012, logit=17.000)', '\" hockey\"[28051] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.84765625, logit=21.25, token_id=41342, metadata=None))), (96096, (26, PredictedToken(token=' Dolphin', prob=0.0005645751953125, logit=13.9375, token_id=96096, metadata=None))), (40975, (143, PredictedToken(token=' Marker', prob=1.5079975128173828e-05, logit=10.3125, token_id=40975, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:54 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:54 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.859, logit=21.625)', '\" The\"[578] (p=0.055, logit=18.875)', '\" Among\"[22395] (p=0.016, logit=17.625)', '\" headphones\"[44101] (p=0.014, logit=17.500)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.875, logit=23.125)', '\" The\"[578] (p=0.072, logit=20.625)', '\" Among\"[22395] (p=0.026, logit=19.625)', '\" A\"[362] (p=0.006, logit=18.125)', '\" \"[220] (p=0.002, logit=17.250)']\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.875, logit=23.125, token_id=1901, metadata=None))), (3341, (21, PredictedToken(token=' Car', prob=0.0002593994140625, logit=15.0, token_id=3341, metadata=None))), (16147, (86, PredictedToken(token=' Smart', prob=1.2934207916259766e-05, logit=12.0, token_id=16147, metadata=None)))])\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.887, logit=22.750)', '\" The\"[578] (p=0.044, logit=19.750)', '\" A\"[362] (p=0.024, logit=19.125)', '\" Car\"[3341] (p=0.021, logit=19.000)', '\" Among\"[22395] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.88671875, logit=22.75, token_id=16147, metadata=None))), (3341, (4, PredictedToken(token=' Car', prob=0.020751953125, logit=19.0, token_id=3341, metadata=None))), (1901, (58, PredictedToken(token=' Z', prob=3.7670135498046875e-05, logit=12.6875, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:54 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:55:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.727, logit=20.625)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" Sco\"[50159] (p=0.047, logit=17.875)', '\" The\"[578] (p=0.041, logit=17.750)', '\" A\"[362] (p=0.028, logit=17.375)']\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.715, logit=22.125)', '\" The\"[578] (p=0.109, logit=20.250)', '\" A\"[362] (p=0.097, logit=20.125)', '\" Among\"[22395] (p=0.036, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.71484375, logit=22.125, token_id=12369, metadata=None))), (40759, (6, PredictedToken(token=' Harmon', prob=0.005462646484375, logit=17.25, token_id=40759, metadata=None))), (4923, (49, PredictedToken(token=' Sk', prob=0.00010633468627929688, logit=13.3125, token_id=4923, metadata=None))), (94091, (90, PredictedToken(token=' Tomato', prob=2.372264862060547e-05, logit=11.8125, token_id=94091, metadata=None))), (70306, (113, PredictedToken(token=' Brace', prob=1.1920928955078125e-05, logit=11.125, token_id=70306, metadata=None))), (36895, (315, PredictedToken(token=' Eagle', prob=1.6167759895324707e-06, logit=9.125, token_id=36895, metadata=None)))])\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.781, logit=21.500)', '\" The\"[578] (p=0.093, logit=19.375)', '\" Among\"[22395] (p=0.064, logit=19.000)', '\" Brace\"[70306] (p=0.007, logit=16.750)', '\" Harmon\"[40759] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.78125, logit=21.5, token_id=4923, metadata=None))), (70306, (5, PredictedToken(token=' Brace', prob=0.006744384765625, logit=16.75, token_id=70306, metadata=None))), (40759, (4, PredictedToken(token=' Harmon', prob=0.006744384765625, logit=16.75, token_id=40759, metadata=None))), (36895, (34, PredictedToken(token=' Eagle', prob=0.0003566741943359375, logit=13.8125, token_id=36895, metadata=None))), (94091, (121, PredictedToken(token=' Tomato', prob=2.014636993408203e-05, logit=10.9375, token_id=94091, metadata=None))), (12369, (166, PredictedToken(token=' Food', prob=9.5367431640625e-06, logit=10.1875, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:55 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:55 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.828, logit=21.750)', '\" The\"[578] (p=0.041, logit=18.750)', '\" A\"[362] (p=0.041, logit=18.750)', '\" Among\"[22395] (p=0.032, logit=18.500)', '\" cuff\"[75523] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:55:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     clean_prediction=['\" Raspberry\"[48665] (p=0.660, logit=20.500)', '\" The\"[578] (p=0.114, logit=18.750)', '\" Among\"[22395] (p=0.054, logit=18.000)', '\" None\"[2290] (p=0.023, logit=17.125)', '\" A\"[362] (p=0.023, logit=17.125)']\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     clean_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.66015625, logit=20.5, token_id=48665, metadata=None))), (18191, (6, PredictedToken(token=' Mouse', prob=0.017578125, logit=16.875, token_id=18191, metadata=None))), (469, (29, PredictedToken(token=' E', prob=0.000873565673828125, logit=13.875, token_id=469, metadata=None))), (39247, (218, PredictedToken(token=' Slow', prob=1.704692840576172e-05, logit=9.9375, token_id=39247, metadata=None))), (6017, (357, PredictedToken(token=' Book', prob=6.258487701416016e-06, logit=8.9375, token_id=6017, metadata=None))), (23462, (4900, PredictedToken(token=' Stadium', prob=1.564621925354004e-07, logit=5.25, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.695, logit=21.625)', '\" Raspberry\"[48665] (p=0.073, logit=19.375)', '\" An\"[1556] (p=0.065, logit=19.250)', '\" The\"[578] (p=0.057, logit=19.125)', '\" None\"[2290] (p=0.016, logit=17.875)']\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.6953125, logit=21.625, token_id=469, metadata=None))), (48665, (2, PredictedToken(token=' Raspberry', prob=0.0732421875, logit=19.375, token_id=48665, metadata=None))), (18191, (7, PredictedToken(token=' Mouse', prob=0.01446533203125, logit=17.75, token_id=18191, metadata=None))), (6017, (90, PredictedToken(token=' Book', prob=4.0531158447265625e-05, logit=11.875, token_id=6017, metadata=None))), (39247, (335, PredictedToken(token=' Slow', prob=2.9355287551879883e-06, logit=9.25, token_id=39247, metadata=None))), (23462, (18515, PredictedToken(token=' Stadium', prob=4.71482053399086e-09, logit=2.8125, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:56 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:55:56 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.820, logit=21.750)', '\" The\"[578] (p=0.059, logit=19.125)', '\" Among\"[22395] (p=0.041, logit=18.750)', '\" A\"[362] (p=0.025, logit=18.250)', '\" cat\"[8415] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:55:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     clean_prediction=['\" Orange\"[22725] (p=0.848, logit=22.875)', '\" An\"[1556] (p=0.054, logit=20.125)', '\" The\"[578] (p=0.054, logit=20.125)', '\" Among\"[22395] (p=0.020, logit=19.125)', '\" OR\"[2794] (p=0.004, logit=17.625)']\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     clean_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.84765625, logit=22.875, token_id=22725, metadata=None))), (13120, (62, PredictedToken(token=' Night', prob=2.8133392333984375e-05, logit=12.5625, token_id=13120, metadata=None))), (34392, (63, PredictedToken(token=' Horse', prob=2.8133392333984375e-05, logit=12.5625, token_id=34392, metadata=None))), (58586, (103, PredictedToken(token=' Tape', prob=1.1026859283447266e-05, logit=11.625, token_id=58586, metadata=None))), (98641, (211, PredictedToken(token=' Microwave', prob=2.4586915969848633e-06, logit=10.125, token_id=98641, metadata=None))), (23462, (2065, PredictedToken(token=' Stadium', prob=6.752088665962219e-08, logit=6.53125, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.703, logit=21.500)', '\" The\"[578] (p=0.139, logit=19.875)', '\" A\"[362] (p=0.065, logit=19.125)', '\" Among\"[22395] (p=0.045, logit=18.750)', '\" Orange\"[22725] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.703125, logit=21.5, token_id=34392, metadata=None))), (22725, (5, PredictedToken(token=' Orange', prob=0.006866455078125, logit=16.875, token_id=22725, metadata=None))), (13120, (25, PredictedToken(token=' Night', prob=0.000530242919921875, logit=14.3125, token_id=13120, metadata=None))), (23462, (41, PredictedToken(token=' Stadium', prob=0.00017261505126953125, logit=13.1875, token_id=23462, metadata=None))), (98641, (51, PredictedToken(token=' Microwave', prob=8.678436279296875e-05, logit=12.5, token_id=98641, metadata=None))), (58586, (179, PredictedToken(token=' Tape', prob=8.58306884765625e-06, logit=10.1875, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:57 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:55:57 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.906, logit=22.625)', '\" The\"[578] (p=0.040, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=18.500)', '\" A\"[362] (p=0.013, logit=18.375)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.766, logit=23.250)', '\" An\"[1556] (p=0.134, logit=21.500)', '\" The\"[578] (p=0.049, logit=20.500)', '\" Among\"[22395] (p=0.030, logit=20.000)', '\" It\"[1102] (p=0.002, logit=17.250)']\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.765625, logit=23.25, token_id=6690, metadata=None))), (57915, (56, PredictedToken(token=' Ank', prob=3.9577484130859375e-05, logit=13.375, token_id=57915, metadata=None))), (17810, (78, PredictedToken(token=' Cat', prob=1.6450881958007812e-05, logit=12.5, token_id=17810, metadata=None)))])\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     int_prediction=['\" Cat\"[17810] (p=0.844, logit=23.000)', '\" The\"[578] (p=0.054, logit=20.250)', '\" A\"[362] (p=0.054, logit=20.250)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" cat\"[8415] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     int_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.84375, logit=23.0, token_id=17810, metadata=None))), (57915, (6, PredictedToken(token=' Ank', prob=0.002685546875, logit=17.25, token_id=57915, metadata=None))), (6690, (49, PredictedToken(token=' Air', prob=5.245208740234375e-05, logit=13.3125, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:57 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     patch_prediction=['\" Laptop\"[57225] (p=0.891, logit=21.750)', '\" The\"[578] (p=0.031, logit=18.375)', '\" A\"[362] (p=0.019, logit=17.875)', '\" Among\"[22395] (p=0.014, logit=17.625)', '\" laptop\"[21288] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.766, logit=21.500)', '\" The\"[578] (p=0.104, logit=19.500)', '\" Among\"[22395] (p=0.055, logit=18.875)', '\" An\"[1556] (p=0.030, logit=18.250)', '\" A\"[362] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.765625, logit=21.5, token_id=66821, metadata=None))), (36845, (65, PredictedToken(token=' Tiger', prob=4.458427429199219e-05, logit=11.75, token_id=36845, metadata=None))), (39247, (165, PredictedToken(token=' Slow', prob=7.748603820800781e-06, logit=10.0, token_id=39247, metadata=None))), (26698, (434, PredictedToken(token=' Keyboard', prob=1.5273690223693848e-06, logit=8.375, token_id=26698, metadata=None))), (30760, (614, PredictedToken(token=' Scar', prob=9.834766387939453e-07, logit=7.9375, token_id=30760, metadata=None)))])\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.543, logit=20.750)', '\" The\"[578] (p=0.227, logit=19.875)', '\" A\"[362] (p=0.121, logit=19.250)', '\" Among\"[22395] (p=0.039, logit=18.125)', '\" Iris\"[66821] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.54296875, logit=20.75, token_id=26698, metadata=None))), (66821, (5, PredictedToken(token=' Iris', prob=0.0068359375, logit=16.375, token_id=66821, metadata=None))), (30760, (15, PredictedToken(token=' Scar', prob=0.00162506103515625, logit=14.9375, token_id=30760, metadata=None))), (39247, (75, PredictedToken(token=' Slow', prob=8.106231689453125e-05, logit=11.9375, token_id=39247, metadata=None))), (36845, (128, PredictedToken(token=' Tiger', prob=3.170967102050781e-05, logit=11.0, token_id=36845, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:58 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:55:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.762, logit=21.375)', '\" The\"[578] (p=0.080, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.375)', '\" A\"[362] (p=0.026, logit=18.000)', '\" phone\"[4641] (p=0.020, logit=17.750)']\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.746, logit=21.000)', '\" The\"[578] (p=0.089, logit=18.875)', '\" A\"[362] (p=0.069, logit=18.625)', '\" Among\"[22395] (p=0.042, logit=18.125)', '\" It\"[1102] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.74609375, logit=21.0, token_id=91263, metadata=None))), (10777, (10, PredictedToken(token=' Router', prob=0.0013580322265625, logit=14.6875, token_id=10777, metadata=None))), (3804, (32, PredictedToken(token=' Sub', prob=0.0004138946533203125, logit=13.5, token_id=3804, metadata=None))), (34392, (40, PredictedToken(token=' Horse', prob=0.0002841949462890625, logit=13.125, token_id=34392, metadata=None))), (3816, (47, PredictedToken(token=' Red', prob=0.0002079010009765625, logit=12.8125, token_id=3816, metadata=None)))])\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     int_prediction=['\" Router\"[10777] (p=0.420, logit=19.375)', '\" The\"[578] (p=0.175, logit=18.500)', '\" A\"[362] (p=0.094, logit=17.875)', '\" Binder\"[91263] (p=0.064, logit=17.500)', '\" Among\"[22395] (p=0.064, logit=17.500)']\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     int_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.419921875, logit=19.375, token_id=10777, metadata=None))), (91263, (5, PredictedToken(token=' Binder', prob=0.064453125, logit=17.5, token_id=91263, metadata=None))), (3816, (6, PredictedToken(token=' Red', prob=0.0208740234375, logit=16.375, token_id=3816, metadata=None))), (3804, (7, PredictedToken(token=' Sub', prob=0.0184326171875, logit=16.25, token_id=3804, metadata=None))), (34392, (15, PredictedToken(token=' Horse', prob=0.004669189453125, logit=14.875, token_id=34392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:55:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:55:59 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.852, logit=22.375)', '\" The\"[578] (p=0.070, logit=19.875)', '\" A\"[362] (p=0.029, logit=19.000)', '\" Among\"[22395] (p=0.018, logit=18.500)', '\" Pine\"[42609] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.781, logit=20.500)', '\" The\"[578] (p=0.057, logit=17.875)', '\" Among\"[22395] (p=0.034, logit=17.375)', '\" A\"[362] (p=0.027, logit=17.125)', '\" Peach\"[64695] (p=0.014, logit=16.500)']\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.78125, logit=20.5, token_id=79028, metadata=None))), (64695, (5, PredictedToken(token=' Peach', prob=0.01434326171875, logit=16.5, token_id=64695, metadata=None))), (13120, (18, PredictedToken(token=' Night', prob=0.0015106201171875, logit=14.25, token_id=13120, metadata=None))), (1183, (19, PredictedToken(token=' Tr', prob=0.00110626220703125, logit=13.9375, token_id=1183, metadata=None))), (13597, (51, PredictedToken(token=' Pen', prob=0.000217437744140625, logit=12.3125, token_id=13597, metadata=None)))])\n",
      "2025-09-16 09:55:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.723, logit=21.000)', '\" A\"[362] (p=0.059, logit=18.500)', '\" Hick\"[79028] (p=0.052, logit=18.375)', '\" The\"[578] (p=0.041, logit=18.125)', '\" Night\"[13120] (p=0.028, logit=17.750)']\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.72265625, logit=21.0, token_id=64695, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.05224609375, logit=18.375, token_id=79028, metadata=None))), (13120, (5, PredictedToken(token=' Night', prob=0.028076171875, logit=17.75, token_id=13120, metadata=None))), (13597, (7, PredictedToken(token=' Pen', prob=0.01324462890625, logit=17.0, token_id=13597, metadata=None))), (1183, (13, PredictedToken(token=' Tr', prob=0.0026092529296875, logit=15.375, token_id=1183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:00 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:00 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.656, logit=21.125)', '\" The\"[578] (p=0.129, logit=19.500)', '\" Among\"[22395] (p=0.069, logit=18.875)', '\" A\"[362] (p=0.061, logit=18.750)', '\" strawberry\"[73700] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.844, logit=21.875)', '\" The\"[578] (p=0.037, logit=18.750)', '\" A\"[362] (p=0.029, logit=18.500)', '\" Peach\"[64695] (p=0.022, logit=18.250)', '\" Among\"[22395] (p=0.020, logit=18.125)']\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.84375, logit=21.875, token_id=33578, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.0224609375, logit=18.25, token_id=64695, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.0009307861328125, logit=15.0625, token_id=1183, metadata=None)))])\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.898, logit=22.875)', '\" Palm\"[33578] (p=0.045, logit=19.875)', '\" A\"[362] (p=0.016, logit=18.875)', '\" The\"[578] (p=0.013, logit=18.625)', '\" Among\"[22395] (p=0.006, logit=17.875)']\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.8984375, logit=22.875, token_id=64695, metadata=None))), (33578, (2, PredictedToken(token=' Palm', prob=0.044677734375, logit=19.875, token_id=33578, metadata=None))), (1183, (7, PredictedToken(token=' Tr', prob=0.002227783203125, logit=16.875, token_id=1183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:00 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:00 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.762, logit=22.375)', '\" The\"[578] (p=0.103, logit=20.375)', '\" A\"[362] (p=0.062, logit=19.875)', '\" Among\"[22395] (p=0.038, logit=19.375)', '\" z\"[1167] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     clean_prediction=['\" Fl\"[3061] (p=0.770, logit=21.625)', '\" The\"[578] (p=0.104, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.250)', '\" flute\"[96812] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     clean_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.76953125, logit=21.625, token_id=3061, metadata=None))), (82452, (181, PredictedToken(token=' Jasmine', prob=5.692243576049805e-06, logit=9.8125, token_id=82452, metadata=None))), (49431, (201, PredictedToken(token=' Rabbit', prob=4.4405460357666016e-06, logit=9.5625, token_id=49431, metadata=None))), (52882, (282, PredictedToken(token=' Pepper', prob=2.5331974029541016e-06, logit=9.0, token_id=52882, metadata=None))), (13394, (665, PredictedToken(token=' Bed', prob=5.997717380523682e-07, logit=7.5625, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     int_prediction=['\" Fl\"[3061] (p=0.586, logit=20.500)', '\" The\"[578] (p=0.131, logit=19.000)', '\" Rabbit\"[49431] (p=0.102, logit=18.750)', '\" Among\"[22395] (p=0.062, logit=18.250)', '\" A\"[362] (p=0.026, logit=17.375)']\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     int_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.5859375, logit=20.5, token_id=3061, metadata=None))), (49431, (3, PredictedToken(token=' Rabbit', prob=0.10205078125, logit=18.75, token_id=49431, metadata=None))), (82452, (11, PredictedToken(token=' Jasmine', prob=0.004791259765625, logit=15.6875, token_id=82452, metadata=None))), (52882, (15, PredictedToken(token=' Pepper', prob=0.003082275390625, logit=15.25, token_id=52882, metadata=None))), (13394, (242, PredictedToken(token=' Bed', prob=8.64267349243164e-06, logit=9.375, token_id=13394, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:01 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:01 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.805, logit=21.875)', '\" The\"[578] (p=0.052, logit=19.125)', '\" A\"[362] (p=0.040, logit=18.875)', '\" Among\"[22395] (p=0.035, logit=18.750)', '\" It\"[1102] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.727, logit=21.875)', '\" The\"[578] (p=0.112, logit=20.000)', '\" Among\"[22395] (p=0.060, logit=19.375)', '\" A\"[362] (p=0.053, logit=19.250)', '\" (\"[320] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.7265625, logit=21.875, token_id=24941, metadata=None))), (32498, (71, PredictedToken(token=' Mall', prob=4.506111145019531e-05, logit=12.1875, token_id=32498, metadata=None))), (86460, (258, PredictedToken(token=' Necklace', prob=3.7103891372680664e-06, logit=9.6875, token_id=86460, metadata=None))), (47759, (427, PredictedToken(token=' Guitar', prob=1.4528632164001465e-06, logit=8.75, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:56:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     int_prediction=['\" Guitar\"[47759] (p=0.365, logit=19.750)', '\" Necklace\"[86460] (p=0.250, logit=19.375)', '\" The\"[578] (p=0.134, logit=18.750)', '\" Among\"[22395] (p=0.082, logit=18.250)', '\" A\"[362] (p=0.056, logit=17.875)']\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     int_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.365234375, logit=19.75, token_id=47759, metadata=None))), (86460, (2, PredictedToken(token=' Necklace', prob=0.25, logit=19.375, token_id=86460, metadata=None))), (24941, (23, PredictedToken(token=' Bear', prob=0.00148773193359375, logit=14.25, token_id=24941, metadata=None))), (32498, (42, PredictedToken(token=' Mall', prob=0.000621795654296875, logit=13.375, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:02 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     patch_prediction=['\" Uk\"[60413] (p=0.746, logit=22.000)', '\" The\"[578] (p=0.130, logit=20.250)', '\" Among\"[22395] (p=0.048, logit=19.250)', '\" A\"[362] (p=0.033, logit=18.875)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.852, logit=22.375)', '\" The\"[578] (p=0.070, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=19.250)', '\" A\"[362] (p=0.011, logit=18.000)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.8515625, logit=22.375, token_id=15883, metadata=None))), (328, (20, PredictedToken(token=' S', prob=0.0004405975341796875, logit=14.8125, token_id=328, metadata=None))), (36895, (198, PredictedToken(token=' Eagle', prob=3.814697265625e-06, logit=10.0625, token_id=36895, metadata=None))), (30555, (213, PredictedToken(token=' Viol', prob=3.3676624298095703e-06, logit=9.9375, token_id=30555, metadata=None))), (6690, (262, PredictedToken(token=' Air', prob=2.473592758178711e-06, logit=9.625, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.871, logit=22.375)', '\" The\"[578] (p=0.043, logit=19.375)', '\" A\"[362] (p=0.026, logit=18.875)', '\" Among\"[22395] (p=0.012, logit=18.125)', '\" (\"[320] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.87109375, logit=22.375, token_id=30555, metadata=None))), (6690, (6, PredictedToken(token=' Air', prob=0.005859375, logit=17.375, token_id=6690, metadata=None))), (15883, (7, PredictedToken(token=' Spr', prob=0.0040283203125, logit=17.0, token_id=15883, metadata=None))), (36895, (13, PredictedToken(token=' Eagle', prob=0.00122833251953125, logit=15.8125, token_id=36895, metadata=None))), (328, (30, PredictedToken(token=' S', prob=0.0002918243408203125, logit=14.375, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:02 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:56:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.758, logit=22.125)', '\" The\"[578] (p=0.090, logit=20.000)', '\" Among\"[22395] (p=0.062, logit=19.625)', '\" A\"[362] (p=0.048, logit=19.375)', '\" z\"[1167] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.676, logit=22.375)', '\" An\"[1556] (p=0.171, logit=21.000)', '\" The\"[578] (p=0.063, logit=20.000)', '\" Among\"[22395] (p=0.056, logit=19.875)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.67578125, logit=22.375, token_id=6690, metadata=None))), (469, (23, PredictedToken(token=' E', prob=0.0004520416259765625, logit=15.0625, token_id=469, metadata=None))), (24941, (29, PredictedToken(token=' Bear', prob=0.00037384033203125, logit=14.875, token_id=24941, metadata=None))), (735, (82, PredictedToken(token=' K', prob=2.396106719970703e-05, logit=12.125, token_id=735, metadata=None))), (86460, (1132, PredictedToken(token=' Necklace', prob=1.7136335372924805e-07, logit=7.1875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.703, logit=22.000)', '\" E\"[469] (p=0.122, logit=20.250)', '\" The\"[578] (p=0.065, logit=19.625)', '\" A\"[362] (p=0.035, logit=19.000)', '\" Among\"[22395] (p=0.031, logit=18.875)']\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.703125, logit=22.0, token_id=24941, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.1220703125, logit=20.25, token_id=469, metadata=None))), (6690, (58, PredictedToken(token=' Air', prob=9.250640869140625e-05, logit=13.0625, token_id=6690, metadata=None))), (735, (67, PredictedToken(token=' K', prob=5.602836608886719e-05, logit=12.5625, token_id=735, metadata=None))), (86460, (652, PredictedToken(token=' Necklace', prob=7.525086402893066e-07, logit=8.25, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:03 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.582, logit=20.125)', '\" None\"[2290] (p=0.242, logit=19.250)', '\" Mushroom\"[91297] (p=0.037, logit=17.375)', '\" There\"[2684] (p=0.033, logit=17.250)', '\" A\"[362] (p=0.029, logit=17.125)']\n",
      "2025-09-16 09:56:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.828, logit=21.125)', '\" The\"[578] (p=0.060, logit=18.500)', '\" Among\"[22395] (p=0.041, logit=18.125)', '\" Sub\"[3804] (p=0.008, logit=16.500)', '\" A\"[362] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.828125, logit=21.125, token_id=82994, metadata=None))), (3804, (4, PredictedToken(token=' Sub', prob=0.00811767578125, logit=16.5, token_id=3804, metadata=None))), (6914, (11, PredictedToken(token=' Let', prob=0.0021820068359375, logit=15.1875, token_id=6914, metadata=None))), (27738, (19, PredictedToken(token=' Ward', prob=0.00090789794921875, logit=14.3125, token_id=27738, metadata=None))), (45805, (116, PredictedToken(token=' Cherry', prob=3.743171691894531e-05, logit=11.125, token_id=45805, metadata=None))), (65329, (367, PredictedToken(token=' Elm', prob=4.202127456665039e-06, logit=8.9375, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.852, logit=21.125)', '\" The\"[578] (p=0.048, logit=18.250)', '\" Among\"[22395] (p=0.018, logit=17.250)', '\" Cherry\"[45805] (p=0.014, logit=17.000)', '\" (\"[320] (p=0.007, logit=16.250)']\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.8515625, logit=21.125, token_id=65329, metadata=None))), (45805, (4, PredictedToken(token=' Cherry', prob=0.01373291015625, logit=17.0, token_id=45805, metadata=None))), (6914, (6, PredictedToken(token=' Let', prob=0.0057373046875, logit=16.125, token_id=6914, metadata=None))), (27738, (37, PredictedToken(token=' Ward', prob=0.0003223419189453125, logit=13.25, token_id=27738, metadata=None))), (3804, (86, PredictedToken(token=' Sub', prob=6.341934204101562e-05, logit=11.625, token_id=3804, metadata=None))), (82994, (1051, PredictedToken(token=' Toilet', prob=1.0281801223754883e-06, logit=7.5, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:04 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.445, logit=19.875)', '\" Helmet\"[67629] (p=0.145, logit=18.750)', '\" The\"[578] (p=0.113, logit=18.500)', '\" Among\"[22395] (p=0.068, logit=18.000)', '\" A\"[362] (p=0.068, logit=18.000)']\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.844, logit=22.375)', '\" The\"[578] (p=0.089, logit=20.125)', '\" Among\"[22395] (p=0.029, logit=19.000)', '\" A\"[362] (p=0.012, logit=18.125)', '\" Box\"[8425] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.84375, logit=22.375, token_id=72683, metadata=None))), (19111, (77, PredictedToken(token=' Bus', prob=2.6345252990722656e-05, logit=12.0, token_id=19111, metadata=None))), (15883, (88, PredictedToken(token=' Spr', prob=1.811981201171875e-05, logit=11.625, token_id=15883, metadata=None))), (6690, (102, PredictedToken(token=' Air', prob=1.245737075805664e-05, logit=11.25, token_id=6690, metadata=None))), (67553, (376, PredictedToken(token=' Pants', prob=1.087784767150879e-06, logit=8.8125, token_id=67553, metadata=None))), (94091, (426, PredictedToken(token=' Tomato', prob=9.015202522277832e-07, logit=8.625, token_id=94091, metadata=None)))])\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.832, logit=21.250)', '\" The\"[578] (p=0.088, logit=19.000)', '\" Among\"[22395] (p=0.025, logit=17.750)', '\" Boxing\"[72683] (p=0.007, logit=16.500)', '\" (\"[320] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.83203125, logit=21.25, token_id=67553, metadata=None))), (72683, (5, PredictedToken(token=' Boxing', prob=0.0072021484375, logit=16.5, token_id=72683, metadata=None))), (15883, (6, PredictedToken(token=' Spr', prob=0.00384521484375, logit=15.875, token_id=15883, metadata=None))), (19111, (65, PredictedToken(token=' Bus', prob=6.246566772460938e-05, logit=11.75, token_id=19111, metadata=None))), (94091, (180, PredictedToken(token=' Tomato', prob=1.0192394256591797e-05, logit=9.9375, token_id=94091, metadata=None))), (6690, (409, PredictedToken(token=' Air', prob=2.2649765014648438e-06, logit=8.4375, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:04 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:04 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:56:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     patch_prediction=['\" P\"[393] (p=0.770, logit=21.125)', '\" The\"[578] (p=0.072, logit=18.750)', '\" Among\"[22395] (p=0.049, logit=18.375)', '\" A\"[362] (p=0.034, logit=18.000)', '\" It\"[1102] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     clean_prediction=['\" Amb\"[20423] (p=0.578, logit=22.125)', '\" An\"[1556] (p=0.188, logit=21.000)', '\" Among\"[22395] (p=0.114, logit=20.500)', '\" The\"[578] (p=0.078, logit=20.125)', '\" Option\"[7104] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     clean_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.578125, logit=22.125, token_id=20423, metadata=None))), (66821, (26, PredictedToken(token=' Iris', prob=0.0004100799560546875, logit=14.875, token_id=66821, metadata=None))), (91263, (70, PredictedToken(token=' Binder', prob=3.5762786865234375e-05, logit=12.4375, token_id=91263, metadata=None))), (37326, (516, PredictedToken(token=' Swe', prob=6.146728992462158e-07, logit=8.375, token_id=37326, metadata=None)))])\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.551, logit=20.250)', '\" The\"[578] (p=0.179, logit=19.125)', '\" Binder\"[91263] (p=0.074, logit=18.250)', '\" Among\"[22395] (p=0.051, logit=17.875)', '\" A\"[362] (p=0.045, logit=17.750)']\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.55078125, logit=20.25, token_id=37326, metadata=None))), (91263, (3, PredictedToken(token=' Binder', prob=0.07421875, logit=18.25, token_id=91263, metadata=None))), (20423, (80, PredictedToken(token=' Amb', prob=0.00012683868408203125, logit=11.875, token_id=20423, metadata=None))), (66821, (92, PredictedToken(token=' Iris', prob=8.678436279296875e-05, logit=11.5, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:05 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:05 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.042, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.625)', '\" slow\"[6435] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:56:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.812, logit=22.375)', '\" The\"[578] (p=0.097, logit=20.250)', '\" A\"[362] (p=0.031, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=18.750)', '\" (\"[320] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.8125, logit=22.375, token_id=60413, metadata=None))), (47643, (24, PredictedToken(token=' Cel', prob=0.0002899169921875, logit=14.4375, token_id=47643, metadata=None))), (88668, (45, PredictedToken(token=' Blender', prob=6.914138793945312e-05, logit=13.0, token_id=88668, metadata=None)))])\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     int_prediction=['\" Blender\"[88668] (p=0.840, logit=22.250)', '\" Cel\"[47643] (p=0.078, logit=19.875)', '\" The\"[578] (p=0.037, logit=19.125)', '\" (\"[320] (p=0.009, logit=17.750)', '\" Among\"[22395] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     int_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.83984375, logit=22.25, token_id=88668, metadata=None))), (47643, (2, PredictedToken(token=' Cel', prob=0.078125, logit=19.875, token_id=47643, metadata=None))), (60413, (1279, PredictedToken(token=' Uk', prob=2.5704503059387207e-07, logit=7.25, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:06 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     patch_prediction=['\" Ash\"[14937] (p=0.781, logit=21.250)', '\" The\"[578] (p=0.083, logit=19.000)', '\" An\"[1556] (p=0.039, logit=18.250)', '\" Among\"[22395] (p=0.024, logit=17.750)', '\" A\"[362] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.871, logit=21.625)', '\" The\"[578] (p=0.038, logit=18.500)', '\" A\"[362] (p=0.023, logit=18.000)', '\" Among\"[22395] (p=0.014, logit=17.500)', '\" BAT\"[79081] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.87109375, logit=21.625, token_id=16488, metadata=None))), (6771, (9, PredictedToken(token=' Table', prob=0.0023040771484375, logit=15.6875, token_id=6771, metadata=None))), (18787, (19, PredictedToken(token=' Oak', prob=0.0009613037109375, logit=14.8125, token_id=18787, metadata=None))), (432, (31, PredictedToken(token=' R', prob=0.0003757476806640625, logit=13.875, token_id=432, metadata=None)))])\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.543, logit=20.875)', '\" Table\"[6771] (p=0.291, logit=20.250)', '\" Oak\"[18787] (p=0.045, logit=18.375)', '\" The\"[578] (p=0.040, logit=18.250)', '\" A\"[362] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.54296875, logit=20.875, token_id=16488, metadata=None))), (6771, (2, PredictedToken(token=' Table', prob=0.291015625, logit=20.25, token_id=6771, metadata=None))), (18787, (3, PredictedToken(token=' Oak', prob=0.044677734375, logit=18.375, token_id=18787, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.005340576171875, logit=16.25, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:06 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:56:06 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     patch_prediction=['\" Theater\"[38571] (p=0.824, logit=21.375)', '\" The\"[578] (p=0.052, logit=18.625)', '\" A\"[362] (p=0.028, logit=18.000)', '\" Among\"[22395] (p=0.019, logit=17.625)', '\" None\"[2290] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     clean_prediction=['\" Ju\"[22410] (p=0.684, logit=20.750)', '\" The\"[578] (p=0.093, logit=18.750)', '\" A\"[362] (p=0.093, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.250)', '\" It\"[1102] (p=0.008, logit=16.250)']\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     clean_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.68359375, logit=20.75, token_id=22410, metadata=None))), (42609, (17, PredictedToken(token=' Pine', prob=0.00180816650390625, logit=14.8125, token_id=42609, metadata=None))), (59825, (70, PredictedToken(token=' Tie', prob=0.00010824203491210938, logit=12.0, token_id=59825, metadata=None))), (49431, (93, PredictedToken(token=' Rabbit', prob=6.198883056640625e-05, logit=11.4375, token_id=49431, metadata=None))), (17367, (165, PredictedToken(token=' Factory', prob=1.7642974853515625e-05, logit=10.1875, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     int_prediction=['\" Factory\"[17367] (p=0.443, logit=20.125)', '\" Tie\"[59825] (p=0.305, logit=19.750)', '\" The\"[578] (p=0.053, logit=18.000)', '\" Among\"[22395] (p=0.041, logit=17.750)', '\" None\"[2290] (p=0.036, logit=17.625)']\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     int_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.443359375, logit=20.125, token_id=17367, metadata=None))), (59825, (2, PredictedToken(token=' Tie', prob=0.3046875, logit=19.75, token_id=59825, metadata=None))), (42609, (6, PredictedToken(token=' Pine', prob=0.0220947265625, logit=17.125, token_id=42609, metadata=None))), (22410, (8, PredictedToken(token=' Ju', prob=0.01177978515625, logit=16.5, token_id=22410, metadata=None))), (49431, (23, PredictedToken(token=' Rabbit', prob=0.0010986328125, logit=14.125, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:07 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:07 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.824, logit=21.625)', '\" A\"[362] (p=0.060, logit=19.000)', '\" The\"[578] (p=0.046, logit=18.750)', '\" Among\"[22395] (p=0.015, logit=17.625)', '\" Only\"[8442] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:56:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.859, logit=22.250)', '\" b\"[293] (p=0.062, logit=19.625)', '\" The\"[578] (p=0.023, logit=18.625)', '\" A\"[362] (p=0.016, logit=18.250)', '\" (\"[320] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.859375, logit=22.25, token_id=426, metadata=None))), (88088, (16, PredictedToken(token=' Birch', prob=0.000507354736328125, logit=14.8125, token_id=88088, metadata=None))), (36943, (47, PredictedToken(token=' Folder', prob=6.866455078125e-05, logit=12.8125, token_id=36943, metadata=None)))])\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.848, logit=21.375)', '\" The\"[578] (p=0.037, logit=18.250)', '\" Birch\"[88088] (p=0.018, logit=17.500)', '\" A\"[362] (p=0.018, logit=17.500)', '\" (\"[320] (p=0.018, logit=17.500)']\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.84765625, logit=21.375, token_id=36943, metadata=None))), (88088, (5, PredictedToken(token=' Birch', prob=0.017578125, logit=17.5, token_id=88088, metadata=None))), (426, (6, PredictedToken(token=' B', prob=0.00830078125, logit=16.75, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:08 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.680, logit=21.500)', '\" The\"[578] (p=0.134, logit=19.875)', '\" Among\"[22395] (p=0.092, logit=19.500)', '\" A\"[362] (p=0.038, logit=18.625)', '\" (\"[320] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.805, logit=20.625)', '\" Among\"[22395] (p=0.058, logit=18.000)', '\" The\"[578] (p=0.045, logit=17.750)', '\" A\"[362] (p=0.024, logit=17.125)', '\" lotion\"[87942] (p=0.007, logit=15.938)']\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.8046875, logit=20.625, token_id=445, metadata=None))), (27738, (34, PredictedToken(token=' Ward', prob=0.0003261566162109375, logit=12.8125, token_id=27738, metadata=None))), (23910, (126, PredictedToken(token=' Pear', prob=4.1484832763671875e-05, logit=10.75, token_id=23910, metadata=None))), (47759, (172, PredictedToken(token=' Guitar', prob=2.086162567138672e-05, logit=10.0625, token_id=47759, metadata=None))), (3816, (223, PredictedToken(token=' Red', prob=1.1146068572998047e-05, logit=9.4375, token_id=3816, metadata=None))), (100031, (237, PredictedToken(token=' Mosque', prob=9.834766387939453e-06, logit=9.3125, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     int_prediction=['\" Ward\"[27738] (p=0.855, logit=21.000)', '\" The\"[578] (p=0.038, logit=17.875)', '\" Among\"[22395] (p=0.026, logit=17.500)', '\" A\"[362] (p=0.020, logit=17.250)', '\" Red\"[3816] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     int_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.85546875, logit=21.0, token_id=27738, metadata=None))), (3816, (5, PredictedToken(token=' Red', prob=0.0137939453125, logit=16.875, token_id=3816, metadata=None))), (100031, (6, PredictedToken(token=' Mosque', prob=0.00946044921875, logit=16.5, token_id=100031, metadata=None))), (445, (7, PredictedToken(token=' L', prob=0.002899169921875, logit=15.3125, token_id=445, metadata=None))), (23910, (10, PredictedToken(token=' Pear', prob=0.00186920166015625, logit=14.875, token_id=23910, metadata=None))), (47759, (246, PredictedToken(token=' Guitar', prob=6.735324859619141e-06, logit=9.25, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:08 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:56:08 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.871, logit=22.125)', '\" The\"[578] (p=0.049, logit=19.250)', '\" A\"[362] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=18.375)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     clean_prediction=['\" Camera\"[14669] (p=0.688, logit=21.000)', '\" The\"[578] (p=0.105, logit=19.125)', '\" Among\"[22395] (p=0.056, logit=18.500)', '\" A\"[362] (p=0.027, logit=17.750)', '\" It\"[1102] (p=0.023, logit=17.625)']\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     clean_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.6875, logit=21.0, token_id=14669, metadata=None))), (3341, (19, PredictedToken(token=' Car', prob=0.00193023681640625, logit=15.125, token_id=3341, metadata=None))), (34046, (25, PredictedToken(token=' Cabinet', prob=0.00141143798828125, logit=14.8125, token_id=34046, metadata=None))), (33578, (35, PredictedToken(token=' Palm', prob=0.000804901123046875, logit=14.25, token_id=33578, metadata=None)))])\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     int_prediction=['\" Cabinet\"[34046] (p=0.863, logit=21.250)', '\" The\"[578] (p=0.030, logit=17.875)', '\" Car\"[3341] (p=0.020, logit=17.500)', '\" Among\"[22395] (p=0.016, logit=17.250)', '\" None\"[2290] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     int_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.86328125, logit=21.25, token_id=34046, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.020263671875, logit=17.5, token_id=3341, metadata=None))), (33578, (11, PredictedToken(token=' Palm', prob=0.0025787353515625, logit=15.4375, token_id=33578, metadata=None))), (14669, (140, PredictedToken(token=' Camera', prob=1.8477439880371094e-05, logit=10.5, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:09 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:09 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.840, logit=22.375)', '\" The\"[578] (p=0.069, logit=19.875)', '\" Among\"[22395] (p=0.054, logit=19.625)', '\" JE\"[71430] (p=0.006, logit=17.500)', '\" Jean\"[20263] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.738, logit=21.500)', '\" Among\"[22395] (p=0.078, logit=19.250)', '\" The\"[578] (p=0.061, logit=19.000)', '\" A\"[362] (p=0.053, logit=18.875)', '\" pressure\"[7410] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.73828125, logit=21.5, token_id=40090, metadata=None))), (17929, (9, PredictedToken(token=' Pin', prob=0.005645751953125, logit=16.625, token_id=17929, metadata=None))), (61731, (27, PredictedToken(token=' Soap', prob=0.0004634857177734375, logit=14.125, token_id=61731, metadata=None))), (4923, (44, PredictedToken(token=' Sk', prob=0.000141143798828125, logit=12.9375, token_id=4923, metadata=None))), (33711, (62, PredictedToken(token=' Suit', prob=6.67572021484375e-05, logit=12.1875, token_id=33711, metadata=None)))])\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.750, logit=21.625)', '\" A\"[362] (p=0.070, logit=19.250)', '\" Among\"[22395] (p=0.054, logit=19.000)', '\" The\"[578] (p=0.048, logit=18.875)', '\" Sk\"[4923] (p=0.014, logit=17.625)']\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.75, logit=21.625, token_id=33711, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.01373291015625, logit=17.625, token_id=4923, metadata=None))), (17929, (7, PredictedToken(token=' Pin', prob=0.007354736328125, logit=17.0, token_id=17929, metadata=None))), (40090, (65, PredictedToken(token=' Pressure', prob=6.771087646484375e-05, logit=12.3125, token_id=40090, metadata=None))), (61731, (299, PredictedToken(token=' Soap', prob=3.1739473342895508e-06, logit=9.25, token_id=61731, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:10 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:10 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.695, logit=21.375)', '\" The\"[578] (p=0.121, logit=19.625)', '\" Among\"[22395] (p=0.073, logit=19.125)', '\" A\"[362] (p=0.057, logit=18.875)', '\" B\"[426] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.762, logit=21.625)', '\" The\"[578] (p=0.071, logit=19.250)', '\" A\"[362] (p=0.043, logit=18.750)', '\" b\"[293] (p=0.038, logit=18.625)', '\" Among\"[22395] (p=0.033, logit=18.500)']\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.76171875, logit=21.625, token_id=426, metadata=None))), (48390, (46, PredictedToken(token=' Lily', prob=0.00010013580322265625, logit=12.6875, token_id=48390, metadata=None))), (33711, (92, PredictedToken(token=' Suit', prob=2.6941299438476562e-05, logit=11.375, token_id=33711, metadata=None))), (80629, (297, PredictedToken(token=' Grape', prob=2.3543834686279297e-06, logit=8.9375, token_id=80629, metadata=None))), (50159, (440, PredictedToken(token=' Sco', prob=1.259148120880127e-06, logit=8.3125, token_id=50159, metadata=None))), (53889, (676, PredictedToken(token=' Apartment', prob=6.332993507385254e-07, logit=7.625, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:56:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.707, logit=20.500)', '\" Among\"[22395] (p=0.075, logit=18.250)', '\" The\"[578] (p=0.058, logit=18.000)', '\" A\"[362] (p=0.045, logit=17.750)', '\" Option\"[7104] (p=0.015, logit=16.625)']\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.70703125, logit=20.5, token_id=80629, metadata=None))), (426, (9, PredictedToken(token=' B', prob=0.006134033203125, logit=15.75, token_id=426, metadata=None))), (48390, (56, PredictedToken(token=' Lily', prob=0.00014400482177734375, logit=12.0, token_id=48390, metadata=None))), (53889, (78, PredictedToken(token=' Apartment', prob=8.20159912109375e-05, logit=11.4375, token_id=53889, metadata=None))), (33711, (378, PredictedToken(token=' Suit', prob=4.649162292480469e-06, logit=8.5625, token_id=33711, metadata=None))), (50159, (536, PredictedToken(token=' Sco', prob=2.816319465637207e-06, logit=8.0625, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:11 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:11 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.832, logit=21.000)', '\" The\"[578] (p=0.047, logit=18.125)', '\" Among\"[22395] (p=0.037, logit=17.875)', '\" Let\"[6914] (p=0.020, logit=17.250)', '\" toilet\"[27306] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.742, logit=22.375)', '\" The\"[578] (p=0.100, logit=20.375)', '\" A\"[362] (p=0.100, logit=20.375)', '\" Among\"[22395] (p=0.037, logit=19.375)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.7421875, logit=22.375, token_id=3341, metadata=None))), (26781, (40, PredictedToken(token=' Hair', prob=7.104873657226562e-05, logit=13.125, token_id=26781, metadata=None))), (63606, (58, PredictedToken(token=' Stap', prob=4.0531158447265625e-05, logit=12.5625, token_id=63606, metadata=None))), (56491, (545, PredictedToken(token=' Piano', prob=6.146728992462158e-07, logit=8.375, token_id=56491, metadata=None))), (91782, (791, PredictedToken(token=' Shorts', prob=3.296881914138794e-07, logit=7.75, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.355, logit=19.625)', '\" The\"[578] (p=0.215, logit=19.125)', '\" Hair\"[26781] (p=0.131, logit=18.625)', '\" Shorts\"[91782] (p=0.115, logit=18.500)', '\" Among\"[22395] (p=0.062, logit=17.875)']\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.35546875, logit=19.625, token_id=63606, metadata=None))), (26781, (3, PredictedToken(token=' Hair', prob=0.130859375, logit=18.625, token_id=26781, metadata=None))), (91782, (4, PredictedToken(token=' Shorts', prob=0.115234375, logit=18.5, token_id=91782, metadata=None))), (3341, (11, PredictedToken(token=' Car', prob=0.0028839111328125, logit=14.8125, token_id=3341, metadata=None))), (56491, (143, PredictedToken(token=' Piano', prob=3.1948089599609375e-05, logit=10.3125, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:11 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:11 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.812, logit=22.000)', '\" The\"[578] (p=0.059, logit=19.375)', '\" A\"[362] (p=0.052, logit=19.250)', '\" Among\"[22395] (p=0.028, logit=18.625)', '\" Option\"[7104] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.809, logit=21.500)', '\" The\"[578] (p=0.075, logit=19.125)', '\" Among\"[22395] (p=0.036, logit=18.375)', '\" A\"[362] (p=0.022, logit=17.875)', '\" laptop\"[21288] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.80859375, logit=21.5, token_id=57225, metadata=None))), (23126, (59, PredictedToken(token=' Ti', prob=6.0558319091796875e-05, logit=12.0, token_id=23126, metadata=None))), (18787, (94, PredictedToken(token=' Oak', prob=2.5272369384765625e-05, logit=11.125, token_id=18787, metadata=None))), (100031, (172, PredictedToken(token=' Mosque', prob=8.761882781982422e-06, logit=10.0625, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     int_prediction=['\" Ti\"[23126] (p=0.820, logit=21.250)', '\" The\"[578] (p=0.067, logit=18.750)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" Mosque\"[100031] (p=0.013, logit=17.125)', '\" A\"[362] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     int_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.8203125, logit=21.25, token_id=23126, metadata=None))), (100031, (5, PredictedToken(token=' Mosque', prob=0.0133056640625, logit=17.125, token_id=100031, metadata=None))), (18787, (34, PredictedToken(token=' Oak', prob=0.0002593994140625, logit=13.1875, token_id=18787, metadata=None))), (57225, (51, PredictedToken(token=' Laptop', prob=0.00010776519775390625, logit=12.3125, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:12 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     patch_prediction=['\" Acc\"[11683] (p=0.691, logit=21.750)', '\" The\"[578] (p=0.120, logit=20.000)', '\" An\"[1556] (p=0.083, logit=19.625)', '\" Among\"[22395] (p=0.050, logit=19.125)', '\" It\"[1102] (p=0.016, logit=18.000)']\n",
      "2025-09-16 09:56:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.941, logit=22.000)', '\" The\"[578] (p=0.015, logit=17.875)', '\" Among\"[22395] (p=0.012, logit=17.625)', '\" A\"[362] (p=0.012, logit=17.625)', '\" None\"[2290] (p=0.002, logit=15.688)']\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.94140625, logit=22.0, token_id=41493, metadata=None))), (1630, (24, PredictedToken(token=' X', prob=0.00018024444580078125, logit=13.4375, token_id=1630, metadata=None))), (78703, (65, PredictedToken(token=' Potato', prob=4.029273986816406e-05, logit=11.9375, token_id=78703, metadata=None))), (3816, (66, PredictedToken(token=' Red', prob=3.552436828613281e-05, logit=11.8125, token_id=3816, metadata=None))), (30558, (71, PredictedToken(token=' Ki', prob=3.337860107421875e-05, logit=11.75, token_id=30558, metadata=None)))])\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.053, logit=18.625)', '\" A\"[362] (p=0.022, logit=17.750)', '\" Among\"[22395] (p=0.020, logit=17.625)', '\" (\"[320] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.8359375, logit=21.375, token_id=1630, metadata=None))), (41493, (11, PredictedToken(token=' Tow', prob=0.003021240234375, logit=15.75, token_id=41493, metadata=None))), (30558, (20, PredictedToken(token=' Ki', prob=0.0013427734375, logit=14.9375, token_id=30558, metadata=None))), (3816, (55, PredictedToken(token=' Red', prob=0.00013256072998046875, logit=12.625, token_id=3816, metadata=None))), (78703, (87, PredictedToken(token=' Potato', prob=5.1975250244140625e-05, logit=11.6875, token_id=78703, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:13 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:13 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.781, logit=21.375)', '\" An\"[1556] (p=0.093, logit=19.250)', '\" The\"[578] (p=0.039, logit=18.375)', '\" Among\"[22395] (p=0.027, logit=18.000)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.777, logit=21.250)', '\" The\"[578] (p=0.082, logit=19.000)', '\" Among\"[22395] (p=0.050, logit=18.500)', '\" A\"[362] (p=0.027, logit=17.875)', '\" Option\"[7104] (p=0.009, logit=16.750)']\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.77734375, logit=21.25, token_id=80629, metadata=None))), (57094, (92, PredictedToken(token=' Highlight', prob=3.528594970703125e-05, logit=11.25, token_id=57094, metadata=None))), (21424, (155, PredictedToken(token=' Football', prob=1.2159347534179688e-05, logit=10.1875, token_id=21424, metadata=None))), (38571, (235, PredictedToken(token=' Theater', prob=6.109476089477539e-06, logit=9.5, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.773, logit=21.250)', '\" The\"[578] (p=0.082, logit=19.000)', '\" Among\"[22395] (p=0.050, logit=18.500)', '\" A\"[362] (p=0.030, logit=18.000)', '\" Grape\"[80629] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.7734375, logit=21.25, token_id=57094, metadata=None))), (80629, (5, PredictedToken(token=' Grape', prob=0.009765625, logit=16.875, token_id=80629, metadata=None))), (38571, (21, PredictedToken(token=' Theater', prob=0.00080108642578125, logit=14.375, token_id=38571, metadata=None))), (21424, (59, PredictedToken(token=' Football', prob=0.00011539459228515625, logit=12.4375, token_id=21424, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:13 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:56:13 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.836, logit=22.750)', '\" The\"[578] (p=0.078, logit=20.375)', '\" Among\"[22395] (p=0.053, logit=20.000)', '\" A\"[362] (p=0.013, logit=18.625)', '\" \"[220] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     clean_prediction=['\" Basketball\"[47589] (p=0.895, logit=22.250)', '\" The\"[578] (p=0.045, logit=19.250)', '\" Among\"[22395] (p=0.019, logit=18.375)', '\" A\"[362] (p=0.014, logit=18.125)', '\" It\"[1102] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     clean_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.89453125, logit=22.25, token_id=47589, metadata=None))), (82994, (15, PredictedToken(token=' Toilet', prob=0.000560760498046875, logit=14.875, token_id=82994, metadata=None))), (6031, (23, PredictedToken(token=' Bro', prob=0.0003204345703125, logit=14.3125, token_id=6031, metadata=None))), (30555, (63, PredictedToken(token=' Viol', prob=4.601478576660156e-05, logit=12.375, token_id=30555, metadata=None))), (11452, (120, PredictedToken(token=' Head', prob=1.0967254638671875e-05, logit=10.9375, token_id=11452, metadata=None)))])\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.910, logit=22.125)', '\" The\"[578] (p=0.045, logit=19.125)', '\" Among\"[22395] (p=0.011, logit=17.750)', '\" Basketball\"[47589] (p=0.005, logit=17.000)', '\" It\"[1102] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.91015625, logit=22.125, token_id=6031, metadata=None))), (47589, (4, PredictedToken(token=' Basketball', prob=0.005401611328125, logit=17.0, token_id=47589, metadata=None))), (82994, (96, PredictedToken(token=' Toilet', prob=2.0742416381835938e-05, logit=11.4375, token_id=82994, metadata=None))), (30555, (158, PredictedToken(token=' Viol', prob=7.62939453125e-06, logit=10.4375, token_id=30555, metadata=None))), (11452, (285, PredictedToken(token=' Head', prob=2.4884939193725586e-06, logit=9.3125, token_id=11452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:14 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:14 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     patch_prediction=['\" Coat\"[68867] (p=0.711, logit=21.750)', '\" The\"[578] (p=0.109, logit=19.875)', '\" Among\"[22395] (p=0.066, logit=19.375)', '\" A\"[362] (p=0.066, logit=19.375)', '\" CO\"[7432] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:56:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     clean_prediction=['\" Television\"[41445] (p=0.703, logit=21.250)', '\" The\"[578] (p=0.138, logit=19.625)', '\" Among\"[22395] (p=0.051, logit=18.625)', '\" A\"[362] (p=0.016, logit=17.500)', '\" Option\"[7104] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     clean_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.703125, logit=21.25, token_id=41445, metadata=None))), (423, (28, PredictedToken(token=' D', prob=0.00077056884765625, logit=14.4375, token_id=423, metadata=None))), (27171, (29, PredictedToken(token=' Coffee', prob=0.00072479248046875, logit=14.375, token_id=27171, metadata=None))), (82507, (269, PredictedToken(token=' Jeans', prob=6.258487701416016e-06, logit=9.625, token_id=82507, metadata=None))), (76924, (333, PredictedToken(token=' Banana', prob=4.0531158447265625e-06, logit=9.1875, token_id=76924, metadata=None)))])\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     int_prediction=['\" Jeans\"[82507] (p=0.891, logit=21.750)', '\" The\"[578] (p=0.044, logit=18.750)', '\" Among\"[22395] (p=0.021, logit=18.000)', '\" Out\"[4470] (p=0.005, logit=16.500)', '\" “\"[1054] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     int_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.890625, logit=21.75, token_id=82507, metadata=None))), (423, (13, PredictedToken(token=' D', prob=0.00125885009765625, logit=15.1875, token_id=423, metadata=None))), (76924, (104, PredictedToken(token=' Banana', prob=2.6106834411621094e-05, logit=11.3125, token_id=76924, metadata=None))), (27171, (141, PredictedToken(token=' Coffee', prob=1.3947486877441406e-05, logit=10.6875, token_id=27171, metadata=None))), (41445, (147, PredictedToken(token=' Television', prob=1.3113021850585938e-05, logit=10.625, token_id=41445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:15 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:15 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.844, logit=22.875)', '\" The\"[578] (p=0.069, logit=20.375)', '\" Among\"[22395] (p=0.061, logit=20.250)', '\" It\"[1102] (p=0.006, logit=17.875)', '\" A\"[362] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     clean_prediction=['\" Apple\"[8325] (p=0.645, logit=21.500)', '\" The\"[578] (p=0.144, logit=20.000)', '\" An\"[1556] (p=0.099, logit=19.625)', '\" Among\"[22395] (p=0.068, logit=19.250)', '\" There\"[2684] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     clean_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.64453125, logit=21.5, token_id=8325, metadata=None))), (60413, (16, PredictedToken(token=' Uk', prob=0.0010986328125, logit=15.125, token_id=60413, metadata=None))), (78703, (32, PredictedToken(token=' Potato', prob=0.0004291534423828125, logit=14.1875, token_id=78703, metadata=None))), (82994, (266, PredictedToken(token=' Toilet', prob=4.500150680541992e-06, logit=9.625, token_id=82994, metadata=None))), (39794, (2248, PredictedToken(token=' Desk', prob=1.5366822481155396e-07, logit=6.25, token_id=39794, metadata=None))), (52466, (2468, PredictedToken(token=' Warehouse', prob=1.3504177331924438e-07, logit=6.125, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     int_prediction=['\" Potato\"[78703] (p=0.326, logit=20.250)', '\" Apple\"[8325] (p=0.254, logit=20.000)', '\" The\"[578] (p=0.224, logit=19.875)', '\" Among\"[22395] (p=0.120, logit=19.250)', '\" An\"[1556] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     int_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.326171875, logit=20.25, token_id=78703, metadata=None))), (8325, (2, PredictedToken(token=' Apple', prob=0.25390625, logit=20.0, token_id=8325, metadata=None))), (60413, (10, PredictedToken(token=' Uk', prob=0.002655029296875, logit=15.4375, token_id=60413, metadata=None))), (82994, (22, PredictedToken(token=' Toilet', prob=0.0011749267578125, logit=14.625, token_id=82994, metadata=None))), (52466, (26, PredictedToken(token=' Warehouse', prob=0.000858306884765625, logit=14.3125, token_id=52466, metadata=None))), (39794, (402, PredictedToken(token=' Desk', prob=3.516674041748047e-06, logit=8.8125, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:15 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:15 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:15 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.895, logit=22.500)', '\" The\"[578] (p=0.039, logit=19.375)', '\" A\"[362] (p=0.027, logit=19.000)', '\" Among\"[22395] (p=0.007, logit=17.625)', '\" night\"[3814] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.844, logit=21.125)', '\" The\"[578] (p=0.033, logit=17.875)', '\" Among\"[22395] (p=0.029, logit=17.750)', '\" Bench\"[36358] (p=0.015, logit=17.125)', '\" A\"[362] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.84375, logit=21.125, token_id=445, metadata=None))), (36358, (5, PredictedToken(token=' Bench', prob=0.01544189453125, logit=17.125, token_id=36358, metadata=None))), (3816, (30, PredictedToken(token=' Red', prob=0.0003871917724609375, logit=13.4375, token_id=3816, metadata=None)))])\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.535, logit=21.000)', '\" L\"[445] (p=0.367, logit=20.625)', '\" The\"[578] (p=0.023, logit=17.875)', '\" Among\"[22395] (p=0.018, logit=17.625)', '\" None\"[2290] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.53515625, logit=21.0, token_id=36358, metadata=None))), (445, (2, PredictedToken(token=' L', prob=0.3671875, logit=20.625, token_id=445, metadata=None))), (3816, (8, PredictedToken(token=' Red', prob=0.002471923828125, logit=15.625, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:16 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.934, logit=21.875)', '\" The\"[578] (p=0.015, logit=17.750)', '\" Drum\"[46506] (p=0.010, logit=17.375)', '\" Glo\"[25372] (p=0.007, logit=17.000)', '\" Among\"[22395] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:56:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.664, logit=20.875)', '\" The\"[578] (p=0.168, logit=19.500)', '\" Among\"[22395] (p=0.048, logit=18.250)', '\" A\"[362] (p=0.048, logit=18.250)', '\" It\"[1102] (p=0.018, logit=17.250)']\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.6640625, logit=20.875, token_id=94467, metadata=None))), (82507, (37, PredictedToken(token=' Jeans', prob=0.0003032684326171875, logit=13.1875, token_id=82507, metadata=None))), (36895, (234, PredictedToken(token=' Eagle', prob=6.735324859619141e-06, logit=9.375, token_id=36895, metadata=None))), (71264, (2497, PredictedToken(token=' Daisy', prob=2.5331974029541016e-07, logit=6.09375, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     int_prediction=['\" Jeans\"[82507] (p=0.516, logit=20.250)', '\" Trom\"[94467] (p=0.243, logit=19.500)', '\" The\"[578] (p=0.102, logit=18.625)', '\" Among\"[22395] (p=0.048, logit=17.875)', '\" JE\"[71430] (p=0.014, logit=16.625)']\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     int_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.515625, logit=20.25, token_id=82507, metadata=None))), (94467, (2, PredictedToken(token=' Trom', prob=0.2431640625, logit=19.5, token_id=94467, metadata=None))), (71264, (17, PredictedToken(token=' Daisy', prob=0.00164031982421875, logit=14.5, token_id=71264, metadata=None))), (36895, (21, PredictedToken(token=' Eagle', prob=0.001129150390625, logit=14.125, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:17 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:17 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     patch_prediction=['\" Mar\"[2947] (p=0.836, logit=22.125)', '\" The\"[578] (p=0.078, logit=19.750)', '\" Among\"[22395] (p=0.029, logit=18.750)', '\" A\"[362] (p=0.017, logit=18.250)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.680, logit=21.000)', '\" Among\"[22395] (p=0.092, logit=19.000)', '\" The\"[578] (p=0.092, logit=19.000)', '\" A\"[362] (p=0.049, logit=18.375)', '\" Option\"[7104] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6796875, logit=21.0, token_id=27171, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.006683349609375, logit=16.375, token_id=469, metadata=None))), (41342, (57, PredictedToken(token=' Hockey', prob=0.00010824203491210938, logit=12.25, token_id=41342, metadata=None))), (27738, (59, PredictedToken(token=' Ward', prob=0.00010156631469726562, logit=12.1875, token_id=27738, metadata=None))), (49431, (176, PredictedToken(token=' Rabbit', prob=1.0669231414794922e-05, logit=9.9375, token_id=49431, metadata=None))), (82452, (526, PredictedToken(token=' Jasmine', prob=1.4007091522216797e-06, logit=7.90625, token_id=82452, metadata=None)))])\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.832, logit=21.500)', '\" Among\"[22395] (p=0.060, logit=18.875)', '\" The\"[578] (p=0.029, logit=18.125)', '\" Option\"[7104] (p=0.013, logit=17.375)', '\" E\"[469] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.83203125, logit=21.5, token_id=82452, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.010498046875, logit=17.125, token_id=469, metadata=None))), (27738, (8, PredictedToken(token=' Ward', prob=0.0034027099609375, logit=16.0, token_id=27738, metadata=None))), (49431, (41, PredictedToken(token=' Rabbit', prob=0.0002040863037109375, logit=13.1875, token_id=49431, metadata=None))), (27171, (367, PredictedToken(token=' Coffee', prob=2.0116567611694336e-06, logit=8.5625, token_id=27171, metadata=None))), (41342, (2471, PredictedToken(token=' Hockey', prob=1.4528632164001465e-07, logit=5.9375, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:17 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:17 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:56:17 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.898, logit=22.125)', '\" The\"[578] (p=0.045, logit=19.125)', '\" Among\"[22395] (p=0.021, logit=18.375)', '\" Glo\"[25372] (p=0.008, logit=17.375)', '\" It\"[1102] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.828, logit=22.250)', '\" The\"[578] (p=0.099, logit=20.125)', '\" Among\"[22395] (p=0.028, logit=18.875)', '\" A\"[362] (p=0.022, logit=18.625)', '\" (\"[320] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.828125, logit=22.25, token_id=42609, metadata=None))), (1630, (100, PredictedToken(token=' X', prob=1.2993812561035156e-05, logit=11.1875, token_id=1630, metadata=None))), (22050, (252, PredictedToken(token=' Hat', prob=2.5480985641479492e-06, logit=9.5625, token_id=22050, metadata=None)))])\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     int_prediction=['\" Hat\"[22050] (p=0.727, logit=21.750)', '\" The\"[578] (p=0.087, logit=19.625)', '\" Pine\"[42609] (p=0.077, logit=19.500)', '\" A\"[362] (p=0.041, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.375)']\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     int_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.7265625, logit=21.75, token_id=22050, metadata=None))), (42609, (3, PredictedToken(token=' Pine', prob=0.07666015625, logit=19.5, token_id=42609, metadata=None))), (1630, (20, PredictedToken(token=' X', prob=0.00058746337890625, logit=14.625, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:18 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:56:18 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.758, logit=21.375)', '\" The\"[578] (p=0.080, logit=19.125)', '\" A\"[362] (p=0.055, logit=18.750)', '\" Among\"[22395] (p=0.043, logit=18.500)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.797, logit=22.250)', '\" The\"[578] (p=0.058, logit=19.625)', '\" A\"[362] (p=0.051, logit=19.500)', '\" Among\"[22395] (p=0.019, logit=18.500)', '\" (\"[320] (p=0.017, logit=18.375)']\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.796875, logit=22.25, token_id=22607, metadata=None))), (41445, (134, PredictedToken(token=' Television', prob=7.599592208862305e-06, logit=10.6875, token_id=41445, metadata=None))), (38571, (137, PredictedToken(token=' Theater', prob=7.12275505065918e-06, logit=10.625, token_id=38571, metadata=None))), (37128, (491, PredictedToken(token=' Calculator', prob=7.525086402893066e-07, logit=8.375, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     int_prediction=['\" Calculator\"[37128] (p=0.369, logit=19.875)', '\" Television\"[41445] (p=0.198, logit=19.250)', '\" The\"[578] (p=0.154, logit=19.000)', '\" A\"[362] (p=0.073, logit=18.250)', '\" Option\"[7104] (p=0.030, logit=17.375)']\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     int_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.369140625, logit=19.875, token_id=37128, metadata=None))), (41445, (2, PredictedToken(token=' Television', prob=0.1982421875, logit=19.25, token_id=41445, metadata=None))), (38571, (149, PredictedToken(token=' Theater', prob=3.790855407714844e-05, logit=10.6875, token_id=38571, metadata=None))), (22607, (1063, PredictedToken(token=' Cow', prob=1.5124678611755371e-06, logit=7.46875, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:19 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.906, logit=22.000)', '\" None\"[2290] (p=0.027, logit=18.500)', '\" The\"[578] (p=0.027, logit=18.500)', '\" Among\"[22395] (p=0.006, logit=17.000)', '\" There\"[2684] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     clean_prediction=['\" Phone\"[14642] (p=0.809, logit=21.750)', '\" The\"[578] (p=0.075, logit=19.375)', '\" Among\"[22395] (p=0.031, logit=18.500)', '\" A\"[362] (p=0.019, logit=18.000)', '\" phone\"[4641] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     clean_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.80859375, logit=21.75, token_id=14642, metadata=None))), (356, (15, PredictedToken(token=' C', prob=0.00156402587890625, logit=15.5, token_id=356, metadata=None))), (32498, (123, PredictedToken(token=' Mall', prob=1.9669532775878906e-05, logit=11.125, token_id=32498, metadata=None))), (48390, (681, PredictedToken(token=' Lily', prob=6.51925802230835e-07, logit=7.71875, token_id=48390, metadata=None)))])\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.688, logit=21.375)', '\" Lily\"[48390] (p=0.153, logit=19.875)', '\" The\"[578] (p=0.056, logit=18.875)', '\" Among\"[22395] (p=0.030, logit=18.250)', '\" A\"[362] (p=0.013, logit=17.375)']\n",
      "2025-09-16 09:56:19 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.6875, logit=21.375, token_id=356, metadata=None))), (48390, (2, PredictedToken(token=' Lily', prob=0.1533203125, logit=19.875, token_id=48390, metadata=None))), (14642, (124, PredictedToken(token=' Phone', prob=2.014636993408203e-05, logit=10.9375, token_id=14642, metadata=None))), (32498, (963, PredictedToken(token=' Mall', prob=6.258487701416016e-07, logit=7.46875, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:20 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:20 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.809, logit=21.375)', '\" The\"[578] (p=0.085, logit=19.125)', '\" A\"[362] (p=0.031, logit=18.125)', '\" Among\"[22395] (p=0.021, logit=17.750)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.785, logit=21.375)', '\" The\"[578] (p=0.073, logit=19.000)', '\" Among\"[22395] (p=0.064, logit=18.875)', '\" A\"[362] (p=0.027, logit=18.000)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.78515625, logit=21.375, token_id=3816, metadata=None))), (1666, (7, PredictedToken(token=' As', prob=0.0030059814453125, logit=15.8125, token_id=1666, metadata=None))), (61731, (8, PredictedToken(token=' Soap', prob=0.0028228759765625, logit=15.75, token_id=61731, metadata=None))), (38258, (447, PredictedToken(token=' Baseball', prob=2.130866050720215e-06, logit=8.5625, token_id=38258, metadata=None))), (38930, (942, PredictedToken(token=' Bike', prob=7.37607479095459e-07, logit=7.5, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.508, logit=20.000)', '\" The\"[578] (p=0.146, logit=18.750)', '\" A\"[362] (p=0.069, logit=18.000)', '\" Soap\"[61731] (p=0.061, logit=17.875)', '\" Among\"[22395] (p=0.061, logit=17.875)']\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.5078125, logit=20.0, token_id=38930, metadata=None))), (61731, (5, PredictedToken(token=' Soap', prob=0.060791015625, logit=17.875, token_id=61731, metadata=None))), (3816, (6, PredictedToken(token=' Red', prob=0.0286865234375, logit=17.125, token_id=3816, metadata=None))), (1666, (7, PredictedToken(token=' As', prob=0.015380859375, logit=16.5, token_id=1666, metadata=None))), (38258, (9, PredictedToken(token=' Baseball', prob=0.0087890625, logit=15.9375, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:20 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:20 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:20 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.855, logit=22.625)', '\" A\"[362] (p=0.080, logit=20.250)', '\" The\"[578] (p=0.020, logit=18.875)', '\" pin\"[9160] (p=0.018, logit=18.750)', '\" Among\"[22395] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.715, logit=22.375)', '\" The\"[578] (p=0.124, logit=20.625)', '\" A\"[362] (p=0.097, logit=20.375)', '\" Among\"[22395] (p=0.031, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.71484375, logit=22.375, token_id=34785, metadata=None))), (70306, (49, PredictedToken(token=' Brace', prob=8.821487426757812e-05, logit=13.375, token_id=70306, metadata=None))), (21424, (88, PredictedToken(token=' Football', prob=2.09808349609375e-05, logit=11.9375, token_id=21424, metadata=None)))])\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     int_prediction=['\" Brace\"[70306] (p=0.742, logit=22.000)', '\" The\"[578] (p=0.101, logit=20.000)', '\" A\"[362] (p=0.089, logit=19.875)', '\" Football\"[21424] (p=0.014, logit=18.000)', '\" B\"[426] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     int_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.7421875, logit=22.0, token_id=70306, metadata=None))), (21424, (4, PredictedToken(token=' Football', prob=0.01361083984375, logit=18.0, token_id=21424, metadata=None))), (34785, (9, PredictedToken(token=' Truck', prob=0.002685546875, logit=16.375, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:21 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:21 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.852, logit=22.500)', '\" The\"[578] (p=0.054, logit=19.750)', '\" A\"[362] (p=0.037, logit=19.375)', '\" Among\"[22395] (p=0.020, logit=18.750)', '\" night\"[3814] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.902, logit=22.625)', '\" Among\"[22395] (p=0.045, logit=19.625)', '\" The\"[578] (p=0.031, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.750)', '\" It\"[1102] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.90234375, logit=22.625, token_id=1666, metadata=None))), (65449, (32, PredictedToken(token=' Willow', prob=0.00015163421630859375, logit=13.9375, token_id=65449, metadata=None))), (61948, (443, PredictedToken(token=' Sofa', prob=8.493661880493164e-07, logit=8.75, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:56:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     int_prediction=['\" Sofa\"[61948] (p=0.680, logit=20.500)', '\" The\"[578] (p=0.082, logit=18.375)', '\" A\"[362] (p=0.063, logit=18.125)', '\" Among\"[22395] (p=0.049, logit=17.875)', '\" Option\"[7104] (p=0.018, logit=16.875)']\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     int_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.6796875, logit=20.5, token_id=61948, metadata=None))), (1666, (12, PredictedToken(token=' As', prob=0.004058837890625, logit=15.375, token_id=1666, metadata=None))), (65449, (18, PredictedToken(token=' Willow', prob=0.001800537109375, logit=14.5625, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:22 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.770, logit=21.375)', '\" The\"[578] (p=0.081, logit=19.125)', '\" Among\"[22395] (p=0.071, logit=19.000)', '\" A\"[362] (p=0.023, logit=17.875)', '\" l\"[326] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     clean_prediction=['\" Mushroom\"[91297] (p=0.781, logit=20.250)', '\" The\"[578] (p=0.064, logit=17.750)', '\" A\"[362] (p=0.056, logit=17.625)', '\" Among\"[22395] (p=0.024, logit=16.750)', '\" None\"[2290] (p=0.007, logit=15.562)']\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     clean_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.78125, logit=20.25, token_id=91297, metadata=None))), (6771, (27, PredictedToken(token=' Table', prob=0.000629425048828125, logit=13.125, token_id=6771, metadata=None))), (71264, (64, PredictedToken(token=' Daisy', prob=0.0001239776611328125, logit=11.5, token_id=71264, metadata=None))), (68027, (74, PredictedToken(token=' Sax', prob=0.00010251998901367188, logit=11.3125, token_id=68027, metadata=None))), (58586, (189, PredictedToken(token=' Tape', prob=2.014636993408203e-05, logit=9.6875, token_id=58586, metadata=None)))])\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.633, logit=20.000)', '\" Mushroom\"[91297] (p=0.110, logit=18.250)', '\" A\"[362] (p=0.076, logit=17.875)', '\" The\"[578] (p=0.066, logit=17.750)', '\" None\"[2290] (p=0.015, logit=16.250)']\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.6328125, logit=20.0, token_id=71264, metadata=None))), (91297, (2, PredictedToken(token=' Mushroom', prob=0.10986328125, logit=18.25, token_id=91297, metadata=None))), (6771, (42, PredictedToken(token=' Table', prob=0.0003719329833984375, logit=12.5625, token_id=6771, metadata=None))), (68027, (62, PredictedToken(token=' Sax', prob=0.00015544891357421875, logit=11.6875, token_id=68027, metadata=None))), (58586, (238, PredictedToken(token=' Tape', prob=1.633167266845703e-05, logit=9.4375, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:22 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:56:22 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.793, logit=21.875)', '\" The\"[578] (p=0.083, logit=19.625)', '\" A\"[362] (p=0.040, logit=18.875)', '\" Among\"[22395] (p=0.027, logit=18.500)', '\" cat\"[8415] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.867, logit=22.000)', '\" An\"[1556] (p=0.043, logit=19.000)', '\" The\"[578] (p=0.030, logit=18.625)', '\" Among\"[22395] (p=0.023, logit=18.375)', '\" ank\"[71572] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.8671875, logit=22.0, token_id=57915, metadata=None))), (14642, (29, PredictedToken(token=' Phone', prob=0.0002002716064453125, logit=13.625, token_id=14642, metadata=None))), (19111, (51, PredictedToken(token=' Bus', prob=7.343292236328125e-05, logit=12.625, token_id=19111, metadata=None))), (84008, (372, PredictedToken(token=' Sheep', prob=1.7285346984863281e-06, logit=8.875, token_id=84008, metadata=None))), (78703, (423, PredictedToken(token=' Potato', prob=1.4379620552062988e-06, logit=8.6875, token_id=78703, metadata=None)))])\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     int_prediction=['\" Sheep\"[84008] (p=0.781, logit=20.875)', '\" A\"[362] (p=0.064, logit=18.375)', '\" The\"[578] (p=0.044, logit=18.000)', '\" Among\"[22395] (p=0.034, logit=17.750)', '\" Ank\"[57915] (p=0.016, logit=17.000)']\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     int_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.78125, logit=20.875, token_id=84008, metadata=None))), (57915, (5, PredictedToken(token=' Ank', prob=0.0162353515625, logit=17.0, token_id=57915, metadata=None))), (19111, (6, PredictedToken(token=' Bus', prob=0.0052490234375, logit=15.875, token_id=19111, metadata=None))), (78703, (21, PredictedToken(token=' Potato', prob=0.000972747802734375, logit=14.1875, token_id=78703, metadata=None))), (14642, (198, PredictedToken(token=' Phone', prob=1.150369644165039e-05, logit=9.75, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:23 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.848, logit=22.375)', '\" A\"[362] (p=0.069, logit=19.875)', '\" The\"[578] (p=0.037, logit=19.250)', '\" Among\"[22395] (p=0.012, logit=18.125)', '\" It\"[1102] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     clean_prediction=['\" Router\"[10777] (p=0.676, logit=20.375)', '\" The\"[578] (p=0.081, logit=18.250)', '\" B\"[426] (p=0.071, logit=18.125)', '\" Among\"[22395] (p=0.034, logit=17.375)', '\" A\"[362] (p=0.030, logit=17.250)']\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     clean_track=OrderedDict([(10777, (1, PredictedToken(token=' Router', prob=0.67578125, logit=20.375, token_id=10777, metadata=None))), (426, (3, PredictedToken(token=' B', prob=0.0712890625, logit=18.125, token_id=426, metadata=None))), (1630, (34, PredictedToken(token=' X', prob=0.000698089599609375, logit=13.5, token_id=1630, metadata=None))), (1443, (90, PredictedToken(token=' Sh', prob=8.869171142578125e-05, logit=11.4375, token_id=1443, metadata=None))), (29318, (441, PredictedToken(token=' Dress', prob=4.410743713378906e-06, logit=8.4375, token_id=29318, metadata=None))), (80629, (446, PredictedToken(token=' Grape', prob=4.410743713378906e-06, logit=8.4375, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:56:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.859, logit=21.750)', '\" The\"[578] (p=0.033, logit=18.500)', '\" b\"[293] (p=0.023, logit=18.125)', '\" A\"[362] (p=0.016, logit=17.750)', '\" Among\"[22395] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.859375, logit=21.75, token_id=426, metadata=None))), (29318, (7, PredictedToken(token=' Dress', prob=0.005767822265625, logit=16.75, token_id=29318, metadata=None))), (1630, (9, PredictedToken(token=' X', prob=0.003509521484375, logit=16.25, token_id=1630, metadata=None))), (1443, (17, PredictedToken(token=' Sh', prob=0.00128936767578125, logit=15.25, token_id=1443, metadata=None))), (80629, (51, PredictedToken(token=' Grape', prob=0.00010585784912109375, logit=12.75, token_id=80629, metadata=None))), (10777, (134, PredictedToken(token=' Router', prob=1.3470649719238281e-05, logit=10.6875, token_id=10777, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:24 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:24 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.852, logit=22.375)', '\" The\"[578] (p=0.054, logit=19.625)', '\" A\"[362] (p=0.048, logit=19.500)', '\" Among\"[22395] (p=0.020, logit=18.625)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.645, logit=21.625)', '\" Among\"[22395] (p=0.127, logit=20.000)', '\" The\"[578] (p=0.112, logit=19.875)', '\" A\"[362] (p=0.068, logit=19.375)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.64453125, logit=21.625, token_id=4923, metadata=None))), (469, (17, PredictedToken(token=' E', prob=0.00090789794921875, logit=15.0625, token_id=469, metadata=None))), (33199, (59, PredictedToken(token=' Lion', prob=8.440017700195312e-05, logit=12.6875, token_id=33199, metadata=None))), (816, (88, PredictedToken(token=' Y', prob=3.528594970703125e-05, logit=11.8125, token_id=816, metadata=None))), (1901, (132, PredictedToken(token=' Z', prob=1.3768672943115234e-05, logit=10.875, token_id=1901, metadata=None))), (83499, (163, PredictedToken(token=' Tooth', prob=8.344650268554688e-06, logit=10.375, token_id=83499, metadata=None)))])\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     int_prediction=['\" Lion\"[33199] (p=0.730, logit=21.375)', '\" The\"[578] (p=0.087, logit=19.250)', '\" A\"[362] (p=0.077, logit=19.125)', '\" Among\"[22395] (p=0.036, logit=18.375)', '\" Y\"[816] (p=0.019, logit=17.750)']\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     int_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.73046875, logit=21.375, token_id=33199, metadata=None))), (816, (5, PredictedToken(token=' Y', prob=0.0194091796875, logit=17.75, token_id=816, metadata=None))), (469, (43, PredictedToken(token=' E', prob=0.00022983551025390625, logit=13.3125, token_id=469, metadata=None))), (1901, (118, PredictedToken(token=' Z', prob=2.1338462829589844e-05, logit=10.9375, token_id=1901, metadata=None))), (83499, (121, PredictedToken(token=' Tooth', prob=2.014636993408203e-05, logit=10.875, token_id=83499, metadata=None))), (4923, (239, PredictedToken(token=' Sk', prob=5.066394805908203e-06, logit=9.5, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:24 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:24 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:56:24 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.859, logit=22.500)', '\" The\"[578] (p=0.062, logit=19.875)', '\" Among\"[22395] (p=0.043, logit=19.500)', '\" JE\"[71430] (p=0.011, logit=18.125)', '\" A\"[362] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.816, logit=21.750)', '\" The\"[578] (p=0.067, logit=19.250)', '\" A\"[362] (p=0.041, logit=18.750)', '\" Among\"[22395] (p=0.032, logit=18.500)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.81640625, logit=21.75, token_id=5907, metadata=None))), (38571, (10, PredictedToken(token=' Theater', prob=0.0014801025390625, logit=15.4375, token_id=38571, metadata=None))), (60413, (37, PredictedToken(token=' Uk', prob=0.00024127960205078125, logit=13.625, token_id=60413, metadata=None))), (37326, (134, PredictedToken(token=' Swe', prob=1.6450881958007812e-05, logit=10.9375, token_id=37326, metadata=None))), (48665, (893, PredictedToken(token=' Raspberry', prob=4.675239324569702e-07, logit=7.375, token_id=48665, metadata=None))), (65329, (1379, PredictedToken(token=' Elm', prob=2.421438694000244e-07, logit=6.71875, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.766, logit=20.750)', '\" The\"[578] (p=0.081, logit=18.500)', '\" A\"[362] (p=0.071, logit=18.375)', '\" Among\"[22395] (p=0.012, logit=16.625)', '\" Theater\"[38571] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.765625, logit=20.75, token_id=37326, metadata=None))), (38571, (5, PredictedToken(token=' Theater', prob=0.0096435546875, logit=16.375, token_id=38571, metadata=None))), (65329, (33, PredictedToken(token=' Elm', prob=0.000545501708984375, logit=13.5, token_id=65329, metadata=None))), (5907, (53, PredictedToken(token=' Project', prob=0.000156402587890625, logit=12.25, token_id=5907, metadata=None))), (48665, (106, PredictedToken(token=' Raspberry', prob=4.482269287109375e-05, logit=11.0, token_id=48665, metadata=None))), (60413, (312, PredictedToken(token=' Uk', prob=5.692243576049805e-06, logit=8.9375, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:25 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     patch_prediction=['\" Razor\"[74968] (p=0.910, logit=21.375)', '\" The\"[578] (p=0.019, logit=17.500)', '\" Among\"[22395] (p=0.013, logit=17.125)', '\" A\"[362] (p=0.013, logit=17.125)', '\" R\"[432] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:56:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.432, logit=19.500)', '\" None\"[2290] (p=0.381, logit=19.375)', '\" Magn\"[20918] (p=0.021, logit=16.500)', '\" There\"[2684] (p=0.021, logit=16.500)', '\" Tennis\"[58251] (p=0.019, logit=16.375)']\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.431640625, logit=19.5, token_id=10573, metadata=None))), (20918, (4, PredictedToken(token=' Magn', prob=0.021484375, logit=16.5, token_id=20918, metadata=None))), (58251, (5, PredictedToken(token=' Tennis', prob=0.0189208984375, logit=16.375, token_id=58251, metadata=None))), (36358, (9, PredictedToken(token=' Bench', prob=0.01080322265625, logit=15.8125, token_id=36358, metadata=None))), (41445, (26, PredictedToken(token=' Television', prob=0.000885009765625, logit=13.3125, token_id=41445, metadata=None))), (48471, (28, PredictedToken(token=' Shower', prob=0.00083160400390625, logit=13.25, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     int_prediction=['\" Watch\"[10573] (p=0.363, logit=20.250)', '\" Bench\"[36358] (p=0.283, logit=20.000)', '\" None\"[2290] (p=0.172, logit=19.500)', '\" A\"[362] (p=0.049, logit=18.250)', '\" The\"[578] (p=0.021, logit=17.375)']\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     int_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.36328125, logit=20.25, token_id=10573, metadata=None))), (36358, (2, PredictedToken(token=' Bench', prob=0.283203125, logit=20.0, token_id=36358, metadata=None))), (48471, (7, PredictedToken(token=' Shower', prob=0.01409912109375, logit=17.0, token_id=48471, metadata=None))), (41445, (8, PredictedToken(token=' Television', prob=0.012451171875, logit=16.875, token_id=41445, metadata=None))), (58251, (9, PredictedToken(token=' Tennis', prob=0.00970458984375, logit=16.625, token_id=58251, metadata=None))), (20918, (37, PredictedToken(token=' Magn', prob=0.0003757476806640625, logit=13.375, token_id=20918, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:26 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:26 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.836, logit=22.000)', '\" The\"[578] (p=0.042, logit=19.000)', '\" A\"[362] (p=0.042, logit=19.000)', '\" Among\"[22395] (p=0.032, logit=18.750)', '\" slow\"[6435] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.832, logit=22.750)', '\" The\"[578] (p=0.078, logit=20.375)', '\" A\"[362] (p=0.047, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=19.125)', '\" SH\"[6570] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.83203125, logit=22.75, token_id=55807, metadata=None))), (21424, (54, PredictedToken(token=' Football', prob=2.944469451904297e-05, logit=12.5, token_id=21424, metadata=None))), (87213, (295, PredictedToken(token=' Oven', prob=1.296401023864746e-06, logit=9.375, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.770, logit=21.500)', '\" The\"[578] (p=0.092, logit=19.375)', '\" An\"[1556] (p=0.043, logit=18.625)', '\" Football\"[21424] (p=0.021, logit=17.875)', '\" Among\"[22395] (p=0.018, logit=17.750)']\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.76953125, logit=21.5, token_id=87213, metadata=None))), (21424, (4, PredictedToken(token=' Football', prob=0.0205078125, logit=17.875, token_id=21424, metadata=None))), (55807, (7, PredictedToken(token=' Shirt', prob=0.00518798828125, logit=16.5, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:26 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:26 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:56:26 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     patch_prediction=['\" Ju\"[22410] (p=0.504, logit=20.500)', '\" A\"[362] (p=0.163, logit=19.375)', '\" The\"[578] (p=0.145, logit=19.250)', '\" Among\"[22395] (p=0.099, logit=18.875)', '\" Option\"[7104] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     clean_prediction=['\" Temple\"[19176] (p=0.840, logit=21.500)', '\" The\"[578] (p=0.054, logit=18.750)', '\" A\"[362] (p=0.047, logit=18.625)', '\" Among\"[22395] (p=0.022, logit=17.875)', '\" It\"[1102] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     clean_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.83984375, logit=21.5, token_id=19176, metadata=None))), (43316, (53, PredictedToken(token=' Tul', prob=8.058547973632812e-05, logit=12.25, token_id=43316, metadata=None))), (4923, (60, PredictedToken(token=' Sk', prob=6.29425048828125e-05, logit=12.0, token_id=4923, metadata=None))), (75258, (104, PredictedToken(token=' Refriger', prob=1.800060272216797e-05, logit=10.75, token_id=75258, metadata=None)))])\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.680, logit=20.375)', '\" The\"[578] (p=0.104, logit=18.500)', '\" A\"[362] (p=0.063, logit=18.000)', '\" Among\"[22395] (p=0.026, logit=17.125)', '\" Refriger\"[75258] (p=0.023, logit=17.000)']\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.6796875, logit=20.375, token_id=4923, metadata=None))), (75258, (5, PredictedToken(token=' Refriger', prob=0.0233154296875, logit=17.0, token_id=75258, metadata=None))), (43316, (8, PredictedToken(token=' Tul', prob=0.010986328125, logit=16.25, token_id=43316, metadata=None))), (19176, (119, PredictedToken(token=' Temple', prob=4.482269287109375e-05, logit=10.75, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:27 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:27 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:27 src.selection.optimization INFO     patch_prediction=['\" Truck\"[34785] (p=0.582, logit=21.125)', '\" The\"[578] (p=0.147, logit=19.750)', '\" A\"[362] (p=0.130, logit=19.625)', '\" Among\"[22395] (p=0.079, logit=19.125)', '\" It\"[1102] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.840, logit=21.750)', '\" The\"[578] (p=0.061, logit=19.125)', '\" Among\"[22395] (p=0.032, logit=18.500)', '\" A\"[362] (p=0.032, logit=18.500)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.83984375, logit=21.75, token_id=42609, metadata=None))), (426, (32, PredictedToken(token=' B', prob=0.00019359588623046875, logit=13.375, token_id=426, metadata=None))), (16183, (58, PredictedToken(token=' Hel', prob=5.555152893066406e-05, logit=12.125, token_id=16183, metadata=None))), (6031, (63, PredictedToken(token=' Bro', prob=4.601478576660156e-05, logit=11.9375, token_id=6031, metadata=None))), (72683, (1744, PredictedToken(token=' Boxing', prob=2.1327286958694458e-07, logit=6.5625, token_id=72683, metadata=None))), (52466, (1877, PredictedToken(token=' Warehouse', prob=1.9371509552001953e-07, logit=6.46875, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.730, logit=21.250)', '\" The\"[578] (p=0.068, logit=18.875)', '\" A\"[362] (p=0.068, logit=18.875)', '\" Pine\"[42609] (p=0.053, logit=18.625)', '\" Among\"[22395] (p=0.028, logit=18.000)']\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.73046875, logit=21.25, token_id=16183, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.052978515625, logit=18.625, token_id=42609, metadata=None))), (426, (13, PredictedToken(token=' B', prob=0.0018157958984375, logit=15.25, token_id=426, metadata=None))), (6031, (18, PredictedToken(token=' Bro', prob=0.0013275146484375, logit=14.9375, token_id=6031, metadata=None))), (72683, (38, PredictedToken(token=' Boxing', prob=0.000278472900390625, logit=13.375, token_id=72683, metadata=None))), (52466, (160, PredictedToken(token=' Warehouse', prob=1.4722347259521484e-05, logit=10.4375, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:28 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:28 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     patch_prediction=['\" Bus\"[19111] (p=0.680, logit=21.625)', '\" The\"[578] (p=0.134, logit=20.000)', '\" Among\"[22395] (p=0.072, logit=19.375)', '\" A\"[362] (p=0.056, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     clean_prediction=['\" Bed\"[13394] (p=0.805, logit=22.500)', '\" The\"[578] (p=0.085, logit=20.250)', '\" A\"[362] (p=0.045, logit=19.625)', '\" Among\"[22395] (p=0.028, logit=19.125)', '\" BED\"[83364] (p=0.007, logit=17.750)']\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     clean_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.8046875, logit=22.5, token_id=13394, metadata=None))), (469, (39, PredictedToken(token=' E', prob=0.00013637542724609375, logit=13.8125, token_id=469, metadata=None))), (6031, (48, PredictedToken(token=' Bro', prob=7.772445678710938e-05, logit=13.25, token_id=6031, metadata=None))), (13597, (66, PredictedToken(token=' Pen', prob=4.410743713378906e-05, logit=12.6875, token_id=13597, metadata=None))), (47589, (156, PredictedToken(token=' Basketball', prob=5.602836608886719e-06, logit=10.625, token_id=47589, metadata=None))), (70762, (362, PredictedToken(token=' Motorcycle', prob=1.2516975402832031e-06, logit=9.125, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.652, logit=22.250)', '\" Basketball\"[47589] (p=0.271, logit=21.375)', '\" The\"[578] (p=0.029, logit=19.125)', '\" Among\"[22395] (p=0.014, logit=18.375)', '\" A\"[362] (p=0.012, logit=18.250)']\n",
      "2025-09-16 09:56:28 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.65234375, logit=22.25, token_id=70762, metadata=None))), (47589, (2, PredictedToken(token=' Basketball', prob=0.271484375, logit=21.375, token_id=47589, metadata=None))), (13394, (75, PredictedToken(token=' Bed', prob=2.6226043701171875e-05, logit=12.125, token_id=13394, metadata=None))), (469, (86, PredictedToken(token=' E', prob=1.919269561767578e-05, logit=11.8125, token_id=469, metadata=None))), (6031, (177, PredictedToken(token=' Bro', prob=4.023313522338867e-06, logit=10.25, token_id=6031, metadata=None))), (13597, (220, PredictedToken(token=' Pen', prob=2.592802047729492e-06, logit=9.8125, token_id=13597, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:29 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:29 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     patch_prediction=['\" B\"[426] (p=0.734, logit=22.375)', '\" The\"[578] (p=0.099, logit=20.375)', '\" A\"[362] (p=0.087, logit=20.250)', '\" Among\"[22395] (p=0.025, logit=19.000)', '\" b\"[293] (p=0.017, logit=18.625)']\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.633, logit=21.750)', '\" The\"[578] (p=0.125, logit=20.125)', '\" Among\"[22395] (p=0.110, logit=20.000)', '\" A\"[362] (p=0.067, logit=19.500)', '\" Option\"[7104] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6328125, logit=21.75, token_id=27171, metadata=None))), (74968, (18, PredictedToken(token=' Razor', prob=0.000789642333984375, logit=15.0625, token_id=74968, metadata=None))), (445, (91, PredictedToken(token=' L', prob=2.5391578674316406e-05, logit=11.625, token_id=445, metadata=None))), (55807, (741, PredictedToken(token=' Shirt', prob=6.183981895446777e-07, logit=7.90625, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.754, logit=21.875)', '\" A\"[362] (p=0.090, logit=19.750)', '\" The\"[578] (p=0.043, logit=19.000)', '\" Among\"[22395] (p=0.043, logit=19.000)', '\" Option\"[7104] (p=0.023, logit=18.375)']\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.75390625, logit=21.875, token_id=445, metadata=None))), (55807, (7, PredictedToken(token=' Shirt', prob=0.00653076171875, logit=17.125, token_id=55807, metadata=None))), (74968, (13, PredictedToken(token=' Razor', prob=0.00165557861328125, logit=15.75, token_id=74968, metadata=None))), (27171, (45, PredictedToken(token=' Coffee', prob=0.00010585784912109375, logit=13.0, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:29 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:29 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:29 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     patch_prediction=['\" Keyboard\"[26698] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.037, logit=18.250)', '\" keyboard\"[13939] (p=0.017, logit=17.500)', '\" None\"[2290] (p=0.015, logit=17.375)', '\" Har\"[5340] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.754, logit=21.000)', '\" The\"[578] (p=0.070, logit=18.625)', '\" Short\"[10928] (p=0.038, logit=18.000)', '\" shorts\"[36876] (p=0.029, logit=17.750)', '\" Among\"[22395] (p=0.023, logit=17.500)']\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.75390625, logit=21.0, token_id=91782, metadata=None))), (65449, (14, PredictedToken(token=' Willow', prob=0.0017547607421875, logit=14.9375, token_id=65449, metadata=None))), (11452, (28, PredictedToken(token=' Head', prob=0.000644683837890625, logit=13.9375, token_id=11452, metadata=None)))])\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     int_prediction=['\" Head\"[11452] (p=0.906, logit=22.375)', '\" The\"[578] (p=0.035, logit=19.125)', '\" headphones\"[44101] (p=0.019, logit=18.500)', '\" Among\"[22395] (p=0.005, logit=17.250)', '\" (\"[320] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     int_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.90625, logit=22.375, token_id=11452, metadata=None))), (65449, (6, PredictedToken(token=' Willow', prob=0.0025482177734375, logit=16.5, token_id=65449, metadata=None))), (91782, (78, PredictedToken(token=' Shorts', prob=2.5033950805664062e-05, logit=11.875, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:30 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     patch_prediction=['\" Guitar\"[47759] (p=0.559, logit=20.750)', '\" The\"[578] (p=0.206, logit=19.750)', '\" Among\"[22395] (p=0.086, logit=18.875)', '\" A\"[362] (p=0.059, logit=18.500)', '\" G\"[480] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.625, logit=21.250)', '\" The\"[578] (p=0.109, logit=19.500)', '\" Among\"[22395] (p=0.084, logit=19.250)', '\" A\"[362] (p=0.084, logit=19.250)', '\" C\"[356] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.625, logit=21.25, token_id=58600, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.01470947265625, logit=17.5, token_id=356, metadata=None))), (16147, (101, PredictedToken(token=' Smart', prob=3.218650817871094e-05, logit=11.375, token_id=16147, metadata=None))), (6690, (200, PredictedToken(token=' Air', prob=8.165836334228516e-06, logit=10.0, token_id=6690, metadata=None))), (17367, (463, PredictedToken(token=' Factory', prob=1.9371509552001953e-06, logit=8.5625, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:56:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.523, logit=21.625)', '\" C\"[356] (p=0.192, logit=20.625)', '\" A\"[362] (p=0.103, logit=20.000)', '\" The\"[578] (p=0.080, logit=19.750)', '\" Among\"[22395] (p=0.026, logit=18.625)']\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.5234375, logit=21.625, token_id=16147, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.1923828125, logit=20.625, token_id=356, metadata=None))), (6690, (127, PredictedToken(token=' Air', prob=1.9669532775878906e-05, logit=11.4375, token_id=6690, metadata=None))), (58600, (1708, PredictedToken(token=' Charm', prob=2.0489096641540527e-07, logit=6.875, token_id=58600, metadata=None))), (17367, (2520, PredictedToken(token=' Factory', prob=1.0663643479347229e-07, logit=6.21875, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:31 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:31 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.832, logit=22.250)', '\" The\"[578] (p=0.078, logit=19.875)', '\" Among\"[22395] (p=0.025, logit=18.750)', '\" A\"[362] (p=0.022, logit=18.625)', '\" B\"[426] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.945, logit=23.375)', '\" An\"[1556] (p=0.017, logit=19.375)', '\" The\"[578] (p=0.012, logit=19.000)', '\" ank\"[71572] (p=0.007, logit=18.500)', '\" Among\"[22395] (p=0.006, logit=18.375)']\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.9453125, logit=23.375, token_id=57915, metadata=None))), (18191, (77, PredictedToken(token=' Mouse', prob=1.233816146850586e-05, logit=12.125, token_id=18191, metadata=None))), (10164, (166, PredictedToken(token=' Water', prob=2.2798776626586914e-06, logit=10.4375, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.934, logit=22.625)', '\" The\"[578] (p=0.015, logit=18.500)', '\" Among\"[22395] (p=0.013, logit=18.375)', '\" water\"[3090] (p=0.009, logit=18.000)', '\" None\"[2290] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.93359375, logit=22.625, token_id=10164, metadata=None))), (18191, (9, PredictedToken(token=' Mouse', prob=0.0015869140625, logit=16.25, token_id=18191, metadata=None))), (57915, (537, PredictedToken(token=' Ank', prob=6.444752216339111e-07, logit=8.4375, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:31 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:56:31 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.816, logit=22.375)', '\" The\"[578] (p=0.067, logit=19.875)', '\" A\"[362] (p=0.067, logit=19.875)', '\" Among\"[22395] (p=0.019, logit=18.625)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.668, logit=21.000)', '\" The\"[578] (p=0.103, logit=19.125)', '\" Among\"[22395] (p=0.070, logit=18.750)', '\" A\"[362] (p=0.070, logit=18.750)', '\" It\"[1102] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.66796875, logit=21.0, token_id=75258, metadata=None))), (17810, (16, PredictedToken(token=' Cat', prob=0.00128936767578125, logit=14.75, token_id=17810, metadata=None))), (91963, (117, PredictedToken(token=' Mango', prob=3.4332275390625e-05, logit=11.125, token_id=91963, metadata=None))), (74968, (221, PredictedToken(token=' Razor', prob=1.049041748046875e-05, logit=9.9375, token_id=74968, metadata=None))), (9441, (1331, PredictedToken(token=' Church', prob=5.736947059631348e-07, logit=7.03125, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.898, logit=22.000)', '\" The\"[578] (p=0.027, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" A\"[362] (p=0.008, logit=17.250)', '\" Option\"[7104] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.8984375, logit=22.0, token_id=9441, metadata=None))), (17810, (6, PredictedToken(token=' Cat', prob=0.005340576171875, logit=16.875, token_id=17810, metadata=None))), (75258, (14, PredictedToken(token=' Refriger', prob=0.0010528564453125, logit=15.25, token_id=75258, metadata=None))), (91963, (671, PredictedToken(token=' Mango', prob=7.227063179016113e-07, logit=7.96875, token_id=91963, metadata=None))), (74968, (1970, PredictedToken(token=' Razor', prob=1.51805579662323e-07, logit=6.40625, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:32 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.742, logit=22.625)', '\" The\"[578] (p=0.129, logit=20.875)', '\" Among\"[22395] (p=0.048, logit=19.875)', '\" A\"[362] (p=0.048, logit=19.875)', '\" dress\"[8679] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     clean_prediction=['\" Sheep\"[84008] (p=0.490, logit=20.500)', '\" The\"[578] (p=0.204, logit=19.625)', '\" A\"[362] (p=0.109, logit=19.000)', '\" Among\"[22395] (p=0.075, logit=18.625)', '\" sheep\"[33012] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     clean_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.490234375, logit=20.5, token_id=84008, metadata=None))), (37326, (59, PredictedToken(token=' Swe', prob=0.0001277923583984375, logit=12.25, token_id=37326, metadata=None))), (58586, (309, PredictedToken(token=' Tape', prob=5.632638931274414e-06, logit=9.125, token_id=58586, metadata=None))), (29318, (605, PredictedToken(token=' Dress', prob=1.8253922462463379e-06, logit=8.0, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:56:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.547, logit=20.375)', '\" A\"[362] (p=0.178, logit=19.250)', '\" The\"[578] (p=0.084, logit=18.500)', '\" Sheep\"[84008] (p=0.074, logit=18.375)', '\" Among\"[22395] (p=0.035, logit=17.625)']\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.546875, logit=20.375, token_id=37326, metadata=None))), (84008, (4, PredictedToken(token=' Sheep', prob=0.07421875, logit=18.375, token_id=84008, metadata=None))), (29318, (41, PredictedToken(token=' Dress', prob=0.000469207763671875, logit=13.3125, token_id=29318, metadata=None))), (58586, (64, PredictedToken(token=' Tape', prob=0.000152587890625, logit=12.1875, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:33 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:33 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.590, logit=21.375)', '\" The\"[578] (p=0.169, logit=20.125)', '\" A\"[362] (p=0.132, logit=19.875)', '\" Among\"[22395] (p=0.055, logit=19.000)', '\" \"[220] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.676, logit=22.125)', '\" An\"[1556] (p=0.193, logit=20.875)', '\" The\"[578] (p=0.055, logit=19.625)', '\" Among\"[22395] (p=0.030, logit=19.000)', '\" Ash\"[14937] (p=0.016, logit=18.375)']\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.67578125, logit=22.125, token_id=6690, metadata=None))), (14937, (5, PredictedToken(token=' Ash', prob=0.015869140625, logit=18.375, token_id=14937, metadata=None))), (6914, (19, PredictedToken(token=' Let', prob=0.00054168701171875, logit=15.0, token_id=6914, metadata=None))), (59825, (34, PredictedToken(token=' Tie', prob=0.00015544891357421875, logit=13.75, token_id=59825, metadata=None))), (45805, (63, PredictedToken(token=' Cherry', prob=5.054473876953125e-05, logit=12.625, token_id=45805, metadata=None))), (16730, (408, PredictedToken(token=' Museum', prob=1.0505318641662598e-06, logit=8.75, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.840, logit=22.000)', '\" Cherry\"[45805] (p=0.054, logit=19.250)', '\" The\"[578] (p=0.042, logit=19.000)', '\" Among\"[22395] (p=0.022, logit=18.375)', '\" Tie\"[59825] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.83984375, logit=22.0, token_id=6914, metadata=None))), (45805, (2, PredictedToken(token=' Cherry', prob=0.0537109375, logit=19.25, token_id=45805, metadata=None))), (59825, (5, PredictedToken(token=' Tie', prob=0.00933837890625, logit=17.5, token_id=59825, metadata=None))), (16730, (68, PredictedToken(token=' Museum', prob=5.221366882324219e-05, logit=12.3125, token_id=16730, metadata=None))), (14937, (531, PredictedToken(token=' Ash', prob=1.0207295417785645e-06, logit=8.375, token_id=14937, metadata=None))), (6690, (937, PredictedToken(token=' Air', prob=4.6566128730773926e-07, logit=7.59375, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:33 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:33 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:56:33 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.910, logit=21.375)', '\" The\"[578] (p=0.028, logit=17.875)', '\" A\"[362] (p=0.009, logit=16.750)', '\" Maple\"[44570] (p=0.007, logit=16.500)', '\" dumb\"[30355] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     clean_prediction=['\" Micro\"[18654] (p=0.746, logit=21.000)', '\" The\"[578] (p=0.069, logit=18.625)', '\" Among\"[22395] (p=0.048, logit=18.250)', '\" A\"[362] (p=0.037, logit=18.000)', '\" None\"[2290] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     clean_track=OrderedDict([(18654, (1, PredictedToken(token=' Micro', prob=0.74609375, logit=21.0, token_id=18654, metadata=None))), (74968, (61, PredictedToken(token=' Razor', prob=0.00014209747314453125, logit=12.4375, token_id=74968, metadata=None))), (41342, (73, PredictedToken(token=' Hockey', prob=9.202957153320312e-05, logit=12.0, token_id=41342, metadata=None))), (86460, (85, PredictedToken(token=' Necklace', prob=6.723403930664062e-05, logit=11.6875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     int_prediction=['\" Hockey\"[41342] (p=0.801, logit=21.250)', '\" The\"[578] (p=0.045, logit=18.375)', '\" A\"[362] (p=0.040, logit=18.250)', '\" Among\"[22395] (p=0.019, logit=17.500)', '\" None\"[2290] (p=0.015, logit=17.250)']\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     int_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.80078125, logit=21.25, token_id=41342, metadata=None))), (74968, (10, PredictedToken(token=' Razor', prob=0.00537109375, logit=16.25, token_id=74968, metadata=None))), (18654, (238, PredictedToken(token=' Micro', prob=6.288290023803711e-06, logit=9.5, token_id=18654, metadata=None))), (86460, (333, PredictedToken(token=' Necklace', prob=3.3676624298095703e-06, logit=8.875, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:34 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.836, logit=22.750)', '\" The\"[578] (p=0.069, logit=20.250)', '\" A\"[362] (p=0.047, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.500)']\n",
      "2025-09-16 09:56:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.859, logit=22.500)', '\" The\"[578] (p=0.055, logit=19.750)', '\" A\"[362] (p=0.038, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=19.000)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.859375, logit=22.5, token_id=88668, metadata=None))), (94467, (53, PredictedToken(token=' Trom', prob=4.7206878662109375e-05, logit=12.6875, token_id=94467, metadata=None))), (42609, (69, PredictedToken(token=' Pine', prob=2.682209014892578e-05, logit=12.125, token_id=42609, metadata=None))), (61948, (166, PredictedToken(token=' Sofa', prob=4.976987838745117e-06, logit=10.4375, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.078, logit=19.000)', '\" A\"[362] (p=0.025, logit=17.875)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" It\"[1102] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.8359375, logit=21.375, token_id=42609, metadata=None))), (61948, (13, PredictedToken(token=' Sofa', prob=0.00103759765625, logit=14.6875, token_id=61948, metadata=None))), (94467, (18, PredictedToken(token=' Trom', prob=0.000629425048828125, logit=14.1875, token_id=94467, metadata=None))), (88668, (161, PredictedToken(token=' Blender', prob=1.2278556823730469e-05, logit=10.25, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:35 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:35 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     patch_prediction=['\" Drum\"[46506] (p=0.867, logit=21.875)', '\" Option\"[7104] (p=0.030, logit=18.500)', '\" The\"[578] (p=0.023, logit=18.250)', '\" (\"[320] (p=0.020, logit=18.125)', '\" d\"[294] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.926, logit=22.875)', '\" The\"[578] (p=0.028, logit=19.375)', '\" Among\"[22395] (p=0.010, logit=18.375)', '\" A\"[362] (p=0.007, logit=18.000)', '\" (\"[320] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.92578125, logit=22.875, token_id=356, metadata=None))), (58600, (642, PredictedToken(token=' Charm', prob=4.116445779800415e-07, logit=8.25, token_id=58600, metadata=None)))])\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.906, logit=22.500)', '\" The\"[578] (p=0.031, logit=19.125)', '\" Option\"[7104] (p=0.010, logit=18.000)', '\" Charm\"[58600] (p=0.009, logit=17.875)', '\" Among\"[22395] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.90625, logit=22.5, token_id=356, metadata=None))), (58600, (5, PredictedToken(token=' Charm', prob=0.0089111328125, logit=17.875, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:35 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:35 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     patch_prediction=['\" Charm\"[58600] (p=0.691, logit=20.125)', '\" None\"[2290] (p=0.120, logit=18.375)', '\" The\"[578] (p=0.039, logit=17.250)', '\" A\"[362] (p=0.034, logit=17.125)', '\" Bat\"[16488] (p=0.021, logit=16.625)']\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.871, logit=22.625)', '\" The\"[578] (p=0.056, logit=19.875)', '\" Among\"[22395] (p=0.049, logit=19.750)', '\" It\"[1102] (p=0.002, logit=16.500)', '\" \"[220] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.87109375, logit=22.625, token_id=47643, metadata=None))), (426, (49, PredictedToken(token=' B', prob=5.412101745605469e-05, logit=12.9375, token_id=426, metadata=None))), (30760, (71, PredictedToken(token=' Scar', prob=3.2901763916015625e-05, logit=12.4375, token_id=30760, metadata=None))), (13120, (69, PredictedToken(token=' Night', prob=3.2901763916015625e-05, logit=12.4375, token_id=13120, metadata=None))), (11452, (212, PredictedToken(token=' Head', prob=2.86102294921875e-06, logit=10.0, token_id=11452, metadata=None)))])\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.852, logit=23.000)', '\" The\"[578] (p=0.042, logit=20.000)', '\" A\"[362] (p=0.042, logit=20.000)', '\" Among\"[22395] (p=0.033, logit=19.750)', '\" b\"[293] (p=0.007, logit=18.125)']\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.8515625, logit=23.0, token_id=426, metadata=None))), (30760, (9, PredictedToken(token=' Scar', prob=0.00145721435546875, logit=16.625, token_id=30760, metadata=None))), (47643, (15, PredictedToken(token=' Cel', prob=0.000644683837890625, logit=15.8125, token_id=47643, metadata=None))), (11452, (21, PredictedToken(token=' Head', prob=0.00030517578125, logit=15.0625, token_id=11452, metadata=None))), (13120, (72, PredictedToken(token=' Night', prob=2.205371856689453e-05, logit=12.4375, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:36 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.898, logit=22.125)', '\" The\"[578] (p=0.035, logit=18.875)', '\" Among\"[22395] (p=0.016, logit=18.125)', '\" A\"[362] (p=0.011, logit=17.750)', '\" Head\"[11452] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:56:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     clean_prediction=['\" Bamboo\"[98028] (p=0.816, logit=20.875)', '\" The\"[578] (p=0.059, logit=18.250)', '\" Among\"[22395] (p=0.032, logit=17.625)', '\" None\"[2290] (p=0.017, logit=17.000)', '\" A\"[362] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     clean_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.81640625, logit=20.875, token_id=98028, metadata=None))), (30616, (38, PredictedToken(token=' Rice', prob=0.000274658203125, logit=12.875, token_id=30616, metadata=None))), (33711, (39, PredictedToken(token=' Suit', prob=0.0002574920654296875, logit=12.8125, token_id=33711, metadata=None))), (38673, (53, PredictedToken(token=' Yoga', prob=0.00013828277587890625, logit=12.1875, token_id=38673, metadata=None))), (14669, (730, PredictedToken(token=' Camera', prob=1.735985279083252e-06, logit=7.8125, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     int_prediction=['\" Yoga\"[38673] (p=0.387, logit=19.750)', '\" Camera\"[14669] (p=0.143, logit=18.750)', '\" None\"[2290] (p=0.126, logit=18.625)', '\" A\"[362] (p=0.111, logit=18.500)', '\" The\"[578] (p=0.086, logit=18.250)']\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     int_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.38671875, logit=19.75, token_id=38673, metadata=None))), (14669, (2, PredictedToken(token=' Camera', prob=0.142578125, logit=18.75, token_id=14669, metadata=None))), (30616, (7, PredictedToken(token=' Rice', prob=0.01031494140625, logit=16.125, token_id=30616, metadata=None))), (33711, (8, PredictedToken(token=' Suit', prob=0.01031494140625, logit=16.125, token_id=33711, metadata=None))), (98028, (35, PredictedToken(token=' Bamboo', prob=0.00084686279296875, logit=13.625, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:37 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:37 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     patch_prediction=['\" Paper\"[18343] (p=0.895, logit=21.625)', '\" Comb\"[23262] (p=0.027, logit=18.125)', '\" The\"[578] (p=0.021, logit=17.875)', '\" paper\"[5684] (p=0.008, logit=16.875)', '\" A\"[362] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.648, logit=21.750)', '\" A\"[362] (p=0.146, logit=20.250)', '\" The\"[578] (p=0.128, logit=20.125)', '\" Among\"[22395] (p=0.025, logit=18.500)', '\" F\"[435] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.6484375, logit=21.75, token_id=75258, metadata=None))), (57094, (40, PredictedToken(token=' Highlight', prob=0.00014972686767578125, logit=13.375, token_id=57094, metadata=None))), (14588, (317, PredictedToken(token=' Dog', prob=2.428889274597168e-06, logit=9.25, token_id=14588, metadata=None)))])\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.723, logit=21.875)', '\" The\"[578] (p=0.111, logit=20.000)', '\" A\"[362] (p=0.098, logit=19.875)', '\" Refriger\"[75258] (p=0.028, logit=18.625)', '\" Among\"[22395] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.72265625, logit=21.875, token_id=57094, metadata=None))), (75258, (4, PredictedToken(token=' Refriger', prob=0.028076171875, logit=18.625, token_id=75258, metadata=None))), (14588, (238, PredictedToken(token=' Dog', prob=4.4405460357666016e-06, logit=9.875, token_id=14588, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:37 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:37 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.668, logit=21.750)', '\" A\"[362] (p=0.116, logit=20.000)', '\" The\"[578] (p=0.102, logit=19.875)', '\" Among\"[22395] (p=0.062, logit=19.375)', '\" Option\"[7104] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.906, logit=21.500)', '\" The\"[578] (p=0.027, logit=18.000)', '\" A\"[362] (p=0.009, logit=16.875)', '\" Among\"[22395] (p=0.006, logit=16.500)', '\" None\"[2290] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.90625, logit=21.5, token_id=18343, metadata=None))), (6914, (9, PredictedToken(token=' Let', prob=0.0023956298828125, logit=15.5625, token_id=6914, metadata=None))), (16344, (36, PredictedToken(token=' Rose', prob=0.00025177001953125, logit=13.3125, token_id=16344, metadata=None))), (6150, (61, PredictedToken(token=' School', prob=9.870529174804688e-05, logit=12.375, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     int_prediction=['\" Paper\"[18343] (p=0.453, logit=19.750)', '\" Let\"[6914] (p=0.188, logit=18.875)', '\" Rose\"[16344] (p=0.101, logit=18.250)', '\" School\"[6150] (p=0.089, logit=18.125)', '\" None\"[2290] (p=0.061, logit=17.750)']\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     int_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.453125, logit=19.75, token_id=18343, metadata=None))), (6914, (2, PredictedToken(token=' Let', prob=0.1884765625, logit=18.875, token_id=6914, metadata=None))), (16344, (3, PredictedToken(token=' Rose', prob=0.10107421875, logit=18.25, token_id=16344, metadata=None))), (6150, (4, PredictedToken(token=' School', prob=0.08935546875, logit=18.125, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:38 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     patch_prediction=['\" Violet\"[74574] (p=0.883, logit=22.000)', '\" The\"[578] (p=0.050, logit=19.125)', '\" Among\"[22395] (p=0.027, logit=18.500)', '\" A\"[362] (p=0.009, logit=17.375)', '\" Option\"[7104] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:56:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     clean_prediction=['\" Monkey\"[58937] (p=0.824, logit=21.125)', '\" The\"[578] (p=0.041, logit=18.125)', '\" A\"[362] (p=0.032, logit=17.875)', '\" Among\"[22395] (p=0.028, logit=17.750)', '\" (\"[320] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     clean_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.82421875, logit=21.125, token_id=58937, metadata=None))), (72392, (27, PredictedToken(token=' Mixer', prob=0.00090789794921875, logit=14.3125, token_id=72392, metadata=None))), (57748, (42, PredictedToken(token=' Cedar', prob=0.000377655029296875, logit=13.4375, token_id=57748, metadata=None))), (71264, (103, PredictedToken(token=' Daisy', prob=4.506111145019531e-05, logit=11.3125, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.582, logit=20.125)', '\" d\"[294] (p=0.189, logit=19.000)', '\" The\"[578] (p=0.042, logit=17.500)', '\" Among\"[22395] (p=0.033, logit=17.250)', '\" Cedar\"[57748] (p=0.029, logit=17.125)']\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.58203125, logit=20.125, token_id=71264, metadata=None))), (57748, (5, PredictedToken(token=' Cedar', prob=0.029052734375, logit=17.125, token_id=57748, metadata=None))), (72392, (38, PredictedToken(token=' Mixer', prob=0.0004405975341796875, logit=12.9375, token_id=72392, metadata=None))), (58937, (39, PredictedToken(token=' Monkey', prob=0.0003662109375, logit=12.75, token_id=58937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:39 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.809, logit=21.750)', '\" The\"[578] (p=0.059, logit=19.125)', '\" Among\"[22395] (p=0.046, logit=18.875)', '\" A\"[362] (p=0.028, logit=18.375)', '\" Option\"[7104] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     clean_prediction=['\" Monkey\"[58937] (p=0.855, logit=22.125)', '\" The\"[578] (p=0.043, logit=19.125)', '\" A\"[362] (p=0.043, logit=19.125)', '\" Among\"[22395] (p=0.016, logit=18.125)', '\" (\"[320] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     clean_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.85546875, logit=22.125, token_id=58937, metadata=None))), (91263, (7, PredictedToken(token=' Binder', prob=0.0034942626953125, logit=16.625, token_id=91263, metadata=None))), (23126, (42, PredictedToken(token=' Ti', prob=0.00015354156494140625, logit=13.5, token_id=23126, metadata=None)))])\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     int_prediction=['\" Binder\"[91263] (p=0.648, logit=21.875)', '\" Ti\"[23126] (p=0.270, logit=21.000)', '\" The\"[578] (p=0.028, logit=18.750)', '\" A\"[362] (p=0.015, logit=18.125)', '\" (\"[320] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     int_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.6484375, logit=21.875, token_id=91263, metadata=None))), (23126, (2, PredictedToken(token=' Ti', prob=0.26953125, logit=21.0, token_id=23126, metadata=None))), (58937, (54, PredictedToken(token=' Monkey', prob=6.198883056640625e-05, logit=12.625, token_id=58937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:39 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:39 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:56:39 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.660, logit=21.875)', '\" The\"[578] (p=0.130, logit=20.250)', '\" A\"[362] (p=0.130, logit=20.250)', '\" Among\"[22395] (p=0.054, logit=19.375)', '\" \"[220] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.734, logit=21.375)', '\" The\"[578] (p=0.127, logit=19.625)', '\" Among\"[22395] (p=0.077, logit=19.125)', '\" Ski\"[61595] (p=0.012, logit=17.250)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.734375, logit=21.375, token_id=4923, metadata=None))), (88088, (49, PredictedToken(token=' Birch', prob=0.0001583099365234375, logit=12.9375, token_id=88088, metadata=None))), (1901, (53, PredictedToken(token=' Z', prob=0.00011587142944335938, logit=12.625, token_id=1901, metadata=None))), (10164, (107, PredictedToken(token=' Water', prob=2.1457672119140625e-05, logit=10.9375, token_id=10164, metadata=None))), (6017, (205, PredictedToken(token=' Book', prob=6.556510925292969e-06, logit=9.75, token_id=6017, metadata=None))), (71264, (1622, PredictedToken(token=' Daisy', prob=2.4586915969848633e-07, logit=6.46875, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     int_prediction=['\" Book\"[6017] (p=0.766, logit=21.750)', '\" The\"[578] (p=0.091, logit=19.625)', '\" A\"[362] (p=0.055, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.750)', '\" Z\"[1901] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     int_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.765625, logit=21.75, token_id=6017, metadata=None))), (1901, (5, PredictedToken(token=' Z', prob=0.01239013671875, logit=17.625, token_id=1901, metadata=None))), (4923, (31, PredictedToken(token=' Sk', prob=0.0003509521484375, logit=14.0625, token_id=4923, metadata=None))), (88088, (52, PredictedToken(token=' Birch', prob=0.00011396408081054688, logit=12.9375, token_id=88088, metadata=None))), (10164, (250, PredictedToken(token=' Water', prob=3.4421682357788086e-06, logit=9.4375, token_id=10164, metadata=None))), (71264, (408, PredictedToken(token=' Daisy', prob=1.5273690223693848e-06, logit=8.625, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:40 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:40 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:56:40 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.855, logit=21.500)', '\" The\"[578] (p=0.042, logit=18.500)', '\" A\"[362] (p=0.033, logit=18.250)', '\" Among\"[22395] (p=0.018, logit=17.625)', '\" Comb\"[23262] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.660, logit=20.875)', '\" The\"[578] (p=0.115, logit=19.125)', '\" Among\"[22395] (p=0.101, logit=19.000)', '\" A\"[362] (p=0.037, logit=18.000)', '\" It\"[1102] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.66015625, logit=20.875, token_id=88088, metadata=None))), (30173, (12, PredictedToken(token=' Speaker', prob=0.003692626953125, logit=15.6875, token_id=30173, metadata=None))), (469, (26, PredictedToken(token=' E', prob=0.000774383544921875, logit=14.125, token_id=469, metadata=None))), (13120, (226, PredictedToken(token=' Night', prob=1.0371208190917969e-05, logit=9.8125, token_id=13120, metadata=None))), (40975, (285, PredictedToken(token=' Marker', prob=7.12275505065918e-06, logit=9.4375, token_id=40975, metadata=None))), (58251, (1756, PredictedToken(token=' Tennis', prob=5.327165126800537e-07, logit=6.84375, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.691, logit=21.875)', '\" E\"[469] (p=0.106, logit=20.000)', '\" An\"[1556] (p=0.083, logit=19.750)', '\" The\"[578] (p=0.050, logit=19.250)', '\" A\"[362] (p=0.018, logit=18.250)']\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.69140625, logit=21.875, token_id=40975, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.10595703125, logit=20.0, token_id=469, metadata=None))), (88088, (12, PredictedToken(token=' Birch', prob=0.002197265625, logit=16.125, token_id=88088, metadata=None))), (30173, (46, PredictedToken(token=' Speaker', prob=0.00015926361083984375, logit=13.5, token_id=30173, metadata=None))), (58251, (796, PredictedToken(token=' Tennis', prob=6.92903995513916e-07, logit=8.0625, token_id=58251, metadata=None))), (13120, (1162, PredictedToken(token=' Night', prob=4.0605664253234863e-07, logit=7.53125, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:41 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     patch_prediction=['\" Dish\"[49268] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.090, logit=19.250)', '\" A\"[362] (p=0.080, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.375)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.836, logit=21.625)', '\" None\"[2290] (p=0.053, logit=18.875)', '\" A\"[362] (p=0.037, logit=18.500)', '\" The\"[578] (p=0.029, logit=18.250)', '\" It\"[1102] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.8359375, logit=21.625, token_id=17929, metadata=None))), (36845, (8, PredictedToken(token=' Tiger', prob=0.0034027099609375, logit=16.125, token_id=36845, metadata=None))), (91263, (34, PredictedToken(token=' Binder', prob=0.00020503997802734375, logit=13.3125, token_id=91263, metadata=None))), (18191, (48, PredictedToken(token=' Mouse', prob=0.00011682510375976562, logit=12.75, token_id=18191, metadata=None))), (27171, (55, PredictedToken(token=' Coffee', prob=9.679794311523438e-05, logit=12.5625, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:56:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.648, logit=21.375)', '\" Mouse\"[18191] (p=0.164, logit=20.000)', '\" None\"[2290] (p=0.078, logit=19.250)', '\" A\"[362] (p=0.042, logit=18.625)', '\" The\"[578] (p=0.022, logit=18.000)']\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6484375, logit=21.375, token_id=27171, metadata=None))), (18191, (2, PredictedToken(token=' Mouse', prob=0.1640625, logit=20.0, token_id=18191, metadata=None))), (91263, (59, PredictedToken(token=' Binder', prob=7.05718994140625e-05, logit=12.25, token_id=91263, metadata=None))), (17929, (96, PredictedToken(token=' Pin', prob=3.123283386230469e-05, logit=11.4375, token_id=17929, metadata=None))), (36845, (458, PredictedToken(token=' Tiger', prob=1.7657876014709473e-06, logit=8.5625, token_id=36845, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:42 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:42 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.102, logit=19.375)', '\" A\"[362] (p=0.070, logit=19.000)', '\" Among\"[22395] (p=0.029, logit=18.125)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.793, logit=22.125)', '\" The\"[578] (p=0.083, logit=19.875)', '\" A\"[362] (p=0.065, logit=19.625)', '\" Among\"[22395] (p=0.031, logit=18.875)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.79296875, logit=22.125, token_id=86460, metadata=None))), (423, (13, PredictedToken(token=' D', prob=0.00077056884765625, logit=15.1875, token_id=423, metadata=None))), (36845, (57, PredictedToken(token=' Tiger', prob=5.5789947509765625e-05, logit=12.5625, token_id=36845, metadata=None))), (2522, (112, PredictedToken(token=' Sc', prob=1.4066696166992188e-05, logit=11.1875, token_id=2522, metadata=None))), (6771, (128, PredictedToken(token=' Table', prob=1.1682510375976562e-05, logit=11.0, token_id=6771, metadata=None))), (65197, (155, PredictedToken(token=' Surf', prob=8.046627044677734e-06, logit=10.625, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:56:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     int_prediction=['\" Surf\"[65197] (p=0.629, logit=21.250)', '\" Sc\"[2522] (p=0.204, logit=20.125)', '\" The\"[578] (p=0.075, logit=19.125)', '\" Among\"[22395] (p=0.028, logit=18.125)', '\" Tiger\"[36845] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     int_track=OrderedDict([(65197, (1, PredictedToken(token=' Surf', prob=0.62890625, logit=21.25, token_id=65197, metadata=None))), (2522, (2, PredictedToken(token=' Sc', prob=0.2041015625, logit=20.125, token_id=2522, metadata=None))), (36845, (5, PredictedToken(token=' Tiger', prob=0.01153564453125, logit=17.25, token_id=36845, metadata=None))), (6771, (29, PredictedToken(token=' Table', prob=0.000347137451171875, logit=13.75, token_id=6771, metadata=None))), (423, (48, PredictedToken(token=' D', prob=0.0001544952392578125, logit=12.9375, token_id=423, metadata=None))), (86460, (5360, PredictedToken(token=' Necklace', prob=5.681067705154419e-08, logit=5.03125, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:43 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:43 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.770, logit=20.875)', '\" The\"[578] (p=0.072, logit=18.500)', '\" A\"[362] (p=0.063, logit=18.375)', '\" Among\"[22395] (p=0.026, logit=17.500)', '\" It\"[1102] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.797, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.051, logit=18.625)', '\" Option\"[7104] (p=0.010, logit=17.000)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.796875, logit=21.375, token_id=82452, metadata=None))), (2057, (9, PredictedToken(token=' To', prob=0.004730224609375, logit=16.25, token_id=2057, metadata=None))), (69755, (170, PredictedToken(token=' Notebook', prob=1.1026859283447266e-05, logit=10.1875, token_id=69755, metadata=None))), (55807, (864, PredictedToken(token=' Shirt', prob=8.791685104370117e-07, logit=7.65625, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     int_prediction=['\" Notebook\"[69755] (p=0.695, logit=20.625)', '\" The\"[578] (p=0.083, logit=18.500)', '\" A\"[362] (p=0.073, logit=18.375)', '\" Among\"[22395] (p=0.031, logit=17.500)', '\" Jasmine\"[82452] (p=0.021, logit=17.125)']\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     int_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.6953125, logit=20.625, token_id=69755, metadata=None))), (82452, (5, PredictedToken(token=' Jasmine', prob=0.02099609375, logit=17.125, token_id=82452, metadata=None))), (2057, (15, PredictedToken(token=' To', prob=0.001953125, logit=14.75, token_id=2057, metadata=None))), (55807, (152, PredictedToken(token=' Shirt', prob=2.3126602172851562e-05, logit=10.3125, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:43 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:43 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.707, logit=21.625)', '\" The\"[578] (p=0.139, logit=20.000)', '\" Among\"[22395] (p=0.074, logit=19.375)', '\" Pant\"[54222] (p=0.019, logit=18.000)', '\" A\"[362] (p=0.015, logit=17.750)']\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.883, logit=22.875)', '\" The\"[578] (p=0.044, logit=19.875)', '\" A\"[362] (p=0.030, logit=19.500)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" horse\"[15580] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.8828125, logit=22.875, token_id=34392, metadata=None))), (23126, (34, PredictedToken(token=' Ti', prob=0.0001583099365234375, logit=14.25, token_id=23126, metadata=None))), (68867, (96, PredictedToken(token=' Coat', prob=1.2218952178955078e-05, logit=11.6875, token_id=68867, metadata=None)))])\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     int_prediction=['\" Coat\"[68867] (p=0.844, logit=21.875)', '\" The\"[578] (p=0.069, logit=19.375)', '\" A\"[362] (p=0.026, logit=18.375)', '\" Among\"[22395] (p=0.008, logit=17.250)', '\" None\"[2290] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     int_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.84375, logit=21.875, token_id=68867, metadata=None))), (23126, (6, PredictedToken(token=' Ti', prob=0.007293701171875, logit=17.125, token_id=23126, metadata=None))), (34392, (60, PredictedToken(token=' Horse', prob=8.630752563476562e-05, logit=12.6875, token_id=34392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:44 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:44 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     patch_prediction=['\" Y\"[816] (p=0.668, logit=22.000)', '\" A\"[362] (p=0.169, logit=20.625)', '\" The\"[578] (p=0.090, logit=20.000)', '\" Among\"[22395] (p=0.033, logit=19.000)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:56:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     clean_prediction=['\" Stap\"[63606] (p=0.621, logit=20.875)', '\" The\"[578] (p=0.179, logit=19.625)', '\" A\"[362] (p=0.096, logit=19.000)', '\" Among\"[22395] (p=0.045, logit=18.250)', '\" It\"[1102] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     clean_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.62109375, logit=20.875, token_id=63606, metadata=None))), (3341, (20, PredictedToken(token=' Car', prob=0.000728607177734375, logit=14.125, token_id=3341, metadata=None))), (44570, (87, PredictedToken(token=' Maple', prob=5.2928924560546875e-05, logit=11.5, token_id=44570, metadata=None))), (26781, (111, PredictedToken(token=' Hair', prob=3.409385681152344e-05, logit=11.0625, token_id=26781, metadata=None)))])\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.719, logit=21.625)', '\" The\"[578] (p=0.160, logit=20.125)', '\" A\"[362] (p=0.052, logit=19.000)', '\" Among\"[22395] (p=0.013, logit=17.625)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.71875, logit=21.625, token_id=3341, metadata=None))), (26781, (28, PredictedToken(token=' Hair', prob=0.00051116943359375, logit=14.375, token_id=26781, metadata=None))), (44570, (62, PredictedToken(token=' Maple', prob=0.0001068115234375, logit=12.8125, token_id=44570, metadata=None))), (63606, (103, PredictedToken(token=' Stap', prob=3.457069396972656e-05, logit=11.6875, token_id=63606, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:45 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.680, logit=21.875)', '\" The\"[578] (p=0.151, logit=20.375)', '\" A\"[362] (p=0.081, logit=19.750)', '\" Among\"[22395] (p=0.056, logit=19.375)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     clean_prediction=['\" Blue\"[8868] (p=0.820, logit=22.375)', '\" The\"[578] (p=0.098, logit=20.250)', '\" Among\"[22395] (p=0.032, logit=19.125)', '\" A\"[362] (p=0.019, logit=18.625)', '\" Fruit\"[44187] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     clean_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.8203125, logit=22.375, token_id=8868, metadata=None))), (2522, (106, PredictedToken(token=' Sc', prob=1.4543533325195312e-05, logit=11.4375, token_id=2522, metadata=None))), (26781, (119, PredictedToken(token=' Hair', prob=1.0013580322265625e-05, logit=11.0625, token_id=26781, metadata=None))), (36358, (185, PredictedToken(token=' Bench', prob=4.738569259643555e-06, logit=10.3125, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.363, logit=20.750)', '\" Blue\"[8868] (p=0.250, logit=20.375)', '\" The\"[578] (p=0.151, logit=19.875)', '\" Among\"[22395] (p=0.104, logit=19.500)', '\" A\"[362] (p=0.056, logit=18.875)']\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.36328125, logit=20.75, token_id=36358, metadata=None))), (8868, (2, PredictedToken(token=' Blue', prob=0.25, logit=20.375, token_id=8868, metadata=None))), (2522, (6, PredictedToken(token=' Sc', prob=0.012451171875, logit=17.375, token_id=2522, metadata=None))), (26781, (54, PredictedToken(token=' Hair', prob=0.00012969970703125, logit=12.8125, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:45 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:45 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:45 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.922, logit=22.375)', '\" An\"[1556] (p=0.019, logit=18.500)', '\" The\"[578] (p=0.015, logit=18.250)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" ank\"[71572] (p=0.012, logit=18.000)']\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.855, logit=22.125)', '\" The\"[578] (p=0.048, logit=19.250)', '\" Among\"[22395] (p=0.029, logit=18.750)', '\" A\"[362] (p=0.020, logit=18.375)', '\" jacket\"[27300] (p=0.009, logit=17.625)']\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.85546875, logit=22.125, token_id=55870, metadata=None))), (58600, (6, PredictedToken(token=' Charm', prob=0.005767822265625, logit=17.125, token_id=58600, metadata=None))), (16488, (43, PredictedToken(token=' Bat', prob=0.00011968612670898438, logit=13.25, token_id=16488, metadata=None))), (22607, (388, PredictedToken(token=' Cow', prob=1.3262033462524414e-06, logit=8.75, token_id=22607, metadata=None)))])\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.777, logit=21.625)', '\" The\"[578] (p=0.064, logit=19.125)', '\" Among\"[22395] (p=0.039, logit=18.625)', '\" Charm\"[58600] (p=0.027, logit=18.250)', '\" A\"[362] (p=0.014, logit=17.625)']\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.77734375, logit=21.625, token_id=16488, metadata=None))), (58600, (4, PredictedToken(token=' Charm', prob=0.026611328125, logit=18.25, token_id=58600, metadata=None))), (55870, (38, PredictedToken(token=' Jacket', prob=0.000335693359375, logit=13.875, token_id=55870, metadata=None))), (22607, (51, PredictedToken(token=' Cow', prob=0.000179290771484375, logit=13.25, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:46 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.598, logit=21.125)', '\" The\"[578] (p=0.171, logit=19.875)', '\" Among\"[22395] (p=0.081, logit=19.125)', '\" A\"[362] (p=0.071, logit=19.000)', '\" It\"[1102] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:56:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.844, logit=21.250)', '\" The\"[578] (p=0.042, logit=18.250)', '\" None\"[2290] (p=0.033, logit=18.000)', '\" A\"[362] (p=0.026, logit=17.750)', '\" Among\"[22395] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.84375, logit=21.25, token_id=33578, metadata=None))), (17367, (6, PredictedToken(token=' Factory', prob=0.005035400390625, logit=16.125, token_id=17367, metadata=None))), (65197, (30, PredictedToken(token=' Surf', prob=0.0004119873046875, logit=13.625, token_id=65197, metadata=None))), (27171, (37, PredictedToken(token=' Coffee', prob=0.000171661376953125, logit=12.75, token_id=27171, metadata=None))), (46506, (44, PredictedToken(token=' Drum', prob=0.000125885009765625, logit=12.4375, token_id=46506, metadata=None)))])\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.539, logit=20.500)', '\" Surf\"[65197] (p=0.225, logit=19.625)', '\" A\"[362] (p=0.073, logit=18.500)', '\" None\"[2290] (p=0.057, logit=18.250)', '\" The\"[578] (p=0.050, logit=18.125)']\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.5390625, logit=20.5, token_id=33578, metadata=None))), (65197, (2, PredictedToken(token=' Surf', prob=0.224609375, logit=19.625, token_id=65197, metadata=None))), (46506, (11, PredictedToken(token=' Drum', prob=0.002197265625, logit=15.0, token_id=46506, metadata=None))), (27171, (157, PredictedToken(token=' Coffee', prob=2.300739288330078e-05, logit=10.4375, token_id=27171, metadata=None))), (17367, (195, PredictedToken(token=' Factory', prob=1.6808509826660156e-05, logit=10.125, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:47 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:47 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.730, logit=21.875)', '\" The\"[578] (p=0.099, logit=19.875)', '\" A\"[362] (p=0.068, logit=19.500)', '\" Among\"[22395] (p=0.041, logit=19.000)', '\" Option\"[7104] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.477, logit=19.625)', '\" Hel\"[16183] (p=0.328, logit=19.250)', '\" None\"[2290] (p=0.050, logit=17.375)', '\" The\"[578] (p=0.021, logit=16.500)', '\" Viol\"[30555] (p=0.018, logit=16.375)']\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.4765625, logit=19.625, token_id=24423, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.328125, logit=19.25, token_id=16183, metadata=None))), (30555, (5, PredictedToken(token=' Viol', prob=0.0184326171875, logit=16.375, token_id=30555, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.005645751953125, logit=15.1875, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.695, logit=20.750)', '\" Hel\"[16183] (p=0.121, logit=19.000)', '\" None\"[2290] (p=0.094, logit=18.750)', '\" The\"[578] (p=0.014, logit=16.875)', '\" A\"[362] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.6953125, logit=20.75, token_id=24423, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.12060546875, logit=19.0, token_id=16183, metadata=None))), (96096, (6, PredictedToken(token=' Dolphin', prob=0.006805419921875, logit=16.125, token_id=96096, metadata=None))), (30555, (99, PredictedToken(token=' Viol', prob=5.888938903808594e-05, logit=11.375, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:47 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:47 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:56:47 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.855, logit=21.500)', '\" The\"[578] (p=0.038, logit=18.375)', '\" Among\"[22395] (p=0.033, logit=18.250)', '\" SOAP\"[64332] (p=0.011, logit=17.125)', '\" Option\"[7104] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.875, logit=22.375)', '\" A\"[362] (p=0.043, logit=19.375)', '\" The\"[578] (p=0.034, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=18.750)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.875, logit=22.375, token_id=81501, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.00168609619140625, logit=16.125, token_id=23262, metadata=None))), (3341, (32, PredictedToken(token=' Car', prob=0.00013828277587890625, logit=13.625, token_id=3341, metadata=None))), (24941, (72, PredictedToken(token=' Bear', prob=3.0994415283203125e-05, logit=12.125, token_id=24941, metadata=None)))])\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     int_prediction=['\" Pendant\"[81501] (p=0.672, logit=21.250)', '\" Comb\"[23262] (p=0.103, logit=19.375)', '\" The\"[578] (p=0.062, logit=18.875)', '\" A\"[362] (p=0.062, logit=18.875)', '\" Among\"[22395] (p=0.049, logit=18.625)']\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     int_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.671875, logit=21.25, token_id=81501, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.10302734375, logit=19.375, token_id=23262, metadata=None))), (3341, (7, PredictedToken(token=' Car', prob=0.0035247802734375, logit=16.0, token_id=3341, metadata=None))), (24941, (10, PredictedToken(token=' Bear', prob=0.00201416015625, logit=15.4375, token_id=24941, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:48 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:48 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:56:48 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     patch_prediction=['\" Violet\"[74574] (p=0.887, logit=21.875)', '\" The\"[578] (p=0.050, logit=19.000)', '\" Among\"[22395] (p=0.024, logit=18.250)', '\" A\"[362] (p=0.009, logit=17.250)', '\" Option\"[7104] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     clean_prediction=['\" Pepper\"[52882] (p=0.824, logit=21.125)', '\" None\"[2290] (p=0.087, logit=18.875)', '\" The\"[578] (p=0.022, logit=17.500)', '\" There\"[2684] (p=0.012, logit=16.875)', '\" A\"[362] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     clean_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.82421875, logit=21.125, token_id=52882, metadata=None))), (3341, (9, PredictedToken(token=' Car', prob=0.00262451171875, logit=15.375, token_id=3341, metadata=None))), (30173, (13, PredictedToken(token=' Speaker', prob=0.001495361328125, logit=14.8125, token_id=30173, metadata=None))), (445, (16, PredictedToken(token=' L', prob=0.00115966796875, logit=14.5625, token_id=445, metadata=None))), (71264, (43, PredictedToken(token=' Daisy', prob=0.00018978118896484375, logit=12.75, token_id=71264, metadata=None))), (13394, (61, PredictedToken(token=' Bed', prob=0.00010824203491210938, logit=12.1875, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.723, logit=21.000)', '\" None\"[2290] (p=0.086, logit=18.875)', '\" Pepper\"[52882] (p=0.067, logit=18.625)', '\" The\"[578] (p=0.022, logit=17.500)', '\" A\"[362] (p=0.022, logit=17.500)']\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.72265625, logit=21.0, token_id=71264, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.0673828125, logit=18.625, token_id=52882, metadata=None))), (13394, (33, PredictedToken(token=' Bed', prob=0.0003986358642578125, logit=13.5, token_id=13394, metadata=None))), (3341, (31, PredictedToken(token=' Car', prob=0.0003986358642578125, logit=13.5, token_id=3341, metadata=None))), (30173, (60, PredictedToken(token=' Speaker', prob=0.0001010894775390625, logit=12.125, token_id=30173, metadata=None))), (445, (91, PredictedToken(token=' L', prob=5.412101745605469e-05, logit=11.5, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:49 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.891, logit=22.375)', '\" The\"[578] (p=0.039, logit=19.250)', '\" A\"[362] (p=0.039, logit=19.250)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" MOS\"[74174] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.875, logit=21.000)', '\" The\"[578] (p=0.030, logit=17.625)', '\" Sc\"[2522] (p=0.026, logit=17.500)', '\" Among\"[22395] (p=0.010, logit=16.500)', '\" A\"[362] (p=0.006, logit=15.938)']\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.875, logit=21.0, token_id=16488, metadata=None))), (2522, (3, PredictedToken(token=' Sc', prob=0.0264892578125, logit=17.5, token_id=2522, metadata=None))), (24423, (11, PredictedToken(token=' Monitor', prob=0.002044677734375, logit=14.9375, token_id=24423, metadata=None))), (96096, (24, PredictedToken(token=' Dolphin', prob=0.000751495361328125, logit=13.9375, token_id=96096, metadata=None))), (23462, (30, PredictedToken(token=' Stadium', prob=0.000484466552734375, logit=13.5, token_id=23462, metadata=None))), (90538, (49, PredictedToken(token=' Caul', prob=0.00017833709716796875, logit=12.5, token_id=90538, metadata=None)))])\n",
      "2025-09-16 09:56:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.875, logit=21.125)', '\" None\"[2290] (p=0.026, logit=17.625)', '\" The\"[578] (p=0.021, logit=17.375)', '\" Caul\"[90538] (p=0.010, logit=16.625)', '\" A\"[362] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.875, logit=21.125, token_id=23462, metadata=None))), (90538, (5, PredictedToken(token=' Caul', prob=0.00970458984375, logit=16.625, token_id=90538, metadata=None))), (96096, (6, PredictedToken(token=' Dolphin', prob=0.00860595703125, logit=16.5, token_id=96096, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.005218505859375, logit=16.0, token_id=24423, metadata=None))), (16488, (21, PredictedToken(token=' Bat', prob=0.000797271728515625, logit=14.125, token_id=16488, metadata=None))), (2522, (339, PredictedToken(token=' Sc', prob=4.470348358154297e-06, logit=8.9375, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:50 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.715, logit=22.625)', '\" An\"[1556] (p=0.141, logit=21.000)', '\" The\"[578] (p=0.075, logit=20.375)', '\" Among\"[22395] (p=0.040, logit=19.750)', '\" (\"[320] (p=0.005, logit=17.750)']\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     clean_prediction=['\" Eagle\"[36895] (p=0.637, logit=21.500)', '\" An\"[1556] (p=0.182, logit=20.250)', '\" The\"[578] (p=0.086, logit=19.500)', '\" Among\"[22395] (p=0.041, logit=18.750)', '\" E\"[469] (p=0.015, logit=17.750)']\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     clean_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.63671875, logit=21.5, token_id=36895, metadata=None))), (356, (39, PredictedToken(token=' C', prob=0.0001373291015625, logit=13.0625, token_id=356, metadata=None))), (97796, (57, PredictedToken(token=' Skate', prob=6.103515625e-05, logit=12.25, token_id=97796, metadata=None))), (98641, (125, PredictedToken(token=' Microwave', prob=1.4483928680419922e-05, logit=10.8125, token_id=98641, metadata=None))), (16478, (217, PredictedToken(token=' Chair', prob=5.0067901611328125e-06, logit=9.75, token_id=16478, metadata=None)))])\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     int_prediction=['\" Microwave\"[98641] (p=0.898, logit=22.000)', '\" The\"[578] (p=0.031, logit=18.625)', '\" A\"[362] (p=0.021, logit=18.250)', '\" Among\"[22395] (p=0.010, logit=17.500)', '\" C\"[356] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     int_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.8984375, logit=22.0, token_id=98641, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.004730224609375, logit=16.75, token_id=356, metadata=None))), (16478, (22, PredictedToken(token=' Chair', prob=0.000530242919921875, logit=14.5625, token_id=16478, metadata=None))), (97796, (86, PredictedToken(token=' Skate', prob=2.9921531677246094e-05, logit=11.6875, token_id=97796, metadata=None))), (36895, (1989, PredictedToken(token=' Eagle', prob=1.7229467630386353e-07, logit=6.53125, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:50 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:50 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:56:50 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     patch_prediction=['\" Yoga\"[38673] (p=0.777, logit=20.375)', '\" The\"[578] (p=0.044, logit=17.500)', '\" Tie\"[59825] (p=0.027, logit=17.000)', '\" Peach\"[64695] (p=0.018, logit=16.625)', '\" Among\"[22395] (p=0.018, logit=16.625)']\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.691, logit=22.000)', '\" The\"[578] (p=0.136, logit=20.375)', '\" A\"[362] (p=0.083, logit=19.875)', '\" Among\"[22395] (p=0.057, logit=19.500)', '\" Out\"[4470] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.69140625, logit=22.0, token_id=4923, metadata=None))), (11896, (50, PredictedToken(token=' Library', prob=9.059906005859375e-05, logit=13.0625, token_id=11896, metadata=None))), (58251, (104, PredictedToken(token=' Tennis', prob=1.4781951904296875e-05, logit=11.25, token_id=58251, metadata=None))), (10164, (188, PredictedToken(token=' Water', prob=4.500150680541992e-06, logit=10.0625, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.789, logit=21.500)', '\" The\"[578] (p=0.107, logit=19.500)', '\" A\"[362] (p=0.039, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" (\"[320] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.7890625, logit=21.5, token_id=58251, metadata=None))), (4923, (9, PredictedToken(token=' Sk', prob=0.0023651123046875, logit=15.6875, token_id=4923, metadata=None))), (10164, (32, PredictedToken(token=' Water', prob=0.000339508056640625, logit=13.75, token_id=10164, metadata=None))), (11896, (282, PredictedToken(token=' Library', prob=4.023313522338867e-06, logit=9.3125, token_id=11896, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:51 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:51 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.727, logit=21.125)', '\" The\"[578] (p=0.126, logit=19.375)', '\" A\"[362] (p=0.046, logit=18.375)', '\" Among\"[22395] (p=0.036, logit=18.125)', '\" It\"[1102] (p=0.015, logit=17.250)']\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     clean_prediction=['\" Skate\"[97796] (p=0.824, logit=21.625)', '\" The\"[578] (p=0.068, logit=19.125)', '\" A\"[362] (p=0.036, logit=18.500)', '\" Among\"[22395] (p=0.022, logit=18.000)', '\" Option\"[7104] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     clean_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.82421875, logit=21.625, token_id=97796, metadata=None))), (6031, (12, PredictedToken(token=' Bro', prob=0.0016937255859375, logit=15.4375, token_id=6031, metadata=None))), (5340, (13, PredictedToken(token=' Har', prob=0.00159454345703125, logit=15.375, token_id=5340, metadata=None)))])\n",
      "2025-09-16 09:56:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.812, logit=21.875)', '\" Bro\"[6031] (p=0.086, logit=19.625)', '\" The\"[578] (p=0.041, logit=18.875)', '\" A\"[362] (p=0.015, logit=17.875)', '\" None\"[2290] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.8125, logit=21.875, token_id=5340, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.0859375, logit=19.625, token_id=6031, metadata=None))), (97796, (7, PredictedToken(token=' Skate', prob=0.004852294921875, logit=16.75, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:52 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.855, logit=21.375)', '\" The\"[578] (p=0.048, logit=18.500)', '\" Among\"[22395] (p=0.043, logit=18.375)', '\" Out\"[4470] (p=0.004, logit=16.125)', '\" A\"[362] (p=0.004, logit=15.938)']\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.715, logit=21.500)', '\" The\"[578] (p=0.110, logit=19.625)', '\" A\"[362] (p=0.085, logit=19.375)', '\" Among\"[22395] (p=0.046, logit=18.750)', '\" It\"[1102] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.71484375, logit=21.5, token_id=4923, metadata=None))), (23262, (54, PredictedToken(token=' Comb', prob=7.295608520507812e-05, logit=12.3125, token_id=23262, metadata=None))), (64695, (94, PredictedToken(token=' Peach', prob=2.6941299438476562e-05, logit=11.3125, token_id=64695, metadata=None))), (48035, (162, PredictedToken(token=' Gir', prob=9.298324584960938e-06, logit=10.25, token_id=48035, metadata=None))), (19176, (206, PredictedToken(token=' Temple', prob=5.990266799926758e-06, logit=9.8125, token_id=19176, metadata=None)))])\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.750, logit=21.250)', '\" The\"[578] (p=0.102, logit=19.250)', '\" A\"[362] (p=0.048, logit=18.500)', '\" Among\"[22395] (p=0.037, logit=18.250)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.75, logit=21.25, token_id=23262, metadata=None))), (19176, (7, PredictedToken(token=' Temple', prob=0.003265380859375, logit=15.8125, token_id=19176, metadata=None))), (4923, (15, PredictedToken(token=' Sk', prob=0.00154876708984375, logit=15.0625, token_id=4923, metadata=None))), (64695, (108, PredictedToken(token=' Peach', prob=3.409385681152344e-05, logit=11.25, token_id=64695, metadata=None))), (48035, (156, PredictedToken(token=' Gir', prob=1.609325408935547e-05, logit=10.5, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:56:52 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:56:52 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     patch_prediction=['\" Clar\"[31181] (p=0.723, logit=21.625)', '\" The\"[578] (p=0.143, logit=20.000)', '\" A\"[362] (p=0.052, logit=19.000)', '\" Among\"[22395] (p=0.036, logit=18.625)', '\" It\"[1102] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.918, logit=22.125)', '\" Among\"[22395] (p=0.028, logit=18.625)', '\" The\"[578] (p=0.028, logit=18.625)', '\" violet\"[80836] (p=0.003, logit=16.500)', '\" A\"[362] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.91796875, logit=22.125, token_id=74574, metadata=None))), (60413, (74, PredictedToken(token=' Uk', prob=2.86102294921875e-05, logit=11.75, token_id=60413, metadata=None))), (74968, (102, PredictedToken(token=' Razor', prob=1.52587890625e-05, logit=11.125, token_id=74968, metadata=None))), (38930, (503, PredictedToken(token=' Bike', prob=9.201467037200928e-07, logit=8.3125, token_id=38930, metadata=None))), (16730, (1113, PredictedToken(token=' Museum', prob=3.1851232051849365e-07, logit=7.25, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.494, logit=19.875)', '\" Uk\"[60413] (p=0.299, logit=19.375)', '\" The\"[578] (p=0.067, logit=17.875)', '\" Among\"[22395] (p=0.019, logit=16.625)', '\" A\"[362] (p=0.017, logit=16.500)']\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.494140625, logit=19.875, token_id=74574, metadata=None))), (60413, (2, PredictedToken(token=' Uk', prob=0.298828125, logit=19.375, token_id=60413, metadata=None))), (38930, (11, PredictedToken(token=' Bike', prob=0.0035400390625, logit=14.9375, token_id=38930, metadata=None))), (74968, (14, PredictedToken(token=' Razor', prob=0.002593994140625, logit=14.625, token_id=74968, metadata=None))), (16730, (3144, PredictedToken(token=' Museum', prob=3.7439167499542236e-07, logit=5.78125, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:53 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:53 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.711, logit=21.375)', '\" The\"[578] (p=0.109, logit=19.500)', '\" Among\"[22395] (p=0.066, logit=19.000)', '\" A\"[362] (p=0.066, logit=19.000)', '\" (\"[320] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:56:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     clean_prediction=['\" Lily\"[48390] (p=0.656, logit=21.625)', '\" The\"[578] (p=0.166, logit=20.250)', '\" Among\"[22395] (p=0.061, logit=19.250)', '\" A\"[362] (p=0.061, logit=19.250)', '\" l\"[326] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     clean_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.65625, logit=21.625, token_id=48390, metadata=None))), (6031, (26, PredictedToken(token=' Bro', prob=0.000362396240234375, logit=14.125, token_id=6031, metadata=None))), (34392, (94, PredictedToken(token=' Horse', prob=2.0503997802734375e-05, logit=11.25, token_id=34392, metadata=None))), (34046, (257, PredictedToken(token=' Cabinet', prob=3.1441450119018555e-06, logit=9.375, token_id=34046, metadata=None))), (69755, (935, PredictedToken(token=' Notebook', prob=4.6566128730773926e-07, logit=7.46875, token_id=69755, metadata=None))), (82507, (1198, PredictedToken(token=' Jeans', prob=3.3155083656311035e-07, logit=7.125, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.816, logit=22.250)', '\" The\"[578] (p=0.086, logit=20.000)', '\" A\"[362] (p=0.046, logit=19.375)', '\" Among\"[22395] (p=0.025, logit=18.750)', '\" Lily\"[48390] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.81640625, logit=22.25, token_id=34392, metadata=None))), (48390, (5, PredictedToken(token=' Lily', prob=0.007049560546875, logit=17.5, token_id=48390, metadata=None))), (69755, (38, PredictedToken(token=' Notebook', prob=9.441375732421875e-05, logit=13.1875, token_id=69755, metadata=None))), (34046, (41, PredictedToken(token=' Cabinet', prob=8.344650268554688e-05, logit=13.0625, token_id=34046, metadata=None))), (6031, (74, PredictedToken(token=' Bro', prob=2.384185791015625e-05, logit=11.8125, token_id=6031, metadata=None))), (82507, (79, PredictedToken(token=' Jeans', prob=2.2411346435546875e-05, logit=11.75, token_id=82507, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:54 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:56:54 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     patch_prediction=['\" St\"[800] (p=0.832, logit=22.750)', '\" The\"[578] (p=0.060, logit=20.125)', '\" A\"[362] (p=0.053, logit=20.000)', '\" Among\"[22395] (p=0.032, logit=19.500)', '\" stool\"[64172] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     clean_prediction=['\" Rice\"[30616] (p=0.750, logit=21.125)', '\" The\"[578] (p=0.079, logit=18.875)', '\" A\"[362] (p=0.062, logit=18.625)', '\" Among\"[22395] (p=0.037, logit=18.125)', '\" Bench\"[36358] (p=0.020, logit=17.500)']\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     clean_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.75, logit=21.125, token_id=30616, metadata=None))), (36358, (5, PredictedToken(token=' Bench', prob=0.0198974609375, logit=17.5, token_id=36358, metadata=None))), (48665, (79, PredictedToken(token=' Raspberry', prob=5.9604644775390625e-05, logit=11.6875, token_id=48665, metadata=None))), (22607, (224, PredictedToken(token=' Cow', prob=7.12275505065918e-06, logit=9.5625, token_id=22607, metadata=None)))])\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.820, logit=21.625)', '\" The\"[578] (p=0.059, logit=19.000)', '\" A\"[362] (p=0.036, logit=18.500)', '\" Among\"[22395] (p=0.032, logit=18.375)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.8203125, logit=21.625, token_id=36358, metadata=None))), (22607, (22, PredictedToken(token=' Cow', prob=0.000583648681640625, logit=14.375, token_id=22607, metadata=None))), (30616, (32, PredictedToken(token=' Rice', prob=0.0002593994140625, logit=13.5625, token_id=30616, metadata=None))), (48665, (1658, PredictedToken(token=' Raspberry', prob=3.129243850708008e-07, logit=6.84375, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:54 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:56:54 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.883, logit=21.875)', '\" The\"[578] (p=0.044, logit=18.875)', '\" Among\"[22395] (p=0.039, logit=18.750)', '\" It\"[1102] (p=0.004, logit=16.500)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     clean_prediction=['\" Night\"[13120] (p=0.746, logit=21.750)', '\" Among\"[22395] (p=0.069, logit=19.375)', '\" The\"[578] (p=0.061, logit=19.250)', '\" A\"[362] (p=0.042, logit=18.875)', '\" Slow\"[39247] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     clean_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.74609375, logit=21.75, token_id=13120, metadata=None))), (39247, (5, PredictedToken(token=' Slow', prob=0.0120849609375, logit=17.625, token_id=39247, metadata=None))), (9441, (8, PredictedToken(token=' Church', prob=0.0064697265625, logit=17.0, token_id=9441, metadata=None))), (1666, (12, PredictedToken(token=' As', prob=0.0030517578125, logit=16.25, token_id=1666, metadata=None))), (14588, (16, PredictedToken(token=' Dog', prob=0.0019683837890625, logit=15.8125, token_id=14588, metadata=None))), (58600, (208, PredictedToken(token=' Charm', prob=6.258487701416016e-06, logit=10.0625, token_id=58600, metadata=None)))])\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     int_prediction=['\" As\"[1666] (p=0.949, logit=23.250)', '\" Among\"[22395] (p=0.017, logit=19.250)', '\" The\"[578] (p=0.017, logit=19.250)', '\" as\"[439] (p=0.003, logit=17.625)', '\" A\"[362] (p=0.001, logit=16.750)']\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     int_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.94921875, logit=23.25, token_id=1666, metadata=None))), (58600, (121, PredictedToken(token=' Charm', prob=6.198883056640625e-06, logit=11.3125, token_id=58600, metadata=None))), (39247, (135, PredictedToken(token=' Slow', prob=4.827976226806641e-06, logit=11.0625, token_id=39247, metadata=None))), (14588, (260, PredictedToken(token=' Dog', prob=1.385807991027832e-06, logit=9.8125, token_id=14588, metadata=None))), (9441, (302, PredictedToken(token=' Church', prob=1.0132789611816406e-06, logit=9.5, token_id=9441, metadata=None))), (13120, (902, PredictedToken(token=' Night', prob=1.7601996660232544e-07, logit=7.75, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:55 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:55 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.820, logit=20.750)', '\" None\"[2290] (p=0.067, logit=18.250)', '\" The\"[578] (p=0.028, logit=17.375)', '\" A\"[362] (p=0.022, logit=17.125)', '\" There\"[2684] (p=0.008, logit=16.125)']\n",
      "2025-09-16 09:56:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.793, logit=20.250)', '\" The\"[578] (p=0.065, logit=17.750)', '\" helmet\"[32635] (p=0.015, logit=16.250)', '\" Among\"[22395] (p=0.011, logit=16.000)', '\" None\"[2290] (p=0.011, logit=16.000)']\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.79296875, logit=20.25, token_id=67629, metadata=None))), (98028, (12, PredictedToken(token=' Bamboo', prob=0.004730224609375, logit=15.125, token_id=98028, metadata=None))), (40090, (14, PredictedToken(token=' Pressure', prob=0.0032501220703125, logit=14.75, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     int_prediction=['\" Bamboo\"[98028] (p=0.836, logit=20.500)', '\" The\"[578] (p=0.037, logit=17.375)', '\" bamboo\"[59982] (p=0.015, logit=16.500)', '\" Option\"[7104] (p=0.013, logit=16.375)', '\" c\"[272] (p=0.009, logit=16.000)']\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     int_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.8359375, logit=20.5, token_id=98028, metadata=None))), (67629, (15, PredictedToken(token=' Helmet', prob=0.0020751953125, logit=14.5, token_id=67629, metadata=None))), (40090, (81, PredictedToken(token=' Pressure', prob=7.534027099609375e-05, logit=11.1875, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:56 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:56 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.805, logit=21.500)', '\" The\"[578] (p=0.096, logit=19.375)', '\" Among\"[22395] (p=0.040, logit=18.500)', '\" Glo\"[25372] (p=0.009, logit=17.000)', '\" Option\"[7104] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.809, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.625)', '\" It\"[1102] (p=0.013, logit=18.125)']\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.80859375, logit=22.25, token_id=56491, metadata=None))), (8868, (190, PredictedToken(token=' Blue', prob=3.6209821701049805e-06, logit=9.9375, token_id=8868, metadata=None))), (67553, (218, PredictedToken(token=' Pants', prob=2.8312206268310547e-06, logit=9.6875, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.363, logit=19.625)', '\" Pants\"[67553] (p=0.250, logit=19.250)', '\" The\"[578] (p=0.151, logit=18.750)', '\" Among\"[22395] (p=0.072, logit=18.000)', '\" Blue\"[8868] (p=0.049, logit=17.625)']\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.36328125, logit=19.625, token_id=56491, metadata=None))), (67553, (2, PredictedToken(token=' Pants', prob=0.25, logit=19.25, token_id=67553, metadata=None))), (8868, (5, PredictedToken(token=' Blue', prob=0.04931640625, logit=17.625, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:56 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:56 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:56:56 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.648, logit=21.500)', '\" The\"[578] (p=0.145, logit=20.000)', '\" A\"[362] (p=0.088, logit=19.500)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" (\"[320] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     clean_prediction=['\" St\"[800] (p=0.902, logit=23.500)', '\" A\"[362] (p=0.040, logit=20.375)', '\" The\"[578] (p=0.035, logit=20.250)', '\" Among\"[22395] (p=0.007, logit=18.625)', '\" stool\"[64172] (p=0.002, logit=17.500)']\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     clean_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.90234375, logit=23.5, token_id=800, metadata=None))), (1901, (10, PredictedToken(token=' Z', prob=0.000469207763671875, logit=15.9375, token_id=1901, metadata=None))), (88668, (68, PredictedToken(token=' Blender', prob=1.4185905456542969e-05, logit=12.4375, token_id=88668, metadata=None)))])\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.926, logit=22.375)', '\" The\"[578] (p=0.022, logit=18.625)', '\" A\"[362] (p=0.010, logit=17.875)', '\" Blender\"[88668] (p=0.009, logit=17.750)', '\" Among\"[22395] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.92578125, logit=22.375, token_id=1901, metadata=None))), (88668, (4, PredictedToken(token=' Blender', prob=0.00909423828125, logit=17.75, token_id=88668, metadata=None))), (800, (11, PredictedToken(token=' St', prob=0.001312255859375, logit=15.8125, token_id=800, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:57 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:57 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.777, logit=21.500)', '\" The\"[578] (p=0.064, logit=19.000)', '\" A\"[362] (p=0.030, logit=18.250)', '\" Among\"[22395] (p=0.027, logit=18.125)', '\" Option\"[7104] (p=0.016, logit=17.625)']\n",
      "2025-09-16 09:56:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     clean_prediction=['\" Marker\"[40975] (p=0.906, logit=22.500)', '\" A\"[362] (p=0.031, logit=19.125)', '\" The\"[578] (p=0.027, logit=19.000)', '\" marker\"[11381] (p=0.008, logit=17.750)', '\" Among\"[22395] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     clean_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.90625, logit=22.5, token_id=40975, metadata=None))), (24941, (66, PredictedToken(token=' Bear', prob=3.409385681152344e-05, logit=12.3125, token_id=24941, metadata=None))), (71264, (136, PredictedToken(token=' Daisy', prob=8.106231689453125e-06, logit=10.875, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.424, logit=20.875)', '\" Marker\"[40975] (p=0.424, logit=20.875)', '\" The\"[578] (p=0.045, logit=18.625)', '\" A\"[362] (p=0.024, logit=18.000)', '\" Daisy\"[71264] (p=0.016, logit=17.625)']\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     int_track=OrderedDict([(40975, (2, PredictedToken(token=' Marker', prob=0.423828125, logit=20.875, token_id=40975, metadata=None))), (24941, (1, PredictedToken(token=' Bear', prob=0.423828125, logit=20.875, token_id=24941, metadata=None))), (71264, (5, PredictedToken(token=' Daisy', prob=0.016357421875, logit=17.625, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:58 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:56:58 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.863, logit=21.875)', '\" The\"[578] (p=0.030, logit=18.500)', '\" phone\"[4641] (p=0.018, logit=18.000)', '\" A\"[362] (p=0.018, logit=18.000)', '\" Har\"[5340] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.789, logit=21.000)', '\" The\"[578] (p=0.057, logit=18.375)', '\" A\"[362] (p=0.044, logit=18.125)', '\" Keyboard\"[26698] (p=0.021, logit=17.375)', '\" None\"[2290] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.7890625, logit=21.0, token_id=36943, metadata=None))), (26698, (4, PredictedToken(token=' Keyboard', prob=0.02099609375, logit=17.375, token_id=26698, metadata=None))), (48471, (52, PredictedToken(token=' Shower', prob=0.00020599365234375, logit=12.75, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.867, logit=21.375)', '\" The\"[578] (p=0.038, logit=18.250)', '\" None\"[2290] (p=0.023, logit=17.750)', '\" keyboard\"[13939] (p=0.011, logit=17.000)', '\" A\"[362] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.8671875, logit=21.375, token_id=26698, metadata=None))), (48471, (6, PredictedToken(token=' Shower', prob=0.00750732421875, logit=16.625, token_id=48471, metadata=None))), (36943, (21, PredictedToken(token=' Folder', prob=0.000698089599609375, logit=14.25, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:58 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:58 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:56:58 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.559, logit=21.500)', '\" The\"[578] (p=0.264, logit=20.750)', '\" A\"[362] (p=0.086, logit=19.625)', '\" Among\"[22395] (p=0.046, logit=19.000)', '\" It\"[1102] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.840, logit=22.000)', '\" The\"[578] (p=0.069, logit=19.500)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" A\"[362] (p=0.014, logit=17.875)', '\" PE\"[22557] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.83984375, logit=22.0, token_id=64695, metadata=None))), (94467, (15, PredictedToken(token=' Trom', prob=0.0004634857177734375, logit=14.5, token_id=94467, metadata=None))), (96096, (127, PredictedToken(token=' Dolphin', prob=1.0251998901367188e-05, logit=10.6875, token_id=96096, metadata=None))), (39247, (304, PredictedToken(token=' Slow', prob=1.8998980522155762e-06, logit=9.0, token_id=39247, metadata=None))), (58600, (957, PredictedToken(token=' Charm', prob=3.986060619354248e-07, logit=7.4375, token_id=58600, metadata=None))), (14669, (4704, PredictedToken(token=' Camera', prob=5.052424967288971e-08, logit=5.375, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     int_prediction=['\" The\"[578] (p=0.396, logit=19.500)', '\" Trom\"[94467] (p=0.273, logit=19.125)', '\" Among\"[22395] (p=0.129, logit=18.375)', '\" A\"[362] (p=0.069, logit=17.750)', '\" Peach\"[64695] (p=0.029, logit=16.875)']\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     int_track=OrderedDict([(94467, (2, PredictedToken(token=' Trom', prob=0.2734375, logit=19.125, token_id=94467, metadata=None))), (64695, (5, PredictedToken(token=' Peach', prob=0.02880859375, logit=16.875, token_id=64695, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.00640869140625, logit=15.375, token_id=96096, metadata=None))), (14669, (94, PredictedToken(token=' Camera', prob=8.58306884765625e-05, logit=11.0625, token_id=14669, metadata=None))), (39247, (162, PredictedToken(token=' Slow', prob=3.361701965332031e-05, logit=10.125, token_id=39247, metadata=None))), (58600, (348, PredictedToken(token=' Charm', prob=8.52346420288086e-06, logit=8.75, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:56:59 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:56:59 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:56:59 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.723, logit=21.500)', '\" The\"[578] (p=0.126, logit=19.750)', '\" Among\"[22395] (p=0.052, logit=18.875)', '\" A\"[362] (p=0.046, logit=18.750)', '\" L\"[445] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     clean_prediction=['\" Train\"[27217] (p=0.723, logit=21.875)', '\" The\"[578] (p=0.110, logit=20.000)', '\" A\"[362] (p=0.086, logit=19.750)', '\" Among\"[22395] (p=0.046, logit=19.125)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     clean_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.72265625, logit=21.875, token_id=27217, metadata=None))), (29625, (10, PredictedToken(token=' Chain', prob=0.00157928466796875, logit=15.75, token_id=29625, metadata=None))), (82994, (71, PredictedToken(token=' Toilet', prob=6.532669067382812e-05, logit=12.5625, token_id=82994, metadata=None))), (1901, (80, PredictedToken(token=' Z', prob=4.76837158203125e-05, logit=12.25, token_id=1901, metadata=None))), (40975, (117, PredictedToken(token=' Marker', prob=1.8596649169921875e-05, logit=11.3125, token_id=40975, metadata=None))), (9441, (359, PredictedToken(token=' Church', prob=1.735985279083252e-06, logit=8.9375, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.797, logit=21.875)', '\" A\"[362] (p=0.074, logit=19.500)', '\" The\"[578] (p=0.058, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" Chain\"[29625] (p=0.017, logit=18.000)']\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.796875, logit=21.875, token_id=1901, metadata=None))), (29625, (5, PredictedToken(token=' Chain', prob=0.0166015625, logit=18.0, token_id=29625, metadata=None))), (9441, (20, PredictedToken(token=' Church', prob=0.000728607177734375, logit=14.875, token_id=9441, metadata=None))), (27217, (28, PredictedToken(token=' Train', prob=0.0002841949462890625, logit=13.9375, token_id=27217, metadata=None))), (40975, (102, PredictedToken(token=' Marker', prob=2.0623207092285156e-05, logit=11.3125, token_id=40975, metadata=None))), (82994, (189, PredictedToken(token=' Toilet', prob=5.21540641784668e-06, logit=9.9375, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:00 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:57:00 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     patch_prediction=['\" Potato\"[78703] (p=0.828, logit=21.750)', '\" The\"[578] (p=0.060, logit=19.125)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" A\"[362] (p=0.028, logit=18.375)', '\" Pot\"[14020] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     clean_prediction=['\" Hospital\"[15429] (p=0.914, logit=22.875)', '\" Among\"[22395] (p=0.021, logit=19.125)', '\" The\"[578] (p=0.021, logit=19.125)', '\" A\"[362] (p=0.017, logit=18.875)', '\" It\"[1102] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     clean_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.9140625, logit=22.875, token_id=15429, metadata=None))), (3341, (11, PredictedToken(token=' Car', prob=0.000888824462890625, logit=15.9375, token_id=3341, metadata=None))), (6914, (14, PredictedToken(token=' Let', prob=0.000690460205078125, logit=15.6875, token_id=6914, metadata=None))), (13394, (24, PredictedToken(token=' Bed', prob=0.0003261566162109375, logit=14.9375, token_id=13394, metadata=None))), (61731, (57, PredictedToken(token=' Soap', prob=6.866455078125e-05, logit=13.375, token_id=61731, metadata=None))), (30173, (58, PredictedToken(token=' Speaker', prob=6.437301635742188e-05, logit=13.3125, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:57:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.422, logit=19.875)', '\" Speaker\"[30173] (p=0.226, logit=19.250)', '\" The\"[578] (p=0.107, logit=18.500)', '\" None\"[2290] (p=0.050, logit=17.750)', '\" Bed\"[13394] (p=0.044, logit=17.625)']\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.421875, logit=19.875, token_id=6914, metadata=None))), (30173, (2, PredictedToken(token=' Speaker', prob=0.2255859375, logit=19.25, token_id=30173, metadata=None))), (13394, (5, PredictedToken(token=' Bed', prob=0.04443359375, logit=17.625, token_id=13394, metadata=None))), (61731, (10, PredictedToken(token=' Soap', prob=0.007720947265625, logit=15.875, token_id=61731, metadata=None))), (15429, (14, PredictedToken(token=' Hospital', prob=0.0050048828125, logit=15.4375, token_id=15429, metadata=None))), (3341, (31, PredictedToken(token=' Car', prob=0.000865936279296875, logit=13.6875, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:01 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:57:01 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.789, logit=22.000)', '\" The\"[578] (p=0.094, logit=19.875)', '\" A\"[362] (p=0.044, logit=19.125)', '\" Among\"[22395] (p=0.035, logit=18.875)', '\" hair\"[7013] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     clean_prediction=['\" Chair\"[16478] (p=0.875, logit=23.625)', '\" The\"[578] (p=0.050, logit=20.750)', '\" A\"[362] (p=0.050, logit=20.750)', '\" Among\"[22395] (p=0.008, logit=18.875)', '\" chair\"[10716] (p=0.004, logit=18.125)']\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     clean_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.875, logit=23.625, token_id=16478, metadata=None))), (61731, (22, PredictedToken(token=' Soap', prob=0.0001678466796875, logit=15.0625, token_id=61731, metadata=None))), (49268, (55, PredictedToken(token=' Dish', prob=2.1338462829589844e-05, logit=13.0, token_id=49268, metadata=None)))])\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.930, logit=23.250)', '\" The\"[578] (p=0.032, logit=19.875)', '\" Chair\"[16478] (p=0.009, logit=18.625)', '\" A\"[362] (p=0.008, logit=18.500)', '\" Among\"[22395] (p=0.005, logit=18.000)']\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.9296875, logit=23.25, token_id=61731, metadata=None))), (16478, (3, PredictedToken(token=' Chair', prob=0.0091552734375, logit=18.625, token_id=16478, metadata=None))), (49268, (32, PredictedToken(token=' Dish', prob=8.96453857421875e-05, logit=14.0, token_id=49268, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:57:01 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:57:01 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.758, logit=22.250)', '\" A\"[362] (p=0.090, logit=20.125)', '\" The\"[578] (p=0.080, logit=20.000)', '\" Among\"[22395] (p=0.033, logit=19.125)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     clean_prediction=['\" Camera\"[14669] (p=0.723, logit=21.375)', '\" The\"[578] (p=0.076, logit=19.125)', '\" A\"[362] (p=0.067, logit=19.000)', '\" Among\"[22395] (p=0.046, logit=18.625)', '\" Night\"[13120] (p=0.028, logit=18.125)']\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     clean_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.72265625, logit=21.375, token_id=14669, metadata=None))), (13120, (5, PredictedToken(token=' Night', prob=0.0279541015625, logit=18.125, token_id=13120, metadata=None))), (20423, (43, PredictedToken(token=' Amb', prob=0.0002574920654296875, logit=13.4375, token_id=20423, metadata=None))), (52466, (251, PredictedToken(token=' Warehouse', prob=6.467103958129883e-06, logit=9.75, token_id=52466, metadata=None))), (74968, (401, PredictedToken(token=' Razor', prob=2.5331974029541016e-06, logit=8.8125, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     int_prediction=['\" Amb\"[20423] (p=0.652, logit=21.625)', '\" An\"[1556] (p=0.129, logit=20.000)', '\" Warehouse\"[52466] (p=0.100, logit=19.750)', '\" The\"[578] (p=0.042, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.625)']\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     int_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.65234375, logit=21.625, token_id=20423, metadata=None))), (52466, (3, PredictedToken(token=' Warehouse', prob=0.10009765625, logit=19.75, token_id=52466, metadata=None))), (14669, (10, PredictedToken(token=' Camera', prob=0.002349853515625, logit=16.0, token_id=14669, metadata=None))), (13120, (209, PredictedToken(token=' Night', prob=5.841255187988281e-06, logit=10.0, token_id=13120, metadata=None))), (74968, (1007, PredictedToken(token=' Razor', prob=4.637986421585083e-07, logit=7.46875, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:02 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:57:02 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     patch_prediction=['\" Sh\"[1443] (p=0.832, logit=21.625)', '\" Among\"[22395] (p=0.053, logit=18.875)', '\" The\"[578] (p=0.047, logit=18.750)', '\" Option\"[7104] (p=0.009, logit=17.125)', '\" (\"[320] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.891, logit=22.250)', '\" The\"[578] (p=0.035, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.875)', '\" dress\"[8679] (p=0.010, logit=17.750)', '\" Among\"[22395] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.890625, logit=22.25, token_id=29318, metadata=None))), (70110, (37, PredictedToken(token=' Ottoman', prob=0.00010347366333007812, logit=13.1875, token_id=70110, metadata=None))), (48471, (179, PredictedToken(token=' Shower', prob=4.827976226806641e-06, logit=10.125, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:57:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.754, logit=20.625)', '\" Dress\"[29318] (p=0.062, logit=18.125)', '\" The\"[578] (p=0.042, logit=17.750)', '\" An\"[1556] (p=0.038, logit=17.625)', '\" Shower\"[48471] (p=0.016, logit=16.750)']\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.75390625, logit=20.625, token_id=70110, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.06201171875, logit=18.125, token_id=29318, metadata=None))), (48471, (5, PredictedToken(token=' Shower', prob=0.015625, logit=16.75, token_id=48471, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:57:03 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     patch_prediction=['\" Shirt\"[55807] (p=0.699, logit=21.875)', '\" The\"[578] (p=0.121, logit=20.125)', '\" A\"[362] (p=0.074, logit=19.625)', '\" Among\"[22395] (p=0.065, logit=19.500)', '\" Out\"[4470] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.871, logit=21.750)', '\" A\"[362] (p=0.026, logit=18.250)', '\" The\"[578] (p=0.023, logit=18.125)', '\" None\"[2290] (p=0.012, logit=17.500)', '\" watch\"[3821] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.87109375, logit=21.75, token_id=10573, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.00665283203125, logit=16.875, token_id=23262, metadata=None))), (8868, (22, PredictedToken(token=' Blue', prob=0.00061798095703125, logit=14.5, token_id=8868, metadata=None))), (91782, (40, PredictedToken(token=' Shorts', prob=0.00022792816162109375, logit=13.5, token_id=91782, metadata=None))), (56491, (81, PredictedToken(token=' Piano', prob=5.7697296142578125e-05, logit=12.125, token_id=56491, metadata=None))), (82452, (304, PredictedToken(token=' Jasmine', prob=4.172325134277344e-06, logit=9.5, token_id=82452, metadata=None)))])\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.551, logit=19.625)', '\" Comb\"[23262] (p=0.157, logit=18.375)', '\" None\"[2290] (p=0.096, logit=17.875)', '\" The\"[578] (p=0.045, logit=17.125)', '\" A\"[362] (p=0.021, logit=16.375)']\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.55078125, logit=19.625, token_id=91782, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.1572265625, logit=18.375, token_id=23262, metadata=None))), (10573, (7, PredictedToken(token=' Watch', prob=0.006927490234375, logit=15.25, token_id=10573, metadata=None))), (8868, (391, PredictedToken(token=' Blue', prob=1.2576580047607422e-05, logit=8.9375, token_id=8868, metadata=None))), (56491, (2240, PredictedToken(token=' Piano', prob=1.2442469596862793e-06, logit=6.625, token_id=56491, metadata=None))), (82452, (6431, PredictedToken(token=' Jasmine', prob=3.1478703022003174e-07, logit=5.25, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:03 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:57:03 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:57:03 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     patch_prediction=['\" Uk\"[60413] (p=0.730, logit=21.500)', '\" The\"[578] (p=0.127, logit=19.750)', '\" A\"[362] (p=0.053, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.375)', '\" It\"[1102] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.867, logit=21.750)', '\" A\"[362] (p=0.043, logit=18.750)', '\" The\"[578] (p=0.030, logit=18.375)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" (\"[320] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.8671875, logit=21.75, token_id=23262, metadata=None))), (9939, (8, PredictedToken(token=' Er', prob=0.002288818359375, logit=15.8125, token_id=9939, metadata=None))), (3420, (158, PredictedToken(token=' Trump', prob=1.0609626770019531e-05, logit=10.4375, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.922, logit=21.875)', '\" The\"[578] (p=0.022, logit=18.125)', '\" Among\"[22395] (p=0.012, logit=17.500)', '\" A\"[362] (p=0.008, logit=17.125)', '\" None\"[2290] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.921875, logit=21.875, token_id=3420, metadata=None))), (9939, (22, PredictedToken(token=' Er', prob=0.0003299713134765625, logit=13.9375, token_id=9939, metadata=None))), (23262, (29, PredictedToken(token=' Comb', prob=0.00024127960205078125, logit=13.625, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:57:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:57:04 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     Caching the query states for the 145 heads\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.738, logit=22.000)', '\" The\"[578] (p=0.128, logit=20.250)', '\" Among\"[22395] (p=0.032, logit=18.875)', '\" A\"[362] (p=0.032, logit=18.875)', '\" c\"[272] (p=0.020, logit=18.375)']\n",
      "2025-09-16 09:57:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:57:05 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.087, logit=19.875)', '\" Among\"[22395] (p=0.041, logit=19.125)', '\" A\"[362] (p=0.007, logit=17.375)', '\" It\"[1102] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:57:05 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.82421875, logit=22.125, token_id=18343, metadata=None))), (55870, (13, PredictedToken(token=' Jacket', prob=0.00102996826171875, logit=15.4375, token_id=55870, metadata=None))), (3341, (89, PredictedToken(token=' Car', prob=2.9206275939941406e-05, logit=11.875, token_id=3341, metadata=None))), (8325, (189, PredictedToken(token=' Apple', prob=6.496906280517578e-06, logit=10.375, token_id=8325, metadata=None))), (47589, (345, PredictedToken(token=' Basketball', prob=2.250075340270996e-06, logit=9.3125, token_id=47589, metadata=None))), (60413, (446, PredictedToken(token=' Uk', prob=1.2814998626708984e-06, logit=8.75, token_id=60413, metadata=None)))])\n",
      "2025-09-16 09:57:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:57:05 src.selection.optimization INFO     int_prediction=['\" Uk\"[60413] (p=0.719, logit=21.125)', '\" The\"[578] (p=0.161, logit=19.625)', '\" Among\"[22395] (p=0.032, logit=18.000)', '\" A\"[362] (p=0.025, logit=17.750)', '\" \"[220] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:57:05 src.selection.optimization INFO     int_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.71875, logit=21.125, token_id=60413, metadata=None))), (55870, (15, PredictedToken(token=' Jacket', prob=0.0015716552734375, logit=15.0, token_id=55870, metadata=None))), (3341, (30, PredictedToken(token=' Car', prob=0.0003509521484375, logit=13.5, token_id=3341, metadata=None))), (47589, (50, PredictedToken(token=' Basketball', prob=0.000156402587890625, logit=12.6875, token_id=47589, metadata=None))), (18343, (343, PredictedToken(token=' Paper', prob=4.1425228118896484e-06, logit=9.0625, token_id=18343, metadata=None))), (8325, (376, PredictedToken(token=' Apple', prob=3.4421682357788086e-06, logit=8.875, token_id=8325, metadata=None)))])\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    # clean_sample.default_option_style=\"numbered\"\n",
    "    # patch_sample.default_option_style=\"numbered\"\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77e0b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88597f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_rank_delta: 137.4492 ± 445.1577\n",
      "target_rank_delta: -135.4512 ± 208.6684\n",
      "clean_rank_after_intervention: 138.4512 ± 445.1575\n",
      "target_rank_after_intervention: 3.0332 ± 17.1032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0ee4558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_logit_delta: -6.9389 ± 3.8012\n",
      "target_logit_delta: 8.2198 ± 3.1892\n",
      "clean_logit_after_intervention: 14.7764 ± 3.8365\n",
      "target_logit_after_intervention: 20.6578 ± 1.8404\n"
     ]
    }
   ],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "083a64bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae404a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Counterfactual patching accuracy: 0.7617 (390/512)\n",
      "================================================================================\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! find the positions after the patched intervention.\n",
    "# Is it looking at the first one, or the position of the \n",
    "# previous answer?\n",
    "\n",
    "from src.selection.utils import get_first_token_id\n",
    "\n",
    "failed_pos_track = {\n",
    "    \"clean_obj_idx\": [],\n",
    "    \"patch_obj_idx\": [],\n",
    "    \"first_obj_idx\": [],\n",
    "    \"other\": []\n",
    "}\n",
    "\n",
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "    clean_obj_idx = clean_sample.obj_idx\n",
    "    patch_obj_idx = patch_sample.obj_idx\n",
    "\n",
    "    int_top_tok = list(int_track.keys())[0]\n",
    "    int_top_obj = int_track[int_top_tok][1].token_id\n",
    "    opt_first_tokens = [\n",
    "        get_first_token_id(name=opt, tokenizer=mt.tokenizer, prefix=\" \")\n",
    "        for opt in clean_sample.options\n",
    "    ]\n",
    "    int_top_idx = opt_first_tokens.index(int_top_obj)\n",
    "\n",
    "    if int_top_idx == clean_obj_idx:\n",
    "        failed_pos_track[\"clean_obj_idx\"].append(failed_case)\n",
    "    elif int_top_idx == patch_obj_idx:\n",
    "        failed_pos_track[\"patch_obj_idx\"].append(failed_case)\n",
    "    elif int_top_idx == 0:\n",
    "        failed_pos_track[\"first_obj_idx\"].append(failed_case)\n",
    "    else:\n",
    "        failed_pos_track[\"other\"].append(failed_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124414a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x_vals = failed_pos_track.keys()\n",
    "y_vals = [len(failed_pos_track[key]) for key in x_vals]\n",
    "plt.bar(x_vals, y_vals)\n",
    "plt.xlabel(\"Failed Position Types\")\n",
    "plt.ylabel(\"Number of Failed Cases\")\n",
    "plt.title(\"Failed Position Types Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4b0c9",
   "metadata": {},
   "source": [
    "## Select One -- MCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e798959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectionSample, SelectOneTask\n",
    "\n",
    "select_one_mcq = SelectOneTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        # \"landmarks.json\"\n",
    "    )\n",
    ")\n",
    "print(select_one_mcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f28f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from src.selection.utils import get_first_token_id\n",
    "from src.functional import predict_next_token\n",
    "from src.selection.data import MCQify_sample\n",
    "\n",
    "test_sample = select_one_task.get_random_sample(\n",
    "    mt=mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    # category=\"actor\",\n",
    "    # category=\"United Kingdom\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "test_sample = MCQify_sample(mt, test_sample)\n",
    "print(\n",
    "    test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"'\n",
    ")\n",
    "\n",
    "predict_next_token(mt=mt, inputs=test_sample.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2feed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1305d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 1024\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_one_task.task_name,\n",
    "    \"objects\",\n",
    "    # \"profession\",\n",
    "    # \"nationality\"\n",
    "    # \"landmarks\"\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    pred_target_token_id = cf_pair.clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    pred_obj_idx = cf_pair.clean_sample.metadata[\"track_type_obj_idx\"]\n",
    "    cf_pair.clean_sample.metadata[\"track_type_obj_token_id\"] = get_first_token_id(\n",
    "        name=chr(ord('a') + pred_obj_idx),\n",
    "        tokenizer=mt.tokenizer,\n",
    "        prefix=\" \"\n",
    "    )\n",
    "    validation_set.append((\n",
    "        MCQify_sample(cf_pair.clean_sample), \n",
    "        MCQify_sample(cf_pair.patch_sample)\n",
    "    ))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98039964",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "import copy\n",
    "\n",
    "clean, patch = copy.deepcopy(validation_set[5])\n",
    "# failed_case = failed_pos_track[\"patch_obj_idx\"][5]\n",
    "# clean = failed_case[\"clean_sample\"]\n",
    "# patch = failed_case[\"patch_sample\"]\n",
    "# clean.default_option_style=\"numbered\"\n",
    "patch.default_option_style=\"numbered\"\n",
    "\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    "    patch_args={\n",
    "        \"batch_size\": len(patch.options),\n",
    "        \"distinct_options\": False,\n",
    "        # \"task\": select_task,\n",
    "        # \"prompt_template_idx\": prompt_template_idx,\n",
    "        # \"option_style\": patch.default_option_style,\n",
    "        # \"n_distractors\": N_DISTRACTORS,\n",
    "    },\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    patch_sample.default_option_style=\"numbered\"\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "            # \"task\": select_task,\n",
    "            # \"prompt_template_idx\": prompt_template_idx,\n",
    "            # \"option_style\": patch.default_option_style,\n",
    "            # \"n_distractors\": N_DISTRACTORS,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eca4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92069e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643faf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dba4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f0962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63c326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006632f5",
   "metadata": {},
   "source": [
    "## SelectFirst Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectionSample, SelectFirstTask\n",
    "\n",
    "select_first_task = SelectFirstTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(select_first_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d107a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = select_first_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=\"single_line\",\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6630da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_first_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 256\n",
    "start_number = 257\n",
    "\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_first_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_first_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(4, 7)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set) + start_number - 1:05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_first_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e23141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[15]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb576ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        # patch_args={\n",
    "        #     \"batch_size\": len(patch.options),\n",
    "        #     \"distinct_options\": False,\n",
    "        # },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ba769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_sample, patch_sample in validation_set:\n",
    "    assert \"first\" in clean_sample.prompt()\n",
    "    assert \"first\" in patch_sample.prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd275e7a",
   "metadata": {},
   "source": [
    "## SelectLast Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectLastTask\n",
    "\n",
    "select_last_task = SelectLastTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(select_last_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b04029",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = select_last_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=\"single_line\",\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_last_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 200\n",
    "start_number = 312\n",
    "\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_last_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_last_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(4, 7)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set) + start_number - 1:05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61015489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "from src.functional import free_gpu_cache\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_last_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38319c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2896cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[15]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf475c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d217f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cff4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9315a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_sample, patch_sample in validation_set:\n",
    "    assert \"last\" in clean_sample.prompt()\n",
    "    assert \"last\" in patch_sample.prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d20aed",
   "metadata": {},
   "source": [
    "## YesNo Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ff1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import YesNoSample, YesNoTask\n",
    "\n",
    "yes_no_task = YesNoTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(yes_no_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1776c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = yes_no_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    "    yes_mode=False\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair, get_counterfactual_samples_interface\n",
    "from src.functional import free_gpu_cache\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    yes_no_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[yes_no_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=yes_no_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_options=5,\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set):05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    yes_no_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[15]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4761dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        # patch_args={\n",
    "        #     \"batch_size\": len(patch_sample.options),\n",
    "        #     \"distinct_options\": False,\n",
    "        # },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7958bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab562a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c783064",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96debe34",
   "metadata": {},
   "source": [
    "## Counting Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CountingSample, CountingTask\n",
    "\n",
    "counting_task = CountingTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(counting_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_sample = counting_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    "    n_options = random.choice(range(2, 4)),\n",
    ")\n",
    "\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    counting_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[counting_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=counting_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_options=5,\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set):05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "import random\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    counting_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da11e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[1]\n",
    "print('\"' + patch.prompt() + '\"', \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print('\"' + clean.prompt() + '\"', \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], f'\"{mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c71f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[3]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4821fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f190e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448134da",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910d98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e40928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
