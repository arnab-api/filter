{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e7c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cd4155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:38:38 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-09-16 09:38:39 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-09-16 09:38:39 __main__ INFO     transformers.__version__='4.55.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3b2420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:38:42 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks/checking_head_generalization, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-16 09:38:42 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks/checking_head_generalization, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-16 09:38:42 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-09-16 09:38:42 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b62bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:38:43 src.models WARNING  meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-09-16 09:38:43 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-09-16 09:38:43 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-09-16 09:38:43 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-09-16 09:38:43 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/meta-llama/Llama-3.3-70B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe524d2ed70412599d628a26f8ea765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:39:33 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-09-16 09:39:33 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-09-16 09:39:33 src.models INFO     loaded model <meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77abadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFirstTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectFirstTask\n",
    "\n",
    "#################################################################################\n",
    "TASK_CLS = SelectFirstTask\n",
    "prompt_template_idx = 3\n",
    "N_DISTRACTORS = 5\n",
    "OPTION_STYLE = \"single_line\"\n",
    "#################################################################################\n",
    "\n",
    "optimized_task = TASK_CLS.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(optimized_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da783c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Orange, Apartment, Bench, Shower, Cow, Watermelon, Piano, Grape, Plum.\n",
      "What is the first fruit from the list above?\n",
      "Answer: >> \" Orange\"\n"
     ]
    }
   ],
   "source": [
    "sample = optimized_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    # category=\"actor\",\n",
    "    # category=\"Brazil\"\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=False,\n",
    ")\n",
    "\n",
    "print(sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([sample.ans_token_id])}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb708dc",
   "metadata": {},
   "source": [
    "## Loading the heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42843f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"selection/optimized_backup_heads\",\n",
    "#     mt.name.split(\"/\")[-1],\n",
    "#     f\"{select_task.task_name}.npz\"\n",
    "# )\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection/optimized_heads\",\n",
    "    model_key.split(\"/\")[-1],\n",
    "    \"distinct_options\",\n",
    "    f\"{optimized_task.task_name}\",\n",
    "    \"legacy\",\n",
    "    \"epoch_10.npz\"\n",
    ")\n",
    "\n",
    "# optimized_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"test_opt_code\",\n",
    "#     model_key.split(\"/\")[-1],\n",
    "#     \"distinct_options\",\n",
    "#     f\"{select_task.task_name}\",\n",
    "#     \"legacy\",\n",
    "#     \"epoch_10.npz\"\n",
    "# )\n",
    "\n",
    "optimization_results = np.load(optimized_path, allow_pickle=True)\n",
    "plt.plot(optimization_results[\"losses\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcc867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(torch.float32)\n",
    "optimal_head_mask[52:, :] = 0.0\n",
    "\n",
    "plt.imshow(\n",
    "    optimal_head_mask.T.numpy(),\n",
    "    cmap=\"Blues\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "optimized_heads = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).tolist()\n",
    "optimized_heads = [\n",
    "    (layer_idx, head_idx) for layer_idx, head_idx in optimized_heads\n",
    "]\n",
    "print(len(optimized_heads))\n",
    "\n",
    "HEADS = optimized_heads\n",
    "\n",
    "(35, 19) in HEADS, (35, 19) in optimized_heads\n",
    "# [(29, 3) in HEADS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb620ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:10 src.selection.functional DEBUG    Predictions: ['\" Orange\"[22725] (p=0.648, logit=21.750)', '\" Water\"[10164] (p=0.186, logit=20.500)', '\" The\"[578] (p=0.113, logit=20.000)', '\" Plum\"[84409] (p=0.010, logit=17.625)', '\" OR\"[2794] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:40:10 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-9e7d337c-4345\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-9e7d337c-4345\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Orange\", \",\", \" Apartment\", \",\", \" Bench\", \",\", \" Shower\", \",\", \" Cow\", \",\", \" Water\", \"melon\", \",\", \" Piano\", \",\", \" Grape\", \",\", \" Plum\", \".\\n\", \"What\", \" is\", \" the\", \" first\", \" fruit\", \" from\", \" the\", \" list\", \" above\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.0230272077023983, 0.002729451283812523, 0.038602594286203384, 0.015617482364177704, 0.004010750912129879, 0.020802486687898636, 0.0036032700445502996, 0.011271629482507706, 0.00485289515927434, 0.005579748190939426, 0.008627950213849545, 0.012834737077355385, 0.01050447579473257, 0.040518585592508316, 0.024532342329621315, 0.004677660763263702, 0.005209051538258791, 0.02176908776164055, 0.03070748969912529, 0.02048705518245697, 0.020122762769460678, 0.0034862919710576534, 0.0029260495211929083, 0.00826819147914648, 0.009261080995202065, 0.09900476783514023, 0.012568661943078041, 0.010604151524603367, 0.02162066288292408, 0.009451022371649742, 0.04737790301442146, 0.01262381486594677, 0.06504350900650024]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f8ed04080d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.attention import get_attention_matrices\n",
    "from src.selection.functional import (\n",
    "    verify_head_patterns,\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    ")\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=sample.prompt(option_style=\"single_line\"),\n",
    "    options=sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fff0b",
   "metadata": {},
   "source": [
    "# Validating Against Other Reduce Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c517d0",
   "metadata": {},
   "source": [
    "## SelectOne Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257b8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'prompt_templates', 'odd_one_prompt_templates', 'order_prompt_templates', 'count_prompt_templates', 'yes_no_prompt_templates', 'first_item_in_cat_prompt_templates', 'last_item_in_cat_prompt_templates', 'categories', 'exclude_categories']\n",
      "SelectOneTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n",
      "{'fruit': ['flower', 'tree', 'vegetable'], 'flower': ['fruit', 'tree', 'vegetable'], 'tree': ['fruit', 'flower'], 'vegetable': ['fruit', 'flower'], 'electronics': ['kitchen appliance', 'office supply'], 'kitchen appliance': ['electronics', 'office supply'], 'office supply': ['electronics', 'kitchen appliance']}\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample, SelectOneTask\n",
    "\n",
    "select_one_task = SelectOneTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        # \"landmarks.json\"\n",
    "        # \"rhymes.json\"\n",
    "    )\n",
    ")\n",
    "print(select_one_task)\n",
    "print(select_one_task.exclude_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19a798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Marker, Willow, Brooch, Bear, Toothbrush, Baseball.\n",
      "Which among these objects mentioned above is a animal?\n",
      "Answer: >> \" Bear\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Bear', prob=0.765625, logit=21.375, token_id=24941, metadata=None),\n",
       " PredictedToken(token=' Among', prob=0.0712890625, logit=19.0, token_id=22395, metadata=None),\n",
       " PredictedToken(token=' The', prob=0.06298828125, logit=18.875, token_id=578, metadata=None),\n",
       " PredictedToken(token=' A', prob=0.038330078125, logit=18.375, token_id=362, metadata=None),\n",
       " PredictedToken(token=' BE', prob=0.00457763671875, logit=16.25, token_id=7354, metadata=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = select_one_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    # category=\"fruit\",\n",
    "    # category=\"actor\",\n",
    "    # category=\"United Kingdom\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "# test_sample.prompt_template = \"Recall the nationality of these people:\\n\" + test_sample.prompt_template\n",
    "# test_sample.prompt_template = \"Recall which country these landmarks are located in:\\n\" + test_sample.prompt_template\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc685a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:20 src.selection.functional DEBUG    Predictions: ['\" Bear\"[24941] (p=0.766, logit=21.375)', '\" Among\"[22395] (p=0.071, logit=19.000)', '\" The\"[578] (p=0.063, logit=18.875)', '\" A\"[362] (p=0.038, logit=18.375)', '\" BE\"[7354] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:40:20 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b06c78a6-7043\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b06c78a6-7043\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Marker\", \",\", \" Willow\", \",\", \" Bro\", \"och\", \",\", \" Bear\", \",\", \" Tooth\", \"brush\", \",\", \" Baseball\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" animal\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.028712142258882523, 0.005574067588895559, 0.009543430991470814, 0.009217992424964905, 0.028015583753585815, 0.034994643181562424, 0.010122746229171753, 0.010026571340858936, 0.013982272706925869, 0.09551624953746796, 0.029273632913827896, 0.012401157058775425, 0.007490498013794422, 0.013359729200601578, 0.00847675185650587, 0.02265496924519539, 0.009042318910360336, 0.01091392245143652, 0.012599397450685501, 0.012516728602349758, 0.005108463112264872, 0.004050336312502623, 0.008205958642065525, 0.008714322932064533, 0.0831388309597969, 0.04981167986989021, 0.014300934970378876, 0.0718693658709526]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f8eb03295d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71509977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_one_task.task_name,\n",
    "    \"objects\",\n",
    "    # \"profession\",\n",
    "    # \"nationality\",\n",
    "    # \"landmarks\"\n",
    "    # \"rhymes\"\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 474\n",
    "start_from = 550\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_one_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_one_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(2, 6)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(\n",
    "            validation_samples_save_path,\n",
    "            f\"{len(validation_set) + start_from - 1:05d}.json\",\n",
    "        ),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f353375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:33 __main__ INFO     Found 1024 sample files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_one_task.task_name,\n",
    "    \"objects\",\n",
    "    # \"profession\",\n",
    "    # \"nationality\"\n",
    "    # \"landmarks\",\n",
    "    # \"rhymes\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "prefix = \"\"\n",
    "# prefix = \"Recall the nationality of these people:\\n\"\n",
    "# prefix = \"Recall which country these landmarks are located in:\\n\"\n",
    "# prefix = \"Think about how these words sound when you say them aloud:\\n\"\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    # cf_pair.patch_sample.default_option_style = \"bulleted\"\n",
    "    # cf_pair.clean_sample.default_option_style = \"bulleted\"\n",
    "\n",
    "    cf_pair.clean_sample.prompt_template = prefix + cf_pair.clean_sample.prompt_template\n",
    "    cf_pair.patch_sample.prompt_template = prefix + cf_pair.patch_sample.prompt_template\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca935a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options: Lettuce, Apartment, Pendant, Highlighter.\n",
      "Which among these objects mentioned above is a office supply?\n",
      "Answer: >>  Highlight\n",
      "Options: Ruler, Necklace, Cabinet, Refrigerator.\n",
      "Which among these objects mentioned above is a jewelry?\n",
      "Answer: >>  Necklace\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(432, ' R')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0064aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:37 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:40:37 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:40:37 src.selection.optimization INFO     Verifying head behavior...\n",
      "2025-09-16 09:40:37 src.selection.optimization INFO     Clean Sample >> Ans:  Tr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:41 src.selection.functional DEBUG    Generated full answer: \" Tractor.\n",
      "Explanation: A tractor is a vehicle, typically with large, heavy-duty wheels, used for pulling or operating machinery in agriculture or construction.\"\n",
      "2025-09-16 09:40:42 src.selection.functional DEBUG    Predictions: ['\" Tr\"[1183] (p=0.781, logit=22.000)', '\" The\"[578] (p=0.083, logit=19.750)', '\" A\"[362] (p=0.064, logit=19.500)', '\" Among\"[22395] (p=0.034, logit=18.875)', '\"Tr\"[1305] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:40:42 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-4ef87b80-f10f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-4ef87b80-f10f\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Watch\", \",\", \" Drum\", \",\", \" Elm\", \",\", \" Sk\", \"irt\", \",\", \" Tr\", \"actor\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" vehicle\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.031240016222000122, 0.0078618498519063, 0.004555136896669865, 0.004912193864583969, 0.0075360992923378944, 0.014196678064763546, 0.008785989135503769, 0.017278388142585754, 0.011105078272521496, 0.006795603781938553, 0.009310075081884861, 0.010108229704201221, 0.1126289814710617, 0.03852495551109314, 0.007529125548899174, 0.011461891233921051, 0.012487799860537052, 0.0155728654935956, 0.007300190161913633, 0.005999102257192135, 0.008402053266763687, 0.014993596822023392, 0.07659950107336044, 0.04251788556575775, 0.022784696891903877, 0.06667648255825043]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f6e04359c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:42 src.selection.optimization INFO     Patch Sample >> Ans:  Sax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:46 src.selection.functional DEBUG    Generated full answer: \" Saxophone. It is a musical instrument. The rest of the options are not musical instruments. A bus is a vehicle, a tennis ball is a\"\n",
      "2025-09-16 09:40:46 src.selection.functional DEBUG    Predictions: ['\" Sax\"[68027] (p=0.523, logit=20.875)', '\" The\"[578] (p=0.279, logit=20.250)', '\" A\"[362] (p=0.071, logit=18.875)', '\" Among\"[22395] (p=0.062, logit=18.750)', '\" It\"[1102] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:40:46 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-a8788974-fd19\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-a8788974-fd19\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Sax\", \"ophone\", \",\", \" Bus\", \",\", \" Tennis\", \" ball\", \",\", \" Swe\", \"ater\", \",\", \" Tow\", \"el\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" music\", \" instrument\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.03275883197784424, 0.007808343973010778, 0.047066476196050644, 0.051730308681726456, 0.026105526834726334, 0.005312224850058556, 0.013781418092548847, 0.003320923540741205, 0.005433530081063509, 0.012484162114560604, 0.004793225787580013, 0.005106366705149412, 0.005768187344074249, 0.004579196684062481, 0.003223264589905739, 0.02131311409175396, 0.01082285400480032, 0.01437256671488285, 0.012507391162216663, 0.011872727423906326, 0.009364325553178787, 0.005874380469322205, 0.010257694870233536, 0.012378904968500137, 0.01931178756058216, 0.05116333067417145, 0.05139688774943352, 0.024430062621831894, 0.06828289479017258]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f8eb036e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:40:46 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.523, logit=20.875)', '\" The\"[578] (p=0.279, logit=20.250)', '\" A\"[362] (p=0.071, logit=18.875)', '\" Among\"[22395] (p=0.062, logit=18.750)', '\" It\"[1102] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:40:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:40:46 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.781, logit=22.000)', '\" The\"[578] (p=0.083, logit=19.750)', '\" A\"[362] (p=0.064, logit=19.500)', '\" Among\"[22395] (p=0.034, logit=18.875)', '\" It\"[1102] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:40:46 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.78125, logit=22.0, token_id=1183, metadata=None))), (4923, (53, PredictedToken(token=' Sk', prob=9.059906005859375e-05, logit=12.9375, token_id=4923, metadata=None))), (10573, (64, PredictedToken(token=' Watch', prob=5.841255187988281e-05, logit=12.5, token_id=10573, metadata=None))), (46506, (271, PredictedToken(token=' Drum', prob=2.562999725341797e-06, logit=9.375, token_id=46506, metadata=None))), (65329, (300, PredictedToken(token=' Elm', prob=2.130866050720215e-06, logit=9.1875, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:40:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:40:47 src.selection.functional DEBUG    Predictions: ['\" Watch\"[10573] (p=0.539, logit=20.750)', '\" Elm\"[65329] (p=0.175, logit=19.625)', '\" The\"[578] (p=0.094, logit=19.000)', '\" Among\"[22395] (p=0.057, logit=18.500)', '\" None\"[2290] (p=0.039, logit=18.125)']\n",
      "2025-09-16 09:40:47 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cd2af72a-e4c1\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cd2af72a-e4c1\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Watch\", \",\", \" Drum\", \",\", \" Elm\", \",\", \" Sk\", \"irt\", \",\", \" Tr\", \"actor\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" a\", \" vehicle\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.0391438789665699, 0.008349371142685413, 0.006189734674990177, 0.006907951552420855, 0.022460443899035454, 0.028077702969312668, 0.010993321426212788, 0.023063024505972862, 0.007909280247986317, 0.005489890929311514, 0.009750084020197392, 0.007938961498439312, 0.00783196184784174, 0.030735062435269356, 0.013260425999760628, 0.016080161556601524, 0.014972592703998089, 0.015974916517734528, 0.010493425652384758, 0.006958284415304661, 0.011392079293727875, 0.01458361092954874, 0.027110841125249863, 0.038726575672626495, 0.027424883097410202, 0.04127800464630127]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f8eb0400f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:40:47 src.selection.optimization INFO     int_prediction=['\" Watch\"[10573] (p=0.539, logit=20.750)', '\" Elm\"[65329] (p=0.175, logit=19.625)', '\" The\"[578] (p=0.094, logit=19.000)', '\" Among\"[22395] (p=0.057, logit=18.500)', '\" None\"[2290] (p=0.039, logit=18.125)']\n",
      "2025-09-16 09:40:47 src.selection.optimization INFO     int_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.5390625, logit=20.75, token_id=10573, metadata=None))), (65329, (2, PredictedToken(token=' Elm', prob=0.1748046875, logit=19.625, token_id=65329, metadata=None))), (46506, (8, PredictedToken(token=' Drum', prob=0.005279541015625, logit=16.125, token_id=46506, metadata=None))), (4923, (39, PredictedToken(token=' Sk', prob=0.0003833770751953125, logit=13.5, token_id=4923, metadata=None))), (1183, (353, PredictedToken(token=' Tr', prob=4.26173210144043e-06, logit=9.0, token_id=1183, metadata=None)))])\n",
      "2025-09-16 09:40:47 __main__ DEBUG    clean obj:  Tr\n",
      "2025-09-16 09:40:47 __main__ DEBUG    target obj:  Drum\n",
      "2025-09-16 09:40:47 __main__ INFO     Clean Prediction Rank Change: 1 -> 353 | Delta: 352 \n",
      "2025-09-16 09:40:47 __main__ INFO     Target Prediction Rank Change: 271 -> 8 | Delta: -263 \n",
      "2025-09-16 09:40:47 __main__ INFO     Clean Prediction Logit Change: 22.0000 -> 9.0000 | Delta: -13.0000 \n",
      "2025-09-16 09:40:47 __main__ INFO     Target Prediction Logit Change: 9.3750 -> 16.1250 | Delta: 6.7500 \n"
     ]
    }
   ],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "import copy\n",
    "\n",
    "clean, patch = copy.deepcopy(validation_set[5])\n",
    "# failed_case = failed_pos_track[\"patch_obj_idx\"][5]\n",
    "# clean = failed_case[\"clean_sample\"]\n",
    "# patch = failed_case[\"patch_sample\"]\n",
    "# clean.default_option_style=\"numbered\"\n",
    "# patch.default_option_style=\"numbered\"\n",
    "\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    "    patch_args={\n",
    "        \"batch_size\": len(patch.options),\n",
    "        \"distinct_options\": False,\n",
    "        # \"task\": select_task,\n",
    "        # \"prompt_template_idx\": prompt_template_idx,\n",
    "        # \"option_style\": patch.default_option_style,\n",
    "        # \"n_distractors\": N_DISTRACTORS,\n",
    "    },\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f130d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bce44ad2b24f139e966bdae90f8d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-16 09:41:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:06 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.941, logit=23.875)', '\" The\"[578] (p=0.022, logit=20.125)', '\" A\"[362] (p=0.022, logit=20.125)', '\" Among\"[22395] (p=0.007, logit=19.000)', '\" motorcycle\"[35404] (p=0.001, logit=17.000)']\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.691, logit=22.125)', '\" An\"[1556] (p=0.136, logit=20.500)', '\" The\"[578] (p=0.073, logit=19.875)', '\" e\"[384] (p=0.039, logit=19.250)', '\" Among\"[22395] (p=0.030, logit=19.000)']\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.69140625, logit=22.125, token_id=469, metadata=None))), (74574, (7, PredictedToken(token=' Violet', prob=0.0036163330078125, logit=16.875, token_id=74574, metadata=None))), (63606, (14, PredictedToken(token=' Stap', prob=0.0011749267578125, logit=15.75, token_id=63606, metadata=None))), (91782, (258, PredictedToken(token=' Shorts', prob=2.4139881134033203e-06, logit=9.5625, token_id=91782, metadata=None))), (34785, (316, PredictedToken(token=' Truck', prob=1.55717134475708e-06, logit=9.125, token_id=34785, metadata=None)))])\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     int_prediction=['\" Shorts\"[91782] (p=0.293, logit=19.500)', '\" Truck\"[34785] (p=0.229, logit=19.250)', '\" Among\"[22395] (p=0.157, logit=18.875)', '\" The\"[578] (p=0.157, logit=18.875)', '\" Short\"[10928] (p=0.024, logit=17.000)']\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     int_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.29296875, logit=19.5, token_id=91782, metadata=None))), (34785, (2, PredictedToken(token=' Truck', prob=0.228515625, logit=19.25, token_id=34785, metadata=None))), (469, (144, PredictedToken(token=' E', prob=4.100799560546875e-05, logit=10.625, token_id=469, metadata=None))), (63606, (163, PredictedToken(token=' Stap', prob=3.0040740966796875e-05, logit=10.3125, token_id=63606, metadata=None))), (74574, (622, PredictedToken(token=' Violet', prob=3.591179847717285e-06, logit=8.1875, token_id=74574, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:06 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:41:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.844, logit=21.500)', '\" The\"[578] (p=0.054, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" A\"[362] (p=0.020, logit=17.750)', '\" Project\"[5907] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     clean_prediction=['\" Hair\"[26781] (p=0.855, logit=21.750)', '\" The\"[578] (p=0.048, logit=18.875)', '\" A\"[362] (p=0.033, logit=18.500)', '\" Among\"[22395] (p=0.023, logit=18.125)', '\" hair\"[7013] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     clean_track=OrderedDict([(26781, (1, PredictedToken(token=' Hair', prob=0.85546875, logit=21.75, token_id=26781, metadata=None))), (5340, (6, PredictedToken(token=' Har', prob=0.005096435546875, logit=16.625, token_id=5340, metadata=None))), (43950, (35, PredictedToken(token=' Lav', prob=0.00023746490478515625, logit=13.5625, token_id=43950, metadata=None))), (22725, (131, PredictedToken(token=' Orange', prob=1.519918441772461e-05, logit=10.8125, token_id=22725, metadata=None))), (61948, (134, PredictedToken(token=' Sofa', prob=1.430511474609375e-05, logit=10.75, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     int_prediction=['\" Lav\"[43950] (p=0.375, logit=19.000)', '\" Option\"[7104] (p=0.156, logit=18.125)', '\" Among\"[22395] (p=0.138, logit=18.000)', '\" The\"[578] (p=0.122, logit=17.875)', '\" Only\"[8442] (p=0.024, logit=16.250)']\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     int_track=OrderedDict([(43950, (1, PredictedToken(token=' Lav', prob=0.375, logit=19.0, token_id=43950, metadata=None))), (61948, (9, PredictedToken(token=' Sofa', prob=0.0128173828125, logit=15.625, token_id=61948, metadata=None))), (22725, (12, PredictedToken(token=' Orange', prob=0.00933837890625, logit=15.3125, token_id=22725, metadata=None))), (26781, (542, PredictedToken(token=' Hair', prob=5.692243576049805e-06, logit=7.90625, token_id=26781, metadata=None))), (5340, (1575, PredictedToken(token=' Har', prob=1.2665987014770508e-06, logit=6.40625, token_id=5340, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:07 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.797, logit=21.125)', '\" A\"[362] (p=0.074, logit=18.750)', '\" The\"[578] (p=0.045, logit=18.250)', '\" Among\"[22395] (p=0.027, logit=17.750)', '\" None\"[2290] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.762, logit=22.500)', '\" The\"[578] (p=0.091, logit=20.375)', '\" A\"[362] (p=0.091, logit=20.375)', '\" Among\"[22395] (p=0.026, logit=19.125)', '\" \"[220] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.76171875, logit=22.5, token_id=1901, metadata=None))), (16488, (11, PredictedToken(token=' Bat', prob=0.000949859619140625, logit=15.8125, token_id=16488, metadata=None))), (3804, (37, PredictedToken(token=' Sub', prob=9.393692016601562e-05, logit=13.5, token_id=3804, metadata=None))), (26781, (42, PredictedToken(token=' Hair', prob=7.772445678710938e-05, logit=13.3125, token_id=26781, metadata=None))), (88668, (2234, PredictedToken(token=' Blender', prob=5.8906152844429016e-08, logit=6.125, token_id=88668, metadata=None)))])\n",
      "2025-09-16 09:41:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     int_prediction=['\" Hair\"[26781] (p=0.801, logit=22.125)', '\" The\"[578] (p=0.084, logit=19.875)', '\" A\"[362] (p=0.035, logit=19.000)', '\" Bat\"[16488] (p=0.024, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=18.500)']\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     int_track=OrderedDict([(26781, (1, PredictedToken(token=' Hair', prob=0.80078125, logit=22.125, token_id=26781, metadata=None))), (16488, (4, PredictedToken(token=' Bat', prob=0.024169921875, logit=18.625, token_id=16488, metadata=None))), (88668, (11, PredictedToken(token=' Blender', prob=0.001129150390625, logit=15.5625, token_id=88668, metadata=None))), (3804, (160, PredictedToken(token=' Sub', prob=7.152557373046875e-06, logit=10.5, token_id=3804, metadata=None))), (1901, (308, PredictedToken(token=' Z', prob=2.0563602447509766e-06, logit=9.25, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:08 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.816, logit=21.625)', '\" The\"[578] (p=0.067, logit=19.125)', '\" Among\"[22395] (p=0.052, logit=18.875)', '\" A\"[362] (p=0.025, logit=18.125)', '\" It\"[1102] (p=0.003, logit=16.125)']\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.801, logit=22.125)', '\" A\"[362] (p=0.074, logit=19.750)', '\" The\"[578] (p=0.058, logit=19.500)', '\" Among\"[22395] (p=0.027, logit=18.750)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.80078125, logit=22.125, token_id=86460, metadata=None))), (432, (18, PredictedToken(token=' R', prob=0.000568389892578125, logit=14.875, token_id=432, metadata=None))), (34046, (263, PredictedToken(token=' Cabinet', prob=2.9802322387695312e-06, logit=9.625, token_id=34046, metadata=None))), (75258, (345, PredictedToken(token=' Refriger', prob=1.8104910850524902e-06, logit=9.125, token_id=75258, metadata=None)))])\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.465, logit=19.000)', '\" Among\"[22395] (p=0.133, logit=17.750)', '\" None\"[2290] (p=0.091, logit=17.375)', '\" The\"[578] (p=0.091, logit=17.375)', '\" Option\"[7104] (p=0.063, logit=17.000)']\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.46484375, logit=19.0, token_id=432, metadata=None))), (86460, (77, PredictedToken(token=' Necklace', prob=0.00015544891357421875, logit=11.0, token_id=86460, metadata=None))), (34046, (122, PredictedToken(token=' Cabinet', prob=6.103515625e-05, logit=10.0625, token_id=34046, metadata=None))), (75258, (538, PredictedToken(token=' Refriger', prob=4.857778549194336e-06, logit=7.53125, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:08 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.730, logit=20.875)', '\" The\"[578] (p=0.087, logit=18.750)', '\" A\"[362] (p=0.087, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.000)', '\" stap\"[36114] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.754, logit=20.875)', '\" Among\"[22395] (p=0.070, logit=18.500)', '\" The\"[578] (p=0.070, logit=18.500)', '\" A\"[362] (p=0.038, logit=17.875)', '\" MAP\"[28322] (p=0.007, logit=16.250)']\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.75390625, logit=20.875, token_id=44570, metadata=None))), (79189, (7, PredictedToken(token=' Elephant', prob=0.00506591796875, logit=15.875, token_id=79189, metadata=None))), (1443, (145, PredictedToken(token=' Sh', prob=2.205371856689453e-05, logit=10.4375, token_id=1443, metadata=None))), (2522, (344, PredictedToken(token=' Sc', prob=4.6193599700927734e-06, logit=8.875, token_id=2522, metadata=None))), (18654, (704, PredictedToken(token=' Micro', prob=1.646578311920166e-06, logit=7.84375, token_id=18654, metadata=None))), (12369, (1343, PredictedToken(token=' Food', prob=6.668269634246826e-07, logit=6.9375, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     int_prediction=['\" Sc\"[2522] (p=0.895, logit=21.875)', '\" Among\"[22395] (p=0.031, logit=18.500)', '\" The\"[578] (p=0.031, logit=18.500)', '\" Micro\"[18654] (p=0.008, logit=17.125)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     int_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.89453125, logit=21.875, token_id=2522, metadata=None))), (18654, (4, PredictedToken(token=' Micro', prob=0.007720947265625, logit=17.125, token_id=18654, metadata=None))), (1443, (6, PredictedToken(token=' Sh', prob=0.0036468505859375, logit=16.375, token_id=1443, metadata=None))), (12369, (17, PredictedToken(token=' Food', prob=0.000766754150390625, logit=14.8125, token_id=12369, metadata=None))), (79189, (86, PredictedToken(token=' Elephant', prob=2.968311309814453e-05, logit=11.5625, token_id=79189, metadata=None))), (44570, (455, PredictedToken(token=' Maple', prob=1.1473894119262695e-06, logit=8.3125, token_id=44570, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:09 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.523, logit=20.875)', '\" The\"[578] (p=0.279, logit=20.250)', '\" A\"[362] (p=0.071, logit=18.875)', '\" Among\"[22395] (p=0.062, logit=18.750)', '\" It\"[1102] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:41:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.781, logit=22.000)', '\" The\"[578] (p=0.083, logit=19.750)', '\" A\"[362] (p=0.064, logit=19.500)', '\" Among\"[22395] (p=0.034, logit=18.875)', '\" It\"[1102] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.78125, logit=22.0, token_id=1183, metadata=None))), (4923, (53, PredictedToken(token=' Sk', prob=9.059906005859375e-05, logit=12.9375, token_id=4923, metadata=None))), (10573, (64, PredictedToken(token=' Watch', prob=5.841255187988281e-05, logit=12.5, token_id=10573, metadata=None))), (46506, (271, PredictedToken(token=' Drum', prob=2.562999725341797e-06, logit=9.375, token_id=46506, metadata=None))), (65329, (300, PredictedToken(token=' Elm', prob=2.130866050720215e-06, logit=9.1875, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     int_prediction=['\" Watch\"[10573] (p=0.539, logit=20.750)', '\" Elm\"[65329] (p=0.175, logit=19.625)', '\" The\"[578] (p=0.094, logit=19.000)', '\" Among\"[22395] (p=0.057, logit=18.500)', '\" None\"[2290] (p=0.039, logit=18.125)']\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     int_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.5390625, logit=20.75, token_id=10573, metadata=None))), (65329, (2, PredictedToken(token=' Elm', prob=0.1748046875, logit=19.625, token_id=65329, metadata=None))), (46506, (8, PredictedToken(token=' Drum', prob=0.005279541015625, logit=16.125, token_id=46506, metadata=None))), (4923, (39, PredictedToken(token=' Sk', prob=0.0003833770751953125, logit=13.5, token_id=4923, metadata=None))), (1183, (353, PredictedToken(token=' Tr', prob=4.26173210144043e-06, logit=9.0, token_id=1183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:10 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:10 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     patch_prediction=['\" Camera\"[14669] (p=0.777, logit=21.000)', '\" The\"[578] (p=0.072, logit=18.625)', '\" Among\"[22395] (p=0.039, logit=18.000)', '\" A\"[362] (p=0.016, logit=17.125)', '\" It\"[1102] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.750, logit=22.000)', '\" The\"[578] (p=0.115, logit=20.125)', '\" A\"[362] (p=0.037, logit=19.000)', '\" It\"[1102] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.023, logit=18.500)']\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.75, logit=22.0, token_id=356, metadata=None))), (23126, (76, PredictedToken(token=' Ti', prob=3.1948089599609375e-05, logit=11.9375, token_id=23126, metadata=None))), (30173, (80, PredictedToken(token=' Speaker', prob=3.0040740966796875e-05, logit=11.875, token_id=30173, metadata=None))), (2522, (112, PredictedToken(token=' Sc', prob=1.5079975128173828e-05, logit=11.1875, token_id=2522, metadata=None)))])\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     int_prediction=['\" Speaker\"[30173] (p=0.719, logit=21.500)', '\" The\"[578] (p=0.125, logit=19.750)', '\" Among\"[22395] (p=0.059, logit=19.000)', '\" A\"[362] (p=0.025, logit=18.125)', '\" It\"[1102] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     int_track=OrderedDict([(30173, (1, PredictedToken(token=' Speaker', prob=0.71875, logit=21.5, token_id=30173, metadata=None))), (356, (14, PredictedToken(token=' C', prob=0.0015716552734375, logit=15.375, token_id=356, metadata=None))), (2522, (29, PredictedToken(token=' Sc', prob=0.000743865966796875, logit=14.625, token_id=2522, metadata=None))), (23126, (84, PredictedToken(token=' Ti', prob=4.744529724121094e-05, logit=11.875, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:10 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.801, logit=22.250)', '\" An\"[1556] (p=0.075, logit=19.875)', '\" The\"[578] (p=0.058, logit=19.625)', '\" Among\"[22395] (p=0.035, logit=19.125)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     clean_prediction=['\" Swe\"[37326] (p=0.672, logit=22.375)', '\" The\"[578] (p=0.149, logit=20.875)', '\" A\"[362] (p=0.091, logit=20.375)', '\" Among\"[22395] (p=0.062, logit=20.000)', '\" It\"[1102] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     clean_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.671875, logit=22.375, token_id=37326, metadata=None))), (27171, (76, PredictedToken(token=' Coffee', prob=3.039836883544922e-05, logit=12.375, token_id=27171, metadata=None))), (53889, (81, PredictedToken(token=' Apartment', prob=2.5272369384765625e-05, logit=12.1875, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.762, logit=22.750)', '\" The\"[578] (p=0.133, logit=21.000)', '\" Among\"[22395] (p=0.055, logit=20.125)', '\" It\"[1102] (p=0.012, logit=18.625)', '\" A\"[362] (p=0.008, logit=18.250)']\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.76171875, logit=22.75, token_id=27171, metadata=None))), (53889, (135, PredictedToken(token=' Apartment', prob=6.020069122314453e-06, logit=11.0, token_id=53889, metadata=None))), (37326, (1736, PredictedToken(token=' Swe', prob=9.452924132347107e-08, logit=6.84375, token_id=37326, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:11 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:11 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.707, logit=21.625)', '\" The\"[578] (p=0.139, logit=20.000)', '\" Among\"[22395] (p=0.074, logit=19.375)', '\" Pant\"[54222] (p=0.019, logit=18.000)', '\" A\"[362] (p=0.015, logit=17.750)']\n",
      "2025-09-16 09:41:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.883, logit=22.875)', '\" The\"[578] (p=0.044, logit=19.875)', '\" A\"[362] (p=0.030, logit=19.500)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" horse\"[15580] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.8828125, logit=22.875, token_id=34392, metadata=None))), (23126, (34, PredictedToken(token=' Ti', prob=0.0001583099365234375, logit=14.25, token_id=23126, metadata=None))), (68867, (96, PredictedToken(token=' Coat', prob=1.2218952178955078e-05, logit=11.6875, token_id=68867, metadata=None)))])\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     int_prediction=['\" Ti\"[23126] (p=0.617, logit=21.750)', '\" Coat\"[68867] (p=0.258, logit=20.875)', '\" The\"[578] (p=0.040, logit=19.000)', '\" Among\"[22395] (p=0.027, logit=18.625)', '\" None\"[2290] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     int_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.6171875, logit=21.75, token_id=23126, metadata=None))), (68867, (2, PredictedToken(token=' Coat', prob=0.2578125, logit=20.875, token_id=68867, metadata=None))), (34392, (147, PredictedToken(token=' Horse', prob=8.58306884765625e-06, logit=10.5625, token_id=34392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:12 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:12 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.723, logit=21.750)', '\" The\"[578] (p=0.126, logit=20.000)', '\" Among\"[22395] (p=0.067, logit=19.375)', '\" (\"[320] (p=0.025, logit=18.375)', '\" A\"[362] (p=0.013, logit=17.750)']\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     clean_prediction=['\" Eagle\"[36895] (p=0.809, logit=21.500)', '\" Among\"[22395] (p=0.040, logit=18.500)', '\" The\"[578] (p=0.040, logit=18.500)', '\" An\"[1556] (p=0.036, logit=18.375)', '\" (\"[320] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     clean_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.80859375, logit=21.5, token_id=36895, metadata=None))), (8219, (49, PredictedToken(token=' Sun', prob=0.00011301040649414062, logit=12.625, token_id=8219, metadata=None))), (78703, (162, PredictedToken(token=' Potato', prob=9.894371032714844e-06, logit=10.1875, token_id=78703, metadata=None)))])\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.605, logit=21.000)', '\" None\"[2290] (p=0.223, logit=20.000)', '\" Among\"[22395] (p=0.064, logit=18.750)', '\" The\"[578] (p=0.027, logit=17.875)', '\" none\"[7000] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.60546875, logit=21.0, token_id=8219, metadata=None))), (78703, (39, PredictedToken(token=' Potato', prob=0.000278472900390625, logit=13.3125, token_id=78703, metadata=None))), (36895, (821, PredictedToken(token=' Eagle', prob=9.126961231231689e-07, logit=7.59375, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:12 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-16 09:41:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.785, logit=21.000)', '\" The\"[578] (p=0.083, logit=18.750)', '\" Among\"[22395] (p=0.034, logit=17.875)', '\" A\"[362] (p=0.014, logit=17.000)', '\" l\"[326] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.707, logit=21.125)', '\" The\"[578] (p=0.108, logit=19.250)', '\" Among\"[22395] (p=0.051, logit=18.500)', '\" A\"[362] (p=0.051, logit=18.500)', '\" D\"[423] (p=0.017, logit=17.375)']\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.70703125, logit=21.125, token_id=3816, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.0166015625, logit=17.375, token_id=423, metadata=None))), (34954, (34, PredictedToken(token=' Mirror', prob=0.000324249267578125, logit=13.4375, token_id=34954, metadata=None))), (19176, (40, PredictedToken(token=' Temple', prob=0.0002689361572265625, logit=13.25, token_id=19176, metadata=None))), (1183, (53, PredictedToken(token=' Tr', prob=0.00014400482177734375, logit=12.625, token_id=1183, metadata=None)))])\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.068, logit=19.375)', '\" Among\"[22395] (p=0.029, logit=18.500)', '\" d\"[294] (p=0.013, logit=17.750)', '\" A\"[362] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.8359375, logit=21.875, token_id=423, metadata=None))), (34954, (6, PredictedToken(token=' Mirror', prob=0.00927734375, logit=17.375, token_id=34954, metadata=None))), (19176, (42, PredictedToken(token=' Temple', prob=0.00011682510375976562, logit=13.0, token_id=19176, metadata=None))), (1183, (39, PredictedToken(token=' Tr', prob=0.00011682510375976562, logit=13.0, token_id=1183, metadata=None))), (3816, (269, PredictedToken(token=' Red', prob=2.2798776626586914e-06, logit=9.0625, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:13 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:13 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.762, logit=20.375)', '\" None\"[2290] (p=0.080, logit=18.125)', '\" The\"[578] (p=0.043, logit=17.500)', '\" Sax\"[68027] (p=0.018, logit=16.625)', '\" Horse\"[34392] (p=0.016, logit=16.500)']\n",
      "2025-09-16 09:41:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.742, logit=22.250)', '\" The\"[578] (p=0.114, logit=20.375)', '\" A\"[362] (p=0.079, logit=20.000)', '\" Among\"[22395] (p=0.037, logit=19.250)', '\" It\"[1102] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.7421875, logit=22.25, token_id=86460, metadata=None))), (52882, (55, PredictedToken(token=' Pepper', prob=4.9114227294921875e-05, logit=12.625, token_id=52882, metadata=None))), (34392, (75, PredictedToken(token=' Horse', prob=3.170967102050781e-05, logit=12.1875, token_id=34392, metadata=None))), (24423, (157, PredictedToken(token=' Monitor', prob=6.258487701416016e-06, logit=10.5625, token_id=24423, metadata=None))), (97796, (424, PredictedToken(token=' Skate', prob=1.1548399925231934e-06, logit=8.875, token_id=97796, metadata=None))), (68027, (806, PredictedToken(token=' Sax', prob=4.5262277126312256e-07, logit=7.9375, token_id=68027, metadata=None)))])\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.574, logit=21.000)', '\" The\"[578] (p=0.212, logit=20.000)', '\" A\"[362] (p=0.088, logit=19.125)', '\" Among\"[22395] (p=0.047, logit=18.500)', '\" Sax\"[68027] (p=0.017, logit=17.500)']\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.57421875, logit=21.0, token_id=97796, metadata=None))), (68027, (5, PredictedToken(token=' Sax', prob=0.017333984375, logit=17.5, token_id=68027, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.00439453125, logit=16.125, token_id=24423, metadata=None))), (34392, (13, PredictedToken(token=' Horse', prob=0.00171661376953125, logit=15.1875, token_id=34392, metadata=None))), (52882, (69, PredictedToken(token=' Pepper', prob=9.72747802734375e-05, logit=12.3125, token_id=52882, metadata=None))), (86460, (298, PredictedToken(token=' Necklace', prob=4.827976226806641e-06, logit=9.3125, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:14 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:14 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.891, logit=21.875)', '\" The\"[578] (p=0.039, logit=18.750)', '\" None\"[2290] (p=0.027, logit=18.375)', '\" A\"[362] (p=0.007, logit=17.000)', '\" Tow\"[41493] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.777, logit=21.125)', '\" The\"[578] (p=0.082, logit=18.875)', '\" A\"[362] (p=0.064, logit=18.625)', '\" Note\"[7181] (p=0.011, logit=16.875)', '\" Among\"[22395] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.77734375, logit=21.125, token_id=69755, metadata=None))), (8868, (36, PredictedToken(token=' Blue', prob=0.0003566741943359375, logit=13.4375, token_id=8868, metadata=None))), (1901, (55, PredictedToken(token=' Z', prob=0.0001316070556640625, logit=12.4375, token_id=1901, metadata=None)))])\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.766, logit=22.125)', '\" Z\"[1901] (p=0.133, logit=20.375)', '\" The\"[578] (p=0.055, logit=19.500)', '\" Among\"[22395] (p=0.008, logit=17.625)', '\" Only\"[8442] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.765625, logit=22.125, token_id=8868, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.1328125, logit=20.375, token_id=1901, metadata=None))), (69755, (150, PredictedToken(token=' Notebook', prob=8.761882781982422e-06, logit=10.75, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:14 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:14 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:41:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     patch_prediction=['\" Tennis\"[58251] (p=0.727, logit=20.875)', '\" The\"[578] (p=0.086, logit=18.750)', '\" A\"[362] (p=0.052, logit=18.250)', '\" Among\"[22395] (p=0.032, logit=17.750)', '\" Option\"[7104] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.812, logit=22.625)', '\" The\"[578] (p=0.076, logit=20.250)', '\" A\"[362] (p=0.059, logit=20.000)', '\" Among\"[22395] (p=0.031, logit=19.375)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.8125, logit=22.625, token_id=3341, metadata=None))), (57551, (83, PredictedToken(token=' Sink', prob=1.3589859008789062e-05, logit=11.625, token_id=57551, metadata=None))), (38673, (102, PredictedToken(token=' Yoga', prob=9.298324584960938e-06, logit=11.25, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     int_prediction=['\" Yoga\"[38673] (p=0.711, logit=20.750)', '\" Among\"[22395] (p=0.085, logit=18.625)', '\" The\"[578] (p=0.066, logit=18.375)', '\" Sink\"[57551] (p=0.028, logit=17.500)', '\" None\"[2290] (p=0.028, logit=17.500)']\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     int_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.7109375, logit=20.75, token_id=38673, metadata=None))), (57551, (5, PredictedToken(token=' Sink', prob=0.027587890625, logit=17.5, token_id=57551, metadata=None))), (3341, (90, PredictedToken(token=' Car', prob=4.410743713378906e-05, logit=11.0625, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:15 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:15 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.523, logit=20.875)', '\" Pine\"[42609] (p=0.279, logit=20.250)', '\" Among\"[22395] (p=0.062, logit=18.750)', '\" The\"[578] (p=0.055, logit=18.625)', '\" (\"[320] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     clean_prediction=['\" Dolphin\"[96096] (p=0.902, logit=21.875)', '\" The\"[578] (p=0.031, logit=18.500)', '\" Among\"[22395] (p=0.019, logit=18.000)', '\" A\"[362] (p=0.011, logit=17.500)', '\" dolphin\"[99269] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     clean_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.90234375, logit=21.875, token_id=96096, metadata=None))), (19176, (15, PredictedToken(token=' Temple', prob=0.00072479248046875, logit=14.75, token_id=19176, metadata=None))), (84409, (103, PredictedToken(token=' Plum', prob=1.823902130126953e-05, logit=11.0625, token_id=84409, metadata=None))), (67629, (190, PredictedToken(token=' Helmet', prob=5.543231964111328e-06, logit=9.875, token_id=67629, metadata=None)))])\n",
      "2025-09-16 09:41:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.828, logit=21.375)', '\" The\"[578] (p=0.047, logit=18.500)', '\" Among\"[22395] (p=0.041, logit=18.375)', '\" Option\"[7104] (p=0.022, logit=17.750)', '\" plum\"[42272] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.828125, logit=21.375, token_id=84409, metadata=None))), (19176, (25, PredictedToken(token=' Temple', prob=0.00070953369140625, logit=14.3125, token_id=19176, metadata=None))), (96096, (85, PredictedToken(token=' Dolphin', prob=4.00543212890625e-05, logit=11.4375, token_id=96096, metadata=None))), (67629, (167, PredictedToken(token=' Helmet', prob=1.150369644165039e-05, logit=10.1875, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:16 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.871, logit=23.000)', '\" A\"[362] (p=0.049, logit=20.125)', '\" The\"[578] (p=0.043, logit=20.000)', '\" Among\"[22395] (p=0.018, logit=19.125)', '\" Option\"[7104] (p=0.002, logit=17.125)']\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     clean_prediction=['\" Elm\"[65329] (p=0.785, logit=21.125)', '\" Among\"[22395] (p=0.064, logit=18.625)', '\" The\"[578] (p=0.064, logit=18.625)', '\" An\"[1556] (p=0.027, logit=17.750)', '\" E\"[469] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     clean_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.78515625, logit=21.125, token_id=65329, metadata=None))), (38571, (39, PredictedToken(token=' Theater', prob=0.0001811981201171875, logit=12.75, token_id=38571, metadata=None))), (9939, (227, PredictedToken(token=' Er', prob=7.4803829193115234e-06, logit=9.5625, token_id=9939, metadata=None))), (70306, (307, PredictedToken(token=' Brace', prob=4.5299530029296875e-06, logit=9.0625, token_id=70306, metadata=None))), (33199, (462, PredictedToken(token=' Lion', prob=2.2798776626586914e-06, logit=8.375, token_id=33199, metadata=None))), (74968, (3759, PredictedToken(token=' Razor', prob=1.601874828338623e-07, logit=5.71875, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.430, logit=20.000)', '\" Brace\"[70306] (p=0.180, logit=19.125)', '\" Among\"[22395] (p=0.158, logit=19.000)', '\" The\"[578] (p=0.123, logit=18.750)', '\" A\"[362] (p=0.027, logit=17.250)']\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.4296875, logit=20.0, token_id=38571, metadata=None))), (70306, (2, PredictedToken(token=' Brace', prob=0.1796875, logit=19.125, token_id=70306, metadata=None))), (65329, (126, PredictedToken(token=' Elm', prob=3.647804260253906e-05, logit=10.625, token_id=65329, metadata=None))), (74968, (335, PredictedToken(token=' Razor', prob=6.3478946685791016e-06, logit=8.875, token_id=74968, metadata=None))), (9939, (814, PredictedToken(token=' Er', prob=2.0563602447509766e-06, logit=7.75, token_id=9939, metadata=None))), (33199, (1938, PredictedToken(token=' Lion', prob=6.891787052154541e-07, logit=6.65625, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:16 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:41:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.490, logit=20.750)', '\" Bat\"[16488] (p=0.262, logit=20.125)', '\" The\"[578] (p=0.085, logit=19.000)', '\" A\"[362] (p=0.052, logit=18.500)', '\" B\"[426] (p=0.022, logit=17.625)']\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     clean_prediction=['\" St\"[800] (p=0.781, logit=22.250)', '\" The\"[578] (p=0.073, logit=19.875)', '\" A\"[362] (p=0.064, logit=19.750)', '\" Among\"[22395] (p=0.050, logit=19.500)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     clean_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.78125, logit=22.25, token_id=800, metadata=None))), (34785, (38, PredictedToken(token=' Truck', prob=0.00010967254638671875, logit=13.375, token_id=34785, metadata=None))), (30558, (43, PredictedToken(token=' Ki', prob=9.059906005859375e-05, logit=13.1875, token_id=30558, metadata=None))), (58251, (124, PredictedToken(token=' Tennis', prob=9.59634780883789e-06, logit=10.9375, token_id=58251, metadata=None))), (44570, (128, PredictedToken(token=' Maple', prob=9.000301361083984e-06, logit=10.875, token_id=44570, metadata=None)))])\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.699, logit=20.875)', '\" The\"[578] (p=0.107, logit=19.000)', '\" Among\"[22395] (p=0.074, logit=18.625)', '\" Maple\"[44570] (p=0.031, logit=17.750)', '\" A\"[362] (p=0.021, logit=17.375)']\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.69921875, logit=20.875, token_id=58251, metadata=None))), (44570, (4, PredictedToken(token=' Maple', prob=0.0306396484375, logit=17.75, token_id=44570, metadata=None))), (34785, (8, PredictedToken(token=' Truck', prob=0.005340576171875, logit=16.0, token_id=34785, metadata=None))), (30558, (55, PredictedToken(token=' Ki', prob=0.00016117095947265625, logit=12.5, token_id=30558, metadata=None))), (800, (240, PredictedToken(token=' St', prob=7.539987564086914e-06, logit=9.4375, token_id=800, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:17 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:17 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     patch_prediction=['\" Brace\"[70306] (p=0.750, logit=21.750)', '\" The\"[578] (p=0.079, logit=19.500)', '\" A\"[362] (p=0.070, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.375)', '\" b\"[293] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:41:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     clean_prediction=['\" Cel\"[47643] (p=0.934, logit=22.875)', '\" Among\"[22395] (p=0.025, logit=19.250)', '\" The\"[578] (p=0.025, logit=19.250)', '\" None\"[2290] (p=0.002, logit=16.500)', '\" (\"[320] (p=0.001, logit=16.375)']\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     clean_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.93359375, logit=22.875, token_id=47643, metadata=None))), (68867, (276, PredictedToken(token=' Coat', prob=1.5422701835632324e-06, logit=9.5625, token_id=68867, metadata=None))), (81501, (356, PredictedToken(token=' Pendant', prob=9.98377799987793e-07, logit=9.125, token_id=81501, metadata=None)))])\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     int_prediction=['\" Pendant\"[81501] (p=0.934, logit=22.250)', '\" The\"[578] (p=0.019, logit=18.375)', '\" A\"[362] (p=0.015, logit=18.125)', '\" Among\"[22395] (p=0.013, logit=18.000)', '\" It\"[1102] (p=0.002, logit=16.250)']\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     int_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.93359375, logit=22.25, token_id=81501, metadata=None))), (68867, (9, PredictedToken(token=' Coat', prob=0.00109100341796875, logit=15.5, token_id=68867, metadata=None))), (47643, (3173, PredictedToken(token=' Cel', prob=8.42846930027008e-08, logit=6.03125, token_id=47643, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:18 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:18 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.715, logit=20.750)', '\" The\"[578] (p=0.085, logit=18.625)', '\" Among\"[22395] (p=0.075, logit=18.500)', '\" A\"[362] (p=0.046, logit=18.000)', '\" (\"[320] (p=0.006, logit=16.000)']\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.895, logit=22.125)', '\" The\"[578] (p=0.031, logit=18.750)', '\" None\"[2290] (p=0.019, logit=18.250)', '\" Train\"[27217] (p=0.019, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.750)']\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.89453125, logit=22.125, token_id=423, metadata=None))), (27217, (4, PredictedToken(token=' Train', prob=0.0185546875, logit=18.25, token_id=27217, metadata=None))), (328, (21, PredictedToken(token=' S', prob=0.000385284423828125, logit=14.375, token_id=328, metadata=None))), (13120, (86, PredictedToken(token=' Night', prob=2.4557113647460938e-05, logit=11.625, token_id=13120, metadata=None))), (61731, (108, PredictedToken(token=' Soap', prob=1.4901161193847656e-05, logit=11.125, token_id=61731, metadata=None))), (64695, (111, PredictedToken(token=' Peach', prob=1.3172626495361328e-05, logit=11.0, token_id=64695, metadata=None)))])\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.746, logit=21.125)', '\" None\"[2290] (p=0.146, logit=19.500)', '\" The\"[578] (p=0.029, logit=17.875)', '\" Among\"[22395] (p=0.020, logit=17.500)', '\" There\"[2684] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.74609375, logit=21.125, token_id=27217, metadata=None))), (13120, (7, PredictedToken(token=' Night', prob=0.003448486328125, logit=15.75, token_id=13120, metadata=None))), (423, (11, PredictedToken(token=' D', prob=0.0016326904296875, logit=15.0, token_id=423, metadata=None))), (328, (27, PredictedToken(token=' S', prob=0.00049591064453125, logit=13.8125, token_id=328, metadata=None))), (61731, (75, PredictedToken(token=' Soap', prob=5.936622619628906e-05, logit=11.6875, token_id=61731, metadata=None))), (64695, (120, PredictedToken(token=' Peach', prob=2.6345252990722656e-05, logit=10.875, token_id=64695, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:18 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:18 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:41:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     patch_prediction=['\" Mango\"[91963] (p=0.941, logit=22.500)', '\" The\"[578] (p=0.022, logit=18.750)', '\" Among\"[22395] (p=0.008, logit=17.750)', '\" Option\"[7104] (p=0.004, logit=17.125)', '\" (\"[320] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     clean_prediction=['\" Night\"[13120] (p=0.809, logit=22.750)', '\" A\"[362] (p=0.075, logit=20.375)', '\" The\"[578] (p=0.059, logit=20.125)', '\" Among\"[22395] (p=0.019, logit=19.000)', '\" night\"[3814] (p=0.012, logit=18.500)']\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     clean_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.80859375, logit=22.75, token_id=13120, metadata=None))), (5250, (35, PredictedToken(token=' Pe', prob=0.00010633468627929688, logit=13.8125, token_id=5250, metadata=None))), (84409, (95, PredictedToken(token=' Plum', prob=1.1205673217773438e-05, logit=11.5625, token_id=84409, metadata=None)))])\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.703, logit=21.750)', '\" Among\"[22395] (p=0.095, logit=19.750)', '\" The\"[578] (p=0.095, logit=19.750)', '\" Pe\"[5250] (p=0.031, logit=18.625)', '\" Option\"[7104] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.703125, logit=21.75, token_id=84409, metadata=None))), (5250, (4, PredictedToken(token=' Pe', prob=0.0308837890625, logit=18.625, token_id=5250, metadata=None))), (13120, (360, PredictedToken(token=' Night', prob=2.3096799850463867e-06, logit=9.125, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:19 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:19 src.selection.optimization DEBUG    torch.Size([3, 27])\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.887, logit=22.125)', '\" None\"[2290] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.024, logit=18.500)', '\" The\"[578] (p=0.024, logit=18.500)', '\" Among\"[22395] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:41:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.742, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" A\"[362] (p=0.061, logit=19.375)', '\" Among\"[22395] (p=0.015, logit=18.000)', '\" Option\"[7104] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.7421875, logit=21.875, token_id=1630, metadata=None))), (23262, (30, PredictedToken(token=' Comb', prob=0.000339508056640625, logit=14.1875, token_id=23262, metadata=None))), (32498, (44, PredictedToken(token=' Mall', prob=0.00014209747314453125, logit=13.3125, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     int_prediction=['\" Mall\"[32498] (p=0.883, logit=21.875)', '\" A\"[362] (p=0.034, logit=18.625)', '\" The\"[578] (p=0.027, logit=18.375)', '\" Among\"[22395] (p=0.008, logit=17.125)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     int_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.8828125, logit=21.875, token_id=32498, metadata=None))), (23262, (10, PredictedToken(token=' Comb', prob=0.0028076171875, logit=16.125, token_id=23262, metadata=None))), (1630, (204, PredictedToken(token=' X', prob=4.500150680541992e-06, logit=9.6875, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:20 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:20 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.875, logit=22.125)', '\" A\"[362] (p=0.039, logit=19.000)', '\" The\"[578] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.018, logit=18.250)', '\" submarine\"[58629] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.832, logit=22.375)', '\" A\"[362] (p=0.060, logit=19.750)', '\" The\"[578] (p=0.053, logit=19.625)', '\" Among\"[22395] (p=0.015, logit=18.375)', '\" F\"[435] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.83203125, logit=22.375, token_id=75258, metadata=None))), (1183, (60, PredictedToken(token=' Tr', prob=4.839897155761719e-05, logit=12.625, token_id=1183, metadata=None))), (23262, (78, PredictedToken(token=' Comb', prob=2.5987625122070312e-05, logit=12.0, token_id=23262, metadata=None)))])\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.844, logit=22.000)', '\" None\"[2290] (p=0.048, logit=19.125)', '\" The\"[578] (p=0.037, logit=18.875)', '\" Among\"[22395] (p=0.020, logit=18.250)', '\" (\"[320] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.84375, logit=22.0, token_id=1183, metadata=None))), (23262, (8, PredictedToken(token=' Comb', prob=0.00390625, logit=16.625, token_id=23262, metadata=None))), (75258, (69, PredictedToken(token=' Refriger', prob=3.600120544433594e-05, logit=11.9375, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:20 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:20 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:41:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.707, logit=21.500)', '\" The\"[578] (p=0.108, logit=19.625)', '\" Among\"[22395] (p=0.058, logit=19.000)', '\" A\"[362] (p=0.058, logit=19.000)', '\" Tr\"[1183] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.746, logit=20.875)', '\" The\"[578] (p=0.089, logit=18.750)', '\" Among\"[22395] (p=0.048, logit=18.125)', '\" A\"[362] (p=0.042, logit=18.000)', '\" GRA\"[65120] (p=0.016, logit=17.000)']\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.74609375, logit=20.875, token_id=80629, metadata=None))), (59825, (173, PredictedToken(token=' Tie', prob=1.4126300811767578e-05, logit=10.0, token_id=59825, metadata=None))), (56491, (224, PredictedToken(token=' Piano', prob=8.58306884765625e-06, logit=9.5, token_id=56491, metadata=None))), (34046, (281, PredictedToken(token=' Cabinet', prob=5.900859832763672e-06, logit=9.125, token_id=34046, metadata=None))), (6150, (303, PredictedToken(token=' School', prob=5.185604095458984e-06, logit=9.0, token_id=6150, metadata=None))), (87213, (354, PredictedToken(token=' Oven', prob=4.0531158447265625e-06, logit=8.75, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.766, logit=20.875)', '\" The\"[578] (p=0.063, logit=18.375)', '\" Among\"[22395] (p=0.055, logit=18.250)', '\" Cabinet\"[34046] (p=0.034, logit=17.750)', '\" A\"[362] (p=0.020, logit=17.250)']\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.765625, logit=20.875, token_id=59825, metadata=None))), (34046, (4, PredictedToken(token=' Cabinet', prob=0.03369140625, logit=17.75, token_id=34046, metadata=None))), (6150, (10, PredictedToken(token=' School', prob=0.002593994140625, logit=15.1875, token_id=6150, metadata=None))), (87213, (13, PredictedToken(token=' Oven', prob=0.00201416015625, logit=14.9375, token_id=87213, metadata=None))), (56491, (14, PredictedToken(token=' Piano', prob=0.00189971923828125, logit=14.875, token_id=56491, metadata=None))), (80629, (356, PredictedToken(token=' Grape', prob=3.6656856536865234e-06, logit=8.625, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:21 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.633, logit=21.625)', '\" The\"[578] (p=0.142, logit=20.125)', '\" A\"[362] (p=0.110, logit=19.875)', '\" Among\"[22395] (p=0.059, logit=19.250)', '\" It\"[1102] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:41:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     clean_prediction=['\" Carn\"[32749] (p=0.852, logit=22.500)', '\" The\"[578] (p=0.062, logit=19.875)', '\" A\"[362] (p=0.042, logit=19.500)', '\" Among\"[22395] (p=0.026, logit=19.000)', '\" C\"[356] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     clean_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.8515625, logit=22.5, token_id=32749, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.00347900390625, logit=17.0, token_id=356, metadata=None))), (27171, (137, PredictedToken(token=' Coffee', prob=4.9173831939697266e-06, logit=10.4375, token_id=27171, metadata=None))), (15429, (338, PredictedToken(token=' Hospital', prob=1.0281801223754883e-06, logit=8.875, token_id=15429, metadata=None))), (57551, (400, PredictedToken(token=' Sink', prob=8.009374141693115e-07, logit=8.625, token_id=57551, metadata=None)))])\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.730, logit=22.250)', '\" The\"[578] (p=0.127, logit=20.500)', '\" Among\"[22395] (p=0.041, logit=19.375)', '\" Coffee\"[27171] (p=0.022, logit=18.750)', '\" c\"[272] (p=0.022, logit=18.750)']\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.73046875, logit=22.25, token_id=356, metadata=None))), (27171, (5, PredictedToken(token=' Coffee', prob=0.0220947265625, logit=18.75, token_id=27171, metadata=None))), (57551, (102, PredictedToken(token=' Sink', prob=1.3887882232666016e-05, logit=11.375, token_id=57551, metadata=None))), (15429, (144, PredictedToken(token=' Hospital', prob=6.556510925292969e-06, logit=10.625, token_id=15429, metadata=None))), (32749, (974, PredictedToken(token=' Carn', prob=2.5331974029541016e-07, logit=7.375, token_id=32749, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:22 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.891, logit=22.125)', '\" A\"[362] (p=0.044, logit=19.125)', '\" The\"[578] (p=0.034, logit=18.875)', '\" Among\"[22395] (p=0.009, logit=17.500)', '\" MOS\"[74174] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     clean_prediction=['\" Calculator\"[37128] (p=0.566, logit=19.375)', '\" A\"[362] (p=0.126, logit=17.875)', '\" The\"[578] (p=0.111, logit=17.750)', '\" Among\"[22395] (p=0.053, logit=17.000)', '\" It\"[1102] (p=0.012, logit=15.500)']\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     clean_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.56640625, logit=19.375, token_id=37128, metadata=None))), (68027, (33, PredictedToken(token=' Sax', prob=0.00109100341796875, logit=13.125, token_id=68027, metadata=None))), (44570, (42, PredictedToken(token=' Maple', prob=0.00080108642578125, logit=12.8125, token_id=44570, metadata=None))), (66821, (82, PredictedToken(token=' Iris', prob=0.00018978118896484375, logit=11.375, token_id=66821, metadata=None))), (79189, (265, PredictedToken(token=' Elephant', prob=2.1338462829589844e-05, logit=9.1875, token_id=79189, metadata=None))), (16730, (316, PredictedToken(token=' Museum', prob=1.5616416931152344e-05, logit=8.875, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     int_prediction=['\" Maple\"[44570] (p=0.192, logit=18.000)', '\" Elephant\"[79189] (p=0.192, logit=18.000)', '\" Among\"[22395] (p=0.170, logit=17.875)', '\" Iris\"[66821] (p=0.150, logit=17.750)', '\" The\"[578] (p=0.071, logit=17.000)']\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     int_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.1923828125, logit=18.0, token_id=44570, metadata=None))), (79189, (2, PredictedToken(token=' Elephant', prob=0.1923828125, logit=18.0, token_id=79189, metadata=None))), (66821, (4, PredictedToken(token=' Iris', prob=0.150390625, logit=17.75, token_id=66821, metadata=None))), (16730, (43, PredictedToken(token=' Museum', prob=0.0008392333984375, logit=12.5625, token_id=16730, metadata=None))), (37128, (3280, PredictedToken(token=' Calculator', prob=6.556510925292969e-07, logit=5.40625, token_id=37128, metadata=None))), (68027, (4308, PredictedToken(token=' Sax', prob=4.3585896492004395e-07, logit=5.0, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:22 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     patch_prediction=['\" Baseball\"[38258] (p=0.680, logit=21.125)', '\" The\"[578] (p=0.151, logit=19.625)', '\" A\"[362] (p=0.063, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.625)', '\" It\"[1102] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     clean_prediction=['\" Potato\"[78703] (p=0.805, logit=21.875)', '\" The\"[578] (p=0.075, logit=19.500)', '\" Among\"[22395] (p=0.058, logit=19.250)', '\" A\"[362] (p=0.028, logit=18.500)', '\" POT\"[62602] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     clean_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.8046875, logit=21.875, token_id=78703, metadata=None))), (49431, (60, PredictedToken(token=' Rabbit', prob=6.818771362304688e-05, logit=12.5, token_id=49431, metadata=None))), (18343, (71, PredictedToken(token=' Paper', prob=4.410743713378906e-05, logit=12.0625, token_id=18343, metadata=None))), (4923, (82, PredictedToken(token=' Sk', prob=3.4332275390625e-05, logit=11.8125, token_id=4923, metadata=None))), (67629, (96, PredictedToken(token=' Helmet', prob=2.5153160095214844e-05, logit=11.5, token_id=67629, metadata=None))), (98641, (97, PredictedToken(token=' Microwave', prob=2.5153160095214844e-05, logit=11.5, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.379, logit=19.250)', '\" Among\"[22395] (p=0.140, logit=18.250)', '\" None\"[2290] (p=0.140, logit=18.250)', '\" Helmet\"[67629] (p=0.096, logit=17.875)', '\" The\"[578] (p=0.084, logit=17.750)']\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.37890625, logit=19.25, token_id=49431, metadata=None))), (67629, (4, PredictedToken(token=' Helmet', prob=0.095703125, logit=17.875, token_id=67629, metadata=None))), (4923, (6, PredictedToken(token=' Sk', prob=0.03515625, logit=16.875, token_id=4923, metadata=None))), (18343, (43, PredictedToken(token=' Paper', prob=0.000606536865234375, logit=12.8125, token_id=18343, metadata=None))), (78703, (74, PredictedToken(token=' Potato', prob=0.00023746490478515625, logit=11.875, token_id=78703, metadata=None))), (98641, (1152, PredictedToken(token=' Microwave', prob=2.115964889526367e-06, logit=7.15625, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:23 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:23 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:41:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.773, logit=22.125)', '\" A\"[362] (p=0.082, logit=19.875)', '\" The\"[578] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.039, logit=19.125)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.066, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=18.625)', '\" A\"[362] (p=0.021, logit=18.000)', '\" Option\"[7104] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.8046875, logit=21.625, token_id=24423, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.00164794921875, logit=15.4375, token_id=356, metadata=None))), (469, (17, PredictedToken(token=' E', prob=0.00128173828125, logit=15.1875, token_id=469, metadata=None))), (48665, (104, PredictedToken(token=' Raspberry', prob=3.0159950256347656e-05, logit=11.4375, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.621, logit=21.125)', '\" Raspberry\"[48665] (p=0.122, logit=19.500)', '\" The\"[578] (p=0.065, logit=18.875)', '\" An\"[1556] (p=0.058, logit=18.750)', '\" Among\"[22395] (p=0.040, logit=18.375)']\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.62109375, logit=21.125, token_id=469, metadata=None))), (48665, (2, PredictedToken(token=' Raspberry', prob=0.1220703125, logit=19.5, token_id=48665, metadata=None))), (356, (27, PredictedToken(token=' C', prob=0.00072479248046875, logit=14.375, token_id=356, metadata=None))), (24423, (200, PredictedToken(token=' Monitor', prob=8.046627044677734e-06, logit=9.875, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:24 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:24 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     patch_prediction=['\" Potato\"[78703] (p=0.844, logit=21.250)', '\" The\"[578] (p=0.048, logit=18.375)', '\" Among\"[22395] (p=0.025, logit=17.750)', '\" A\"[362] (p=0.020, logit=17.500)', '\" None\"[2290] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.840, logit=22.125)', '\" The\"[578] (p=0.069, logit=19.625)', '\" Among\"[22395] (p=0.037, logit=19.000)', '\" A\"[362] (p=0.025, logit=18.625)', '\" Option\"[7104] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.83984375, logit=22.125, token_id=42609, metadata=None))), (14642, (15, PredictedToken(token=' Phone', prob=0.000492095947265625, logit=14.6875, token_id=14642, metadata=None))), (41785, (66, PredictedToken(token=' Spin', prob=3.814697265625e-05, logit=12.125, token_id=41785, metadata=None))), (57094, (67, PredictedToken(token=' Highlight', prob=3.814697265625e-05, logit=12.125, token_id=57094, metadata=None)))])\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.852, logit=22.250)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" The\"[578] (p=0.037, logit=19.125)', '\" Highlight\"[57094] (p=0.026, logit=18.750)', '\" Phone\"[14642] (p=0.020, logit=18.500)']\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.8515625, logit=22.25, token_id=41785, metadata=None))), (57094, (4, PredictedToken(token=' Highlight', prob=0.0257568359375, logit=18.75, token_id=57094, metadata=None))), (14642, (5, PredictedToken(token=' Phone', prob=0.02001953125, logit=18.5, token_id=14642, metadata=None))), (42609, (74, PredictedToken(token=' Pine', prob=3.409385681152344e-05, logit=12.125, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:24 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:24 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.641, logit=22.500)', '\" An\"[1556] (p=0.143, logit=21.000)', '\" The\"[578] (p=0.143, logit=21.000)', '\" Among\"[22395] (p=0.028, logit=19.375)', '\" It\"[1102] (p=0.012, logit=18.500)']\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.859, logit=22.750)', '\" The\"[578] (p=0.055, logit=20.000)', '\" A\"[362] (p=0.043, logit=19.750)', '\" Among\"[22395] (p=0.016, logit=18.750)', '\" Option\"[7104] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.859375, logit=22.75, token_id=735, metadata=None))), (41785, (12, PredictedToken(token=' Spin', prob=0.0006103515625, logit=15.5, token_id=41785, metadata=None))), (70306, (51, PredictedToken(token=' Brace', prob=5.0067901611328125e-05, logit=13.0, token_id=70306, metadata=None)))])\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.852, logit=22.500)', '\" Brace\"[70306] (p=0.090, logit=20.250)', '\" The\"[578] (p=0.020, logit=18.750)', '\" Among\"[22395] (p=0.016, logit=18.500)', '\" (\"[320] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.8515625, logit=22.5, token_id=41785, metadata=None))), (70306, (2, PredictedToken(token=' Brace', prob=0.08984375, logit=20.25, token_id=70306, metadata=None))), (735, (166, PredictedToken(token=' K', prob=4.6193599700927734e-06, logit=10.375, token_id=735, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:25 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:25 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:41:25 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.785, logit=21.375)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" The\"[578] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.039, logit=18.375)', '\" z\"[1167] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.789, logit=21.250)', '\" The\"[578] (p=0.074, logit=18.875)', '\" Among\"[22395] (p=0.057, logit=18.625)', '\" An\"[1556] (p=0.019, logit=17.500)', '\" It\"[1102] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.7890625, logit=21.25, token_id=66821, metadata=None))), (14588, (100, PredictedToken(token=' Dog', prob=2.7894973754882812e-05, logit=11.0, token_id=14588, metadata=None))), (26781, (317, PredictedToken(token=' Hair', prob=3.7848949432373047e-06, logit=9.0, token_id=26781, metadata=None))), (38673, (430, PredictedToken(token=' Yoga', prob=2.294778823852539e-06, logit=8.5, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.785, logit=21.875)', '\" The\"[578] (p=0.106, logit=19.875)', '\" A\"[362] (p=0.039, logit=18.875)', '\" Among\"[22395] (p=0.024, logit=18.375)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.78515625, logit=21.875, token_id=14588, metadata=None))), (26781, (44, PredictedToken(token=' Hair', prob=0.0001239776611328125, logit=13.125, token_id=26781, metadata=None))), (66821, (58, PredictedToken(token=' Iris', prob=9.107589721679688e-05, logit=12.8125, token_id=66821, metadata=None))), (38673, (107, PredictedToken(token=' Yoga', prob=1.9073486328125e-05, logit=11.25, token_id=38673, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:26 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:26 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.938, logit=22.875)', '\" The\"[578] (p=0.017, logit=18.875)', '\" jacket\"[27300] (p=0.010, logit=18.375)', '\" Among\"[22395] (p=0.010, logit=18.375)', '\" A\"[362] (p=0.008, logit=18.125)']\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.875, logit=22.500)', '\" The\"[578] (p=0.044, logit=19.500)', '\" A\"[362] (p=0.044, logit=19.500)', '\" Among\"[22395] (p=0.010, logit=18.000)', '\" (\"[320] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.875, logit=22.5, token_id=83499, metadata=None))), (33711, (43, PredictedToken(token=' Suit', prob=6.961822509765625e-05, logit=13.0625, token_id=33711, metadata=None))), (11896, (246, PredictedToken(token=' Library', prob=2.384185791015625e-06, logit=9.6875, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.910, logit=22.500)', '\" The\"[578] (p=0.028, logit=19.000)', '\" A\"[362] (p=0.015, logit=18.375)', '\" Among\"[22395] (p=0.010, logit=18.000)', '\" Option\"[7104] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.91015625, logit=22.5, token_id=33711, metadata=None))), (11896, (7, PredictedToken(token=' Library', prob=0.00372314453125, logit=17.0, token_id=11896, metadata=None))), (83499, (116, PredictedToken(token=' Tooth', prob=9.238719940185547e-06, logit=11.0, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:26 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:26 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.590, logit=20.000)', '\" The\"[578] (p=0.132, logit=18.500)', '\" Rice\"[30616] (p=0.062, logit=17.750)', '\" Among\"[22395] (p=0.055, logit=17.625)', '\" \"[220] (p=0.012, logit=16.125)']\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.832, logit=22.625)', '\" The\"[578] (p=0.077, logit=20.250)', '\" A\"[362] (p=0.025, logit=19.125)', '\" Among\"[22395] (p=0.020, logit=18.875)', '\" It\"[1102] (p=0.010, logit=18.250)']\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.83203125, logit=22.625, token_id=56491, metadata=None))), (47033, (104, PredictedToken(token=' Printer', prob=9.5367431640625e-06, logit=11.25, token_id=47033, metadata=None))), (91782, (708, PredictedToken(token=' Shorts', prob=3.259629011154175e-07, logit=7.875, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     int_prediction=['\" Printer\"[47033] (p=0.891, logit=22.500)', '\" The\"[578] (p=0.044, logit=19.500)', '\" Among\"[22395] (p=0.011, logit=18.125)', '\" A\"[362] (p=0.010, logit=18.000)', '\" (\"[320] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     int_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.890625, logit=22.5, token_id=47033, metadata=None))), (91782, (34, PredictedToken(token=' Shorts', prob=0.0001811981201171875, logit=14.0, token_id=91782, metadata=None))), (56491, (43, PredictedToken(token=' Piano', prob=0.00013256072998046875, logit=13.6875, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:27 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:27 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:41:27 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     patch_prediction=['\" Pressure\"[40090] (p=0.707, logit=21.625)', '\" The\"[578] (p=0.108, logit=19.750)', '\" Among\"[22395] (p=0.074, logit=19.375)', '\" A\"[362] (p=0.058, logit=19.125)', '\" Option\"[7104] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.688, logit=20.500)', '\" The\"[578] (p=0.153, logit=19.000)', '\" A\"[362] (p=0.050, logit=17.875)', '\" Among\"[22395] (p=0.039, logit=17.625)', '\" It\"[1102] (p=0.014, logit=16.625)']\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.6875, logit=20.5, token_id=94467, metadata=None))), (72392, (6, PredictedToken(token=' Mixer', prob=0.007171630859375, logit=15.9375, token_id=72392, metadata=None))), (2522, (62, PredictedToken(token=' Sc', prob=0.00012302398681640625, logit=11.875, token_id=2522, metadata=None))), (29318, (783, PredictedToken(token=' Dress', prob=1.601874828338623e-06, logit=7.53125, token_id=29318, metadata=None))), (87035, (1226, PredictedToken(token=' Onion', prob=9.126961231231689e-07, logit=6.96875, token_id=87035, metadata=None))), (58600, (1984, PredictedToken(token=' Charm', prob=4.880130290985107e-07, logit=6.34375, token_id=58600, metadata=None)))])\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.723, logit=20.750)', '\" The\"[578] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.032, logit=17.625)', '\" Option\"[7104] (p=0.032, logit=17.625)', '\" A\"[362] (p=0.022, logit=17.250)']\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.72265625, logit=20.75, token_id=72392, metadata=None))), (87035, (7, PredictedToken(token=' Onion', prob=0.01031494140625, logit=16.5, token_id=87035, metadata=None))), (29318, (25, PredictedToken(token=' Dress', prob=0.0007476806640625, logit=13.875, token_id=29318, metadata=None))), (2522, (30, PredictedToken(token=' Sc', prob=0.000583648681640625, logit=13.625, token_id=2522, metadata=None))), (94467, (430, PredictedToken(token=' Trom', prob=3.4570693969726562e-06, logit=8.5, token_id=94467, metadata=None))), (58600, (5598, PredictedToken(token=' Charm', prob=1.1827796697616577e-07, logit=5.125, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:28 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:28 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.863, logit=22.875)', '\" The\"[578] (p=0.062, logit=20.250)', '\" Among\"[22395] (p=0.023, logit=19.250)', '\" A\"[362] (p=0.018, logit=19.000)', '\" d\"[294] (p=0.011, logit=18.500)']\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     clean_prediction=['\" Temple\"[19176] (p=0.852, logit=22.375)', '\" A\"[362] (p=0.054, logit=19.625)', '\" The\"[578] (p=0.048, logit=19.500)', '\" Among\"[22395] (p=0.014, logit=18.250)', '\" (\"[320] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     clean_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.8515625, logit=22.375, token_id=19176, metadata=None))), (8219, (67, PredictedToken(token=' Sun', prob=2.8252601623535156e-05, logit=12.0625, token_id=8219, metadata=None))), (37128, (229, PredictedToken(token=' Calculator', prob=2.473592758178711e-06, logit=9.625, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     int_prediction=['\" Sun\"[8219] (p=0.832, logit=22.125)', '\" The\"[578] (p=0.053, logit=19.375)', '\" Among\"[22395] (p=0.042, logit=19.125)', '\" A\"[362] (p=0.022, logit=18.500)', '\" (\"[320] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:41:28 src.selection.optimization INFO     int_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.83203125, logit=22.125, token_id=8219, metadata=None))), (37128, (9, PredictedToken(token=' Calculator', prob=0.0034027099609375, logit=16.625, token_id=37128, metadata=None))), (19176, (194, PredictedToken(token=' Temple', prob=5.125999450683594e-06, logit=10.125, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:28 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:29 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.879, logit=21.875)', '\" The\"[578] (p=0.044, logit=18.875)', '\" Among\"[22395] (p=0.034, logit=18.625)', '\" A\"[362] (p=0.010, logit=17.375)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.637, logit=20.625)', '\" A\"[362] (p=0.126, logit=19.000)', '\" The\"[578] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.052, logit=18.125)', '\" It\"[1102] (p=0.013, logit=16.750)']\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.63671875, logit=20.625, token_id=69755, metadata=None))), (1666, (8, PredictedToken(token=' As', prob=0.004302978515625, logit=15.625, token_id=1666, metadata=None))), (16183, (61, PredictedToken(token=' Hel', prob=0.00013828277587890625, logit=12.1875, token_id=16183, metadata=None))), (79028, (135, PredictedToken(token=' Hick', prob=3.075599670410156e-05, logit=10.6875, token_id=79028, metadata=None))), (83499, (141, PredictedToken(token=' Tooth', prob=2.8967857360839844e-05, logit=10.625, token_id=83499, metadata=None))), (28131, (533, PredictedToken(token=' Golf', prob=3.248453140258789e-06, logit=8.4375, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.621, logit=20.375)', '\" As\"[1666] (p=0.084, logit=18.375)', '\" The\"[578] (p=0.084, logit=18.375)', '\" Among\"[22395] (p=0.074, logit=18.250)', '\" Hel\"[16183] (p=0.065, logit=18.125)']\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.62109375, logit=20.375, token_id=79028, metadata=None))), (1666, (3, PredictedToken(token=' As', prob=0.083984375, logit=18.375, token_id=1666, metadata=None))), (16183, (5, PredictedToken(token=' Hel', prob=0.0654296875, logit=18.125, token_id=16183, metadata=None))), (83499, (163, PredictedToken(token=' Tooth', prob=2.8133392333984375e-05, logit=10.375, token_id=83499, metadata=None))), (28131, (1191, PredictedToken(token=' Golf', prob=1.2367963790893555e-06, logit=7.25, token_id=28131, metadata=None))), (69755, (2669, PredictedToken(token=' Notebook', prob=4.414469003677368e-07, logit=6.21875, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:29 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:29 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:41:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     patch_prediction=['\" Sh\"[1443] (p=0.809, logit=21.125)', '\" Among\"[22395] (p=0.075, logit=18.750)', '\" The\"[578] (p=0.040, logit=18.125)', '\" Option\"[7104] (p=0.010, logit=16.750)', '\" Out\"[4470] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.727, logit=20.500)', '\" The\"[578] (p=0.053, logit=17.875)', '\" Pin\"[17929] (p=0.046, logit=17.750)', '\" A\"[362] (p=0.046, logit=17.750)', '\" Among\"[22395] (p=0.032, logit=17.375)']\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.7265625, logit=20.5, token_id=69755, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.04638671875, logit=17.75, token_id=17929, metadata=None))), (4923, (12, PredictedToken(token=' Sk', prob=0.003814697265625, logit=15.25, token_id=4923, metadata=None))), (74968, (13, PredictedToken(token=' Razor', prob=0.0029754638671875, logit=15.0, token_id=74968, metadata=None))), (19176, (260, PredictedToken(token=' Temple', prob=1.2159347534179688e-05, logit=9.5, token_id=19176, metadata=None)))])\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     int_prediction=['\" Razor\"[74968] (p=0.715, logit=20.375)', '\" Pin\"[17929] (p=0.085, logit=18.250)', '\" The\"[578] (p=0.046, logit=17.625)', '\" Among\"[22395] (p=0.022, logit=16.875)', '\" Sk\"[4923] (p=0.022, logit=16.875)']\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     int_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.71484375, logit=20.375, token_id=74968, metadata=None))), (17929, (2, PredictedToken(token=' Pin', prob=0.08544921875, logit=18.25, token_id=17929, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.0216064453125, logit=16.875, token_id=4923, metadata=None))), (19176, (95, PredictedToken(token=' Temple', prob=0.00010013580322265625, logit=11.5, token_id=19176, metadata=None))), (69755, (569, PredictedToken(token=' Notebook', prob=3.874301910400391e-06, logit=8.25, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:30 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:30 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.734, logit=21.000)', '\" An\"[1556] (p=0.087, logit=18.875)', '\" The\"[578] (p=0.077, logit=18.750)', '\" Among\"[22395] (p=0.037, logit=18.000)', '\" It\"[1102] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.812, logit=22.250)', '\" The\"[578] (p=0.086, logit=20.000)', '\" A\"[362] (p=0.041, logit=19.250)', '\" Among\"[22395] (p=0.028, logit=18.875)', '\" It\"[1102] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8125, logit=22.25, token_id=40759, metadata=None))), (18654, (9, PredictedToken(token=' Micro', prob=0.0015716552734375, logit=16.0, token_id=18654, metadata=None))), (57094, (13, PredictedToken(token=' Highlight', prob=0.000896453857421875, logit=15.4375, token_id=57094, metadata=None))), (445, (98, PredictedToken(token=' L', prob=1.6450881958007812e-05, logit=11.4375, token_id=445, metadata=None))), (68554, (200, PredictedToken(token=' Gloves', prob=3.904104232788086e-06, logit=10.0, token_id=68554, metadata=None))), (39794, (1197, PredictedToken(token=' Desk', prob=2.337619662284851e-07, logit=7.1875, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:41:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     int_prediction=['\" Micro\"[18654] (p=0.566, logit=20.750)', '\" The\"[578] (p=0.143, logit=19.375)', '\" Among\"[22395] (p=0.126, logit=19.250)', '\" Highlight\"[57094] (p=0.032, logit=17.875)', '\" A\"[362] (p=0.025, logit=17.625)']\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     int_track=OrderedDict([(18654, (1, PredictedToken(token=' Micro', prob=0.56640625, logit=20.75, token_id=18654, metadata=None))), (57094, (4, PredictedToken(token=' Highlight', prob=0.031982421875, logit=17.875, token_id=57094, metadata=None))), (68554, (8, PredictedToken(token=' Gloves', prob=0.0133056640625, logit=17.0, token_id=68554, metadata=None))), (445, (11, PredictedToken(token=' L', prob=0.0048828125, logit=16.0, token_id=445, metadata=None))), (39794, (24, PredictedToken(token=' Desk', prob=0.000797271728515625, logit=14.1875, token_id=39794, metadata=None))), (40759, (74, PredictedToken(token=' Harmon', prob=9.5367431640625e-05, logit=12.0625, token_id=40759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:31 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.895, logit=21.375)', '\" The\"[578] (p=0.051, logit=18.500)', '\" A\"[362] (p=0.009, logit=16.750)', '\" SK\"[12343] (p=0.005, logit=16.125)', '\" Hick\"[79028] (p=0.003, logit=15.750)']\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     clean_prediction=['\" Dolphin\"[96096] (p=0.836, logit=21.500)', '\" The\"[578] (p=0.068, logit=19.000)', '\" A\"[362] (p=0.029, logit=18.125)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" D\"[423] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     clean_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.8359375, logit=21.5, token_id=96096, metadata=None))), (22050, (20, PredictedToken(token=' Hat', prob=0.00067138671875, logit=14.375, token_id=22050, metadata=None))), (41493, (83, PredictedToken(token=' Tow', prob=3.337860107421875e-05, logit=11.375, token_id=41493, metadata=None))), (24423, (242, PredictedToken(token=' Monitor', prob=4.5299530029296875e-06, logit=9.375, token_id=24423, metadata=None))), (36943, (828, PredictedToken(token=' Folder', prob=6.92903995513916e-07, logit=7.5, token_id=36943, metadata=None)))])\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.707, logit=21.250)', '\" Folder\"[36943] (p=0.108, logit=19.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.024, logit=17.875)', '\" A\"[362] (p=0.024, logit=17.875)']\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.70703125, logit=21.25, token_id=41493, metadata=None))), (36943, (2, PredictedToken(token=' Folder', prob=0.1083984375, logit=19.375, token_id=36943, metadata=None))), (24423, (6, PredictedToken(token=' Monitor', prob=0.018798828125, logit=17.625, token_id=24423, metadata=None))), (22050, (7, PredictedToken(token=' Hat', prob=0.005401611328125, logit=16.375, token_id=22050, metadata=None))), (96096, (46, PredictedToken(token=' Dolphin', prob=0.00016307830810546875, logit=12.875, token_id=96096, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:31 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:31 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:41:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     patch_prediction=['\" Sub\"[3804] (p=0.797, logit=22.000)', '\" A\"[362] (p=0.084, logit=19.750)', '\" The\"[578] (p=0.051, logit=19.250)', '\" Among\"[22395] (p=0.027, logit=18.625)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.883, logit=22.375)', '\" The\"[578] (p=0.044, logit=19.375)', '\" A\"[362] (p=0.034, logit=19.125)', '\" Among\"[22395] (p=0.011, logit=18.000)', '\" chain\"[8957] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.8828125, logit=22.375, token_id=29625, metadata=None))), (33711, (7, PredictedToken(token=' Suit', prob=0.0021820068359375, logit=16.375, token_id=33711, metadata=None))), (68027, (76, PredictedToken(token=' Sax', prob=4.8160552978515625e-05, logit=12.5625, token_id=68027, metadata=None))), (70762, (183, PredictedToken(token=' Motorcycle', prob=6.5267086029052734e-06, logit=10.5625, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.883, logit=21.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" Among\"[22395] (p=0.016, logit=17.625)', '\" A\"[362] (p=0.013, logit=17.375)', '\" Sax\"[68027] (p=0.011, logit=17.250)']\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.8828125, logit=21.625, token_id=70762, metadata=None))), (68027, (5, PredictedToken(token=' Sax', prob=0.0111083984375, logit=17.25, token_id=68027, metadata=None))), (29625, (16, PredictedToken(token=' Chain', prob=0.0010986328125, logit=14.9375, token_id=29625, metadata=None))), (33711, (18, PredictedToken(token=' Suit', prob=0.000804901123046875, logit=14.625, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:32 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     patch_prediction=['\" None\"[2290] (p=0.531, logit=19.750)', '\" Yoga\"[38673] (p=0.252, logit=19.000)', '\" Z\"[1901] (p=0.082, logit=17.875)', '\" Comb\"[23262] (p=0.021, logit=16.500)', '\" The\"[578] (p=0.018, logit=16.375)']\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.758, logit=21.250)', '\" The\"[578] (p=0.091, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.250)', '\" A\"[362] (p=0.033, logit=18.125)', '\" It\"[1102] (p=0.010, logit=16.875)']\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.7578125, logit=21.25, token_id=26698, metadata=None))), (21424, (32, PredictedToken(token=' Football', prob=0.000507354736328125, logit=13.9375, token_id=21424, metadata=None))), (34785, (165, PredictedToken(token=' Truck', prob=1.436471939086914e-05, logit=10.375, token_id=34785, metadata=None))), (8219, (319, PredictedToken(token=' Sun', prob=4.112720489501953e-06, logit=9.125, token_id=8219, metadata=None)))])\n",
      "2025-09-16 09:41:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     int_prediction=['\" Football\"[21424] (p=0.479, logit=19.500)', '\" None\"[2290] (p=0.155, logit=18.375)', '\" Sun\"[8219] (p=0.094, logit=17.875)', '\" Truck\"[34785] (p=0.083, logit=17.750)', '\" The\"[578] (p=0.050, logit=17.250)']\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     int_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.478515625, logit=19.5, token_id=21424, metadata=None))), (8219, (3, PredictedToken(token=' Sun', prob=0.09423828125, logit=17.875, token_id=8219, metadata=None))), (34785, (4, PredictedToken(token=' Truck', prob=0.0830078125, logit=17.75, token_id=34785, metadata=None))), (26698, (118, PredictedToken(token=' Keyboard', prob=7.104873657226562e-05, logit=10.6875, token_id=26698, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:33 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:33 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.840, logit=21.375)', '\" The\"[578] (p=0.078, logit=19.000)', '\" Among\"[22395] (p=0.025, logit=17.875)', '\" A\"[362] (p=0.012, logit=17.125)', '\" Only\"[8442] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.871, logit=22.250)', '\" Among\"[22395] (p=0.056, logit=19.500)', '\" The\"[578] (p=0.043, logit=19.250)', '\" Out\"[4470] (p=0.004, logit=16.875)', '\" It\"[1102] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.87109375, logit=22.25, token_id=41785, metadata=None))), (17929, (7, PredictedToken(token=' Pin', prob=0.0021514892578125, logit=16.25, token_id=17929, metadata=None))), (63606, (32, PredictedToken(token=' Stap', prob=0.0001773834228515625, logit=13.75, token_id=63606, metadata=None))), (445, (43, PredictedToken(token=' L', prob=0.0001010894775390625, logit=13.1875, token_id=445, metadata=None))), (27738, (152, PredictedToken(token=' Ward', prob=6.0498714447021484e-06, logit=10.375, token_id=27738, metadata=None))), (57225, (3175, PredictedToken(token=' Laptop', prob=5.2386894822120667e-08, logit=5.625, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.781, logit=21.625)', '\" The\"[578] (p=0.057, logit=19.000)', '\" A\"[362] (p=0.050, logit=18.875)', '\" Among\"[22395] (p=0.039, logit=18.625)', '\" Stap\"[63606] (p=0.027, logit=18.250)']\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.78125, logit=21.625, token_id=17929, metadata=None))), (63606, (5, PredictedToken(token=' Stap', prob=0.0267333984375, logit=18.25, token_id=63606, metadata=None))), (445, (6, PredictedToken(token=' L', prob=0.01263427734375, logit=17.5, token_id=445, metadata=None))), (57225, (23, PredictedToken(token=' Laptop', prob=0.0004596710205078125, logit=14.1875, token_id=57225, metadata=None))), (27738, (61, PredictedToken(token=' Ward', prob=5.14984130859375e-05, logit=12.0, token_id=27738, metadata=None))), (41785, (247, PredictedToken(token=' Spin', prob=3.293156623840332e-06, logit=9.25, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:33 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:33 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:41:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.750, logit=21.375)', '\" The\"[578] (p=0.090, logit=19.250)', '\" Among\"[22395] (p=0.062, logit=18.875)', '\" A\"[362] (p=0.037, logit=18.375)', '\" Option\"[7104] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.680, logit=22.625)', '\" The\"[578] (p=0.151, logit=21.125)', '\" Among\"[22395] (p=0.072, logit=20.375)', '\" A\"[362] (p=0.063, logit=20.250)', '\" It\"[1102] (p=0.005, logit=17.750)']\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.6796875, logit=22.625, token_id=19111, metadata=None))), (328, (58, PredictedToken(token=' S', prob=3.719329833984375e-05, logit=12.8125, token_id=328, metadata=None))), (57915, (65, PredictedToken(token=' Ank', prob=3.2901763916015625e-05, logit=12.6875, token_id=57915, metadata=None))), (75258, (100, PredictedToken(token=' Refriger', prob=1.4603137969970703e-05, logit=11.875, token_id=75258, metadata=None))), (52882, (155, PredictedToken(token=' Pepper', prob=5.036592483520508e-06, logit=10.8125, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     int_prediction=['\" Refriger\"[75258] (p=0.330, logit=20.500)', '\" Pepper\"[52882] (p=0.200, logit=20.000)', '\" The\"[578] (p=0.200, logit=20.000)', '\" Among\"[22395] (p=0.156, logit=19.750)', '\" A\"[362] (p=0.024, logit=17.875)']\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     int_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.330078125, logit=20.5, token_id=75258, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.2001953125, logit=20.0, token_id=52882, metadata=None))), (328, (11, PredictedToken(token=' S', prob=0.00469970703125, logit=16.25, token_id=328, metadata=None))), (57915, (24, PredictedToken(token=' Ank', prob=0.0010528564453125, logit=14.75, token_id=57915, metadata=None))), (19111, (297, PredictedToken(token=' Bus', prob=4.291534423828125e-06, logit=9.25, token_id=19111, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:34 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:34 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.648, logit=20.875)', '\" Mouse\"[18191] (p=0.113, logit=19.125)', '\" Among\"[22395] (p=0.078, logit=18.750)', '\" The\"[578] (p=0.047, logit=18.250)', '\" There\"[2684] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:34 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.586, logit=22.000)', '\" The\"[578] (p=0.148, logit=20.625)', '\" A\"[362] (p=0.131, logit=20.500)', '\" Horse\"[34392] (p=0.062, logit=19.750)', '\" Among\"[22395] (p=0.033, logit=19.125)']\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.5859375, logit=22.0, token_id=3341, metadata=None))), (34392, (4, PredictedToken(token=' Horse', prob=0.061767578125, logit=19.75, token_id=34392, metadata=None))), (11683, (30, PredictedToken(token=' Acc', prob=0.0003910064697265625, logit=14.6875, token_id=11683, metadata=None))), (22410, (114, PredictedToken(token=' Ju', prob=1.33514404296875e-05, logit=11.3125, token_id=22410, metadata=None))), (89077, (1596, PredictedToken(token=' Strawberry', prob=1.2665987014770508e-07, logit=6.65625, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.801, logit=22.375)', '\" The\"[578] (p=0.084, logit=20.125)', '\" A\"[362] (p=0.045, logit=19.500)', '\" Among\"[22395] (p=0.035, logit=19.250)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.80078125, logit=22.375, token_id=34392, metadata=None))), (89077, (6, PredictedToken(token=' Strawberry', prob=0.00421142578125, logit=17.125, token_id=89077, metadata=None))), (11683, (9, PredictedToken(token=' Acc', prob=0.001983642578125, logit=16.375, token_id=11683, metadata=None))), (22410, (28, PredictedToken(token=' Ju', prob=0.00025177001953125, logit=14.3125, token_id=22410, metadata=None))), (3341, (54, PredictedToken(token=' Car', prob=5.626678466796875e-05, logit=12.8125, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:35 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.711, logit=21.500)', '\" The\"[578] (p=0.096, logit=19.500)', '\" Glo\"[25372] (p=0.058, logit=19.000)', '\" Among\"[22395] (p=0.052, logit=18.875)', '\" A\"[362] (p=0.035, logit=18.500)']\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.922, logit=22.375)', '\" The\"[578] (p=0.022, logit=18.625)', '\" Among\"[22395] (p=0.012, logit=18.000)', '\" laptop\"[21288] (p=0.012, logit=18.000)', '\" A\"[362] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.921875, logit=22.375, token_id=57225, metadata=None))), (4923, (21, PredictedToken(token=' Sk', prob=0.0002574920654296875, logit=14.1875, token_id=4923, metadata=None))), (6771, (35, PredictedToken(token=' Table', prob=0.00012111663818359375, logit=13.4375, token_id=6771, metadata=None))), (91297, (189, PredictedToken(token=' Mushroom', prob=3.6656856536865234e-06, logit=9.9375, token_id=91297, metadata=None)))])\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     int_prediction=['\" Table\"[6771] (p=0.547, logit=19.625)', '\" None\"[2290] (p=0.201, logit=18.625)', '\" Among\"[22395] (p=0.084, logit=17.750)', '\" The\"[578] (p=0.035, logit=16.875)', '\" Option\"[7104] (p=0.011, logit=15.750)']\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     int_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.546875, logit=19.625, token_id=6771, metadata=None))), (4923, (16, PredictedToken(token=' Sk', prob=0.002532958984375, logit=14.25, token_id=4923, metadata=None))), (57225, (77, PredictedToken(token=' Laptop', prob=0.00011157989501953125, logit=11.125, token_id=57225, metadata=None))), (91297, (531, PredictedToken(token=' Mushroom', prob=3.159046173095703e-06, logit=7.5625, token_id=91297, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:35 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:41:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     patch_prediction=['\" Dish\"[49268] (p=0.824, logit=21.375)', '\" The\"[578] (p=0.053, logit=18.625)', '\" Oak\"[18787] (p=0.019, logit=17.625)', '\" A\"[362] (p=0.019, logit=17.625)', '\" Among\"[22395] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.820, logit=22.375)', '\" The\"[578] (p=0.076, logit=20.000)', '\" A\"[362] (p=0.052, logit=19.625)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.8203125, logit=22.375, token_id=16488, metadata=None))), (46506, (75, PredictedToken(token=' Drum', prob=2.396106719970703e-05, logit=11.9375, token_id=46506, metadata=None))), (70306, (125, PredictedToken(token=' Brace', prob=1.0013580322265625e-05, logit=11.0625, token_id=70306, metadata=None))), (30616, (262, PredictedToken(token=' Rice', prob=2.2351741790771484e-06, logit=9.5625, token_id=30616, metadata=None))), (10777, (1580, PredictedToken(token=' Router', prob=1.257285475730896e-07, logit=6.6875, token_id=10777, metadata=None)))])\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.443, logit=20.125)', '\" The\"[578] (p=0.210, logit=19.375)', '\" Among\"[22395] (p=0.112, logit=18.750)', '\" Router\"[10777] (p=0.068, logit=18.250)', '\" A\"[362] (p=0.068, logit=18.250)']\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.443359375, logit=20.125, token_id=30616, metadata=None))), (10777, (5, PredictedToken(token=' Router', prob=0.06787109375, logit=18.25, token_id=10777, metadata=None))), (46506, (57, PredictedToken(token=' Drum', prob=0.000179290771484375, logit=12.3125, token_id=46506, metadata=None))), (70306, (192, PredictedToken(token=' Brace', prob=1.895427703857422e-05, logit=10.0625, token_id=70306, metadata=None))), (16488, (240, PredictedToken(token=' Bat', prob=1.2218952178955078e-05, logit=9.625, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:36 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     patch_prediction=['\" Grape\"[80629] (p=0.707, logit=20.750)', '\" The\"[578] (p=0.109, logit=18.875)', '\" Among\"[22395] (p=0.051, logit=18.125)', '\" A\"[362] (p=0.051, logit=18.125)', '\" GRA\"[65120] (p=0.013, logit=16.750)']\n",
      "2025-09-16 09:41:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.060, logit=19.500)', '\" A\"[362] (p=0.046, logit=19.250)', '\" Among\"[22395] (p=0.022, logit=18.500)', '\" z\"[1167] (p=0.012, logit=17.875)']\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.82421875, logit=22.125, token_id=1901, metadata=None))), (8325, (45, PredictedToken(token=' Apple', prob=8.96453857421875e-05, logit=13.0, token_id=8325, metadata=None))), (10573, (58, PredictedToken(token=' Watch', prob=6.151199340820312e-05, logit=12.625, token_id=10573, metadata=None))), (70110, (70, PredictedToken(token=' Ottoman', prob=4.506111145019531e-05, logit=12.3125, token_id=70110, metadata=None)))])\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.793, logit=21.125)', '\" The\"[578] (p=0.057, logit=18.500)', '\" Among\"[22395] (p=0.051, logit=18.375)', '\" An\"[1556] (p=0.021, logit=17.500)', '\" Ottoman\"[70110] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.79296875, logit=21.125, token_id=8325, metadata=None))), (70110, (5, PredictedToken(token=' Ottoman', prob=0.007781982421875, logit=16.5, token_id=70110, metadata=None))), (10573, (16, PredictedToken(token=' Watch', prob=0.002227783203125, logit=15.25, token_id=10573, metadata=None))), (1901, (204, PredictedToken(token=' Z', prob=9.715557098388672e-06, logit=9.8125, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:37 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:37 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.598, logit=21.250)', '\" The\"[578] (p=0.194, logit=20.125)', '\" A\"[362] (p=0.134, logit=19.750)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" It\"[1102] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     clean_prediction=['\" To\"[2057] (p=0.695, logit=21.625)', '\" The\"[578] (p=0.137, logit=20.000)', '\" A\"[362] (p=0.073, logit=19.375)', '\" Among\"[22395] (p=0.039, logit=18.750)', '\" It\"[1102] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     clean_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.6953125, logit=21.625, token_id=2057, metadata=None))), (16488, (8, PredictedToken(token=' Bat', prob=0.004119873046875, logit=16.5, token_id=16488, metadata=None))), (38673, (55, PredictedToken(token=' Yoga', prob=9.72747802734375e-05, logit=12.75, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     int_prediction=['\" Among\"[22395] (p=0.262, logit=17.875)', '\" The\"[578] (p=0.180, logit=17.500)', '\" A\"[362] (p=0.085, logit=16.750)', '\" None\"[2290] (p=0.066, logit=16.500)', '\" Object\"[3075] (p=0.058, logit=16.375)']\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     int_track=OrderedDict([(16488, (27, PredictedToken(token=' Bat', prob=0.002410888671875, logit=13.1875, token_id=16488, metadata=None))), (2057, (65, PredictedToken(token=' To', prob=0.00041961669921875, logit=11.4375, token_id=2057, metadata=None))), (38673, (67, PredictedToken(token=' Yoga', prob=0.000392913818359375, logit=11.375, token_id=38673, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:37 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:37 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     patch_prediction=['\" Fl\"[3061] (p=0.773, logit=21.125)', '\" The\"[578] (p=0.105, logit=19.125)', '\" Among\"[22395] (p=0.030, logit=17.875)', '\" A\"[362] (p=0.026, logit=17.750)', '\" It\"[1102] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.715, logit=21.500)', '\" The\"[578] (p=0.110, logit=19.625)', '\" A\"[362] (p=0.076, logit=19.250)', '\" Among\"[22395] (p=0.052, logit=18.875)', '\" CO\"[7432] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.71484375, logit=21.5, token_id=68867, metadata=None))), (423, (17, PredictedToken(token=' D', prob=0.00074005126953125, logit=14.625, token_id=423, metadata=None))), (11683, (37, PredictedToken(token=' Acc', prob=0.000255584716796875, logit=13.5625, token_id=11683, metadata=None))), (36845, (85, PredictedToken(token=' Tiger', prob=4.172325134277344e-05, logit=11.75, token_id=36845, metadata=None))), (43316, (100, PredictedToken(token=' Tul', prob=2.872943878173828e-05, logit=11.375, token_id=43316, metadata=None))), (82994, (284, PredictedToken(token=' Toilet', prob=3.6507844924926758e-06, logit=9.3125, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     int_prediction=['\" Acc\"[11683] (p=0.758, logit=21.625)', '\" Among\"[22395] (p=0.091, logit=19.500)', '\" The\"[578] (p=0.080, logit=19.375)', '\" Tul\"[43316] (p=0.012, logit=17.500)', '\" An\"[1556] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     int_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.7578125, logit=21.625, token_id=11683, metadata=None))), (43316, (5, PredictedToken(token=' Tul', prob=0.01226806640625, logit=17.5, token_id=43316, metadata=None))), (36845, (7, PredictedToken(token=' Tiger', prob=0.00396728515625, logit=16.375, token_id=36845, metadata=None))), (423, (23, PredictedToken(token=' D', prob=0.0004749298095703125, logit=14.25, token_id=423, metadata=None))), (82994, (156, PredictedToken(token=' Toilet', prob=1.2695789337158203e-05, logit=10.625, token_id=82994, metadata=None))), (68867, (2001, PredictedToken(token=' Coat', prob=1.862645149230957e-07, logit=6.40625, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:38 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.938, logit=22.375)', '\" The\"[578] (p=0.017, logit=18.375)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" A\"[362] (p=0.006, logit=17.375)', '\" Factory\"[17367] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:41:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.883, logit=21.500)', '\" The\"[578] (p=0.044, logit=18.500)', '\" Among\"[22395] (p=0.030, logit=18.125)', '\" A\"[362] (p=0.007, logit=16.625)', '\" Option\"[7104] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.8828125, logit=21.5, token_id=79028, metadata=None))), (3804, (18, PredictedToken(token=' Sub', prob=0.000518798828125, logit=14.0625, token_id=3804, metadata=None))), (8325, (29, PredictedToken(token=' Apple', prob=0.0002613067626953125, logit=13.375, token_id=8325, metadata=None))), (36895, (40, PredictedToken(token=' Eagle', prob=0.0001392364501953125, logit=12.75, token_id=36895, metadata=None))), (2522, (153, PredictedToken(token=' Sc', prob=1.2218952178955078e-05, logit=10.3125, token_id=2522, metadata=None)))])\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.805, logit=22.125)', '\" An\"[1556] (p=0.066, logit=19.625)', '\" The\"[578] (p=0.058, logit=19.500)', '\" Among\"[22395] (p=0.024, logit=18.625)', '\" It\"[1102] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.8046875, logit=22.125, token_id=8325, metadata=None))), (3804, (7, PredictedToken(token=' Sub', prob=0.002899169921875, logit=16.5, token_id=3804, metadata=None))), (2522, (17, PredictedToken(token=' Sc', prob=0.00099945068359375, logit=15.4375, token_id=2522, metadata=None))), (36895, (31, PredictedToken(token=' Eagle', prob=0.000270843505859375, logit=14.125, token_id=36895, metadata=None))), (79028, (635, PredictedToken(token=' Hick', prob=7.115304470062256e-07, logit=8.1875, token_id=79028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:39 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.949, logit=22.500)', '\" The\"[578] (p=0.012, logit=18.125)', '\" Among\"[22395] (p=0.011, logit=18.000)', '\" soap\"[27883] (p=0.004, logit=17.000)', '\" (\"[320] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.883, logit=22.375)', '\" The\"[578] (p=0.050, logit=19.500)', '\" Among\"[22395] (p=0.014, logit=18.250)', '\" A\"[362] (p=0.014, logit=18.250)', '\" laptop\"[21288] (p=0.011, logit=18.000)']\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.8828125, logit=22.375, token_id=57225, metadata=None))), (445, (8, PredictedToken(token=' L', prob=0.002471923828125, logit=16.5, token_id=445, metadata=None))), (65449, (58, PredictedToken(token=' Willow', prob=2.9325485229492188e-05, logit=12.0625, token_id=65449, metadata=None)))])\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.648, logit=21.125)', '\" Willow\"[65449] (p=0.164, logit=19.750)', '\" The\"[578] (p=0.068, logit=18.875)', '\" Among\"[22395] (p=0.037, logit=18.250)', '\" lotion\"[87942] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.6484375, logit=21.125, token_id=445, metadata=None))), (65449, (2, PredictedToken(token=' Willow', prob=0.1640625, logit=19.75, token_id=65449, metadata=None))), (57225, (42, PredictedToken(token=' Laptop', prob=0.00015926361083984375, logit=12.8125, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:39 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:39 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:41:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.883, logit=21.500)', '\" The\"[578] (p=0.027, logit=18.000)', '\" Among\"[22395] (p=0.016, logit=17.500)', '\" Cherry\"[45805] (p=0.014, logit=17.375)', '\" A\"[362] (p=0.014, logit=17.375)']\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     clean_prediction=['\" Hat\"[22050] (p=0.590, logit=21.375)', '\" The\"[578] (p=0.191, logit=20.250)', '\" Among\"[22395] (p=0.090, logit=19.500)', '\" A\"[362] (p=0.070, logit=19.250)', '\" hat\"[9072] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     clean_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.58984375, logit=21.375, token_id=22050, metadata=None))), (65329, (68, PredictedToken(token=' Elm', prob=8.249282836914062e-05, logit=12.5, token_id=65329, metadata=None))), (34785, (81, PredictedToken(token=' Truck', prob=5.316734313964844e-05, logit=12.0625, token_id=34785, metadata=None))), (47759, (135, PredictedToken(token=' Guitar', prob=1.8358230590820312e-05, logit=11.0, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.797, logit=21.250)', '\" The\"[578] (p=0.074, logit=18.875)', '\" Among\"[22395] (p=0.065, logit=18.750)', '\" elm\"[43305] (p=0.005, logit=16.250)', '\" Option\"[7104] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.796875, logit=21.25, token_id=65329, metadata=None))), (34785, (6, PredictedToken(token=' Truck', prob=0.004730224609375, logit=16.125, token_id=34785, metadata=None))), (47759, (51, PredictedToken(token=' Guitar', prob=0.0001430511474609375, logit=12.625, token_id=47759, metadata=None))), (22050, (413, PredictedToken(token=' Hat', prob=2.6226043701171875e-06, logit=8.625, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:40 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.848, logit=21.750)', '\" The\"[578] (p=0.048, logit=18.875)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" A\"[362] (p=0.023, logit=18.125)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:41:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.758, logit=21.750)', '\" The\"[578] (p=0.091, logit=19.625)', '\" A\"[362] (p=0.091, logit=19.625)', '\" Among\"[22395] (p=0.020, logit=18.125)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.7578125, logit=21.75, token_id=83499, metadata=None))), (13000, (169, PredictedToken(token=' Van', prob=9.298324584960938e-06, logit=10.4375, token_id=13000, metadata=None))), (12369, (334, PredictedToken(token=' Food', prob=2.339482307434082e-06, logit=9.0625, token_id=12369, metadata=None))), (87035, (463, PredictedToken(token=' Onion', prob=1.5124678611755371e-06, logit=8.625, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.742, logit=21.000)', '\" The\"[578] (p=0.078, logit=18.750)', '\" Among\"[22395] (p=0.061, logit=18.500)', '\" An\"[1556] (p=0.020, logit=17.375)', '\" None\"[2290] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.7421875, logit=21.0, token_id=87035, metadata=None))), (12369, (9, PredictedToken(token=' Food', prob=0.0038909912109375, logit=15.75, token_id=12369, metadata=None))), (13000, (20, PredictedToken(token=' Van', prob=0.001190185546875, logit=14.5625, token_id=13000, metadata=None))), (83499, (116, PredictedToken(token=' Tooth', prob=3.814697265625e-05, logit=11.125, token_id=83499, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:41 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     patch_prediction=['\" Desk\"[39794] (p=0.820, logit=21.875)', '\" The\"[578] (p=0.067, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.625)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.777, logit=20.625)', '\" The\"[578] (p=0.063, logit=18.125)', '\" A\"[362] (p=0.056, logit=18.000)', '\" Among\"[22395] (p=0.039, logit=17.625)', '\" Note\"[7181] (p=0.008, logit=16.000)']\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.77734375, logit=20.625, token_id=69755, metadata=None))), (30760, (36, PredictedToken(token=' Scar', prob=0.000354766845703125, logit=12.9375, token_id=30760, metadata=None))), (48390, (37, PredictedToken(token=' Lily', prob=0.000354766845703125, logit=12.9375, token_id=48390, metadata=None))), (36845, (118, PredictedToken(token=' Tiger', prob=3.981590270996094e-05, logit=10.75, token_id=36845, metadata=None))), (16488, (134, PredictedToken(token=' Bat', prob=3.0994415283203125e-05, logit=10.5, token_id=16488, metadata=None))), (36358, (306, PredictedToken(token=' Bench', prob=7.3909759521484375e-06, logit=9.0625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.402, logit=19.625)', '\" Bench\"[36358] (p=0.275, logit=19.250)', '\" Among\"[22395] (p=0.090, logit=18.125)', '\" The\"[578] (p=0.079, logit=18.000)', '\" Scar\"[30760] (p=0.037, logit=17.250)']\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.40234375, logit=19.625, token_id=16488, metadata=None))), (36358, (2, PredictedToken(token=' Bench', prob=0.275390625, logit=19.25, token_id=36358, metadata=None))), (30760, (5, PredictedToken(token=' Scar', prob=0.037353515625, logit=17.25, token_id=30760, metadata=None))), (36845, (31, PredictedToken(token=' Tiger', prob=0.000934600830078125, logit=13.5625, token_id=36845, metadata=None))), (69755, (267, PredictedToken(token=' Notebook', prob=1.33514404296875e-05, logit=9.3125, token_id=69755, metadata=None))), (48390, (347, PredictedToken(token=' Lily', prob=8.106231689453125e-06, logit=8.8125, token_id=48390, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:41 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:41:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     patch_prediction=['\" Pe\"[5250] (p=0.645, logit=21.000)', '\" The\"[578] (p=0.163, logit=19.625)', '\" Among\"[22395] (p=0.087, logit=19.000)', '\" A\"[362] (p=0.047, logit=18.375)', '\" Option\"[7104] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     clean_prediction=['\" Shower\"[48471] (p=0.613, logit=20.250)', '\" The\"[578] (p=0.121, logit=18.625)', '\" Among\"[22395] (p=0.106, logit=18.500)', '\" A\"[362] (p=0.057, logit=17.875)', '\" Option\"[7104] (p=0.016, logit=16.625)']\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     clean_track=OrderedDict([(48471, (1, PredictedToken(token=' Shower', prob=0.61328125, logit=20.25, token_id=48471, metadata=None))), (43316, (71, PredictedToken(token=' Tul', prob=0.00016021728515625, logit=12.0, token_id=43316, metadata=None))), (27217, (78, PredictedToken(token=' Train', prob=0.00013256072998046875, logit=11.8125, token_id=27217, metadata=None))), (26698, (243, PredictedToken(token=' Keyboard', prob=1.233816146850586e-05, logit=9.4375, token_id=26698, metadata=None))), (16730, (375, PredictedToken(token=' Museum', prob=5.841255187988281e-06, logit=8.6875, token_id=16730, metadata=None))), (65329, (2375, PredictedToken(token=' Elm', prob=5.103647708892822e-07, logit=6.25, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     int_prediction=['\" Tul\"[43316] (p=0.590, logit=20.125)', '\" Elm\"[65329] (p=0.191, logit=19.000)', '\" Among\"[22395] (p=0.070, logit=18.000)', '\" The\"[578] (p=0.055, logit=17.750)', '\" It\"[1102] (p=0.010, logit=16.000)']\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     int_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.58984375, logit=20.125, token_id=43316, metadata=None))), (65329, (2, PredictedToken(token=' Elm', prob=0.19140625, logit=19.0, token_id=65329, metadata=None))), (48471, (1330, PredictedToken(token=' Shower', prob=1.0728836059570312e-06, logit=6.90625, token_id=48471, metadata=None))), (26698, (2033, PredictedToken(token=' Keyboard', prob=6.295740604400635e-07, logit=6.375, token_id=26698, metadata=None))), (27217, (2527, PredictedToken(token=' Train', prob=4.7497451305389404e-07, logit=6.09375, token_id=27217, metadata=None))), (16730, (3059, PredictedToken(token=' Museum', prob=3.7066638469696045e-07, logit=5.84375, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:42 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     patch_prediction=['\" Mar\"[2947] (p=0.824, logit=22.000)', '\" The\"[578] (p=0.077, logit=19.625)', '\" Among\"[22395] (p=0.032, logit=18.750)', '\" A\"[362] (p=0.022, logit=18.375)', '\" (\"[320] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:41:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.938, logit=22.375)', '\" Among\"[22395] (p=0.017, logit=18.375)', '\" The\"[578] (p=0.017, logit=18.375)', '\" Option\"[7104] (p=0.005, logit=17.125)', '\" It\"[1102] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.9375, logit=22.375, token_id=41785, metadata=None))), (14937, (7, PredictedToken(token=' Ash', prob=0.00180816650390625, logit=16.125, token_id=14937, metadata=None))), (87213, (31, PredictedToken(token=' Oven', prob=0.00020313262939453125, logit=13.9375, token_id=87213, metadata=None))), (71264, (36, PredictedToken(token=' Daisy', prob=0.0001678466796875, logit=13.75, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.867, logit=21.250)', '\" Among\"[22395] (p=0.033, logit=18.000)', '\" The\"[578] (p=0.033, logit=18.000)', '\" d\"[294] (p=0.012, logit=17.000)', '\" Option\"[7104] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.8671875, logit=21.25, token_id=71264, metadata=None))), (14937, (24, PredictedToken(token=' Ash', prob=0.0004787445068359375, logit=13.75, token_id=14937, metadata=None))), (87213, (38, PredictedToken(token=' Oven', prob=0.00018787384033203125, logit=12.8125, token_id=87213, metadata=None))), (41785, (44, PredictedToken(token=' Spin', prob=0.00012874603271484375, logit=12.4375, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:43 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.941, logit=23.625)', '\" An\"[1556] (p=0.020, logit=19.750)', '\" The\"[578] (p=0.015, logit=19.500)', '\" Among\"[22395] (p=0.007, logit=18.750)', '\" ank\"[71572] (p=0.006, logit=18.625)']\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     clean_prediction=['\" Desk\"[39794] (p=0.801, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" A\"[362] (p=0.035, logit=18.250)', '\" Among\"[22395] (p=0.024, logit=17.875)', '\" It\"[1102] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     clean_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.80078125, logit=21.375, token_id=39794, metadata=None))), (58600, (7, PredictedToken(token=' Charm', prob=0.006103515625, logit=16.5, token_id=58600, metadata=None))), (39247, (99, PredictedToken(token=' Slow', prob=3.8623809814453125e-05, logit=11.4375, token_id=39247, metadata=None)))])\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.365, logit=18.250)', '\" Among\"[22395] (p=0.152, logit=17.375)', '\" None\"[2290] (p=0.092, logit=16.875)', '\" The\"[578] (p=0.092, logit=16.875)', '\" Charm\"[58600] (p=0.044, logit=16.125)']\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     int_track=OrderedDict([(58600, (5, PredictedToken(token=' Charm', prob=0.043701171875, logit=16.125, token_id=58600, metadata=None))), (39794, (22, PredictedToken(token=' Desk', prob=0.002960205078125, logit=13.4375, token_id=39794, metadata=None))), (39247, (54, PredictedToken(token=' Slow', prob=0.000621795654296875, logit=11.875, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:43 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     patch_prediction=['\" Marker\"[40975] (p=0.871, logit=22.250)', '\" The\"[578] (p=0.043, logit=19.250)', '\" A\"[362] (p=0.034, logit=19.000)', '\" Among\"[22395] (p=0.021, logit=18.500)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.734, logit=22.125)', '\" The\"[578] (p=0.087, logit=20.000)', '\" A\"[362] (p=0.087, logit=20.000)', '\" Among\"[22395] (p=0.032, logit=19.000)', '\" Binder\"[91263] (p=0.022, logit=18.625)']\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.734375, logit=22.125, token_id=34785, metadata=None))), (91263, (5, PredictedToken(token=' Binder', prob=0.0220947265625, logit=18.625, token_id=91263, metadata=None))), (15429, (38, PredictedToken(token=' Hospital', prob=0.00021648406982421875, logit=14.0, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     int_prediction=['\" Binder\"[91263] (p=0.949, logit=23.000)', '\" The\"[578] (p=0.015, logit=18.875)', '\" Among\"[22395] (p=0.011, logit=18.500)', '\" A\"[362] (p=0.009, logit=18.375)', '\" Option\"[7104] (p=0.002, logit=16.875)']\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     int_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.94921875, logit=23.0, token_id=91263, metadata=None))), (15429, (7, PredictedToken(token=' Hospital', prob=0.00098419189453125, logit=16.125, token_id=15429, metadata=None))), (34785, (36, PredictedToken(token=' Truck', prob=7.581710815429688e-05, logit=13.5625, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:44 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:44 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.785, logit=22.250)', '\" The\"[578] (p=0.083, logit=20.000)', '\" A\"[362] (p=0.083, logit=20.000)', '\" Among\"[22395] (p=0.016, logit=18.375)', '\" Tow\"[41493] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:41:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.641, logit=20.000)', '\" None\"[2290] (p=0.208, logit=18.875)', '\" A\"[362] (p=0.025, logit=16.750)', '\" Tie\"[59825] (p=0.017, logit=16.375)', '\" The\"[578] (p=0.017, logit=16.375)']\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.640625, logit=20.0, token_id=23262, metadata=None))), (59825, (5, PredictedToken(token=' Tie', prob=0.01708984375, logit=16.375, token_id=59825, metadata=None))), (86460, (7, PredictedToken(token=' Necklace', prob=0.005889892578125, logit=15.3125, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.516, logit=19.750)', '\" None\"[2290] (p=0.216, logit=18.875)', '\" Comb\"[23262] (p=0.131, logit=18.375)', '\" The\"[578] (p=0.023, logit=16.625)', '\" A\"[362] (p=0.018, logit=16.375)']\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.515625, logit=19.75, token_id=59825, metadata=None))), (23262, (3, PredictedToken(token=' Comb', prob=0.130859375, logit=18.375, token_id=23262, metadata=None))), (86460, (7, PredictedToken(token=' Necklace', prob=0.00946044921875, logit=15.75, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:45 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.754, logit=22.125)', '\" The\"[578] (p=0.070, logit=19.750)', '\" A\"[362] (p=0.070, logit=19.750)', '\" Among\"[22395] (p=0.048, logit=19.375)', '\" Iris\"[66821] (p=0.023, logit=18.625)']\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     clean_prediction=['\" Tul\"[43316] (p=0.773, logit=20.625)', '\" The\"[578] (p=0.082, logit=18.375)', '\" Among\"[22395] (p=0.044, logit=17.750)', '\" A\"[362] (p=0.023, logit=17.125)', '\" Option\"[7104] (p=0.016, logit=16.750)']\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     clean_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.7734375, logit=20.625, token_id=43316, metadata=None))), (48471, (23, PredictedToken(token=' Shower', prob=0.000904083251953125, logit=13.875, token_id=48471, metadata=None))), (29625, (35, PredictedToken(token=' Chain', prob=0.000484466552734375, logit=13.25, token_id=29625, metadata=None))), (58403, (59, PredictedToken(token=' Tablet', prob=0.00014781951904296875, logit=12.0625, token_id=58403, metadata=None))), (96096, (1488, PredictedToken(token=' Dolphin', prob=7.301568984985352e-07, logit=6.75, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     int_prediction=['\" Chain\"[29625] (p=0.459, logit=19.250)', '\" Tul\"[43316] (p=0.169, logit=18.250)', '\" The\"[578] (p=0.103, logit=17.750)', '\" Among\"[22395] (p=0.055, logit=17.125)', '\" Option\"[7104] (p=0.038, logit=16.750)']\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     int_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.458984375, logit=19.25, token_id=29625, metadata=None))), (43316, (2, PredictedToken(token=' Tul', prob=0.1689453125, logit=18.25, token_id=43316, metadata=None))), (58403, (6, PredictedToken(token=' Tablet', prob=0.033203125, logit=16.625, token_id=58403, metadata=None))), (48471, (38, PredictedToken(token=' Shower', prob=0.000942230224609375, logit=13.0625, token_id=48471, metadata=None))), (96096, (295, PredictedToken(token=' Dolphin', prob=1.519918441772461e-05, logit=8.9375, token_id=96096, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:45 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:41:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.660, logit=21.250)', '\" An\"[1556] (p=0.115, logit=19.500)', '\" The\"[578] (p=0.102, logit=19.375)', '\" Among\"[22395] (p=0.070, logit=19.000)', '\" A\"[362] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.789, logit=21.500)', '\" The\"[578] (p=0.073, logit=19.125)', '\" A\"[362] (p=0.065, logit=19.000)', '\" Among\"[22395] (p=0.024, logit=18.000)', '\" BAT\"[79081] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.7890625, logit=21.5, token_id=16488, metadata=None))), (22410, (13, PredictedToken(token=' Ju', prob=0.0011138916015625, logit=14.9375, token_id=22410, metadata=None))), (356, (17, PredictedToken(token=' C', prob=0.000865936279296875, logit=14.6875, token_id=356, metadata=None))), (74574, (370, PredictedToken(token=' Violet', prob=2.294778823852539e-06, logit=8.75, token_id=74574, metadata=None))), (47759, (378, PredictedToken(token=' Guitar', prob=2.1457672119140625e-06, logit=8.6875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     int_prediction=['\" Ju\"[22410] (p=0.543, logit=19.750)', '\" The\"[578] (p=0.155, logit=18.500)', '\" Among\"[22395] (p=0.121, logit=18.250)', '\" A\"[362] (p=0.057, logit=17.500)', '\" It\"[1102] (p=0.016, logit=16.250)']\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     int_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.54296875, logit=19.75, token_id=22410, metadata=None))), (356, (15, PredictedToken(token=' C', prob=0.0032196044921875, logit=14.625, token_id=356, metadata=None))), (74574, (187, PredictedToken(token=' Violet', prob=2.4557113647460938e-05, logit=9.75, token_id=74574, metadata=None))), (16488, (294, PredictedToken(token=' Bat', prob=1.1622905731201172e-05, logit=9.0, token_id=16488, metadata=None))), (47759, (507, PredictedToken(token=' Guitar', prob=4.559755325317383e-06, logit=8.0625, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:46 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     patch_prediction=['\" Chain\"[29625] (p=0.910, logit=22.875)', '\" The\"[578] (p=0.027, logit=19.375)', '\" A\"[362] (p=0.021, logit=19.125)', '\" None\"[2290] (p=0.011, logit=18.500)', '\" Among\"[22395] (p=0.010, logit=18.375)']\n",
      "2025-09-16 09:41:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.707, logit=21.875)', '\" The\"[578] (p=0.108, logit=20.000)', '\" A\"[362] (p=0.084, logit=19.750)', '\" Among\"[22395] (p=0.045, logit=19.125)', '\" It\"[1102] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.70703125, logit=21.875, token_id=12369, metadata=None))), (445, (14, PredictedToken(token=' L', prob=0.00093841552734375, logit=15.25, token_id=445, metadata=None))), (6914, (17, PredictedToken(token=' Let', prob=0.000881195068359375, logit=15.1875, token_id=6914, metadata=None))), (6690, (23, PredictedToken(token=' Air', prob=0.000728607177734375, logit=15.0, token_id=6690, metadata=None))), (33711, (26, PredictedToken(token=' Suit', prob=0.000568389892578125, logit=14.75, token_id=33711, metadata=None)))])\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.730, logit=21.625)', '\" Among\"[22395] (p=0.099, logit=19.625)', '\" The\"[578] (p=0.077, logit=19.375)', '\" A\"[362] (p=0.032, logit=18.500)', '\" It\"[1102] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.73046875, logit=21.625, token_id=445, metadata=None))), (33711, (13, PredictedToken(token=' Suit', prob=0.00159454345703125, logit=15.5, token_id=33711, metadata=None))), (6914, (24, PredictedToken(token=' Let', prob=0.00058746337890625, logit=14.5, token_id=6914, metadata=None))), (6690, (162, PredictedToken(token=' Air', prob=8.940696716308594e-06, logit=10.3125, token_id=6690, metadata=None))), (12369, (285, PredictedToken(token=' Food', prob=2.8908252716064453e-06, logit=9.1875, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:47 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.879, logit=21.750)', '\" The\"[578] (p=0.056, logit=19.000)', '\" A\"[362] (p=0.018, logit=17.875)', '\" Among\"[22395] (p=0.008, logit=17.000)', '\" None\"[2290] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.789, logit=22.750)', '\" The\"[578] (p=0.121, logit=20.875)', '\" An\"[1556] (p=0.031, logit=19.500)', '\" Among\"[22395] (p=0.024, logit=19.250)', '\" Accord\"[80657] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.7890625, logit=22.75, token_id=11683, metadata=None))), (33711, (47, PredictedToken(token=' Suit', prob=6.723403930664062e-05, logit=13.375, token_id=33711, metadata=None))), (97796, (249, PredictedToken(token=' Skate', prob=2.16066837310791e-06, logit=9.9375, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:41:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.738, logit=21.625)', '\" The\"[578] (p=0.128, logit=19.875)', '\" Among\"[22395] (p=0.032, logit=18.500)', '\" Suit\"[33711] (p=0.025, logit=18.250)', '\" A\"[362] (p=0.025, logit=18.250)']\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.73828125, logit=21.625, token_id=97796, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.0252685546875, logit=18.25, token_id=33711, metadata=None))), (11683, (6, PredictedToken(token=' Acc', prob=0.006378173828125, logit=16.875, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:48 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:48 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     patch_prediction=['\" Necklace\"[86460] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.075, logit=19.500)', '\" A\"[362] (p=0.046, logit=19.000)', '\" Among\"[22395] (p=0.036, logit=18.750)', '\" necklace\"[55547] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.828, logit=20.625)', '\" None\"[2290] (p=0.036, logit=17.500)', '\" The\"[578] (p=0.028, logit=17.250)', '\" Micro\"[18654] (p=0.022, logit=17.000)', '\" Among\"[22395] (p=0.010, logit=16.250)']\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.828125, logit=20.625, token_id=67629, metadata=None))), (18654, (4, PredictedToken(token=' Micro', prob=0.0220947265625, logit=17.0, token_id=18654, metadata=None))), (58600, (6, PredictedToken(token=' Charm', prob=0.00811767578125, logit=16.0, token_id=58600, metadata=None))), (6914, (18, PredictedToken(token=' Let', prob=0.00124359130859375, logit=14.125, token_id=6914, metadata=None))), (36943, (110, PredictedToken(token=' Folder', prob=4.839897155761719e-05, logit=10.875, token_id=36943, metadata=None))), (17367, (163, PredictedToken(token=' Factory', prob=2.4318695068359375e-05, logit=10.1875, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.762, logit=20.125)', '\" None\"[2290] (p=0.150, logit=18.500)', '\" Among\"[22395] (p=0.018, logit=16.375)', '\" The\"[578] (p=0.012, logit=16.000)', '\" none\"[7000] (p=0.007, logit=15.500)']\n",
      "2025-09-16 09:41:48 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.76171875, logit=20.125, token_id=6914, metadata=None))), (58600, (6, PredictedToken(token=' Charm', prob=0.005828857421875, logit=15.25, token_id=58600, metadata=None))), (18654, (9, PredictedToken(token=' Micro', prob=0.00189208984375, logit=14.125, token_id=18654, metadata=None))), (67629, (33, PredictedToken(token=' Helmet', prob=0.0003719329833984375, logit=12.5, token_id=67629, metadata=None))), (36943, (41, PredictedToken(token=' Folder', prob=0.000255584716796875, logit=12.125, token_id=36943, metadata=None))), (17367, (1228, PredictedToken(token=' Factory', prob=8.67992639541626e-07, logit=6.4375, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:49 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:49 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     patch_prediction=['\" Calculator\"[37128] (p=0.668, logit=21.125)', '\" A\"[362] (p=0.131, logit=19.500)', '\" The\"[578] (p=0.102, logit=19.250)', '\" None\"[2290] (p=0.018, logit=17.500)', '\" Among\"[22395] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.918, logit=22.500)', '\" The\"[578] (p=0.022, logit=18.750)', '\" A\"[362] (p=0.012, logit=18.125)', '\" Among\"[22395] (p=0.010, logit=18.000)', '\" Option\"[7104] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.91796875, logit=22.5, token_id=27738, metadata=None))), (393, (7, PredictedToken(token=' P', prob=0.003753662109375, logit=17.0, token_id=393, metadata=None))), (55807, (15, PredictedToken(token=' Shirt', prob=0.00078582763671875, logit=15.4375, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     int_prediction=['\" P\"[393] (p=0.730, logit=22.250)', '\" Shirt\"[55807] (p=0.185, logit=20.875)', '\" A\"[362] (p=0.025, logit=18.875)', '\" The\"[578] (p=0.020, logit=18.625)', '\" Among\"[22395] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     int_track=OrderedDict([(393, (1, PredictedToken(token=' P', prob=0.73046875, logit=22.25, token_id=393, metadata=None))), (55807, (2, PredictedToken(token=' Shirt', prob=0.1845703125, logit=20.875, token_id=55807, metadata=None))), (27738, (163, PredictedToken(token=' Ward', prob=6.139278411865234e-06, logit=10.5625, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:49 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:41:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.934, logit=21.250)', '\" The\"[578] (p=0.019, logit=17.375)', '\" A\"[362] (p=0.006, logit=16.250)', '\" Among\"[22395] (p=0.005, logit=15.938)', '\" It\"[1102] (p=0.003, logit=15.625)']\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.664, logit=21.875)', '\" The\"[578] (p=0.148, logit=20.375)', '\" A\"[362] (p=0.080, logit=19.750)', '\" Among\"[22395] (p=0.070, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.6640625, logit=21.875, token_id=8219, metadata=None))), (57915, (40, PredictedToken(token=' Ank', prob=0.00019741058349609375, logit=13.75, token_id=57915, metadata=None))), (2522, (43, PredictedToken(token=' Sc', prob=0.00015354156494140625, logit=13.5, token_id=2522, metadata=None))), (20423, (68, PredictedToken(token=' Amb', prob=4.38690185546875e-05, logit=12.25, token_id=20423, metadata=None))), (15429, (210, PredictedToken(token=' Hospital', prob=4.351139068603516e-06, logit=9.9375, token_id=15429, metadata=None))), (12369, (255, PredictedToken(token=' Food', prob=2.995133399963379e-06, logit=9.5625, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     int_prediction=['\" Sc\"[2522] (p=0.412, logit=21.000)', '\" Food\"[12369] (p=0.363, logit=20.875)', '\" The\"[578] (p=0.092, logit=19.500)', '\" Among\"[22395] (p=0.038, logit=18.625)', '\" Ank\"[57915] (p=0.021, logit=18.000)']\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     int_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.412109375, logit=21.0, token_id=2522, metadata=None))), (12369, (2, PredictedToken(token=' Food', prob=0.36328125, logit=20.875, token_id=12369, metadata=None))), (57915, (5, PredictedToken(token=' Ank', prob=0.0205078125, logit=18.0, token_id=57915, metadata=None))), (15429, (6, PredictedToken(token=' Hospital', prob=0.01409912109375, logit=17.625, token_id=15429, metadata=None))), (20423, (16, PredictedToken(token=' Amb', prob=0.00139617919921875, logit=15.3125, token_id=20423, metadata=None))), (8219, (412, PredictedToken(token=' Sun', prob=1.735985279083252e-06, logit=8.625, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:50 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:50 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.902, logit=21.500)', '\" The\"[578] (p=0.024, logit=17.875)', '\" A\"[362] (p=0.017, logit=17.500)', '\" Among\"[22395] (p=0.011, logit=17.125)', '\" school\"[2978] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.652, logit=20.750)', '\" The\"[578] (p=0.165, logit=19.375)', '\" Among\"[22395] (p=0.069, logit=18.500)', '\" A\"[362] (p=0.037, logit=17.875)', '\" It\"[1102] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.65234375, logit=20.75, token_id=94467, metadata=None))), (79189, (42, PredictedToken(token=' Elephant', prob=0.00023365020751953125, logit=12.8125, token_id=79189, metadata=None))), (38930, (57, PredictedToken(token=' Bike', prob=0.00010347366333007812, logit=12.0, token_id=38930, metadata=None))), (15429, (389, PredictedToken(token=' Hospital', prob=3.3229589462280273e-06, logit=8.5625, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:41:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     int_prediction=['\" Hospital\"[15429] (p=0.836, logit=22.125)', '\" The\"[578] (p=0.061, logit=19.500)', '\" Among\"[22395] (p=0.042, logit=19.125)', '\" Option\"[7104] (p=0.010, logit=17.750)', '\" A\"[362] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     int_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.8359375, logit=22.125, token_id=15429, metadata=None))), (38930, (9, PredictedToken(token=' Bike', prob=0.002655029296875, logit=16.375, token_id=38930, metadata=None))), (79189, (17, PredictedToken(token=' Elephant', prob=0.000919342041015625, logit=15.3125, token_id=79189, metadata=None))), (94467, (1646, PredictedToken(token=' Trom', prob=1.7601996660232544e-07, logit=6.75, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:51 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:51 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.820, logit=20.750)', '\" None\"[2290] (p=0.060, logit=18.125)', '\" Mall\"[32498] (p=0.025, logit=17.250)', '\" The\"[578] (p=0.015, logit=16.750)', '\" (\"[320] (p=0.012, logit=16.500)']\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     clean_prediction=['\" Mouse\"[18191] (p=0.914, logit=22.625)', '\" The\"[578] (p=0.028, logit=19.125)', '\" A\"[362] (p=0.019, logit=18.750)', '\" mouse\"[8814] (p=0.008, logit=17.875)', '\" Among\"[22395] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     clean_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.9140625, logit=22.625, token_id=18191, metadata=None))), (1050, (16, PredictedToken(token=' Re', prob=0.0004749298095703125, logit=15.0625, token_id=1050, metadata=None))), (52882, (25, PredictedToken(token=' Pepper', prob=0.0002384185791015625, logit=14.375, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.871, logit=21.875)', '\" Among\"[22395] (p=0.030, logit=18.500)', '\" The\"[578] (p=0.026, logit=18.375)', '\" pepper\"[25349] (p=0.018, logit=18.000)', '\" None\"[2290] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.87109375, logit=21.875, token_id=52882, metadata=None))), (1050, (10, PredictedToken(token=' Re', prob=0.00244140625, logit=16.0, token_id=1050, metadata=None))), (18191, (41, PredictedToken(token=' Mouse', prob=0.00013828277587890625, logit=13.125, token_id=18191, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:51 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     patch_prediction=['\" Train\"[27217] (p=0.703, logit=22.000)', '\" The\"[578] (p=0.122, logit=20.250)', '\" A\"[362] (p=0.084, logit=19.875)', '\" Among\"[22395] (p=0.051, logit=19.375)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.840, logit=21.375)', '\" The\"[578] (p=0.042, logit=18.375)', '\" A\"[362] (p=0.029, logit=18.000)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" D\"[423] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.83984375, logit=21.375, token_id=47033, metadata=None))), (423, (5, PredictedToken(token=' D', prob=0.01055908203125, logit=17.0, token_id=423, metadata=None))), (40759, (14, PredictedToken(token=' Harmon', prob=0.00142669677734375, logit=15.0, token_id=40759, metadata=None))), (17929, (16, PredictedToken(token=' Pin', prob=0.00118255615234375, logit=14.8125, token_id=17929, metadata=None))), (36358, (21, PredictedToken(token=' Bench', prob=0.000675201416015625, logit=14.25, token_id=36358, metadata=None))), (70762, (34, PredictedToken(token=' Motorcycle', prob=0.000362396240234375, logit=13.625, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.695, logit=20.500)', '\" Motorcycle\"[70762] (p=0.137, logit=18.875)', '\" None\"[2290] (p=0.034, logit=17.500)', '\" Among\"[22395] (p=0.027, logit=17.250)', '\" The\"[578] (p=0.027, logit=17.250)']\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.6953125, logit=20.5, token_id=36358, metadata=None))), (70762, (2, PredictedToken(token=' Motorcycle', prob=0.13671875, logit=18.875, token_id=70762, metadata=None))), (423, (7, PredictedToken(token=' D', prob=0.004669189453125, logit=15.5, token_id=423, metadata=None))), (17929, (67, PredictedToken(token=' Pin', prob=0.00012493133544921875, logit=11.875, token_id=17929, metadata=None))), (47033, (81, PredictedToken(token=' Printer', prob=8.058547973632812e-05, logit=11.4375, token_id=47033, metadata=None))), (40759, (170, PredictedToken(token=' Harmon', prob=1.800060272216797e-05, logit=9.9375, token_id=40759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:52 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:52 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     patch_prediction=['\" Speaker\"[30173] (p=0.840, logit=21.625)', '\" The\"[578] (p=0.037, logit=18.500)', '\" A\"[362] (p=0.029, logit=18.250)', '\" speaker\"[19114] (p=0.022, logit=18.000)', '\" (\"[320] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.871, logit=23.125)', '\" The\"[578] (p=0.056, logit=20.375)', '\" Among\"[22395] (p=0.034, logit=19.875)', '\" A\"[362] (p=0.016, logit=19.125)', '\" socks\"[40086] (p=0.004, logit=17.750)']\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.87109375, logit=23.125, token_id=328, metadata=None))), (11452, (9, PredictedToken(token=' Head', prob=0.00148773193359375, logit=16.75, token_id=11452, metadata=None))), (34046, (306, PredictedToken(token=' Cabinet', prob=8.754432201385498e-07, logit=9.3125, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:41:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     int_prediction=['\" Head\"[11452] (p=0.891, logit=23.000)', '\" The\"[578] (p=0.057, logit=20.250)', '\" Among\"[22395] (p=0.021, logit=19.250)', '\" headphones\"[44101] (p=0.005, logit=17.750)', '\" It\"[1102] (p=0.004, logit=17.500)']\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     int_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.890625, logit=23.0, token_id=11452, metadata=None))), (34046, (7, PredictedToken(token=' Cabinet', prob=0.00250244140625, logit=17.125, token_id=34046, metadata=None))), (328, (33, PredictedToken(token=' S', prob=0.000141143798828125, logit=14.25, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:53 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:53 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.848, logit=22.125)', '\" The\"[578] (p=0.070, logit=19.625)', '\" Among\"[22395] (p=0.026, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.625)', '\" (\"[320] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.816, logit=22.000)', '\" The\"[578] (p=0.086, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=18.875)', '\" A\"[362] (p=0.015, logit=18.000)', '\" Option\"[7104] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.81640625, logit=22.0, token_id=60413, metadata=None))), (30558, (24, PredictedToken(token=' Ki', prob=0.0003299713134765625, logit=14.1875, token_id=30558, metadata=None))), (1443, (167, PredictedToken(token=' Sh', prob=7.3015689849853516e-06, logit=10.375, token_id=1443, metadata=None))), (82452, (362, PredictedToken(token=' Jasmine', prob=1.6316771507263184e-06, logit=8.875, token_id=82452, metadata=None)))])\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.836, logit=21.500)', '\" The\"[578] (p=0.053, logit=18.750)', '\" Among\"[22395] (p=0.042, logit=18.500)', '\" Option\"[7104] (p=0.011, logit=17.125)', '\" (\"[320] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.8359375, logit=21.5, token_id=82452, metadata=None))), (30558, (19, PredictedToken(token=' Ki', prob=0.000812530517578125, logit=14.5625, token_id=30558, metadata=None))), (1443, (37, PredictedToken(token=' Sh', prob=0.0002803802490234375, logit=13.5, token_id=1443, metadata=None))), (60413, (1650, PredictedToken(token=' Uk', prob=2.812594175338745e-07, logit=6.59375, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:53 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.629, logit=20.750)', '\" Comb\"[23262] (p=0.203, logit=19.625)', '\" An\"[1556] (p=0.040, logit=18.000)', '\" The\"[578] (p=0.028, logit=17.625)', '\" Among\"[22395] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     clean_prediction=['\" Shower\"[48471] (p=0.602, logit=20.750)', '\" The\"[578] (p=0.151, logit=19.375)', '\" A\"[362] (p=0.118, logit=19.125)', '\" Among\"[22395] (p=0.056, logit=18.375)', '\" SH\"[6570] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     clean_track=OrderedDict([(48471, (1, PredictedToken(token=' Shower', prob=0.6015625, logit=20.75, token_id=48471, metadata=None))), (63606, (24, PredictedToken(token=' Stap', prob=0.0009002685546875, logit=14.25, token_id=63606, metadata=None))), (20423, (37, PredictedToken(token=' Amb', prob=0.0003757476806640625, logit=13.375, token_id=20423, metadata=None)))])\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.785, logit=21.125)', '\" The\"[578] (p=0.073, logit=18.750)', '\" A\"[362] (p=0.050, logit=18.375)', '\" Among\"[22395] (p=0.024, logit=17.625)', '\" Amb\"[20423] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.78515625, logit=21.125, token_id=63606, metadata=None))), (20423, (5, PredictedToken(token=' Amb', prob=0.0098876953125, logit=16.75, token_id=20423, metadata=None))), (48471, (35, PredictedToken(token=' Shower', prob=0.000339508056640625, logit=13.375, token_id=48471, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:54 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:41:54 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     patch_prediction=['\" Swe\"[37326] (p=0.738, logit=21.375)', '\" The\"[578] (p=0.088, logit=19.250)', '\" A\"[362] (p=0.078, logit=19.125)', '\" Among\"[22395] (p=0.042, logit=18.500)', '\" sweater\"[61221] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.867, logit=22.375)', '\" The\"[578] (p=0.043, logit=19.375)', '\" A\"[362] (p=0.034, logit=19.125)', '\" Among\"[22395] (p=0.018, logit=18.500)', '\" chain\"[8957] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.8671875, logit=22.375, token_id=29625, metadata=None))), (6914, (16, PredictedToken(token=' Let', prob=0.000743865966796875, logit=15.3125, token_id=6914, metadata=None))), (29318, (67, PredictedToken(token=' Dress', prob=4.744529724121094e-05, logit=12.5625, token_id=29318, metadata=None))), (11896, (98, PredictedToken(token=' Library', prob=1.9788742065429688e-05, logit=11.6875, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.797, logit=21.625)', '\" The\"[578] (p=0.058, logit=19.000)', '\" Among\"[22395] (p=0.027, logit=18.250)', '\" Library\"[11896] (p=0.024, logit=18.125)', '\" Let\"[6914] (p=0.021, logit=18.000)']\n",
      "2025-09-16 09:41:54 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.796875, logit=21.625, token_id=29318, metadata=None))), (11896, (4, PredictedToken(token=' Library', prob=0.0240478515625, logit=18.125, token_id=11896, metadata=None))), (6914, (5, PredictedToken(token=' Let', prob=0.021240234375, logit=18.0, token_id=6914, metadata=None))), (29625, (81, PredictedToken(token=' Chain', prob=5.602836608886719e-05, logit=12.0625, token_id=29625, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:55 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.750, logit=21.875)', '\" The\"[578] (p=0.079, logit=19.625)', '\" A\"[362] (p=0.070, logit=19.500)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" It\"[1102] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.836, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.042, logit=19.250)', '\" A\"[362] (p=0.017, logit=18.375)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.8359375, logit=22.25, token_id=15883, metadata=None))), (469, (21, PredictedToken(token=' E', prob=0.0003833770751953125, logit=14.5625, token_id=469, metadata=None))), (16147, (47, PredictedToken(token=' Smart', prob=8.058547973632812e-05, logit=13.0, token_id=16147, metadata=None))), (61731, (75, PredictedToken(token=' Soap', prob=3.790855407714844e-05, logit=12.25, token_id=61731, metadata=None))), (29318, (993, PredictedToken(token=' Dress', prob=3.6135315895080566e-07, logit=7.59375, token_id=29318, metadata=None))), (61948, (1596, PredictedToken(token=' Sofa', prob=1.9371509552001953e-07, logit=6.96875, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.812, logit=22.500)', '\" An\"[1556] (p=0.075, logit=20.125)', '\" The\"[578] (p=0.052, logit=19.750)', '\" Among\"[22395] (p=0.017, logit=18.625)', '\" e\"[384] (p=0.012, logit=18.250)']\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.8125, logit=22.5, token_id=469, metadata=None))), (29318, (9, PredictedToken(token=' Dress', prob=0.0025787353515625, logit=16.75, token_id=29318, metadata=None))), (61731, (14, PredictedToken(token=' Soap', prob=0.001007080078125, logit=15.8125, token_id=61731, metadata=None))), (16147, (33, PredictedToken(token=' Smart', prob=0.00013637542724609375, logit=13.8125, token_id=16147, metadata=None))), (15883, (35, PredictedToken(token=' Spr', prob=0.00011348724365234375, logit=13.625, token_id=15883, metadata=None))), (61948, (132, PredictedToken(token=' Sofa', prob=7.241964340209961e-06, logit=10.875, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:41:55 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:41:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     patch_prediction=['\" Bike\"[38930] (p=0.777, logit=22.000)', '\" The\"[578] (p=0.082, logit=19.750)', '\" Among\"[22395] (p=0.056, logit=19.375)', '\" A\"[362] (p=0.039, logit=19.000)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.828, logit=22.250)', '\" The\"[578] (p=0.060, logit=19.625)', '\" A\"[362] (p=0.060, logit=19.625)', '\" Among\"[22395] (p=0.020, logit=18.500)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.828125, logit=22.25, token_id=27738, metadata=None))), (36943, (25, PredictedToken(token=' Folder', prob=0.0003147125244140625, logit=14.375, token_id=36943, metadata=None))), (2057, (37, PredictedToken(token=' To', prob=0.0001239776611328125, logit=13.4375, token_id=2057, metadata=None))), (3341, (69, PredictedToken(token=' Car', prob=3.314018249511719e-05, logit=12.125, token_id=3341, metadata=None))), (47589, (281, PredictedToken(token=' Basketball', prob=1.996755599975586e-06, logit=9.3125, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.871, logit=22.750)', '\" The\"[578] (p=0.043, logit=19.750)', '\" Among\"[22395] (p=0.026, logit=19.250)', '\" A\"[362] (p=0.021, logit=19.000)', '\" Car\"[3341] (p=0.007, logit=17.875)']\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.87109375, logit=22.75, token_id=47589, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.00665283203125, logit=17.875, token_id=3341, metadata=None))), (2057, (30, PredictedToken(token=' To', prob=0.0002002716064453125, logit=14.375, token_id=2057, metadata=None))), (27738, (927, PredictedToken(token=' Ward', prob=2.738088369369507e-07, logit=7.78125, token_id=27738, metadata=None))), (36943, (1217, PredictedToken(token=' Folder', prob=1.8905848264694214e-07, logit=7.40625, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:56 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:56 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.938, logit=22.750)', '\" The\"[578] (p=0.017, logit=18.750)', '\" Among\"[22395] (p=0.009, logit=18.125)', '\" blue\"[6437] (p=0.006, logit=17.625)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.957, logit=23.000)', '\" The\"[578] (p=0.015, logit=18.875)', '\" Among\"[22395] (p=0.009, logit=18.375)', '\" violet\"[80836] (p=0.003, logit=17.125)', '\" Option\"[7104] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.95703125, logit=23.0, token_id=74574, metadata=None))), (10164, (36, PredictedToken(token=' Water', prob=7.152557373046875e-05, logit=13.5, token_id=10164, metadata=None))), (65197, (117, PredictedToken(token=' Surf', prob=5.513429641723633e-06, logit=10.9375, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:41:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.766, logit=21.375)', '\" Surf\"[65197] (p=0.063, logit=18.875)', '\" None\"[2290] (p=0.063, logit=18.875)', '\" Among\"[22395] (p=0.030, logit=18.125)', '\" The\"[578] (p=0.026, logit=18.000)']\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.765625, logit=21.375, token_id=10164, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.06298828125, logit=18.875, token_id=65197, metadata=None))), (74574, (322, PredictedToken(token=' Violet', prob=3.4421682357788086e-06, logit=9.0625, token_id=74574, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:57 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:57 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     patch_prediction=['\" Necklace\"[86460] (p=0.871, logit=23.000)', '\" The\"[578] (p=0.056, logit=20.250)', '\" A\"[362] (p=0.038, logit=19.875)', '\" Among\"[22395] (p=0.014, logit=18.875)', '\" It\"[1102] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     clean_prediction=['\" Magn\"[20918] (p=0.867, logit=22.000)', '\" The\"[578] (p=0.038, logit=18.875)', '\" A\"[362] (p=0.023, logit=18.375)', '\" Among\"[22395] (p=0.016, logit=18.000)', '\" Option\"[7104] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     clean_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.8671875, logit=22.0, token_id=20918, metadata=None))), (426, (17, PredictedToken(token=' B', prob=0.00054168701171875, logit=14.625, token_id=426, metadata=None))), (34046, (72, PredictedToken(token=' Cabinet', prob=3.4809112548828125e-05, logit=11.875, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.852, logit=22.000)', '\" The\"[578] (p=0.029, logit=18.625)', '\" b\"[293] (p=0.029, logit=18.625)', '\" A\"[362] (p=0.020, logit=18.250)', '\" Option\"[7104] (p=0.018, logit=18.125)']\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.8515625, logit=22.0, token_id=426, metadata=None))), (34046, (9, PredictedToken(token=' Cabinet', prob=0.003936767578125, logit=16.625, token_id=34046, metadata=None))), (20918, (32, PredictedToken(token=' Magn', prob=0.00025177001953125, logit=13.875, token_id=20918, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:41:57 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:41:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.859, logit=22.375)', '\" A\"[362] (p=0.055, logit=19.625)', '\" The\"[578] (p=0.049, logit=19.500)', '\" Among\"[22395] (p=0.014, logit=18.250)', '\" MOS\"[74174] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.730, logit=21.750)', '\" The\"[578] (p=0.087, logit=19.625)', '\" A\"[362] (p=0.087, logit=19.625)', '\" Among\"[22395] (p=0.047, logit=19.000)', '\" tractor\"[59785] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.73046875, logit=21.75, token_id=1183, metadata=None))), (469, (12, PredictedToken(token=' E', prob=0.0021820068359375, logit=15.9375, token_id=469, metadata=None))), (24423, (76, PredictedToken(token=' Monitor', prob=4.5299530029296875e-05, logit=12.0625, token_id=24423, metadata=None))), (14588, (236, PredictedToken(token=' Dog', prob=3.9637088775634766e-06, logit=9.625, token_id=14588, metadata=None))), (38673, (420, PredictedToken(token=' Yoga', prob=1.1324882507324219e-06, logit=8.375, token_id=38673, metadata=None))), (9441, (624, PredictedToken(token=' Church', prob=6.444752216339111e-07, logit=7.8125, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.562, logit=21.750)', '\" E\"[469] (p=0.206, logit=20.750)', '\" The\"[578] (p=0.110, logit=20.125)', '\" Among\"[22395] (p=0.052, logit=19.375)', '\" A\"[362] (p=0.022, logit=18.500)']\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.5625, logit=21.75, token_id=9441, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.2060546875, logit=20.75, token_id=469, metadata=None))), (14588, (48, PredictedToken(token=' Dog', prob=0.0001373291015625, logit=13.4375, token_id=14588, metadata=None))), (38673, (253, PredictedToken(token=' Yoga', prob=3.039836883544922e-06, logit=9.625, token_id=38673, metadata=None))), (1183, (286, PredictedToken(token=' Tr', prob=2.3692846298217773e-06, logit=9.375, token_id=1183, metadata=None))), (24423, (573, PredictedToken(token=' Monitor', prob=7.227063179016113e-07, logit=8.1875, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:58 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:58 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.906, logit=22.625)', '\" The\"[578] (p=0.040, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=18.500)', '\" A\"[362] (p=0.013, logit=18.375)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.766, logit=23.250)', '\" An\"[1556] (p=0.134, logit=21.500)', '\" The\"[578] (p=0.049, logit=20.500)', '\" Among\"[22395] (p=0.030, logit=20.000)', '\" It\"[1102] (p=0.002, logit=17.250)']\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.765625, logit=23.25, token_id=6690, metadata=None))), (57915, (56, PredictedToken(token=' Ank', prob=3.9577484130859375e-05, logit=13.375, token_id=57915, metadata=None))), (17810, (78, PredictedToken(token=' Cat', prob=1.6450881958007812e-05, logit=12.5, token_id=17810, metadata=None)))])\n",
      "2025-09-16 09:41:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     int_prediction=['\" Cat\"[17810] (p=0.855, logit=23.000)', '\" The\"[578] (p=0.048, logit=20.125)', '\" Ank\"[57915] (p=0.033, logit=19.750)', '\" Among\"[22395] (p=0.029, logit=19.625)', '\" A\"[362] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     int_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.85546875, logit=23.0, token_id=17810, metadata=None))), (57915, (3, PredictedToken(token=' Ank', prob=0.033203125, logit=19.75, token_id=57915, metadata=None))), (6690, (250, PredictedToken(token=' Air', prob=1.5050172805786133e-06, logit=9.75, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:59 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:59 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.883, logit=22.375)', '\" The\"[578] (p=0.050, logit=19.500)', '\" A\"[362] (p=0.023, logit=18.750)', '\" dress\"[8679] (p=0.011, logit=18.000)', '\" Among\"[22395] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     clean_prediction=['\" Sheep\"[84008] (p=0.699, logit=20.875)', '\" The\"[578] (p=0.074, logit=18.625)', '\" Among\"[22395] (p=0.051, logit=18.250)', '\" sheep\"[33012] (p=0.040, logit=18.000)', '\" A\"[362] (p=0.040, logit=18.000)']\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     clean_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.69921875, logit=20.875, token_id=84008, metadata=None))), (68554, (10, PredictedToken(token=' Gloves', prob=0.004425048828125, logit=15.8125, token_id=68554, metadata=None))), (43316, (52, PredictedToken(token=' Tul', prob=0.00018310546875, logit=12.625, token_id=43316, metadata=None)))])\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.793, logit=21.125)', '\" Among\"[22395] (p=0.035, logit=18.000)', '\" Glo\"[25372] (p=0.031, logit=17.875)', '\" Option\"[7104] (p=0.031, logit=17.875)', '\" The\"[578] (p=0.024, logit=17.625)']\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.79296875, logit=21.125, token_id=68554, metadata=None))), (43316, (8, PredictedToken(token=' Tul', prob=0.0068359375, logit=16.375, token_id=43316, metadata=None))), (84008, (63, PredictedToken(token=' Sheep', prob=8.106231689453125e-05, logit=11.9375, token_id=84008, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:41:59 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:41:59 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:41:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.930, logit=22.375)', '\" (\"[320] (p=0.017, logit=18.375)', '\" The\"[578] (p=0.015, logit=18.250)', '\" Among\"[22395] (p=0.009, logit=17.750)', '\" Spr\"[15883] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     clean_prediction=['\" Desk\"[39794] (p=0.879, logit=22.625)', '\" The\"[578] (p=0.050, logit=19.750)', '\" A\"[362] (p=0.018, logit=18.750)', '\" Among\"[22395] (p=0.016, logit=18.625)', '\" (\"[320] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     clean_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.87890625, logit=22.625, token_id=39794, metadata=None))), (921, (43, PredictedToken(token=' Ch', prob=9.584426879882812e-05, logit=13.5, token_id=921, metadata=None))), (1630, (80, PredictedToken(token=' X', prob=1.8835067749023438e-05, logit=11.875, token_id=1630, metadata=None)))])\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     int_prediction=['\" Ch\"[921] (p=0.793, logit=22.125)', '\" X\"[1630] (p=0.083, logit=19.875)', '\" The\"[578] (p=0.045, logit=19.250)', '\" Among\"[22395] (p=0.019, logit=18.375)', '\" (\"[320] (p=0.016, logit=18.250)']\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     int_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.79296875, logit=22.125, token_id=921, metadata=None))), (1630, (2, PredictedToken(token=' X', prob=0.08349609375, logit=19.875, token_id=1630, metadata=None))), (39794, (3017, PredictedToken(token=' Desk', prob=5.075708031654358e-08, logit=5.5625, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:00 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:00 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     patch_prediction=['\" Orange\"[22725] (p=0.859, logit=21.750)', '\" The\"[578] (p=0.038, logit=18.625)', '\" Among\"[22395] (p=0.023, logit=18.125)', '\" An\"[1556] (p=0.018, logit=17.875)', '\" Palm\"[33578] (p=0.014, logit=17.625)']\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.875, logit=22.250)', '\" The\"[578] (p=0.043, logit=19.250)', '\" A\"[362] (p=0.038, logit=19.125)', '\" Among\"[22395] (p=0.016, logit=18.250)', '\" horse\"[15580] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.875, logit=22.25, token_id=34392, metadata=None))), (84409, (13, PredictedToken(token=' Plum', prob=0.000659942626953125, logit=15.0625, token_id=84409, metadata=None))), (70306, (35, PredictedToken(token=' Brace', prob=0.00015735626220703125, logit=13.625, token_id=70306, metadata=None))), (46506, (52, PredictedToken(token=' Drum', prob=6.532669067382812e-05, logit=12.75, token_id=46506, metadata=None))), (13000, (153, PredictedToken(token=' Van', prob=7.331371307373047e-06, logit=10.5625, token_id=13000, metadata=None))), (47643, (201, PredictedToken(token=' Cel', prob=3.933906555175781e-06, logit=9.9375, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.852, logit=22.125)', '\" Among\"[22395] (p=0.042, logit=19.125)', '\" The\"[578] (p=0.042, logit=19.125)', '\" Cel\"[47643] (p=0.018, logit=18.250)', '\" Van\"[13000] (p=0.009, logit=17.625)']\n",
      "2025-09-16 09:42:00 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.8515625, logit=22.125, token_id=84409, metadata=None))), (47643, (4, PredictedToken(token=' Cel', prob=0.0177001953125, logit=18.25, token_id=47643, metadata=None))), (13000, (5, PredictedToken(token=' Van', prob=0.00946044921875, logit=17.625, token_id=13000, metadata=None))), (70306, (8, PredictedToken(token=' Brace', prob=0.00347900390625, logit=16.625, token_id=70306, metadata=None))), (34392, (228, PredictedToken(token=' Horse', prob=3.844499588012695e-06, logit=9.8125, token_id=34392, metadata=None))), (46506, (272, PredictedToken(token=' Drum', prob=2.8014183044433594e-06, logit=9.5, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:01 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:01 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.934, logit=21.875)', '\" The\"[578] (p=0.015, logit=17.750)', '\" Drum\"[46506] (p=0.010, logit=17.375)', '\" Glo\"[25372] (p=0.007, logit=17.000)', '\" Among\"[22395] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.664, logit=20.875)', '\" The\"[578] (p=0.168, logit=19.500)', '\" Among\"[22395] (p=0.048, logit=18.250)', '\" A\"[362] (p=0.048, logit=18.250)', '\" It\"[1102] (p=0.018, logit=17.250)']\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.6640625, logit=20.875, token_id=94467, metadata=None))), (82507, (37, PredictedToken(token=' Jeans', prob=0.0003032684326171875, logit=13.1875, token_id=82507, metadata=None))), (36895, (234, PredictedToken(token=' Eagle', prob=6.735324859619141e-06, logit=9.375, token_id=36895, metadata=None))), (71264, (2497, PredictedToken(token=' Daisy', prob=2.5331974029541016e-07, logit=6.09375, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     int_prediction=['\" Jeans\"[82507] (p=0.590, logit=20.500)', '\" The\"[578] (p=0.103, logit=18.750)', '\" Among\"[22395] (p=0.090, logit=18.625)', '\" Daisy\"[71264] (p=0.038, logit=17.750)', '\" JE\"[71430] (p=0.033, logit=17.625)']\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     int_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.58984375, logit=20.5, token_id=82507, metadata=None))), (71264, (4, PredictedToken(token=' Daisy', prob=0.03759765625, logit=17.75, token_id=71264, metadata=None))), (36895, (16, PredictedToken(token=' Eagle', prob=0.0030975341796875, logit=15.25, token_id=36895, metadata=None))), (94467, (2547, PredictedToken(token=' Trom', prob=3.166496753692627e-07, logit=6.0625, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:01 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:01 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-16 09:42:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     patch_prediction=['\" Watch\"[10573] (p=0.867, logit=22.125)', '\" A\"[362] (p=0.055, logit=19.375)', '\" The\"[578] (p=0.030, logit=18.750)', '\" Among\"[22395] (p=0.010, logit=17.625)', '\" None\"[2290] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     clean_prediction=['\" Cherry\"[45805] (p=0.898, logit=21.500)', '\" The\"[578] (p=0.040, logit=18.375)', '\" Among\"[22395] (p=0.015, logit=17.375)', '\" A\"[362] (p=0.009, logit=16.875)', '\" It\"[1102] (p=0.003, logit=15.938)']\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     clean_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.8984375, logit=21.5, token_id=45805, metadata=None))), (10777, (17, PredictedToken(token=' Router', prob=0.000926971435546875, logit=14.625, token_id=10777, metadata=None))), (17929, (29, PredictedToken(token=' Pin', prob=0.0003414154052734375, logit=13.625, token_id=17929, metadata=None))), (22410, (50, PredictedToken(token=' Ju', prob=9.775161743164062e-05, logit=12.375, token_id=22410, metadata=None))), (96096, (398, PredictedToken(token=' Dolphin', prob=2.4437904357910156e-06, logit=8.6875, token_id=96096, metadata=None))), (50159, (395, PredictedToken(token=' Sco', prob=2.4437904357910156e-06, logit=8.6875, token_id=50159, metadata=None)))])\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     int_prediction=['\" Cherry\"[45805] (p=0.875, logit=21.125)', '\" The\"[578] (p=0.030, logit=17.750)', '\" Pin\"[17929] (p=0.018, logit=17.250)', '\" None\"[2290] (p=0.011, logit=16.750)', '\" A\"[362] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     int_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.875, logit=21.125, token_id=45805, metadata=None))), (17929, (3, PredictedToken(token=' Pin', prob=0.0181884765625, logit=17.25, token_id=17929, metadata=None))), (10777, (10, PredictedToken(token=' Router', prob=0.001800537109375, logit=14.9375, token_id=10777, metadata=None))), (50159, (54, PredictedToken(token=' Sco', prob=0.00010824203491210938, logit=12.125, token_id=50159, metadata=None))), (22410, (110, PredictedToken(token=' Ju', prob=2.9087066650390625e-05, logit=10.8125, token_id=22410, metadata=None))), (96096, (302, PredictedToken(token=' Dolphin', prob=5.7220458984375e-06, logit=9.1875, token_id=96096, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:02 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     patch_prediction=['\" Lily\"[48390] (p=0.770, logit=21.375)', '\" The\"[578] (p=0.081, logit=19.125)', '\" Among\"[22395] (p=0.071, logit=19.000)', '\" A\"[362] (p=0.023, logit=17.875)', '\" l\"[326] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     clean_prediction=['\" Mushroom\"[91297] (p=0.781, logit=20.250)', '\" The\"[578] (p=0.064, logit=17.750)', '\" A\"[362] (p=0.056, logit=17.625)', '\" Among\"[22395] (p=0.024, logit=16.750)', '\" None\"[2290] (p=0.007, logit=15.562)']\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     clean_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.78125, logit=20.25, token_id=91297, metadata=None))), (6771, (27, PredictedToken(token=' Table', prob=0.000629425048828125, logit=13.125, token_id=6771, metadata=None))), (71264, (64, PredictedToken(token=' Daisy', prob=0.0001239776611328125, logit=11.5, token_id=71264, metadata=None))), (68027, (74, PredictedToken(token=' Sax', prob=0.00010251998901367188, logit=11.3125, token_id=68027, metadata=None))), (58586, (189, PredictedToken(token=' Tape', prob=2.014636993408203e-05, logit=9.6875, token_id=58586, metadata=None)))])\n",
      "2025-09-16 09:42:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.715, logit=19.875)', '\" The\"[578] (p=0.085, logit=17.750)', '\" Among\"[22395] (p=0.036, logit=16.875)', '\" A\"[362] (p=0.031, logit=16.750)', '\" None\"[2290] (p=0.024, logit=16.500)']\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.71484375, logit=19.875, token_id=71264, metadata=None))), (91297, (13, PredictedToken(token=' Mushroom', prob=0.0029144287109375, logit=14.375, token_id=91297, metadata=None))), (6771, (19, PredictedToken(token=' Table', prob=0.00188446044921875, logit=13.9375, token_id=6771, metadata=None))), (68027, (101, PredictedToken(token=' Sax', prob=8.296966552734375e-05, logit=10.8125, token_id=68027, metadata=None))), (58586, (100, PredictedToken(token=' Tape', prob=8.296966552734375e-05, logit=10.8125, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:03 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.707, logit=22.375)', '\" The\"[578] (p=0.123, logit=20.625)', '\" A\"[362] (p=0.084, logit=20.250)', '\" Among\"[22395] (p=0.058, logit=19.875)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.656, logit=21.000)', '\" An\"[1556] (p=0.114, logit=19.250)', '\" The\"[578] (p=0.101, logit=19.125)', '\" Among\"[22395] (p=0.069, logit=18.750)', '\" It\"[1102] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.65625, logit=21.0, token_id=87213, metadata=None))), (11683, (77, PredictedToken(token=' Acc', prob=6.723403930664062e-05, logit=11.8125, token_id=11683, metadata=None))), (47589, (108, PredictedToken(token=' Basketball', prob=3.838539123535156e-05, logit=11.25, token_id=47589, metadata=None))), (74968, (221, PredictedToken(token=' Razor', prob=8.52346420288086e-06, logit=9.75, token_id=74968, metadata=None))), (36895, (522, PredictedToken(token=' Eagle', prob=2.16066837310791e-06, logit=8.375, token_id=36895, metadata=None))), (71264, (634, PredictedToken(token=' Daisy', prob=1.6838312149047852e-06, logit=8.125, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.863, logit=22.000)', '\" The\"[578] (p=0.055, logit=19.250)', '\" Among\"[22395] (p=0.033, logit=18.750)', '\" d\"[294] (p=0.016, logit=18.000)', '\" D\"[423] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.86328125, logit=22.0, token_id=71264, metadata=None))), (11683, (35, PredictedToken(token=' Acc', prob=0.00010633468627929688, logit=13.0, token_id=11683, metadata=None))), (47589, (119, PredictedToken(token=' Basketball', prob=1.055002212524414e-05, logit=10.6875, token_id=47589, metadata=None))), (36895, (333, PredictedToken(token=' Eagle', prob=1.8328428268432617e-06, logit=8.9375, token_id=36895, metadata=None))), (74968, (1078, PredictedToken(token=' Razor', prob=3.8370490074157715e-07, logit=7.375, token_id=74968, metadata=None))), (87213, (1108, PredictedToken(token=' Oven', prob=3.725290298461914e-07, logit=7.34375, token_id=87213, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:03 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:42:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.742, logit=22.625)', '\" The\"[578] (p=0.165, logit=21.125)', '\" A\"[362] (p=0.047, logit=19.875)', '\" Among\"[22395] (p=0.020, logit=19.000)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.738, logit=21.875)', '\" The\"[578] (p=0.088, logit=19.750)', '\" Among\"[22395] (p=0.078, logit=19.625)', '\" A\"[362] (p=0.053, logit=19.250)', '\" slow\"[6435] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.73828125, logit=21.875, token_id=39247, metadata=None))), (20423, (30, PredictedToken(token=' Amb', prob=0.0003376007080078125, logit=14.1875, token_id=20423, metadata=None))), (23910, (32, PredictedToken(token=' Pear', prob=0.00029754638671875, logit=14.0625, token_id=23910, metadata=None))), (94467, (36, PredictedToken(token=' Trom', prob=0.000263214111328125, logit=13.9375, token_id=94467, metadata=None))), (53889, (90, PredictedToken(token=' Apartment', prob=3.147125244140625e-05, logit=11.8125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     int_prediction=['\" Among\"[22395] (p=0.334, logit=19.375)', '\" Trom\"[94467] (p=0.260, logit=19.125)', '\" The\"[578] (p=0.229, logit=19.000)', '\" Pear\"[23910] (p=0.027, logit=16.875)', '\" None\"[2290] (p=0.019, logit=16.500)']\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     int_track=OrderedDict([(94467, (2, PredictedToken(token=' Trom', prob=0.259765625, logit=19.125, token_id=94467, metadata=None))), (23910, (4, PredictedToken(token=' Pear', prob=0.02734375, logit=16.875, token_id=23910, metadata=None))), (20423, (117, PredictedToken(token=' Amb', prob=5.984306335449219e-05, logit=10.75, token_id=20423, metadata=None))), (53889, (183, PredictedToken(token=' Apartment', prob=2.491474151611328e-05, logit=9.875, token_id=53889, metadata=None))), (39247, (1306, PredictedToken(token=' Slow', prob=1.4081597328186035e-06, logit=7.0, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:04 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.898, logit=22.125)', '\" The\"[578] (p=0.035, logit=18.875)', '\" Among\"[22395] (p=0.016, logit=18.125)', '\" A\"[362] (p=0.011, logit=17.750)', '\" Head\"[11452] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     clean_prediction=['\" Bamboo\"[98028] (p=0.816, logit=20.875)', '\" The\"[578] (p=0.059, logit=18.250)', '\" Among\"[22395] (p=0.032, logit=17.625)', '\" None\"[2290] (p=0.017, logit=17.000)', '\" A\"[362] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     clean_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.81640625, logit=20.875, token_id=98028, metadata=None))), (30616, (38, PredictedToken(token=' Rice', prob=0.000274658203125, logit=12.875, token_id=30616, metadata=None))), (33711, (39, PredictedToken(token=' Suit', prob=0.0002574920654296875, logit=12.8125, token_id=33711, metadata=None))), (38673, (53, PredictedToken(token=' Yoga', prob=0.00013828277587890625, logit=12.1875, token_id=38673, metadata=None))), (14669, (730, PredictedToken(token=' Camera', prob=1.735985279083252e-06, logit=7.8125, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:42:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     int_prediction=['\" Rice\"[30616] (p=0.305, logit=19.250)', '\" Camera\"[14669] (p=0.209, logit=18.875)', '\" None\"[2290] (p=0.163, logit=18.625)', '\" A\"[362] (p=0.112, logit=18.250)', '\" The\"[578] (p=0.087, logit=18.000)']\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     int_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.3046875, logit=19.25, token_id=30616, metadata=None))), (14669, (2, PredictedToken(token=' Camera', prob=0.208984375, logit=18.875, token_id=14669, metadata=None))), (38673, (14, PredictedToken(token=' Yoga', prob=0.003173828125, logit=14.6875, token_id=38673, metadata=None))), (33711, (26, PredictedToken(token=' Suit', prob=0.00116729736328125, logit=13.6875, token_id=33711, metadata=None))), (98028, (539, PredictedToken(token=' Bamboo', prob=4.500150680541992e-06, logit=8.125, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:05 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:05 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.805, logit=21.875)', '\" None\"[2290] (p=0.045, logit=19.000)', '\" Marker\"[40975] (p=0.040, logit=18.875)', '\" A\"[362] (p=0.040, logit=18.875)', '\" The\"[578] (p=0.031, logit=18.625)']\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.820, logit=21.125)', '\" The\"[578] (p=0.046, logit=18.250)', '\" A\"[362] (p=0.046, logit=18.250)', '\" None\"[2290] (p=0.028, logit=17.750)', '\" It\"[1102] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.8203125, logit=21.125, token_id=36943, metadata=None))), (19111, (23, PredictedToken(token=' Bus', prob=0.000659942626953125, logit=14.0, token_id=19111, metadata=None))), (86460, (38, PredictedToken(token=' Necklace', prob=0.0002918243408203125, logit=13.1875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.348, logit=19.500)', '\" Necklace\"[86460] (p=0.307, logit=19.375)', '\" None\"[2290] (p=0.128, logit=18.500)', '\" The\"[578] (p=0.069, logit=17.875)', '\" A\"[362] (p=0.042, logit=17.375)']\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.34765625, logit=19.5, token_id=36943, metadata=None))), (86460, (2, PredictedToken(token=' Necklace', prob=0.306640625, logit=19.375, token_id=86460, metadata=None))), (19111, (9, PredictedToken(token=' Bus', prob=0.004974365234375, logit=15.25, token_id=19111, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:05 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:05 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.730, logit=21.500)', '\" An\"[1556] (p=0.112, logit=19.625)', '\" The\"[578] (p=0.068, logit=19.125)', '\" Among\"[22395] (p=0.032, logit=18.375)', '\" Only\"[8442] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     clean_prediction=['\" Ch\"[921] (p=0.766, logit=22.500)', '\" The\"[578] (p=0.117, logit=20.625)', '\" A\"[362] (p=0.049, logit=19.750)', '\" Among\"[22395] (p=0.043, logit=19.625)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     clean_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.765625, logit=22.5, token_id=921, metadata=None))), (816, (40, PredictedToken(token=' Y', prob=8.869171142578125e-05, logit=13.4375, token_id=816, metadata=None))), (33199, (80, PredictedToken(token=' Lion', prob=1.8596649169921875e-05, logit=11.875, token_id=33199, metadata=None))), (27171, (102, PredictedToken(token=' Coffee', prob=9.953975677490234e-06, logit=11.25, token_id=27171, metadata=None))), (38673, (290, PredictedToken(token=' Yoga', prob=1.3485550880432129e-06, logit=9.25, token_id=38673, metadata=None))), (10777, (2305, PredictedToken(token=' Router', prob=4.912726581096649e-08, logit=5.9375, token_id=10777, metadata=None)))])\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     int_prediction=['\" Lion\"[33199] (p=0.652, logit=21.250)', '\" The\"[578] (p=0.165, logit=19.875)', '\" Among\"[22395] (p=0.088, logit=19.250)', '\" A\"[362] (p=0.042, logit=18.500)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     int_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.65234375, logit=21.25, token_id=33199, metadata=None))), (10777, (9, PredictedToken(token=' Router', prob=0.00341796875, logit=16.0, token_id=10777, metadata=None))), (816, (10, PredictedToken(token=' Y', prob=0.002838134765625, logit=15.8125, token_id=816, metadata=None))), (38673, (48, PredictedToken(token=' Yoga', prob=0.00011014938354492188, logit=12.5625, token_id=38673, metadata=None))), (921, (296, PredictedToken(token=' Ch', prob=3.11434268951416e-06, logit=9.0, token_id=921, metadata=None))), (27171, (410, PredictedToken(token=' Coffee', prob=2.0116567611694336e-06, logit=8.5625, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:06 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     patch_prediction=['\" Coat\"[68867] (p=0.711, logit=21.750)', '\" The\"[578] (p=0.109, logit=19.875)', '\" Among\"[22395] (p=0.066, logit=19.375)', '\" A\"[362] (p=0.066, logit=19.375)', '\" CO\"[7432] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:42:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     clean_prediction=['\" Television\"[41445] (p=0.703, logit=21.250)', '\" The\"[578] (p=0.138, logit=19.625)', '\" Among\"[22395] (p=0.051, logit=18.625)', '\" A\"[362] (p=0.016, logit=17.500)', '\" Option\"[7104] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     clean_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.703125, logit=21.25, token_id=41445, metadata=None))), (423, (28, PredictedToken(token=' D', prob=0.00077056884765625, logit=14.4375, token_id=423, metadata=None))), (27171, (29, PredictedToken(token=' Coffee', prob=0.00072479248046875, logit=14.375, token_id=27171, metadata=None))), (82507, (269, PredictedToken(token=' Jeans', prob=6.258487701416016e-06, logit=9.625, token_id=82507, metadata=None))), (76924, (333, PredictedToken(token=' Banana', prob=4.0531158447265625e-06, logit=9.1875, token_id=76924, metadata=None)))])\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     int_prediction=['\" Jeans\"[82507] (p=0.758, logit=21.000)', '\" Among\"[22395] (p=0.080, logit=18.750)', '\" The\"[578] (p=0.071, logit=18.625)', '\" Option\"[7104] (p=0.008, logit=16.500)', '\" None\"[2290] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     int_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.7578125, logit=21.0, token_id=82507, metadata=None))), (423, (29, PredictedToken(token=' D', prob=0.00069427490234375, logit=14.0, token_id=423, metadata=None))), (76924, (47, PredictedToken(token=' Banana', prob=0.0002117156982421875, logit=12.8125, token_id=76924, metadata=None))), (27171, (75, PredictedToken(token=' Coffee', prob=9.393692016601562e-05, logit=12.0, token_id=27171, metadata=None))), (41445, (454, PredictedToken(token=' Television', prob=2.339482307434082e-06, logit=8.3125, token_id=41445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:07 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.910, logit=21.875)', '\" The\"[578] (p=0.024, logit=18.250)', '\" A\"[362] (p=0.019, logit=18.000)', '\" Among\"[22395] (p=0.017, logit=17.875)', '\" It\"[1102] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.633, logit=21.125)', '\" An\"[1556] (p=0.110, logit=19.375)', '\" The\"[578] (p=0.110, logit=19.375)', '\" Among\"[22395] (p=0.086, logit=19.125)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.6328125, logit=21.125, token_id=87213, metadata=None))), (34392, (72, PredictedToken(token=' Horse', prob=6.914138793945312e-05, logit=12.0, token_id=34392, metadata=None))), (82507, (375, PredictedToken(token=' Jeans', prob=2.8461217880249023e-06, logit=8.8125, token_id=82507, metadata=None))), (38258, (434, PredictedToken(token=' Baseball', prob=2.3692846298217773e-06, logit=8.625, token_id=38258, metadata=None))), (39794, (456, PredictedToken(token=' Desk', prob=2.2202730178833008e-06, logit=8.5625, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     int_prediction=['\" Desk\"[39794] (p=0.477, logit=20.375)', '\" The\"[578] (p=0.176, logit=19.375)', '\" Horse\"[34392] (p=0.137, logit=19.125)', '\" Among\"[22395] (p=0.094, logit=18.750)', '\" A\"[362] (p=0.027, logit=17.500)']\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     int_track=OrderedDict([(39794, (1, PredictedToken(token=' Desk', prob=0.4765625, logit=20.375, token_id=39794, metadata=None))), (34392, (3, PredictedToken(token=' Horse', prob=0.13671875, logit=19.125, token_id=34392, metadata=None))), (82507, (6, PredictedToken(token=' Jeans', prob=0.016357421875, logit=17.0, token_id=82507, metadata=None))), (87213, (358, PredictedToken(token=' Oven', prob=4.5299530029296875e-06, logit=8.8125, token_id=87213, metadata=None))), (38258, (454, PredictedToken(token=' Baseball', prob=3.11434268951416e-06, logit=8.4375, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:07 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:07 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:42:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     patch_prediction=['\" Scar\"[30760] (p=0.461, logit=20.625)', '\" Tow\"[41493] (p=0.192, logit=19.750)', '\" The\"[578] (p=0.117, logit=19.250)', '\" A\"[362] (p=0.103, logit=19.125)', '\" Among\"[22395] (p=0.071, logit=18.750)']\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.871, logit=22.875)', '\" A\"[362] (p=0.049, logit=20.000)', '\" The\"[578] (p=0.043, logit=19.875)', '\" Among\"[22395] (p=0.016, logit=18.875)', '\" Motor\"[18079] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.87109375, logit=22.875, token_id=70762, metadata=None))), (5340, (54, PredictedToken(token=' Har', prob=3.9577484130859375e-05, logit=12.875, token_id=5340, metadata=None))), (432, (104, PredictedToken(token=' R', prob=9.417533874511719e-06, logit=11.4375, token_id=432, metadata=None))), (82994, (190, PredictedToken(token=' Toilet', prob=2.5331974029541016e-06, logit=10.125, token_id=82994, metadata=None))), (59825, (548, PredictedToken(token=' Tie', prob=4.1350722312927246e-07, logit=8.3125, token_id=59825, metadata=None))), (12369, (998, PredictedToken(token=' Food', prob=1.6670674085617065e-07, logit=7.40625, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.656, logit=21.750)', '\" The\"[578] (p=0.146, logit=20.250)', '\" A\"[362] (p=0.089, logit=19.750)', '\" Among\"[22395] (p=0.037, logit=18.875)', '\" Har\"[5340] (p=0.037, logit=18.875)']\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.65625, logit=21.75, token_id=59825, metadata=None))), (5340, (4, PredictedToken(token=' Har', prob=0.037109375, logit=18.875, token_id=5340, metadata=None))), (432, (9, PredictedToken(token=' R', prob=0.0023651123046875, logit=16.125, token_id=432, metadata=None))), (12369, (62, PredictedToken(token=' Food', prob=5.245208740234375e-05, logit=12.3125, token_id=12369, metadata=None))), (82994, (110, PredictedToken(token=' Toilet', prob=1.5974044799804688e-05, logit=11.125, token_id=82994, metadata=None))), (70762, (122, PredictedToken(token=' Motorcycle', prob=1.3232231140136719e-05, logit=10.9375, token_id=70762, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:08 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:08 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.855, logit=22.500)', '\" The\"[578] (p=0.080, logit=20.125)', '\" Among\"[22395] (p=0.033, logit=19.250)', '\" A\"[362] (p=0.009, logit=18.000)', '\" water\"[3090] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:42:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     clean_prediction=['\" Tooth\"[83499] (p=0.938, logit=21.625)', '\" Among\"[22395] (p=0.012, logit=17.250)', '\" The\"[578] (p=0.012, logit=17.250)', '\" D\"[423] (p=0.006, logit=16.500)', '\" None\"[2290] (p=0.003, logit=15.875)']\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     clean_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.9375, logit=21.625, token_id=83499, metadata=None))), (423, (4, PredictedToken(token=' D', prob=0.00555419921875, logit=16.5, token_id=423, metadata=None))), (91782, (15, PredictedToken(token=' Shorts', prob=0.00080108642578125, logit=14.5625, token_id=91782, metadata=None))), (89077, (22, PredictedToken(token=' Strawberry', prob=0.000518798828125, logit=14.125, token_id=89077, metadata=None))), (30173, (28, PredictedToken(token=' Speaker', prob=0.0002956390380859375, logit=13.5625, token_id=30173, metadata=None))), (23462, (32, PredictedToken(token=' Stadium', prob=0.0002155303955078125, logit=13.25, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     int_prediction=['\" Strawberry\"[89077] (p=0.660, logit=20.125)', '\" Shorts\"[91782] (p=0.070, logit=17.875)', '\" Among\"[22395] (p=0.062, logit=17.750)', '\" None\"[2290] (p=0.037, logit=17.250)', '\" The\"[578] (p=0.037, logit=17.250)']\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     int_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.66015625, logit=20.125, token_id=89077, metadata=None))), (91782, (2, PredictedToken(token=' Shorts', prob=0.06982421875, logit=17.875, token_id=91782, metadata=None))), (423, (17, PredictedToken(token=' D', prob=0.002532958984375, logit=14.5625, token_id=423, metadata=None))), (23462, (198, PredictedToken(token=' Stadium', prob=2.193450927734375e-05, logit=9.8125, token_id=23462, metadata=None))), (83499, (799, PredictedToken(token=' Tooth', prob=2.4586915969848633e-06, logit=7.625, token_id=83499, metadata=None))), (30173, (1525, PredictedToken(token=' Speaker', prob=1.0579824447631836e-06, logit=6.78125, token_id=30173, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:09 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:09 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.629, logit=20.250)', '\" A\"[362] (p=0.141, logit=18.750)', '\" The\"[578] (p=0.097, logit=18.375)', '\" Among\"[22395] (p=0.040, logit=17.500)', '\" None\"[2290] (p=0.015, logit=16.500)']\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.816, logit=22.000)', '\" The\"[578] (p=0.067, logit=19.500)', '\" A\"[362] (p=0.046, logit=19.125)', '\" Among\"[22395] (p=0.032, logit=18.750)', '\" dress\"[8679] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.81640625, logit=22.0, token_id=29318, metadata=None))), (38930, (16, PredictedToken(token=' Bike', prob=0.000743865966796875, logit=15.0, token_id=38930, metadata=None))), (36895, (127, PredictedToken(token=' Eagle', prob=9.953975677490234e-06, logit=10.6875, token_id=36895, metadata=None))), (18191, (184, PredictedToken(token=' Mouse', prob=4.708766937255859e-06, logit=9.9375, token_id=18191, metadata=None))), (23910, (212, PredictedToken(token=' Pear', prob=3.6656856536865234e-06, logit=9.6875, token_id=23910, metadata=None))), (17367, (523, PredictedToken(token=' Factory', prob=9.275972843170166e-07, logit=8.3125, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     int_prediction=['\" Factory\"[17367] (p=0.844, logit=22.125)', '\" Among\"[22395] (p=0.054, logit=19.375)', '\" The\"[578] (p=0.054, logit=19.375)', '\" Option\"[7104] (p=0.004, logit=16.875)', '\" A\"[362] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     int_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.84375, logit=22.125, token_id=17367, metadata=None))), (36895, (8, PredictedToken(token=' Eagle', prob=0.0030364990234375, logit=16.5, token_id=36895, metadata=None))), (18191, (9, PredictedToken(token=' Mouse', prob=0.002685546875, logit=16.375, token_id=18191, metadata=None))), (38930, (279, PredictedToken(token=' Bike', prob=3.1441450119018555e-06, logit=9.625, token_id=38930, metadata=None))), (23910, (287, PredictedToken(token=' Pear', prob=2.950429916381836e-06, logit=9.5625, token_id=23910, metadata=None))), (29318, (300, PredictedToken(token=' Dress', prob=2.771615982055664e-06, logit=9.5, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:09 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:09 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     patch_prediction=['\" Onion\"[87035] (p=0.824, logit=21.250)', '\" The\"[578] (p=0.052, logit=18.500)', '\" Among\"[22395] (p=0.046, logit=18.375)', '\" An\"[1556] (p=0.012, logit=17.000)', '\" On\"[1952] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.742, logit=22.000)', '\" The\"[578] (p=0.101, logit=20.000)', '\" A\"[362] (p=0.054, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=19.250)', '\" It\"[1102] (p=0.014, logit=18.000)']\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.7421875, logit=22.0, token_id=56491, metadata=None))), (3341, (29, PredictedToken(token=' Car', prob=0.00028228759765625, logit=14.125, token_id=3341, metadata=None))), (432, (43, PredictedToken(token=' R', prob=0.000133514404296875, logit=13.375, token_id=432, metadata=None))), (30558, (82, PredictedToken(token=' Ki', prob=2.7894973754882812e-05, logit=11.8125, token_id=30558, metadata=None)))])\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.691, logit=22.000)', '\" Car\"[3341] (p=0.083, logit=19.875)', '\" The\"[578] (p=0.083, logit=19.875)', '\" Among\"[22395] (p=0.064, logit=19.625)', '\" A\"[362] (p=0.021, logit=18.500)']\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.69140625, logit=22.0, token_id=432, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.08251953125, logit=19.875, token_id=3341, metadata=None))), (30558, (6, PredictedToken(token=' Ki', prob=0.014404296875, logit=18.125, token_id=30558, metadata=None))), (56491, (124, PredictedToken(token=' Piano', prob=1.1563301086425781e-05, logit=11.0, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:10 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.789, logit=22.375)', '\" The\"[578] (p=0.083, logit=20.125)', '\" A\"[362] (p=0.057, logit=19.750)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" dog\"[5679] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:42:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     clean_prediction=['\" Ward\"[27738] (p=0.926, logit=23.125)', '\" The\"[578] (p=0.025, logit=19.500)', '\" A\"[362] (p=0.025, logit=19.500)', '\" Among\"[22395] (p=0.006, logit=18.125)', '\" (\"[320] (p=0.003, logit=17.500)']\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     clean_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.92578125, logit=23.125, token_id=27738, metadata=None))), (1901, (56, PredictedToken(token=' Z', prob=1.990795135498047e-05, logit=12.375, token_id=1901, metadata=None))), (23126, (132, PredictedToken(token=' Ti', prob=3.904104232788086e-06, logit=10.75, token_id=23126, metadata=None)))])\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.918, logit=23.500)', '\" The\"[578] (p=0.031, logit=20.125)', '\" A\"[362] (p=0.010, logit=19.000)', '\" Among\"[22395] (p=0.009, logit=18.875)', '\" z\"[1167] (p=0.009, logit=18.875)']\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.91796875, logit=23.5, token_id=1901, metadata=None))), (23126, (15, PredictedToken(token=' Ti', prob=0.000576019287109375, logit=16.125, token_id=23126, metadata=None))), (27738, (403, PredictedToken(token=' Ward', prob=4.917383193969727e-07, logit=9.0625, token_id=27738, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:11 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     patch_prediction=['\" Coat\"[68867] (p=0.746, logit=22.375)', '\" The\"[578] (p=0.101, logit=20.375)', '\" Among\"[22395] (p=0.061, logit=19.875)', '\" A\"[362] (p=0.061, logit=19.875)', '\" Out\"[4470] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.770, logit=21.625)', '\" The\"[578] (p=0.081, logit=19.375)', '\" A\"[362] (p=0.071, logit=19.250)', '\" Among\"[22395] (p=0.034, logit=18.500)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.76953125, logit=21.625, token_id=29318, metadata=None))), (55807, (6, PredictedToken(token=' Shirt', prob=0.0040283203125, logit=16.375, token_id=55807, metadata=None))), (36943, (12, PredictedToken(token=' Folder', prob=0.001678466796875, logit=15.5, token_id=36943, metadata=None))), (6914, (20, PredictedToken(token=' Let', prob=0.000743865966796875, logit=14.6875, token_id=6914, metadata=None)))])\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.777, logit=21.625)', '\" The\"[578] (p=0.072, logit=19.250)', '\" Dress\"[29318] (p=0.039, logit=18.625)', '\" Among\"[22395] (p=0.034, logit=18.500)', '\" A\"[362] (p=0.034, logit=18.500)']\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.77734375, logit=21.625, token_id=55807, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.03857421875, logit=18.625, token_id=29318, metadata=None))), (6914, (6, PredictedToken(token=' Let', prob=0.005218505859375, logit=16.625, token_id=6914, metadata=None))), (36943, (8, PredictedToken(token=' Folder', prob=0.002471923828125, logit=15.875, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:11 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.750, logit=21.750)', '\" The\"[578] (p=0.070, logit=19.375)', '\" Among\"[22395] (p=0.054, logit=19.125)', '\" A\"[362] (p=0.054, logit=19.125)', '\" Pen\"[13597] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.770, logit=22.250)', '\" The\"[578] (p=0.118, logit=20.375)', '\" Among\"[22395] (p=0.043, logit=19.375)', '\" An\"[1556] (p=0.030, logit=19.000)', '\" It\"[1102] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.76953125, logit=22.25, token_id=11683, metadata=None))), (14642, (90, PredictedToken(token=' Phone', prob=2.2649765014648438e-05, logit=11.8125, token_id=14642, metadata=None))), (82452, (114, PredictedToken(token=' Jasmine', prob=1.3709068298339844e-05, logit=11.3125, token_id=82452, metadata=None))), (38930, (225, PredictedToken(token=' Bike', prob=3.248453140258789e-06, logit=9.875, token_id=38930, metadata=None))), (29318, (366, PredictedToken(token=' Dress', prob=1.1995434761047363e-06, logit=8.875, token_id=29318, metadata=None))), (87213, (814, PredictedToken(token=' Oven', prob=3.129243850708008e-07, logit=7.53125, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.531, logit=20.875)', '\" The\"[578] (p=0.151, logit=19.625)', '\" Among\"[22395] (p=0.118, logit=19.375)', '\" Phone\"[14642] (p=0.081, logit=19.000)', '\" It\"[1102] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.53125, logit=20.875, token_id=87213, metadata=None))), (14642, (4, PredictedToken(token=' Phone', prob=0.0810546875, logit=19.0, token_id=14642, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.0159912109375, logit=17.375, token_id=38930, metadata=None))), (82452, (50, PredictedToken(token=' Jasmine', prob=0.00016689300537109375, logit=12.8125, token_id=82452, metadata=None))), (29318, (335, PredictedToken(token=' Dress', prob=3.933906555175781e-06, logit=9.0625, token_id=29318, metadata=None))), (11683, (581, PredictedToken(token=' Acc', prob=1.6316771507263184e-06, logit=8.1875, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:12 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:12 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.895, logit=22.000)', '\" A\"[362] (p=0.035, logit=18.750)', '\" The\"[578] (p=0.024, logit=18.375)', '\" Among\"[22395] (p=0.013, logit=17.750)', '\" None\"[2290] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:42:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.695, logit=21.500)', '\" A\"[362] (p=0.121, logit=19.750)', '\" The\"[578] (p=0.083, logit=19.375)', '\" Among\"[22395] (p=0.019, logit=17.875)', '\" It\"[1102] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.6953125, logit=21.5, token_id=12369, metadata=None))), (469, (14, PredictedToken(token=' E', prob=0.0020751953125, logit=15.6875, token_id=469, metadata=None))), (91963, (27, PredictedToken(token=' Mango', prob=0.000812530517578125, logit=14.75, token_id=91963, metadata=None))), (445, (48, PredictedToken(token=' L', prob=0.0001506805419921875, logit=13.0625, token_id=445, metadata=None)))])\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.766, logit=21.125)', '\" Among\"[22395] (p=0.056, logit=18.500)', '\" Mango\"[91963] (p=0.049, logit=18.375)', '\" The\"[578] (p=0.038, logit=18.125)', '\" Option\"[7104] (p=0.020, logit=17.500)']\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.765625, logit=21.125, token_id=469, metadata=None))), (91963, (3, PredictedToken(token=' Mango', prob=0.049072265625, logit=18.375, token_id=91963, metadata=None))), (445, (7, PredictedToken(token=' L', prob=0.01092529296875, logit=16.875, token_id=445, metadata=None))), (12369, (82, PredictedToken(token=' Food', prob=4.76837158203125e-05, logit=11.4375, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:13 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:13 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.812, logit=22.000)', '\" The\"[578] (p=0.059, logit=19.375)', '\" A\"[362] (p=0.052, logit=19.250)', '\" Among\"[22395] (p=0.028, logit=18.625)', '\" Option\"[7104] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.809, logit=21.500)', '\" The\"[578] (p=0.075, logit=19.125)', '\" Among\"[22395] (p=0.036, logit=18.375)', '\" A\"[362] (p=0.022, logit=17.875)', '\" laptop\"[21288] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.80859375, logit=21.5, token_id=57225, metadata=None))), (23126, (59, PredictedToken(token=' Ti', prob=6.0558319091796875e-05, logit=12.0, token_id=23126, metadata=None))), (18787, (94, PredictedToken(token=' Oak', prob=2.5272369384765625e-05, logit=11.125, token_id=18787, metadata=None))), (100031, (172, PredictedToken(token=' Mosque', prob=8.761882781982422e-06, logit=10.0625, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     int_prediction=['\" Ti\"[23126] (p=0.672, logit=20.750)', '\" Mosque\"[100031] (p=0.103, logit=18.875)', '\" The\"[578] (p=0.081, logit=18.625)', '\" Among\"[22395] (p=0.055, logit=18.250)', '\" A\"[362] (p=0.016, logit=17.000)']\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     int_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.671875, logit=20.75, token_id=23126, metadata=None))), (100031, (2, PredictedToken(token=' Mosque', prob=0.10302734375, logit=18.875, token_id=100031, metadata=None))), (18787, (57, PredictedToken(token=' Oak', prob=0.0001068115234375, logit=12.0, token_id=18787, metadata=None))), (57225, (1247, PredictedToken(token=' Laptop', prob=6.966292858123779e-07, logit=6.96875, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:13 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:13 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.879, logit=22.500)', '\" The\"[578] (p=0.050, logit=19.625)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" A\"[362] (p=0.023, logit=18.875)', '\" (\"[320] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.773, logit=20.875)', '\" The\"[578] (p=0.082, logit=18.625)', '\" Among\"[22395] (p=0.044, logit=18.000)', '\" A\"[362] (p=0.034, logit=17.750)', '\" It\"[1102] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.7734375, logit=20.875, token_id=42609, metadata=None))), (43316, (14, PredictedToken(token=' Tul', prob=0.002044677734375, logit=14.9375, token_id=43316, metadata=None))), (30760, (69, PredictedToken(token=' Scar', prob=7.915496826171875e-05, logit=11.6875, token_id=30760, metadata=None))), (10777, (346, PredictedToken(token=' Router', prob=3.933906555175781e-06, logit=8.6875, token_id=10777, metadata=None))), (27217, (439, PredictedToken(token=' Train', prob=2.8908252716064453e-06, logit=8.375, token_id=27217, metadata=None)))])\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     int_prediction=['\" Tul\"[43316] (p=0.645, logit=20.250)', '\" Among\"[22395] (p=0.112, logit=18.500)', '\" The\"[578] (p=0.112, logit=18.500)', '\" A\"[362] (p=0.036, logit=17.375)', '\" It\"[1102] (p=0.012, logit=16.250)']\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     int_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.64453125, logit=20.25, token_id=43316, metadata=None))), (27217, (8, PredictedToken(token=' Train', prob=0.004608154296875, logit=15.3125, token_id=27217, metadata=None))), (30760, (15, PredictedToken(token=' Scar', prob=0.001922607421875, logit=14.4375, token_id=30760, metadata=None))), (10777, (21, PredictedToken(token=' Router', prob=0.00131988525390625, logit=14.0625, token_id=10777, metadata=None))), (42609, (38, PredictedToken(token=' Pine', prob=0.0004558563232421875, logit=13.0, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:14 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:14 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:42:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.805, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" A\"[362] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" Flower\"[43786] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     clean_prediction=['\" Temple\"[19176] (p=0.875, logit=21.125)', '\" Pepper\"[52882] (p=0.026, logit=17.625)', '\" None\"[2290] (p=0.026, logit=17.625)', '\" The\"[578] (p=0.018, logit=17.250)', '\" Among\"[22395] (p=0.008, logit=16.375)']\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     clean_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.875, logit=21.125, token_id=19176, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.0264892578125, logit=17.625, token_id=52882, metadata=None))), (55405, (8, PredictedToken(token=' Orch', prob=0.00335693359375, logit=15.5625, token_id=55405, metadata=None))), (30558, (20, PredictedToken(token=' Ki', prob=0.000583648681640625, logit=13.8125, token_id=30558, metadata=None))), (1443, (28, PredictedToken(token=' Sh', prob=0.000354766845703125, logit=13.3125, token_id=1443, metadata=None))), (6690, (37, PredictedToken(token=' Air', prob=0.0002288818359375, logit=12.875, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     int_prediction=['\" Ki\"[30558] (p=0.400, logit=19.375)', '\" Temple\"[19176] (p=0.243, logit=18.875)', '\" None\"[2290] (p=0.167, logit=18.500)', '\" Pepper\"[52882] (p=0.042, logit=17.125)', '\" The\"[578] (p=0.026, logit=16.625)']\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     int_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.400390625, logit=19.375, token_id=30558, metadata=None))), (19176, (2, PredictedToken(token=' Temple', prob=0.2431640625, logit=18.875, token_id=19176, metadata=None))), (52882, (4, PredictedToken(token=' Pepper', prob=0.042236328125, logit=17.125, token_id=52882, metadata=None))), (55405, (6, PredictedToken(token=' Orch', prob=0.025634765625, logit=16.625, token_id=55405, metadata=None))), (6690, (19, PredictedToken(token=' Air', prob=0.001861572265625, logit=14.0, token_id=6690, metadata=None))), (1443, (62, PredictedToken(token=' Sh', prob=0.00018405914306640625, logit=11.6875, token_id=1443, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:15 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:15 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.805, logit=21.500)', '\" The\"[578] (p=0.096, logit=19.375)', '\" Among\"[22395] (p=0.040, logit=18.500)', '\" Glo\"[25372] (p=0.009, logit=17.000)', '\" Option\"[7104] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.809, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.625)', '\" It\"[1102] (p=0.013, logit=18.125)']\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.80859375, logit=22.25, token_id=56491, metadata=None))), (8868, (190, PredictedToken(token=' Blue', prob=3.6209821701049805e-06, logit=9.9375, token_id=8868, metadata=None))), (67553, (218, PredictedToken(token=' Pants', prob=2.8312206268310547e-06, logit=9.6875, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.668, logit=20.750)', '\" Among\"[22395] (p=0.132, logit=19.125)', '\" The\"[578] (p=0.071, logit=18.500)', '\" None\"[2290] (p=0.038, logit=17.875)', '\" Pant\"[54222] (p=0.008, logit=16.375)']\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.66796875, logit=20.75, token_id=67553, metadata=None))), (8868, (11, PredictedToken(token=' Blue', prob=0.00396728515625, logit=15.625, token_id=8868, metadata=None))), (56491, (21, PredictedToken(token=' Piano', prob=0.001373291015625, logit=14.5625, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:15 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:15 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:42:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.844, logit=22.125)', '\" Among\"[22395] (p=0.089, logit=19.875)', '\" The\"[578] (p=0.037, logit=19.000)', '\" Cherry\"[45805] (p=0.003, logit=16.375)', '\" as\"[439] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     clean_prediction=['\" Water\"[10164] (p=0.867, logit=22.750)', '\" The\"[578] (p=0.056, logit=20.000)', '\" Among\"[22395] (p=0.038, logit=19.625)', '\" A\"[362] (p=0.011, logit=18.375)', '\" water\"[3090] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     clean_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.8671875, logit=22.75, token_id=10164, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.000545501708984375, logit=15.375, token_id=1183, metadata=None))), (41785, (19, PredictedToken(token=' Spin', prob=0.00051116943359375, logit=15.3125, token_id=41785, metadata=None))), (61731, (66, PredictedToken(token=' Soap', prob=2.8848648071289062e-05, logit=12.4375, token_id=61731, metadata=None))), (735, (99, PredictedToken(token=' K', prob=1.3649463653564453e-05, logit=11.6875, token_id=735, metadata=None))), (53889, (396, PredictedToken(token=' Apartment', prob=7.674098014831543e-07, logit=8.8125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     int_prediction=['\" Spin\"[41785] (p=0.812, logit=22.000)', '\" The\"[578] (p=0.052, logit=19.250)', '\" Soap\"[61731] (p=0.046, logit=19.125)', '\" Among\"[22395] (p=0.046, logit=19.125)', '\" Tr\"[1183] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     int_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.8125, logit=22.0, token_id=41785, metadata=None))), (61731, (4, PredictedToken(token=' Soap', prob=0.0458984375, logit=19.125, token_id=61731, metadata=None))), (1183, (5, PredictedToken(token=' Tr', prob=0.01025390625, logit=17.625, token_id=1183, metadata=None))), (735, (11, PredictedToken(token=' K', prob=0.00167083740234375, logit=15.8125, token_id=735, metadata=None))), (10164, (82, PredictedToken(token=' Water', prob=3.266334533691406e-05, logit=11.875, token_id=10164, metadata=None))), (53889, (815, PredictedToken(token=' Apartment', prob=4.954636096954346e-07, logit=7.6875, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:16 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:42:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.621, logit=21.375)', '\" The\"[578] (p=0.157, logit=20.000)', '\" A\"[362] (p=0.122, logit=19.750)', '\" Among\"[22395] (p=0.027, logit=18.250)', '\" It\"[1102] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     clean_prediction=['\" Jeans\"[82507] (p=0.762, logit=21.625)', '\" The\"[578] (p=0.104, logit=19.625)', '\" Among\"[22395] (p=0.062, logit=19.125)', '\" Ank\"[57915] (p=0.010, logit=17.250)', '\" JE\"[71430] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     clean_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.76171875, logit=21.625, token_id=82507, metadata=None))), (57915, (4, PredictedToken(token=' Ank', prob=0.00958251953125, logit=17.25, token_id=57915, metadata=None))), (3341, (46, PredictedToken(token=' Car', prob=0.00021266937255859375, logit=13.4375, token_id=3341, metadata=None))), (47589, (200, PredictedToken(token=' Basketball', prob=6.8247318267822266e-06, logit=10.0, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.852, logit=22.500)', '\" The\"[578] (p=0.048, logit=19.625)', '\" Among\"[22395] (p=0.042, logit=19.500)', '\" A\"[362] (p=0.014, logit=18.375)', '\" Option\"[7104] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.8515625, logit=22.5, token_id=47589, metadata=None))), (3341, (7, PredictedToken(token=' Car', prob=0.0030670166015625, logit=16.875, token_id=3341, metadata=None))), (57915, (15, PredictedToken(token=' Ank', prob=0.00119781494140625, logit=15.9375, token_id=57915, metadata=None))), (82507, (143, PredictedToken(token=' Jeans', prob=7.599592208862305e-06, logit=10.875, token_id=82507, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:17 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:17 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     patch_prediction=['\" Iris\"[66821] (p=0.824, logit=21.875)', '\" The\"[578] (p=0.068, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=19.000)', '\" An\"[1556] (p=0.019, logit=18.125)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     clean_prediction=['\" Sc\"[2522] (p=0.840, logit=21.000)', '\" The\"[578] (p=0.042, logit=18.000)', '\" Suit\"[33711] (p=0.029, logit=17.625)', '\" Among\"[22395] (p=0.025, logit=17.500)', '\" It\"[1102] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     clean_track=OrderedDict([(2522, (1, PredictedToken(token=' Sc', prob=0.83984375, logit=21.0, token_id=2522, metadata=None))), (33711, (3, PredictedToken(token=' Suit', prob=0.0286865234375, logit=17.625, token_id=33711, metadata=None))), (48390, (17, PredictedToken(token=' Lily', prob=0.0011138916015625, logit=14.375, token_id=48390, metadata=None))), (23910, (104, PredictedToken(token=' Pear', prob=4.315376281738281e-05, logit=11.125, token_id=23910, metadata=None)))])\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     int_prediction=['\" Lily\"[48390] (p=0.707, logit=19.875)', '\" The\"[578] (p=0.065, logit=17.500)', '\" Among\"[22395] (p=0.045, logit=17.125)', '\" None\"[2290] (p=0.021, logit=16.375)', '\" A\"[362] (p=0.017, logit=16.125)']\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     int_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.70703125, logit=19.875, token_id=48390, metadata=None))), (23910, (6, PredictedToken(token=' Pear', prob=0.0166015625, logit=16.125, token_id=23910, metadata=None))), (33711, (89, PredictedToken(token=' Suit', prob=0.00011920928955078125, logit=11.1875, token_id=33711, metadata=None))), (2522, (629, PredictedToken(token=' Sc', prob=4.351139068603516e-06, logit=7.875, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:17 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:17 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:42:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.832, logit=22.250)', '\" The\"[578] (p=0.078, logit=19.875)', '\" A\"[362] (p=0.042, logit=19.250)', '\" Among\"[22395] (p=0.022, logit=18.625)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     clean_prediction=['\" Ottoman\"[70110] (p=0.816, logit=21.125)', '\" The\"[578] (p=0.067, logit=18.625)', '\" An\"[1556] (p=0.041, logit=18.125)', '\" Among\"[22395] (p=0.015, logit=17.125)', '\" (\"[320] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     clean_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.81640625, logit=21.125, token_id=70110, metadata=None))), (55405, (27, PredictedToken(token=' Orch', prob=0.000579833984375, logit=13.875, token_id=55405, metadata=None))), (23262, (40, PredictedToken(token=' Comb', prob=0.0002727508544921875, logit=13.125, token_id=23262, metadata=None))), (47033, (50, PredictedToken(token=' Printer', prob=0.00015544891357421875, logit=12.5625, token_id=47033, metadata=None)))])\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     int_prediction=['\" Orch\"[55405] (p=0.746, logit=21.125)', '\" The\"[578] (p=0.061, logit=18.625)', '\" Printer\"[47033] (p=0.048, logit=18.375)', '\" Among\"[22395] (p=0.033, logit=18.000)', '\" An\"[1556] (p=0.020, logit=17.500)']\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     int_track=OrderedDict([(55405, (1, PredictedToken(token=' Orch', prob=0.74609375, logit=21.125, token_id=55405, metadata=None))), (47033, (3, PredictedToken(token=' Printer', prob=0.047607421875, logit=18.375, token_id=47033, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.01202392578125, logit=17.0, token_id=23262, metadata=None))), (70110, (1655, PredictedToken(token=' Ottoman', prob=4.5262277126312256e-07, logit=6.8125, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:18 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:18 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.859, logit=22.125)', '\" The\"[578] (p=0.049, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.625)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.824, logit=22.250)', '\" The\"[578] (p=0.067, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=19.125)', '\" A\"[362] (p=0.032, logit=19.000)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.82421875, logit=22.25, token_id=38930, metadata=None))), (16488, (18, PredictedToken(token=' Bat', prob=0.000514984130859375, logit=14.875, token_id=16488, metadata=None))), (61948, (216, PredictedToken(token=' Sofa', prob=2.8759241104125977e-06, logit=9.6875, token_id=61948, metadata=None))), (26698, (462, PredictedToken(token=' Keyboard', prob=7.301568984985352e-07, logit=8.3125, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     int_prediction=['\" Sofa\"[61948] (p=0.539, logit=20.500)', '\" The\"[578] (p=0.198, logit=19.500)', '\" Among\"[22395] (p=0.073, logit=18.500)', '\" A\"[362] (p=0.064, logit=18.375)', '\" It\"[1102] (p=0.027, logit=17.500)']\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     int_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.5390625, logit=20.5, token_id=61948, metadata=None))), (26698, (24, PredictedToken(token=' Keyboard', prob=0.00091552734375, logit=14.125, token_id=26698, metadata=None))), (38930, (124, PredictedToken(token=' Bike', prob=3.552436828613281e-05, logit=10.875, token_id=38930, metadata=None))), (16488, (795, PredictedToken(token=' Bat', prob=1.3783574104309082e-06, logit=7.625, token_id=16488, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:19 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:19 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.836, logit=22.000)', '\" The\"[578] (p=0.042, logit=19.000)', '\" A\"[362] (p=0.042, logit=19.000)', '\" Among\"[22395] (p=0.032, logit=18.750)', '\" slow\"[6435] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.832, logit=22.750)', '\" The\"[578] (p=0.078, logit=20.375)', '\" A\"[362] (p=0.047, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=19.125)', '\" SH\"[6570] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.83203125, logit=22.75, token_id=55807, metadata=None))), (21424, (54, PredictedToken(token=' Football', prob=2.944469451904297e-05, logit=12.5, token_id=21424, metadata=None))), (87213, (295, PredictedToken(token=' Oven', prob=1.296401023864746e-06, logit=9.375, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.844, logit=22.000)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" The\"[578] (p=0.054, logit=19.250)', '\" An\"[1556] (p=0.005, logit=16.875)', '\" O\"[507] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.84375, logit=22.0, token_id=87213, metadata=None))), (21424, (6, PredictedToken(token=' Football', prob=0.0050048828125, logit=16.875, token_id=21424, metadata=None))), (55807, (60, PredictedToken(token=' Shirt', prob=5.91278076171875e-05, logit=12.4375, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:19 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:19 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:42:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.559, logit=21.500)', '\" The\"[578] (p=0.264, logit=20.750)', '\" A\"[362] (p=0.086, logit=19.625)', '\" Among\"[22395] (p=0.046, logit=19.000)', '\" It\"[1102] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.840, logit=22.000)', '\" The\"[578] (p=0.069, logit=19.500)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" A\"[362] (p=0.014, logit=17.875)', '\" PE\"[22557] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.83984375, logit=22.0, token_id=64695, metadata=None))), (94467, (15, PredictedToken(token=' Trom', prob=0.0004634857177734375, logit=14.5, token_id=94467, metadata=None))), (96096, (127, PredictedToken(token=' Dolphin', prob=1.0251998901367188e-05, logit=10.6875, token_id=96096, metadata=None))), (39247, (304, PredictedToken(token=' Slow', prob=1.8998980522155762e-06, logit=9.0, token_id=39247, metadata=None))), (58600, (957, PredictedToken(token=' Charm', prob=3.986060619354248e-07, logit=7.4375, token_id=58600, metadata=None))), (14669, (4704, PredictedToken(token=' Camera', prob=5.052424967288971e-08, logit=5.375, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     int_prediction=['\" Trom\"[94467] (p=0.361, logit=19.375)', '\" The\"[578] (p=0.318, logit=19.250)', '\" Among\"[22395] (p=0.171, logit=18.625)', '\" A\"[362] (p=0.018, logit=16.375)', '\" Option\"[7104] (p=0.012, logit=16.000)']\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     int_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.361328125, logit=19.375, token_id=94467, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.007049560546875, logit=15.4375, token_id=96096, metadata=None))), (14669, (15, PredictedToken(token=' Camera', prob=0.0035400390625, logit=14.75, token_id=14669, metadata=None))), (64695, (197, PredictedToken(token=' Peach', prob=2.5391578674316406e-05, logit=9.8125, token_id=64695, metadata=None))), (39247, (194, PredictedToken(token=' Slow', prob=2.5391578674316406e-05, logit=9.8125, token_id=39247, metadata=None))), (58600, (311, PredictedToken(token=' Charm', prob=1.0609626770019531e-05, logit=8.9375, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:20 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:20 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.891, logit=21.625)', '\" The\"[578] (p=0.024, logit=18.000)', '\" Brace\"[70306] (p=0.021, logit=17.875)', '\" helmet\"[32635] (p=0.008, logit=16.875)', '\" A\"[362] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:42:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.848, logit=22.750)', '\" A\"[362] (p=0.054, logit=20.000)', '\" The\"[578] (p=0.042, logit=19.750)', '\" Among\"[22395] (p=0.023, logit=19.125)', '\" cuff\"[75523] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.84765625, logit=22.75, token_id=356, metadata=None))), (432, (22, PredictedToken(token=' R', prob=0.0003223419189453125, logit=14.875, token_id=432, metadata=None))), (1901, (34, PredictedToken(token=' Z', prob=0.0001430511474609375, logit=14.0625, token_id=1901, metadata=None)))])\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.836, logit=22.375)', '\" The\"[578] (p=0.037, logit=19.250)', '\" C\"[356] (p=0.037, logit=19.250)', '\" A\"[362] (p=0.025, logit=18.875)', '\" Among\"[22395] (p=0.022, logit=18.750)']\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.8359375, logit=22.375, token_id=432, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.03662109375, logit=19.25, token_id=356, metadata=None))), (1901, (8, PredictedToken(token=' Z', prob=0.003875732421875, logit=17.0, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:21 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.695, logit=21.000)', '\" The\"[578] (p=0.107, logit=19.125)', '\" Among\"[22395] (p=0.065, logit=18.625)', '\" A\"[362] (p=0.051, logit=18.375)', '\" Option\"[7104] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.875, logit=22.500)', '\" The\"[578] (p=0.049, logit=19.625)', '\" Among\"[22395] (p=0.030, logit=19.125)', '\" A\"[362] (p=0.021, logit=18.750)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.875, logit=22.5, token_id=356, metadata=None))), (3804, (12, PredictedToken(token=' Sub', prob=0.000850677490234375, logit=15.5625, token_id=3804, metadata=None))), (47589, (55, PredictedToken(token=' Basketball', prob=5.435943603515625e-05, logit=12.8125, token_id=47589, metadata=None))), (49431, (159, PredictedToken(token=' Rabbit', prob=5.364418029785156e-06, logit=10.5, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     int_prediction=['\" Sub\"[3804] (p=0.316, logit=19.750)', '\" Rabbit\"[49431] (p=0.316, logit=19.750)', '\" Among\"[22395] (p=0.103, logit=18.625)', '\" The\"[578] (p=0.090, logit=18.500)', '\" None\"[2290] (p=0.070, logit=18.250)']\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     int_track=OrderedDict([(3804, (1, PredictedToken(token=' Sub', prob=0.31640625, logit=19.75, token_id=3804, metadata=None))), (49431, (2, PredictedToken(token=' Rabbit', prob=0.31640625, logit=19.75, token_id=49431, metadata=None))), (47589, (8, PredictedToken(token=' Basketball', prob=0.006988525390625, logit=15.9375, token_id=47589, metadata=None))), (356, (43, PredictedToken(token=' C', prob=0.000446319580078125, logit=13.1875, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:21 src.selection.optimization DEBUG    torch.Size([4, 30])\n",
      "2025-09-16 09:42:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     patch_prediction=['\" Surf\"[65197] (p=0.467, logit=19.750)', '\" Razor\"[74968] (p=0.221, logit=19.000)', '\" The\"[578] (p=0.092, logit=18.125)', '\" Among\"[22395] (p=0.056, logit=17.625)', '\" A\"[362] (p=0.026, logit=16.875)']\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.738, logit=21.125)', '\" Among\"[22395] (p=0.088, logit=19.000)', '\" The\"[578] (p=0.088, logit=19.000)', '\" A\"[362] (p=0.014, logit=17.125)', '\" It\"[1102] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.73828125, logit=21.125, token_id=88088, metadata=None))), (4923, (85, PredictedToken(token=' Sk', prob=4.315376281738281e-05, logit=11.375, token_id=4923, metadata=None))), (56491, (155, PredictedToken(token=' Piano', prob=1.4007091522216797e-05, logit=10.25, token_id=56491, metadata=None))), (11896, (179, PredictedToken(token=' Library', prob=1.0907649993896484e-05, logit=10.0, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     int_prediction=['\" Piano\"[56491] (p=0.625, logit=21.000)', '\" Sk\"[4923] (p=0.139, logit=19.500)', '\" The\"[578] (p=0.074, logit=18.875)', '\" Among\"[22395] (p=0.035, logit=18.125)', '\" Option\"[7104] (p=0.024, logit=17.750)']\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     int_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.625, logit=21.0, token_id=56491, metadata=None))), (4923, (2, PredictedToken(token=' Sk', prob=0.138671875, logit=19.5, token_id=4923, metadata=None))), (11896, (6, PredictedToken(token=' Library', prob=0.024169921875, logit=17.75, token_id=11896, metadata=None))), (88088, (324, PredictedToken(token=' Birch', prob=3.844499588012695e-06, logit=9.0, token_id=88088, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:22 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.680, logit=22.375)', '\" An\"[1556] (p=0.172, logit=21.000)', '\" The\"[578] (p=0.071, logit=20.125)', '\" Among\"[22395] (p=0.049, logit=19.750)', '\" It\"[1102] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.730, logit=20.375)', '\" The\"[578] (p=0.087, logit=18.250)', '\" A\"[362] (p=0.032, logit=17.250)', '\" Among\"[22395] (p=0.022, logit=16.875)', '\" Pine\"[42609] (p=0.015, logit=16.500)']\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.73046875, logit=20.375, token_id=58403, metadata=None))), (42609, (5, PredictedToken(token=' Pine', prob=0.01513671875, logit=16.5, token_id=42609, metadata=None))), (11683, (15, PredictedToken(token=' Acc', prob=0.003173828125, logit=14.9375, token_id=11683, metadata=None))), (19111, (35, PredictedToken(token=' Bus', prob=0.000751495361328125, logit=13.5, token_id=19111, metadata=None))), (91297, (377, PredictedToken(token=' Mushroom', prob=7.3909759521484375e-06, logit=8.875, token_id=91297, metadata=None))), (22050, (421, PredictedToken(token=' Hat', prob=6.109476089477539e-06, logit=8.6875, token_id=22050, metadata=None)))])\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     int_prediction=['\" Bus\"[19111] (p=0.855, logit=21.375)', '\" None\"[2290] (p=0.033, logit=18.125)', '\" The\"[578] (p=0.029, logit=18.000)', '\" Among\"[22395] (p=0.018, logit=17.500)', '\" BUS\"[23504] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     int_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.85546875, logit=21.375, token_id=19111, metadata=None))), (42609, (8, PredictedToken(token=' Pine', prob=0.00506591796875, logit=16.25, token_id=42609, metadata=None))), (58403, (132, PredictedToken(token=' Tablet', prob=2.3484230041503906e-05, logit=10.875, token_id=58403, metadata=None))), (22050, (144, PredictedToken(token=' Hat', prob=1.9550323486328125e-05, logit=10.6875, token_id=22050, metadata=None))), (11683, (179, PredictedToken(token=' Acc', prob=1.1801719665527344e-05, logit=10.1875, token_id=11683, metadata=None))), (91297, (219, PredictedToken(token=' Mushroom', prob=7.62939453125e-06, logit=9.75, token_id=91297, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:23 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:23 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.824, logit=21.875)', '\" The\"[578] (p=0.068, logit=19.375)', '\" A\"[362] (p=0.041, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.375)', '\" \"[220] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.734, logit=21.375)', '\" The\"[578] (p=0.099, logit=19.375)', '\" Among\"[22395] (p=0.068, logit=19.000)', '\" A\"[362] (p=0.047, logit=18.625)', '\" It\"[1102] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.734375, logit=21.375, token_id=81501, metadata=None))), (68027, (17, PredictedToken(token=' Sax', prob=0.000911712646484375, logit=14.6875, token_id=68027, metadata=None))), (22607, (410, PredictedToken(token=' Cow', prob=2.130866050720215e-06, logit=8.625, token_id=22607, metadata=None))), (82507, (644, PredictedToken(token=' Jeans', prob=1.214444637298584e-06, logit=8.0625, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     int_prediction=['\" Cow\"[22607] (p=0.887, logit=22.375)', '\" The\"[578] (p=0.034, logit=19.125)', '\" Among\"[22395] (p=0.027, logit=18.875)', '\" cow\"[19923] (p=0.011, logit=18.000)', '\" A\"[362] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     int_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.88671875, logit=22.375, token_id=22607, metadata=None))), (68027, (12, PredictedToken(token=' Sax', prob=0.001251220703125, logit=15.8125, token_id=68027, metadata=None))), (82507, (172, PredictedToken(token=' Jeans', prob=4.26173210144043e-06, logit=10.125, token_id=82507, metadata=None))), (81501, (1191, PredictedToken(token=' Pendant', prob=2.551823854446411e-07, logit=7.3125, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:23 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:42:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.715, logit=22.250)', '\" The\"[578] (p=0.097, logit=20.250)', '\" A\"[362] (p=0.075, logit=20.000)', '\" Among\"[22395] (p=0.066, logit=19.875)', '\" (\"[320] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.969, logit=22.250)', '\" The\"[578] (p=0.007, logit=17.375)', '\" Pin\"[17929] (p=0.006, logit=17.125)', '\" A\"[362] (p=0.004, logit=16.750)', '\" Among\"[22395] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.96875, logit=22.25, token_id=41493, metadata=None))), (17929, (3, PredictedToken(token=' Pin', prob=0.005767822265625, logit=17.125, token_id=17929, metadata=None))), (80629, (20, PredictedToken(token=' Grape', prob=0.00017452239990234375, logit=13.625, token_id=80629, metadata=None))), (30760, (31, PredictedToken(token=' Scar', prob=8.249282836914062e-05, logit=12.875, token_id=30760, metadata=None))), (48035, (138, PredictedToken(token=' Gir', prob=7.62939453125e-06, logit=10.5, token_id=48035, metadata=None)))])\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.512, logit=19.000)', '\" Tow\"[41493] (p=0.101, logit=17.375)', '\" None\"[2290] (p=0.089, logit=17.250)', '\" Grape\"[80629] (p=0.078, logit=17.125)', '\" The\"[578] (p=0.042, logit=16.500)']\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.51171875, logit=19.0, token_id=17929, metadata=None))), (41493, (2, PredictedToken(token=' Tow', prob=0.1005859375, logit=17.375, token_id=41493, metadata=None))), (80629, (4, PredictedToken(token=' Grape', prob=0.078125, logit=17.125, token_id=80629, metadata=None))), (48035, (7, PredictedToken(token=' Gir', prob=0.0185546875, logit=15.6875, token_id=48035, metadata=None))), (30760, (15, PredictedToken(token=' Scar', prob=0.00323486328125, logit=13.9375, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:24 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:24 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     patch_prediction=['\" Sheep\"[84008] (p=0.498, logit=20.375)', '\" The\"[578] (p=0.208, logit=19.500)', '\" A\"[362] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.076, logit=18.500)', '\" SHE\"[54695] (p=0.012, logit=16.625)']\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.809, logit=20.375)', '\" The\"[578] (p=0.052, logit=17.625)', '\" Among\"[22395] (p=0.024, logit=16.875)', '\" E\"[469] (p=0.015, logit=16.375)', '\" None\"[2290] (p=0.012, logit=16.125)']\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.80859375, logit=20.375, token_id=67629, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.01483154296875, logit=16.375, token_id=469, metadata=None))), (735, (6, PredictedToken(token=' K', prob=0.00897216796875, logit=15.875, token_id=735, metadata=None))), (36845, (30, PredictedToken(token=' Tiger', prob=0.00069427490234375, logit=13.3125, token_id=36845, metadata=None))), (41785, (36, PredictedToken(token=' Spin', prob=0.0006103515625, logit=13.1875, token_id=41785, metadata=None))), (58403, (72, PredictedToken(token=' Tablet', prob=0.0001544952392578125, logit=11.8125, token_id=58403, metadata=None)))])\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.859, logit=21.000)', '\" Among\"[22395] (p=0.049, logit=18.125)', '\" The\"[578] (p=0.038, logit=17.875)', '\" None\"[2290] (p=0.005, logit=15.938)', '\" K\"[735] (p=0.002, logit=15.125)']\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.859375, logit=21.0, token_id=36845, metadata=None))), (735, (5, PredictedToken(token=' K', prob=0.002410888671875, logit=15.125, token_id=735, metadata=None))), (58403, (9, PredictedToken(token=' Tablet', prob=0.00213623046875, logit=15.0, token_id=58403, metadata=None))), (41785, (11, PredictedToken(token=' Spin', prob=0.00177001953125, logit=14.8125, token_id=41785, metadata=None))), (469, (82, PredictedToken(token=' E', prob=5.6743621826171875e-05, logit=11.375, token_id=469, metadata=None))), (67629, (578, PredictedToken(token=' Helmet', prob=1.8253922462463379e-06, logit=7.9375, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:25 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:25 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.730, logit=22.500)', '\" An\"[1556] (p=0.144, logit=20.875)', '\" The\"[578] (p=0.060, logit=20.000)', '\" Among\"[22395] (p=0.032, logit=19.375)', '\" It\"[1102] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.820, logit=21.125)', '\" The\"[578] (p=0.067, logit=18.625)', '\" A\"[362] (p=0.041, logit=18.125)', '\" Among\"[22395] (p=0.019, logit=17.375)', '\" It\"[1102] (p=0.004, logit=15.812)']\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.8203125, logit=21.125, token_id=91263, metadata=None))), (71264, (15, PredictedToken(token=' Daisy', prob=0.00122833251953125, logit=14.625, token_id=71264, metadata=None))), (18787, (84, PredictedToken(token=' Oak', prob=4.76837158203125e-05, logit=11.375, token_id=18787, metadata=None))), (45332, (100, PredictedToken(token=' Boat', prob=3.4809112548828125e-05, logit=11.0625, token_id=45332, metadata=None)))])\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     int_prediction=['\" Boat\"[45332] (p=0.754, logit=21.125)', '\" The\"[578] (p=0.080, logit=18.875)', '\" Among\"[22395] (p=0.055, logit=18.500)', '\" A\"[362] (p=0.018, logit=17.375)', '\" Option\"[7104] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:42:25 src.selection.optimization INFO     int_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.75390625, logit=21.125, token_id=45332, metadata=None))), (18787, (6, PredictedToken(token=' Oak', prob=0.00836181640625, logit=16.625, token_id=18787, metadata=None))), (71264, (29, PredictedToken(token=' Daisy', prob=0.000732421875, logit=14.1875, token_id=71264, metadata=None))), (91263, (119, PredictedToken(token=' Binder', prob=3.886222839355469e-05, logit=11.25, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:26 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:26 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     patch_prediction=['\" Bamboo\"[98028] (p=0.699, logit=20.750)', '\" None\"[2290] (p=0.200, logit=19.500)', '\" The\"[578] (p=0.019, logit=17.125)', '\" Spin\"[41785] (p=0.011, logit=16.625)', '\" There\"[2684] (p=0.011, logit=16.625)']\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     clean_prediction=['\" Horse\"[34392] (p=0.902, logit=22.375)', '\" The\"[578] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.625)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" horse\"[15580] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     clean_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.90234375, logit=22.375, token_id=34392, metadata=None))), (42609, (17, PredictedToken(token=' Pine', prob=0.000530242919921875, logit=14.9375, token_id=42609, metadata=None))), (38258, (77, PredictedToken(token=' Baseball', prob=2.3365020751953125e-05, logit=11.8125, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.879, logit=21.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" Option\"[7104] (p=0.011, logit=17.250)', '\" (\"[320] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.87890625, logit=21.625, token_id=42609, metadata=None))), (34392, (11, PredictedToken(token=' Horse', prob=0.0023193359375, logit=15.6875, token_id=34392, metadata=None))), (38258, (56, PredictedToken(token=' Baseball', prob=7.915496826171875e-05, logit=12.3125, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:26 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:42:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.820, logit=22.250)', '\" The\"[578] (p=0.052, logit=19.500)', '\" A\"[362] (p=0.052, logit=19.500)', '\" Among\"[22395] (p=0.025, logit=18.750)', '\" C\"[356] (p=0.015, logit=18.250)']\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.918, logit=21.375)', '\" The\"[578] (p=0.019, logit=17.500)', '\" Among\"[22395] (p=0.013, logit=17.125)', '\" A\"[362] (p=0.007, logit=16.500)', '\" R\"[432] (p=0.003, logit=15.750)']\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.91796875, logit=21.375, token_id=74968, metadata=None))), (36845, (6, PredictedToken(token=' Tiger', prob=0.0033111572265625, logit=15.75, token_id=36845, metadata=None))), (14937, (10, PredictedToken(token=' Ash', prob=0.0022735595703125, logit=15.375, token_id=14937, metadata=None))), (24423, (31, PredictedToken(token=' Monitor', prob=0.0002880096435546875, logit=13.3125, token_id=24423, metadata=None))), (98641, (117, PredictedToken(token=' Microwave', prob=2.5272369384765625e-05, logit=10.875, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.629, logit=18.875)', '\" Among\"[22395] (p=0.109, logit=17.125)', '\" The\"[578] (p=0.066, logit=16.625)', '\" None\"[2290] (p=0.021, logit=15.500)', '\" Ash\"[14937] (p=0.017, logit=15.250)']\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.62890625, logit=18.875, token_id=36845, metadata=None))), (14937, (5, PredictedToken(token=' Ash', prob=0.0167236328125, logit=15.25, token_id=14937, metadata=None))), (24423, (23, PredictedToken(token=' Monitor', prob=0.0021209716796875, logit=13.1875, token_id=24423, metadata=None))), (74968, (39, PredictedToken(token=' Razor', prob=0.00113677978515625, logit=12.5625, token_id=74968, metadata=None))), (98641, (50, PredictedToken(token=' Microwave', prob=0.0006103515625, logit=11.9375, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:27 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:27 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     patch_prediction=['\" Re\"[1050] (p=0.785, logit=21.875)', '\" The\"[578] (p=0.064, logit=19.375)', '\" A\"[362] (p=0.050, logit=19.125)', '\" Among\"[22395] (p=0.039, logit=18.875)', '\" It\"[1102] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.793, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.045, logit=18.500)', '\" A\"[362] (p=0.031, logit=18.125)', '\" Option\"[7104] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.79296875, logit=21.375, token_id=57551, metadata=None))), (356, (9, PredictedToken(token=' C', prob=0.00238037109375, logit=15.5625, token_id=356, metadata=None))), (57915, (14, PredictedToken(token=' Ank', prob=0.0016326904296875, logit=15.1875, token_id=57915, metadata=None))), (16183, (39, PredictedToken(token=' Hel', prob=0.00026702880859375, logit=13.375, token_id=16183, metadata=None))), (34046, (53, PredictedToken(token=' Cabinet', prob=0.00015163421630859375, logit=12.8125, token_id=34046, metadata=None))), (57225, (439, PredictedToken(token=' Laptop', prob=2.16066837310791e-06, logit=8.5625, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:42:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.486, logit=19.750)', '\" Ank\"[57915] (p=0.158, logit=18.625)', '\" Among\"[22395] (p=0.084, logit=18.000)', '\" The\"[578] (p=0.058, logit=17.625)', '\" Cabinet\"[34046] (p=0.051, logit=17.500)']\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.486328125, logit=19.75, token_id=356, metadata=None))), (57915, (2, PredictedToken(token=' Ank', prob=0.158203125, logit=18.625, token_id=57915, metadata=None))), (34046, (5, PredictedToken(token=' Cabinet', prob=0.05126953125, logit=17.5, token_id=34046, metadata=None))), (57225, (7, PredictedToken(token=' Laptop', prob=0.018798828125, logit=16.5, token_id=57225, metadata=None))), (16183, (15, PredictedToken(token=' Hel', prob=0.00421142578125, logit=15.0, token_id=16183, metadata=None))), (57551, (76, PredictedToken(token=' Sink', prob=0.00016307830810546875, logit=11.75, token_id=57551, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:28 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:28 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     patch_prediction=['\" Keyboard\"[26698] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.037, logit=18.250)', '\" keyboard\"[13939] (p=0.017, logit=17.500)', '\" None\"[2290] (p=0.015, logit=17.375)', '\" Har\"[5340] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.754, logit=21.000)', '\" The\"[578] (p=0.070, logit=18.625)', '\" Short\"[10928] (p=0.038, logit=18.000)', '\" shorts\"[36876] (p=0.029, logit=17.750)', '\" Among\"[22395] (p=0.023, logit=17.500)']\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.75390625, logit=21.0, token_id=91782, metadata=None))), (65449, (14, PredictedToken(token=' Willow', prob=0.0017547607421875, logit=14.9375, token_id=65449, metadata=None))), (11452, (28, PredictedToken(token=' Head', prob=0.000644683837890625, logit=13.9375, token_id=11452, metadata=None)))])\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     int_prediction=['\" Head\"[11452] (p=0.918, logit=22.750)', '\" The\"[578] (p=0.028, logit=19.250)', '\" headphones\"[44101] (p=0.013, logit=18.500)', '\" Among\"[22395] (p=0.008, logit=18.000)', '\" (\"[320] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     int_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.91796875, logit=22.75, token_id=11452, metadata=None))), (65449, (6, PredictedToken(token=' Willow', prob=0.003753662109375, logit=17.25, token_id=65449, metadata=None))), (91782, (378, PredictedToken(token=' Shorts', prob=8.67992639541626e-07, logit=8.875, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:28 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:42:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.781, logit=21.375)', '\" An\"[1556] (p=0.093, logit=19.250)', '\" The\"[578] (p=0.039, logit=18.375)', '\" Among\"[22395] (p=0.027, logit=18.000)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.777, logit=21.250)', '\" The\"[578] (p=0.082, logit=19.000)', '\" Among\"[22395] (p=0.050, logit=18.500)', '\" A\"[362] (p=0.027, logit=17.875)', '\" Option\"[7104] (p=0.009, logit=16.750)']\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.77734375, logit=21.25, token_id=80629, metadata=None))), (57094, (92, PredictedToken(token=' Highlight', prob=3.528594970703125e-05, logit=11.25, token_id=57094, metadata=None))), (21424, (155, PredictedToken(token=' Football', prob=1.2159347534179688e-05, logit=10.1875, token_id=21424, metadata=None))), (38571, (235, PredictedToken(token=' Theater', prob=6.109476089477539e-06, logit=9.5, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.855, logit=21.625)', '\" The\"[578] (p=0.055, logit=18.875)', '\" Among\"[22395] (p=0.029, logit=18.250)', '\" A\"[362] (p=0.014, logit=17.500)', '\" None\"[2290] (p=0.012, logit=17.375)']\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.85546875, logit=21.625, token_id=57094, metadata=None))), (38571, (33, PredictedToken(token=' Theater', prob=0.0002231597900390625, logit=13.375, token_id=38571, metadata=None))), (21424, (34, PredictedToken(token=' Football', prob=0.00019741058349609375, logit=13.25, token_id=21424, metadata=None))), (80629, (115, PredictedToken(token=' Grape', prob=1.9550323486328125e-05, logit=10.9375, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:29 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:29 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.867, logit=21.875)', '\" The\"[578] (p=0.038, logit=18.750)', '\" An\"[1556] (p=0.034, logit=18.625)', '\" Among\"[22395] (p=0.018, logit=18.000)', '\" (\"[320] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     clean_prediction=['\" Scar\"[30760] (p=0.578, logit=20.500)', '\" Among\"[22395] (p=0.114, logit=18.875)', '\" The\"[578] (p=0.114, logit=18.875)', '\" A\"[362] (p=0.088, logit=18.625)', '\" C\"[356] (p=0.022, logit=17.250)']\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     clean_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.578125, logit=20.5, token_id=30760, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.0223388671875, logit=17.25, token_id=356, metadata=None))), (32749, (40, PredictedToken(token=' Carn', prob=0.0004100799560546875, logit=13.25, token_id=32749, metadata=None))), (1443, (61, PredictedToken(token=' Sh', prob=0.00018215179443359375, logit=12.4375, token_id=1443, metadata=None))), (58403, (132, PredictedToken(token=' Tablet', prob=4.0531158447265625e-05, logit=10.9375, token_id=58403, metadata=None))), (16730, (316, PredictedToken(token=' Museum', prob=6.22868537902832e-06, logit=9.0625, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:42:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     int_prediction=['\" Among\"[22395] (p=0.367, logit=18.000)', '\" The\"[578] (p=0.153, logit=17.125)', '\" Museum\"[16730] (p=0.120, logit=16.875)', '\" None\"[2290] (p=0.056, logit=16.125)', '\" A\"[362] (p=0.036, logit=15.688)']\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     int_track=OrderedDict([(16730, (3, PredictedToken(token=' Museum', prob=0.11962890625, logit=16.875, token_id=16730, metadata=None))), (58403, (10, PredictedToken(token=' Tablet', prob=0.01519775390625, logit=14.8125, token_id=58403, metadata=None))), (356, (14, PredictedToken(token=' C', prob=0.006744384765625, logit=14.0, token_id=356, metadata=None))), (32749, (77, PredictedToken(token=' Carn', prob=0.0002956390380859375, logit=10.875, token_id=32749, metadata=None))), (1443, (118, PredictedToken(token=' Sh', prob=0.0001583099365234375, logit=10.25, token_id=1443, metadata=None))), (30760, (794, PredictedToken(token=' Scar', prob=4.649162292480469e-06, logit=6.71875, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:30 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     patch_prediction=['\" Library\"[11896] (p=0.867, logit=21.875)', '\" A\"[362] (p=0.034, logit=18.625)', '\" The\"[578] (p=0.030, logit=18.500)', '\" Among\"[22395] (p=0.020, logit=18.125)', '\" None\"[2290] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     clean_prediction=['\" Re\"[1050] (p=0.758, logit=21.625)', '\" The\"[578] (p=0.090, logit=19.500)', '\" Among\"[22395] (p=0.055, logit=19.000)', '\" A\"[362] (p=0.048, logit=18.875)', '\" (\"[320] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     clean_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.7578125, logit=21.625, token_id=1050, metadata=None))), (19176, (13, PredictedToken(token=' Temple', prob=0.001068115234375, logit=15.0625, token_id=19176, metadata=None))), (40090, (32, PredictedToken(token=' Pressure', prob=0.000370025634765625, logit=14.0, token_id=40090, metadata=None))), (78703, (227, PredictedToken(token=' Potato', prob=4.649162292480469e-06, logit=9.625, token_id=78703, metadata=None)))])\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.812, logit=21.500)', '\" The\"[578] (p=0.076, logit=19.125)', '\" Among\"[22395] (p=0.036, logit=18.375)', '\" Pressure\"[40090] (p=0.013, logit=17.375)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.8125, logit=21.5, token_id=19176, metadata=None))), (40090, (4, PredictedToken(token=' Pressure', prob=0.01312255859375, logit=17.375, token_id=40090, metadata=None))), (78703, (8, PredictedToken(token=' Potato', prob=0.00482177734375, logit=16.375, token_id=78703, metadata=None))), (1050, (157, PredictedToken(token=' Re', prob=9.953975677490234e-06, logit=10.1875, token_id=1050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:30 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:30 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:42:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.855, logit=22.625)', '\" Among\"[22395] (p=0.062, logit=20.000)', '\" The\"[578] (p=0.055, logit=19.875)', '\" It\"[1102] (p=0.006, logit=17.625)', '\" \"[220] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     clean_prediction=['\" Monkey\"[58937] (p=0.758, logit=21.625)', '\" The\"[578] (p=0.090, logit=19.500)', '\" A\"[362] (p=0.062, logit=19.125)', '\" Among\"[22395] (p=0.048, logit=18.875)', '\" \"[220] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     clean_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.7578125, logit=21.625, token_id=58937, metadata=None))), (356, (26, PredictedToken(token=' C', prob=0.000446319580078125, logit=14.1875, token_id=356, metadata=None))), (432, (59, PredictedToken(token=' R', prob=6.818771362304688e-05, logit=12.3125, token_id=432, metadata=None))), (80629, (93, PredictedToken(token=' Grape', prob=3.0279159545898438e-05, logit=11.5, token_id=80629, metadata=None))), (47759, (165, PredictedToken(token=' Guitar', prob=9.238719940185547e-06, logit=10.3125, token_id=47759, metadata=None))), (12369, (354, PredictedToken(token=' Food', prob=2.339482307434082e-06, logit=8.9375, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.441, logit=20.500)', '\" C\"[356] (p=0.303, logit=20.125)', '\" The\"[578] (p=0.111, logit=19.125)', '\" Among\"[22395] (p=0.068, logit=18.625)', '\" \"[220] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.44140625, logit=20.5, token_id=80629, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.302734375, logit=20.125, token_id=356, metadata=None))), (12369, (20, PredictedToken(token=' Food', prob=0.000965118408203125, logit=14.375, token_id=12369, metadata=None))), (432, (76, PredictedToken(token=' R', prob=6.580352783203125e-05, logit=11.6875, token_id=432, metadata=None))), (47759, (302, PredictedToken(token=' Guitar', prob=4.76837158203125e-06, logit=9.0625, token_id=47759, metadata=None))), (58937, (729, PredictedToken(token=' Monkey', prob=1.2442469596862793e-06, logit=7.71875, token_id=58937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:31 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:31 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.781, logit=20.875)', '\" None\"[2290] (p=0.050, logit=18.125)', '\" The\"[578] (p=0.044, logit=18.000)', '\" Among\"[22395] (p=0.039, logit=17.875)', '\" A\"[362] (p=0.027, logit=17.500)']\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.770, logit=21.875)', '\" The\"[578] (p=0.092, logit=19.750)', '\" Among\"[22395] (p=0.049, logit=19.125)', '\" A\"[362] (p=0.049, logit=19.125)', '\" sun\"[7160] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.76953125, logit=21.875, token_id=8219, metadata=None))), (17929, (11, PredictedToken(token=' Pin', prob=0.00157928466796875, logit=15.6875, token_id=17929, metadata=None))), (52882, (14, PredictedToken(token=' Pepper', prob=0.0010223388671875, logit=15.25, token_id=52882, metadata=None))), (3420, (119, PredictedToken(token=' Trump', prob=1.5497207641601562e-05, logit=11.0625, token_id=3420, metadata=None))), (22410, (296, PredictedToken(token=' Ju', prob=2.86102294921875e-06, logit=9.375, token_id=22410, metadata=None)))])\n",
      "2025-09-16 09:42:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     int_prediction=['\" Pepper\"[52882] (p=0.785, logit=21.625)', '\" The\"[578] (p=0.073, logit=19.250)', '\" Among\"[22395] (p=0.044, logit=18.750)', '\" A\"[362] (p=0.024, logit=18.125)', '\" Trump\"[3420] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     int_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.78515625, logit=21.625, token_id=52882, metadata=None))), (3420, (5, PredictedToken(token=' Trump', prob=0.01123046875, logit=17.375, token_id=3420, metadata=None))), (17929, (6, PredictedToken(token=' Pin', prob=0.01123046875, logit=17.375, token_id=17929, metadata=None))), (22410, (7, PredictedToken(token=' Ju', prob=0.00872802734375, logit=17.125, token_id=22410, metadata=None))), (8219, (338, PredictedToken(token=' Sun', prob=2.428889274597168e-06, logit=8.9375, token_id=8219, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:32 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     patch_prediction=['\" Watch\"[10573] (p=0.863, logit=21.500)', '\" A\"[362] (p=0.030, logit=18.125)', '\" The\"[578] (p=0.020, logit=17.750)', '\" Among\"[22395] (p=0.014, logit=17.375)', '\" None\"[2290] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.766, logit=21.625)', '\" The\"[578] (p=0.071, logit=19.250)', '\" Among\"[22395] (p=0.049, logit=18.875)', '\" A\"[362] (p=0.049, logit=18.875)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.765625, logit=21.625, token_id=13597, metadata=None))), (356, (9, PredictedToken(token=' C', prob=0.0031280517578125, logit=16.125, token_id=356, metadata=None))), (11683, (21, PredictedToken(token=' Acc', prob=0.00101470947265625, logit=15.0, token_id=11683, metadata=None))), (5250, (42, PredictedToken(token=' Pe', prob=0.0002899169921875, logit=13.75, token_id=5250, metadata=None))), (36358, (394, PredictedToken(token=' Bench', prob=2.682209014892578e-06, logit=9.0625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.053, logit=19.000)', '\" Among\"[22395] (p=0.037, logit=18.625)', '\" A\"[362] (p=0.022, logit=18.125)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.83203125, logit=21.75, token_id=356, metadata=None))), (11683, (27, PredictedToken(token=' Acc', prob=0.00055694580078125, logit=14.4375, token_id=11683, metadata=None))), (13597, (60, PredictedToken(token=' Pen', prob=7.05718994140625e-05, logit=12.375, token_id=13597, metadata=None))), (5250, (324, PredictedToken(token=' Pe', prob=2.7418136596679688e-06, logit=9.125, token_id=5250, metadata=None))), (36358, (892, PredictedToken(token=' Bench', prob=5.550682544708252e-07, logit=7.53125, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:32 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:42:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     patch_prediction=['\" Sofa\"[61948] (p=0.602, logit=21.250)', '\" The\"[578] (p=0.172, logit=20.000)', '\" Among\"[22395] (p=0.082, logit=19.250)', '\" A\"[362] (p=0.082, logit=19.250)', '\" SO\"[5745] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     clean_prediction=['\" Van\"[13000] (p=0.793, logit=21.875)', '\" The\"[578] (p=0.074, logit=19.500)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" A\"[362] (p=0.040, logit=18.875)', '\" VAN\"[97753] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     clean_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.79296875, logit=21.875, token_id=13000, metadata=None))), (5907, (7, PredictedToken(token=' Project', prob=0.005340576171875, logit=16.875, token_id=5907, metadata=None))), (423, (28, PredictedToken(token=' D', prob=0.0003204345703125, logit=14.0625, token_id=423, metadata=None))), (432, (41, PredictedToken(token=' R', prob=0.0001430511474609375, logit=13.25, token_id=432, metadata=None))), (3816, (86, PredictedToken(token=' Red', prob=3.3855438232421875e-05, logit=11.8125, token_id=3816, metadata=None))), (36358, (97, PredictedToken(token=' Bench', prob=2.6345252990722656e-05, logit=11.5625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.629, logit=21.125)', '\" Among\"[22395] (p=0.141, logit=19.625)', '\" The\"[578] (p=0.097, logit=19.250)', '\" Project\"[5907] (p=0.031, logit=18.125)', '\" A\"[362] (p=0.022, logit=17.750)']\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.62890625, logit=21.125, token_id=36358, metadata=None))), (5907, (4, PredictedToken(token=' Project', prob=0.03125, logit=18.125, token_id=5907, metadata=None))), (423, (10, PredictedToken(token=' D', prob=0.0037384033203125, logit=16.0, token_id=423, metadata=None))), (432, (19, PredictedToken(token=' R', prob=0.00188446044921875, logit=15.3125, token_id=432, metadata=None))), (13000, (34, PredictedToken(token=' Van', prob=0.00041961669921875, logit=13.8125, token_id=13000, metadata=None))), (3816, (121, PredictedToken(token=' Red', prob=2.682209014892578e-05, logit=11.0625, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:33 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:33 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     patch_prediction=['\" Tr\"[1183] (p=0.730, logit=21.875)', '\" The\"[578] (p=0.099, logit=19.875)', '\" A\"[362] (p=0.068, logit=19.500)', '\" Among\"[22395] (p=0.041, logit=19.000)', '\" Option\"[7104] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.477, logit=19.625)', '\" Hel\"[16183] (p=0.328, logit=19.250)', '\" None\"[2290] (p=0.050, logit=17.375)', '\" The\"[578] (p=0.021, logit=16.500)', '\" Viol\"[30555] (p=0.018, logit=16.375)']\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.4765625, logit=19.625, token_id=24423, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.328125, logit=19.25, token_id=16183, metadata=None))), (30555, (5, PredictedToken(token=' Viol', prob=0.0184326171875, logit=16.375, token_id=30555, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.005645751953125, logit=15.1875, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:42:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.352, logit=18.500)', '\" Dolphin\"[96096] (p=0.311, logit=18.375)', '\" None\"[2290] (p=0.188, logit=17.875)', '\" The\"[578] (p=0.017, logit=15.500)', '\" Among\"[22395] (p=0.016, logit=15.438)']\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.3515625, logit=18.5, token_id=24423, metadata=None))), (96096, (2, PredictedToken(token=' Dolphin', prob=0.310546875, logit=18.375, token_id=96096, metadata=None))), (30555, (37, PredictedToken(token=' Viol', prob=0.000637054443359375, logit=12.1875, token_id=30555, metadata=None))), (16183, (42, PredictedToken(token=' Hel', prob=0.000598907470703125, logit=12.125, token_id=16183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:34 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:34 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.042, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.625)', '\" slow\"[6435] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.812, logit=22.375)', '\" The\"[578] (p=0.097, logit=20.250)', '\" A\"[362] (p=0.031, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=18.750)', '\" (\"[320] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.8125, logit=22.375, token_id=60413, metadata=None))), (47643, (24, PredictedToken(token=' Cel', prob=0.0002899169921875, logit=14.4375, token_id=47643, metadata=None))), (88668, (45, PredictedToken(token=' Blender', prob=6.914138793945312e-05, logit=13.0, token_id=88668, metadata=None)))])\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     int_prediction=['\" Blender\"[88668] (p=0.930, logit=22.625)', '\" The\"[578] (p=0.025, logit=19.000)', '\" Among\"[22395] (p=0.010, logit=18.125)', '\" Cel\"[47643] (p=0.006, logit=17.625)', '\" It\"[1102] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     int_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.9296875, logit=22.625, token_id=88668, metadata=None))), (47643, (4, PredictedToken(token=' Cel', prob=0.006256103515625, logit=17.625, token_id=47643, metadata=None))), (60413, (8515, PredictedToken(token=' Uk', prob=1.3737007975578308e-08, logit=4.59375, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:34 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:34 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:42:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.867, logit=21.500)', '\" The\"[578] (p=0.038, logit=18.375)', '\" A\"[362] (p=0.034, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.125)', '\" factory\"[8803] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     clean_prediction=['\" Bamboo\"[98028] (p=0.879, logit=21.750)', '\" None\"[2290] (p=0.026, logit=18.250)', '\" The\"[578] (p=0.026, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.375)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     clean_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.87890625, logit=21.75, token_id=98028, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.004058837890625, logit=16.375, token_id=4923, metadata=None))), (800, (15, PredictedToken(token=' St', prob=0.00159454345703125, logit=15.4375, token_id=800, metadata=None)))])\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.805, logit=21.750)', '\" None\"[2290] (p=0.075, logit=19.375)', '\" St\"[800] (p=0.040, logit=18.750)', '\" The\"[578] (p=0.024, logit=18.250)', '\" A\"[362] (p=0.017, logit=17.875)']\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.8046875, logit=21.75, token_id=4923, metadata=None))), (800, (3, PredictedToken(token=' St', prob=0.0400390625, logit=18.75, token_id=800, metadata=None))), (98028, (258, PredictedToken(token=' Bamboo', prob=4.082918167114258e-06, logit=9.5625, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:35 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:35 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.891, logit=22.500)', '\" The\"[578] (p=0.044, logit=19.500)', '\" Among\"[22395] (p=0.027, logit=19.000)', '\" A\"[362] (p=0.010, logit=18.000)', '\" Palm\"[33578] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.723, logit=21.500)', '\" The\"[578] (p=0.111, logit=19.625)', '\" A\"[362] (p=0.059, logit=19.000)', '\" Among\"[22395] (p=0.052, logit=18.875)', '\" It\"[1102] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.72265625, logit=21.5, token_id=432, metadata=None))), (49431, (47, PredictedToken(token=' Rabbit', prob=0.000156402587890625, logit=13.0625, token_id=49431, metadata=None))), (27217, (58, PredictedToken(token=' Train', prob=8.916854858398438e-05, logit=12.5, token_id=27217, metadata=None))), (76924, (230, PredictedToken(token=' Banana', prob=5.364418029785156e-06, logit=9.6875, token_id=76924, metadata=None))), (27171, (288, PredictedToken(token=' Coffee', prob=3.4570693969726562e-06, logit=9.25, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:42:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     int_prediction=['\" Banana\"[76924] (p=0.746, logit=21.125)', '\" The\"[578] (p=0.115, logit=19.250)', '\" Among\"[22395] (p=0.048, logit=18.375)', '\" Coffee\"[27171] (p=0.023, logit=17.625)', '\" It\"[1102] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     int_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.74609375, logit=21.125, token_id=76924, metadata=None))), (27171, (4, PredictedToken(token=' Coffee', prob=0.0225830078125, logit=17.625, token_id=27171, metadata=None))), (49431, (33, PredictedToken(token=' Rabbit', prob=0.0003223419189453125, logit=13.375, token_id=49431, metadata=None))), (432, (107, PredictedToken(token=' R', prob=3.1948089599609375e-05, logit=11.0625, token_id=432, metadata=None))), (27217, (317, PredictedToken(token=' Train', prob=4.589557647705078e-06, logit=9.125, token_id=27217, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:36 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:36 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     patch_prediction=['\" Daisy\"[71264] (p=0.676, logit=21.375)', '\" The\"[578] (p=0.117, logit=19.625)', '\" A\"[362] (p=0.071, logit=19.125)', '\" Among\"[22395] (p=0.062, logit=19.000)', '\" d\"[294] (p=0.033, logit=18.375)']\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.902, logit=22.875)', '\" A\"[362] (p=0.035, logit=19.625)', '\" The\"[578] (p=0.027, logit=19.375)', '\" Among\"[22395] (p=0.017, logit=18.875)', '\" It\"[1102] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.90234375, logit=22.875, token_id=70762, metadata=None))), (48035, (74, PredictedToken(token=' Gir', prob=1.823902130126953e-05, logit=12.0625, token_id=48035, metadata=None))), (921, (80, PredictedToken(token=' Ch', prob=1.4185905456542969e-05, logit=11.8125, token_id=921, metadata=None))), (58251, (164, PredictedToken(token=' Tennis', prob=2.9802322387695312e-06, logit=10.25, token_id=58251, metadata=None))), (63606, (487, PredictedToken(token=' Stap', prob=4.5634806156158447e-07, logit=8.375, token_id=63606, metadata=None))), (57551, (756, PredictedToken(token=' Sink', prob=2.3655593395233154e-07, logit=7.71875, token_id=57551, metadata=None)))])\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     int_prediction=['\" Ch\"[921] (p=0.789, logit=22.250)', '\" The\"[578] (p=0.083, logit=20.000)', '\" Among\"[22395] (p=0.057, logit=19.625)', '\" A\"[362] (p=0.035, logit=19.125)', '\" It\"[1102] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     int_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.7890625, logit=22.25, token_id=921, metadata=None))), (48035, (6, PredictedToken(token=' Gir', prob=0.004150390625, logit=17.0, token_id=48035, metadata=None))), (58251, (234, PredictedToken(token=' Tennis', prob=2.4437904357910156e-06, logit=9.5625, token_id=58251, metadata=None))), (63606, (259, PredictedToken(token=' Stap', prob=2.16066837310791e-06, logit=9.4375, token_id=63606, metadata=None))), (70762, (592, PredictedToken(token=' Motorcycle', prob=4.954636096954346e-07, logit=7.96875, token_id=70762, metadata=None))), (57551, (628, PredictedToken(token=' Sink', prob=4.507601261138916e-07, logit=7.875, token_id=57551, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:36 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:42:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.762, logit=21.000)', '\" The\"[578] (p=0.091, logit=18.875)', '\" Among\"[22395] (p=0.038, logit=18.000)', '\" A\"[362] (p=0.033, logit=17.875)', '\" Option\"[7104] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     clean_prediction=['\" Printer\"[47033] (p=0.844, logit=22.000)', '\" The\"[578] (p=0.061, logit=19.375)', '\" A\"[362] (p=0.042, logit=19.000)', '\" Among\"[22395] (p=0.015, logit=18.000)', '\" printer\"[23185] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     clean_track=OrderedDict([(47033, (1, PredictedToken(token=' Printer', prob=0.84375, logit=22.0, token_id=47033, metadata=None))), (445, (90, PredictedToken(token=' L', prob=2.6345252990722656e-05, logit=11.625, token_id=445, metadata=None))), (24941, (212, PredictedToken(token=' Bear', prob=4.559755325317383e-06, logit=9.875, token_id=24941, metadata=None))), (67553, (1492, PredictedToken(token=' Pants', prob=2.5890767574310303e-07, logit=7.0, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.523, logit=19.750)', '\" Among\"[22395] (p=0.192, logit=18.750)', '\" The\"[578] (p=0.116, logit=18.250)', '\" L\"[445] (p=0.038, logit=17.125)', '\" Pant\"[54222] (p=0.010, logit=15.812)']\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.5234375, logit=19.75, token_id=67553, metadata=None))), (445, (4, PredictedToken(token=' L', prob=0.037841796875, logit=17.125, token_id=445, metadata=None))), (24941, (7, PredictedToken(token=' Bear', prob=0.00958251953125, logit=15.75, token_id=24941, metadata=None))), (47033, (37, PredictedToken(token=' Printer', prob=0.000507354736328125, logit=12.8125, token_id=47033, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:37 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.828, logit=21.625)', '\" The\"[578] (p=0.060, logit=19.000)', '\" A\"[362] (p=0.047, logit=18.750)', '\" Among\"[22395] (p=0.020, logit=17.875)', '\" BAT\"[79081] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:42:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     clean_prediction=['\" Ti\"[23126] (p=0.730, logit=22.125)', '\" The\"[578] (p=0.112, logit=20.250)', '\" A\"[362] (p=0.077, logit=19.875)', '\" Among\"[22395] (p=0.041, logit=19.250)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     clean_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.73046875, logit=22.125, token_id=23126, metadata=None))), (8325, (48, PredictedToken(token=' Apple', prob=9.584426879882812e-05, logit=13.1875, token_id=8325, metadata=None))), (97796, (450, PredictedToken(token=' Skate', prob=1.1324882507324219e-06, logit=8.75, token_id=97796, metadata=None))), (48471, (445, PredictedToken(token=' Shower', prob=1.1324882507324219e-06, logit=8.75, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.691, logit=21.125)', '\" The\"[578] (p=0.175, logit=19.750)', '\" A\"[362] (p=0.030, logit=18.000)', '\" Among\"[22395] (p=0.024, logit=17.750)', '\" It\"[1102] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.69140625, logit=21.125, token_id=97796, metadata=None))), (48471, (16, PredictedToken(token=' Shower', prob=0.00133514404296875, logit=14.875, token_id=48471, metadata=None))), (8325, (313, PredictedToken(token=' Apple', prob=5.125999450683594e-06, logit=9.3125, token_id=8325, metadata=None))), (23126, (4987, PredictedToken(token=' Ti', prob=9.685754776000977e-08, logit=5.34375, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:38 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:38 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.879, logit=22.875)', '\" A\"[362] (p=0.034, logit=19.625)', '\" The\"[578] (p=0.026, logit=19.375)', '\" cow\"[19923] (p=0.023, logit=19.250)', '\" Among\"[22395] (p=0.011, logit=18.500)']\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.863, logit=21.875)', '\" None\"[2290] (p=0.033, logit=18.625)', '\" An\"[1556] (p=0.033, logit=18.625)', '\" The\"[578] (p=0.023, logit=18.250)', '\" Among\"[22395] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.86328125, logit=21.875, token_id=53889, metadata=None))), (91263, (6, PredictedToken(token=' Binder', prob=0.003997802734375, logit=16.5, token_id=91263, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.0022735595703125, logit=15.9375, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.691, logit=20.750)', '\" None\"[2290] (p=0.225, logit=19.625)', '\" The\"[578] (p=0.024, logit=17.375)', '\" Among\"[22395] (p=0.008, logit=16.250)', '\" none\"[7000] (p=0.007, logit=16.125)']\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.69140625, logit=20.75, token_id=96096, metadata=None))), (53889, (76, PredictedToken(token=' Apartment', prob=4.863739013671875e-05, logit=11.1875, token_id=53889, metadata=None))), (91263, (1364, PredictedToken(token=' Binder', prob=7.152557373046875e-07, logit=6.96875, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:38 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:42:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.508, logit=21.000)', '\" The\"[578] (p=0.271, logit=20.375)', '\" A\"[362] (p=0.088, logit=19.250)', '\" Among\"[22395] (p=0.069, logit=19.000)', '\" It\"[1102] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     clean_prediction=['\" Tennis\"[58251] (p=0.668, logit=20.625)', '\" The\"[578] (p=0.132, logit=19.000)', '\" A\"[362] (p=0.080, logit=18.500)', '\" Among\"[22395] (p=0.038, logit=17.750)', '\" It\"[1102] (p=0.011, logit=16.500)']\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     clean_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.66796875, logit=20.625, token_id=58251, metadata=None))), (46506, (8, PredictedToken(token=' Drum', prob=0.004791259765625, logit=15.6875, token_id=46506, metadata=None))), (22249, (71, PredictedToken(token=' Ring', prob=8.7738037109375e-05, logit=11.6875, token_id=22249, metadata=None))), (48390, (90, PredictedToken(token=' Lily', prob=6.031990051269531e-05, logit=11.3125, token_id=48390, metadata=None))), (11896, (253, PredictedToken(token=' Library', prob=7.68899917602539e-06, logit=9.25, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.738, logit=21.375)', '\" The\"[578] (p=0.078, logit=19.125)', '\" Among\"[22395] (p=0.069, logit=19.000)', '\" Drum\"[46506] (p=0.032, logit=18.250)', '\" A\"[362] (p=0.017, logit=17.625)']\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.73828125, logit=21.375, token_id=22249, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.032470703125, logit=18.25, token_id=46506, metadata=None))), (58251, (48, PredictedToken(token=' Tennis', prob=0.0001697540283203125, logit=13.0, token_id=58251, metadata=None))), (48390, (71, PredictedToken(token=' Lily', prob=7.104873657226562e-05, logit=12.125, token_id=48390, metadata=None))), (11896, (269, PredictedToken(token=' Library', prob=3.993511199951172e-06, logit=9.25, token_id=11896, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:39 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     patch_prediction=['\" Bamboo\"[98028] (p=0.793, logit=20.750)', '\" The\"[578] (p=0.065, logit=18.250)', '\" A\"[362] (p=0.040, logit=17.750)', '\" Among\"[22395] (p=0.019, logit=17.000)', '\" Only\"[8442] (p=0.011, logit=16.500)']\n",
      "2025-09-16 09:42:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.801, logit=22.250)', '\" A\"[362] (p=0.074, logit=19.875)', '\" The\"[578] (p=0.058, logit=19.625)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" food\"[3691] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.80078125, logit=22.25, token_id=12369, metadata=None))), (15883, (10, PredictedToken(token=' Spr', prob=0.003692626953125, logit=16.875, token_id=15883, metadata=None))), (76924, (18, PredictedToken(token=' Banana', prob=0.000934600830078125, logit=15.5, token_id=76924, metadata=None)))])\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     int_prediction=['\" Spr\"[15883] (p=0.461, logit=21.625)', '\" Banana\"[76924] (p=0.461, logit=21.625)', '\" The\"[578] (p=0.026, logit=18.750)', '\" Among\"[22395] (p=0.014, logit=18.125)', '\" spr\"[8314] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     int_track=OrderedDict([(76924, (2, PredictedToken(token=' Banana', prob=0.4609375, logit=21.625, token_id=76924, metadata=None))), (15883, (1, PredictedToken(token=' Spr', prob=0.4609375, logit=21.625, token_id=15883, metadata=None))), (12369, (1182, PredictedToken(token=' Food', prob=2.551823854446411e-07, logit=7.21875, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:40 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     patch_prediction=['\" Eagle\"[36895] (p=0.730, logit=21.375)', '\" An\"[1556] (p=0.087, logit=19.250)', '\" The\"[578] (p=0.068, logit=19.000)', '\" Among\"[22395] (p=0.047, logit=18.625)', '\" Option\"[7104] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.832, logit=21.375)', '\" The\"[578] (p=0.087, logit=19.125)', '\" Among\"[22395] (p=0.020, logit=17.625)', '\" A\"[362] (p=0.020, logit=17.625)', '\" Only\"[8442] (p=0.003, logit=15.812)']\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.83203125, logit=21.375, token_id=82994, metadata=None))), (13597, (113, PredictedToken(token=' Pen', prob=2.765655517578125e-05, logit=11.0625, token_id=13597, metadata=None))), (48035, (121, PredictedToken(token=' Gir', prob=2.4318695068359375e-05, logit=10.9375, token_id=48035, metadata=None))), (98641, (159, PredictedToken(token=' Microwave', prob=1.3887882232666016e-05, logit=10.375, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     int_prediction=['\" Gir\"[48035] (p=0.781, logit=21.625)', '\" The\"[578] (p=0.082, logit=19.375)', '\" A\"[362] (p=0.082, logit=19.375)', '\" Among\"[22395] (p=0.016, logit=17.750)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     int_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.78125, logit=21.625, token_id=48035, metadata=None))), (98641, (77, PredictedToken(token=' Microwave', prob=4.839897155761719e-05, logit=11.9375, token_id=98641, metadata=None))), (82994, (141, PredictedToken(token=' Toilet', prob=1.3887882232666016e-05, logit=10.6875, token_id=82994, metadata=None))), (13597, (222, PredictedToken(token=' Pen', prob=5.0961971282958984e-06, logit=9.6875, token_id=13597, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:40 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:40 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:42:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.887, logit=22.000)', '\" The\"[578] (p=0.039, logit=18.875)', '\" Among\"[22395] (p=0.027, logit=18.500)', '\" A\"[362] (p=0.018, logit=18.125)', '\" It\"[1102] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     clean_prediction=['\" Monkey\"[58937] (p=0.684, logit=21.750)', '\" The\"[578] (p=0.105, logit=19.875)', '\" A\"[362] (p=0.093, logit=19.750)', '\" Among\"[22395] (p=0.072, logit=19.500)', '\" \"[220] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     clean_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.68359375, logit=21.75, token_id=58937, metadata=None))), (1630, (21, PredictedToken(token=' X', prob=0.00070953369140625, logit=14.875, token_id=1630, metadata=None))), (2057, (60, PredictedToken(token=' To', prob=7.43865966796875e-05, logit=12.625, token_id=2057, metadata=None))), (22249, (228, PredictedToken(token=' Ring', prob=4.470348358154297e-06, logit=9.8125, token_id=22249, metadata=None))), (91782, (1521, PredictedToken(token=' Shorts', prob=2.3748725652694702e-07, logit=6.875, token_id=91782, metadata=None))), (70110, (3391, PredictedToken(token=' Ottoman', prob=8.475035429000854e-08, logit=5.84375, token_id=70110, metadata=None)))])\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     int_prediction=['\" To\"[2057] (p=0.688, logit=21.375)', '\" The\"[578] (p=0.120, logit=19.625)', '\" Among\"[22395] (p=0.056, logit=18.875)', '\" X\"[1630] (p=0.050, logit=18.750)', '\" A\"[362] (p=0.024, logit=18.000)']\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     int_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.6875, logit=21.375, token_id=2057, metadata=None))), (1630, (4, PredictedToken(token=' X', prob=0.0498046875, logit=18.75, token_id=1630, metadata=None))), (91782, (43, PredictedToken(token=' Shorts', prob=0.00021648406982421875, logit=13.3125, token_id=91782, metadata=None))), (70110, (117, PredictedToken(token=' Ottoman', prob=2.288818359375e-05, logit=11.0625, token_id=70110, metadata=None))), (22249, (190, PredictedToken(token=' Ring', prob=8.940696716308594e-06, logit=10.125, token_id=22249, metadata=None))), (58937, (3828, PredictedToken(token=' Monkey', prob=5.657784640789032e-08, logit=5.0625, token_id=58937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:41 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     patch_prediction=['\" Bear\"[24941] (p=0.723, logit=21.500)', '\" The\"[578] (p=0.098, logit=19.500)', '\" A\"[362] (p=0.086, logit=19.375)', '\" Among\"[22395] (p=0.041, logit=18.625)', '\" (\"[320] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:42:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.855, logit=22.500)', '\" The\"[578] (p=0.048, logit=19.625)', '\" An\"[1556] (p=0.038, logit=19.375)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" Banana\"[76924] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.85546875, logit=22.5, token_id=6690, metadata=None))), (76924, (5, PredictedToken(token=' Banana', prob=0.005096435546875, logit=17.375, token_id=76924, metadata=None))), (328, (49, PredictedToken(token=' S', prob=6.818771362304688e-05, logit=13.0625, token_id=328, metadata=None))), (83499, (101, PredictedToken(token=' Tooth', prob=1.621246337890625e-05, logit=11.625, token_id=83499, metadata=None))), (97796, (203, PredictedToken(token=' Skate', prob=3.6209821701049805e-06, logit=10.125, token_id=97796, metadata=None))), (14588, (350, PredictedToken(token=' Dog', prob=1.3336539268493652e-06, logit=9.125, token_id=14588, metadata=None)))])\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.828, logit=22.375)', '\" Among\"[22395] (p=0.047, logit=19.500)', '\" The\"[578] (p=0.047, logit=19.500)', '\" None\"[2290] (p=0.025, logit=18.875)', '\" Banana\"[76924] (p=0.010, logit=18.000)']\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.828125, logit=22.375, token_id=14588, metadata=None))), (76924, (5, PredictedToken(token=' Banana', prob=0.01043701171875, logit=18.0, token_id=76924, metadata=None))), (328, (20, PredictedToken(token=' S', prob=0.0008544921875, logit=15.5, token_id=328, metadata=None))), (83499, (28, PredictedToken(token=' Tooth', prob=0.0003566741943359375, logit=14.625, token_id=83499, metadata=None))), (97796, (227, PredictedToken(token=' Skate', prob=3.2782554626464844e-06, logit=9.9375, token_id=97796, metadata=None))), (6690, (1217, PredictedToken(token=' Air', prob=2.1606683731079102e-07, logit=7.21875, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:42 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:42 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.777, logit=21.500)', '\" The\"[578] (p=0.064, logit=19.000)', '\" A\"[362] (p=0.030, logit=18.250)', '\" Among\"[22395] (p=0.027, logit=18.125)', '\" Option\"[7104] (p=0.016, logit=17.625)']\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     clean_prediction=['\" Marker\"[40975] (p=0.906, logit=22.500)', '\" A\"[362] (p=0.031, logit=19.125)', '\" The\"[578] (p=0.027, logit=19.000)', '\" marker\"[11381] (p=0.008, logit=17.750)', '\" Among\"[22395] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     clean_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.90625, logit=22.5, token_id=40975, metadata=None))), (24941, (66, PredictedToken(token=' Bear', prob=3.409385681152344e-05, logit=12.3125, token_id=24941, metadata=None))), (71264, (136, PredictedToken(token=' Daisy', prob=8.106231689453125e-06, logit=10.875, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.484, logit=20.500)', '\" Daisy\"[71264] (p=0.332, logit=20.125)', '\" The\"[578] (p=0.058, logit=18.375)', '\" d\"[294] (p=0.027, logit=17.625)', '\" Among\"[22395] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.484375, logit=20.5, token_id=24941, metadata=None))), (71264, (2, PredictedToken(token=' Daisy', prob=0.33203125, logit=20.125, token_id=71264, metadata=None))), (40975, (30, PredictedToken(token=' Marker', prob=0.0004711151123046875, logit=13.5625, token_id=40975, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:42 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:42 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:42:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.816, logit=21.625)', '\" A\"[362] (p=0.076, logit=19.250)', '\" The\"[578] (p=0.036, logit=18.500)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.793, logit=21.875)', '\" The\"[578] (p=0.083, logit=19.625)', '\" Among\"[22395] (p=0.065, logit=19.375)', '\" A\"[362] (p=0.024, logit=18.375)', '\" socks\"[40086] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.79296875, logit=21.875, token_id=328, metadata=None))), (4923, (17, PredictedToken(token=' Sk', prob=0.000560760498046875, logit=14.625, token_id=4923, metadata=None))), (432, (36, PredictedToken(token=' R', prob=0.00018215179443359375, logit=13.5, token_id=432, metadata=None))), (1443, (74, PredictedToken(token=' Sh', prob=3.814697265625e-05, logit=11.9375, token_id=1443, metadata=None))), (45332, (294, PredictedToken(token=' Boat', prob=2.16066837310791e-06, logit=9.0625, token_id=45332, metadata=None))), (33199, (364, PredictedToken(token=' Lion', prob=1.4826655387878418e-06, logit=8.6875, token_id=33199, metadata=None)))])\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.770, logit=22.000)', '\" The\"[578] (p=0.071, logit=19.625)', '\" Among\"[22395] (p=0.063, logit=19.500)', '\" Boat\"[45332] (p=0.026, logit=18.625)', '\" A\"[362] (p=0.026, logit=18.625)']\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.76953125, logit=22.0, token_id=4923, metadata=None))), (45332, (5, PredictedToken(token=' Boat', prob=0.0262451171875, logit=18.625, token_id=45332, metadata=None))), (33199, (8, PredictedToken(token=' Lion', prob=0.0040283203125, logit=16.75, token_id=33199, metadata=None))), (328, (18, PredictedToken(token=' S', prob=0.00061798095703125, logit=14.875, token_id=328, metadata=None))), (1443, (39, PredictedToken(token=' Sh', prob=0.0001773834228515625, logit=13.625, token_id=1443, metadata=None))), (432, (149, PredictedToken(token=' R', prob=8.821487426757812e-06, logit=10.625, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:43 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.934, logit=23.125)', '\" The\"[578] (p=0.025, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" Option\"[7104] (p=0.003, logit=17.500)', '\" (\"[320] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:42:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.770, logit=21.250)', '\" The\"[578] (p=0.082, logit=19.000)', '\" A\"[362] (p=0.063, logit=18.750)', '\" None\"[2290] (p=0.011, logit=17.000)', '\" F\"[435] (p=0.009, logit=16.750)']\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.76953125, logit=21.25, token_id=36943, metadata=None))), (1630, (20, PredictedToken(token=' X', prob=0.0009613037109375, logit=14.5625, token_id=1630, metadata=None))), (4923, (25, PredictedToken(token=' Sk', prob=0.000659942626953125, logit=14.1875, token_id=4923, metadata=None)))])\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.672, logit=20.250)', '\" None\"[2290] (p=0.117, logit=18.500)', '\" The\"[578] (p=0.071, logit=18.000)', '\" Sk\"[4923] (p=0.030, logit=17.125)', '\" Among\"[22395] (p=0.023, logit=16.875)']\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.671875, logit=20.25, token_id=1630, metadata=None))), (4923, (4, PredictedToken(token=' Sk', prob=0.029541015625, logit=17.125, token_id=4923, metadata=None))), (36943, (38, PredictedToken(token=' Folder', prob=0.0003719329833984375, logit=12.75, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:44 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.805, logit=21.875)', '\" The\"[578] (p=0.085, logit=19.625)', '\" Among\"[22395] (p=0.035, logit=18.750)', '\" A\"[362] (p=0.031, logit=18.625)', '\" Out\"[4470] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.855, logit=21.750)', '\" A\"[362] (p=0.048, logit=18.875)', '\" The\"[578] (p=0.038, logit=18.625)', '\" Among\"[22395] (p=0.016, logit=17.750)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.85546875, logit=21.75, token_id=17367, metadata=None))), (48471, (9, PredictedToken(token=' Shower', prob=0.00225830078125, logit=15.8125, token_id=48471, metadata=None))), (393, (13, PredictedToken(token=' P', prob=0.00113677978515625, logit=15.125, token_id=393, metadata=None))), (82507, (17, PredictedToken(token=' Jeans', prob=0.000881195068359375, logit=14.875, token_id=82507, metadata=None))), (17929, (58, PredictedToken(token=' Pin', prob=9.918212890625e-05, logit=12.6875, token_id=17929, metadata=None)))])\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     int_prediction=['\" Jeans\"[82507] (p=0.479, logit=20.250)', '\" P\"[393] (p=0.291, logit=19.750)', '\" The\"[578] (p=0.065, logit=18.250)', '\" Among\"[22395] (p=0.044, logit=17.875)', '\" None\"[2290] (p=0.024, logit=17.250)']\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     int_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.478515625, logit=20.25, token_id=82507, metadata=None))), (393, (2, PredictedToken(token=' P', prob=0.291015625, logit=19.75, token_id=393, metadata=None))), (17929, (7, PredictedToken(token=' Pin', prob=0.0068359375, logit=16.0, token_id=17929, metadata=None))), (17367, (115, PredictedToken(token=' Factory', prob=5.555152893066406e-05, logit=11.1875, token_id=17367, metadata=None))), (48471, (224, PredictedToken(token=' Shower', prob=1.3172626495361328e-05, logit=9.75, token_id=48471, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:44 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:42:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.820, logit=21.250)', '\" An\"[1556] (p=0.067, logit=18.750)', '\" The\"[578] (p=0.041, logit=18.250)', '\" Among\"[22395] (p=0.022, logit=17.625)', '\" It\"[1102] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.836, logit=21.250)', '\" The\"[578] (p=0.068, logit=18.750)', '\" Among\"[22395] (p=0.042, logit=18.250)', '\" toilet\"[27306] (p=0.005, logit=16.125)', '\" A\"[362] (p=0.004, logit=15.875)']\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.8359375, logit=21.25, token_id=82994, metadata=None))), (97796, (64, PredictedToken(token=' Skate', prob=0.000102996826171875, logit=12.25, token_id=97796, metadata=None))), (3061, (152, PredictedToken(token=' Fl', prob=1.5735626220703125e-05, logit=10.375, token_id=3061, metadata=None))), (58937, (232, PredictedToken(token=' Monkey', prob=7.450580596923828e-06, logit=9.625, token_id=58937, metadata=None))), (50159, (283, PredictedToken(token=' Sco', prob=4.827976226806641e-06, logit=9.1875, token_id=50159, metadata=None))), (71264, (715, PredictedToken(token=' Daisy', prob=1.214444637298584e-06, logit=7.8125, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     int_prediction=['\" Daisy\"[71264] (p=0.828, logit=21.500)', '\" The\"[578] (p=0.077, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=17.875)', '\" A\"[362] (p=0.017, logit=17.625)', '\" d\"[294] (p=0.017, logit=17.625)']\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     int_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.828125, logit=21.5, token_id=71264, metadata=None))), (3061, (15, PredictedToken(token=' Fl', prob=0.00096893310546875, logit=14.75, token_id=3061, metadata=None))), (58937, (19, PredictedToken(token=' Monkey', prob=0.000518798828125, logit=14.125, token_id=58937, metadata=None))), (97796, (102, PredictedToken(token=' Skate', prob=2.276897430419922e-05, logit=11.0, token_id=97796, metadata=None))), (50159, (348, PredictedToken(token=' Sco', prob=2.726912498474121e-06, logit=8.875, token_id=50159, metadata=None))), (82994, (388, PredictedToken(token=' Toilet', prob=2.250075340270996e-06, logit=8.6875, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:45 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.836, logit=22.375)', '\" A\"[362] (p=0.061, logit=19.750)', '\" The\"[578] (p=0.042, logit=19.375)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" cuff\"[75523] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:42:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     clean_prediction=['\" Cat\"[17810] (p=0.852, logit=22.625)', '\" The\"[578] (p=0.054, logit=19.875)', '\" A\"[362] (p=0.029, logit=19.250)', '\" Among\"[22395] (p=0.018, logit=18.750)', '\" cat\"[8415] (p=0.016, logit=18.625)']\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     clean_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.8515625, logit=22.625, token_id=17810, metadata=None))), (17929, (9, PredictedToken(token=' Pin', prob=0.0023956298828125, logit=16.75, token_id=17929, metadata=None))), (70110, (48, PredictedToken(token=' Ottoman', prob=5.984306335449219e-05, logit=13.0625, token_id=70110, metadata=None)))])\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     int_prediction=['\" Pin\"[17929] (p=0.898, logit=22.500)', '\" The\"[578] (p=0.031, logit=19.125)', '\" Among\"[22395] (p=0.016, logit=18.500)', '\" A\"[362] (p=0.011, logit=18.125)', '\" pin\"[9160] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     int_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.8984375, logit=22.5, token_id=17929, metadata=None))), (17810, (12, PredictedToken(token=' Cat', prob=0.0019683837890625, logit=16.375, token_id=17810, metadata=None))), (70110, (34, PredictedToken(token=' Ottoman', prob=0.00018215179443359375, logit=14.0, token_id=70110, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:46 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:46 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     patch_prediction=['\" Pine\"[42609] (p=0.824, logit=21.750)', '\" The\"[578] (p=0.087, logit=19.500)', '\" Among\"[22395] (p=0.046, logit=18.875)', '\" A\"[362] (p=0.010, logit=17.375)', '\" \"[220] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     clean_prediction=['\" Magn\"[20918] (p=0.820, logit=21.625)', '\" Among\"[22395] (p=0.067, logit=19.125)', '\" The\"[578] (p=0.052, logit=18.875)', '\" A\"[362] (p=0.012, logit=17.375)', '\" Option\"[7104] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     clean_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.8203125, logit=21.625, token_id=20918, metadata=None))), (30558, (27, PredictedToken(token=' Ki', prob=0.000400543212890625, logit=14.0, token_id=30558, metadata=None))), (34954, (48, PredictedToken(token=' Mirror', prob=0.00012969970703125, logit=12.875, token_id=34954, metadata=None))), (56491, (306, PredictedToken(token=' Piano', prob=3.0547380447387695e-06, logit=9.125, token_id=56491, metadata=None)))])\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     int_prediction=['\" Ki\"[30558] (p=0.887, logit=22.125)', '\" The\"[578] (p=0.039, logit=19.000)', '\" Among\"[22395] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.008, logit=17.375)', '\" Option\"[7104] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     int_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.88671875, logit=22.125, token_id=30558, metadata=None))), (56491, (6, PredictedToken(token=' Piano', prob=0.0059814453125, logit=17.125, token_id=56491, metadata=None))), (34954, (164, PredictedToken(token=' Mirror', prob=5.811452865600586e-06, logit=10.1875, token_id=34954, metadata=None))), (20918, (210, PredictedToken(token=' Magn', prob=3.516674041748047e-06, logit=9.6875, token_id=20918, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:46 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:46 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:42:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.961, logit=22.375)', '\" Among\"[22395] (p=0.009, logit=17.750)', '\" The\"[578] (p=0.009, logit=17.750)', '\" A\"[362] (p=0.005, logit=17.125)', '\" None\"[2290] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.770, logit=22.125)', '\" The\"[578] (p=0.092, logit=20.000)', '\" Among\"[22395] (p=0.063, logit=19.625)', '\" A\"[362] (p=0.034, logit=19.000)', '\" School\"[6150] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.76953125, logit=22.125, token_id=19111, metadata=None))), (6150, (5, PredictedToken(token=' School', prob=0.005859375, logit=17.25, token_id=6150, metadata=None))), (74968, (48, PredictedToken(token=' Razor', prob=9.489059448242188e-05, logit=13.125, token_id=74968, metadata=None))), (59825, (182, PredictedToken(token=' Tie', prob=5.692243576049805e-06, logit=10.3125, token_id=59825, metadata=None))), (74574, (298, PredictedToken(token=' Violet', prob=2.1010637283325195e-06, logit=9.3125, token_id=74574, metadata=None))), (61948, (531, PredictedToken(token=' Sofa', prob=8.195638656616211e-07, logit=8.375, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.879, logit=21.750)', '\" Among\"[22395] (p=0.050, logit=18.875)', '\" The\"[578] (p=0.034, logit=18.500)', '\" Option\"[7104] (p=0.004, logit=16.375)', '\" A\"[362] (p=0.003, logit=16.125)']\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.87890625, logit=21.75, token_id=74574, metadata=None))), (74968, (11, PredictedToken(token=' Razor', prob=0.00124359130859375, logit=15.1875, token_id=74968, metadata=None))), (19111, (24, PredictedToken(token=' Bus', prob=0.0003337860107421875, logit=13.875, token_id=19111, metadata=None))), (6150, (30, PredictedToken(token=' School', prob=0.000293731689453125, logit=13.75, token_id=6150, metadata=None))), (61948, (36, PredictedToken(token=' Sofa', prob=0.00017833709716796875, logit=13.25, token_id=61948, metadata=None))), (59825, (46, PredictedToken(token=' Tie', prob=0.00010156631469726562, logit=12.6875, token_id=59825, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:47 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     patch_prediction=['\" Paper\"[18343] (p=0.844, logit=22.375)', '\" The\"[578] (p=0.061, logit=19.750)', '\" A\"[362] (p=0.037, logit=19.250)', '\" Among\"[22395] (p=0.022, logit=18.750)', '\" It\"[1102] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:42:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.770, logit=22.125)', '\" A\"[362] (p=0.072, logit=19.750)', '\" The\"[578] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=19.125)', '\" (\"[320] (p=0.012, logit=18.000)']\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.76953125, logit=22.125, token_id=1183, metadata=None))), (27738, (13, PredictedToken(token=' Ward', prob=0.00157928466796875, logit=15.9375, token_id=27738, metadata=None))), (37128, (73, PredictedToken(token=' Calculator', prob=3.504753112792969e-05, logit=12.125, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.453, logit=20.500)', '\" Ward\"[27738] (p=0.311, logit=20.125)', '\" Calculator\"[37128] (p=0.069, logit=18.625)', '\" Among\"[22395] (p=0.061, logit=18.500)', '\" The\"[578] (p=0.037, logit=18.000)']\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     int_track=OrderedDict([(27738, (2, PredictedToken(token=' Ward', prob=0.310546875, logit=20.125, token_id=27738, metadata=None))), (37128, (3, PredictedToken(token=' Calculator', prob=0.0693359375, logit=18.625, token_id=37128, metadata=None))), (1183, (161, PredictedToken(token=' Tr', prob=1.1682510375976562e-05, logit=9.9375, token_id=1183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:48 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.828, logit=20.875)', '\" The\"[578] (p=0.060, logit=18.250)', '\" Among\"[22395] (p=0.036, logit=17.750)', '\" toilet\"[27306] (p=0.008, logit=16.250)', '\" Only\"[8442] (p=0.005, logit=15.812)']\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.602, logit=21.625)', '\" The\"[578] (p=0.173, logit=20.375)', '\" Among\"[22395] (p=0.082, logit=19.625)', '\" A\"[362] (p=0.082, logit=19.625)', '\" It\"[1102] (p=0.013, logit=17.750)']\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.6015625, logit=21.625, token_id=1630, metadata=None))), (61731, (42, PredictedToken(token=' Soap', prob=0.0001392364501953125, logit=13.25, token_id=61731, metadata=None))), (15883, (62, PredictedToken(token=' Spr', prob=7.915496826171875e-05, logit=12.6875, token_id=15883, metadata=None))), (10164, (172, PredictedToken(token=' Water', prob=8.344650268554688e-06, logit=10.4375, token_id=10164, metadata=None))), (49431, (654, PredictedToken(token=' Rabbit', prob=6.258487701416016e-07, logit=7.84375, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.836, logit=22.125)', '\" Among\"[22395] (p=0.053, logit=19.375)', '\" The\"[578] (p=0.053, logit=19.375)', '\" Water\"[10164] (p=0.017, logit=18.250)', '\" SOAP\"[64332] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.8359375, logit=22.125, token_id=61731, metadata=None))), (10164, (4, PredictedToken(token=' Water', prob=0.017333984375, logit=18.25, token_id=10164, metadata=None))), (15883, (16, PredictedToken(token=' Spr', prob=0.0007171630859375, logit=15.0625, token_id=15883, metadata=None))), (1630, (306, PredictedToken(token=' X', prob=1.8924474716186523e-06, logit=9.125, token_id=1630, metadata=None))), (49431, (492, PredictedToken(token=' Rabbit', prob=8.940696716308594e-07, logit=8.375, token_id=49431, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:48 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:48 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:42:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.848, logit=21.875)', '\" The\"[578] (p=0.070, logit=19.375)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" A\"[362] (p=0.006, logit=17.000)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.863, logit=22.375)', '\" The\"[578] (p=0.071, logit=19.875)', '\" A\"[362] (p=0.020, logit=18.625)', '\" Among\"[22395] (p=0.016, logit=18.375)', '\" It\"[1102] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.86328125, logit=22.375, token_id=3420, metadata=None))), (16344, (40, PredictedToken(token=' Rose', prob=0.00011348724365234375, logit=13.4375, token_id=16344, metadata=None))), (11452, (48, PredictedToken(token=' Head', prob=6.866455078125e-05, logit=12.9375, token_id=11452, metadata=None))), (40975, (89, PredictedToken(token=' Marker', prob=2.09808349609375e-05, logit=11.75, token_id=40975, metadata=None)))])\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.852, logit=22.250)', '\" The\"[578] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.029, logit=18.875)', '\" Among\"[22395] (p=0.020, logit=18.500)', '\" It\"[1102] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.8515625, logit=22.25, token_id=16344, metadata=None))), (40975, (9, PredictedToken(token=' Marker', prob=0.0023956298828125, logit=16.375, token_id=40975, metadata=None))), (11452, (42, PredictedToken(token=' Head', prob=0.00011920928955078125, logit=13.375, token_id=11452, metadata=None))), (3420, (362, PredictedToken(token=' Trump', prob=1.2442469596862793e-06, logit=8.8125, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:49 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:49 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.805, logit=22.875)', '\" The\"[578] (p=0.075, logit=20.500)', '\" A\"[362] (p=0.075, logit=20.500)', '\" Among\"[22395] (p=0.017, logit=19.000)', '\" Dress\"[29318] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:42:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.060, logit=19.125)', '\" A\"[362] (p=0.037, logit=18.625)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" It\"[1102] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.83203125, logit=21.75, token_id=432, metadata=None))), (8325, (40, PredictedToken(token=' Apple', prob=0.00015926361083984375, logit=13.1875, token_id=8325, metadata=None))), (29318, (89, PredictedToken(token=' Dress', prob=3.337860107421875e-05, logit=11.625, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.832, logit=21.250)', '\" Apple\"[8325] (p=0.047, logit=18.375)', '\" The\"[578] (p=0.037, logit=18.125)', '\" None\"[2290] (p=0.025, logit=17.750)', '\" Among\"[22395] (p=0.009, logit=16.750)']\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.83203125, logit=21.25, token_id=29318, metadata=None))), (8325, (2, PredictedToken(token=' Apple', prob=0.046875, logit=18.375, token_id=8325, metadata=None))), (432, (66, PredictedToken(token=' R', prob=7.963180541992188e-05, logit=12.0, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:50 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.816, logit=22.375)', '\" The\"[578] (p=0.086, logit=20.125)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" A\"[362] (p=0.025, logit=18.875)', '\" d\"[294] (p=0.022, logit=18.750)']\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     clean_prediction=['\" Strawberry\"[89077] (p=0.762, logit=21.125)', '\" The\"[578] (p=0.080, logit=18.875)', '\" Among\"[22395] (p=0.062, logit=18.625)', '\" A\"[362] (p=0.018, logit=17.375)', '\" Option\"[7104] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     clean_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.76171875, logit=21.125, token_id=89077, metadata=None))), (426, (18, PredictedToken(token=' B', prob=0.000949859619140625, logit=14.4375, token_id=426, metadata=None))), (36895, (49, PredictedToken(token=' Eagle', prob=0.00019931793212890625, logit=12.875, token_id=36895, metadata=None))), (2947, (53, PredictedToken(token=' Mar', prob=0.00016498565673828125, logit=12.6875, token_id=2947, metadata=None))), (68027, (138, PredictedToken(token=' Sax', prob=1.9669532775878906e-05, logit=10.5625, token_id=68027, metadata=None)))])\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.723, logit=21.125)', '\" The\"[578] (p=0.076, logit=18.875)', '\" Among\"[22395] (p=0.067, logit=18.750)', '\" Eagle\"[36895] (p=0.032, logit=18.000)', '\" Option\"[7104] (p=0.017, logit=17.375)']\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.72265625, logit=21.125, token_id=2947, metadata=None))), (36895, (4, PredictedToken(token=' Eagle', prob=0.03173828125, logit=18.0, token_id=36895, metadata=None))), (426, (12, PredictedToken(token=' B', prob=0.0035552978515625, logit=15.8125, token_id=426, metadata=None))), (68027, (132, PredictedToken(token=' Sax', prob=2.2530555725097656e-05, logit=10.75, token_id=68027, metadata=None))), (89077, (1189, PredictedToken(token=' Strawberry', prob=5.476176738739014e-07, logit=7.03125, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:50 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:50 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:42:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     patch_prediction=['\" School\"[6150] (p=0.762, logit=21.875)', '\" None\"[2290] (p=0.117, logit=20.000)', '\" The\"[578] (p=0.033, logit=18.750)', '\" Among\"[22395] (p=0.020, logit=18.250)', '\" Plum\"[84409] (p=0.016, logit=18.000)']\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     clean_prediction=['\" Pear\"[23910] (p=0.801, logit=22.625)', '\" The\"[578] (p=0.084, logit=20.375)', '\" Among\"[22395] (p=0.045, logit=19.750)', '\" A\"[362] (p=0.045, logit=19.750)', '\" pear\"[38790] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     clean_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.80078125, logit=22.625, token_id=23910, metadata=None))), (3341, (83, PredictedToken(token=' Car', prob=1.519918441772461e-05, logit=11.75, token_id=3341, metadata=None))), (3420, (97, PredictedToken(token=' Trump', prob=1.1801719665527344e-05, logit=11.5, token_id=3420, metadata=None))), (82507, (495, PredictedToken(token=' Jeans', prob=6.258487701416016e-07, logit=8.5625, token_id=82507, metadata=None))), (15429, (760, PredictedToken(token=' Hospital', prob=3.3527612686157227e-07, logit=7.9375, token_id=15429, metadata=None))), (67629, (2186, PredictedToken(token=' Helmet', prob=9.033828973770142e-08, logit=6.625, token_id=67629, metadata=None)))])\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     int_prediction=['\" Hospital\"[15429] (p=0.762, logit=22.250)', '\" The\"[578] (p=0.103, logit=20.250)', '\" Among\"[22395] (p=0.091, logit=20.125)', '\" A\"[362] (p=0.010, logit=17.875)', '\" Car\"[3341] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     int_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.76171875, logit=22.25, token_id=15429, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.0045166015625, logit=17.125, token_id=3341, metadata=None))), (82507, (23, PredictedToken(token=' Jeans', prob=0.0003719329833984375, logit=14.625, token_id=82507, metadata=None))), (67629, (30, PredictedToken(token=' Helmet', prob=0.000225067138671875, logit=14.125, token_id=67629, metadata=None))), (3420, (155, PredictedToken(token=' Trump', prob=6.794929504394531e-06, logit=10.625, token_id=3420, metadata=None))), (23910, (2321, PredictedToken(token=' Pear', prob=1.0337680578231812e-07, logit=6.4375, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:51 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:51 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:42:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.621, logit=22.500)', '\" An\"[1556] (p=0.178, logit=21.250)', '\" The\"[578] (p=0.122, logit=20.875)', '\" Among\"[22395] (p=0.040, logit=19.750)', '\" e\"[384] (p=0.010, logit=18.375)']\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.688, logit=21.000)', '\" An\"[1556] (p=0.119, logit=19.250)', '\" The\"[578] (p=0.093, logit=19.000)', '\" Among\"[22395] (p=0.044, logit=18.250)', '\" It\"[1102] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.6875, logit=21.0, token_id=87035, metadata=None))), (20423, (7, PredictedToken(token=' Amb', prob=0.00360107421875, logit=15.75, token_id=20423, metadata=None))), (39794, (53, PredictedToken(token=' Desk', prob=0.00013065338134765625, logit=12.4375, token_id=39794, metadata=None))), (86460, (93, PredictedToken(token=' Necklace', prob=4.00543212890625e-05, logit=11.25, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.730, logit=20.625)', '\" The\"[578] (p=0.087, logit=18.500)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" None\"[2290] (p=0.032, logit=17.500)', '\" It\"[1102] (p=0.009, logit=16.250)']\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.73046875, logit=20.625, token_id=86460, metadata=None))), (20423, (92, PredictedToken(token=' Amb', prob=5.4836273193359375e-05, logit=11.125, token_id=20423, metadata=None))), (39794, (113, PredictedToken(token=' Desk', prob=3.7670135498046875e-05, logit=10.75, token_id=39794, metadata=None))), (87035, (214, PredictedToken(token=' Onion', prob=1.3887882232666016e-05, logit=9.75, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:52 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.910, logit=23.125)', '\" The\"[578] (p=0.031, logit=19.750)', '\" A\"[362] (p=0.024, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" Motor\"[18079] (p=0.002, logit=17.125)']\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.848, logit=22.375)', '\" The\"[578] (p=0.054, logit=19.625)', '\" An\"[1556] (p=0.042, logit=19.375)', '\" Among\"[22395] (p=0.029, logit=19.000)', '\" ank\"[71572] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.84765625, logit=22.375, token_id=57915, metadata=None))), (60413, (17, PredictedToken(token=' Uk', prob=0.000499725341796875, logit=14.9375, token_id=60413, metadata=None))), (800, (69, PredictedToken(token=' St', prob=2.8133392333984375e-05, logit=12.0625, token_id=800, metadata=None))), (34785, (367, PredictedToken(token=' Truck', prob=1.2367963790893555e-06, logit=8.9375, token_id=34785, metadata=None)))])\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     int_prediction=['\" Truck\"[34785] (p=0.734, logit=21.750)', '\" The\"[578] (p=0.145, logit=20.125)', '\" Among\"[22395] (p=0.047, logit=19.000)', '\" It\"[1102] (p=0.010, logit=17.500)', '\" A\"[362] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:42:52 src.selection.optimization INFO     int_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.734375, logit=21.75, token_id=34785, metadata=None))), (800, (130, PredictedToken(token=' St', prob=1.9073486328125e-05, logit=11.1875, token_id=800, metadata=None))), (57915, (2596, PredictedToken(token=' Ank', prob=1.648440957069397e-07, logit=6.4375, token_id=57915, metadata=None))), (60413, (3192, PredictedToken(token=' Uk', prob=1.2386590242385864e-07, logit=6.15625, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:53 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.820, logit=21.500)', '\" The\"[578] (p=0.052, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.500)', '\" A\"[362] (p=0.041, logit=18.500)', '\" (\"[320] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.691, logit=20.750)', '\" The\"[578] (p=0.120, logit=19.000)', '\" Among\"[22395] (p=0.083, logit=18.625)', '\" A\"[362] (p=0.024, logit=17.375)', '\" B\"[426] (p=0.013, logit=16.750)']\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.69140625, logit=20.75, token_id=88088, metadata=None))), (81501, (13, PredictedToken(token=' Pendant', prob=0.00142669677734375, logit=14.5625, token_id=81501, metadata=None))), (41493, (40, PredictedToken(token=' Tow', prob=0.0003376007080078125, logit=13.125, token_id=41493, metadata=None))), (22410, (167, PredictedToken(token=' Ju', prob=1.5854835510253906e-05, logit=10.0625, token_id=22410, metadata=None))), (27217, (925, PredictedToken(token=' Train', prob=1.296401023864746e-06, logit=7.5625, token_id=27217, metadata=None)))])\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     int_prediction=['\" Tow\"[41493] (p=0.566, logit=20.375)', '\" Ju\"[22410] (p=0.144, logit=19.000)', '\" Among\"[22395] (p=0.068, logit=18.250)', '\" The\"[578] (p=0.068, logit=18.250)', '\" Pendant\"[81501] (p=0.046, logit=17.875)']\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     int_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.56640625, logit=20.375, token_id=41493, metadata=None))), (22410, (2, PredictedToken(token=' Ju', prob=0.1435546875, logit=19.0, token_id=22410, metadata=None))), (81501, (5, PredictedToken(token=' Pendant', prob=0.04638671875, logit=17.875, token_id=81501, metadata=None))), (27217, (8, PredictedToken(token=' Train', prob=0.01507568359375, logit=16.75, token_id=27217, metadata=None))), (88088, (826, PredictedToken(token=' Birch', prob=1.5422701835632324e-06, logit=7.5625, token_id=88088, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:53 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:42:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.058, logit=19.000)', '\" Among\"[22395] (p=0.045, logit=18.750)', '\" A\"[362] (p=0.040, logit=18.625)', '\" BAT\"[79081] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.785, logit=22.125)', '\" The\"[578] (p=0.094, logit=20.000)', '\" A\"[362] (p=0.030, logit=18.875)', '\" Among\"[22395] (p=0.027, logit=18.750)', '\" It\"[1102] (p=0.014, logit=18.125)']\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.78515625, logit=22.125, token_id=30555, metadata=None))), (426, (17, PredictedToken(token=' B', prob=0.00110626220703125, logit=15.5625, token_id=426, metadata=None))), (34954, (39, PredictedToken(token=' Mirror', prob=0.0001811981201171875, logit=13.75, token_id=34954, metadata=None))), (66821, (184, PredictedToken(token=' Iris', prob=4.827976226806641e-06, logit=10.125, token_id=66821, metadata=None))), (87035, (973, PredictedToken(token=' Onion', prob=2.812594175338745e-07, logit=7.28125, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     int_prediction=['\" Mirror\"[34954] (p=0.730, logit=21.500)', '\" Among\"[22395] (p=0.053, logit=18.875)', '\" The\"[578] (p=0.053, logit=18.875)', '\" b\"[293] (p=0.028, logit=18.250)', '\" B\"[426] (p=0.022, logit=18.000)']\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     int_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.73046875, logit=21.5, token_id=34954, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.0220947265625, logit=18.0, token_id=426, metadata=None))), (66821, (7, PredictedToken(token=' Iris', prob=0.01513671875, logit=17.625, token_id=66821, metadata=None))), (87035, (47, PredictedToken(token=' Onion', prob=0.00020313262939453125, logit=13.3125, token_id=87035, metadata=None))), (30555, (181, PredictedToken(token=' Viol', prob=8.940696716308594e-06, logit=10.1875, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:42:54 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:42:54 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.750, logit=22.125)', '\" The\"[578] (p=0.115, logit=20.250)', '\" Among\"[22395] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.048, logit=19.375)', '\" Pearl\"[37343] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     clean_prediction=['\" Scar\"[30760] (p=0.391, logit=20.375)', '\" The\"[578] (p=0.209, logit=19.750)', '\" A\"[362] (p=0.185, logit=19.625)', '\" Among\"[22395] (p=0.144, logit=19.375)', '\" Out\"[4470] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     clean_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.390625, logit=20.375, token_id=30760, metadata=None))), (63606, (35, PredictedToken(token=' Stap', prob=0.0003337860107421875, logit=13.3125, token_id=63606, metadata=None))), (91963, (57, PredictedToken(token=' Mango', prob=0.00013065338134765625, logit=12.375, token_id=91963, metadata=None))), (58251, (196, PredictedToken(token=' Tennis', prob=1.0728836059570312e-05, logit=9.875, token_id=58251, metadata=None))), (12369, (301, PredictedToken(token=' Food', prob=5.066394805908203e-06, logit=9.125, token_id=12369, metadata=None))), (14669, (1123, PredictedToken(token=' Camera', prob=6.854534149169922e-07, logit=7.125, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     int_prediction=['\" Mango\"[91963] (p=0.420, logit=20.125)', '\" The\"[578] (p=0.198, logit=19.375)', '\" Tennis\"[58251] (p=0.176, logit=19.250)', '\" Among\"[22395] (p=0.106, logit=18.750)', '\" A\"[362] (p=0.021, logit=17.125)']\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     int_track=OrderedDict([(91963, (1, PredictedToken(token=' Mango', prob=0.419921875, logit=20.125, token_id=91963, metadata=None))), (58251, (3, PredictedToken(token=' Tennis', prob=0.17578125, logit=19.25, token_id=58251, metadata=None))), (12369, (8, PredictedToken(token=' Food', prob=0.006011962890625, logit=15.875, token_id=12369, metadata=None))), (14669, (1011, PredictedToken(token=' Camera', prob=1.1101365089416504e-06, logit=7.28125, token_id=14669, metadata=None))), (63606, (1699, PredictedToken(token=' Stap', prob=5.774199962615967e-07, logit=6.625, token_id=63606, metadata=None))), (30760, (15226, PredictedToken(token=' Scar', prob=2.2351741790771484e-08, logit=3.375, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:55 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.590, logit=20.875)', '\" The\"[578] (p=0.132, logit=19.375)', '\" Keyboard\"[26698] (p=0.103, logit=19.125)', '\" Among\"[22395] (p=0.048, logit=18.375)', '\" A\"[362] (p=0.026, logit=17.750)']\n",
      "2025-09-16 09:42:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.902, logit=22.500)', '\" The\"[578] (p=0.035, logit=19.250)', '\" A\"[362] (p=0.021, logit=18.750)', '\" Among\"[22395] (p=0.013, logit=18.250)', '\" None\"[2290] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.90234375, logit=22.5, token_id=29625, metadata=None))), (31181, (122, PredictedToken(token=' Clar', prob=1.0371208190917969e-05, logit=11.125, token_id=31181, metadata=None))), (16730, (220, PredictedToken(token=' Museum', prob=3.159046173095703e-06, logit=9.9375, token_id=16730, metadata=None))), (97796, (276, PredictedToken(token=' Skate', prob=2.175569534301758e-06, logit=9.5625, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.844, logit=21.625)', '\" The\"[578] (p=0.061, logit=19.000)', '\" A\"[362] (p=0.023, logit=18.000)', '\" Among\"[22395] (p=0.020, logit=17.875)', '\" None\"[2290] (p=0.011, logit=17.250)']\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.84375, logit=21.625, token_id=31181, metadata=None))), (16730, (11, PredictedToken(token=' Museum', prob=0.0019683837890625, logit=15.5625, token_id=16730, metadata=None))), (29625, (83, PredictedToken(token=' Chain', prob=4.935264587402344e-05, logit=11.875, token_id=29625, metadata=None))), (97796, (155, PredictedToken(token=' Skate', prob=1.329183578491211e-05, logit=10.5625, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:56 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:56 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     patch_prediction=['\" Project\"[5907] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.061, logit=19.125)', '\" A\"[362] (p=0.029, logit=18.375)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" It\"[1102] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     clean_prediction=['\" Yoga\"[38673] (p=0.680, logit=20.500)', '\" A\"[362] (p=0.092, logit=18.500)', '\" The\"[578] (p=0.081, logit=18.375)', '\" Among\"[22395] (p=0.034, logit=17.500)', '\" None\"[2290] (p=0.030, logit=17.375)']\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     clean_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.6796875, logit=20.5, token_id=38673, metadata=None))), (30558, (46, PredictedToken(token=' Ki', prob=0.000331878662109375, logit=12.875, token_id=30558, metadata=None))), (14642, (87, PredictedToken(token=' Phone', prob=7.867813110351562e-05, logit=11.4375, token_id=14642, metadata=None))), (86460, (99, PredictedToken(token=' Necklace', prob=6.532669067382812e-05, logit=11.25, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.477, logit=19.875)', '\" Phone\"[14642] (p=0.371, logit=19.625)', '\" Among\"[22395] (p=0.027, logit=17.000)', '\" The\"[578] (p=0.027, logit=17.000)', '\" Option\"[7104] (p=0.013, logit=16.250)']\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     int_track=OrderedDict([(14642, (2, PredictedToken(token=' Phone', prob=0.37109375, logit=19.625, token_id=14642, metadata=None))), (30558, (10, PredictedToken(token=' Ki', prob=0.003875732421875, logit=15.0625, token_id=30558, metadata=None))), (38673, (37, PredictedToken(token=' Yoga', prob=0.0003833770751953125, logit=12.75, token_id=38673, metadata=None))), (86460, (121, PredictedToken(token=' Necklace', prob=4.0531158447265625e-05, logit=10.5, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:56 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:42:56 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:42:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     patch_prediction=['\" Calculator\"[37128] (p=0.586, logit=20.125)', '\" The\"[578] (p=0.115, logit=18.500)', '\" A\"[362] (p=0.079, logit=18.125)', '\" Camera\"[14669] (p=0.062, logit=17.875)', '\" Among\"[22395] (p=0.033, logit=17.250)']\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.812, logit=21.500)', '\" A\"[362] (p=0.052, logit=18.750)', '\" The\"[578] (p=0.046, logit=18.625)', '\" Among\"[22395] (p=0.031, logit=18.250)', '\" It\"[1102] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.8125, logit=21.5, token_id=16730, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.003753662109375, logit=16.125, token_id=4923, metadata=None))), (91297, (36, PredictedToken(token=' Mushroom', prob=0.0002117156982421875, logit=13.25, token_id=91297, metadata=None))), (13597, (73, PredictedToken(token=' Pen', prob=5.364418029785156e-05, logit=11.875, token_id=13597, metadata=None)))])\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.762, logit=21.250)', '\" None\"[2290] (p=0.117, logit=19.375)', '\" The\"[578] (p=0.033, logit=18.125)', '\" A\"[362] (p=0.026, logit=17.875)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.76171875, logit=21.25, token_id=13597, metadata=None))), (4923, (8, PredictedToken(token=' Sk', prob=0.003997802734375, logit=16.0, token_id=4923, metadata=None))), (91297, (35, PredictedToken(token=' Mushroom', prob=0.000255584716796875, logit=13.25, token_id=91297, metadata=None))), (16730, (79, PredictedToken(token=' Museum', prob=5.340576171875e-05, logit=11.6875, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:57 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     patch_prediction=['\" Uk\"[60413] (p=0.797, logit=22.000)', '\" The\"[578] (p=0.095, logit=19.875)', '\" Among\"[22395] (p=0.040, logit=19.000)', '\" A\"[362] (p=0.027, logit=18.625)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:42:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.809, logit=22.500)', '\" The\"[578] (p=0.066, logit=20.000)', '\" A\"[362] (p=0.059, logit=19.875)', '\" Among\"[22395] (p=0.046, logit=19.625)', '\" None\"[2290] (p=0.002, logit=16.500)']\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.80859375, logit=22.5, token_id=33711, metadata=None))), (31181, (31, PredictedToken(token=' Clar', prob=0.00018596649169921875, logit=14.125, token_id=31181, metadata=None))), (34785, (98, PredictedToken(token=' Truck', prob=1.52587890625e-05, logit=11.625, token_id=34785, metadata=None))), (10164, (399, PredictedToken(token=' Water', prob=9.760260581970215e-07, logit=8.875, token_id=10164, metadata=None))), (22410, (677, PredictedToken(token=' Ju', prob=4.6193599700927734e-07, logit=8.125, token_id=22410, metadata=None)))])\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.621, logit=20.875)', '\" Among\"[22395] (p=0.156, logit=19.500)', '\" The\"[578] (p=0.084, logit=18.875)', '\" None\"[2290] (p=0.065, logit=18.625)', '\" A\"[362] (p=0.019, logit=17.375)']\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.62109375, logit=20.875, token_id=31181, metadata=None))), (22410, (10, PredictedToken(token=' Ju', prob=0.00286865234375, logit=15.5, token_id=22410, metadata=None))), (10164, (117, PredictedToken(token=' Water', prob=3.3855438232421875e-05, logit=11.0625, token_id=10164, metadata=None))), (33711, (326, PredictedToken(token=' Suit', prob=4.32133674621582e-06, logit=9.0, token_id=33711, metadata=None))), (34785, (548, PredictedToken(token=' Truck', prob=1.7955899238586426e-06, logit=8.125, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:58 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:42:58 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     patch_prediction=['\" Tie\"[59825] (p=0.848, logit=22.125)', '\" The\"[578] (p=0.054, logit=19.375)', '\" A\"[362] (p=0.037, logit=19.000)', '\" Among\"[22395] (p=0.026, logit=18.625)', '\" Option\"[7104] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     clean_prediction=['\" Potato\"[78703] (p=0.840, logit=22.125)', '\" The\"[578] (p=0.061, logit=19.500)', '\" Among\"[22395] (p=0.032, logit=18.875)', '\" A\"[362] (p=0.029, logit=18.750)', '\" Pot\"[14020] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     clean_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.83984375, logit=22.125, token_id=78703, metadata=None))), (328, (9, PredictedToken(token=' S', prob=0.0020751953125, logit=16.125, token_id=328, metadata=None))), (6031, (13, PredictedToken(token=' Bro', prob=0.00104522705078125, logit=15.4375, token_id=6031, metadata=None)))])\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.479, logit=21.125)', '\" S\"[328] (p=0.373, logit=20.875)', '\" The\"[578] (p=0.051, logit=18.875)', '\" Among\"[22395] (p=0.031, logit=18.375)', '\" A\"[362] (p=0.021, logit=18.000)']\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.478515625, logit=21.125, token_id=6031, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.373046875, logit=20.875, token_id=328, metadata=None))), (78703, (15, PredictedToken(token=' Potato', prob=0.00104522705078125, logit=15.0, token_id=78703, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:58 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:58 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:42:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.832, logit=22.750)', '\" The\"[578] (p=0.078, logit=20.375)', '\" Among\"[22395] (p=0.060, logit=20.125)', '\" A\"[362] (p=0.008, logit=18.125)', '\" z\"[1167] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     clean_prediction=['\" Football\"[21424] (p=0.930, logit=22.250)', '\" The\"[578] (p=0.028, logit=18.750)', '\" Among\"[22395] (p=0.010, logit=17.750)', '\" A\"[362] (p=0.006, logit=17.125)', '\" Acc\"[11683] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     clean_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.9296875, logit=22.25, token_id=21424, metadata=None))), (11683, (5, PredictedToken(token=' Acc', prob=0.0026092529296875, logit=16.375, token_id=11683, metadata=None))), (393, (28, PredictedToken(token=' P', prob=0.000202178955078125, logit=13.8125, token_id=393, metadata=None))), (48665, (38, PredictedToken(token=' Raspberry', prob=0.00013065338134765625, logit=13.375, token_id=48665, metadata=None))), (94091, (958, PredictedToken(token=' Tomato', prob=3.129243850708008e-07, logit=7.34375, token_id=94091, metadata=None)))])\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     int_prediction=['\" Raspberry\"[48665] (p=0.250, logit=18.250)', '\" None\"[2290] (p=0.194, logit=18.000)', '\" Tomato\"[94091] (p=0.118, logit=17.500)', '\" The\"[578] (p=0.104, logit=17.375)', '\" Football\"[21424] (p=0.081, logit=17.125)']\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     int_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.25, logit=18.25, token_id=48665, metadata=None))), (94091, (3, PredictedToken(token=' Tomato', prob=0.1181640625, logit=17.5, token_id=94091, metadata=None))), (21424, (5, PredictedToken(token=' Football', prob=0.0810546875, logit=17.125, token_id=21424, metadata=None))), (393, (36, PredictedToken(token=' P', prob=0.00122833251953125, logit=12.9375, token_id=393, metadata=None))), (11683, (80, PredictedToken(token=' Acc', prob=0.0002918243408203125, logit=11.5, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:42:59 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:42:59 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.734, logit=21.250)', '\" Ki\"[30558] (p=0.100, logit=19.250)', '\" The\"[578] (p=0.042, logit=18.375)', '\" Among\"[22395] (p=0.037, logit=18.250)', '\" A\"[362] (p=0.032, logit=18.125)']\n",
      "2025-09-16 09:42:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.824, logit=21.000)', '\" The\"[578] (p=0.047, logit=18.125)', '\" Among\"[22395] (p=0.036, logit=17.875)', '\" A\"[362] (p=0.025, logit=17.500)', '\" Option\"[7104] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.82421875, logit=21.0, token_id=57551, metadata=None))), (24423, (19, PredictedToken(token=' Monitor', prob=0.00080108642578125, logit=14.0625, token_id=24423, metadata=None))), (42609, (20, PredictedToken(token=' Pine', prob=0.000705718994140625, logit=13.9375, token_id=42609, metadata=None))), (22607, (66, PredictedToken(token=' Cow', prob=0.00011539459228515625, logit=12.125, token_id=22607, metadata=None))), (41342, (258, PredictedToken(token=' Hockey', prob=6.943941116333008e-06, logit=9.3125, token_id=41342, metadata=None)))])\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.539, logit=19.875)', '\" Cow\"[22607] (p=0.289, logit=19.250)', '\" Among\"[22395] (p=0.044, logit=17.375)', '\" The\"[578] (p=0.034, logit=17.125)', '\" None\"[2290] (p=0.014, logit=16.250)']\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.5390625, logit=19.875, token_id=42609, metadata=None))), (22607, (2, PredictedToken(token=' Cow', prob=0.2890625, logit=19.25, token_id=22607, metadata=None))), (57551, (122, PredictedToken(token=' Sink', prob=4.029273986816406e-05, logit=10.375, token_id=57551, metadata=None))), (41342, (453, PredictedToken(token=' Hockey', prob=4.5299530029296875e-06, logit=8.1875, token_id=41342, metadata=None))), (24423, (1569, PredictedToken(token=' Monitor', prob=8.642673492431641e-07, logit=6.53125, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:00 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.914, logit=22.125)', '\" The\"[578] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.021, logit=18.375)', '\" warehouse\"[31212] (p=0.007, logit=17.250)', '\" Among\"[22395] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     clean_prediction=['\" Lion\"[33199] (p=0.777, logit=21.875)', '\" The\"[578] (p=0.105, logit=19.875)', '\" Among\"[22395] (p=0.034, logit=18.750)', '\" A\"[362] (p=0.027, logit=18.500)', '\" Option\"[7104] (p=0.016, logit=18.000)']\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     clean_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.77734375, logit=21.875, token_id=33199, metadata=None))), (6031, (100, PredictedToken(token=' Bro', prob=1.8835067749023438e-05, logit=11.25, token_id=6031, metadata=None))), (19176, (216, PredictedToken(token=' Temple', prob=4.202127456665039e-06, logit=9.75, token_id=19176, metadata=None))), (16478, (261, PredictedToken(token=' Chair', prob=2.8908252716064453e-06, logit=9.375, token_id=16478, metadata=None)))])\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     int_prediction=['\" Chair\"[16478] (p=0.445, logit=20.875)', '\" The\"[578] (p=0.145, logit=19.750)', '\" Bro\"[6031] (p=0.128, logit=19.625)', '\" Among\"[22395] (p=0.112, logit=19.500)', '\" Temple\"[19176] (p=0.053, logit=18.750)']\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     int_track=OrderedDict([(16478, (1, PredictedToken(token=' Chair', prob=0.4453125, logit=20.875, token_id=16478, metadata=None))), (6031, (3, PredictedToken(token=' Bro', prob=0.1279296875, logit=19.625, token_id=6031, metadata=None))), (19176, (5, PredictedToken(token=' Temple', prob=0.05322265625, logit=18.75, token_id=19176, metadata=None))), (33199, (104, PredictedToken(token=' Lion', prob=3.552436828613281e-05, logit=11.4375, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:00 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:00 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:43:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.078, logit=19.500)', '\" Among\"[22395] (p=0.020, logit=18.125)', '\" A\"[362] (p=0.020, logit=18.125)', '\" It\"[1102] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.855, logit=22.375)', '\" The\"[578] (p=0.042, logit=19.375)', '\" A\"[362] (p=0.042, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.875)', '\" (\"[320] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.85546875, logit=22.375, token_id=88668, metadata=None))), (32749, (34, PredictedToken(token=' Carn', prob=0.00015354156494140625, logit=13.75, token_id=32749, metadata=None))), (38673, (86, PredictedToken(token=' Yoga', prob=1.621246337890625e-05, logit=11.5, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     int_prediction=['\" Carn\"[32749] (p=0.789, logit=20.375)', '\" The\"[578] (p=0.050, logit=17.625)', '\" Among\"[22395] (p=0.039, logit=17.375)', '\" Yoga\"[38673] (p=0.019, logit=16.625)', '\" None\"[2290] (p=0.016, logit=16.500)']\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     int_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.7890625, logit=20.375, token_id=32749, metadata=None))), (38673, (4, PredictedToken(token=' Yoga', prob=0.0185546875, logit=16.625, token_id=38673, metadata=None))), (88668, (288, PredictedToken(token=' Blender', prob=7.033348083496094e-06, logit=8.75, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:01 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:01 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.664, logit=21.875)', '\" The\"[578] (p=0.147, logit=20.375)', '\" Among\"[22395] (p=0.090, logit=19.875)', '\" A\"[362] (p=0.062, logit=19.500)', '\" sun\"[7160] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:43:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.797, logit=22.500)', '\" A\"[362] (p=0.065, logit=20.000)', '\" The\"[578] (p=0.058, logit=19.875)', '\" Among\"[22395] (p=0.045, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.796875, logit=22.5, token_id=45332, metadata=None))), (15429, (6, PredictedToken(token=' Hospital', prob=0.003692626953125, logit=17.125, token_id=15429, metadata=None))), (17810, (120, PredictedToken(token=' Cat', prob=1.2516975402832031e-05, logit=11.4375, token_id=17810, metadata=None))), (55870, (181, PredictedToken(token=' Jacket', prob=4.887580871582031e-06, logit=10.5, token_id=55870, metadata=None))), (47759, (200, PredictedToken(token=' Guitar', prob=4.32133674621582e-06, logit=10.375, token_id=47759, metadata=None))), (66821, (423, PredictedToken(token=' Iris', prob=1.0281801223754883e-06, logit=8.9375, token_id=66821, metadata=None)))])\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.883, logit=22.375)', '\" Among\"[22395] (p=0.056, logit=19.625)', '\" The\"[578] (p=0.021, logit=18.625)', '\" Cat\"[17810] (p=0.005, logit=17.250)', '\" None\"[2290] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.8828125, logit=22.375, token_id=66821, metadata=None))), (17810, (4, PredictedToken(token=' Cat', prob=0.0052490234375, logit=17.25, token_id=17810, metadata=None))), (45332, (60, PredictedToken(token=' Boat', prob=4.839897155761719e-05, logit=12.5625, token_id=45332, metadata=None))), (55870, (157, PredictedToken(token=' Jacket', prob=5.424022674560547e-06, logit=10.375, token_id=55870, metadata=None))), (47759, (259, PredictedToken(token=' Guitar', prob=2.4139881134033203e-06, logit=9.5625, token_id=47759, metadata=None))), (15429, (532, PredictedToken(token=' Hospital', prob=6.48200511932373e-07, logit=8.25, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:02 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:02 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     patch_prediction=['\" Willow\"[65449] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.042, logit=18.375)', '\" Among\"[22395] (p=0.017, logit=17.500)', '\" Blue\"[8868] (p=0.014, logit=17.250)', '\" None\"[2290] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     clean_prediction=['\" Banana\"[76924] (p=0.770, logit=21.875)', '\" The\"[578] (p=0.092, logit=19.750)', '\" A\"[362] (p=0.049, logit=19.125)', '\" Among\"[22395] (p=0.038, logit=18.875)', '\" (\"[320] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     clean_track=OrderedDict([(76924, (1, PredictedToken(token=' Banana', prob=0.76953125, logit=21.875, token_id=76924, metadata=None))), (33578, (32, PredictedToken(token=' Palm', prob=0.0002593994140625, logit=13.875, token_id=33578, metadata=None))), (13394, (208, PredictedToken(token=' Bed', prob=4.738569259643555e-06, logit=9.875, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     int_prediction=['\" Palm\"[33578] (p=0.855, logit=22.125)', '\" The\"[578] (p=0.048, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=19.125)', '\" A\"[362] (p=0.010, logit=17.625)', '\" Option\"[7104] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     int_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.85546875, logit=22.125, token_id=33578, metadata=None))), (13394, (6, PredictedToken(token=' Bed', prob=0.005767822265625, logit=17.125, token_id=13394, metadata=None))), (76924, (20, PredictedToken(token=' Banana', prob=0.0005340576171875, logit=14.75, token_id=76924, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:02 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:43:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.930, logit=23.500)', '\" The\"[578] (p=0.028, logit=20.000)', '\" A\"[362] (p=0.022, logit=19.750)', '\" Among\"[22395] (p=0.009, logit=18.875)', '\" Motor\"[18079] (p=0.002, logit=17.500)']\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.801, logit=21.875)', '\" The\"[578] (p=0.075, logit=19.500)', '\" Among\"[22395] (p=0.051, logit=19.125)', '\" A\"[362] (p=0.027, logit=18.500)', '\" It\"[1102] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.80078125, logit=21.875, token_id=40090, metadata=None))), (16183, (10, PredictedToken(token=' Hel', prob=0.001983642578125, logit=15.875, token_id=16183, metadata=None))), (30555, (37, PredictedToken(token=' Viol', prob=0.00023746490478515625, logit=13.75, token_id=30555, metadata=None))), (22725, (106, PredictedToken(token=' Orange', prob=1.71661376953125e-05, logit=11.125, token_id=22725, metadata=None))), (55807, (385, PredictedToken(token=' Shirt', prob=1.5050172805786133e-06, logit=8.6875, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.369, logit=20.000)', '\" Hel\"[16183] (p=0.225, logit=19.500)', '\" The\"[578] (p=0.136, logit=19.000)', '\" Orange\"[22725] (p=0.106, logit=18.750)', '\" Among\"[22395] (p=0.083, logit=18.500)']\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.369140625, logit=20.0, token_id=55807, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.224609375, logit=19.5, token_id=16183, metadata=None))), (22725, (4, PredictedToken(token=' Orange', prob=0.10595703125, logit=18.75, token_id=22725, metadata=None))), (30555, (15, PredictedToken(token=' Viol', prob=0.0030059814453125, logit=15.1875, token_id=30555, metadata=None))), (40090, (3369, PredictedToken(token=' Pressure', prob=1.5459954738616943e-07, logit=5.3125, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:03 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.641, logit=20.500)', '\" The\"[578] (p=0.111, logit=18.750)', '\" Among\"[22395] (p=0.087, logit=18.500)', '\" A\"[362] (p=0.041, logit=17.750)', '\" Sax\"[68027] (p=0.025, logit=17.250)']\n",
      "2025-09-16 09:43:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.855, logit=21.875)', '\" A\"[362] (p=0.048, logit=19.000)', '\" The\"[578] (p=0.029, logit=18.500)', '\" Among\"[22395] (p=0.026, logit=18.375)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.85546875, logit=21.875, token_id=23262, metadata=None))), (14937, (31, PredictedToken(token=' Ash', prob=0.0003070831298828125, logit=13.9375, token_id=14937, metadata=None))), (3341, (33, PredictedToken(token=' Car', prob=0.0002536773681640625, logit=13.75, token_id=3341, metadata=None))), (84409, (49, PredictedToken(token=' Plum', prob=0.00015354156494140625, logit=13.25, token_id=84409, metadata=None))), (14669, (174, PredictedToken(token=' Camera', prob=1.1861324310302734e-05, logit=10.6875, token_id=14669, metadata=None))), (24941, (194, PredictedToken(token=' Bear', prob=9.834766387939453e-06, logit=10.5, token_id=24941, metadata=None)))])\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     int_prediction=['\" Camera\"[14669] (p=0.816, logit=20.875)', '\" Among\"[22395] (p=0.032, logit=17.625)', '\" The\"[578] (p=0.032, logit=17.625)', '\" None\"[2290] (p=0.022, logit=17.250)', '\" Car\"[3341] (p=0.012, logit=16.625)']\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     int_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.81640625, logit=20.875, token_id=14669, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.01165771484375, logit=16.625, token_id=3341, metadata=None))), (23262, (24, PredictedToken(token=' Comb', prob=0.00122833251953125, logit=14.375, token_id=23262, metadata=None))), (24941, (33, PredictedToken(token=' Bear', prob=0.000743865966796875, logit=13.875, token_id=24941, metadata=None))), (14937, (51, PredictedToken(token=' Ash', prob=0.0003108978271484375, logit=13.0, token_id=14937, metadata=None))), (84409, (203, PredictedToken(token=' Plum', prob=2.110004425048828e-05, logit=10.3125, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:04 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:04 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     patch_prediction=['\" Monitor\"[24423] (p=0.875, logit=22.125)', '\" A\"[362] (p=0.039, logit=19.000)', '\" The\"[578] (p=0.034, logit=18.875)', '\" (\"[320] (p=0.008, logit=17.375)', '\" Among\"[22395] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     clean_prediction=['\" Tiger\"[36845] (p=0.914, logit=22.500)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" The\"[578] (p=0.021, logit=18.750)', '\" A\"[362] (p=0.008, logit=17.750)', '\" (\"[320] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     clean_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.9140625, logit=22.5, token_id=36845, metadata=None))), (65449, (13, PredictedToken(token=' Willow', prob=0.000782012939453125, logit=15.4375, token_id=65449, metadata=None))), (14669, (250, PredictedToken(token=' Camera', prob=1.9371509552001953e-06, logit=9.4375, token_id=14669, metadata=None)))])\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     int_prediction=['\" Camera\"[14669] (p=0.770, logit=21.375)', '\" Among\"[22395] (p=0.043, logit=18.500)', '\" The\"[578] (p=0.043, logit=18.500)', '\" None\"[2290] (p=0.030, logit=18.125)', '\" (\"[320] (p=0.023, logit=17.875)']\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     int_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.76953125, logit=21.375, token_id=14669, metadata=None))), (36845, (56, PredictedToken(token=' Tiger', prob=0.000156402587890625, logit=12.875, token_id=36845, metadata=None))), (65449, (76, PredictedToken(token=' Willow', prob=6.961822509765625e-05, logit=12.0625, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:04 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.891, logit=22.375)', '\" The\"[578] (p=0.039, logit=19.250)', '\" A\"[362] (p=0.039, logit=19.250)', '\" Among\"[22395] (p=0.013, logit=18.125)', '\" MOS\"[74174] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.875, logit=21.000)', '\" The\"[578] (p=0.030, logit=17.625)', '\" Sc\"[2522] (p=0.026, logit=17.500)', '\" Among\"[22395] (p=0.010, logit=16.500)', '\" A\"[362] (p=0.006, logit=15.938)']\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.875, logit=21.0, token_id=16488, metadata=None))), (2522, (3, PredictedToken(token=' Sc', prob=0.0264892578125, logit=17.5, token_id=2522, metadata=None))), (24423, (11, PredictedToken(token=' Monitor', prob=0.002044677734375, logit=14.9375, token_id=24423, metadata=None))), (96096, (24, PredictedToken(token=' Dolphin', prob=0.000751495361328125, logit=13.9375, token_id=96096, metadata=None))), (23462, (30, PredictedToken(token=' Stadium', prob=0.000484466552734375, logit=13.5, token_id=23462, metadata=None))), (90538, (49, PredictedToken(token=' Caul', prob=0.00017833709716796875, logit=12.5, token_id=90538, metadata=None)))])\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.836, logit=20.625)', '\" The\"[578] (p=0.032, logit=17.375)', '\" Among\"[22395] (p=0.029, logit=17.250)', '\" Dolphin\"[96096] (p=0.022, logit=17.000)', '\" None\"[2290] (p=0.014, logit=16.500)']\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.8359375, logit=20.625, token_id=23462, metadata=None))), (96096, (4, PredictedToken(token=' Dolphin', prob=0.0223388671875, logit=17.0, token_id=96096, metadata=None))), (90538, (29, PredictedToken(token=' Caul', prob=0.0004634857177734375, logit=13.125, token_id=90538, metadata=None))), (24423, (53, PredictedToken(token=' Monitor', prob=0.0001811981201171875, logit=12.1875, token_id=24423, metadata=None))), (16488, (99, PredictedToken(token=' Bat', prob=5.53131103515625e-05, logit=11.0, token_id=16488, metadata=None))), (2522, (418, PredictedToken(token=' Sc', prob=4.5299530029296875e-06, logit=8.5, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:05 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:05 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.059, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=18.625)', '\" tooth\"[26588] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:43:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     clean_prediction=['\" Cherry\"[45805] (p=0.766, logit=21.625)', '\" The\"[578] (p=0.091, logit=19.500)', '\" Among\"[22395] (p=0.055, logit=19.000)', '\" A\"[362] (p=0.038, logit=18.625)', '\" (\"[320] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     clean_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.765625, logit=21.625, token_id=45805, metadata=None))), (40759, (46, PredictedToken(token=' Harmon', prob=0.0001468658447265625, logit=13.0625, token_id=40759, metadata=None))), (61731, (64, PredictedToken(token=' Soap', prob=5.745887756347656e-05, logit=12.125, token_id=61731, metadata=None))), (40975, (201, PredictedToken(token=' Marker', prob=6.0498714447021484e-06, logit=9.875, token_id=40975, metadata=None)))])\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.590, logit=21.125)', '\" Harmon\"[40759] (p=0.191, logit=20.000)', '\" The\"[578] (p=0.070, logit=19.000)', '\" Among\"[22395] (p=0.055, logit=18.750)', '\" A\"[362] (p=0.029, logit=18.125)']\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.58984375, logit=21.125, token_id=61731, metadata=None))), (40759, (2, PredictedToken(token=' Harmon', prob=0.19140625, logit=20.0, token_id=40759, metadata=None))), (40975, (6, PredictedToken(token=' Marker', prob=0.01226806640625, logit=17.25, token_id=40975, metadata=None))), (45805, (1776, PredictedToken(token=' Cherry', prob=3.259629011154175e-07, logit=6.71875, token_id=45805, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:06 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.840, logit=21.625)', '\" The\"[578] (p=0.054, logit=18.875)', '\" Among\"[22395] (p=0.037, logit=18.500)', '\" A\"[362] (p=0.020, logit=17.875)', '\" Rose\"[16344] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     clean_prediction=['\" Skate\"[97796] (p=0.730, logit=21.375)', '\" The\"[578] (p=0.087, logit=19.250)', '\" Among\"[22395] (p=0.060, logit=18.875)', '\" A\"[362] (p=0.053, logit=18.750)', '\" As\"[1666] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     clean_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.73046875, logit=21.375, token_id=97796, metadata=None))), (1666, (5, PredictedToken(token=' As', prob=0.0118408203125, logit=17.25, token_id=1666, metadata=None))), (426, (8, PredictedToken(token=' B', prob=0.00384521484375, logit=16.125, token_id=426, metadata=None))), (15883, (55, PredictedToken(token=' Spr', prob=0.00012302398681640625, logit=12.6875, token_id=15883, metadata=None))), (30616, (801, PredictedToken(token=' Rice', prob=8.307397365570068e-07, logit=7.6875, token_id=30616, metadata=None)))])\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     int_prediction=['\" Spr\"[15883] (p=0.543, logit=21.500)', '\" As\"[1666] (p=0.328, logit=21.000)', '\" The\"[578] (p=0.051, logit=19.125)', '\" Among\"[22395] (p=0.031, logit=18.625)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     int_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.54296875, logit=21.5, token_id=15883, metadata=None))), (1666, (2, PredictedToken(token=' As', prob=0.328125, logit=21.0, token_id=1666, metadata=None))), (426, (12, PredictedToken(token=' B', prob=0.0017242431640625, logit=15.75, token_id=426, metadata=None))), (97796, (36, PredictedToken(token=' Skate', prob=0.00023365020751953125, logit=13.75, token_id=97796, metadata=None))), (30616, (156, PredictedToken(token=' Rice', prob=9.655952453613281e-06, logit=10.5625, token_id=30616, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:06 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:43:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     patch_prediction=['\" None\"[2290] (p=0.523, logit=20.000)', '\" Yoga\"[38673] (p=0.170, logit=18.875)', '\" C\"[356] (p=0.117, logit=18.500)', '\" Mouse\"[18191] (p=0.062, logit=17.875)', '\" The\"[578] (p=0.026, logit=17.000)']\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     clean_prediction=['\" Uk\"[60413] (p=0.676, logit=21.750)', '\" The\"[578] (p=0.170, logit=20.375)', '\" A\"[362] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.043, logit=19.000)', '\" It\"[1102] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     clean_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.67578125, logit=21.75, token_id=60413, metadata=None))), (2057, (38, PredictedToken(token=' To', prob=0.0001373291015625, logit=13.25, token_id=2057, metadata=None))), (58251, (159, PredictedToken(token=' Tennis', prob=9.357929229736328e-06, logit=10.5625, token_id=58251, metadata=None))), (82994, (249, PredictedToken(token=' Toilet', prob=3.904104232788086e-06, logit=9.6875, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.393, logit=19.875)', '\" The\"[578] (p=0.238, logit=19.375)', '\" Among\"[22395] (p=0.113, logit=18.625)', '\" A\"[362] (p=0.100, logit=18.500)', '\" Toilet\"[82994] (p=0.047, logit=17.750)']\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.392578125, logit=19.875, token_id=58251, metadata=None))), (82994, (5, PredictedToken(token=' Toilet', prob=0.046875, logit=17.75, token_id=82994, metadata=None))), (2057, (41, PredictedToken(token=' To', prob=0.000591278076171875, logit=13.375, token_id=2057, metadata=None))), (60413, (302, PredictedToken(token=' Uk', prob=8.404254913330078e-06, logit=9.125, token_id=60413, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:07 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:07 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:43:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.664, logit=21.875)', '\" The\"[578] (p=0.168, logit=20.500)', '\" A\"[362] (p=0.070, logit=19.625)', '\" Among\"[22395] (p=0.055, logit=19.375)', '\" It\"[1102] (p=0.009, logit=17.625)']\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     clean_prediction=['\" Mall\"[32498] (p=0.762, logit=21.250)', '\" A\"[362] (p=0.091, logit=19.125)', '\" The\"[578] (p=0.062, logit=18.750)', '\" Among\"[22395] (p=0.033, logit=18.125)', '\" Only\"[8442] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     clean_track=OrderedDict([(32498, (1, PredictedToken(token=' Mall', prob=0.76171875, logit=21.25, token_id=32498, metadata=None))), (921, (33, PredictedToken(token=' Ch', prob=0.0002117156982421875, logit=13.0625, token_id=921, metadata=None))), (75258, (63, PredictedToken(token=' Refriger', prob=7.772445678710938e-05, logit=12.0625, token_id=75258, metadata=None))), (68027, (242, PredictedToken(token=' Sax', prob=5.304813385009766e-06, logit=9.375, token_id=68027, metadata=None))), (30558, (252, PredictedToken(token=' Ki', prob=4.976987838745117e-06, logit=9.3125, token_id=30558, metadata=None))), (50159, (357, PredictedToken(token=' Sco', prob=2.8461217880249023e-06, logit=8.75, token_id=50159, metadata=None)))])\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.676, logit=20.375)', '\" The\"[578] (p=0.104, logit=18.500)', '\" Among\"[22395] (p=0.055, logit=17.875)', '\" None\"[2290] (p=0.055, logit=17.875)', '\" A\"[362] (p=0.030, logit=17.250)']\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.67578125, logit=20.375, token_id=68027, metadata=None))), (50159, (16, PredictedToken(token=' Sco', prob=0.00177764892578125, logit=14.4375, token_id=50159, metadata=None))), (921, (24, PredictedToken(token=' Ch', prob=0.0006561279296875, logit=13.4375, token_id=921, metadata=None))), (75258, (63, PredictedToken(token=' Refriger', prob=0.00014591217041015625, logit=11.9375, token_id=75258, metadata=None))), (30558, (224, PredictedToken(token=' Ki', prob=1.3589859008789062e-05, logit=9.5625, token_id=30558, metadata=None))), (32498, (242, PredictedToken(token=' Mall', prob=1.1265277862548828e-05, logit=9.375, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:08 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:08 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.875, logit=21.875)', '\" A\"[362] (p=0.039, logit=18.750)', '\" The\"[578] (p=0.030, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=18.125)', '\" It\"[1102] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     clean_prediction=['\" Skate\"[97796] (p=0.664, logit=20.500)', '\" The\"[578] (p=0.102, logit=18.625)', '\" A\"[362] (p=0.090, logit=18.500)', '\" Among\"[22395] (p=0.070, logit=18.250)', '\" It\"[1102] (p=0.005, logit=15.688)']\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     clean_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.6640625, logit=20.5, token_id=97796, metadata=None))), (30558, (15, PredictedToken(token=' Ki', prob=0.00164794921875, logit=14.5, token_id=30558, metadata=None))), (6031, (48, PredictedToken(token=' Bro', prob=0.00030517578125, logit=12.8125, token_id=6031, metadata=None))), (9441, (218, PredictedToken(token=' Church', prob=1.2576580047607422e-05, logit=9.625, token_id=9441, metadata=None))), (98641, (238, PredictedToken(token=' Microwave', prob=1.1086463928222656e-05, logit=9.5, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.520, logit=20.750)', '\" Ki\"[30558] (p=0.316, logit=20.250)', '\" The\"[578] (p=0.062, logit=18.625)', '\" Among\"[22395] (p=0.038, logit=18.125)', '\" None\"[2290] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:43:08 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.51953125, logit=20.75, token_id=9441, metadata=None))), (30558, (2, PredictedToken(token=' Ki', prob=0.31640625, logit=20.25, token_id=30558, metadata=None))), (6031, (21, PredictedToken(token=' Bro', prob=0.00064849853515625, logit=14.0625, token_id=6031, metadata=None))), (97796, (357, PredictedToken(token=' Skate', prob=3.203749656677246e-06, logit=8.75, token_id=97796, metadata=None))), (98641, (3969, PredictedToken(token=' Microwave', prob=9.96515154838562e-08, logit=5.28125, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:09 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.719, logit=21.625)', '\" The\"[578] (p=0.110, logit=19.750)', '\" A\"[362] (p=0.067, logit=19.250)', '\" Among\"[22395] (p=0.041, logit=18.750)', '\" \"[220] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.848, logit=21.000)', '\" The\"[578] (p=0.037, logit=17.875)', '\" Option\"[7104] (p=0.020, logit=17.250)', '\" Among\"[22395] (p=0.018, logit=17.125)', '\" (\"[320] (p=0.012, logit=16.750)']\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.84765625, logit=21.0, token_id=41342, metadata=None))), (24423, (7, PredictedToken(token=' Monitor', prob=0.0064697265625, logit=16.125, token_id=24423, metadata=None))), (1901, (14, PredictedToken(token=' Z', prob=0.0013580322265625, logit=14.5625, token_id=1901, metadata=None))), (42609, (154, PredictedToken(token=' Pine', prob=1.609325408935547e-05, logit=10.125, token_id=42609, metadata=None)))])\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.895, logit=21.250)', '\" The\"[578] (p=0.024, logit=17.625)', '\" Option\"[7104] (p=0.014, logit=17.125)', '\" Among\"[22395] (p=0.013, logit=17.000)', '\" z\"[1167] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.89453125, logit=21.25, token_id=1901, metadata=None))), (24423, (8, PredictedToken(token=' Monitor', prob=0.00469970703125, logit=16.0, token_id=24423, metadata=None))), (41342, (12, PredictedToken(token=' Hockey', prob=0.001434326171875, logit=14.8125, token_id=41342, metadata=None))), (42609, (59, PredictedToken(token=' Pine', prob=7.581710815429688e-05, logit=11.875, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:09 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:09 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:43:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.820, logit=21.000)', '\" Among\"[22395] (p=0.059, logit=18.375)', '\" The\"[578] (p=0.041, logit=18.000)', '\" Library\"[11896] (p=0.012, logit=16.750)', '\" toilet\"[27306] (p=0.005, logit=15.875)']\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.941, logit=22.375)', '\" The\"[578] (p=0.017, logit=18.375)', '\" A\"[362] (p=0.008, logit=17.625)', '\" Among\"[22395] (p=0.005, logit=17.125)', '\" E\"[469] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.94140625, logit=22.375, token_id=29625, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.00384521484375, logit=16.875, token_id=469, metadata=None))), (91263, (6, PredictedToken(token=' Binder', prob=0.003387451171875, logit=16.75, token_id=91263, metadata=None))), (3420, (16, PredictedToken(token=' Trump', prob=0.000591278076171875, logit=15.0, token_id=3420, metadata=None))), (15429, (31, PredictedToken(token=' Hospital', prob=0.00019168853759765625, logit=13.875, token_id=15429, metadata=None))), (48471, (137, PredictedToken(token=' Shower', prob=9.5367431640625e-06, logit=10.875, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     int_prediction=['\" Chain\"[29625] (p=0.949, logit=22.625)', '\" The\"[578] (p=0.012, logit=18.250)', '\" E\"[469] (p=0.006, logit=17.625)', '\" Hospital\"[15429] (p=0.006, logit=17.500)', '\" A\"[362] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     int_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.94921875, logit=22.625, token_id=29625, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.00640869140625, logit=17.625, token_id=469, metadata=None))), (15429, (4, PredictedToken(token=' Hospital', prob=0.005645751953125, logit=17.5, token_id=15429, metadata=None))), (91263, (11, PredictedToken(token=' Binder', prob=0.000812530517578125, logit=15.5625, token_id=91263, metadata=None))), (48471, (88, PredictedToken(token=' Shower', prob=2.4557113647460938e-05, logit=12.0625, token_id=48471, metadata=None))), (3420, (2032, PredictedToken(token=' Trump', prob=1.0058283805847168e-07, logit=6.5625, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:10 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:10 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     patch_prediction=['\" Grape\"[80629] (p=0.730, logit=20.625)', '\" The\"[578] (p=0.077, logit=18.375)', '\" Among\"[22395] (p=0.053, logit=18.000)', '\" A\"[362] (p=0.041, logit=17.750)', '\" GRA\"[65120] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.797, logit=22.250)', '\" The\"[578] (p=0.065, logit=19.750)', '\" A\"[362] (p=0.065, logit=19.750)', '\" Among\"[22395] (p=0.027, logit=18.875)', '\" z\"[1167] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.796875, logit=22.25, token_id=1901, metadata=None))), (22725, (59, PredictedToken(token=' Orange', prob=5.269050598144531e-05, logit=12.625, token_id=22725, metadata=None))), (74968, (148, PredictedToken(token=' Razor', prob=8.58306884765625e-06, logit=10.8125, token_id=74968, metadata=None))), (67553, (571, PredictedToken(token=' Pants', prob=6.631016731262207e-07, logit=8.25, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:43:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     int_prediction=['\" Orange\"[22725] (p=0.824, logit=21.625)', '\" Among\"[22395] (p=0.047, logit=18.750)', '\" The\"[578] (p=0.047, logit=18.750)', '\" An\"[1556] (p=0.013, logit=17.500)', '\" Option\"[7104] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     int_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.82421875, logit=21.625, token_id=22725, metadata=None))), (67553, (18, PredictedToken(token=' Pants', prob=0.00159454345703125, logit=15.375, token_id=67553, metadata=None))), (74968, (23, PredictedToken(token=' Razor', prob=0.00080108642578125, logit=14.6875, token_id=74968, metadata=None))), (1901, (232, PredictedToken(token=' Z', prob=5.751848220825195e-06, logit=9.75, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:11 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.859, logit=21.500)', '\" The\"[578] (p=0.048, logit=18.625)', '\" Among\"[22395] (p=0.029, logit=18.125)', '\" A\"[362] (p=0.014, logit=17.375)', '\" Option\"[7104] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     clean_prediction=['\" Tie\"[59825] (p=0.863, logit=22.000)', '\" The\"[578] (p=0.043, logit=19.000)', '\" A\"[362] (p=0.038, logit=18.875)', '\" Among\"[22395] (p=0.033, logit=18.750)', '\" (\"[320] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     clean_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.86328125, logit=22.0, token_id=59825, metadata=None))), (34954, (54, PredictedToken(token=' Mirror', prob=5.698204040527344e-05, logit=12.375, token_id=34954, metadata=None))), (3341, (78, PredictedToken(token=' Car', prob=2.5272369384765625e-05, logit=11.5625, token_id=3341, metadata=None))), (8219, (173, PredictedToken(token=' Sun', prob=5.304813385009766e-06, logit=10.0, token_id=8219, metadata=None))), (89077, (904, PredictedToken(token=' Strawberry', prob=4.4889748096466064e-07, logit=7.53125, token_id=89077, metadata=None))), (12369, (916, PredictedToken(token=' Food', prob=4.3585896492004395e-07, logit=7.5, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     int_prediction=['\" The\"[578] (p=0.235, logit=18.250)', '\" Strawberry\"[89077] (p=0.208, logit=18.125)', '\" Among\"[22395] (p=0.184, logit=18.000)', '\" Mirror\"[34954] (p=0.086, logit=17.250)', '\" None\"[2290] (p=0.036, logit=16.375)']\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     int_track=OrderedDict([(89077, (2, PredictedToken(token=' Strawberry', prob=0.2080078125, logit=18.125, token_id=89077, metadata=None))), (34954, (4, PredictedToken(token=' Mirror', prob=0.08642578125, logit=17.25, token_id=34954, metadata=None))), (12369, (6, PredictedToken(token=' Food', prob=0.03173828125, logit=16.25, token_id=12369, metadata=None))), (8219, (9, PredictedToken(token=' Sun', prob=0.0181884765625, logit=15.6875, token_id=8219, metadata=None))), (59825, (126, PredictedToken(token=' Tie', prob=0.00011491775512695312, logit=10.625, token_id=59825, metadata=None))), (3341, (187, PredictedToken(token=' Car', prob=5.412101745605469e-05, logit=9.875, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:11 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:43:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     patch_prediction=['\" Daisy\"[71264] (p=0.688, logit=20.625)', '\" The\"[578] (p=0.105, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.125)', '\" d\"[294] (p=0.056, logit=18.125)', '\" A\"[362] (p=0.014, logit=16.750)']\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     clean_prediction=['\" Ash\"[14937] (p=0.867, logit=21.875)', '\" The\"[578] (p=0.043, logit=18.875)', '\" Among\"[22395] (p=0.018, logit=18.000)', '\" An\"[1556] (p=0.011, logit=17.500)', '\" A\"[362] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     clean_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.8671875, logit=21.875, token_id=14937, metadata=None))), (356, (11, PredictedToken(token=' C', prob=0.0027618408203125, logit=16.125, token_id=356, metadata=None))), (2947, (14, PredictedToken(token=' Mar', prob=0.00189208984375, logit=15.75, token_id=2947, metadata=None))), (68554, (405, PredictedToken(token=' Gloves', prob=2.086162567138672e-06, logit=8.9375, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.637, logit=21.250)', '\" C\"[356] (p=0.182, logit=20.000)', '\" Among\"[22395] (p=0.059, logit=18.875)', '\" The\"[578] (p=0.036, logit=18.375)', '\" None\"[2290] (p=0.022, logit=17.875)']\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.63671875, logit=21.25, token_id=2947, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.181640625, logit=20.0, token_id=356, metadata=None))), (14937, (91, PredictedToken(token=' Ash', prob=4.458427429199219e-05, logit=11.6875, token_id=14937, metadata=None))), (68554, (100, PredictedToken(token=' Gloves', prob=3.695487976074219e-05, logit=11.5, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:12 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:12 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     patch_prediction=['\" St\"[800] (p=0.816, logit=23.125)', '\" A\"[362] (p=0.076, logit=20.750)', '\" The\"[578] (p=0.067, logit=20.625)', '\" Among\"[22395] (p=0.017, logit=19.250)', '\" stool\"[64172] (p=0.005, logit=18.125)']\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.867, logit=22.375)', '\" The\"[578] (p=0.049, logit=19.500)', '\" A\"[362] (p=0.018, logit=18.500)', '\" violin\"[63137] (p=0.011, logit=18.000)', '\" Option\"[7104] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.8671875, logit=22.375, token_id=30555, metadata=None))), (6017, (29, PredictedToken(token=' Book', prob=0.0002918243408203125, logit=14.375, token_id=6017, metadata=None))), (79028, (34, PredictedToken(token=' Hick', prob=0.0002269744873046875, logit=14.125, token_id=79028, metadata=None)))])\n",
      "2025-09-16 09:43:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.645, logit=20.250)', '\" Book\"[6017] (p=0.162, logit=18.875)', '\" The\"[578] (p=0.047, logit=17.625)', '\" Among\"[22395] (p=0.028, logit=17.125)', '\" None\"[2290] (p=0.017, logit=16.625)']\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.64453125, logit=20.25, token_id=79028, metadata=None))), (6017, (2, PredictedToken(token=' Book', prob=0.162109375, logit=18.875, token_id=6017, metadata=None))), (30555, (19, PredictedToken(token=' Viol', prob=0.0023193359375, logit=14.625, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:13 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:13 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.742, logit=20.250)', '\" The\"[578] (p=0.078, logit=18.000)', '\" A\"[362] (p=0.061, logit=17.750)', '\" Among\"[22395] (p=0.022, logit=16.750)', '\" Note\"[7181] (p=0.015, logit=16.375)']\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.586, logit=20.750)', '\" The\"[578] (p=0.190, logit=19.625)', '\" A\"[362] (p=0.080, logit=18.750)', '\" Among\"[22395] (p=0.070, logit=18.625)', '\" It\"[1102] (p=0.016, logit=17.125)']\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.5859375, logit=20.75, token_id=94467, metadata=None))), (86460, (28, PredictedToken(token=' Necklace', prob=0.0005035400390625, logit=13.6875, token_id=86460, metadata=None))), (432, (38, PredictedToken(token=' R', prob=0.000286102294921875, logit=13.125, token_id=432, metadata=None))), (52466, (653, PredictedToken(token=' Warehouse', prob=1.5050172805786133e-06, logit=7.875, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.598, logit=21.375)', '\" The\"[578] (p=0.133, logit=19.875)', '\" Among\"[22395] (p=0.071, logit=19.250)', '\" Necklace\"[86460] (p=0.071, logit=19.250)', '\" A\"[362] (p=0.063, logit=19.125)']\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.59765625, logit=21.375, token_id=432, metadata=None))), (86460, (4, PredictedToken(token=' Necklace', prob=0.0712890625, logit=19.25, token_id=86460, metadata=None))), (52466, (167, PredictedToken(token=' Warehouse', prob=9.953975677490234e-06, logit=10.375, token_id=52466, metadata=None))), (94467, (417, PredictedToken(token=' Trom', prob=1.6316771507263184e-06, logit=8.5625, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:13 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:13 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.637, logit=21.500)', '\" The\"[578] (p=0.126, logit=19.875)', '\" A\"[362] (p=0.126, logit=19.875)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" It\"[1102] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.746, logit=21.750)', '\" The\"[578] (p=0.101, logit=19.750)', '\" A\"[362] (p=0.069, logit=19.375)', '\" Among\"[22395] (p=0.048, logit=19.000)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.74609375, logit=21.75, token_id=29318, metadata=None))), (14588, (28, PredictedToken(token=' Dog', prob=0.0002841949462890625, logit=13.875, token_id=14588, metadata=None))), (735, (31, PredictedToken(token=' K', prob=0.0002498626708984375, logit=13.75, token_id=735, metadata=None))), (43316, (35, PredictedToken(token=' Tul', prob=0.00018310546875, logit=13.4375, token_id=43316, metadata=None))), (3061, (101, PredictedToken(token=' Fl', prob=2.0623207092285156e-05, logit=11.25, token_id=3061, metadata=None))), (38930, (103, PredictedToken(token=' Bike', prob=1.9311904907226562e-05, logit=11.1875, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     int_prediction=['\" K\"[735] (p=0.812, logit=22.125)', '\" The\"[578] (p=0.075, logit=19.750)', '\" Among\"[22395] (p=0.059, logit=19.500)', '\" A\"[362] (p=0.022, logit=18.500)', '\" It\"[1102] (p=0.009, logit=17.625)']\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     int_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.8125, logit=22.125, token_id=735, metadata=None))), (38930, (40, PredictedToken(token=' Bike', prob=9.393692016601562e-05, logit=13.0625, token_id=38930, metadata=None))), (3061, (75, PredictedToken(token=' Fl', prob=2.6941299438476562e-05, logit=11.8125, token_id=3061, metadata=None))), (43316, (291, PredictedToken(token=' Tul', prob=1.7210841178894043e-06, logit=9.0625, token_id=43316, metadata=None))), (14588, (473, PredictedToken(token=' Dog', prob=7.189810276031494e-07, logit=8.1875, token_id=14588, metadata=None))), (29318, (2156, PredictedToken(token=' Dress', prob=8.288770914077759e-08, logit=6.03125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:14 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:14 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.766, logit=20.750)', '\" Ring\"[22249] (p=0.043, logit=17.875)', '\" The\"[578] (p=0.043, logit=17.875)', '\" An\"[1556] (p=0.043, logit=17.875)', '\" Among\"[22395] (p=0.026, logit=17.375)']\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.777, logit=22.125)', '\" The\"[578] (p=0.064, logit=19.625)', '\" A\"[362] (p=0.056, logit=19.500)', '\" b\"[293] (p=0.034, logit=19.000)', '\" Among\"[22395] (p=0.030, logit=18.875)']\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.77734375, logit=22.125, token_id=426, metadata=None))), (34046, (39, PredictedToken(token=' Cabinet', prob=0.0001316070556640625, logit=13.4375, token_id=34046, metadata=None))), (24941, (67, PredictedToken(token=' Bear', prob=4.8160552978515625e-05, logit=12.4375, token_id=24941, metadata=None))), (63606, (83, PredictedToken(token=' Stap', prob=2.753734588623047e-05, logit=11.875, token_id=63606, metadata=None)))])\n",
      "2025-09-16 09:43:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.809, logit=21.250)', '\" The\"[578] (p=0.059, logit=18.625)', '\" Among\"[22395] (p=0.031, logit=18.000)', '\" A\"[362] (p=0.028, logit=17.875)', '\" Cabinet\"[34046] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.80859375, logit=21.25, token_id=63606, metadata=None))), (34046, (5, PredictedToken(token=' Cabinet', prob=0.0130615234375, logit=17.125, token_id=34046, metadata=None))), (426, (42, PredictedToken(token=' B', prob=0.00023937225341796875, logit=13.125, token_id=426, metadata=None))), (24941, (199, PredictedToken(token=' Bear', prob=7.68899917602539e-06, logit=9.6875, token_id=24941, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:15 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:15 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.773, logit=21.625)', '\" The\"[578] (p=0.072, logit=19.250)', '\" A\"[362] (p=0.063, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=18.125)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.762, logit=21.500)', '\" The\"[578] (p=0.117, logit=19.625)', '\" Among\"[22395] (p=0.043, logit=18.625)', '\" headphones\"[44101] (p=0.012, logit=17.375)', '\" It\"[1102] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.76171875, logit=21.5, token_id=11452, metadata=None))), (1443, (78, PredictedToken(token=' Sh', prob=5.340576171875e-05, logit=11.9375, token_id=1443, metadata=None))), (30760, (108, PredictedToken(token=' Scar', prob=3.039836883544922e-05, logit=11.375, token_id=30760, metadata=None))), (86460, (165, PredictedToken(token=' Necklace', prob=1.3530254364013672e-05, logit=10.5625, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.539, logit=20.750)', '\" A\"[362] (p=0.154, logit=19.500)', '\" The\"[578] (p=0.137, logit=19.375)', '\" Scar\"[30760] (p=0.044, logit=18.250)', '\" Among\"[22395] (p=0.044, logit=18.250)']\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.5390625, logit=20.75, token_id=86460, metadata=None))), (30760, (5, PredictedToken(token=' Scar', prob=0.044189453125, logit=18.25, token_id=30760, metadata=None))), (1443, (148, PredictedToken(token=' Sh', prob=2.0265579223632812e-05, logit=10.5625, token_id=1443, metadata=None))), (11452, (227, PredictedToken(token=' Head', prob=1.0192394256591797e-05, logit=9.875, token_id=11452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:15 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.902, logit=22.750)', '\" The\"[578] (p=0.031, logit=19.375)', '\" A\"[362] (p=0.021, logit=19.000)', '\" Among\"[22395] (p=0.019, logit=18.875)', '\" It\"[1102] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     clean_prediction=['\" Carn\"[32749] (p=0.887, logit=22.500)', '\" The\"[578] (p=0.050, logit=19.625)', '\" A\"[362] (p=0.030, logit=19.125)', '\" Among\"[22395] (p=0.013, logit=18.250)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     clean_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.88671875, logit=22.5, token_id=32749, metadata=None))), (11683, (62, PredictedToken(token=' Acc', prob=2.288818359375e-05, logit=11.9375, token_id=11683, metadata=None))), (81501, (397, PredictedToken(token=' Pendant', prob=8.344650268554688e-07, logit=8.625, token_id=81501, metadata=None))), (50159, (501, PredictedToken(token=' Sco', prob=6.109476089477539e-07, logit=8.3125, token_id=50159, metadata=None))), (26698, (1731, PredictedToken(token=' Keyboard', prob=1.0291114449501038e-07, logit=6.53125, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.684, logit=20.875)', '\" Pendant\"[81501] (p=0.104, logit=19.000)', '\" Among\"[22395] (p=0.082, logit=18.750)', '\" The\"[578] (p=0.072, logit=18.625)', '\" A\"[362] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.68359375, logit=20.875, token_id=50159, metadata=None))), (81501, (2, PredictedToken(token=' Pendant', prob=0.1044921875, logit=19.0, token_id=81501, metadata=None))), (11683, (8, PredictedToken(token=' Acc', prob=0.004058837890625, logit=15.75, token_id=11683, metadata=None))), (26698, (12, PredictedToken(token=' Keyboard', prob=0.001495361328125, logit=14.75, token_id=26698, metadata=None))), (32749, (665, PredictedToken(token=' Carn', prob=1.2367963790893555e-06, logit=7.65625, token_id=32749, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:16 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.918, logit=22.875)', '\" Among\"[22395] (p=0.036, logit=19.625)', '\" The\"[578] (p=0.031, logit=19.500)', '\" A\"[362] (p=0.002, logit=16.625)', '\" Option\"[7104] (p=0.002, logit=16.500)']\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     clean_prediction=['\" Rose\"[16344] (p=0.789, logit=21.625)', '\" The\"[578] (p=0.065, logit=19.125)', '\" Among\"[22395] (p=0.045, logit=18.750)', '\" A\"[362] (p=0.045, logit=18.750)', '\" Potato\"[78703] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     clean_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.7890625, logit=21.625, token_id=16344, metadata=None))), (78703, (5, PredictedToken(token=' Potato', prob=0.00775146484375, logit=17.0, token_id=78703, metadata=None))), (48471, (177, PredictedToken(token=' Shower', prob=7.987022399902344e-06, logit=10.125, token_id=48471, metadata=None))), (14588, (283, PredictedToken(token=' Dog', prob=3.337860107421875e-06, logit=9.25, token_id=14588, metadata=None))), (82507, (868, PredictedToken(token=' Jeans', prob=6.370246410369873e-07, logit=7.59375, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:43:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     int_prediction=['\" Potato\"[78703] (p=0.867, logit=21.625)', '\" The\"[578] (p=0.049, logit=18.750)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" A\"[362] (p=0.008, logit=16.875)', '\" POT\"[62602] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     int_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.8671875, logit=21.625, token_id=78703, metadata=None))), (16344, (28, PredictedToken(token=' Rose', prob=0.0003108978271484375, logit=13.6875, token_id=16344, metadata=None))), (82507, (47, PredictedToken(token=' Jeans', prob=0.00010728836059570312, logit=12.625, token_id=82507, metadata=None))), (14588, (62, PredictedToken(token=' Dog', prob=6.4849853515625e-05, logit=12.125, token_id=14588, metadata=None))), (48471, (135, PredictedToken(token=' Shower', prob=1.3589859008789062e-05, logit=10.5625, token_id=48471, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:17 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.648, logit=21.750)', '\" The\"[578] (p=0.127, logit=20.125)', '\" A\"[362] (p=0.127, logit=20.125)', '\" Among\"[22395] (p=0.053, logit=19.250)', '\" It\"[1102] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.840, logit=21.250)', '\" The\"[578] (p=0.054, logit=18.500)', '\" Among\"[22395] (p=0.042, logit=18.250)', '\" A\"[362] (p=0.014, logit=17.125)', '\" It\"[1102] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.83984375, logit=21.25, token_id=44570, metadata=None))), (30760, (20, PredictedToken(token=' Scar', prob=0.000720977783203125, logit=14.1875, token_id=30760, metadata=None))), (34954, (105, PredictedToken(token=' Mirror', prob=3.361701965332031e-05, logit=11.125, token_id=34954, metadata=None))), (68027, (952, PredictedToken(token=' Sax', prob=8.67992639541626e-07, logit=7.46875, token_id=68027, metadata=None))), (23462, (1196, PredictedToken(token=' Stadium', prob=6.183981895446777e-07, logit=7.125, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.734, logit=20.625)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" The\"[578] (p=0.077, logit=18.375)', '\" Option\"[7104] (p=0.020, logit=17.000)', '\" A\"[362] (p=0.015, logit=16.750)']\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.734375, logit=20.625, token_id=23462, metadata=None))), (34954, (21, PredictedToken(token=' Mirror', prob=0.001251220703125, logit=14.25, token_id=34954, metadata=None))), (44570, (23, PredictedToken(token=' Maple', prob=0.00110626220703125, logit=14.125, token_id=44570, metadata=None))), (30760, (81, PredictedToken(token=' Scar', prob=8.0108642578125e-05, logit=11.5, token_id=30760, metadata=None))), (68027, (92, PredictedToken(token=' Sax', prob=5.841255187988281e-05, logit=11.1875, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:17 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:17 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:43:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.902, logit=22.000)', '\" A\"[362] (p=0.031, logit=18.625)', '\" The\"[578] (p=0.024, logit=18.375)', '\" Among\"[22395] (p=0.009, logit=17.375)', '\" warehouse\"[31212] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.812, logit=22.625)', '\" Among\"[22395] (p=0.097, logit=20.500)', '\" The\"[578] (p=0.066, logit=20.125)', '\" It\"[1102] (p=0.003, logit=16.875)', '\" as\"[439] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.8125, logit=22.625, token_id=1666, metadata=None))), (356, (10, PredictedToken(token=' C', prob=0.00107574462890625, logit=16.0, token_id=356, metadata=None))), (23126, (81, PredictedToken(token=' Ti', prob=2.09808349609375e-05, logit=12.0625, token_id=23126, metadata=None))), (13000, (110, PredictedToken(token=' Van', prob=1.1980533599853516e-05, logit=11.5, token_id=13000, metadata=None))), (58586, (340, PredictedToken(token=' Tape', prob=1.341104507446289e-06, logit=9.3125, token_id=58586, metadata=None))), (38571, (795, PredictedToken(token=' Theater', prob=3.296881914138794e-07, logit=7.90625, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     int_prediction=['\" Theater\"[38571] (p=0.660, logit=21.250)', '\" The\"[578] (p=0.189, logit=20.000)', '\" Among\"[22395] (p=0.061, logit=18.875)', '\" A\"[362] (p=0.014, logit=17.375)', '\" C\"[356] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     int_track=OrderedDict([(38571, (1, PredictedToken(token=' Theater', prob=0.66015625, logit=21.25, token_id=38571, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.0093994140625, logit=17.0, token_id=356, metadata=None))), (23126, (20, PredictedToken(token=' Ti', prob=0.0010528564453125, logit=14.8125, token_id=23126, metadata=None))), (1666, (19, PredictedToken(token=' As', prob=0.0010528564453125, logit=14.8125, token_id=1666, metadata=None))), (13000, (24, PredictedToken(token=' Van', prob=0.00072479248046875, logit=14.4375, token_id=13000, metadata=None))), (58586, (86, PredictedToken(token=' Tape', prob=4.363059997558594e-05, logit=11.625, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:18 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:18 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     patch_prediction=['\" Bench\"[36358] (p=0.859, logit=22.625)', '\" A\"[362] (p=0.055, logit=19.875)', '\" The\"[578] (p=0.043, logit=19.625)', '\" Among\"[22395] (p=0.014, logit=18.500)', '\" bench\"[13731] (p=0.007, logit=17.875)']\n",
      "2025-09-16 09:43:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.832, logit=21.875)', '\" The\"[578] (p=0.053, logit=19.125)', '\" A\"[362] (p=0.047, logit=19.000)', '\" Among\"[22395] (p=0.017, logit=18.000)', '\" Ward\"[27738] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.83203125, logit=21.875, token_id=68867, metadata=None))), (27738, (5, PredictedToken(token=' Ward', prob=0.00634765625, logit=17.0, token_id=27738, metadata=None))), (83499, (74, PredictedToken(token=' Tooth', prob=5.8650970458984375e-05, logit=12.3125, token_id=83499, metadata=None)))])\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     int_prediction=['\" Ward\"[27738] (p=0.699, logit=21.250)', '\" Tooth\"[83499] (p=0.177, logit=19.875)', '\" The\"[578] (p=0.051, logit=18.625)', '\" Among\"[22395] (p=0.024, logit=17.875)', '\" A\"[362] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     int_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.69921875, logit=21.25, token_id=27738, metadata=None))), (83499, (2, PredictedToken(token=' Tooth', prob=0.1767578125, logit=19.875, token_id=83499, metadata=None))), (68867, (76, PredictedToken(token=' Coat', prob=7.152557373046875e-05, logit=12.0625, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:19 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:19 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     patch_prediction=['\" Notebook\"[69755] (p=0.852, logit=21.125)', '\" The\"[578] (p=0.037, logit=18.000)', '\" A\"[362] (p=0.037, logit=18.000)', '\" Note\"[7181] (p=0.014, logit=17.000)', '\" (\"[320] (p=0.006, logit=16.125)']\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.695, logit=22.500)', '\" The\"[578] (p=0.137, logit=20.875)', '\" A\"[362] (p=0.094, logit=20.500)', '\" Among\"[22395] (p=0.044, logit=19.750)', '\" \"[220] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.6953125, logit=22.5, token_id=34785, metadata=None))), (63606, (60, PredictedToken(token=' Stap', prob=4.315376281738281e-05, logit=12.8125, token_id=63606, metadata=None))), (22050, (68, PredictedToken(token=' Hat', prob=3.361701965332031e-05, logit=12.5625, token_id=22050, metadata=None)))])\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.617, logit=21.750)', '\" Hat\"[22050] (p=0.177, logit=20.500)', '\" The\"[578] (p=0.122, logit=20.125)', '\" A\"[362] (p=0.031, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=18.500)']\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.6171875, logit=21.75, token_id=63606, metadata=None))), (22050, (2, PredictedToken(token=' Hat', prob=0.1767578125, logit=20.5, token_id=22050, metadata=None))), (34785, (59, PredictedToken(token=' Truck', prob=4.3392181396484375e-05, logit=12.1875, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:19 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     patch_prediction=['\" Mixer\"[72392] (p=0.660, logit=20.750)', '\" A\"[362] (p=0.114, logit=19.000)', '\" The\"[578] (p=0.101, logit=18.875)', '\" Among\"[22395] (p=0.048, logit=18.125)', '\" Option\"[7104] (p=0.012, logit=16.750)']\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.836, logit=21.750)', '\" A\"[362] (p=0.053, logit=19.000)', '\" The\"[578] (p=0.037, logit=18.625)', '\" None\"[2290] (p=0.015, logit=17.750)', '\" Among\"[22395] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.8359375, logit=21.75, token_id=17929, metadata=None))), (356, (15, PredictedToken(token=' C', prob=0.00125885009765625, logit=15.25, token_id=356, metadata=None))), (52466, (80, PredictedToken(token=' Warehouse', prob=4.887580871582031e-05, logit=12.0, token_id=52466, metadata=None))), (12369, (159, PredictedToken(token=' Food', prob=1.3113021850585938e-05, logit=10.6875, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     int_prediction=['\" Food\"[12369] (p=0.555, logit=19.750)', '\" None\"[2290] (p=0.181, logit=18.625)', '\" C\"[356] (p=0.066, logit=17.625)', '\" The\"[578] (p=0.040, logit=17.125)', '\" A\"[362] (p=0.036, logit=17.000)']\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     int_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.5546875, logit=19.75, token_id=12369, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.06640625, logit=17.625, token_id=356, metadata=None))), (17929, (52, PredictedToken(token=' Pin', prob=0.000255584716796875, logit=12.0625, token_id=17929, metadata=None))), (52466, (680, PredictedToken(token=' Warehouse', prob=3.0100345611572266e-06, logit=7.625, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:20 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:20 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.855, logit=22.500)', '\" The\"[578] (p=0.048, logit=19.625)', '\" A\"[362] (p=0.048, logit=19.625)', '\" Among\"[22395] (p=0.023, logit=18.875)', '\" warehouse\"[31212] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:43:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.820, logit=21.875)', '\" The\"[578] (p=0.086, logit=19.625)', '\" Among\"[22395] (p=0.028, logit=18.500)', '\" A\"[362] (p=0.022, logit=18.250)', '\" Option\"[7104] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.8203125, logit=21.875, token_id=469, metadata=None))), (16730, (111, PredictedToken(token=' Museum', prob=1.4603137969970703e-05, logit=10.9375, token_id=16730, metadata=None))), (33199, (131, PredictedToken(token=' Lion', prob=1.138448715209961e-05, logit=10.6875, token_id=33199, metadata=None))), (70110, (414, PredictedToken(token=' Ottoman', prob=1.2740492820739746e-06, logit=8.5, token_id=70110, metadata=None))), (6690, (498, PredictedToken(token=' Air', prob=8.754432201385498e-07, logit=8.125, token_id=6690, metadata=None))), (69755, (901, PredictedToken(token=' Notebook', prob=3.762543201446533e-07, logit=7.28125, token_id=69755, metadata=None)))])\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.613, logit=20.500)', '\" The\"[578] (p=0.121, logit=18.875)', '\" Among\"[22395] (p=0.094, logit=18.625)', '\" Ottoman\"[70110] (p=0.065, logit=18.250)', '\" A\"[362] (p=0.014, logit=16.750)']\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.61328125, logit=20.5, token_id=16730, metadata=None))), (70110, (4, PredictedToken(token=' Ottoman', prob=0.06494140625, logit=18.25, token_id=70110, metadata=None))), (69755, (7, PredictedToken(token=' Notebook', prob=0.01129150390625, logit=16.5, token_id=69755, metadata=None))), (469, (33, PredictedToken(token=' E', prob=0.0004367828369140625, logit=13.25, token_id=469, metadata=None))), (33199, (47, PredictedToken(token=' Lion', prob=0.0002193450927734375, logit=12.5625, token_id=33199, metadata=None))), (6690, (80, PredictedToken(token=' Air', prob=8.58306884765625e-05, logit=11.625, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:21 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     patch_prediction=['\" Elephant\"[79189] (p=0.719, logit=21.875)', '\" An\"[1556] (p=0.086, logit=19.750)', '\" The\"[578] (p=0.067, logit=19.500)', '\" Among\"[22395] (p=0.059, logit=19.375)', '\" Har\"[5340] (p=0.025, logit=18.500)']\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.641, logit=20.750)', '\" The\"[578] (p=0.144, logit=19.250)', '\" A\"[362] (p=0.067, logit=18.500)', '\" Among\"[22395] (p=0.053, logit=18.250)', '\" It\"[1102] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.640625, logit=20.75, token_id=1630, metadata=None))), (36845, (13, PredictedToken(token=' Tiger', prob=0.0031585693359375, logit=15.4375, token_id=36845, metadata=None))), (22249, (20, PredictedToken(token=' Ring', prob=0.001495361328125, logit=14.6875, token_id=22249, metadata=None))), (3816, (55, PredictedToken(token=' Red', prob=0.00015735626220703125, logit=12.4375, token_id=3816, metadata=None)))])\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.902, logit=21.750)', '\" The\"[578] (p=0.035, logit=18.500)', '\" Among\"[22395] (p=0.024, logit=18.125)', '\" It\"[1102] (p=0.005, logit=16.625)', '\" Option\"[7104] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.90234375, logit=21.75, token_id=36845, metadata=None))), (3816, (18, PredictedToken(token=' Red', prob=0.000530242919921875, logit=14.3125, token_id=3816, metadata=None))), (22249, (60, PredictedToken(token=' Ring', prob=4.100799560546875e-05, logit=11.75, token_id=22249, metadata=None))), (1630, (314, PredictedToken(token=' X', prob=2.175569534301758e-06, logit=8.8125, token_id=1630, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:21 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:21 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.855, logit=22.250)', '\" Among\"[22395] (p=0.042, logit=19.250)', '\" The\"[578] (p=0.042, logit=19.250)', '\" A\"[362] (p=0.033, logit=19.000)', '\" Option\"[7104] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.812, logit=21.625)', '\" None\"[2290] (p=0.067, logit=19.125)', '\" The\"[578] (p=0.028, logit=18.250)', '\" A\"[362] (p=0.022, logit=18.000)', '\" There\"[2684] (p=0.017, logit=17.750)']\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.8125, logit=21.625, token_id=1901, metadata=None))), (39794, (15, PredictedToken(token=' Desk', prob=0.00101470947265625, logit=14.9375, token_id=39794, metadata=None))), (816, (22, PredictedToken(token=' Y', prob=0.00054168701171875, logit=14.3125, token_id=816, metadata=None))), (88668, (123, PredictedToken(token=' Blender', prob=2.110004425048828e-05, logit=11.0625, token_id=88668, metadata=None))), (42609, (175, PredictedToken(token=' Pine', prob=1.0609626770019531e-05, logit=10.375, token_id=42609, metadata=None))), (100031, (346, PredictedToken(token=' Mosque', prob=2.8461217880249023e-06, logit=9.0625, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     int_prediction=['\" Mosque\"[100031] (p=0.559, logit=20.875)', '\" None\"[2290] (p=0.338, logit=20.375)', '\" There\"[2684] (p=0.046, logit=18.375)', '\" The\"[578] (p=0.012, logit=17.000)', '\" A\"[362] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     int_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.55859375, logit=20.875, token_id=100031, metadata=None))), (816, (51, PredictedToken(token=' Y', prob=0.00010013580322265625, logit=12.25, token_id=816, metadata=None))), (39794, (169, PredictedToken(token=' Desk', prob=1.055002212524414e-05, logit=10.0, token_id=39794, metadata=None))), (1901, (171, PredictedToken(token=' Z', prob=9.894371032714844e-06, logit=9.9375, token_id=1901, metadata=None))), (42609, (241, PredictedToken(token=' Pine', prob=6.794929504394531e-06, logit=9.5625, token_id=42609, metadata=None))), (88668, (343, PredictedToken(token=' Blender', prob=3.635883331298828e-06, logit=8.9375, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:22 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:22 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     patch_prediction=['\" Rice\"[30616] (p=0.742, logit=21.625)', '\" The\"[578] (p=0.088, logit=19.500)', '\" A\"[362] (p=0.069, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" C\"[356] (p=0.011, logit=17.375)']\n",
      "2025-09-16 09:43:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     clean_prediction=['\" Sink\"[57551] (p=0.852, logit=20.875)', '\" The\"[578] (p=0.033, logit=17.625)', '\" Among\"[22395] (p=0.020, logit=17.125)', '\" A\"[362] (p=0.016, logit=16.875)', '\" sink\"[19868] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     clean_track=OrderedDict([(57551, (1, PredictedToken(token=' Sink', prob=0.8515625, logit=20.875, token_id=57551, metadata=None))), (33711, (12, PredictedToken(token=' Suit', prob=0.002716064453125, logit=15.125, token_id=33711, metadata=None))), (40090, (34, PredictedToken(token=' Pressure', prob=0.000415802001953125, logit=13.25, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.750, logit=20.250)', '\" None\"[2290] (p=0.115, logit=18.375)', '\" Among\"[22395] (p=0.037, logit=17.250)', '\" The\"[578] (p=0.023, logit=16.750)', '\" pressure\"[7410] (p=0.007, logit=15.562)']\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.75, logit=20.25, token_id=40090, metadata=None))), (33711, (15, PredictedToken(token=' Suit', prob=0.00164031982421875, logit=14.125, token_id=33711, metadata=None))), (57551, (17, PredictedToken(token=' Sink', prob=0.00144195556640625, logit=14.0, token_id=57551, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:23 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:23 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     patch_prediction=['\" Clar\"[31181] (p=0.723, logit=21.625)', '\" The\"[578] (p=0.143, logit=20.000)', '\" A\"[362] (p=0.052, logit=19.000)', '\" Among\"[22395] (p=0.036, logit=18.625)', '\" It\"[1102] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.918, logit=22.125)', '\" Among\"[22395] (p=0.028, logit=18.625)', '\" The\"[578] (p=0.028, logit=18.625)', '\" violet\"[80836] (p=0.003, logit=16.500)', '\" A\"[362] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.91796875, logit=22.125, token_id=74574, metadata=None))), (60413, (74, PredictedToken(token=' Uk', prob=2.86102294921875e-05, logit=11.75, token_id=60413, metadata=None))), (74968, (102, PredictedToken(token=' Razor', prob=1.52587890625e-05, logit=11.125, token_id=74968, metadata=None))), (38930, (503, PredictedToken(token=' Bike', prob=9.201467037200928e-07, logit=8.3125, token_id=38930, metadata=None))), (16730, (1113, PredictedToken(token=' Museum', prob=3.1851232051849365e-07, logit=7.25, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     int_prediction=['\" Razor\"[74968] (p=0.816, logit=20.625)', '\" None\"[2290] (p=0.041, logit=17.625)', '\" The\"[578] (p=0.041, logit=17.625)', '\" Among\"[22395] (p=0.036, logit=17.500)', '\" A\"[362] (p=0.008, logit=16.000)']\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     int_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.81640625, logit=20.625, token_id=74968, metadata=None))), (60413, (13, PredictedToken(token=' Uk', prob=0.001678466796875, logit=14.4375, token_id=60413, metadata=None))), (38930, (25, PredictedToken(token=' Bike', prob=0.00061798095703125, logit=13.4375, token_id=38930, metadata=None))), (74574, (445, PredictedToken(token=' Violet', prob=3.904104232788086e-06, logit=8.375, token_id=74574, metadata=None))), (16730, (6781, PredictedToken(token=' Museum', prob=1.0756775736808777e-07, logit=4.78125, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:23 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     patch_prediction=['\" Bamboo\"[98028] (p=0.824, logit=21.125)', '\" The\"[578] (p=0.060, logit=18.500)', '\" Among\"[22395] (p=0.028, logit=17.750)', '\" None\"[2290] (p=0.022, logit=17.500)', '\" It\"[1102] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.898, logit=22.750)', '\" Among\"[22395] (p=0.051, logit=19.875)', '\" The\"[578] (p=0.035, logit=19.500)', '\" Out\"[4470] (p=0.002, logit=16.750)', '\" It\"[1102] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.8984375, logit=22.75, token_id=41785, metadata=None))), (14937, (7, PredictedToken(token=' Ash', prob=0.00098419189453125, logit=15.9375, token_id=14937, metadata=None))), (29318, (177, PredictedToken(token=' Dress', prob=3.1441450119018555e-06, logit=10.1875, token_id=29318, metadata=None))), (46506, (209, PredictedToken(token=' Drum', prob=2.4437904357910156e-06, logit=9.9375, token_id=46506, metadata=None))), (38258, (216, PredictedToken(token=' Baseball', prob=2.294778823852539e-06, logit=9.875, token_id=38258, metadata=None))), (57225, (1419, PredictedToken(token=' Laptop', prob=1.2945383787155151e-07, logit=7.0, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     int_prediction=['\" Ash\"[14937] (p=0.699, logit=21.375)', '\" The\"[578] (p=0.107, logit=19.500)', '\" Among\"[22395] (p=0.095, logit=19.375)', '\" Drum\"[46506] (p=0.031, logit=18.250)', '\" An\"[1556] (p=0.013, logit=17.375)']\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     int_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.69921875, logit=21.375, token_id=14937, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.03076171875, logit=18.25, token_id=46506, metadata=None))), (57225, (40, PredictedToken(token=' Laptop', prob=0.000194549560546875, logit=13.1875, token_id=57225, metadata=None))), (29318, (95, PredictedToken(token=' Dress', prob=3.3855438232421875e-05, logit=11.4375, token_id=29318, metadata=None))), (41785, (242, PredictedToken(token=' Spin', prob=5.185604095458984e-06, logit=9.5625, token_id=41785, metadata=None))), (38258, (452, PredictedToken(token=' Baseball', prob=1.9073486328125e-06, logit=8.5625, token_id=38258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:24 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     patch_prediction=['\" Clar\"[31181] (p=0.613, logit=21.750)', '\" The\"[578] (p=0.199, logit=20.625)', '\" A\"[362] (p=0.094, logit=19.875)', '\" Among\"[22395] (p=0.050, logit=19.250)', '\" It\"[1102] (p=0.014, logit=18.000)']\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     clean_prediction=['\" Ch\"[921] (p=0.805, logit=22.125)', '\" The\"[578] (p=0.085, logit=19.875)', '\" A\"[362] (p=0.040, logit=19.125)', '\" Among\"[22395] (p=0.035, logit=19.000)', '\" (\"[320] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     clean_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.8046875, logit=22.125, token_id=921, metadata=None))), (29625, (25, PredictedToken(token=' Chain', prob=0.00030517578125, logit=14.25, token_id=29625, metadata=None))), (3061, (41, PredictedToken(token=' Fl', prob=9.918212890625e-05, logit=13.125, token_id=3061, metadata=None))), (23262, (78, PredictedToken(token=' Comb', prob=2.3603439331054688e-05, logit=11.6875, token_id=23262, metadata=None))), (58251, (98, PredictedToken(token=' Tennis', prob=1.621246337890625e-05, logit=11.3125, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     int_prediction=['\" Fl\"[3061] (p=0.617, logit=21.375)', '\" The\"[578] (p=0.201, logit=20.250)', '\" Among\"[22395] (p=0.045, logit=18.750)', '\" A\"[362] (p=0.040, logit=18.625)', '\" Tennis\"[58251] (p=0.027, logit=18.250)']\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     int_track=OrderedDict([(3061, (1, PredictedToken(token=' Fl', prob=0.6171875, logit=21.375, token_id=3061, metadata=None))), (58251, (5, PredictedToken(token=' Tennis', prob=0.0272216796875, logit=18.25, token_id=58251, metadata=None))), (23262, (66, PredictedToken(token=' Comb', prob=5.936622619628906e-05, logit=12.125, token_id=23262, metadata=None))), (29625, (162, PredictedToken(token=' Chain', prob=9.119510650634766e-06, logit=10.25, token_id=29625, metadata=None))), (921, (171, PredictedToken(token=' Ch', prob=8.046627044677734e-06, logit=10.125, token_id=921, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:25 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.754, logit=22.250)', '\" The\"[578] (p=0.115, logit=20.375)', '\" Among\"[22395] (p=0.054, logit=19.625)', '\" A\"[362] (p=0.033, logit=19.125)', '\" B\"[426] (p=0.009, logit=17.875)']\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.836, logit=22.500)', '\" The\"[578] (p=0.068, logit=20.000)', '\" Among\"[22395] (p=0.042, logit=19.500)', '\" A\"[362] (p=0.032, logit=19.250)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.8359375, logit=22.5, token_id=356, metadata=None))), (4923, (71, PredictedToken(token=' Sk', prob=2.6106834411621094e-05, logit=12.125, token_id=4923, metadata=None))), (48665, (177, PredictedToken(token=' Raspberry', prob=4.5299530029296875e-06, logit=10.375, token_id=48665, metadata=None))), (40975, (227, PredictedToken(token=' Marker', prob=2.9206275939941406e-06, logit=9.9375, token_id=40975, metadata=None))), (6150, (408, PredictedToken(token=' School', prob=9.499490261077881e-07, logit=8.8125, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:43:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     int_prediction=['\" Raspberry\"[48665] (p=0.746, logit=21.250)', '\" Among\"[22395] (p=0.089, logit=19.125)', '\" The\"[578] (p=0.069, logit=18.875)', '\" Marker\"[40975] (p=0.012, logit=17.125)', '\" R\"[432] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     int_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.74609375, logit=21.25, token_id=48665, metadata=None))), (40975, (5, PredictedToken(token=' Marker', prob=0.01202392578125, logit=17.125, token_id=40975, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.006439208984375, logit=16.5, token_id=356, metadata=None))), (6150, (13, PredictedToken(token=' School', prob=0.002685546875, logit=15.625, token_id=6150, metadata=None))), (4923, (19, PredictedToken(token=' Sk', prob=0.0009918212890625, logit=14.625, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:26 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     patch_prediction=['\" Ti\"[23126] (p=0.773, logit=21.375)', '\" Among\"[22395] (p=0.056, logit=18.750)', '\" The\"[578] (p=0.056, logit=18.750)', '\" A\"[362] (p=0.050, logit=18.625)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     clean_prediction=['\" Willow\"[65449] (p=0.766, logit=21.625)', '\" The\"[578] (p=0.091, logit=19.500)', '\" Among\"[22395] (p=0.071, logit=19.250)', '\" A\"[362] (p=0.030, logit=18.375)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     clean_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.765625, logit=21.625, token_id=65449, metadata=None))), (4783, (19, PredictedToken(token=' House', prob=0.000614166259765625, logit=14.5, token_id=4783, metadata=None))), (2057, (31, PredictedToken(token=' To', prob=0.0003509521484375, logit=13.9375, token_id=2057, metadata=None))), (356, (34, PredictedToken(token=' C', prob=0.0002899169921875, logit=13.75, token_id=356, metadata=None))), (24941, (194, PredictedToken(token=' Bear', prob=7.748603820800781e-06, logit=10.125, token_id=24941, metadata=None))), (3341, (198, PredictedToken(token=' Car', prob=7.271766662597656e-06, logit=10.0625, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.785, logit=22.000)', '\" The\"[578] (p=0.064, logit=19.500)', '\" Among\"[22395] (p=0.050, logit=19.250)', '\" A\"[362] (p=0.050, logit=19.250)', '\" To\"[2057] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.78515625, logit=22.0, token_id=356, metadata=None))), (2057, (5, PredictedToken(token=' To', prob=0.006805419921875, logit=17.25, token_id=2057, metadata=None))), (24941, (8, PredictedToken(token=' Bear', prob=0.004119873046875, logit=16.75, token_id=24941, metadata=None))), (3341, (66, PredictedToken(token=' Car', prob=4.57763671875e-05, logit=12.25, token_id=3341, metadata=None))), (4783, (255, PredictedToken(token=' House', prob=2.9355287551879883e-06, logit=9.5, token_id=4783, metadata=None))), (65449, (1354, PredictedToken(token=' Willow', prob=2.0582228899002075e-07, logit=6.84375, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:26 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     patch_prediction=['\" Toilet\"[82994] (p=0.840, logit=21.250)', '\" The\"[578] (p=0.061, logit=18.625)', '\" Among\"[22395] (p=0.029, logit=17.875)', '\" A\"[362] (p=0.022, logit=17.625)', '\" It\"[1102] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     clean_prediction=['\" To\"[2057] (p=0.672, logit=21.375)', '\" The\"[578] (p=0.132, logit=19.750)', '\" A\"[362] (p=0.103, logit=19.500)', '\" Among\"[22395] (p=0.049, logit=18.750)', '\" TO\"[5257] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     clean_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.671875, logit=21.375, token_id=2057, metadata=None))), (16488, (15, PredictedToken(token=' Bat', prob=0.0011444091796875, logit=15.0, token_id=16488, metadata=None))), (27171, (34, PredictedToken(token=' Coffee', prob=0.000255584716796875, logit=13.5, token_id=27171, metadata=None))), (3816, (146, PredictedToken(token=' Red', prob=1.1205673217773438e-05, logit=10.375, token_id=3816, metadata=None))), (30555, (157, PredictedToken(token=' Viol', prob=1.055002212524414e-05, logit=10.3125, token_id=30555, metadata=None))), (38673, (491, PredictedToken(token=' Yoga', prob=1.1846423149108887e-06, logit=8.125, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     int_prediction=['\" Bat\"[16488] (p=0.855, logit=22.000)', '\" The\"[578] (p=0.048, logit=19.125)', '\" Among\"[22395] (p=0.042, logit=19.000)', '\" A\"[362] (p=0.029, logit=18.625)', '\" BAT\"[79081] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     int_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.85546875, logit=22.0, token_id=16488, metadata=None))), (3816, (39, PredictedToken(token=' Red', prob=0.00012683868408203125, logit=13.1875, token_id=3816, metadata=None))), (2057, (68, PredictedToken(token=' To', prob=3.647804260253906e-05, logit=11.9375, token_id=2057, metadata=None))), (27171, (111, PredictedToken(token=' Coffee', prob=1.341104507446289e-05, logit=10.9375, token_id=27171, metadata=None))), (38673, (277, PredictedToken(token=' Yoga', prob=2.1904706954956055e-06, logit=9.125, token_id=38673, metadata=None))), (30555, (1417, PredictedToken(token=' Viol', prob=1.8533319234848022e-07, logit=6.65625, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:27 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:27 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.891, logit=21.750)', '\" The\"[578] (p=0.044, logit=18.750)', '\" A\"[362] (p=0.014, logit=17.625)', '\" Among\"[22395] (p=0.009, logit=17.125)', '\" Keyboard\"[26698] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.855, logit=22.000)', '\" The\"[578] (p=0.038, logit=18.875)', '\" A\"[362] (p=0.033, logit=18.750)', '\" (\"[320] (p=0.016, logit=18.000)', '\" Among\"[22395] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.85546875, logit=22.0, token_id=5907, metadata=None))), (57094, (10, PredictedToken(token=' Highlight', prob=0.0023956298828125, logit=16.125, token_id=57094, metadata=None))), (68554, (147, PredictedToken(token=' Gloves', prob=9.775161743164062e-06, logit=10.625, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:43:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.531, logit=20.500)', '\" Gloves\"[68554] (p=0.322, logit=20.000)', '\" The\"[578] (p=0.026, logit=17.500)', '\" A\"[362] (p=0.018, logit=17.125)', '\" Glo\"[25372] (p=0.016, logit=17.000)']\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.53125, logit=20.5, token_id=57094, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.322265625, logit=20.0, token_id=68554, metadata=None))), (5907, (156, PredictedToken(token=' Project', prob=1.4662742614746094e-05, logit=10.0, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:28 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     patch_prediction=['\" E\"[469] (p=0.621, logit=22.250)', '\" An\"[1556] (p=0.178, logit=21.000)', '\" The\"[578] (p=0.122, logit=20.625)', '\" Among\"[22395] (p=0.040, logit=19.500)', '\" e\"[384] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     clean_prediction=['\" Y\"[816] (p=0.656, logit=21.750)', '\" A\"[362] (p=0.146, logit=20.250)', '\" The\"[578] (p=0.101, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=18.875)', '\" None\"[2290] (p=0.017, logit=18.125)']\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     clean_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.65625, logit=21.75, token_id=816, metadata=None))), (57094, (50, PredictedToken(token=' Highlight', prob=0.000110626220703125, logit=13.0625, token_id=57094, metadata=None))), (41785, (203, PredictedToken(token=' Spin', prob=5.841255187988281e-06, logit=10.125, token_id=41785, metadata=None))), (86460, (272, PredictedToken(token=' Necklace', prob=3.129243850708008e-06, logit=9.5, token_id=86460, metadata=None))), (47759, (342, PredictedToken(token=' Guitar', prob=1.8998980522155762e-06, logit=9.0, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.400, logit=21.000)', '\" Highlight\"[57094] (p=0.214, logit=20.375)', '\" None\"[2290] (p=0.188, logit=20.250)', '\" The\"[578] (p=0.069, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.750)']\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.400390625, logit=21.0, token_id=86460, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.2138671875, logit=20.375, token_id=57094, metadata=None))), (41785, (6, PredictedToken(token=' Spin', prob=0.017578125, logit=17.875, token_id=41785, metadata=None))), (816, (306, PredictedToken(token=' Y', prob=3.7997961044311523e-06, logit=9.4375, token_id=816, metadata=None))), (47759, (2480, PredictedToken(token=' Guitar', prob=2.0209699869155884e-07, logit=6.5, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:28 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:43:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.836, logit=22.750)', '\" The\"[578] (p=0.069, logit=20.250)', '\" A\"[362] (p=0.047, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.500)']\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.859, logit=22.500)', '\" The\"[578] (p=0.055, logit=19.750)', '\" A\"[362] (p=0.038, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=19.000)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.859375, logit=22.5, token_id=88668, metadata=None))), (94467, (53, PredictedToken(token=' Trom', prob=4.7206878662109375e-05, logit=12.6875, token_id=94467, metadata=None))), (42609, (69, PredictedToken(token=' Pine', prob=2.682209014892578e-05, logit=12.125, token_id=42609, metadata=None))), (61948, (166, PredictedToken(token=' Sofa', prob=4.976987838745117e-06, logit=10.4375, token_id=61948, metadata=None)))])\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.762, logit=21.250)', '\" The\"[578] (p=0.117, logit=19.375)', '\" Among\"[22395] (p=0.055, logit=18.625)', '\" A\"[362] (p=0.014, logit=17.250)', '\" Sofa\"[61948] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.76171875, logit=21.25, token_id=42609, metadata=None))), (61948, (5, PredictedToken(token=' Sofa', prob=0.0108642578125, logit=17.0, token_id=61948, metadata=None))), (94467, (109, PredictedToken(token=' Trom', prob=2.5391578674316406e-05, logit=10.9375, token_id=94467, metadata=None))), (88668, (1561, PredictedToken(token=' Blender', prob=4.0978193283081055e-07, logit=6.8125, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:29 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:29 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.762, logit=21.625)', '\" The\"[578] (p=0.071, logit=19.250)', '\" A\"[362] (p=0.049, logit=18.875)', '\" None\"[2290] (p=0.038, logit=18.625)', '\" Among\"[22395] (p=0.030, logit=18.375)']\n",
      "2025-09-16 09:43:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.820, logit=21.875)', '\" The\"[578] (p=0.067, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.625)', '\" Only\"[8442] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.8203125, logit=21.875, token_id=38930, metadata=None))), (18787, (54, PredictedToken(token=' Oak', prob=8.392333984375e-05, logit=12.6875, token_id=18787, metadata=None))), (69755, (172, PredictedToken(token=' Notebook', prob=6.467103958129883e-06, logit=10.125, token_id=69755, metadata=None))), (34046, (307, PredictedToken(token=' Cabinet', prob=2.1010637283325195e-06, logit=9.0, token_id=34046, metadata=None))), (15429, (390, PredictedToken(token=' Hospital', prob=1.3560056686401367e-06, logit=8.5625, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.414, logit=20.375)', '\" Cabinet\"[34046] (p=0.285, logit=20.000)', '\" Hospital\"[15429] (p=0.152, logit=19.375)', '\" Among\"[22395] (p=0.044, logit=18.125)', '\" The\"[578] (p=0.023, logit=17.500)']\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     int_track=OrderedDict([(34046, (2, PredictedToken(token=' Cabinet', prob=0.28515625, logit=20.0, token_id=34046, metadata=None))), (15429, (3, PredictedToken(token=' Hospital', prob=0.15234375, logit=19.375, token_id=15429, metadata=None))), (18787, (7, PredictedToken(token=' Oak', prob=0.007568359375, logit=16.375, token_id=18787, metadata=None))), (69755, (306, PredictedToken(token=' Notebook', prob=4.738569259643555e-06, logit=9.0, token_id=69755, metadata=None))), (38930, (332, PredictedToken(token=' Bike', prob=3.933906555175781e-06, logit=8.8125, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:30 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:30 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     patch_prediction=['\" Willow\"[65449] (p=0.879, logit=22.250)', '\" The\"[578] (p=0.034, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.500)', '\" Among\"[22395] (p=0.016, logit=18.250)', '\" (\"[320] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.961, logit=22.125)', '\" The\"[578] (p=0.006, logit=17.000)', '\" Hick\"[79028] (p=0.004, logit=16.625)', '\" violet\"[80836] (p=0.003, logit=16.500)', '\" Mirror\"[34954] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.9609375, logit=22.125, token_id=74574, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.003936767578125, logit=16.625, token_id=79028, metadata=None))), (34954, (4, PredictedToken(token=' Mirror', prob=0.0034637451171875, logit=16.5, token_id=34954, metadata=None)))])\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.629, logit=20.500)', '\" Hick\"[79028] (p=0.262, logit=19.625)', '\" Mirror\"[34954] (p=0.035, logit=17.625)', '\" None\"[2290] (p=0.011, logit=16.500)', '\" The\"[578] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.62890625, logit=20.5, token_id=74574, metadata=None))), (79028, (2, PredictedToken(token=' Hick', prob=0.26171875, logit=19.625, token_id=79028, metadata=None))), (34954, (3, PredictedToken(token=' Mirror', prob=0.035400390625, logit=17.625, token_id=34954, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:30 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:43:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     patch_prediction=['\" Guitar\"[47759] (p=0.559, logit=20.750)', '\" The\"[578] (p=0.206, logit=19.750)', '\" Among\"[22395] (p=0.086, logit=18.875)', '\" A\"[362] (p=0.059, logit=18.500)', '\" G\"[480] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     clean_prediction=['\" Charm\"[58600] (p=0.625, logit=21.250)', '\" The\"[578] (p=0.109, logit=19.500)', '\" Among\"[22395] (p=0.084, logit=19.250)', '\" A\"[362] (p=0.084, logit=19.250)', '\" C\"[356] (p=0.015, logit=17.500)']\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     clean_track=OrderedDict([(58600, (1, PredictedToken(token=' Charm', prob=0.625, logit=21.25, token_id=58600, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.01470947265625, logit=17.5, token_id=356, metadata=None))), (16147, (101, PredictedToken(token=' Smart', prob=3.218650817871094e-05, logit=11.375, token_id=16147, metadata=None))), (6690, (200, PredictedToken(token=' Air', prob=8.165836334228516e-06, logit=10.0, token_id=6690, metadata=None))), (17367, (463, PredictedToken(token=' Factory', prob=1.9371509552001953e-06, logit=8.5625, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.750, logit=22.375)', '\" The\"[578] (p=0.079, logit=20.125)', '\" Among\"[22395] (p=0.062, logit=19.875)', '\" A\"[362] (p=0.042, logit=19.500)', '\" It\"[1102] (p=0.026, logit=19.000)']\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.75, logit=22.375, token_id=16147, metadata=None))), (356, (18, PredictedToken(token=' C', prob=0.000934600830078125, logit=15.6875, token_id=356, metadata=None))), (6690, (169, PredictedToken(token=' Air', prob=6.705522537231445e-06, logit=10.75, token_id=6690, metadata=None))), (17367, (1631, PredictedToken(token=' Factory', prob=1.5273690223693848e-07, logit=6.96875, token_id=17367, metadata=None))), (58600, (4872, PredictedToken(token=' Charm', prob=2.735760062932968e-08, logit=5.25, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:31 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:31 src.selection.optimization DEBUG    torch.Size([6, 35])\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     patch_prediction=['\" Fl\"[3061] (p=0.703, logit=21.250)', '\" The\"[578] (p=0.157, logit=19.750)', '\" Among\"[22395] (p=0.051, logit=18.625)', '\" A\"[362] (p=0.031, logit=18.125)', '\" It\"[1102] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:43:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     clean_prediction=['\" Calculator\"[37128] (p=0.660, logit=20.500)', '\" The\"[578] (p=0.101, logit=18.625)', '\" A\"[362] (p=0.089, logit=18.500)', '\" Among\"[22395] (p=0.042, logit=17.750)', '\" It\"[1102] (p=0.018, logit=16.875)']\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     clean_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.66015625, logit=20.5, token_id=37128, metadata=None))), (469, (10, PredictedToken(token=' E', prob=0.0032501220703125, logit=15.1875, token_id=469, metadata=None))), (3420, (56, PredictedToken(token=' Trump', prob=0.00025177001953125, logit=12.625, token_id=3420, metadata=None))), (3341, (111, PredictedToken(token=' Car', prob=5.9604644775390625e-05, logit=11.1875, token_id=3341, metadata=None))), (61731, (188, PredictedToken(token=' Soap', prob=2.193450927734375e-05, logit=10.1875, token_id=61731, metadata=None))), (13394, (223, PredictedToken(token=' Bed', prob=1.609325408935547e-05, logit=9.875, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.457, logit=19.000)', '\" None\"[2290] (p=0.190, logit=18.125)', '\" Among\"[22395] (p=0.090, logit=17.375)', '\" The\"[578] (p=0.055, logit=16.875)', '\" Trump\"[3420] (p=0.038, logit=16.500)']\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.45703125, logit=19.0, token_id=469, metadata=None))), (3420, (5, PredictedToken(token=' Trump', prob=0.03759765625, logit=16.5, token_id=3420, metadata=None))), (13394, (6, PredictedToken(token=' Bed', prob=0.022705078125, logit=16.0, token_id=13394, metadata=None))), (3341, (84, PredictedToken(token=' Car', prob=0.0001850128173828125, logit=11.1875, token_id=3341, metadata=None))), (61731, (236, PredictedToken(token=' Soap', prob=2.658367156982422e-05, logit=9.25, token_id=61731, metadata=None))), (37128, (474, PredictedToken(token=' Calculator', prob=6.943941116333008e-06, logit=7.90625, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:32 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.875, logit=21.875)', '\" Among\"[22395] (p=0.034, logit=18.625)', '\" The\"[578] (p=0.034, logit=18.625)', '\" A\"[362] (p=0.011, logit=17.500)', '\" Option\"[7104] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     clean_prediction=['\" None\"[2290] (p=0.471, logit=20.000)', '\" Factory\"[17367] (p=0.367, logit=19.750)', '\" The\"[578] (p=0.034, logit=17.375)', '\" A\"[362] (p=0.027, logit=17.125)', '\" There\"[2684] (p=0.016, logit=16.625)']\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (2, PredictedToken(token=' Factory', prob=0.3671875, logit=19.75, token_id=17367, metadata=None))), (61948, (6, PredictedToken(token=' Sofa', prob=0.009765625, logit=16.125, token_id=61948, metadata=None))), (33199, (7, PredictedToken(token=' Lion', prob=0.00762939453125, logit=15.875, token_id=33199, metadata=None))), (6690, (18, PredictedToken(token=' Air', prob=0.00159454345703125, logit=14.3125, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.637, logit=20.000)', '\" Lion\"[33199] (p=0.207, logit=18.875)', '\" The\"[578] (p=0.028, logit=16.875)', '\" Among\"[22395] (p=0.022, logit=16.625)', '\" There\"[2684] (p=0.012, logit=16.000)']\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     int_track=OrderedDict([(33199, (2, PredictedToken(token=' Lion', prob=0.20703125, logit=18.875, token_id=33199, metadata=None))), (17367, (7, PredictedToken(token=' Factory', prob=0.008544921875, logit=15.6875, token_id=17367, metadata=None))), (6690, (15, PredictedToken(token=' Air', prob=0.002777099609375, logit=14.5625, token_id=6690, metadata=None))), (61948, (160, PredictedToken(token=' Sofa', prob=2.8967857360839844e-05, logit=10.0, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:32 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:43:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.758, logit=22.250)', '\" The\"[578] (p=0.116, logit=20.375)', '\" A\"[362] (p=0.062, logit=19.750)', '\" Among\"[22395] (p=0.038, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     clean_prediction=['\" School\"[6150] (p=0.586, logit=21.000)', '\" None\"[2290] (p=0.314, logit=20.375)', '\" The\"[578] (p=0.026, logit=17.875)', '\" There\"[2684] (p=0.012, logit=17.125)', '\" Among\"[22395] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     clean_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.5859375, logit=21.0, token_id=6150, metadata=None))), (41493, (14, PredictedToken(token=' Tow', prob=0.001129150390625, logit=14.75, token_id=41493, metadata=None))), (55405, (21, PredictedToken(token=' Orch', prob=0.0006866455078125, logit=14.25, token_id=55405, metadata=None))), (6690, (33, PredictedToken(token=' Air', prob=0.0003452301025390625, logit=13.5625, token_id=6690, metadata=None))), (65197, (66, PredictedToken(token=' Surf', prob=9.870529174804688e-05, logit=12.3125, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.766, logit=20.875)', '\" Orch\"[55405] (p=0.133, logit=19.125)', '\" There\"[2684] (p=0.026, logit=17.500)', '\" The\"[578] (p=0.014, logit=16.875)', '\" none\"[7000] (p=0.007, logit=16.125)']\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     int_track=OrderedDict([(55405, (2, PredictedToken(token=' Orch', prob=0.1328125, logit=19.125, token_id=55405, metadata=None))), (41493, (24, PredictedToken(token=' Tow', prob=0.000579833984375, logit=13.6875, token_id=41493, metadata=None))), (6690, (117, PredictedToken(token=' Air', prob=3.075599670410156e-05, logit=10.75, token_id=6690, metadata=None))), (6150, (513, PredictedToken(token=' School', prob=2.518296241760254e-06, logit=8.25, token_id=6150, metadata=None))), (65197, (698, PredictedToken(token=' Surf', prob=1.6763806343078613e-06, logit=7.84375, token_id=65197, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:33 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:33 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     patch_prediction=['\" Sc\"[2522] (p=0.613, logit=19.875)', '\" None\"[2290] (p=0.155, logit=18.500)', '\" Mixer\"[72392] (p=0.073, logit=17.750)', '\" The\"[578] (p=0.027, logit=16.750)', '\" Micro\"[18654] (p=0.021, logit=16.500)']\n",
      "2025-09-16 09:43:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     clean_prediction=['\" Yoga\"[38673] (p=0.594, logit=19.750)', '\" None\"[2290] (p=0.133, logit=18.250)', '\" Bamboo\"[98028] (p=0.055, logit=17.375)', '\" Tr\"[1183] (p=0.055, logit=17.375)', '\" The\"[578] (p=0.043, logit=17.125)']\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     clean_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.59375, logit=19.75, token_id=38673, metadata=None))), (98028, (4, PredictedToken(token=' Bamboo', prob=0.05517578125, logit=17.375, token_id=98028, metadata=None))), (1183, (3, PredictedToken(token=' Tr', prob=0.05517578125, logit=17.375, token_id=1183, metadata=None))), (40975, (10, PredictedToken(token=' Marker', prob=0.0042724609375, logit=14.8125, token_id=40975, metadata=None))), (76924, (96, PredictedToken(token=' Banana', prob=0.00011348724365234375, logit=11.1875, token_id=76924, metadata=None))), (12369, (443, PredictedToken(token=' Food', prob=6.8247318267822266e-06, logit=8.375, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.895, logit=21.500)', '\" None\"[2290] (p=0.050, logit=18.625)', '\" The\"[578] (p=0.016, logit=17.500)', '\" A\"[362] (p=0.005, logit=16.375)', '\" Among\"[22395] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.89453125, logit=21.5, token_id=40975, metadata=None))), (98028, (7, PredictedToken(token=' Bamboo', prob=0.002838134765625, logit=15.75, token_id=98028, metadata=None))), (1183, (11, PredictedToken(token=' Tr', prob=0.0011138916015625, logit=14.8125, token_id=1183, metadata=None))), (38673, (40, PredictedToken(token=' Yoga', prob=0.000141143798828125, logit=12.75, token_id=38673, metadata=None))), (76924, (64, PredictedToken(token=' Banana', prob=5.53131103515625e-05, logit=11.8125, token_id=76924, metadata=None))), (12369, (421, PredictedToken(token=' Food', prob=2.1457672119140625e-06, logit=8.5625, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:34 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:34 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.625, logit=21.250)', '\" The\"[578] (p=0.123, logit=19.625)', '\" Among\"[22395] (p=0.108, logit=19.500)', '\" A\"[362] (p=0.040, logit=18.500)', '\" (\"[320] (p=0.021, logit=17.875)']\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.859, logit=21.875)', '\" The\"[578] (p=0.038, logit=18.750)', '\" Among\"[22395] (p=0.029, logit=18.500)', '\" A\"[362] (p=0.018, logit=18.000)', '\" (\"[320] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.859375, logit=21.875, token_id=88088, metadata=None))), (1901, (40, PredictedToken(token=' Z', prob=0.0001277923583984375, logit=13.0625, token_id=1901, metadata=None))), (81501, (51, PredictedToken(token=' Pendant', prob=7.772445678710938e-05, logit=12.5625, token_id=81501, metadata=None)))])\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     int_prediction=['\" Pendant\"[81501] (p=0.633, logit=21.500)', '\" Z\"[1901] (p=0.125, logit=19.875)', '\" Among\"[22395] (p=0.110, logit=19.750)', '\" The\"[578] (p=0.041, logit=18.750)', '\" Option\"[7104] (p=0.028, logit=18.375)']\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     int_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.6328125, logit=21.5, token_id=81501, metadata=None))), (1901, (2, PredictedToken(token=' Z', prob=0.125, logit=19.875, token_id=1901, metadata=None))), (88088, (95, PredictedToken(token=' Birch', prob=3.4809112548828125e-05, logit=11.6875, token_id=88088, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:34 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:43:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     patch_prediction=['\" Lion\"[33199] (p=0.664, logit=21.500)', '\" The\"[578] (p=0.147, logit=20.000)', '\" Among\"[22395] (p=0.070, logit=19.250)', '\" A\"[362] (p=0.062, logit=19.125)', '\" Option\"[7104] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.840, logit=22.375)', '\" The\"[578] (p=0.069, logit=19.875)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" A\"[362] (p=0.022, logit=18.750)', '\" It\"[1102] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.83984375, logit=22.375, token_id=40759, metadata=None))), (8325, (47, PredictedToken(token=' Apple', prob=0.00012493133544921875, logit=13.5625, token_id=8325, metadata=None))), (65449, (85, PredictedToken(token=' Willow', prob=2.181529998779297e-05, logit=11.8125, token_id=65449, metadata=None))), (49431, (361, PredictedToken(token=' Rabbit', prob=1.30385160446167e-06, logit=9.0, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.326, logit=20.500)', '\" Rabbit\"[49431] (p=0.326, logit=20.500)', '\" The\"[578] (p=0.136, logit=19.625)', '\" Among\"[22395] (p=0.094, logit=19.250)', '\" It\"[1102] (p=0.016, logit=17.500)']\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.326171875, logit=20.5, token_id=8325, metadata=None))), (49431, (2, PredictedToken(token=' Rabbit', prob=0.326171875, logit=20.5, token_id=49431, metadata=None))), (65449, (154, PredictedToken(token=' Willow', prob=1.5735626220703125e-05, logit=10.5625, token_id=65449, metadata=None))), (40759, (1431, PredictedToken(token=' Harmon', prob=4.33996319770813e-07, logit=6.96875, token_id=40759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:35 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:35 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.809, logit=22.125)', '\" The\"[578] (p=0.075, logit=19.750)', '\" A\"[362] (p=0.066, logit=19.625)', '\" Among\"[22395] (p=0.013, logit=18.000)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:43:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.812, logit=20.625)', '\" None\"[2290] (p=0.041, logit=17.625)', '\" A\"[362] (p=0.041, logit=17.625)', '\" The\"[578] (p=0.031, logit=17.375)', '\" Note\"[7181] (p=0.010, logit=16.250)']\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.8125, logit=20.625, token_id=69755, metadata=None))), (50159, (47, PredictedToken(token=' Sco', prob=0.00018787384033203125, logit=12.25, token_id=50159, metadata=None))), (13394, (83, PredictedToken(token=' Bed', prob=6.914138793945312e-05, logit=11.25, token_id=13394, metadata=None)))])\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     int_prediction=['\" Bed\"[13394] (p=0.582, logit=19.625)', '\" None\"[2290] (p=0.312, logit=19.000)', '\" Sco\"[50159] (p=0.014, logit=15.875)', '\" The\"[578] (p=0.012, logit=15.750)', '\" A\"[362] (p=0.007, logit=15.250)']\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     int_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.58203125, logit=19.625, token_id=13394, metadata=None))), (50159, (3, PredictedToken(token=' Sco', prob=0.01373291015625, logit=15.875, token_id=50159, metadata=None))), (69755, (17, PredictedToken(token=' Notebook', prob=0.0014495849609375, logit=13.625, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:36 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:36 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     patch_prediction=['\" Tow\"[41493] (p=0.965, logit=22.500)', '\" The\"[578] (p=0.009, logit=17.875)', '\" A\"[362] (p=0.009, logit=17.875)', '\" (\"[320] (p=0.003, logit=16.875)', '\" Among\"[22395] (p=0.002, logit=16.500)']\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     clean_prediction=['\" Pe\"[5250] (p=0.707, logit=21.625)', '\" The\"[578] (p=0.140, logit=20.000)', '\" Among\"[22395] (p=0.066, logit=19.250)', '\" A\"[362] (p=0.027, logit=18.375)', '\" (\"[320] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     clean_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.70703125, logit=21.625, token_id=5250, metadata=None))), (23262, (24, PredictedToken(token=' Comb', prob=0.0004711151123046875, logit=14.3125, token_id=23262, metadata=None))), (53889, (206, PredictedToken(token=' Apartment', prob=7.152557373046875e-06, logit=10.125, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.777, logit=21.875)', '\" The\"[578] (p=0.082, logit=19.625)', '\" Among\"[22395] (p=0.056, logit=19.250)', '\" A\"[362] (p=0.023, logit=18.375)', '\" (\"[320] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.77734375, logit=21.875, token_id=23262, metadata=None))), (53889, (7, PredictedToken(token=' Apartment', prob=0.007598876953125, logit=17.25, token_id=53889, metadata=None))), (5250, (14, PredictedToken(token=' Pe', prob=0.0010986328125, logit=15.3125, token_id=5250, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:36 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.742, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" A\"[362] (p=0.048, logit=19.125)', '\" Among\"[22395] (p=0.042, logit=19.000)', '\" It\"[1102] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.734, logit=21.500)', '\" The\"[578] (p=0.077, logit=19.250)', '\" C\"[356] (p=0.068, logit=19.125)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" An\"[1556] (p=0.017, logit=17.750)']\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.734375, logit=21.5, token_id=6690, metadata=None))), (356, (3, PredictedToken(token=' C', prob=0.068359375, logit=19.125, token_id=356, metadata=None))), (68027, (28, PredictedToken(token=' Sax', prob=0.000667572021484375, logit=14.5, token_id=68027, metadata=None))), (29318, (101, PredictedToken(token=' Dress', prob=2.753734588623047e-05, logit=11.3125, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.373, logit=20.250)', '\" Among\"[22395] (p=0.256, logit=19.875)', '\" The\"[578] (p=0.137, logit=19.250)', '\" Sax\"[68027] (p=0.073, logit=18.625)', '\" Option\"[7104] (p=0.050, logit=18.250)']\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.373046875, logit=20.25, token_id=356, metadata=None))), (68027, (4, PredictedToken(token=' Sax', prob=0.0732421875, logit=18.625, token_id=68027, metadata=None))), (29318, (6, PredictedToken(token=' Dress', prob=0.0238037109375, logit=17.5, token_id=29318, metadata=None))), (6690, (506, PredictedToken(token=' Air', prob=2.428889274597168e-06, logit=8.3125, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:37 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:37 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     patch_prediction=['\" Harmon\"[40759] (p=0.855, logit=22.875)', '\" The\"[578] (p=0.080, logit=20.500)', '\" A\"[362] (p=0.023, logit=19.250)', '\" Among\"[22395] (p=0.018, logit=19.000)', '\" It\"[1102] (p=0.006, logit=17.875)']\n",
      "2025-09-16 09:43:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.820, logit=21.250)', '\" The\"[578] (p=0.059, logit=18.625)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" A\"[362] (p=0.025, logit=17.750)', '\" It\"[1102] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.8203125, logit=21.25, token_id=38258, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.003570556640625, logit=15.8125, token_id=356, metadata=None))), (23262, (32, PredictedToken(token=' Comb', prob=0.000583648681640625, logit=14.0, token_id=23262, metadata=None))), (76924, (35, PredictedToken(token=' Banana', prob=0.000514984130859375, logit=13.875, token_id=76924, metadata=None))), (91263, (108, PredictedToken(token=' Binder', prob=4.220008850097656e-05, logit=11.375, token_id=91263, metadata=None)))])\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.566, logit=20.000)', '\" None\"[2290] (p=0.144, logit=18.625)', '\" The\"[578] (p=0.068, logit=17.875)', '\" Among\"[22395] (p=0.060, logit=17.750)', '\" C\"[356] (p=0.032, logit=17.125)']\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.56640625, logit=20.0, token_id=23262, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.031982421875, logit=17.125, token_id=356, metadata=None))), (91263, (13, PredictedToken(token=' Binder', prob=0.004058837890625, logit=15.0625, token_id=91263, metadata=None))), (38258, (27, PredictedToken(token=' Baseball', prob=0.00102996826171875, logit=13.6875, token_id=38258, metadata=None))), (76924, (32, PredictedToken(token=' Banana', prob=0.00090789794921875, logit=13.5625, token_id=76924, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:38 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     patch_prediction=['\" Mouse\"[18191] (p=0.879, logit=21.875)', '\" The\"[578] (p=0.034, logit=18.625)', '\" A\"[362] (p=0.030, logit=18.500)', '\" Among\"[22395] (p=0.011, logit=17.500)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     clean_prediction=['\" Pear\"[23910] (p=0.863, logit=22.750)', '\" The\"[578] (p=0.055, logit=20.000)', '\" Among\"[22395] (p=0.033, logit=19.500)', '\" A\"[362] (p=0.026, logit=19.250)', '\" pear\"[38790] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     clean_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.86328125, logit=22.75, token_id=23910, metadata=None))), (49431, (67, PredictedToken(token=' Rabbit', prob=1.9669532775878906e-05, logit=12.0625, token_id=49431, metadata=None))), (34046, (76, PredictedToken(token=' Cabinet', prob=1.633167266845703e-05, logit=11.875, token_id=34046, metadata=None))), (11452, (79, PredictedToken(token=' Head', prob=1.537799835205078e-05, logit=11.8125, token_id=11452, metadata=None)))])\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     int_prediction=['\" Head\"[11452] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.097, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=18.750)', '\" Option\"[7104] (p=0.007, logit=17.125)', '\" It\"[1102] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     int_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.80859375, logit=21.875, token_id=11452, metadata=None))), (49431, (12, PredictedToken(token=' Rabbit', prob=0.0016632080078125, logit=15.6875, token_id=49431, metadata=None))), (34046, (36, PredictedToken(token=' Cabinet', prob=0.000255584716796875, logit=13.8125, token_id=34046, metadata=None))), (23910, (165, PredictedToken(token=' Pear', prob=7.68899917602539e-06, logit=10.3125, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:38 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:43:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     patch_prediction=['\" Monkey\"[58937] (p=0.797, logit=21.875)', '\" The\"[578] (p=0.074, logit=19.500)', '\" A\"[362] (p=0.058, logit=19.250)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" \"[220] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     clean_prediction=['\" X\"[1630] (p=0.680, logit=22.000)', '\" The\"[578] (p=0.151, logit=20.500)', '\" A\"[362] (p=0.081, logit=19.875)', '\" Among\"[22395] (p=0.049, logit=19.375)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     clean_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.6796875, logit=22.0, token_id=1630, metadata=None))), (15883, (83, PredictedToken(token=' Spr', prob=2.396106719970703e-05, logit=11.75, token_id=15883, metadata=None))), (50159, (178, PredictedToken(token=' Sco', prob=6.0498714447021484e-06, logit=10.375, token_id=50159, metadata=None))), (28131, (340, PredictedToken(token=' Golf', prob=1.4379620552062988e-06, logit=8.9375, token_id=28131, metadata=None))), (96096, (431, PredictedToken(token=' Dolphin', prob=9.313225746154785e-07, logit=8.5, token_id=96096, metadata=None))), (52882, (849, PredictedToken(token=' Pepper', prob=3.3155083656311035e-07, logit=7.46875, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.770, logit=21.500)', '\" The\"[578] (p=0.081, logit=19.250)', '\" Among\"[22395] (p=0.071, logit=19.125)', '\" D\"[423] (p=0.021, logit=17.875)', '\" A\"[362] (p=0.021, logit=17.875)']\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.76953125, logit=21.5, token_id=96096, metadata=None))), (15883, (8, PredictedToken(token=' Spr', prob=0.0029449462890625, logit=15.9375, token_id=15883, metadata=None))), (52882, (21, PredictedToken(token=' Pepper', prob=0.000545501708984375, logit=14.25, token_id=52882, metadata=None))), (28131, (35, PredictedToken(token=' Golf', prob=0.000213623046875, logit=13.3125, token_id=28131, metadata=None))), (1630, (72, PredictedToken(token=' X', prob=3.9577484130859375e-05, logit=11.625, token_id=1630, metadata=None))), (50159, (246, PredictedToken(token=' Sco', prob=4.172325134277344e-06, logit=9.375, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:39 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:39 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.805, logit=20.875)', '\" None\"[2290] (p=0.052, logit=18.125)', '\" The\"[578] (p=0.045, logit=18.000)', '\" Among\"[22395] (p=0.028, logit=17.500)', '\" A\"[362] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.875, logit=22.125)', '\" An\"[1556] (p=0.038, logit=19.000)', '\" The\"[578] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.023, logit=18.500)', '\" ank\"[71572] (p=0.014, logit=18.000)']\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.875, logit=22.125, token_id=57915, metadata=None))), (15883, (19, PredictedToken(token=' Spr', prob=0.0003528594970703125, logit=14.3125, token_id=15883, metadata=None))), (82452, (94, PredictedToken(token=' Jasmine', prob=1.990795135498047e-05, logit=11.4375, token_id=82452, metadata=None))), (100031, (314, PredictedToken(token=' Mosque', prob=1.7434358596801758e-06, logit=9.0, token_id=100031, metadata=None))), (13120, (323, PredictedToken(token=' Night', prob=1.6391277313232422e-06, logit=8.9375, token_id=13120, metadata=None))), (74968, (336, PredictedToken(token=' Razor', prob=1.5422701835632324e-06, logit=8.875, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     int_prediction=['\" Night\"[13120] (p=0.535, logit=20.875)', '\" Mosque\"[100031] (p=0.223, logit=20.000)', '\" The\"[578] (p=0.093, logit=19.125)', '\" Among\"[22395] (p=0.072, logit=18.875)', '\" Spr\"[15883] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     int_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.53515625, logit=20.875, token_id=13120, metadata=None))), (100031, (2, PredictedToken(token=' Mosque', prob=0.22265625, logit=20.0, token_id=100031, metadata=None))), (15883, (5, PredictedToken(token=' Spr', prob=0.01422119140625, logit=17.25, token_id=15883, metadata=None))), (74968, (266, PredictedToken(token=' Razor', prob=5.3942203521728516e-06, logit=9.375, token_id=74968, metadata=None))), (82452, (385, PredictedToken(token=' Jasmine', prob=2.7120113372802734e-06, logit=8.6875, token_id=82452, metadata=None))), (57915, (3204, PredictedToken(token=' Ank', prob=1.73225998878479e-07, logit=5.9375, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:40 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:40 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     patch_prediction=['\" Necklace\"[86460] (p=0.918, logit=23.250)', '\" The\"[578] (p=0.025, logit=19.625)', '\" A\"[362] (p=0.025, logit=19.625)', '\" Among\"[22395] (p=0.013, logit=19.000)', '\" necklace\"[55547] (p=0.004, logit=17.875)']\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.914, logit=22.500)', '\" A\"[362] (p=0.024, logit=18.875)', '\" The\"[578] (p=0.019, logit=18.625)', '\" monitor\"[8891] (p=0.011, logit=18.125)', '\" (\"[320] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.9140625, logit=22.5, token_id=24423, metadata=None))), (29625, (28, PredictedToken(token=' Chain', prob=0.00022411346435546875, logit=14.1875, token_id=29625, metadata=None))), (16730, (155, PredictedToken(token=' Museum', prob=5.27501106262207e-06, logit=10.4375, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     int_prediction=['\" Chain\"[29625] (p=0.547, logit=20.000)', '\" Museum\"[16730] (p=0.258, logit=19.250)', '\" Among\"[22395] (p=0.045, logit=17.500)', '\" The\"[578] (p=0.031, logit=17.125)', '\" (\"[320] (p=0.016, logit=16.500)']\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     int_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.546875, logit=20.0, token_id=29625, metadata=None))), (16730, (2, PredictedToken(token=' Museum', prob=0.2578125, logit=19.25, token_id=16730, metadata=None))), (24423, (10, PredictedToken(token=' Monitor', prob=0.005340576171875, logit=15.375, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:40 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:43:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     patch_prediction=['\" Amb\"[20423] (p=0.664, logit=22.250)', '\" An\"[1556] (p=0.148, logit=20.750)', '\" Among\"[22395] (p=0.080, logit=20.125)', '\" The\"[578] (p=0.070, logit=20.000)', '\" Option\"[7104] (p=0.008, logit=17.875)']\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     clean_prediction=['\" Jeans\"[82507] (p=0.844, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" A\"[362] (p=0.009, logit=17.750)', '\" JE\"[71430] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     clean_track=OrderedDict([(82507, (1, PredictedToken(token=' Jeans', prob=0.84375, logit=22.25, token_id=82507, metadata=None))), (423, (30, PredictedToken(token=' D', prob=0.0002346038818359375, logit=14.0625, token_id=423, metadata=None))), (16183, (88, PredictedToken(token=' Hel', prob=2.3245811462402344e-05, logit=11.75, token_id=16183, metadata=None))), (16730, (1284, PredictedToken(token=' Museum', prob=1.825392246246338e-07, logit=6.90625, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.805, logit=22.125)', '\" The\"[578] (p=0.096, logit=20.000)', '\" Among\"[22395] (p=0.035, logit=19.000)', '\" A\"[362] (p=0.019, logit=18.375)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.8046875, logit=22.125, token_id=16183, metadata=None))), (16730, (10, PredictedToken(token=' Museum', prob=0.0019989013671875, logit=16.125, token_id=16730, metadata=None))), (423, (17, PredictedToken(token=' D', prob=0.000885009765625, logit=15.3125, token_id=423, metadata=None))), (82507, (325, PredictedToken(token=' Jeans', prob=1.817941665649414e-06, logit=9.125, token_id=82507, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:41 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:43:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.727, logit=21.875)', '\" The\"[578] (p=0.099, logit=19.875)', '\" A\"[362] (p=0.087, logit=19.750)', '\" Among\"[22395] (p=0.053, logit=19.250)', '\" It\"[1102] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     clean_prediction=['\" Baseball\"[38258] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.102, logit=19.375)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" A\"[362] (p=0.043, logit=18.500)', '\" It\"[1102] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     clean_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.75390625, logit=21.375, token_id=38258, metadata=None))), (2057, (36, PredictedToken(token=' To', prob=0.0003681182861328125, logit=13.75, token_id=2057, metadata=None))), (47643, (50, PredictedToken(token=' Cel', prob=0.000164031982421875, logit=12.9375, token_id=47643, metadata=None))), (10164, (294, PredictedToken(token=' Water', prob=4.351139068603516e-06, logit=9.3125, token_id=10164, metadata=None))), (32498, (1650, PredictedToken(token=' Mall', prob=3.371387720108032e-07, logit=6.75, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     int_prediction=['\" To\"[2057] (p=0.754, logit=21.000)', '\" The\"[578] (p=0.080, logit=18.750)', '\" Among\"[22395] (p=0.038, logit=18.000)', '\" A\"[362] (p=0.029, logit=17.750)', '\" Cel\"[47643] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     int_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.75390625, logit=21.0, token_id=2057, metadata=None))), (47643, (5, PredictedToken(token=' Cel', prob=0.0137939453125, logit=17.0, token_id=47643, metadata=None))), (10164, (6, PredictedToken(token=' Water', prob=0.0107421875, logit=16.75, token_id=10164, metadata=None))), (38258, (65, PredictedToken(token=' Baseball', prob=0.00011968612670898438, logit=12.25, token_id=38258, metadata=None))), (32498, (185, PredictedToken(token=' Mall', prob=1.341104507446289e-05, logit=10.0625, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:42 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     patch_prediction=['\" Cedar\"[57748] (p=0.797, logit=21.375)', '\" The\"[578] (p=0.095, logit=19.250)', '\" Among\"[22395] (p=0.045, logit=18.500)', '\" A\"[362] (p=0.011, logit=17.125)', '\" Option\"[7104] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.711, logit=20.875)', '\" The\"[578] (p=0.109, logit=19.000)', '\" Among\"[22395] (p=0.045, logit=18.125)', '\" A\"[362] (p=0.045, logit=18.125)', '\" Key\"[5422] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.7109375, logit=20.875, token_id=26698, metadata=None))), (4923, (34, PredictedToken(token=' Sk', prob=0.00057220458984375, logit=13.75, token_id=4923, metadata=None))), (22607, (52, PredictedToken(token=' Cow', prob=0.000209808349609375, logit=12.75, token_id=22607, metadata=None))), (44570, (125, PredictedToken(token=' Maple', prob=3.647804260253906e-05, logit=11.0, token_id=44570, metadata=None)))])\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     int_prediction=['\" Maple\"[44570] (p=0.777, logit=20.750)', '\" Among\"[22395] (p=0.064, logit=18.250)', '\" None\"[2290] (p=0.056, logit=18.125)', '\" The\"[578] (p=0.027, logit=17.375)', '\" A\"[362] (p=0.006, logit=15.875)']\n",
      "2025-09-16 09:43:42 src.selection.optimization INFO     int_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.77734375, logit=20.75, token_id=44570, metadata=None))), (4923, (107, PredictedToken(token=' Sk', prob=3.7670135498046875e-05, logit=10.8125, token_id=4923, metadata=None))), (26698, (272, PredictedToken(token=' Keyboard', prob=6.556510925292969e-06, logit=9.0625, token_id=26698, metadata=None))), (22607, (492, PredictedToken(token=' Cow', prob=2.562999725341797e-06, logit=8.125, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:43 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     patch_prediction=['\" Dolphin\"[96096] (p=0.879, logit=22.000)', '\" The\"[578] (p=0.044, logit=19.000)', '\" Among\"[22395] (p=0.021, logit=18.250)', '\" A\"[362] (p=0.021, logit=18.250)', '\" Bat\"[16488] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.824, logit=21.750)', '\" The\"[578] (p=0.068, logit=19.250)', '\" Among\"[22395] (p=0.036, logit=18.625)', '\" A\"[362] (p=0.022, logit=18.125)', '\" Option\"[7104] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.82421875, logit=21.75, token_id=469, metadata=None))), (91263, (78, PredictedToken(token=' Binder', prob=4.5299530029296875e-05, logit=11.9375, token_id=91263, metadata=None))), (14588, (110, PredictedToken(token=' Dog', prob=2.002716064453125e-05, logit=11.125, token_id=14588, metadata=None))), (29318, (444, PredictedToken(token=' Dress', prob=1.2069940567016602e-06, logit=8.3125, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.738, logit=21.625)', '\" The\"[578] (p=0.078, logit=19.375)', '\" Among\"[22395] (p=0.053, logit=19.000)', '\" A\"[362] (p=0.053, logit=19.000)', '\" Binder\"[91263] (p=0.025, logit=18.250)']\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.73828125, logit=21.625, token_id=14588, metadata=None))), (91263, (5, PredictedToken(token=' Binder', prob=0.0252685546875, logit=18.25, token_id=91263, metadata=None))), (29318, (13, PredictedToken(token=' Dress', prob=0.001617431640625, logit=15.5, token_id=29318, metadata=None))), (469, (30, PredictedToken(token=' E', prob=0.000408172607421875, logit=14.125, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:43 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:43 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:43:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.871, logit=22.375)', '\" The\"[578] (p=0.038, logit=19.250)', '\" Among\"[22395] (p=0.030, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.625)', '\" None\"[2290] (p=0.012, logit=18.125)']\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.719, logit=21.875)', '\" The\"[578] (p=0.160, logit=20.375)', '\" A\"[362] (p=0.046, logit=19.125)', '\" Among\"[22395] (p=0.031, logit=18.750)', '\" It\"[1102] (p=0.013, logit=17.875)']\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.71875, logit=21.875, token_id=31181, metadata=None))), (67629, (219, PredictedToken(token=' Helmet', prob=3.904104232788086e-06, logit=9.75, token_id=67629, metadata=None))), (14642, (302, PredictedToken(token=' Phone', prob=2.2202730178833008e-06, logit=9.1875, token_id=14642, metadata=None))), (94091, (701, PredictedToken(token=' Tomato', prob=5.62518835067749e-07, logit=7.8125, token_id=94091, metadata=None)))])\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     int_prediction=['\" Tomato\"[94091] (p=0.734, logit=21.500)', '\" The\"[578] (p=0.128, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=18.750)', '\" A\"[362] (p=0.020, logit=17.875)', '\" Phone\"[14642] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     int_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.734375, logit=21.5, token_id=94091, metadata=None))), (14642, (5, PredictedToken(token=' Phone', prob=0.010498046875, logit=17.25, token_id=14642, metadata=None))), (31181, (6, PredictedToken(token=' Clar', prob=0.00921630859375, logit=17.125, token_id=31181, metadata=None))), (67629, (168, PredictedToken(token=' Helmet', prob=1.0788440704345703e-05, logit=10.375, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:44 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.562, logit=20.625)', '\" None\"[2290] (p=0.266, logit=19.875)', '\" There\"[2684] (p=0.041, logit=18.000)', '\" The\"[578] (p=0.041, logit=18.000)', '\" A\"[362] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.641, logit=21.125)', '\" The\"[578] (p=0.111, logit=19.375)', '\" Among\"[22395] (p=0.099, logit=19.250)', '\" A\"[362] (p=0.068, logit=18.875)', '\" C\"[356] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.640625, logit=21.125, token_id=27171, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.0133056640625, logit=17.25, token_id=356, metadata=None))), (6690, (19, PredictedToken(token=' Air', prob=0.0012359619140625, logit=14.875, token_id=6690, metadata=None))), (4923, (46, PredictedToken(token=' Sk', prob=0.000202178955078125, logit=13.0625, token_id=4923, metadata=None))), (84008, (101, PredictedToken(token=' Sheep', prob=4.2438507080078125e-05, logit=11.5, token_id=84008, metadata=None))), (27738, (100, PredictedToken(token=' Ward', prob=4.2438507080078125e-05, logit=11.5, token_id=27738, metadata=None)))])\n",
      "2025-09-16 09:43:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     int_prediction=['\" Sheep\"[84008] (p=0.602, logit=20.500)', '\" Among\"[22395] (p=0.118, logit=18.875)', '\" None\"[2290] (p=0.072, logit=18.375)', '\" The\"[578] (p=0.072, logit=18.375)', '\" Sk\"[4923] (p=0.026, logit=17.375)']\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     int_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.6015625, logit=20.5, token_id=84008, metadata=None))), (4923, (5, PredictedToken(token=' Sk', prob=0.0263671875, logit=17.375, token_id=4923, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.010986328125, logit=16.5, token_id=356, metadata=None))), (27738, (73, PredictedToken(token=' Ward', prob=0.0001220703125, logit=12.0, token_id=27738, metadata=None))), (6690, (437, PredictedToken(token=' Air', prob=3.680586814880371e-06, logit=8.5, token_id=6690, metadata=None))), (27171, (714, PredictedToken(token=' Coffee', prob=1.9073486328125e-06, logit=7.84375, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:45 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.052, logit=19.125)', '\" Among\"[22395] (p=0.031, logit=18.625)', '\" (\"[320] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.613, logit=22.000)', '\" The\"[578] (p=0.176, logit=20.750)', '\" A\"[362] (p=0.107, logit=20.250)', '\" Among\"[22395] (p=0.065, logit=19.750)', '\" \"[220] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.61328125, logit=22.0, token_id=34785, metadata=None))), (14642, (80, PredictedToken(token=' Phone', prob=3.5762786865234375e-05, logit=12.25, token_id=14642, metadata=None))), (27171, (144, PredictedToken(token=' Coffee', prob=8.52346420288086e-06, logit=10.8125, token_id=27171, metadata=None))), (3061, (179, PredictedToken(token=' Fl', prob=5.513429641723633e-06, logit=10.375, token_id=3061, metadata=None))), (22725, (384, PredictedToken(token=' Orange', prob=1.3932585716247559e-06, logit=9.0, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     int_prediction=['\" Orange\"[22725] (p=0.801, logit=23.000)', '\" The\"[578] (p=0.108, logit=21.000)', '\" Among\"[22395] (p=0.031, logit=19.750)', '\" An\"[1556] (p=0.024, logit=19.500)', '\" Coffee\"[27171] (p=0.010, logit=18.625)']\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     int_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.80078125, logit=23.0, token_id=22725, metadata=None))), (27171, (5, PredictedToken(token=' Coffee', prob=0.01007080078125, logit=18.625, token_id=27171, metadata=None))), (3061, (34, PredictedToken(token=' Fl', prob=0.00012683868408203125, logit=14.25, token_id=3061, metadata=None))), (14642, (115, PredictedToken(token=' Phone', prob=8.106231689453125e-06, logit=11.5, token_id=14642, metadata=None))), (34785, (308, PredictedToken(token=' Truck', prob=1.169741153717041e-06, logit=9.5625, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:45 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:43:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     patch_prediction=['\" Mall\"[32498] (p=0.820, logit=21.875)', '\" The\"[578] (p=0.067, logit=19.375)', '\" A\"[362] (p=0.052, logit=19.125)', '\" Among\"[22395] (p=0.017, logit=18.000)', '\" Spr\"[15883] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     clean_prediction=['\" Bamboo\"[98028] (p=0.879, logit=21.125)', '\" The\"[578] (p=0.026, logit=17.625)', '\" bamboo\"[59982] (p=0.014, logit=17.000)', '\" Among\"[22395] (p=0.010, logit=16.625)', '\" None\"[2290] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     clean_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.87890625, logit=21.125, token_id=98028, metadata=None))), (6150, (12, PredictedToken(token=' School', prob=0.0027923583984375, logit=15.375, token_id=6150, metadata=None))), (72392, (80, PredictedToken(token=' Mixer', prob=4.506111145019531e-05, logit=11.25, token_id=72392, metadata=None)))])\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.480, logit=19.875)', '\" Mixer\"[72392] (p=0.330, logit=19.500)', '\" None\"[2290] (p=0.045, logit=17.500)', '\" The\"[578] (p=0.031, logit=17.125)', '\" A\"[362] (p=0.027, logit=17.000)']\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.48046875, logit=19.875, token_id=6150, metadata=None))), (72392, (2, PredictedToken(token=' Mixer', prob=0.330078125, logit=19.5, token_id=72392, metadata=None))), (98028, (112, PredictedToken(token=' Bamboo', prob=4.3392181396484375e-05, logit=10.5625, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:46 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.785, logit=21.250)', '\" The\"[578] (p=0.064, logit=18.750)', '\" None\"[2290] (p=0.034, logit=18.125)', '\" Among\"[22395] (p=0.030, logit=18.000)', '\" A\"[362] (p=0.027, logit=17.875)']\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.930, logit=22.875)', '\" The\"[578] (p=0.022, logit=19.125)', '\" A\"[362] (p=0.019, logit=19.000)', '\" Among\"[22395] (p=0.012, logit=18.500)', '\" motorcycle\"[35404] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.9296875, logit=22.875, token_id=70762, metadata=None))), (79189, (46, PredictedToken(token=' Elephant', prob=5.7697296142578125e-05, logit=13.1875, token_id=79189, metadata=None))), (47589, (56, PredictedToken(token=' Basketball', prob=3.719329833984375e-05, logit=12.75, token_id=47589, metadata=None))), (19176, (72, PredictedToken(token=' Temple', prob=2.4080276489257812e-05, logit=12.3125, token_id=19176, metadata=None))), (44570, (98, PredictedToken(token=' Maple', prob=1.138448715209961e-05, logit=11.5625, token_id=44570, metadata=None)))])\n",
      "2025-09-16 09:43:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.664, logit=21.250)', '\" Among\"[22395] (p=0.090, logit=19.250)', '\" The\"[578] (p=0.090, logit=19.250)', '\" Elephant\"[79189] (p=0.080, logit=19.125)', '\" It\"[1102] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.6640625, logit=21.25, token_id=19176, metadata=None))), (79189, (4, PredictedToken(token=' Elephant', prob=0.07958984375, logit=19.125, token_id=79189, metadata=None))), (44570, (8, PredictedToken(token=' Maple', prob=0.005767822265625, logit=16.5, token_id=44570, metadata=None))), (70762, (310, PredictedToken(token=' Motorcycle', prob=3.3974647521972656e-06, logit=9.0625, token_id=70762, metadata=None))), (47589, (1399, PredictedToken(token=' Basketball', prob=3.688037395477295e-07, logit=6.84375, token_id=47589, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:47 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:47 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.102, logit=19.375)', '\" A\"[362] (p=0.070, logit=19.000)', '\" Among\"[22395] (p=0.029, logit=18.125)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.793, logit=22.125)', '\" The\"[578] (p=0.083, logit=19.875)', '\" A\"[362] (p=0.065, logit=19.625)', '\" Among\"[22395] (p=0.031, logit=18.875)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.79296875, logit=22.125, token_id=86460, metadata=None))), (423, (13, PredictedToken(token=' D', prob=0.00077056884765625, logit=15.1875, token_id=423, metadata=None))), (36845, (57, PredictedToken(token=' Tiger', prob=5.5789947509765625e-05, logit=12.5625, token_id=36845, metadata=None))), (2522, (112, PredictedToken(token=' Sc', prob=1.4066696166992188e-05, logit=11.1875, token_id=2522, metadata=None))), (6771, (128, PredictedToken(token=' Table', prob=1.1682510375976562e-05, logit=11.0, token_id=6771, metadata=None))), (65197, (155, PredictedToken(token=' Surf', prob=8.046627044677734e-06, logit=10.625, token_id=65197, metadata=None)))])\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     int_prediction=['\" Surf\"[65197] (p=0.406, logit=20.375)', '\" Tiger\"[36845] (p=0.247, logit=19.875)', '\" The\"[578] (p=0.149, logit=19.375)', '\" Among\"[22395] (p=0.103, logit=19.000)', '\" It\"[1102] (p=0.020, logit=17.375)']\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     int_track=OrderedDict([(65197, (1, PredictedToken(token=' Surf', prob=0.40625, logit=20.375, token_id=65197, metadata=None))), (36845, (2, PredictedToken(token=' Tiger', prob=0.2470703125, logit=19.875, token_id=36845, metadata=None))), (2522, (7, PredictedToken(token=' Sc', prob=0.00579833984375, logit=16.125, token_id=2522, metadata=None))), (6771, (22, PredictedToken(token=' Table', prob=0.000946044921875, logit=14.3125, token_id=6771, metadata=None))), (423, (50, PredictedToken(token=' D', prob=0.000225067138671875, logit=12.875, token_id=423, metadata=None))), (86460, (3816, PredictedToken(token=' Necklace', prob=1.601874828338623e-07, logit=5.625, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:47 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:47 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:43:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.443, logit=19.750)', '\" To\"[2057] (p=0.270, logit=19.250)', '\" Among\"[22395] (p=0.087, logit=18.125)', '\" The\"[578] (p=0.068, logit=17.875)', '\" A\"[362] (p=0.032, logit=17.125)']\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.832, logit=21.500)', '\" The\"[578] (p=0.053, logit=18.750)', '\" An\"[1556] (p=0.042, logit=18.500)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" IR\"[16646] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.83203125, logit=21.5, token_id=66821, metadata=None))), (13000, (39, PredictedToken(token=' Van', prob=0.00014972686767578125, logit=12.875, token_id=13000, metadata=None))), (14588, (128, PredictedToken(token=' Dog', prob=1.4841556549072266e-05, logit=10.5625, token_id=14588, metadata=None))), (36943, (134, PredictedToken(token=' Folder', prob=1.3947486877441406e-05, logit=10.5, token_id=36943, metadata=None))), (26698, (536, PredictedToken(token=' Keyboard', prob=1.296401023864746e-06, logit=8.125, token_id=26698, metadata=None))), (29318, (799, PredictedToken(token=' Dress', prob=7.599592208862305e-07, logit=7.59375, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.730, logit=21.000)', '\" The\"[578] (p=0.127, logit=19.250)', '\" A\"[362] (p=0.032, logit=17.875)', '\" Dress\"[29318] (p=0.022, logit=17.500)', '\" Among\"[22395] (p=0.022, logit=17.500)']\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.73046875, logit=21.0, token_id=26698, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.02197265625, logit=17.5, token_id=29318, metadata=None))), (36943, (14, PredictedToken(token=' Folder', prob=0.00180816650390625, logit=15.0, token_id=36943, metadata=None))), (13000, (15, PredictedToken(token=' Van', prob=0.0016937255859375, logit=14.9375, token_id=13000, metadata=None))), (14588, (157, PredictedToken(token=' Dog', prob=2.002716064453125e-05, logit=10.5, token_id=14588, metadata=None))), (66821, (1073, PredictedToken(token=' Iris', prob=9.08970832824707e-07, logit=7.40625, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:48 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:48 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.922, logit=22.875)', '\" Among\"[22395] (p=0.025, logit=19.250)', '\" The\"[578] (p=0.025, logit=19.250)', '\" A\"[362] (p=0.005, logit=17.625)', '\" (\"[320] (p=0.004, logit=17.375)']\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     clean_prediction=['\" Hat\"[22050] (p=0.734, logit=21.375)', '\" The\"[578] (p=0.088, logit=19.250)', '\" A\"[362] (p=0.077, logit=19.125)', '\" Among\"[22395] (p=0.037, logit=18.375)', '\" hat\"[9072] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     clean_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.734375, logit=21.375, token_id=22050, metadata=None))), (3816, (57, PredictedToken(token=' Red', prob=9.632110595703125e-05, logit=12.4375, token_id=3816, metadata=None))), (38571, (59, PredictedToken(token=' Theater', prob=9.632110595703125e-05, logit=12.4375, token_id=38571, metadata=None))), (45805, (495, PredictedToken(token=' Cherry', prob=1.7657876014709473e-06, logit=8.4375, token_id=45805, metadata=None)))])\n",
      "2025-09-16 09:43:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     int_prediction=['\" Red\"[3816] (p=0.410, logit=19.875)', '\" Cherry\"[45805] (p=0.249, logit=19.375)', '\" Among\"[22395] (p=0.133, logit=18.750)', '\" The\"[578] (p=0.081, logit=18.250)', '\" Theater\"[38571] (p=0.020, logit=16.875)']\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     int_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.41015625, logit=19.875, token_id=3816, metadata=None))), (45805, (2, PredictedToken(token=' Cherry', prob=0.2490234375, logit=19.375, token_id=45805, metadata=None))), (38571, (5, PredictedToken(token=' Theater', prob=0.0203857421875, logit=16.875, token_id=38571, metadata=None))), (22050, (417, PredictedToken(token=' Hat', prob=4.708766937255859e-06, logit=8.5, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:49 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.816, logit=22.375)', '\" The\"[578] (p=0.067, logit=19.875)', '\" Among\"[22395] (p=0.041, logit=19.375)', '\" A\"[362] (p=0.041, logit=19.375)', '\" slow\"[6435] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.570, logit=20.625)', '\" A\"[362] (p=0.145, logit=19.250)', '\" The\"[578] (p=0.128, logit=19.125)', '\" Among\"[22395] (p=0.087, logit=18.750)', '\" It\"[1102] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.5703125, logit=20.625, token_id=23462, metadata=None))), (469, (11, PredictedToken(token=' E', prob=0.0024871826171875, logit=15.1875, token_id=469, metadata=None))), (41445, (31, PredictedToken(token=' Television', prob=0.00048828125, logit=13.5625, token_id=41445, metadata=None))), (22607, (58, PredictedToken(token=' Cow', prob=0.00016880035400390625, logit=12.5, token_id=22607, metadata=None))), (57551, (82, PredictedToken(token=' Sink', prob=6.198883056640625e-05, logit=11.5, token_id=57551, metadata=None))), (22410, (227, PredictedToken(token=' Ju', prob=8.940696716308594e-06, logit=9.5625, token_id=22410, metadata=None)))])\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     int_prediction=['\" Ju\"[22410] (p=0.467, logit=20.875)', '\" E\"[469] (p=0.221, logit=20.125)', '\" The\"[578] (p=0.118, logit=19.500)', '\" Among\"[22395] (p=0.043, logit=18.500)', '\" An\"[1556] (p=0.043, logit=18.500)']\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     int_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.466796875, logit=20.875, token_id=22410, metadata=None))), (469, (2, PredictedToken(token=' E', prob=0.220703125, logit=20.125, token_id=469, metadata=None))), (22607, (92, PredictedToken(token=' Cow', prob=5.412101745605469e-05, logit=11.8125, token_id=22607, metadata=None))), (57551, (594, PredictedToken(token=' Sink', prob=1.5348196029663086e-06, logit=8.25, token_id=57551, metadata=None))), (41445, (1277, PredictedToken(token=' Television', prob=5.662441253662109e-07, logit=7.25, token_id=41445, metadata=None))), (23462, (3451, PredictedToken(token=' Stadium', prob=1.471489667892456e-07, logit=5.90625, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:49 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:43:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.852, logit=22.375)', '\" The\"[578] (p=0.054, logit=19.625)', '\" A\"[362] (p=0.048, logit=19.500)', '\" Among\"[22395] (p=0.020, logit=18.625)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.645, logit=21.625)', '\" Among\"[22395] (p=0.127, logit=20.000)', '\" The\"[578] (p=0.112, logit=19.875)', '\" A\"[362] (p=0.068, logit=19.375)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.64453125, logit=21.625, token_id=4923, metadata=None))), (469, (17, PredictedToken(token=' E', prob=0.00090789794921875, logit=15.0625, token_id=469, metadata=None))), (33199, (59, PredictedToken(token=' Lion', prob=8.440017700195312e-05, logit=12.6875, token_id=33199, metadata=None))), (816, (88, PredictedToken(token=' Y', prob=3.528594970703125e-05, logit=11.8125, token_id=816, metadata=None))), (1901, (132, PredictedToken(token=' Z', prob=1.3768672943115234e-05, logit=10.875, token_id=1901, metadata=None))), (83499, (163, PredictedToken(token=' Tooth', prob=8.344650268554688e-06, logit=10.375, token_id=83499, metadata=None)))])\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     int_prediction=['\" Lion\"[33199] (p=0.727, logit=21.375)', '\" The\"[578] (p=0.111, logit=19.500)', '\" Among\"[22395] (p=0.087, logit=19.250)', '\" A\"[362] (p=0.015, logit=17.500)', '\" It\"[1102] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     int_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.7265625, logit=21.375, token_id=33199, metadata=None))), (816, (39, PredictedToken(token=' Y', prob=0.000202178955078125, logit=13.1875, token_id=816, metadata=None))), (469, (42, PredictedToken(token=' E', prob=0.00018978118896484375, logit=13.125, token_id=469, metadata=None))), (83499, (85, PredictedToken(token=' Tooth', prob=4.2438507080078125e-05, logit=11.625, token_id=83499, metadata=None))), (1901, (229, PredictedToken(token=' Z', prob=5.7220458984375e-06, logit=9.625, token_id=1901, metadata=None))), (4923, (598, PredictedToken(token=' Sk', prob=1.1995434761047363e-06, logit=8.0625, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:50 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.629, logit=20.500)', '\" The\"[578] (p=0.124, logit=18.875)', '\" A\"[362] (p=0.066, logit=18.250)', '\" Among\"[22395] (p=0.059, logit=18.125)', '\" Food\"[12369] (p=0.035, logit=17.625)']\n",
      "2025-09-16 09:43:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     clean_prediction=['\" Lily\"[48390] (p=0.859, logit=21.625)', '\" The\"[578] (p=0.055, logit=18.875)', '\" Among\"[22395] (p=0.018, logit=17.750)', '\" A\"[362] (p=0.010, logit=17.125)', '\" l\"[326] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     clean_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.859375, logit=21.625, token_id=48390, metadata=None))), (11683, (15, PredictedToken(token=' Acc', prob=0.00113677978515625, logit=15.0, token_id=11683, metadata=None))), (24423, (83, PredictedToken(token=' Monitor', prob=3.4332275390625e-05, logit=11.5, token_id=24423, metadata=None))), (29318, (167, PredictedToken(token=' Dress', prob=8.702278137207031e-06, logit=10.125, token_id=29318, metadata=None))), (74968, (711, PredictedToken(token=' Razor', prob=8.903443813323975e-07, logit=7.84375, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     int_prediction=['\" Monitor\"[24423] (p=0.887, logit=22.125)', '\" Acc\"[11683] (p=0.027, logit=18.625)', '\" The\"[578] (p=0.021, logit=18.375)', '\" Option\"[7104] (p=0.011, logit=17.750)', '\" Among\"[22395] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     int_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.88671875, logit=22.125, token_id=24423, metadata=None))), (11683, (2, PredictedToken(token=' Acc', prob=0.0267333984375, logit=18.625, token_id=11683, metadata=None))), (74968, (63, PredictedToken(token=' Razor', prob=6.246566772460938e-05, logit=12.5625, token_id=74968, metadata=None))), (48390, (1002, PredictedToken(token=' Lily', prob=3.594905138015747e-07, logit=7.40625, token_id=48390, metadata=None))), (29318, (2232, PredictedToken(token=' Dress', prob=1.2014061212539673e-07, logit=6.3125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:51 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:51 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.754, logit=22.625)', '\" The\"[578] (p=0.115, logit=20.750)', '\" A\"[362] (p=0.079, logit=20.375)', '\" Among\"[22395] (p=0.023, logit=19.125)', '\" dress\"[8679] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.801, logit=22.250)', '\" The\"[578] (p=0.084, logit=20.000)', '\" A\"[362] (p=0.045, logit=19.375)', '\" Among\"[22395] (p=0.035, logit=19.125)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.80078125, logit=22.25, token_id=38930, metadata=None))), (37326, (137, PredictedToken(token=' Swe', prob=7.599592208862305e-06, logit=10.6875, token_id=37326, metadata=None))), (90538, (157, PredictedToken(token=' Caul', prob=5.5730342864990234e-06, logit=10.375, token_id=90538, metadata=None)))])\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.598, logit=21.250)', '\" Caul\"[90538] (p=0.219, logit=20.250)', '\" Among\"[22395] (p=0.055, logit=18.875)', '\" The\"[578] (p=0.055, logit=18.875)', '\" None\"[2290] (p=0.023, logit=18.000)']\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.59765625, logit=21.25, token_id=37326, metadata=None))), (90538, (2, PredictedToken(token=' Caul', prob=0.21875, logit=20.25, token_id=90538, metadata=None))), (38930, (316, PredictedToken(token=' Bike', prob=2.8461217880249023e-06, logit=9.0, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:51 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-16 09:43:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     patch_prediction=['\" Camera\"[14669] (p=0.750, logit=21.500)', '\" The\"[578] (p=0.090, logit=19.375)', '\" A\"[362] (p=0.062, logit=19.000)', '\" Among\"[22395] (p=0.042, logit=18.625)', '\" It\"[1102] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.723, logit=21.875)', '\" The\"[578] (p=0.125, logit=20.125)', '\" Among\"[22395] (p=0.067, logit=19.500)', '\" A\"[362] (p=0.052, logit=19.250)', '\" (\"[320] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.72265625, logit=21.875, token_id=42609, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.000843048095703125, logit=15.125, token_id=356, metadata=None))), (432, (87, PredictedToken(token=' R', prob=2.2530555725097656e-05, logit=11.5, token_id=432, metadata=None))), (16147, (90, PredictedToken(token=' Smart', prob=2.110004425048828e-05, logit=11.4375, token_id=16147, metadata=None))), (6771, (114, PredictedToken(token=' Table', prob=1.2814998626708984e-05, logit=10.9375, token_id=6771, metadata=None))), (38930, (321, PredictedToken(token=' Bike', prob=1.9669532775878906e-06, logit=9.0625, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.746, logit=22.000)', '\" The\"[578] (p=0.089, logit=19.875)', '\" R\"[432] (p=0.048, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=19.125)', '\" A\"[362] (p=0.018, logit=18.250)']\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.74609375, logit=22.0, token_id=16147, metadata=None))), (432, (3, PredictedToken(token=' R', prob=0.0478515625, logit=19.25, token_id=432, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0120849609375, logit=17.875, token_id=356, metadata=None))), (6771, (8, PredictedToken(token=' Table', prob=0.00445556640625, logit=16.875, token_id=6771, metadata=None))), (38930, (145, PredictedToken(token=' Bike', prob=9.119510650634766e-06, logit=10.6875, token_id=38930, metadata=None))), (42609, (1406, PredictedToken(token=' Pine', prob=2.0209699869155884e-07, logit=6.875, token_id=42609, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:52 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     patch_prediction=['\" Magn\"[20918] (p=0.789, logit=21.375)', '\" Among\"[22395] (p=0.073, logit=19.000)', '\" The\"[578] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.016, logit=17.500)', '\" Option\"[7104] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:43:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     clean_prediction=['\" Cabinet\"[34046] (p=0.828, logit=21.125)', '\" The\"[578] (p=0.060, logit=18.500)', '\" Among\"[22395] (p=0.028, logit=17.750)', '\" A\"[362] (p=0.015, logit=17.125)', '\" Suit\"[33711] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     clean_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.828125, logit=21.125, token_id=34046, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.007171630859375, logit=16.375, token_id=33711, metadata=None))), (65329, (35, PredictedToken(token=' Elm', prob=0.00040435791015625, logit=13.5, token_id=65329, metadata=None))), (38258, (37, PredictedToken(token=' Baseball', prob=0.0003795623779296875, logit=13.4375, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.316, logit=18.250)', '\" None\"[2290] (p=0.217, logit=17.875)', '\" Among\"[22395] (p=0.132, logit=17.375)', '\" The\"[578] (p=0.062, logit=16.625)', '\" Baseball\"[38258] (p=0.048, logit=16.375)']\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.31640625, logit=18.25, token_id=65329, metadata=None))), (38258, (5, PredictedToken(token=' Baseball', prob=0.04833984375, logit=16.375, token_id=38258, metadata=None))), (34046, (7, PredictedToken(token=' Cabinet', prob=0.01385498046875, logit=15.125, token_id=34046, metadata=None))), (33711, (21, PredictedToken(token=' Suit', prob=0.003509521484375, logit=13.75, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:53 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.887, logit=22.375)', '\" The\"[578] (p=0.057, logit=19.625)', '\" Among\"[22395] (p=0.030, logit=19.000)', '\" It\"[1102] (p=0.003, logit=16.750)', '\" An\"[1556] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     clean_prediction=['\" Eagle\"[36895] (p=0.656, logit=21.875)', '\" An\"[1556] (p=0.166, logit=20.500)', '\" The\"[578] (p=0.101, logit=20.000)', '\" Among\"[22395] (p=0.026, logit=18.625)', '\" Only\"[8442] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     clean_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.65625, logit=21.875, token_id=36895, metadata=None))), (6690, (21, PredictedToken(token=' Air', prob=0.000637054443359375, logit=14.9375, token_id=6690, metadata=None))), (47643, (206, PredictedToken(token=' Cel', prob=4.589557647705078e-06, logit=10.0, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.840, logit=22.125)', '\" The\"[578] (p=0.061, logit=19.500)', '\" Among\"[22395] (p=0.054, logit=19.375)', '\" Option\"[7104] (p=0.005, logit=17.000)', '\" \"[220] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.83984375, logit=22.125, token_id=47643, metadata=None))), (6690, (31, PredictedToken(token=' Air', prob=0.0002498626708984375, logit=14.0, token_id=6690, metadata=None))), (36895, (796, PredictedToken(token=' Eagle', prob=4.6566128730773926e-07, logit=7.71875, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:53 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:43:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.855, logit=22.625)', '\" A\"[362] (p=0.080, logit=20.250)', '\" The\"[578] (p=0.020, logit=18.875)', '\" pin\"[9160] (p=0.018, logit=18.750)', '\" Among\"[22395] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.715, logit=22.375)', '\" The\"[578] (p=0.124, logit=20.625)', '\" A\"[362] (p=0.097, logit=20.375)', '\" Among\"[22395] (p=0.031, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.71484375, logit=22.375, token_id=34785, metadata=None))), (70306, (49, PredictedToken(token=' Brace', prob=8.821487426757812e-05, logit=13.375, token_id=70306, metadata=None))), (21424, (88, PredictedToken(token=' Football', prob=2.09808349609375e-05, logit=11.9375, token_id=21424, metadata=None)))])\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     int_prediction=['\" Brace\"[70306] (p=0.797, logit=22.375)', '\" The\"[578] (p=0.108, logit=20.375)', '\" A\"[362] (p=0.051, logit=19.625)', '\" Football\"[21424] (p=0.015, logit=18.375)', '\" Among\"[22395] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     int_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.796875, logit=22.375, token_id=70306, metadata=None))), (21424, (4, PredictedToken(token=' Football', prob=0.01458740234375, logit=18.375, token_id=21424, metadata=None))), (34785, (160, PredictedToken(token=' Truck', prob=5.900859832763672e-06, logit=10.5625, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:54 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:43:54 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     patch_prediction=['\" Clar\"[31181] (p=0.734, logit=22.000)', '\" The\"[578] (p=0.186, logit=20.625)', '\" A\"[362] (p=0.022, logit=18.500)', '\" Among\"[22395] (p=0.020, logit=18.375)', '\" (\"[320] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:43:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     clean_prediction=['\" Lion\"[33199] (p=0.844, logit=22.375)', '\" The\"[578] (p=0.079, logit=20.000)', '\" A\"[362] (p=0.026, logit=18.875)', '\" Among\"[22395] (p=0.017, logit=18.500)', '\" Option\"[7104] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     clean_track=OrderedDict([(33199, (1, PredictedToken(token=' Lion', prob=0.84375, logit=22.375, token_id=33199, metadata=None))), (5340, (48, PredictedToken(token=' Har', prob=5.221366882324219e-05, logit=12.6875, token_id=5340, metadata=None))), (41445, (86, PredictedToken(token=' Television', prob=1.5974044799804688e-05, logit=11.5, token_id=41445, metadata=None)))])\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.754, logit=22.000)', '\" Television\"[41445] (p=0.080, logit=19.750)', '\" The\"[578] (p=0.080, logit=19.750)', '\" Among\"[22395] (p=0.029, logit=18.750)', '\" (\"[320] (p=0.011, logit=17.750)']\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.75390625, logit=22.0, token_id=5340, metadata=None))), (41445, (3, PredictedToken(token=' Television', prob=0.07958984375, logit=19.75, token_id=41445, metadata=None))), (33199, (142, PredictedToken(token=' Lion', prob=1.1861324310302734e-05, logit=10.9375, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:55 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     patch_prediction=['\" Brace\"[70306] (p=0.637, logit=21.500)', '\" A\"[362] (p=0.142, logit=20.000)', '\" The\"[578] (p=0.125, logit=19.875)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     clean_prediction=['\" Pen\"[13597] (p=0.605, logit=21.000)', '\" The\"[578] (p=0.105, logit=19.250)', '\" A\"[362] (p=0.082, logit=19.000)', '\" Pin\"[17929] (p=0.063, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.625)']\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     clean_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.60546875, logit=21.0, token_id=13597, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.0634765625, logit=18.75, token_id=17929, metadata=None))), (6031, (7, PredictedToken(token=' Bro', prob=0.01104736328125, logit=17.0, token_id=6031, metadata=None))), (328, (64, PredictedToken(token=' S', prob=0.00013065338134765625, logit=12.5625, token_id=328, metadata=None))), (22725, (87, PredictedToken(token=' Orange', prob=8.96453857421875e-05, logit=12.1875, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.684, logit=21.125)', '\" Bro\"[6031] (p=0.119, logit=19.375)', '\" Among\"[22395] (p=0.072, logit=18.875)', '\" The\"[578] (p=0.063, logit=18.750)', '\" It\"[1102] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.68359375, logit=21.125, token_id=328, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.11865234375, logit=19.375, token_id=6031, metadata=None))), (22725, (32, PredictedToken(token=' Orange', prob=0.000514984130859375, logit=13.9375, token_id=22725, metadata=None))), (17929, (91, PredictedToken(token=' Pin', prob=5.125999450683594e-05, logit=11.625, token_id=17929, metadata=None))), (13597, (109, PredictedToken(token=' Pen', prob=3.314018249511719e-05, logit=11.1875, token_id=13597, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:55 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:55 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:43:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     patch_prediction=['\" Charm\"[58600] (p=0.637, logit=20.875)', '\" The\"[578] (p=0.125, logit=19.250)', '\" A\"[362] (p=0.098, logit=19.000)', '\" Among\"[22395] (p=0.059, logit=18.500)', '\" It\"[1102] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     clean_prediction=['\" Amb\"[20423] (p=0.703, logit=22.000)', '\" An\"[1556] (p=0.122, logit=20.250)', '\" Among\"[22395] (p=0.074, logit=19.750)', '\" The\"[578] (p=0.058, logit=19.500)', '\" Option\"[7104] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     clean_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.703125, logit=22.0, token_id=20423, metadata=None))), (84409, (6, PredictedToken(token=' Plum', prob=0.00537109375, logit=17.125, token_id=84409, metadata=None))), (6031, (68, PredictedToken(token=' Bro', prob=4.649162292480469e-05, logit=12.375, token_id=6031, metadata=None))), (445, (75, PredictedToken(token=' L', prob=4.100799560546875e-05, logit=12.25, token_id=445, metadata=None))), (22249, (557, PredictedToken(token=' Ring', prob=7.487833499908447e-07, logit=8.25, token_id=22249, metadata=None)))])\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     int_prediction=['\" Plum\"[84409] (p=0.402, logit=21.000)', '\" Ring\"[22249] (p=0.355, logit=20.875)', '\" Among\"[22395] (p=0.090, logit=19.500)', '\" The\"[578] (p=0.079, logit=19.375)', '\" A\"[362] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     int_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.40234375, logit=21.0, token_id=84409, metadata=None))), (22249, (2, PredictedToken(token=' Ring', prob=0.35546875, logit=20.875, token_id=22249, metadata=None))), (6031, (10, PredictedToken(token=' Bro', prob=0.0030670166015625, logit=16.125, token_id=6031, metadata=None))), (445, (17, PredictedToken(token=' L', prob=0.0012054443359375, logit=15.1875, token_id=445, metadata=None))), (20423, (197, PredictedToken(token=' Amb', prob=7.152557373046875e-06, logit=10.0625, token_id=20423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:56 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:43:56 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     patch_prediction=['\" Spr\"[15883] (p=0.812, logit=21.875)', '\" The\"[578] (p=0.076, logit=19.500)', '\" Among\"[22395] (p=0.052, logit=19.125)', '\" A\"[362] (p=0.012, logit=17.625)', '\" It\"[1102] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:43:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.734, logit=20.750)', '\" The\"[578] (p=0.088, logit=18.625)', '\" Among\"[22395] (p=0.047, logit=18.000)', '\" A\"[362] (p=0.028, logit=17.500)', '\" Option\"[7104] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.734375, logit=20.75, token_id=80629, metadata=None))), (17929, (13, PredictedToken(token=' Pin', prob=0.00408935546875, logit=15.5625, token_id=17929, metadata=None))), (53889, (182, PredictedToken(token=' Apartment', prob=1.5735626220703125e-05, logit=10.0, token_id=53889, metadata=None))), (65449, (189, PredictedToken(token=' Willow', prob=1.4781951904296875e-05, logit=9.9375, token_id=65449, metadata=None)))])\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.695, logit=20.875)', '\" Among\"[22395] (p=0.106, logit=19.000)', '\" The\"[578] (p=0.073, logit=18.625)', '\" Pin\"[17929] (p=0.039, logit=18.000)', '\" Option\"[7104] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.6953125, logit=20.875, token_id=65449, metadata=None))), (17929, (4, PredictedToken(token=' Pin', prob=0.039306640625, logit=18.0, token_id=17929, metadata=None))), (53889, (16, PredictedToken(token=' Apartment', prob=0.001617431640625, logit=14.8125, token_id=53889, metadata=None))), (80629, (81, PredictedToken(token=' Grape', prob=8.058547973632812e-05, logit=11.8125, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:43:57 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.551, logit=20.625)', '\" The\"[578] (p=0.202, logit=19.625)', '\" A\"[362] (p=0.108, logit=19.000)', '\" Among\"[22395] (p=0.058, logit=18.375)', '\" It\"[1102] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.805, logit=22.875)', '\" The\"[578] (p=0.109, logit=20.875)', '\" Among\"[22395] (p=0.045, logit=20.000)', '\" A\"[362] (p=0.021, logit=19.250)', '\" \"[220] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.8046875, logit=22.875, token_id=1901, metadata=None))), (356, (6, PredictedToken(token=' C', prob=0.0025634765625, logit=17.125, token_id=356, metadata=None))), (30616, (185, PredictedToken(token=' Rice', prob=2.637505531311035e-06, logit=10.25, token_id=30616, metadata=None))), (67553, (1416, PredictedToken(token=' Pants', prob=8.242204785346985e-08, logit=6.78125, token_id=67553, metadata=None))), (28131, (3084, PredictedToken(token=' Golf', prob=2.3632310330867767e-08, logit=5.53125, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.471, logit=21.375)', '\" The\"[578] (p=0.252, logit=20.750)', '\" Golf\"[28131] (p=0.105, logit=19.875)', '\" Among\"[22395] (p=0.082, logit=19.625)', '\" A\"[362] (p=0.050, logit=19.125)']\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.470703125, logit=21.375, token_id=356, metadata=None))), (28131, (3, PredictedToken(token=' Golf', prob=0.10498046875, logit=19.875, token_id=28131, metadata=None))), (67553, (65, PredictedToken(token=' Pants', prob=5.125999450683594e-05, logit=12.25, token_id=67553, metadata=None))), (1901, (122, PredictedToken(token=' Z', prob=1.2934207916259766e-05, logit=10.875, token_id=1901, metadata=None))), (30616, (158, PredictedToken(token=' Rice', prob=7.867813110351562e-06, logit=10.375, token_id=30616, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:57 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:57 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:43:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.691, logit=22.250)', '\" An\"[1556] (p=0.154, logit=20.750)', '\" The\"[578] (p=0.064, logit=19.875)', '\" Among\"[22395] (p=0.050, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.871, logit=21.500)', '\" The\"[578] (p=0.034, logit=18.250)', '\" A\"[362] (p=0.034, logit=18.250)', '\" Among\"[22395] (p=0.021, logit=17.750)', '\" R\"[432] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.87109375, logit=21.5, token_id=74968, metadata=None))), (356, (19, PredictedToken(token=' C', prob=0.000659942626953125, logit=14.3125, token_id=356, metadata=None))), (27217, (39, PredictedToken(token=' Train', prob=0.0001888275146484375, logit=13.0625, token_id=27217, metadata=None))), (91263, (57, PredictedToken(token=' Binder', prob=0.0001010894775390625, logit=12.4375, token_id=91263, metadata=None))), (34392, (97, PredictedToken(token=' Horse', prob=3.4809112548828125e-05, logit=11.375, token_id=34392, metadata=None))), (6150, (168, PredictedToken(token=' School', prob=1.2040138244628906e-05, logit=10.3125, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.715, logit=20.750)', '\" Among\"[22395] (p=0.066, logit=18.375)', '\" The\"[578] (p=0.059, logit=18.250)', '\" Binder\"[91263] (p=0.035, logit=17.750)', '\" None\"[2290] (p=0.035, logit=17.750)']\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.71484375, logit=20.75, token_id=27217, metadata=None))), (91263, (5, PredictedToken(token=' Binder', prob=0.035400390625, logit=17.75, token_id=91263, metadata=None))), (6150, (7, PredictedToken(token=' School', prob=0.00897216796875, logit=16.375, token_id=6150, metadata=None))), (34392, (8, PredictedToken(token=' Horse', prob=0.00579833984375, logit=15.9375, token_id=34392, metadata=None))), (356, (30, PredictedToken(token=' C', prob=0.000690460205078125, logit=13.8125, token_id=356, metadata=None))), (74968, (1568, PredictedToken(token=' Razor', prob=5.21540641784668e-07, logit=6.625, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:58 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:58 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:43:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.656, logit=21.375)', '\" The\"[578] (p=0.166, logit=20.000)', '\" Among\"[22395] (p=0.129, logit=19.750)', '\" P\"[393] (p=0.004, logit=16.375)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.688, logit=21.125)', '\" The\"[578] (p=0.093, logit=19.125)', '\" A\"[362] (p=0.093, logit=19.125)', '\" Among\"[22395] (p=0.064, logit=18.750)', '\" F\"[435] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.6875, logit=21.125, token_id=75258, metadata=None))), (423, (24, PredictedToken(token=' D', prob=0.000667572021484375, logit=14.1875, token_id=423, metadata=None))), (3341, (28, PredictedToken(token=' Car', prob=0.00058746337890625, logit=14.0625, token_id=3341, metadata=None))), (33711, (59, PredictedToken(token=' Suit', prob=0.00014019012451171875, logit=12.625, token_id=33711, metadata=None))), (34392, (79, PredictedToken(token=' Horse', prob=6.198883056640625e-05, logit=11.8125, token_id=34392, metadata=None))), (47759, (573, PredictedToken(token=' Guitar', prob=1.6540288925170898e-06, logit=8.1875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.695, logit=21.375)', '\" The\"[578] (p=0.083, logit=19.250)', '\" Suit\"[33711] (p=0.064, logit=19.000)', '\" Among\"[22395] (p=0.064, logit=19.000)', '\" A\"[362] (p=0.024, logit=18.000)']\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.6953125, logit=21.375, token_id=34392, metadata=None))), (33711, (4, PredictedToken(token=' Suit', prob=0.064453125, logit=19.0, token_id=33711, metadata=None))), (3341, (21, PredictedToken(token=' Car', prob=0.000919342041015625, logit=14.75, token_id=3341, metadata=None))), (423, (22, PredictedToken(token=' D', prob=0.000812530517578125, logit=14.625, token_id=423, metadata=None))), (47759, (257, PredictedToken(token=' Guitar', prob=4.5299530029296875e-06, logit=9.4375, token_id=47759, metadata=None))), (75258, (1198, PredictedToken(token=' Refriger', prob=4.4889748096466064e-07, logit=7.125, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:43:59 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:43:59 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:43:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     patch_prediction=['\" Tul\"[43316] (p=0.836, logit=21.000)', '\" The\"[578] (p=0.053, logit=18.250)', '\" Among\"[22395] (p=0.042, logit=18.000)', '\" A\"[362] (p=0.013, logit=16.875)', '\" Grape\"[80629] (p=0.007, logit=16.250)']\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     clean_prediction=['\" Coat\"[68867] (p=0.734, logit=21.875)', '\" The\"[578] (p=0.100, logit=19.875)', '\" A\"[362] (p=0.078, logit=19.625)', '\" Among\"[22395] (p=0.053, logit=19.250)', '\" CO\"[7432] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     clean_track=OrderedDict([(68867, (1, PredictedToken(token=' Coat', prob=0.734375, logit=21.875, token_id=68867, metadata=None))), (1443, (33, PredictedToken(token=' Sh', prob=0.0002040863037109375, logit=13.6875, token_id=1443, metadata=None))), (65197, (46, PredictedToken(token=' Surf', prob=0.00010919570922851562, logit=13.0625, token_id=65197, metadata=None))), (16344, (88, PredictedToken(token=' Rose', prob=3.337860107421875e-05, logit=11.875, token_id=16344, metadata=None))), (44570, (151, PredictedToken(token=' Maple', prob=1.0848045349121094e-05, logit=10.75, token_id=44570, metadata=None))), (14642, (356, PredictedToken(token=' Phone', prob=1.7657876014709473e-06, logit=8.9375, token_id=14642, metadata=None)))])\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.715, logit=21.250)', '\" Among\"[22395] (p=0.124, logit=19.500)', '\" The\"[578] (p=0.075, logit=19.000)', '\" Maple\"[44570] (p=0.024, logit=17.875)', '\" It\"[1102] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.71484375, logit=21.25, token_id=16344, metadata=None))), (44570, (4, PredictedToken(token=' Maple', prob=0.0244140625, logit=17.875, token_id=44570, metadata=None))), (1443, (7, PredictedToken(token=' Sh', prob=0.004241943359375, logit=16.125, token_id=1443, metadata=None))), (65197, (20, PredictedToken(token=' Surf', prob=0.000888824462890625, logit=14.5625, token_id=65197, metadata=None))), (14642, (793, PredictedToken(token=' Phone', prob=8.381903171539307e-07, logit=7.59375, token_id=14642, metadata=None))), (68867, (2733, PredictedToken(token=' Coat', prob=1.5459954738616943e-07, logit=5.90625, token_id=68867, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:00 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.594, logit=20.625)', '\" Monitor\"[24423] (p=0.248, logit=19.750)', '\" The\"[578] (p=0.043, logit=18.000)', '\" A\"[362] (p=0.023, logit=17.375)', '\" Among\"[22395] (p=0.020, logit=17.250)']\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     clean_prediction=['\" Mouse\"[18191] (p=0.836, logit=21.250)', '\" None\"[2290] (p=0.032, logit=18.000)', '\" The\"[578] (p=0.029, logit=17.875)', '\" A\"[362] (p=0.029, logit=17.875)', '\" Only\"[8442] (p=0.014, logit=17.125)']\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     clean_track=OrderedDict([(18191, (1, PredictedToken(token=' Mouse', prob=0.8359375, logit=21.25, token_id=18191, metadata=None))), (69755, (14, PredictedToken(token=' Notebook', prob=0.0018310546875, logit=15.125, token_id=69755, metadata=None))), (28131, (137, PredictedToken(token=' Golf', prob=1.9073486328125e-05, logit=10.5625, token_id=28131, metadata=None))), (22725, (253, PredictedToken(token=' Orange', prob=6.198883056640625e-06, logit=9.4375, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:44:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     int_prediction=['\" Notebook\"[69755] (p=0.594, logit=20.250)', '\" None\"[2290] (p=0.279, logit=19.500)', '\" Orange\"[22725] (p=0.016, logit=16.625)', '\" The\"[578] (p=0.016, logit=16.625)', '\" A\"[362] (p=0.012, logit=16.375)']\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     int_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.59375, logit=20.25, token_id=69755, metadata=None))), (22725, (4, PredictedToken(token=' Orange', prob=0.015869140625, logit=16.625, token_id=22725, metadata=None))), (18191, (9, PredictedToken(token=' Mouse', prob=0.004241943359375, logit=15.3125, token_id=18191, metadata=None))), (28131, (11, PredictedToken(token=' Golf', prob=0.004241943359375, logit=15.3125, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:01 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.594, logit=20.875)', '\" The\"[578] (p=0.133, logit=19.375)', '\" A\"[362] (p=0.133, logit=19.375)', '\" Among\"[22395] (p=0.071, logit=18.750)', '\" Option\"[7104] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.734, logit=21.750)', '\" The\"[578] (p=0.088, logit=19.625)', '\" Among\"[22395] (p=0.060, logit=19.250)', '\" A\"[362] (p=0.060, logit=19.250)', '\" slow\"[6435] (p=0.017, logit=18.000)']\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.734375, logit=21.75, token_id=39247, metadata=None))), (52882, (9, PredictedToken(token=' Pepper', prob=0.002655029296875, logit=16.125, token_id=52882, metadata=None))), (3061, (12, PredictedToken(token=' Fl', prob=0.0014190673828125, logit=15.5, token_id=3061, metadata=None))), (52466, (142, PredictedToken(token=' Warehouse', prob=1.0192394256591797e-05, logit=10.5625, token_id=52466, metadata=None))), (28131, (379, PredictedToken(token=' Golf', prob=1.6614794731140137e-06, logit=8.75, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     int_prediction=['\" Warehouse\"[52466] (p=0.805, logit=22.000)', '\" Among\"[22395] (p=0.066, logit=19.500)', '\" The\"[578] (p=0.066, logit=19.500)', '\" A\"[362] (p=0.011, logit=17.750)', '\" Option\"[7104] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     int_track=OrderedDict([(52466, (1, PredictedToken(token=' Warehouse', prob=0.8046875, logit=22.0, token_id=52466, metadata=None))), (3061, (14, PredictedToken(token=' Fl', prob=0.00154876708984375, logit=15.75, token_id=3061, metadata=None))), (28131, (304, PredictedToken(token=' Golf', prob=2.339482307434082e-06, logit=9.25, token_id=28131, metadata=None))), (52882, (814, PredictedToken(token=' Pepper', prob=5.550682544708252e-07, logit=7.8125, token_id=52882, metadata=None))), (39247, (1396, PredictedToken(token=' Slow', prob=2.6263296604156494e-07, logit=7.0625, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:01 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:01 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:44:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     patch_prediction=['\" Camera\"[14669] (p=0.570, logit=20.375)', '\" Refriger\"[75258] (p=0.099, logit=18.625)', '\" Among\"[22395] (p=0.099, logit=18.625)', '\" The\"[578] (p=0.077, logit=18.375)', '\" A\"[362] (p=0.028, logit=17.375)']\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     clean_prediction=['\" Rice\"[30616] (p=0.734, logit=21.625)', '\" The\"[578] (p=0.087, logit=19.500)', '\" A\"[362] (p=0.087, logit=19.500)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     clean_track=OrderedDict([(30616, (1, PredictedToken(token=' Rice', prob=0.734375, logit=21.625, token_id=30616, metadata=None))), (426, (28, PredictedToken(token=' B', prob=0.0003566741943359375, logit=14.0, token_id=426, metadata=None))), (90538, (53, PredictedToken(token=' Caul', prob=9.059906005859375e-05, logit=12.625, token_id=90538, metadata=None))), (58403, (425, PredictedToken(token=' Tablet', prob=1.3709068298339844e-06, logit=8.4375, token_id=58403, metadata=None))), (52466, (638, PredictedToken(token=' Warehouse', prob=7.599592208862305e-07, logit=7.84375, token_id=52466, metadata=None))), (16478, (1735, PredictedToken(token=' Chair', prob=1.9744038581848145e-07, logit=6.5, token_id=16478, metadata=None)))])\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     int_prediction=['\" Tablet\"[58403] (p=0.609, logit=20.750)', '\" The\"[578] (p=0.154, logit=19.375)', '\" A\"[362] (p=0.064, logit=18.500)', '\" Among\"[22395] (p=0.057, logit=18.375)', '\" Option\"[7104] (p=0.021, logit=17.375)']\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     int_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.609375, logit=20.75, token_id=58403, metadata=None))), (426, (6, PredictedToken(token=' B', prob=0.00872802734375, logit=16.5, token_id=426, metadata=None))), (16478, (50, PredictedToken(token=' Chair', prob=0.0002460479736328125, logit=12.9375, token_id=16478, metadata=None))), (30616, (72, PredictedToken(token=' Rice', prob=0.0001239776611328125, logit=12.25, token_id=30616, metadata=None))), (90538, (81, PredictedToken(token=' Caul', prob=8.535385131835938e-05, logit=11.875, token_id=90538, metadata=None))), (52466, (99, PredictedToken(token=' Warehouse', prob=4.863739013671875e-05, logit=11.3125, token_id=52466, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:02 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:02 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.754, logit=21.625)', '\" The\"[578] (p=0.102, logit=19.625)', '\" A\"[362] (p=0.080, logit=19.375)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:44:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.805, logit=22.250)', '\" The\"[578] (p=0.058, logit=19.625)', '\" A\"[362] (p=0.051, logit=19.500)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" cow\"[19923] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.8046875, logit=22.25, token_id=22607, metadata=None))), (3341, (36, PredictedToken(token=' Car', prob=0.000209808349609375, logit=14.0, token_id=3341, metadata=None))), (78703, (207, PredictedToken(token=' Potato', prob=3.382563591003418e-06, logit=9.875, token_id=78703, metadata=None))), (38673, (352, PredictedToken(token=' Yoga', prob=1.4156103134155273e-06, logit=9.0, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     int_prediction=['\" Yoga\"[38673] (p=0.508, logit=20.500)', '\" The\"[578] (p=0.146, logit=19.250)', '\" Among\"[22395] (p=0.100, logit=18.875)', '\" A\"[362] (p=0.069, logit=18.500)', '\" Car\"[3341] (p=0.047, logit=18.125)']\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     int_track=OrderedDict([(38673, (1, PredictedToken(token=' Yoga', prob=0.5078125, logit=20.5, token_id=38673, metadata=None))), (3341, (5, PredictedToken(token=' Car', prob=0.04736328125, logit=18.125, token_id=3341, metadata=None))), (78703, (69, PredictedToken(token=' Potato', prob=0.00016021728515625, logit=12.4375, token_id=78703, metadata=None))), (22607, (121, PredictedToken(token=' Cow', prob=4.0531158447265625e-05, logit=11.0625, token_id=22607, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:03 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:03 src.selection.optimization DEBUG    torch.Size([6, 27])\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     patch_prediction=['\" Bus\"[19111] (p=0.680, logit=21.625)', '\" The\"[578] (p=0.134, logit=20.000)', '\" Among\"[22395] (p=0.072, logit=19.375)', '\" A\"[362] (p=0.056, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     clean_prediction=['\" Bed\"[13394] (p=0.805, logit=22.500)', '\" The\"[578] (p=0.085, logit=20.250)', '\" A\"[362] (p=0.045, logit=19.625)', '\" Among\"[22395] (p=0.028, logit=19.125)', '\" BED\"[83364] (p=0.007, logit=17.750)']\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     clean_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.8046875, logit=22.5, token_id=13394, metadata=None))), (469, (39, PredictedToken(token=' E', prob=0.00013637542724609375, logit=13.8125, token_id=469, metadata=None))), (6031, (48, PredictedToken(token=' Bro', prob=7.772445678710938e-05, logit=13.25, token_id=6031, metadata=None))), (13597, (66, PredictedToken(token=' Pen', prob=4.410743713378906e-05, logit=12.6875, token_id=13597, metadata=None))), (47589, (156, PredictedToken(token=' Basketball', prob=5.602836608886719e-06, logit=10.625, token_id=47589, metadata=None))), (70762, (362, PredictedToken(token=' Motorcycle', prob=1.2516975402832031e-06, logit=9.125, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.926, logit=23.000)', '\" The\"[578] (p=0.022, logit=19.250)', '\" Among\"[22395] (p=0.019, logit=19.125)', '\" Basketball\"[47589] (p=0.015, logit=18.875)', '\" A\"[362] (p=0.003, logit=17.375)']\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.92578125, logit=23.0, token_id=70762, metadata=None))), (47589, (4, PredictedToken(token=' Basketball', prob=0.01495361328125, logit=18.875, token_id=47589, metadata=None))), (469, (62, PredictedToken(token=' E', prob=2.5510787963867188e-05, logit=12.5, token_id=469, metadata=None))), (6031, (104, PredictedToken(token=' Bro', prob=8.821487426757812e-06, logit=11.4375, token_id=6031, metadata=None))), (13597, (141, PredictedToken(token=' Pen', prob=4.708766937255859e-06, logit=10.8125, token_id=13597, metadata=None))), (13394, (403, PredictedToken(token=' Bed', prob=5.997717380523682e-07, logit=8.75, token_id=13394, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:03 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:03 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:44:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.715, logit=22.125)', '\" The\"[578] (p=0.141, logit=20.500)', '\" A\"[362] (p=0.052, logit=19.500)', '\" Among\"[22395] (p=0.046, logit=19.375)', '\" dress\"[8679] (p=0.012, logit=18.000)']\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     clean_prediction=['\" Tul\"[43316] (p=0.770, logit=21.250)', '\" The\"[578] (p=0.104, logit=19.250)', '\" A\"[362] (p=0.038, logit=18.250)', '\" Among\"[22395] (p=0.034, logit=18.125)', '\" Option\"[7104] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     clean_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.76953125, logit=21.25, token_id=43316, metadata=None))), (816, (50, PredictedToken(token=' Y', prob=8.916854858398438e-05, logit=12.1875, token_id=816, metadata=None))), (19176, (203, PredictedToken(token=' Temple', prob=6.884336471557617e-06, logit=9.625, token_id=19176, metadata=None))), (67553, (2325, PredictedToken(token=' Pants', prob=1.955777406692505e-07, logit=6.0625, token_id=67553, metadata=None)))])\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.555, logit=20.000)', '\" Among\"[22395] (p=0.159, logit=18.750)', '\" The\"[578] (p=0.141, logit=18.625)', '\" Option\"[7104] (p=0.028, logit=17.000)', '\" Pant\"[54222] (p=0.010, logit=15.938)']\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.5546875, logit=20.0, token_id=67553, metadata=None))), (816, (20, PredictedToken(token=' Y', prob=0.00213623046875, logit=14.4375, token_id=816, metadata=None))), (43316, (35, PredictedToken(token=' Tul', prob=0.000652313232421875, logit=13.25, token_id=43316, metadata=None))), (19176, (249, PredictedToken(token=' Temple', prob=1.1920928955078125e-05, logit=9.25, token_id=19176, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:04 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.871, logit=21.500)', '\" The\"[578] (p=0.043, logit=18.500)', '\" Among\"[22395] (p=0.030, logit=18.125)', '\" A\"[362] (p=0.016, logit=17.500)', '\" It\"[1102] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:44:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     clean_prediction=['\" School\"[6150] (p=0.578, logit=20.625)', '\" None\"[2290] (p=0.309, logit=20.000)', '\" There\"[2684] (p=0.025, logit=17.500)', '\" The\"[578] (p=0.017, logit=17.125)', '\" Among\"[22395] (p=0.011, logit=16.625)']\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     clean_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.578125, logit=20.625, token_id=6150, metadata=None))), (18787, (7, PredictedToken(token=' Oak', prob=0.00726318359375, logit=16.25, token_id=18787, metadata=None))), (61948, (8, PredictedToken(token=' Sofa', prob=0.0028533935546875, logit=15.3125, token_id=61948, metadata=None))), (70306, (17, PredictedToken(token=' Brace', prob=0.0011138916015625, logit=14.375, token_id=70306, metadata=None))), (328, (30, PredictedToken(token=' S', prob=0.000385284423828125, logit=13.3125, token_id=328, metadata=None))), (43950, (173, PredictedToken(token=' Lav', prob=1.4960765838623047e-05, logit=10.0625, token_id=43950, metadata=None)))])\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.660, logit=20.375)', '\" Sofa\"[61948] (p=0.130, logit=18.750)', '\" Brace\"[70306] (p=0.033, logit=17.375)', '\" School\"[6150] (p=0.033, logit=17.375)', '\" There\"[2684] (p=0.033, logit=17.375)']\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     int_track=OrderedDict([(61948, (2, PredictedToken(token=' Sofa', prob=0.1298828125, logit=18.75, token_id=61948, metadata=None))), (70306, (5, PredictedToken(token=' Brace', prob=0.032958984375, logit=17.375, token_id=70306, metadata=None))), (6150, (4, PredictedToken(token=' School', prob=0.032958984375, logit=17.375, token_id=6150, metadata=None))), (328, (9, PredictedToken(token=' S', prob=0.0078125, logit=15.9375, token_id=328, metadata=None))), (18787, (351, PredictedToken(token=' Oak', prob=6.67572021484375e-06, logit=8.875, token_id=18787, metadata=None))), (43950, (709, PredictedToken(token=' Lav', prob=2.3096799850463867e-06, logit=7.8125, token_id=43950, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:05 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:05 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     patch_prediction=['\" Violet\"[74574] (p=0.945, logit=22.125)', '\" The\"[578] (p=0.017, logit=18.125)', '\" Church\"[9441] (p=0.008, logit=17.375)', '\" violet\"[80836] (p=0.006, logit=17.000)', '\" Among\"[22395] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.797, logit=22.375)', '\" A\"[362] (p=0.095, logit=20.250)', '\" The\"[578] (p=0.058, logit=19.750)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" Only\"[8442] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.796875, logit=22.375, token_id=16730, metadata=None))), (11452, (27, PredictedToken(token=' Head', prob=0.00018310546875, logit=14.0, token_id=11452, metadata=None))), (32749, (148, PredictedToken(token=' Carn', prob=5.543231964111328e-06, logit=10.5, token_id=32749, metadata=None)))])\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     int_prediction=['\" Carn\"[32749] (p=0.930, logit=23.125)', '\" The\"[578] (p=0.025, logit=19.500)', '\" A\"[362] (p=0.022, logit=19.375)', '\" Among\"[22395] (p=0.007, logit=18.250)', '\" None\"[2290] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     int_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.9296875, logit=23.125, token_id=32749, metadata=None))), (11452, (17, PredictedToken(token=' Head', prob=0.00024318695068359375, logit=14.875, token_id=11452, metadata=None))), (16730, (848, PredictedToken(token=' Museum', prob=1.8347054719924927e-07, logit=7.6875, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:05 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:05 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:44:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.730, logit=22.375)', '\" The\"[578] (p=0.163, logit=20.875)', '\" A\"[362] (p=0.036, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=19.250)', '\" It\"[1102] (p=0.007, logit=17.750)']\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     clean_prediction=['\" Apple\"[8325] (p=0.809, logit=22.375)', '\" The\"[578] (p=0.085, logit=20.125)', '\" Among\"[22395] (p=0.040, logit=19.375)', '\" An\"[1556] (p=0.035, logit=19.250)', '\" (\"[320] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     clean_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.80859375, logit=22.375, token_id=8325, metadata=None))), (94467, (83, PredictedToken(token=' Trom', prob=2.682209014892578e-05, logit=12.0625, token_id=94467, metadata=None))), (55807, (171, PredictedToken(token=' Shirt', prob=5.27501106262207e-06, logit=10.4375, token_id=55807, metadata=None))), (47589, (219, PredictedToken(token=' Basketball', prob=3.203749656677246e-06, logit=9.9375, token_id=47589, metadata=None))), (30173, (398, PredictedToken(token=' Speaker', prob=1.043081283569336e-06, logit=8.8125, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     int_prediction=['\" Trom\"[94467] (p=0.688, logit=20.875)', '\" The\"[578] (p=0.135, logit=19.250)', '\" Among\"[22395] (p=0.093, logit=18.875)', '\" None\"[2290] (p=0.013, logit=16.875)', '\" A\"[362] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     int_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.6875, logit=20.875, token_id=94467, metadata=None))), (30173, (8, PredictedToken(token=' Speaker', prob=0.005950927734375, logit=16.125, token_id=30173, metadata=None))), (47589, (31, PredictedToken(token=' Basketball', prob=0.0003147125244140625, logit=13.1875, token_id=47589, metadata=None))), (55807, (51, PredictedToken(token=' Shirt', prob=0.0001583099365234375, logit=12.5, token_id=55807, metadata=None))), (8325, (233, PredictedToken(token=' Apple', prob=8.404254913330078e-06, logit=9.5625, token_id=8325, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:06 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.629, logit=20.875)', '\" The\"[578] (p=0.181, logit=19.625)', '\" Among\"[22395] (p=0.085, logit=18.875)', '\" shorts\"[36876] (p=0.009, logit=16.625)', '\" Option\"[7104] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:44:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.875, logit=22.500)', '\" The\"[578] (p=0.063, logit=19.875)', '\" Among\"[22395] (p=0.034, logit=19.250)', '\" It\"[1102] (p=0.004, logit=17.125)', '\" A\"[362] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.875, logit=22.5, token_id=6031, metadata=None))), (328, (49, PredictedToken(token=' S', prob=4.792213439941406e-05, logit=12.6875, token_id=328, metadata=None))), (31181, (67, PredictedToken(token=' Clar', prob=3.0994415283203125e-05, logit=12.25, token_id=31181, metadata=None))), (18191, (231, PredictedToken(token=' Mouse', prob=2.5331974029541016e-06, logit=9.75, token_id=18191, metadata=None)))])\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.793, logit=21.875)', '\" The\"[578] (p=0.083, logit=19.625)', '\" Among\"[22395] (p=0.057, logit=19.250)', '\" Mouse\"[18191] (p=0.019, logit=18.125)', '\" A\"[362] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.79296875, logit=21.875, token_id=328, metadata=None))), (18191, (4, PredictedToken(token=' Mouse', prob=0.0186767578125, logit=18.125, token_id=18191, metadata=None))), (31181, (18, PredictedToken(token=' Clar', prob=0.00049591064453125, logit=14.5, token_id=31181, metadata=None))), (6031, (50, PredictedToken(token=' Bro', prob=9.202957153320312e-05, logit=12.8125, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:07 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:07 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.699, logit=20.875)', '\" The\"[578] (p=0.107, logit=19.000)', '\" headphones\"[44101] (p=0.051, logit=18.250)', '\" Among\"[22395] (p=0.045, logit=18.125)', '\" (\"[320] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.734, logit=22.125)', '\" The\"[578] (p=0.128, logit=20.375)', '\" Among\"[22395] (p=0.047, logit=19.375)', '\" A\"[362] (p=0.042, logit=19.250)', '\" dress\"[8679] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.734375, logit=22.125, token_id=29318, metadata=None))), (84409, (7, PredictedToken(token=' Plum', prob=0.0038604736328125, logit=16.875, token_id=84409, metadata=None))), (14642, (113, PredictedToken(token=' Phone', prob=1.3053417205810547e-05, logit=11.1875, token_id=14642, metadata=None))), (3420, (152, PredictedToken(token=' Trump', prob=6.16908073425293e-06, logit=10.4375, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     int_prediction=['\" Trump\"[3420] (p=0.699, logit=21.875)', '\" Phone\"[14642] (p=0.122, logit=20.125)', '\" The\"[578] (p=0.074, logit=19.625)', '\" Among\"[22395] (p=0.045, logit=19.125)', '\" Plum\"[84409] (p=0.013, logit=17.875)']\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     int_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.69921875, logit=21.875, token_id=3420, metadata=None))), (14642, (2, PredictedToken(token=' Phone', prob=0.12158203125, logit=20.125, token_id=14642, metadata=None))), (84409, (5, PredictedToken(token=' Plum', prob=0.0128173828125, logit=17.875, token_id=84409, metadata=None))), (29318, (383, PredictedToken(token=' Dress', prob=1.5795230865478516e-06, logit=8.875, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:07 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:07 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:44:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     patch_prediction=['\" To\"[2057] (p=0.703, logit=21.875)', '\" The\"[578] (p=0.123, logit=20.125)', '\" A\"[362] (p=0.095, logit=19.875)', '\" Among\"[22395] (p=0.040, logit=19.000)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     clean_prediction=['\" Gloves\"[68554] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.077, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" Glo\"[25372] (p=0.008, logit=17.125)', '\" A\"[362] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     clean_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.83203125, logit=21.75, token_id=68554, metadata=None))), (16183, (13, PredictedToken(token=' Hel', prob=0.00141143798828125, logit=15.375, token_id=16183, metadata=None))), (29318, (39, PredictedToken(token=' Dress', prob=0.00019168853759765625, logit=13.375, token_id=29318, metadata=None))), (16344, (47, PredictedToken(token=' Rose', prob=0.00014019012451171875, logit=13.0625, token_id=16344, metadata=None))), (87213, (238, PredictedToken(token=' Oven', prob=4.500150680541992e-06, logit=9.625, token_id=87213, metadata=None)))])\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.555, logit=20.625)', '\" Among\"[22395] (p=0.141, logit=19.250)', '\" Dress\"[29318] (p=0.096, logit=18.875)', '\" The\"[578] (p=0.096, logit=18.875)', '\" None\"[2290] (p=0.019, logit=17.250)']\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.5546875, logit=20.625, token_id=87213, metadata=None))), (29318, (4, PredictedToken(token=' Dress', prob=0.09619140625, logit=18.875, token_id=29318, metadata=None))), (16344, (16, PredictedToken(token=' Rose', prob=0.0032958984375, logit=15.5, token_id=16344, metadata=None))), (16183, (193, PredictedToken(token=' Hel', prob=1.3470649719238281e-05, logit=10.0, token_id=16183, metadata=None))), (68554, (503, PredictedToken(token=' Gloves', prob=2.816319465637207e-06, logit=8.4375, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:08 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:44:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.793, logit=21.750)', '\" The\"[578] (p=0.074, logit=19.375)', '\" Among\"[22395] (p=0.057, logit=19.125)', '\" A\"[362] (p=0.027, logit=18.375)', '\" (\"[320] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.773, logit=22.000)', '\" The\"[578] (p=0.105, logit=20.000)', '\" Among\"[22395] (p=0.039, logit=19.000)', '\" A\"[362] (p=0.026, logit=18.625)', '\" Option\"[7104] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.7734375, logit=22.0, token_id=31181, metadata=None))), (469, (10, PredictedToken(token=' E', prob=0.002471923828125, logit=16.25, token_id=469, metadata=None))), (20423, (29, PredictedToken(token=' Amb', prob=0.0004558563232421875, logit=14.5625, token_id=20423, metadata=None))), (9441, (677, PredictedToken(token=' Church', prob=5.178153514862061e-07, logit=7.78125, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.844, logit=22.000)', '\" Among\"[22395] (p=0.054, logit=19.250)', '\" The\"[578] (p=0.048, logit=19.125)', '\" Option\"[7104] (p=0.017, logit=18.125)', '\" (\"[320] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.84375, logit=22.0, token_id=469, metadata=None))), (20423, (52, PredictedToken(token=' Amb', prob=5.936622619628906e-05, logit=12.4375, token_id=20423, metadata=None))), (9441, (83, PredictedToken(token=' Church', prob=2.0503997802734375e-05, logit=11.375, token_id=9441, metadata=None))), (31181, (336, PredictedToken(token=' Clar', prob=1.2293457984924316e-06, logit=8.5625, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:09 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:09 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     patch_prediction=['\" Carn\"[32749] (p=0.863, logit=22.500)', '\" The\"[578] (p=0.055, logit=19.750)', '\" A\"[362] (p=0.043, logit=19.500)', '\" Among\"[22395] (p=0.016, logit=18.500)', '\" (\"[320] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     clean_prediction=['\" Basketball\"[47589] (p=0.910, logit=22.250)', '\" The\"[578] (p=0.031, logit=18.875)', '\" Among\"[22395] (p=0.009, logit=17.625)', '\" Sc\"[2522] (p=0.009, logit=17.625)', '\" Basket\"[34217] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     clean_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.91015625, logit=22.25, token_id=47589, metadata=None))), (2522, (3, PredictedToken(token=' Sc', prob=0.0089111328125, logit=17.625, token_id=2522, metadata=None))), (3341, (53, PredictedToken(token=' Car', prob=6.389617919921875e-05, logit=12.6875, token_id=3341, metadata=None))), (74574, (207, PredictedToken(token=' Violet', prob=3.844499588012695e-06, logit=9.875, token_id=74574, metadata=None)))])\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.855, logit=21.625)', '\" The\"[578] (p=0.038, logit=18.500)', '\" Among\"[22395] (p=0.026, logit=18.125)', '\" Car\"[3341] (p=0.026, logit=18.125)', '\" Option\"[7104] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.85546875, logit=21.625, token_id=74574, metadata=None))), (3341, (3, PredictedToken(token=' Car', prob=0.02587890625, logit=18.125, token_id=3341, metadata=None))), (47589, (41, PredictedToken(token=' Basketball', prob=0.0001850128173828125, logit=13.1875, token_id=47589, metadata=None))), (2522, (55, PredictedToken(token=' Sc', prob=0.00010585784912109375, logit=12.625, token_id=2522, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:09 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:09 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:44:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.824, logit=21.625)', '\" A\"[362] (p=0.060, logit=19.000)', '\" The\"[578] (p=0.046, logit=18.750)', '\" Among\"[22395] (p=0.015, logit=17.625)', '\" Only\"[8442] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.859, logit=22.250)', '\" b\"[293] (p=0.062, logit=19.625)', '\" The\"[578] (p=0.023, logit=18.625)', '\" A\"[362] (p=0.016, logit=18.250)', '\" (\"[320] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.859375, logit=22.25, token_id=426, metadata=None))), (88088, (16, PredictedToken(token=' Birch', prob=0.000507354736328125, logit=14.8125, token_id=88088, metadata=None))), (36943, (47, PredictedToken(token=' Folder', prob=6.866455078125e-05, logit=12.8125, token_id=36943, metadata=None)))])\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.887, logit=21.250)', '\" The\"[578] (p=0.027, logit=17.750)', '\" (\"[320] (p=0.013, logit=17.000)', '\" folder\"[8695] (p=0.011, logit=16.875)', '\" Among\"[22395] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.88671875, logit=21.25, token_id=36943, metadata=None))), (88088, (7, PredictedToken(token=' Birch', prob=0.0059814453125, logit=16.25, token_id=88088, metadata=None))), (426, (26, PredictedToken(token=' B', prob=0.000591278076171875, logit=13.9375, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:10 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     patch_prediction=['\" Museum\"[16730] (p=0.840, logit=22.625)', '\" A\"[362] (p=0.078, logit=20.250)', '\" The\"[578] (p=0.042, logit=19.625)', '\" Among\"[22395] (p=0.017, logit=18.750)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:44:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     clean_prediction=['\" Acc\"[11683] (p=0.867, logit=22.750)', '\" The\"[578] (p=0.071, logit=20.250)', '\" An\"[1556] (p=0.020, logit=19.000)', '\" Among\"[22395] (p=0.011, logit=18.375)', '\" Accord\"[80657] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     clean_track=OrderedDict([(11683, (1, PredictedToken(token=' Acc', prob=0.8671875, logit=22.75, token_id=11683, metadata=None))), (6150, (138, PredictedToken(token=' School', prob=6.854534149169922e-06, logit=11.0, token_id=6150, metadata=None))), (74968, (142, PredictedToken(token=' Razor', prob=6.4373016357421875e-06, logit=10.9375, token_id=74968, metadata=None)))])\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     int_prediction=['\" School\"[6150] (p=0.867, logit=21.875)', '\" Razor\"[74968] (p=0.043, logit=18.875)', '\" The\"[578] (p=0.026, logit=18.375)', '\" Among\"[22395] (p=0.016, logit=17.875)', '\" school\"[2978] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     int_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.8671875, logit=21.875, token_id=6150, metadata=None))), (74968, (2, PredictedToken(token=' Razor', prob=0.043212890625, logit=18.875, token_id=74968, metadata=None))), (11683, (298, PredictedToken(token=' Acc', prob=2.86102294921875e-06, logit=9.25, token_id=11683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:11 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:11 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.852, logit=21.250)', '\" None\"[2290] (p=0.062, logit=18.625)', '\" The\"[578] (p=0.018, logit=17.375)', '\" Gloves\"[68554] (p=0.008, logit=16.625)', '\" Among\"[22395] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.898, logit=22.625)', '\" The\"[578] (p=0.040, logit=19.500)', '\" Among\"[22395] (p=0.021, logit=18.875)', '\" A\"[362] (p=0.013, logit=18.375)', '\" spr\"[8314] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.8984375, logit=22.625, token_id=15883, metadata=None))), (45332, (202, PredictedToken(token=' Boat', prob=2.950429916381836e-06, logit=10.0, token_id=45332, metadata=None))), (78703, (236, PredictedToken(token=' Potato', prob=2.16066837310791e-06, logit=9.6875, token_id=78703, metadata=None)))])\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     int_prediction=['\" Potato\"[78703] (p=0.824, logit=22.000)', '\" The\"[578] (p=0.046, logit=19.125)', '\" Boat\"[45332] (p=0.041, logit=19.000)', '\" Among\"[22395] (p=0.036, logit=18.875)', '\" A\"[362] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     int_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.82421875, logit=22.0, token_id=78703, metadata=None))), (45332, (3, PredictedToken(token=' Boat', prob=0.041015625, logit=19.0, token_id=45332, metadata=None))), (15883, (10, PredictedToken(token=' Spr', prob=0.001922607421875, logit=15.9375, token_id=15883, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:11 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:11 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.664, logit=22.125)', '\" The\"[578] (p=0.168, logit=20.750)', '\" A\"[362] (p=0.080, logit=20.000)', '\" Among\"[22395] (p=0.048, logit=19.500)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     clean_prediction=['\" Comb\"[23262] (p=0.840, logit=21.875)', '\" A\"[362] (p=0.069, logit=19.375)', '\" The\"[578] (p=0.032, logit=18.625)', '\" Ring\"[22249] (p=0.015, logit=17.875)', '\" Among\"[22395] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     clean_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.83984375, logit=21.875, token_id=23262, metadata=None))), (22249, (4, PredictedToken(token=' Ring', prob=0.015380859375, logit=17.875, token_id=22249, metadata=None))), (49268, (38, PredictedToken(token=' Dish', prob=0.00019359588623046875, logit=13.5, token_id=49268, metadata=None))), (13120, (125, PredictedToken(token=' Night', prob=2.0384788513183594e-05, logit=11.25, token_id=13120, metadata=None)))])\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     int_prediction=['\" Ring\"[22249] (p=0.859, logit=21.375)', '\" Dish\"[49268] (p=0.043, logit=18.375)', '\" The\"[578] (p=0.023, logit=17.750)', '\" Among\"[22395] (p=0.016, logit=17.375)', '\" A\"[362] (p=0.016, logit=17.375)']\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     int_track=OrderedDict([(22249, (1, PredictedToken(token=' Ring', prob=0.859375, logit=21.375, token_id=22249, metadata=None))), (49268, (2, PredictedToken(token=' Dish', prob=0.042724609375, logit=18.375, token_id=49268, metadata=None))), (13120, (14, PredictedToken(token=' Night', prob=0.001068115234375, logit=14.6875, token_id=13120, metadata=None))), (23262, (177, PredictedToken(token=' Comb', prob=1.1146068572998047e-05, logit=10.125, token_id=23262, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:12 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     patch_prediction=['\" Pressure\"[40090] (p=0.781, logit=22.000)', '\" Among\"[22395] (p=0.073, logit=19.625)', '\" The\"[578] (p=0.064, logit=19.500)', '\" A\"[362] (p=0.044, logit=19.125)', '\" It\"[1102] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:44:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     clean_prediction=['\" Table\"[6771] (p=0.801, logit=22.250)', '\" The\"[578] (p=0.084, logit=20.000)', '\" A\"[362] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" To\"[2057] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     clean_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.80078125, logit=22.25, token_id=6771, metadata=None))), (2057, (5, PredictedToken(token=' To', prob=0.006927490234375, logit=17.5, token_id=2057, metadata=None))), (11683, (16, PredictedToken(token=' Acc', prob=0.001129150390625, logit=15.6875, token_id=11683, metadata=None))), (34392, (36, PredictedToken(token=' Horse', prob=0.0002231597900390625, logit=14.0625, token_id=34392, metadata=None))), (15429, (60, PredictedToken(token=' Hospital', prob=6.771087646484375e-05, logit=12.875, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     int_prediction=['\" To\"[2057] (p=0.738, logit=21.875)', '\" The\"[578] (p=0.088, logit=19.750)', '\" Among\"[22395] (p=0.053, logit=19.250)', '\" A\"[362] (p=0.037, logit=18.875)', '\" Acc\"[11683] (p=0.025, logit=18.500)']\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     int_track=OrderedDict([(2057, (1, PredictedToken(token=' To', prob=0.73828125, logit=21.875, token_id=2057, metadata=None))), (11683, (5, PredictedToken(token=' Acc', prob=0.0252685546875, logit=18.5, token_id=11683, metadata=None))), (34392, (30, PredictedToken(token=' Horse', prob=0.0003604888916015625, logit=14.25, token_id=34392, metadata=None))), (6771, (162, PredictedToken(token=' Table', prob=1.0251998901367188e-05, logit=10.6875, token_id=6771, metadata=None))), (15429, (1244, PredictedToken(token=' Hospital', prob=2.644956111907959e-07, logit=7.03125, token_id=15429, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:13 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     patch_prediction=['\" Yoga\"[38673] (p=0.449, logit=18.875)', '\" None\"[2290] (p=0.309, logit=18.500)', '\" Comb\"[23262] (p=0.078, logit=17.125)', '\" The\"[578] (p=0.022, logit=15.875)', '\" Ash\"[14937] (p=0.015, logit=15.500)']\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     clean_prediction=['\" Mirror\"[34954] (p=0.926, logit=21.875)', '\" A\"[362] (p=0.017, logit=17.875)', '\" The\"[578] (p=0.013, logit=17.625)', '\" Among\"[22395] (p=0.008, logit=17.125)', '\" mirror\"[18327] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     clean_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.92578125, logit=21.875, token_id=34954, metadata=None))), (57094, (6, PredictedToken(token=' Highlight', prob=0.0033416748046875, logit=16.25, token_id=57094, metadata=None))), (28131, (89, PredictedToken(token=' Golf', prob=2.5510787963867188e-05, logit=11.375, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     int_prediction=['\" Golf\"[28131] (p=0.543, logit=19.375)', '\" Highlight\"[57094] (p=0.256, logit=18.625)', '\" None\"[2290] (p=0.044, logit=16.875)', '\" The\"[578] (p=0.039, logit=16.750)', '\" A\"[362] (p=0.035, logit=16.625)']\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     int_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.54296875, logit=19.375, token_id=28131, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.255859375, logit=18.625, token_id=57094, metadata=None))), (34954, (48, PredictedToken(token=' Mirror', prob=0.0002803802490234375, logit=11.8125, token_id=34954, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:13 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:13 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:44:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     patch_prediction=['\" Comb\"[23262] (p=0.898, logit=22.000)', '\" A\"[362] (p=0.024, logit=18.375)', '\" The\"[578] (p=0.021, logit=18.250)', '\" Among\"[22395] (p=0.015, logit=17.875)', '\" (\"[320] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     clean_prediction=['\" Drum\"[46506] (p=0.773, logit=22.000)', '\" The\"[578] (p=0.104, logit=20.000)', '\" A\"[362] (p=0.063, logit=19.500)', '\" Among\"[22395] (p=0.016, logit=18.125)', '\" It\"[1102] (p=0.009, logit=17.500)']\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     clean_track=OrderedDict([(46506, (1, PredictedToken(token=' Drum', prob=0.7734375, logit=22.0, token_id=46506, metadata=None))), (83499, (48, PredictedToken(token=' Tooth', prob=0.00010776519775390625, logit=13.125, token_id=83499, metadata=None))), (6150, (76, PredictedToken(token=' School', prob=3.504753112792969e-05, logit=12.0, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     int_prediction=['\" Tooth\"[83499] (p=0.910, logit=22.625)', '\" The\"[578] (p=0.031, logit=19.250)', '\" Among\"[22395] (p=0.017, logit=18.625)', '\" School\"[6150] (p=0.017, logit=18.625)', '\" tooth\"[26588] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     int_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.91015625, logit=22.625, token_id=83499, metadata=None))), (6150, (3, PredictedToken(token=' School', prob=0.0166015625, logit=18.625, token_id=6150, metadata=None))), (46506, (242, PredictedToken(token=' Drum', prob=2.1904706954956055e-06, logit=9.6875, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:14 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:14 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     patch_prediction=['\" Mushroom\"[91297] (p=0.891, logit=21.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" A\"[362] (p=0.024, logit=18.000)', '\" Among\"[22395] (p=0.013, logit=17.375)', '\" Mush\"[59205] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:44:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     clean_prediction=['\" Boat\"[45332] (p=0.777, logit=22.250)', '\" The\"[578] (p=0.082, logit=20.000)', '\" A\"[362] (p=0.063, logit=19.750)', '\" Among\"[22395] (p=0.039, logit=19.250)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     clean_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.77734375, logit=22.25, token_id=45332, metadata=None))), (328, (11, PredictedToken(token=' S', prob=0.00131988525390625, logit=15.875, token_id=328, metadata=None))), (1443, (84, PredictedToken(token=' Sh', prob=2.7418136596679688e-05, logit=12.0, token_id=1443, metadata=None))), (52882, (110, PredictedToken(token=' Pepper', prob=1.6689300537109375e-05, logit=11.5, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.289, logit=20.125)', '\" Sh\"[1443] (p=0.225, logit=19.875)', '\" Pepper\"[52882] (p=0.198, logit=19.750)', '\" Among\"[22395] (p=0.106, logit=19.125)', '\" None\"[2290] (p=0.073, logit=18.750)']\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.2890625, logit=20.125, token_id=328, metadata=None))), (1443, (2, PredictedToken(token=' Sh', prob=0.224609375, logit=19.875, token_id=1443, metadata=None))), (52882, (3, PredictedToken(token=' Pepper', prob=0.1982421875, logit=19.75, token_id=52882, metadata=None))), (45332, (44, PredictedToken(token=' Boat', prob=0.00029754638671875, logit=13.25, token_id=45332, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:15 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:15 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.445, logit=19.875)', '\" Helmet\"[67629] (p=0.145, logit=18.750)', '\" The\"[578] (p=0.113, logit=18.500)', '\" Among\"[22395] (p=0.068, logit=18.000)', '\" A\"[362] (p=0.068, logit=18.000)']\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.844, logit=22.375)', '\" The\"[578] (p=0.089, logit=20.125)', '\" Among\"[22395] (p=0.029, logit=19.000)', '\" A\"[362] (p=0.012, logit=18.125)', '\" Box\"[8425] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.84375, logit=22.375, token_id=72683, metadata=None))), (19111, (77, PredictedToken(token=' Bus', prob=2.6345252990722656e-05, logit=12.0, token_id=19111, metadata=None))), (15883, (88, PredictedToken(token=' Spr', prob=1.811981201171875e-05, logit=11.625, token_id=15883, metadata=None))), (6690, (102, PredictedToken(token=' Air', prob=1.245737075805664e-05, logit=11.25, token_id=6690, metadata=None))), (67553, (376, PredictedToken(token=' Pants', prob=1.087784767150879e-06, logit=8.8125, token_id=67553, metadata=None))), (94091, (426, PredictedToken(token=' Tomato', prob=9.015202522277832e-07, logit=8.625, token_id=94091, metadata=None)))])\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     int_prediction=['\" Pants\"[67553] (p=0.750, logit=21.375)', '\" The\"[578] (p=0.115, logit=19.500)', '\" Among\"[22395] (p=0.070, logit=19.000)', '\" Spr\"[15883] (p=0.018, logit=17.625)', '\" Option\"[7104] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     int_track=OrderedDict([(67553, (1, PredictedToken(token=' Pants', prob=0.75, logit=21.375, token_id=67553, metadata=None))), (15883, (4, PredictedToken(token=' Spr', prob=0.0177001953125, logit=17.625, token_id=15883, metadata=None))), (94091, (36, PredictedToken(token=' Tomato', prob=0.00022220611572265625, logit=13.25, token_id=94091, metadata=None))), (72683, (183, PredictedToken(token=' Boxing', prob=9.179115295410156e-06, logit=10.0625, token_id=72683, metadata=None))), (19111, (185, PredictedToken(token=' Bus', prob=8.64267349243164e-06, logit=10.0, token_id=19111, metadata=None))), (6690, (541, PredictedToken(token=' Air', prob=1.3262033462524414e-06, logit=8.125, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:15 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:15 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     patch_prediction=['\" Motorcycle\"[70762] (p=0.891, logit=23.250)', '\" The\"[578] (p=0.044, logit=20.250)', '\" A\"[362] (p=0.039, logit=20.125)', '\" Among\"[22395] (p=0.009, logit=18.625)', '\" (\"[320] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     clean_prediction=['\" Tablet\"[58403] (p=0.633, logit=20.500)', '\" The\"[578] (p=0.141, logit=19.000)', '\" Among\"[22395] (p=0.059, logit=18.125)', '\" A\"[362] (p=0.059, logit=18.125)', '\" It\"[1102] (p=0.017, logit=16.875)']\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     clean_track=OrderedDict([(58403, (1, PredictedToken(token=' Tablet', prob=0.6328125, logit=20.5, token_id=58403, metadata=None))), (4923, (23, PredictedToken(token=' Sk', prob=0.00138092041015625, logit=14.375, token_id=4923, metadata=None))), (1183, (27, PredictedToken(token=' Tr', prob=0.001007080078125, logit=14.0625, token_id=1183, metadata=None))), (74968, (44, PredictedToken(token=' Razor', prob=0.0004482269287109375, logit=13.25, token_id=74968, metadata=None))), (64695, (138, PredictedToken(token=' Peach', prob=3.910064697265625e-05, logit=10.8125, token_id=64695, metadata=None)))])\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.637, logit=20.125)', '\" Razor\"[74968] (p=0.098, logit=18.250)', '\" Among\"[22395] (p=0.067, logit=17.875)', '\" The\"[578] (p=0.067, logit=17.875)', '\" A\"[362] (p=0.015, logit=16.375)']\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.63671875, logit=20.125, token_id=4923, metadata=None))), (74968, (2, PredictedToken(token=' Razor', prob=0.09765625, logit=18.25, token_id=74968, metadata=None))), (1183, (20, PredictedToken(token=' Tr', prob=0.002166748046875, logit=14.4375, token_id=1183, metadata=None))), (64695, (66, PredictedToken(token=' Peach', prob=0.0001888275146484375, logit=12.0, token_id=64695, metadata=None))), (58403, (503, PredictedToken(token=' Tablet', prob=3.680586814880371e-06, logit=8.0625, token_id=58403, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:16 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:44:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     patch_prediction=['\" Daisy\"[71264] (p=0.691, logit=20.500)', '\" The\"[578] (p=0.093, logit=18.500)', '\" Among\"[22395] (p=0.064, logit=18.125)', '\" d\"[294] (p=0.034, logit=17.500)', '\" Willow\"[65449] (p=0.024, logit=17.125)']\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     clean_prediction=['\" Pepper\"[52882] (p=0.855, logit=21.875)', '\" The\"[578] (p=0.062, logit=19.250)', '\" A\"[362] (p=0.023, logit=18.250)', '\" Among\"[22395] (p=0.020, logit=18.125)', '\" None\"[2290] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     clean_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.85546875, logit=21.875, token_id=52882, metadata=None))), (423, (10, PredictedToken(token=' D', prob=0.00154876708984375, logit=15.5625, token_id=423, metadata=None))), (20918, (165, PredictedToken(token=' Magn', prob=9.238719940185547e-06, logit=10.4375, token_id=20918, metadata=None))), (45332, (216, PredictedToken(token=' Boat', prob=5.9604644775390625e-06, logit=10.0, token_id=45332, metadata=None))), (49268, (217, PredictedToken(token=' Dish', prob=5.9604644775390625e-06, logit=10.0, token_id=49268, metadata=None))), (26781, (287, PredictedToken(token=' Hair', prob=3.3974647521972656e-06, logit=9.4375, token_id=26781, metadata=None)))])\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.664, logit=21.250)', '\" Magn\"[20918] (p=0.131, logit=19.625)', '\" The\"[578] (p=0.062, logit=18.875)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" None\"[2290] (p=0.026, logit=18.000)']\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.6640625, logit=21.25, token_id=423, metadata=None))), (20918, (2, PredictedToken(token=' Magn', prob=0.130859375, logit=19.625, token_id=20918, metadata=None))), (49268, (126, PredictedToken(token=' Dish', prob=2.3484230041503906e-05, logit=11.0, token_id=49268, metadata=None))), (45332, (181, PredictedToken(token=' Boat', prob=1.1086463928222656e-05, logit=10.25, token_id=45332, metadata=None))), (52882, (261, PredictedToken(token=' Pepper', prob=5.5730342864990234e-06, logit=9.5625, token_id=52882, metadata=None))), (26781, (531, PredictedToken(token=' Hair', prob=1.6987323760986328e-06, logit=8.375, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:17 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     patch_prediction=['\" Marker\"[40975] (p=0.883, logit=22.375)', '\" The\"[578] (p=0.039, logit=19.250)', '\" A\"[362] (p=0.039, logit=19.250)', '\" Among\"[22395] (p=0.018, logit=18.500)', '\" marker\"[11381] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.773, logit=21.500)', '\" The\"[578] (p=0.063, logit=19.000)', '\" Among\"[22395] (p=0.056, logit=18.875)', '\" A\"[362] (p=0.050, logit=18.750)', '\" (\"[320] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.7734375, logit=21.5, token_id=40090, metadata=None))), (6031, (9, PredictedToken(token=' Bro', prob=0.0031585693359375, logit=16.0, token_id=6031, metadata=None))), (61731, (49, PredictedToken(token=' Soap', prob=9.5367431640625e-05, logit=12.5, token_id=61731, metadata=None))), (58586, (124, PredictedToken(token=' Tape', prob=1.6570091247558594e-05, logit=10.75, token_id=58586, metadata=None))), (71264, (1537, PredictedToken(token=' Daisy', prob=3.03611159324646e-07, logit=6.75, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:44:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     int_prediction=['\" Tape\"[58586] (p=0.562, logit=20.125)', '\" The\"[578] (p=0.110, logit=18.500)', '\" Daisy\"[71264] (p=0.086, logit=18.250)', '\" Among\"[22395] (p=0.067, logit=18.000)', '\" d\"[294] (p=0.028, logit=17.125)']\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     int_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.5625, logit=20.125, token_id=58586, metadata=None))), (71264, (3, PredictedToken(token=' Daisy', prob=0.0859375, logit=18.25, token_id=71264, metadata=None))), (6031, (19, PredictedToken(token=' Bro', prob=0.001678466796875, logit=14.3125, token_id=6031, metadata=None))), (61731, (23, PredictedToken(token=' Soap', prob=0.0013885498046875, logit=14.125, token_id=61731, metadata=None))), (40090, (507, PredictedToken(token=' Pressure', prob=3.6656856536865234e-06, logit=8.1875, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:18 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:18 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.824, logit=22.000)', '\" A\"[362] (p=0.047, logit=19.125)', '\" The\"[578] (p=0.036, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.500)', '\" helicopter\"[36125] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.789, logit=22.375)', '\" An\"[1556] (p=0.107, logit=20.375)', '\" The\"[578] (p=0.044, logit=19.500)', '\" None\"[2290] (p=0.016, logit=18.500)', '\" Among\"[22395] (p=0.014, logit=18.375)']\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.7890625, logit=22.375, token_id=53889, metadata=None))), (57225, (47, PredictedToken(token=' Laptop', prob=8.058547973632812e-05, logit=13.1875, token_id=57225, metadata=None))), (70762, (112, PredictedToken(token=' Motorcycle', prob=1.3172626495361328e-05, logit=11.375, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     int_prediction=['\" Motorcycle\"[70762] (p=0.840, logit=22.125)', '\" None\"[2290] (p=0.078, logit=19.750)', '\" Laptop\"[57225] (p=0.025, logit=18.625)', '\" The\"[578] (p=0.020, logit=18.375)', '\" Among\"[22395] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     int_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.83984375, logit=22.125, token_id=70762, metadata=None))), (57225, (3, PredictedToken(token=' Laptop', prob=0.025390625, logit=18.625, token_id=57225, metadata=None))), (53889, (48, PredictedToken(token=' Apartment', prob=6.67572021484375e-05, logit=12.6875, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:18 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     patch_prediction=['\" Drum\"[46506] (p=0.680, logit=21.375)', '\" The\"[578] (p=0.151, logit=19.875)', '\" A\"[362] (p=0.072, logit=19.125)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" It\"[1102] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.793, logit=20.750)', '\" Gloves\"[68554] (p=0.057, logit=18.125)', '\" Plum\"[84409] (p=0.040, logit=17.750)', '\" None\"[2290] (p=0.027, logit=17.375)', '\" The\"[578] (p=0.021, logit=17.125)']\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.79296875, logit=20.75, token_id=432, metadata=None))), (68554, (2, PredictedToken(token=' Gloves', prob=0.057373046875, logit=18.125, token_id=68554, metadata=None))), (84409, (3, PredictedToken(token=' Plum', prob=0.03955078125, logit=17.75, token_id=84409, metadata=None))), (3420, (10, PredictedToken(token=' Trump', prob=0.002685546875, logit=15.0625, token_id=3420, metadata=None))), (87035, (133, PredictedToken(token=' Onion', prob=3.3855438232421875e-05, logit=10.6875, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.848, logit=21.375)', '\" Plum\"[84409] (p=0.079, logit=19.000)', '\" The\"[578] (p=0.020, logit=17.625)', '\" None\"[2290] (p=0.012, logit=17.125)', '\" A\"[362] (p=0.004, logit=16.125)']\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.84765625, logit=21.375, token_id=432, metadata=None))), (84409, (2, PredictedToken(token=' Plum', prob=0.0791015625, logit=19.0, token_id=84409, metadata=None))), (3420, (61, PredictedToken(token=' Trump', prob=6.771087646484375e-05, logit=11.9375, token_id=3420, metadata=None))), (68554, (114, PredictedToken(token=' Gloves', prob=2.491474151611328e-05, logit=10.9375, token_id=68554, metadata=None))), (87035, (120, PredictedToken(token=' Onion', prob=2.3365020751953125e-05, logit=10.875, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:19 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:19 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.875, logit=22.750)', '\" The\"[578] (p=0.056, logit=20.000)', '\" Among\"[22395] (p=0.049, logit=19.875)', '\" It\"[1102] (p=0.004, logit=17.250)', '\" \"[220] (p=0.001, logit=16.375)']\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.754, logit=22.375)', '\" The\"[578] (p=0.102, logit=20.375)', '\" A\"[362] (p=0.070, logit=20.000)', '\" Among\"[22395] (p=0.042, logit=19.500)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.75390625, logit=22.375, token_id=16183, metadata=None))), (11683, (21, PredictedToken(token=' Acc', prob=0.0004425048828125, logit=14.9375, token_id=11683, metadata=None))), (1901, (44, PredictedToken(token=' Z', prob=0.00011205673217773438, logit=13.5625, token_id=1901, metadata=None))), (98641, (100, PredictedToken(token=' Microwave', prob=1.609325408935547e-05, logit=11.625, token_id=98641, metadata=None))), (69755, (364, PredictedToken(token=' Notebook', prob=1.2442469596862793e-06, logit=9.0625, token_id=69755, metadata=None)))])\n",
      "2025-09-16 09:44:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.852, logit=23.125)', '\" The\"[578] (p=0.079, logit=20.750)', '\" Among\"[22395] (p=0.037, logit=20.000)', '\" Only\"[8442] (p=0.005, logit=18.000)', '\" It\"[1102] (p=0.004, logit=17.875)']\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.8515625, logit=23.125, token_id=1901, metadata=None))), (69755, (32, PredictedToken(token=' Notebook', prob=0.00017261505126953125, logit=14.625, token_id=69755, metadata=None))), (11683, (49, PredictedToken(token=' Acc', prob=4.9591064453125e-05, logit=13.375, token_id=11683, metadata=None))), (16183, (612, PredictedToken(token=' Hel', prob=2.2910535335540771e-07, logit=8.0, token_id=16183, metadata=None))), (98641, (2084, PredictedToken(token=' Microwave', prob=3.748573362827301e-08, logit=6.1875, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:20 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     patch_prediction=['\" Orch\"[55405] (p=0.734, logit=20.625)', '\" Peach\"[64695] (p=0.077, logit=18.375)', '\" The\"[578] (p=0.060, logit=18.125)', '\" Among\"[22395] (p=0.037, logit=17.625)', '\" orch\"[41245] (p=0.012, logit=16.500)']\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     clean_prediction=['\" School\"[6150] (p=0.637, logit=20.875)', '\" None\"[2290] (p=0.266, logit=20.000)', '\" The\"[578] (p=0.019, logit=17.375)', '\" There\"[2684] (p=0.015, logit=17.125)', '\" C\"[356] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     clean_track=OrderedDict([(6150, (1, PredictedToken(token=' School', prob=0.63671875, logit=20.875, token_id=6150, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.008056640625, logit=16.5, token_id=356, metadata=None))), (8325, (22, PredictedToken(token=' Apple', prob=0.000583648681640625, logit=13.875, token_id=8325, metadata=None))), (5250, (26, PredictedToken(token=' Pe', prob=0.0004825592041015625, logit=13.6875, token_id=5250, metadata=None)))])\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.719, logit=20.750)', '\" Pe\"[5250] (p=0.086, logit=18.625)', '\" C\"[356] (p=0.086, logit=18.625)', '\" The\"[578] (p=0.025, logit=17.375)', '\" There\"[2684] (p=0.017, logit=17.000)']\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     int_track=OrderedDict([(356, (2, PredictedToken(token=' C', prob=0.0859375, logit=18.625, token_id=356, metadata=None))), (5250, (3, PredictedToken(token=' Pe', prob=0.0859375, logit=18.625, token_id=5250, metadata=None))), (8325, (6, PredictedToken(token=' Apple', prob=0.007080078125, logit=16.125, token_id=8325, metadata=None))), (6150, (32, PredictedToken(token=' School', prob=0.0003299713134765625, logit=13.0625, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:20 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:20 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:44:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     patch_prediction=['\" Book\"[6017] (p=0.828, logit=22.000)', '\" The\"[578] (p=0.047, logit=19.125)', '\" A\"[362] (p=0.047, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=18.375)', '\" Coat\"[68867] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.844, logit=21.875)', '\" A\"[362] (p=0.048, logit=19.000)', '\" The\"[578] (p=0.037, logit=18.750)', '\" Dress\"[29318] (p=0.015, logit=17.875)', '\" Among\"[22395] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.84375, logit=21.875, token_id=17367, metadata=None))), (29318, (4, PredictedToken(token=' Dress', prob=0.01544189453125, logit=17.875, token_id=29318, metadata=None))), (328, (7, PredictedToken(token=' S', prob=0.004425048828125, logit=16.625, token_id=328, metadata=None)))])\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     int_prediction=['\" S\"[328] (p=0.730, logit=21.375)', '\" Dress\"[29318] (p=0.144, logit=19.750)', '\" The\"[578] (p=0.032, logit=18.250)', '\" None\"[2290] (p=0.028, logit=18.125)', '\" A\"[362] (p=0.025, logit=18.000)']\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     int_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.73046875, logit=21.375, token_id=328, metadata=None))), (29318, (2, PredictedToken(token=' Dress', prob=0.1435546875, logit=19.75, token_id=29318, metadata=None))), (17367, (19, PredictedToken(token=' Factory', prob=0.00070953369140625, logit=14.4375, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:21 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.832, logit=22.000)', '\" The\"[578] (p=0.060, logit=19.375)', '\" Among\"[22395] (p=0.047, logit=19.125)', '\" A\"[362] (p=0.022, logit=18.375)', '\" Option\"[7104] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     clean_prediction=['\" Mar\"[2947] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.077, logit=19.750)', '\" Among\"[22395] (p=0.036, logit=19.000)', '\" A\"[362] (p=0.022, logit=18.500)', '\" (\"[320] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     clean_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.82421875, logit=22.125, token_id=2947, metadata=None))), (6031, (23, PredictedToken(token=' Bro', prob=0.0004024505615234375, logit=14.5, token_id=6031, metadata=None))), (14588, (115, PredictedToken(token=' Dog', prob=1.2934207916259766e-05, logit=11.0625, token_id=14588, metadata=None))), (47759, (560, PredictedToken(token=' Guitar', prob=7.301568984985352e-07, logit=8.1875, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:44:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.422, logit=20.625)', '\" Dog\"[14588] (p=0.199, logit=19.875)', '\" The\"[578] (p=0.137, logit=19.500)', '\" Among\"[22395] (p=0.083, logit=19.000)', '\" Guitar\"[47759] (p=0.064, logit=18.750)']\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.421875, logit=20.625, token_id=6031, metadata=None))), (14588, (2, PredictedToken(token=' Dog', prob=0.19921875, logit=19.875, token_id=14588, metadata=None))), (47759, (5, PredictedToken(token=' Guitar', prob=0.064453125, logit=18.75, token_id=47759, metadata=None))), (2947, (187, PredictedToken(token=' Mar', prob=9.655952453613281e-06, logit=9.9375, token_id=2947, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:22 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:22 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     patch_prediction=['\" Mouse\"[18191] (p=0.664, logit=20.750)', '\" Pen\"[13597] (p=0.147, logit=19.250)', '\" mouse\"[8814] (p=0.026, logit=17.500)', '\" Computer\"[17863] (p=0.023, logit=17.375)', '\" None\"[2290] (p=0.023, logit=17.375)']\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.828, logit=21.375)', '\" The\"[578] (p=0.053, logit=18.625)', '\" A\"[362] (p=0.053, logit=18.625)', '\" Among\"[22395] (p=0.010, logit=17.000)', '\" (\"[320] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.828125, logit=21.375, token_id=69755, metadata=None))), (43316, (11, PredictedToken(token=' Tul', prob=0.0021820068359375, logit=15.4375, token_id=43316, metadata=None))), (16147, (76, PredictedToken(token=' Smart', prob=5.125999450683594e-05, logit=11.6875, token_id=16147, metadata=None)))])\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     int_prediction=['\" Smart\"[16147] (p=0.887, logit=21.500)', '\" The\"[578] (p=0.030, logit=18.125)', '\" A\"[362] (p=0.016, logit=17.500)', '\" None\"[2290] (p=0.014, logit=17.375)', '\" Among\"[22395] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     int_track=OrderedDict([(16147, (1, PredictedToken(token=' Smart', prob=0.88671875, logit=21.5, token_id=16147, metadata=None))), (43316, (29, PredictedToken(token=' Tul', prob=0.000316619873046875, logit=13.5625, token_id=43316, metadata=None))), (69755, (297, PredictedToken(token=' Notebook', prob=3.3080577850341797e-06, logit=9.0, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:22 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:22 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     patch_prediction=['\" None\"[2290] (p=0.512, logit=20.500)', '\" Factory\"[17367] (p=0.350, logit=20.125)', '\" The\"[578] (p=0.032, logit=17.750)', '\" A\"[362] (p=0.020, logit=17.250)', '\" There\"[2684] (p=0.015, logit=17.000)']\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.773, logit=21.500)', '\" Bro\"[6031] (p=0.105, logit=19.500)', '\" The\"[578] (p=0.044, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" socks\"[40086] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.7734375, logit=21.5, token_id=328, metadata=None))), (6031, (2, PredictedToken(token=' Bro', prob=0.10498046875, logit=19.5, token_id=6031, metadata=None))), (22725, (11, PredictedToken(token=' Orange', prob=0.00191497802734375, logit=15.5, token_id=22725, metadata=None))), (2947, (18, PredictedToken(token=' Mar', prob=0.000850677490234375, logit=14.6875, token_id=2947, metadata=None))), (16730, (854, PredictedToken(token=' Museum', prob=6.854534149169922e-07, logit=7.5625, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     int_prediction=['\" Museum\"[16730] (p=0.785, logit=20.875)', '\" Among\"[22395] (p=0.057, logit=18.250)', '\" The\"[578] (p=0.039, logit=17.875)', '\" Mar\"[2947] (p=0.018, logit=17.125)', '\" Orange\"[22725] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     int_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.78515625, logit=20.875, token_id=16730, metadata=None))), (2947, (4, PredictedToken(token=' Mar', prob=0.0184326171875, logit=17.125, token_id=2947, metadata=None))), (22725, (5, PredictedToken(token=' Orange', prob=0.01434326171875, logit=16.875, token_id=22725, metadata=None))), (6031, (21, PredictedToken(token=' Bro', prob=0.00125885009765625, logit=14.4375, token_id=6031, metadata=None))), (328, (134, PredictedToken(token=' S', prob=2.777576446533203e-05, logit=10.625, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:23 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:23 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.859, logit=22.750)', '\" The\"[578] (p=0.080, logit=20.375)', '\" A\"[362] (p=0.023, logit=19.125)', '\" Among\"[22395] (p=0.012, logit=18.500)', '\" It\"[1102] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     clean_prediction=['\" Basketball\"[47589] (p=0.859, logit=22.625)', '\" The\"[578] (p=0.080, logit=20.250)', '\" A\"[362] (p=0.018, logit=18.750)', '\" Among\"[22395] (p=0.014, logit=18.500)', '\" Basket\"[34217] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     clean_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.859375, logit=22.625, token_id=47589, metadata=None))), (60413, (31, PredictedToken(token=' Uk', prob=0.0001544952392578125, logit=14.0, token_id=60413, metadata=None))), (87035, (213, PredictedToken(token=' Onion', prob=3.0100345611572266e-06, logit=10.0625, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:44:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     int_prediction=['\" Uk\"[60413] (p=0.781, logit=21.250)', '\" The\"[578] (p=0.120, logit=19.375)', '\" Among\"[22395] (p=0.030, logit=18.000)', '\" Onion\"[87035] (p=0.006, logit=16.375)', '\" A\"[362] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     int_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.78125, logit=21.25, token_id=60413, metadata=None))), (87035, (4, PredictedToken(token=' Onion', prob=0.0059814453125, logit=16.375, token_id=87035, metadata=None))), (47589, (36, PredictedToken(token=' Basketball', prob=0.0002040863037109375, logit=13.0, token_id=47589, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:24 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:24 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.902, logit=21.875)', '\" The\"[578] (p=0.027, logit=18.375)', '\" A\"[362] (p=0.015, logit=17.750)', '\" None\"[2290] (p=0.013, logit=17.625)', '\" Among\"[22395] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     clean_prediction=['\" Sun\"[8219] (p=0.836, logit=22.125)', '\" The\"[578] (p=0.068, logit=19.625)', '\" Among\"[22395] (p=0.029, logit=18.750)', '\" A\"[362] (p=0.029, logit=18.750)', '\" It\"[1102] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     clean_track=OrderedDict([(8219, (1, PredictedToken(token=' Sun', prob=0.8359375, logit=22.125, token_id=8219, metadata=None))), (87035, (11, PredictedToken(token=' Onion', prob=0.00171661376953125, logit=15.9375, token_id=87035, metadata=None))), (26781, (25, PredictedToken(token=' Hair', prob=0.0003604888916015625, logit=14.375, token_id=26781, metadata=None)))])\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.762, logit=21.250)', '\" The\"[578] (p=0.062, logit=18.750)', '\" Sun\"[8219] (p=0.049, logit=18.500)', '\" Among\"[22395] (p=0.026, logit=17.875)', '\" Hair\"[26781] (p=0.020, logit=17.625)']\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.76171875, logit=21.25, token_id=87035, metadata=None))), (8219, (3, PredictedToken(token=' Sun', prob=0.048583984375, logit=18.5, token_id=8219, metadata=None))), (26781, (5, PredictedToken(token=' Hair', prob=0.020263671875, logit=17.625, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:24 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:24 src.selection.optimization DEBUG    torch.Size([6, 36])\n",
      "2025-09-16 09:44:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.809, logit=22.000)', '\" The\"[578] (p=0.075, logit=19.625)', '\" A\"[362] (p=0.040, logit=19.000)', '\" Among\"[22395] (p=0.035, logit=18.875)', '\" D\"[423] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     clean_prediction=['\" Piano\"[56491] (p=0.758, logit=21.875)', '\" The\"[578] (p=0.116, logit=20.000)', '\" Among\"[22395] (p=0.043, logit=19.000)', '\" A\"[362] (p=0.038, logit=18.875)', '\" It\"[1102] (p=0.011, logit=17.625)']\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     clean_track=OrderedDict([(56491, (1, PredictedToken(token=' Piano', prob=0.7578125, logit=21.875, token_id=56491, metadata=None))), (52466, (96, PredictedToken(token=' Warehouse', prob=2.3603439331054688e-05, logit=11.5, token_id=52466, metadata=None))), (8219, (165, PredictedToken(token=' Sun', prob=7.212162017822266e-06, logit=10.3125, token_id=8219, metadata=None))), (48035, (261, PredictedToken(token=' Gir', prob=3.0100345611572266e-06, logit=9.4375, token_id=48035, metadata=None))), (34785, (279, PredictedToken(token=' Truck', prob=2.652406692504883e-06, logit=9.3125, token_id=34785, metadata=None))), (3341, (288, PredictedToken(token=' Car', prob=2.339482307434082e-06, logit=9.1875, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     int_prediction=['\" Gir\"[48035] (p=0.809, logit=21.875)', '\" The\"[578] (p=0.097, logit=19.750)', '\" Among\"[22395] (p=0.031, logit=18.625)', '\" A\"[362] (p=0.028, logit=18.500)', '\" It\"[1102] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     int_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.80859375, logit=21.875, token_id=48035, metadata=None))), (3341, (15, PredictedToken(token=' Car', prob=0.000736236572265625, logit=14.875, token_id=3341, metadata=None))), (52466, (29, PredictedToken(token=' Warehouse', prob=0.000270843505859375, logit=13.875, token_id=52466, metadata=None))), (8219, (44, PredictedToken(token=' Sun', prob=0.00013637542724609375, logit=13.1875, token_id=8219, metadata=None))), (34785, (74, PredictedToken(token=' Truck', prob=4.7206878662109375e-05, logit=12.125, token_id=34785, metadata=None))), (56491, (467, PredictedToken(token=' Piano', prob=1.1771917343139648e-06, logit=8.4375, token_id=56491, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:25 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:25 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.816, logit=22.375)', '\" The\"[578] (p=0.086, logit=20.125)', '\" A\"[362] (p=0.036, logit=19.250)', '\" Among\"[22395] (p=0.025, logit=18.875)', '\" d\"[294] (p=0.013, logit=18.250)']\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     clean_prediction=['\" Cow\"[22607] (p=0.781, logit=21.875)', '\" The\"[578] (p=0.073, logit=19.500)', '\" A\"[362] (p=0.056, logit=19.250)', '\" Among\"[22395] (p=0.034, logit=18.750)', '\" C\"[356] (p=0.013, logit=17.750)']\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     clean_track=OrderedDict([(22607, (1, PredictedToken(token=' Cow', prob=0.78125, logit=21.875, token_id=22607, metadata=None))), (469, (22, PredictedToken(token=' E', prob=0.000431060791015625, logit=14.375, token_id=469, metadata=None))), (43950, (70, PredictedToken(token=' Lav', prob=4.267692565917969e-05, logit=12.0625, token_id=43950, metadata=None))), (16183, (142, PredictedToken(token=' Hel', prob=9.5367431640625e-06, logit=10.5625, token_id=16183, metadata=None))), (65197, (208, PredictedToken(token=' Surf', prob=4.500150680541992e-06, logit=9.8125, token_id=65197, metadata=None))), (39794, (1508, PredictedToken(token=' Desk', prob=2.384185791015625e-07, logit=6.875, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:44:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     int_prediction=['\" Lav\"[43950] (p=0.590, logit=20.125)', '\" Among\"[22395] (p=0.149, logit=18.750)', '\" The\"[578] (p=0.132, logit=18.625)', '\" Option\"[7104] (p=0.014, logit=16.375)', '\" \"[220] (p=0.014, logit=16.375)']\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     int_track=OrderedDict([(43950, (1, PredictedToken(token=' Lav', prob=0.58984375, logit=20.125, token_id=43950, metadata=None))), (469, (42, PredictedToken(token=' E', prob=0.0003948211669921875, logit=12.8125, token_id=469, metadata=None))), (22607, (111, PredictedToken(token=' Cow', prob=5.6743621826171875e-05, logit=10.875, token_id=22607, metadata=None))), (16183, (274, PredictedToken(token=' Hel', prob=1.1205673217773438e-05, logit=9.25, token_id=16183, metadata=None))), (65197, (869, PredictedToken(token=' Surf', prob=1.952052116394043e-06, logit=7.5, token_id=65197, metadata=None))), (39794, (8044, PredictedToken(token=' Desk', prob=7.776543498039246e-08, logit=4.28125, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:26 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:26 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     patch_prediction=['\" Lav\"[43950] (p=0.789, logit=20.875)', '\" The\"[578] (p=0.073, logit=18.500)', '\" Among\"[22395] (p=0.031, logit=17.625)', '\" A\"[362] (p=0.021, logit=17.250)', '\" lavender\"[81460] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     clean_prediction=['\" Binder\"[91263] (p=0.828, logit=21.250)', '\" The\"[578] (p=0.060, logit=18.625)', '\" A\"[362] (p=0.036, logit=18.125)', '\" Among\"[22395] (p=0.028, logit=17.875)', '\" It\"[1102] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     clean_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.828125, logit=21.25, token_id=91263, metadata=None))), (86460, (11, PredictedToken(token=' Necklace', prob=0.00141143798828125, logit=14.875, token_id=86460, metadata=None))), (52882, (24, PredictedToken(token=' Pepper', prob=0.00070953369140625, logit=14.1875, token_id=52882, metadata=None))), (48390, (518, PredictedToken(token=' Lily', prob=2.250075340270996e-06, logit=8.4375, token_id=48390, metadata=None)))])\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     int_prediction=['\" Lily\"[48390] (p=0.766, logit=20.750)', '\" The\"[578] (p=0.062, logit=18.250)', '\" Among\"[22395] (p=0.055, logit=18.125)', '\" Option\"[7104] (p=0.023, logit=17.250)', '\" Pepper\"[52882] (p=0.011, logit=16.500)']\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     int_track=OrderedDict([(48390, (1, PredictedToken(token=' Lily', prob=0.765625, logit=20.75, token_id=48390, metadata=None))), (52882, (5, PredictedToken(token=' Pepper', prob=0.01092529296875, logit=16.5, token_id=52882, metadata=None))), (86460, (89, PredictedToken(token=' Necklace', prob=7.343292236328125e-05, logit=11.5, token_id=86460, metadata=None))), (91263, (197, PredictedToken(token=' Binder', prob=1.633167266845703e-05, logit=10.0, token_id=91263, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:26 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:44:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.820, logit=22.250)', '\" The\"[578] (p=0.076, logit=19.875)', '\" Among\"[22395] (p=0.067, logit=19.750)', '\" A\"[362] (p=0.008, logit=17.625)', '\" z\"[1167] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     clean_prediction=['\" Brace\"[70306] (p=0.758, logit=22.125)', '\" The\"[578] (p=0.090, logit=20.000)', '\" A\"[362] (p=0.080, logit=19.875)', '\" Among\"[22395] (p=0.043, logit=19.250)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     clean_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.7578125, logit=22.125, token_id=70306, metadata=None))), (356, (13, PredictedToken(token=' C', prob=0.000690460205078125, logit=15.125, token_id=356, metadata=None))), (36895, (53, PredictedToken(token=' Eagle', prob=7.295608520507812e-05, logit=12.875, token_id=36895, metadata=None))), (11452, (55, PredictedToken(token=' Head', prob=6.818771362304688e-05, logit=12.8125, token_id=11452, metadata=None))), (37326, (124, PredictedToken(token=' Swe', prob=1.2636184692382812e-05, logit=11.125, token_id=37326, metadata=None))), (9441, (303, PredictedToken(token=' Church', prob=2.205371856689453e-06, logit=9.375, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.828, logit=22.375)', '\" Among\"[22395] (p=0.068, logit=19.875)', '\" The\"[578] (p=0.060, logit=19.750)', '\" It\"[1102] (p=0.009, logit=17.875)', '\" A\"[362] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.828125, logit=22.375, token_id=356, metadata=None))), (37326, (6, PredictedToken(token=' Swe', prob=0.0038299560546875, logit=17.0, token_id=37326, metadata=None))), (36895, (13, PredictedToken(token=' Eagle', prob=0.0008544921875, logit=15.5, token_id=36895, metadata=None))), (11452, (576, PredictedToken(token=' Head', prob=6.07222318649292e-07, logit=8.25, token_id=11452, metadata=None))), (70306, (1212, PredictedToken(token=' Brace', prob=2.0954757928848267e-07, logit=7.1875, token_id=70306, metadata=None))), (9441, (5799, PredictedToken(token=' Church', prob=1.8277205526828766e-08, logit=4.75, token_id=9441, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:27 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:27 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.812, logit=22.375)', '\" The\"[578] (p=0.052, logit=19.625)', '\" A\"[362] (p=0.052, logit=19.625)', '\" Among\"[22395] (p=0.028, logit=19.000)', '\" None\"[2290] (p=0.022, logit=18.750)']\n",
      "2025-09-16 09:44:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     clean_prediction=['\" Viol\"[30555] (p=0.688, logit=22.125)', '\" The\"[578] (p=0.197, logit=20.875)', '\" Among\"[22395] (p=0.034, logit=19.125)', '\" A\"[362] (p=0.034, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     clean_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.6875, logit=22.125, token_id=30555, metadata=None))), (1666, (17, PredictedToken(token=' As', prob=0.000858306884765625, logit=15.4375, token_id=1666, metadata=None))), (3341, (62, PredictedToken(token=' Car', prob=6.198883056640625e-05, logit=12.8125, token_id=3341, metadata=None))), (79028, (182, PredictedToken(token=' Hick', prob=5.781650543212891e-06, logit=10.4375, token_id=79028, metadata=None))), (38258, (206, PredictedToken(token=' Baseball', prob=4.500150680541992e-06, logit=10.1875, token_id=38258, metadata=None))), (10164, (369, PredictedToken(token=' Water', prob=1.4603137969970703e-06, logit=9.0625, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     int_prediction=['\" As\"[1666] (p=0.770, logit=22.250)', '\" Water\"[10164] (p=0.072, logit=19.875)', '\" Among\"[22395] (p=0.063, logit=19.750)', '\" The\"[578] (p=0.049, logit=19.500)', '\" It\"[1102] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     int_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.76953125, logit=22.25, token_id=1666, metadata=None))), (10164, (2, PredictedToken(token=' Water', prob=0.07177734375, logit=19.875, token_id=10164, metadata=None))), (79028, (6, PredictedToken(token=' Hick', prob=0.005889892578125, logit=17.375, token_id=79028, metadata=None))), (38258, (63, PredictedToken(token=' Baseball', prob=5.7697296142578125e-05, logit=12.75, token_id=38258, metadata=None))), (3341, (131, PredictedToken(token=' Car', prob=1.0013580322265625e-05, logit=11.0, token_id=3341, metadata=None))), (30555, (273, PredictedToken(token=' Viol', prob=2.384185791015625e-06, logit=9.5625, token_id=30555, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:28 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     patch_prediction=['\" Television\"[41445] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.075, logit=19.250)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" A\"[362] (p=0.019, logit=17.875)', '\" TV\"[6007] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.879, logit=21.500)', '\" The\"[578] (p=0.039, logit=18.375)', '\" A\"[362] (p=0.016, logit=17.500)', '\" Acc\"[11683] (p=0.009, logit=16.875)', '\" Note\"[7181] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.87890625, logit=21.5, token_id=69755, metadata=None))), (11683, (4, PredictedToken(token=' Acc', prob=0.00860595703125, logit=16.875, token_id=11683, metadata=None))), (26698, (7, PredictedToken(token=' Keyboard', prob=0.004608154296875, logit=16.25, token_id=26698, metadata=None))), (48665, (201, PredictedToken(token=' Raspberry', prob=9.47713851928711e-06, logit=10.0625, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.750, logit=20.625)', '\" The\"[578] (p=0.048, logit=17.875)', '\" None\"[2290] (p=0.033, logit=17.500)', '\" Raspberry\"[48665] (p=0.029, logit=17.375)', '\" Among\"[22395] (p=0.029, logit=17.375)']\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.75, logit=20.625, token_id=26698, metadata=None))), (48665, (5, PredictedToken(token=' Raspberry', prob=0.029052734375, logit=17.375, token_id=48665, metadata=None))), (11683, (14, PredictedToken(token=' Acc', prob=0.0027008056640625, logit=15.0, token_id=11683, metadata=None))), (69755, (47, PredictedToken(token=' Notebook', prob=0.0004425048828125, logit=13.1875, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:28 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:44:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.719, logit=21.875)', '\" The\"[578] (p=0.097, logit=19.875)', '\" Among\"[22395] (p=0.067, logit=19.500)', '\" A\"[362] (p=0.067, logit=19.500)', '\" B\"[426] (p=0.015, logit=18.000)']\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     clean_prediction=['\" Gloves\"[68554] (p=0.832, logit=21.875)', '\" The\"[578] (p=0.078, logit=19.500)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" Glo\"[25372] (p=0.012, logit=17.625)', '\" A\"[362] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     clean_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.83203125, logit=21.875, token_id=68554, metadata=None))), (16183, (12, PredictedToken(token=' Hel', prob=0.00160980224609375, logit=15.625, token_id=16183, metadata=None))), (423, (15, PredictedToken(token=' D', prob=0.00103759765625, logit=15.1875, token_id=423, metadata=None))), (8325, (91, PredictedToken(token=' Apple', prob=3.337860107421875e-05, logit=11.75, token_id=8325, metadata=None))), (82994, (147, PredictedToken(token=' Toilet', prob=1.0848045349121094e-05, logit=10.625, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     int_prediction=['\" D\"[423] (p=0.812, logit=22.375)', '\" The\"[578] (p=0.076, logit=20.000)', '\" Among\"[22395] (p=0.036, logit=19.250)', '\" A\"[362] (p=0.022, logit=18.750)', '\" d\"[294] (p=0.010, logit=18.000)']\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     int_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.8125, logit=22.375, token_id=423, metadata=None))), (8325, (6, PredictedToken(token=' Apple', prob=0.0079345703125, logit=17.75, token_id=8325, metadata=None))), (16183, (12, PredictedToken(token=' Hel', prob=0.00156402587890625, logit=16.125, token_id=16183, metadata=None))), (82994, (295, PredictedToken(token=' Toilet', prob=1.6167759895324707e-06, logit=9.25, token_id=82994, metadata=None))), (68554, (607, PredictedToken(token=' Gloves', prob=5.252659320831299e-07, logit=8.125, token_id=68554, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:29 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:29 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.777, logit=22.125)', '\" A\"[362] (p=0.082, logit=19.875)', '\" The\"[578] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.026, logit=18.750)', '\" ring\"[10264] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:44:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.754, logit=22.750)', '\" A\"[362] (p=0.102, logit=20.750)', '\" The\"[578] (p=0.080, logit=20.500)', '\" Among\"[22395] (p=0.029, logit=19.500)', '\" It\"[1102] (p=0.007, logit=18.125)']\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.75390625, logit=22.75, token_id=4783, metadata=None))), (67629, (51, PredictedToken(token=' Helmet', prob=8.20159912109375e-05, logit=13.625, token_id=67629, metadata=None))), (13120, (70, PredictedToken(token=' Night', prob=3.0159950256347656e-05, logit=12.625, token_id=13120, metadata=None))), (10573, (151, PredictedToken(token=' Watch', prob=6.318092346191406e-06, logit=11.0625, token_id=10573, metadata=None)))])\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     int_prediction=['\" Watch\"[10573] (p=0.656, logit=21.500)', '\" The\"[578] (p=0.089, logit=19.500)', '\" None\"[2290] (p=0.069, logit=19.250)', '\" A\"[362] (p=0.061, logit=19.125)', '\" Night\"[13120] (p=0.037, logit=18.625)']\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     int_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.65625, logit=21.5, token_id=10573, metadata=None))), (13120, (5, PredictedToken(token=' Night', prob=0.036865234375, logit=18.625, token_id=13120, metadata=None))), (67629, (12, PredictedToken(token=' Helmet', prob=0.0022125244140625, logit=15.8125, token_id=67629, metadata=None))), (4783, (60, PredictedToken(token=' House', prob=9.775161743164062e-05, logit=12.6875, token_id=4783, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:30 src.selection.optimization DEBUG    torch.Size([4, 30])\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.559, logit=21.250)', '\" The\"[578] (p=0.264, logit=20.500)', '\" A\"[362] (p=0.066, logit=19.125)', '\" Among\"[22395] (p=0.059, logit=19.000)', '\" It\"[1102] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.953, logit=21.875)', '\" The\"[578] (p=0.011, logit=17.375)', '\" A\"[362] (p=0.011, logit=17.375)', '\" Among\"[22395] (p=0.005, logit=16.625)', '\" (\"[320] (p=0.002, logit=15.625)']\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.953125, logit=21.875, token_id=41493, metadata=None))), (18343, (9, PredictedToken(token=' Paper', prob=0.00098419189453125, logit=15.0, token_id=18343, metadata=None))), (5340, (20, PredictedToken(token=' Har', prob=0.0003185272216796875, logit=13.875, token_id=5340, metadata=None))), (82452, (80, PredictedToken(token=' Jasmine', prob=2.7894973754882812e-05, logit=11.4375, token_id=82452, metadata=None)))])\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.785, logit=20.125)', '\" None\"[2290] (p=0.083, logit=17.875)', '\" Among\"[22395] (p=0.027, logit=16.750)', '\" Paper\"[18343] (p=0.014, logit=16.125)', '\" The\"[578] (p=0.014, logit=16.125)']\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.78515625, logit=20.125, token_id=5340, metadata=None))), (18343, (5, PredictedToken(token=' Paper', prob=0.014404296875, logit=16.125, token_id=18343, metadata=None))), (41493, (30, PredictedToken(token=' Tow', prob=0.0005950927734375, logit=12.9375, token_id=41493, metadata=None))), (82452, (2264, PredictedToken(token=' Jasmine', prob=4.76837158203125e-07, logit=5.8125, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:30 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:44:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     patch_prediction=['\" Trump\"[3420] (p=0.836, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.022, logit=18.625)', '\" A\"[362] (p=0.020, logit=18.500)', '\" Option\"[7104] (p=0.012, logit=18.000)']\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     clean_prediction=['\" Brace\"[70306] (p=0.773, logit=22.125)', '\" A\"[362] (p=0.082, logit=19.875)', '\" The\"[578] (p=0.072, logit=19.750)', '\" Among\"[22395] (p=0.034, logit=19.000)', '\" It\"[1102] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     clean_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.7734375, logit=22.125, token_id=70306, metadata=None))), (5340, (59, PredictedToken(token=' Har', prob=7.009506225585938e-05, logit=12.8125, token_id=5340, metadata=None))), (14937, (75, PredictedToken(token=' Ash', prob=4.2438507080078125e-05, logit=12.3125, token_id=14937, metadata=None))), (97796, (144, PredictedToken(token=' Skate', prob=1.0728836059570312e-05, logit=10.9375, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     int_prediction=['\" Ash\"[14937] (p=0.738, logit=21.750)', '\" Among\"[22395] (p=0.113, logit=19.875)', '\" The\"[578] (p=0.047, logit=19.000)', '\" Har\"[5340] (p=0.042, logit=18.875)', '\" An\"[1556] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     int_track=OrderedDict([(14937, (1, PredictedToken(token=' Ash', prob=0.73828125, logit=21.75, token_id=14937, metadata=None))), (5340, (4, PredictedToken(token=' Har', prob=0.04150390625, logit=18.875, token_id=5340, metadata=None))), (97796, (45, PredictedToken(token=' Skate', prob=0.000141143798828125, logit=13.1875, token_id=97796, metadata=None))), (70306, (252, PredictedToken(token=' Brace', prob=4.5299530029296875e-06, logit=9.75, token_id=70306, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:31 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:31 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     patch_prediction=['\" Pressure\"[40090] (p=0.688, logit=21.750)', '\" The\"[578] (p=0.105, logit=19.875)', '\" Among\"[22395] (p=0.093, logit=19.750)', '\" A\"[362] (p=0.039, logit=18.875)', '\" Option\"[7104] (p=0.016, logit=18.000)']\n",
      "2025-09-16 09:44:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.723, logit=21.375)', '\" The\"[578] (p=0.067, logit=19.000)', '\" Slow\"[39247] (p=0.059, logit=18.875)', '\" A\"[362] (p=0.052, logit=18.750)', '\" Among\"[22395] (p=0.041, logit=18.500)']\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.72265625, logit=21.375, token_id=5907, metadata=None))), (39247, (3, PredictedToken(token=' Slow', prob=0.05908203125, logit=18.875, token_id=39247, metadata=None))), (68027, (53, PredictedToken(token=' Sax', prob=0.0001659393310546875, logit=13.0, token_id=68027, metadata=None))), (91782, (395, PredictedToken(token=' Shorts', prob=2.2351741790771484e-06, logit=8.6875, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.338, logit=19.250)', '\" Shorts\"[91782] (p=0.231, logit=18.875)', '\" Among\"[22395] (p=0.181, logit=18.625)', '\" The\"[578] (p=0.075, logit=17.750)', '\" Option\"[7104] (p=0.036, logit=17.000)']\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.337890625, logit=19.25, token_id=39247, metadata=None))), (91782, (2, PredictedToken(token=' Shorts', prob=0.2314453125, logit=18.875, token_id=91782, metadata=None))), (68027, (419, PredictedToken(token=' Sax', prob=5.304813385009766e-06, logit=8.1875, token_id=68027, metadata=None))), (5907, (537, PredictedToken(token=' Project', prob=3.635883331298828e-06, logit=7.8125, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:32 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:32 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.793, logit=22.625)', '\" A\"[362] (p=0.083, logit=20.375)', '\" The\"[578] (p=0.074, logit=20.250)', '\" Among\"[22395] (p=0.021, logit=19.000)', '\" (\"[320] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.887, logit=22.000)', '\" The\"[578] (p=0.039, logit=18.875)', '\" Among\"[22395] (p=0.027, logit=18.500)', '\" An\"[1556] (p=0.008, logit=17.250)', '\" iris\"[65042] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.88671875, logit=22.0, token_id=66821, metadata=None))), (13000, (34, PredictedToken(token=' Van', prob=0.0001697540283203125, logit=13.4375, token_id=13000, metadata=None))), (9441, (99, PredictedToken(token=' Church', prob=1.6808509826660156e-05, logit=11.125, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.898, logit=23.125)', '\" The\"[578] (p=0.045, logit=20.125)', '\" A\"[362] (p=0.016, logit=19.125)', '\" Among\"[22395] (p=0.009, logit=18.500)', '\" It\"[1102] (p=0.006, logit=18.125)']\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.8984375, logit=23.125, token_id=13000, metadata=None))), (9441, (53, PredictedToken(token=' Church', prob=2.8014183044433594e-05, logit=12.75, token_id=9441, metadata=None))), (66821, (170, PredictedToken(token=' Iris', prob=2.771615982055664e-06, logit=10.4375, token_id=66821, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:32 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:44:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     patch_prediction=['\" House\"[4783] (p=0.777, logit=22.500)', '\" The\"[578] (p=0.082, logit=20.250)', '\" A\"[362] (p=0.072, logit=20.125)', '\" Among\"[22395] (p=0.034, logit=19.375)', '\" It\"[1102] (p=0.007, logit=17.750)']\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.793, logit=22.250)', '\" An\"[1556] (p=0.107, logit=20.250)', '\" The\"[578] (p=0.035, logit=19.125)', '\" Among\"[22395] (p=0.024, logit=18.750)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.79296875, logit=22.25, token_id=6690, metadata=None))), (98641, (17, PredictedToken(token=' Microwave', prob=0.0009307861328125, logit=15.5, token_id=98641, metadata=None))), (91263, (122, PredictedToken(token=' Binder', prob=1.5020370483398438e-05, logit=11.375, token_id=91263, metadata=None))), (19176, (152, PredictedToken(token=' Temple', prob=8.58306884765625e-06, logit=10.8125, token_id=19176, metadata=None)))])\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     int_prediction=['\" Binder\"[91263] (p=0.430, logit=20.125)', '\" Temple\"[19176] (p=0.262, logit=19.625)', '\" Among\"[22395] (p=0.084, logit=18.500)', '\" The\"[578] (p=0.058, logit=18.125)', '\" A\"[362] (p=0.045, logit=17.875)']\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     int_track=OrderedDict([(91263, (1, PredictedToken(token=' Binder', prob=0.4296875, logit=20.125, token_id=91263, metadata=None))), (19176, (2, PredictedToken(token=' Temple', prob=0.26171875, logit=19.625, token_id=19176, metadata=None))), (6690, (142, PredictedToken(token=' Air', prob=2.0742416381835938e-05, logit=10.1875, token_id=6690, metadata=None))), (98641, (696, PredictedToken(token=' Microwave', prob=1.601874828338623e-06, logit=7.625, token_id=98641, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:33 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:33 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.898, logit=22.875)', '\" The\"[578] (p=0.039, logit=19.750)', '\" A\"[362] (p=0.027, logit=19.375)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" (\"[320] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.922, logit=22.875)', '\" The\"[578] (p=0.025, logit=19.250)', '\" A\"[362] (p=0.019, logit=19.000)', '\" laptop\"[21288] (p=0.009, logit=18.250)', '\" Among\"[22395] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.921875, logit=22.875, token_id=57225, metadata=None))), (82994, (72, PredictedToken(token=' Toilet', prob=1.2755393981933594e-05, logit=11.6875, token_id=82994, metadata=None))), (29318, (491, PredictedToken(token=' Dress', prob=4.0978193283081055e-07, logit=8.25, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:44:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.824, logit=21.750)', '\" The\"[578] (p=0.077, logit=19.375)', '\" toilet\"[27306] (p=0.015, logit=17.750)', '\" Among\"[22395] (p=0.013, logit=17.625)', '\" A\"[362] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.82421875, logit=21.75, token_id=82994, metadata=None))), (29318, (9, PredictedToken(token=' Dress', prob=0.004913330078125, logit=16.625, token_id=29318, metadata=None))), (57225, (48, PredictedToken(token=' Laptop', prob=0.00013065338134765625, logit=13.0, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:34 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.680, logit=21.500)', '\" The\"[578] (p=0.134, logit=19.875)', '\" Among\"[22395] (p=0.092, logit=19.500)', '\" A\"[362] (p=0.038, logit=18.625)', '\" (\"[320] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.805, logit=20.625)', '\" Among\"[22395] (p=0.058, logit=18.000)', '\" The\"[578] (p=0.045, logit=17.750)', '\" A\"[362] (p=0.024, logit=17.125)', '\" lotion\"[87942] (p=0.007, logit=15.938)']\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.8046875, logit=20.625, token_id=445, metadata=None))), (27738, (34, PredictedToken(token=' Ward', prob=0.0003261566162109375, logit=12.8125, token_id=27738, metadata=None))), (23910, (126, PredictedToken(token=' Pear', prob=4.1484832763671875e-05, logit=10.75, token_id=23910, metadata=None))), (47759, (172, PredictedToken(token=' Guitar', prob=2.086162567138672e-05, logit=10.0625, token_id=47759, metadata=None))), (3816, (223, PredictedToken(token=' Red', prob=1.1146068572998047e-05, logit=9.4375, token_id=3816, metadata=None))), (100031, (237, PredictedToken(token=' Mosque', prob=9.834766387939453e-06, logit=9.3125, token_id=100031, metadata=None)))])\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     int_prediction=['\" Ward\"[27738] (p=0.307, logit=19.250)', '\" Mosque\"[100031] (p=0.271, logit=19.125)', '\" Red\"[3816] (p=0.145, logit=18.500)', '\" Among\"[22395] (p=0.100, logit=18.125)', '\" The\"[578] (p=0.042, logit=17.250)']\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     int_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.306640625, logit=19.25, token_id=27738, metadata=None))), (100031, (2, PredictedToken(token=' Mosque', prob=0.271484375, logit=19.125, token_id=100031, metadata=None))), (3816, (3, PredictedToken(token=' Red', prob=0.14453125, logit=18.5, token_id=3816, metadata=None))), (445, (55, PredictedToken(token=' L', prob=0.000263214111328125, logit=12.1875, token_id=445, metadata=None))), (23910, (71, PredictedToken(token=' Pear', prob=0.0001697540283203125, logit=11.75, token_id=23910, metadata=None))), (47759, (1217, PredictedToken(token=' Guitar', prob=1.296401023864746e-06, logit=6.875, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:34 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:34 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:44:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.691, logit=21.750)', '\" The\"[578] (p=0.154, logit=20.250)', '\" A\"[362] (p=0.057, logit=19.250)', '\" Among\"[22395] (p=0.050, logit=19.125)', '\" It\"[1102] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     clean_prediction=['\" Sheep\"[84008] (p=0.539, logit=20.250)', '\" The\"[578] (p=0.198, logit=19.250)', '\" Among\"[22395] (p=0.073, logit=18.250)', '\" A\"[362] (p=0.073, logit=18.250)', '\" sheep\"[33012] (p=0.018, logit=16.875)']\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     clean_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.5390625, logit=20.25, token_id=84008, metadata=None))), (42609, (61, PredictedToken(token=' Pine', prob=0.00012493133544921875, logit=11.875, token_id=42609, metadata=None))), (6690, (115, PredictedToken(token=' Air', prob=4.029273986816406e-05, logit=10.75, token_id=6690, metadata=None))), (94091, (152, PredictedToken(token=' Tomato', prob=2.6106834411621094e-05, logit=10.3125, token_id=94091, metadata=None))), (40090, (201, PredictedToken(token=' Pressure', prob=1.4841556549072266e-05, logit=9.75, token_id=40090, metadata=None))), (47759, (392, PredictedToken(token=' Guitar', prob=4.26173210144043e-06, logit=8.5, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     int_prediction=['\" Guitar\"[47759] (p=0.672, logit=20.875)', '\" The\"[578] (p=0.150, logit=19.375)', '\" Among\"[22395] (p=0.062, logit=18.500)', '\" Air\"[6690] (p=0.020, logit=17.375)', '\" G\"[480] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     int_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.671875, logit=20.875, token_id=47759, metadata=None))), (6690, (4, PredictedToken(token=' Air', prob=0.0203857421875, logit=17.375, token_id=6690, metadata=None))), (94091, (8, PredictedToken(token=' Tomato', prob=0.007476806640625, logit=16.375, token_id=94091, metadata=None))), (40090, (41, PredictedToken(token=' Pressure', prob=0.000255584716796875, logit=13.0, token_id=40090, metadata=None))), (42609, (300, PredictedToken(token=' Pine', prob=5.304813385009766e-06, logit=9.125, token_id=42609, metadata=None))), (84008, (1769, PredictedToken(token=' Sheep', prob=3.501772880554199e-07, logit=6.40625, token_id=84008, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:35 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     patch_prediction=['\" Rabbit\"[49431] (p=0.559, logit=20.500)', '\" The\"[578] (p=0.160, logit=19.250)', '\" Among\"[22395] (p=0.110, logit=18.875)', '\" A\"[362] (p=0.066, logit=18.375)', '\" Option\"[7104] (p=0.012, logit=16.625)']\n",
      "2025-09-16 09:44:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.816, logit=21.875)', '\" An\"[1556] (p=0.041, logit=18.875)', '\" The\"[578] (p=0.041, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.625)', '\" None\"[2290] (p=0.025, logit=18.375)']\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.81640625, logit=21.875, token_id=53889, metadata=None))), (30173, (19, PredictedToken(token=' Speaker', prob=0.00084686279296875, logit=15.0, token_id=30173, metadata=None))), (14588, (103, PredictedToken(token=' Dog', prob=2.5510787963867188e-05, logit=11.5, token_id=14588, metadata=None))), (87035, (380, PredictedToken(token=' Onion', prob=2.2351741790771484e-06, logit=9.0625, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.383, logit=19.750)', '\" Dog\"[14588] (p=0.383, logit=19.750)', '\" The\"[578] (p=0.052, logit=17.750)', '\" Onion\"[87035] (p=0.046, logit=17.625)', '\" Among\"[22395] (p=0.025, logit=17.000)']\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     int_track=OrderedDict([(14588, (2, PredictedToken(token=' Dog', prob=0.3828125, logit=19.75, token_id=14588, metadata=None))), (87035, (4, PredictedToken(token=' Onion', prob=0.045654296875, logit=17.625, token_id=87035, metadata=None))), (30173, (135, PredictedToken(token=' Speaker', prob=4.172325134277344e-05, logit=10.625, token_id=30173, metadata=None))), (53889, (158, PredictedToken(token=' Apartment', prob=3.0517578125e-05, logit=10.3125, token_id=53889, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:36 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:36 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     patch_prediction=['\" Cabinet\"[34046] (p=0.922, logit=22.000)', '\" The\"[578] (p=0.025, logit=18.375)', '\" cabinet\"[22685] (p=0.009, logit=17.375)', '\" (\"[320] (p=0.007, logit=17.125)', '\" A\"[362] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.867, logit=22.625)', '\" The\"[578] (p=0.071, logit=20.125)', '\" Among\"[22395] (p=0.034, logit=19.375)', '\" It\"[1102] (p=0.007, logit=17.750)', '\" A\"[362] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.8671875, logit=22.625, token_id=6031, metadata=None))), (70762, (148, PredictedToken(token=' Motorcycle', prob=5.334615707397461e-06, logit=10.625, token_id=70762, metadata=None))), (36358, (280, PredictedToken(token=' Bench', prob=1.8402934074401855e-06, logit=9.5625, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     int_prediction=['\" Bench\"[36358] (p=0.734, logit=21.375)', '\" The\"[578] (p=0.113, logit=19.500)', '\" A\"[362] (p=0.053, logit=18.750)', '\" Among\"[22395] (p=0.042, logit=18.500)', '\" It\"[1102] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     int_track=OrderedDict([(36358, (1, PredictedToken(token=' Bench', prob=0.734375, logit=21.375, token_id=36358, metadata=None))), (70762, (6, PredictedToken(token=' Motorcycle', prob=0.0081787109375, logit=16.875, token_id=70762, metadata=None))), (6031, (89, PredictedToken(token=' Bro', prob=3.337860107421875e-05, logit=11.375, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:36 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     patch_prediction=['\" Pin\"[17929] (p=0.789, logit=21.125)', '\" None\"[2290] (p=0.073, logit=18.750)', '\" A\"[362] (p=0.039, logit=18.125)', '\" The\"[578] (p=0.024, logit=17.625)', '\" PIN\"[28228] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.781, logit=20.750)', '\" The\"[578] (p=0.073, logit=18.375)', '\" Among\"[22395] (p=0.034, logit=17.625)', '\" A\"[362] (p=0.021, logit=17.125)', '\" Option\"[7104] (p=0.009, logit=16.250)']\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.78125, logit=20.75, token_id=67629, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.00677490234375, logit=16.0, token_id=23262, metadata=None))), (426, (24, PredictedToken(token=' B', prob=0.00103759765625, logit=14.125, token_id=426, metadata=None))), (37326, (74, PredictedToken(token=' Swe', prob=8.535385131835938e-05, logit=11.625, token_id=37326, metadata=None))), (48665, (637, PredictedToken(token=' Raspberry', prob=2.205371856689453e-06, logit=7.96875, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     int_prediction=['\" B\"[426] (p=0.656, logit=20.500)', '\" Swe\"[37326] (p=0.114, logit=18.750)', '\" The\"[578] (p=0.048, logit=17.875)', '\" Among\"[22395] (p=0.042, logit=17.750)', '\" A\"[362] (p=0.025, logit=17.250)']\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     int_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.65625, logit=20.5, token_id=426, metadata=None))), (37326, (2, PredictedToken(token=' Swe', prob=0.1142578125, logit=18.75, token_id=37326, metadata=None))), (23262, (6, PredictedToken(token=' Comb', prob=0.025390625, logit=17.25, token_id=23262, metadata=None))), (48665, (40, PredictedToken(token=' Raspberry', prob=0.000362396240234375, logit=13.0, token_id=48665, metadata=None))), (67629, (142, PredictedToken(token=' Helmet', prob=2.8014183044433594e-05, logit=10.4375, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:37 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:37 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     patch_prediction=['\" Project\"[5907] (p=0.738, logit=21.000)', '\" The\"[578] (p=0.069, logit=18.625)', '\" Among\"[22395] (p=0.053, logit=18.375)', '\" Pepper\"[52882] (p=0.037, logit=18.000)', '\" A\"[362] (p=0.029, logit=17.750)']\n",
      "2025-09-16 09:44:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.738, logit=22.000)', '\" The\"[578] (p=0.146, logit=20.375)', '\" A\"[362] (p=0.047, logit=19.250)', '\" Among\"[22395] (p=0.032, logit=18.875)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.73828125, logit=22.0, token_id=31181, metadata=None))), (16183, (113, PredictedToken(token=' Hel', prob=1.3172626495361328e-05, logit=11.0625, token_id=16183, metadata=None))), (17929, (174, PredictedToken(token=' Pin', prob=5.4836273193359375e-06, logit=10.1875, token_id=17929, metadata=None))), (11896, (286, PredictedToken(token=' Library', prob=2.1457672119140625e-06, logit=9.25, token_id=11896, metadata=None))), (57225, (628, PredictedToken(token=' Laptop', prob=6.146728992462158e-07, logit=8.0, token_id=57225, metadata=None))), (38258, (643, PredictedToken(token=' Baseball', prob=5.960464477539062e-07, logit=7.96875, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     int_prediction=['\" Laptop\"[57225] (p=0.707, logit=21.375)', '\" Hel\"[16183] (p=0.109, logit=19.500)', '\" The\"[578] (p=0.075, logit=19.125)', '\" Among\"[22395] (p=0.051, logit=18.750)', '\" A\"[362] (p=0.017, logit=17.625)']\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     int_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.70703125, logit=21.375, token_id=57225, metadata=None))), (16183, (2, PredictedToken(token=' Hel', prob=0.10888671875, logit=19.5, token_id=16183, metadata=None))), (11896, (8, PredictedToken(token=' Library', prob=0.0021209716796875, logit=15.5625, token_id=11896, metadata=None))), (17929, (9, PredictedToken(token=' Pin', prob=0.0021209716796875, logit=15.5625, token_id=17929, metadata=None))), (38258, (49, PredictedToken(token=' Baseball', prob=0.00012683868408203125, logit=12.75, token_id=38258, metadata=None))), (31181, (188, PredictedToken(token=' Clar', prob=8.106231689453125e-06, logit=10.0, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:38 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.852, logit=22.375)', '\" The\"[578] (p=0.070, logit=19.875)', '\" A\"[362] (p=0.029, logit=19.000)', '\" Among\"[22395] (p=0.018, logit=18.500)', '\" Pine\"[42609] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.781, logit=20.500)', '\" The\"[578] (p=0.057, logit=17.875)', '\" Among\"[22395] (p=0.034, logit=17.375)', '\" A\"[362] (p=0.027, logit=17.125)', '\" Peach\"[64695] (p=0.014, logit=16.500)']\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.78125, logit=20.5, token_id=79028, metadata=None))), (64695, (5, PredictedToken(token=' Peach', prob=0.01434326171875, logit=16.5, token_id=64695, metadata=None))), (13120, (18, PredictedToken(token=' Night', prob=0.0015106201171875, logit=14.25, token_id=13120, metadata=None))), (1183, (19, PredictedToken(token=' Tr', prob=0.00110626220703125, logit=13.9375, token_id=1183, metadata=None))), (13597, (51, PredictedToken(token=' Pen', prob=0.000217437744140625, logit=12.3125, token_id=13597, metadata=None)))])\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.699, logit=20.875)', '\" Among\"[22395] (p=0.057, logit=18.375)', '\" Pen\"[13597] (p=0.045, logit=18.125)', '\" The\"[578] (p=0.045, logit=18.125)', '\" A\"[362] (p=0.045, logit=18.125)']\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.69921875, logit=20.875, token_id=64695, metadata=None))), (13597, (5, PredictedToken(token=' Pen', prob=0.044677734375, logit=18.125, token_id=13597, metadata=None))), (13120, (7, PredictedToken(token=' Night', prob=0.02392578125, logit=17.5, token_id=13120, metadata=None))), (1183, (44, PredictedToken(token=' Tr', prob=0.000301361083984375, logit=13.125, token_id=1183, metadata=None))), (79028, (86, PredictedToken(token=' Hick', prob=8.630752563476562e-05, logit=11.875, token_id=79028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:38 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:44:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     patch_prediction=['\" Razor\"[74968] (p=0.910, logit=21.375)', '\" The\"[578] (p=0.019, logit=17.500)', '\" Among\"[22395] (p=0.013, logit=17.125)', '\" A\"[362] (p=0.013, logit=17.125)', '\" R\"[432] (p=0.005, logit=16.250)']\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.432, logit=19.500)', '\" None\"[2290] (p=0.381, logit=19.375)', '\" Magn\"[20918] (p=0.021, logit=16.500)', '\" There\"[2684] (p=0.021, logit=16.500)', '\" Tennis\"[58251] (p=0.019, logit=16.375)']\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.431640625, logit=19.5, token_id=10573, metadata=None))), (20918, (4, PredictedToken(token=' Magn', prob=0.021484375, logit=16.5, token_id=20918, metadata=None))), (58251, (5, PredictedToken(token=' Tennis', prob=0.0189208984375, logit=16.375, token_id=58251, metadata=None))), (36358, (9, PredictedToken(token=' Bench', prob=0.01080322265625, logit=15.8125, token_id=36358, metadata=None))), (41445, (26, PredictedToken(token=' Television', prob=0.000885009765625, logit=13.3125, token_id=41445, metadata=None))), (48471, (28, PredictedToken(token=' Shower', prob=0.00083160400390625, logit=13.25, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     int_prediction=['\" Watch\"[10573] (p=0.672, logit=21.125)', '\" None\"[2290] (p=0.192, logit=19.875)', '\" Bench\"[36358] (p=0.033, logit=18.125)', '\" There\"[2684] (p=0.018, logit=17.500)', '\" The\"[578] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     int_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.671875, logit=21.125, token_id=10573, metadata=None))), (36358, (3, PredictedToken(token=' Bench', prob=0.033447265625, logit=18.125, token_id=36358, metadata=None))), (48471, (8, PredictedToken(token=' Shower', prob=0.005828857421875, logit=16.375, token_id=48471, metadata=None))), (58251, (22, PredictedToken(token=' Tennis', prob=0.000652313232421875, logit=14.1875, token_id=58251, metadata=None))), (41445, (33, PredictedToken(token=' Television', prob=0.0003719329833984375, logit=13.625, token_id=41445, metadata=None))), (20918, (32, PredictedToken(token=' Magn', prob=0.0003719329833984375, logit=13.625, token_id=20918, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:39 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:39 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:44:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.566, logit=20.750)', '\" The\"[578] (p=0.236, logit=19.875)', '\" Among\"[22395] (p=0.087, logit=18.875)', '\" A\"[362] (p=0.053, logit=18.375)', '\" It\"[1102] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     clean_prediction=['\" Plum\"[84409] (p=0.734, logit=21.125)', '\" The\"[578] (p=0.099, logit=19.125)', '\" A\"[362] (p=0.060, logit=18.625)', '\" Among\"[22395] (p=0.053, logit=18.500)', '\" Option\"[7104] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     clean_track=OrderedDict([(84409, (1, PredictedToken(token=' Plum', prob=0.734375, logit=21.125, token_id=84409, metadata=None))), (58937, (86, PredictedToken(token=' Monkey', prob=3.123283386230469e-05, logit=11.0625, token_id=58937, metadata=None))), (5340, (91, PredictedToken(token=' Har', prob=2.765655517578125e-05, logit=10.9375, token_id=5340, metadata=None))), (100031, (137, PredictedToken(token=' Mosque', prob=1.4781951904296875e-05, logit=10.3125, token_id=100031, metadata=None))), (91263, (328, PredictedToken(token=' Binder', prob=3.293156623840332e-06, logit=8.8125, token_id=91263, metadata=None))), (58251, (607, PredictedToken(token=' Tennis', prob=1.3336539268493652e-06, logit=7.90625, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.574, logit=20.250)', '\" The\"[578] (p=0.128, logit=18.750)', '\" Binder\"[91263] (p=0.068, logit=18.125)', '\" Among\"[22395] (p=0.060, logit=18.000)', '\" A\"[362] (p=0.047, logit=17.750)']\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.57421875, logit=20.25, token_id=5340, metadata=None))), (91263, (3, PredictedToken(token=' Binder', prob=0.068359375, logit=18.125, token_id=91263, metadata=None))), (58251, (6, PredictedToken(token=' Tennis', prob=0.046875, logit=17.75, token_id=58251, metadata=None))), (100031, (9, PredictedToken(token=' Mosque', prob=0.007659912109375, logit=15.9375, token_id=100031, metadata=None))), (58937, (11, PredictedToken(token=' Monkey', prob=0.0028228759765625, logit=14.9375, token_id=58937, metadata=None))), (84409, (899, PredictedToken(token=' Plum', prob=1.2516975402832031e-06, logit=7.21875, token_id=84409, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:40 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.887, logit=21.500)', '\" Among\"[22395] (p=0.039, logit=18.375)', '\" The\"[578] (p=0.030, logit=18.125)', '\" tooth\"[26588] (p=0.004, logit=16.125)', '\" Out\"[4470] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     clean_prediction=['\" Mosque\"[100031] (p=0.824, logit=21.750)', '\" A\"[362] (p=0.068, logit=19.250)', '\" The\"[578] (p=0.060, logit=19.125)', '\" Among\"[22395] (p=0.013, logit=17.625)', '\" It\"[1102] (p=0.004, logit=16.500)']\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     clean_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.82421875, logit=21.75, token_id=100031, metadata=None))), (34954, (177, PredictedToken(token=' Mirror', prob=6.5267086029052734e-06, logit=10.0, token_id=34954, metadata=None))), (33199, (236, PredictedToken(token=' Lion', prob=3.7103891372680664e-06, logit=9.4375, token_id=33199, metadata=None))), (16344, (441, PredictedToken(token=' Rose', prob=1.3634562492370605e-06, logit=8.4375, token_id=16344, metadata=None))), (8325, (438, PredictedToken(token=' Apple', prob=1.3634562492370605e-06, logit=8.4375, token_id=8325, metadata=None)))])\n",
      "2025-09-16 09:44:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     int_prediction=['\" Apple\"[8325] (p=0.617, logit=21.000)', '\" The\"[578] (p=0.107, logit=19.250)', '\" Rose\"[16344] (p=0.065, logit=18.750)', '\" Among\"[22395] (p=0.057, logit=18.625)', '\" Mirror\"[34954] (p=0.051, logit=18.500)']\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     int_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.6171875, logit=21.0, token_id=8325, metadata=None))), (16344, (3, PredictedToken(token=' Rose', prob=0.06494140625, logit=18.75, token_id=16344, metadata=None))), (34954, (5, PredictedToken(token=' Mirror', prob=0.050537109375, logit=18.5, token_id=34954, metadata=None))), (33199, (31, PredictedToken(token=' Lion', prob=0.00049591064453125, logit=13.875, token_id=33199, metadata=None))), (100031, (43, PredictedToken(token=' Mosque', prob=0.0002498626708984375, logit=13.1875, token_id=100031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:41 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:41 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     patch_prediction=['\" Mixer\"[72392] (p=0.602, logit=20.750)', '\" The\"[578] (p=0.134, logit=19.250)', '\" A\"[362] (p=0.104, logit=19.000)', '\" Among\"[22395] (p=0.056, logit=18.375)', '\" Option\"[7104] (p=0.030, logit=17.750)']\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.605, logit=22.500)', '\" An\"[1556] (p=0.173, logit=21.250)', '\" The\"[578] (p=0.119, logit=20.875)', '\" Among\"[22395] (p=0.056, logit=20.125)', '\" e\"[384] (p=0.018, logit=19.000)']\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.60546875, logit=22.5, token_id=469, metadata=None))), (16344, (13, PredictedToken(token=' Rose', prob=0.0008544921875, logit=15.9375, token_id=16344, metadata=None))), (39247, (30, PredictedToken(token=' Slow', prob=0.00019073486328125, logit=14.4375, token_id=39247, metadata=None))), (16488, (119, PredictedToken(token=' Bat', prob=8.881092071533203e-06, logit=11.375, token_id=16488, metadata=None))), (36358, (263, PredictedToken(token=' Bench', prob=1.646578311920166e-06, logit=9.6875, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     int_prediction=['\" Slow\"[39247] (p=0.617, logit=21.875)', '\" Rose\"[16344] (p=0.122, logit=20.250)', '\" Among\"[22395] (p=0.107, logit=20.125)', '\" The\"[578] (p=0.095, logit=20.000)', '\" It\"[1102] (p=0.015, logit=18.125)']\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     int_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.6171875, logit=21.875, token_id=39247, metadata=None))), (16344, (2, PredictedToken(token=' Rose', prob=0.12158203125, logit=20.25, token_id=16344, metadata=None))), (16488, (52, PredictedToken(token=' Bat', prob=9.1552734375e-05, logit=13.0625, token_id=16488, metadata=None))), (469, (103, PredictedToken(token=' E', prob=2.0503997802734375e-05, logit=11.5625, token_id=469, metadata=None))), (36358, (141, PredictedToken(token=' Bench', prob=1.0967254638671875e-05, logit=10.9375, token_id=36358, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:41 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:41 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:44:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     patch_prediction=['\" Drum\"[46506] (p=0.867, logit=21.875)', '\" Option\"[7104] (p=0.030, logit=18.500)', '\" The\"[578] (p=0.023, logit=18.250)', '\" (\"[320] (p=0.020, logit=18.125)', '\" d\"[294] (p=0.008, logit=17.250)']\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.926, logit=22.875)', '\" The\"[578] (p=0.028, logit=19.375)', '\" Among\"[22395] (p=0.010, logit=18.375)', '\" A\"[362] (p=0.007, logit=18.000)', '\" (\"[320] (p=0.007, logit=18.000)']\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.92578125, logit=22.875, token_id=356, metadata=None))), (58600, (642, PredictedToken(token=' Charm', prob=4.116445779800415e-07, logit=8.25, token_id=58600, metadata=None)))])\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.777, logit=21.125)', '\" Charm\"[58600] (p=0.064, logit=18.625)', '\" The\"[578] (p=0.044, logit=18.250)', '\" Option\"[7104] (p=0.018, logit=17.375)', '\" (\"[320] (p=0.014, logit=17.125)']\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.77734375, logit=21.125, token_id=356, metadata=None))), (58600, (2, PredictedToken(token=' Charm', prob=0.06396484375, logit=18.625, token_id=58600, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:42 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     patch_prediction=['\" Sofa\"[61948] (p=0.641, logit=21.250)', '\" The\"[578] (p=0.143, logit=19.750)', '\" Among\"[22395] (p=0.076, logit=19.125)', '\" A\"[362] (p=0.059, logit=18.875)', '\" Option\"[7104] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     clean_prediction=['\" Stap\"[63606] (p=0.750, logit=20.750)', '\" The\"[578] (p=0.089, logit=18.625)', '\" A\"[362] (p=0.054, logit=18.125)', '\" Among\"[22395] (p=0.042, logit=17.875)', '\" stap\"[36114] (p=0.012, logit=16.625)']\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     clean_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.75, logit=20.75, token_id=63606, metadata=None))), (20918, (36, PredictedToken(token=' Magn', prob=0.00038909912109375, logit=13.1875, token_id=20918, metadata=None))), (57915, (90, PredictedToken(token=' Ank', prob=5.269050598144531e-05, logit=11.1875, token_id=57915, metadata=None))), (6690, (95, PredictedToken(token=' Air', prob=4.649162292480469e-05, logit=11.0625, token_id=6690, metadata=None))), (34046, (131, PredictedToken(token=' Cabinet', prob=2.6464462280273438e-05, logit=10.5, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:44:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     int_prediction=['\" Magn\"[20918] (p=0.385, logit=19.125)', '\" Among\"[22395] (p=0.233, logit=18.625)', '\" The\"[578] (p=0.098, logit=17.750)', '\" None\"[2290] (p=0.086, logit=17.625)', '\" Option\"[7104] (p=0.041, logit=16.875)']\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     int_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.384765625, logit=19.125, token_id=20918, metadata=None))), (34046, (15, PredictedToken(token=' Cabinet', prob=0.005157470703125, logit=14.8125, token_id=34046, metadata=None))), (57915, (154, PredictedToken(token=' Ank', prob=5.054473876953125e-05, logit=10.1875, token_id=57915, metadata=None))), (63606, (197, PredictedToken(token=' Stap', prob=3.075599670410156e-05, logit=9.6875, token_id=63606, metadata=None))), (6690, (221, PredictedToken(token=' Air', prob=2.5510787963867188e-05, logit=9.5, token_id=6690, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:43 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.828, logit=21.750)', '\" The\"[578] (p=0.047, logit=18.875)', '\" A\"[362] (p=0.047, logit=18.875)', '\" Among\"[22395] (p=0.025, logit=18.250)', '\" None\"[2290] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     clean_prediction=['\" Book\"[6017] (p=0.789, logit=21.875)', '\" The\"[578] (p=0.074, logit=19.500)', '\" Among\"[22395] (p=0.045, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.625)', '\" Bro\"[6031] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     clean_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.7890625, logit=21.875, token_id=6017, metadata=None))), (6031, (5, PredictedToken(token=' Bro', prob=0.0087890625, logit=17.375, token_id=6031, metadata=None))), (469, (19, PredictedToken(token=' E', prob=0.0010528564453125, logit=15.25, token_id=469, metadata=None))), (19176, (27, PredictedToken(token=' Temple', prob=0.000560760498046875, logit=14.625, token_id=19176, metadata=None))), (47643, (138, PredictedToken(token=' Cel', prob=1.239776611328125e-05, logit=10.8125, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.918, logit=22.250)', '\" The\"[578] (p=0.022, logit=18.500)', '\" Among\"[22395] (p=0.019, logit=18.375)', '\" TEM\"[76770] (p=0.005, logit=17.125)', '\" (\"[320] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.91796875, logit=22.25, token_id=19176, metadata=None))), (469, (21, PredictedToken(token=' E', prob=0.0002899169921875, logit=14.1875, token_id=469, metadata=None))), (6031, (52, PredictedToken(token=' Bro', prob=6.437301635742188e-05, logit=12.6875, token_id=6031, metadata=None))), (6017, (107, PredictedToken(token=' Book', prob=1.1920928955078125e-05, logit=11.0, token_id=6017, metadata=None))), (47643, (214, PredictedToken(token=' Cel', prob=3.2186508178710938e-06, logit=9.6875, token_id=47643, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:43 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:44:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.871, logit=21.625)', '\" An\"[1556] (p=0.043, logit=18.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" Among\"[22395] (p=0.007, logit=16.750)', '\" It\"[1102] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     clean_prediction=['\" Rose\"[16344] (p=0.867, logit=22.625)', '\" The\"[578] (p=0.043, logit=19.625)', '\" A\"[362] (p=0.043, logit=19.625)', '\" Among\"[22395] (p=0.012, logit=18.375)', '\" rose\"[16392] (p=0.011, logit=18.250)']\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     clean_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.8671875, logit=22.625, token_id=16344, metadata=None))), (57094, (27, PredictedToken(token=' Highlight', prob=0.000255584716796875, logit=14.5, token_id=57094, metadata=None))), (16488, (53, PredictedToken(token=' Bat', prob=4.744529724121094e-05, logit=12.8125, token_id=16488, metadata=None)))])\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.801, logit=22.375)', '\" Bat\"[16488] (p=0.123, logit=20.500)', '\" The\"[578] (p=0.027, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.750)', '\" Among\"[22395] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.80078125, logit=22.375, token_id=57094, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.123046875, logit=20.5, token_id=16488, metadata=None))), (16344, (28, PredictedToken(token=' Rose', prob=0.0001735687255859375, logit=13.9375, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:44 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     patch_prediction=['\" Potato\"[78703] (p=0.828, logit=21.750)', '\" The\"[578] (p=0.060, logit=19.125)', '\" Among\"[22395] (p=0.047, logit=18.875)', '\" A\"[362] (p=0.028, logit=18.375)', '\" Pot\"[14020] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     clean_prediction=['\" Hospital\"[15429] (p=0.914, logit=22.875)', '\" Among\"[22395] (p=0.021, logit=19.125)', '\" The\"[578] (p=0.021, logit=19.125)', '\" A\"[362] (p=0.017, logit=18.875)', '\" It\"[1102] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     clean_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.9140625, logit=22.875, token_id=15429, metadata=None))), (3341, (11, PredictedToken(token=' Car', prob=0.000888824462890625, logit=15.9375, token_id=3341, metadata=None))), (6914, (14, PredictedToken(token=' Let', prob=0.000690460205078125, logit=15.6875, token_id=6914, metadata=None))), (13394, (24, PredictedToken(token=' Bed', prob=0.0003261566162109375, logit=14.9375, token_id=13394, metadata=None))), (61731, (57, PredictedToken(token=' Soap', prob=6.866455078125e-05, logit=13.375, token_id=61731, metadata=None))), (30173, (58, PredictedToken(token=' Speaker', prob=6.437301635742188e-05, logit=13.3125, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:44:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     int_prediction=['\" Let\"[6914] (p=0.777, logit=21.000)', '\" Among\"[22395] (p=0.056, logit=18.375)', '\" The\"[578] (p=0.056, logit=18.375)', '\" None\"[2290] (p=0.021, logit=17.375)', '\" Speaker\"[30173] (p=0.018, logit=17.250)']\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     int_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.77734375, logit=21.0, token_id=6914, metadata=None))), (30173, (5, PredictedToken(token=' Speaker', prob=0.018310546875, logit=17.25, token_id=30173, metadata=None))), (13394, (29, PredictedToken(token=' Bed', prob=0.0004863739013671875, logit=13.625, token_id=13394, metadata=None))), (61731, (66, PredictedToken(token=' Soap', prob=0.00012302398681640625, logit=12.25, token_id=61731, metadata=None))), (15429, (155, PredictedToken(token=' Hospital', prob=2.002716064453125e-05, logit=10.4375, token_id=15429, metadata=None))), (3341, (170, PredictedToken(token=' Car', prob=1.5616416931152344e-05, logit=10.1875, token_id=3341, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:45 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.758, logit=22.125)', '\" The\"[578] (p=0.090, logit=20.000)', '\" Among\"[22395] (p=0.062, logit=19.625)', '\" A\"[362] (p=0.048, logit=19.375)', '\" z\"[1167] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     clean_prediction=['\" Air\"[6690] (p=0.676, logit=22.375)', '\" An\"[1556] (p=0.171, logit=21.000)', '\" The\"[578] (p=0.063, logit=20.000)', '\" Among\"[22395] (p=0.056, logit=19.875)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     clean_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.67578125, logit=22.375, token_id=6690, metadata=None))), (469, (23, PredictedToken(token=' E', prob=0.0004520416259765625, logit=15.0625, token_id=469, metadata=None))), (24941, (29, PredictedToken(token=' Bear', prob=0.00037384033203125, logit=14.875, token_id=24941, metadata=None))), (735, (82, PredictedToken(token=' K', prob=2.396106719970703e-05, logit=12.125, token_id=735, metadata=None))), (86460, (1132, PredictedToken(token=' Necklace', prob=1.7136335372924805e-07, logit=7.1875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     int_prediction=['\" Bear\"[24941] (p=0.805, logit=22.375)', '\" Among\"[22395] (p=0.075, logit=20.000)', '\" The\"[578] (p=0.066, logit=19.875)', '\" E\"[469] (p=0.008, logit=17.750)', '\" A\"[362] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     int_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.8046875, logit=22.375, token_id=24941, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.00787353515625, logit=17.75, token_id=469, metadata=None))), (735, (57, PredictedToken(token=' K', prob=5.316734313964844e-05, logit=12.75, token_id=735, metadata=None))), (6690, (257, PredictedToken(token=' Air', prob=2.1904706954956055e-06, logit=9.5625, token_id=6690, metadata=None))), (86460, (270, PredictedToken(token=' Necklace', prob=2.0563602447509766e-06, logit=9.5, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:45 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:45 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:44:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     patch_prediction=['\" Sax\"[68027] (p=0.676, logit=21.125)', '\" The\"[578] (p=0.171, logit=19.750)', '\" A\"[362] (p=0.056, logit=18.625)', '\" Among\"[22395] (p=0.043, logit=18.375)', '\" It\"[1102] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.891, logit=21.875)', '\" The\"[578] (p=0.039, logit=18.750)', '\" Among\"[22395] (p=0.035, logit=18.625)', '\" A\"[362] (p=0.002, logit=15.875)', '\" (\"[320] (p=0.002, logit=15.875)']\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.890625, logit=21.875, token_id=72683, metadata=None))), (24941, (17, PredictedToken(token=' Bear', prob=0.000675201416015625, logit=14.6875, token_id=24941, metadata=None))), (45332, (31, PredictedToken(token=' Boat', prob=0.0002994537353515625, logit=13.875, token_id=45332, metadata=None))), (47759, (45, PredictedToken(token=' Guitar', prob=0.0001811981201171875, logit=13.375, token_id=47759, metadata=None))), (3816, (72, PredictedToken(token=' Red', prob=6.67572021484375e-05, logit=12.375, token_id=3816, metadata=None))), (48665, (215, PredictedToken(token=' Raspberry', prob=4.827976226806641e-06, logit=9.75, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     int_prediction=['\" The\"[578] (p=0.206, logit=18.125)', '\" Raspberry\"[48665] (p=0.206, logit=18.125)', '\" Among\"[22395] (p=0.182, logit=18.000)', '\" Guitar\"[47759] (p=0.142, logit=17.750)', '\" A\"[362] (p=0.059, logit=16.875)']\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     int_track=OrderedDict([(48665, (2, PredictedToken(token=' Raspberry', prob=0.2060546875, logit=18.125, token_id=48665, metadata=None))), (47759, (4, PredictedToken(token=' Guitar', prob=0.1416015625, logit=17.75, token_id=47759, metadata=None))), (3816, (6, PredictedToken(token=' Red', prob=0.031494140625, logit=16.25, token_id=3816, metadata=None))), (24941, (11, PredictedToken(token=' Bear', prob=0.00848388671875, logit=14.9375, token_id=24941, metadata=None))), (72683, (36, PredictedToken(token=' Boxing', prob=0.001220703125, logit=13.0, token_id=72683, metadata=None))), (45332, (42, PredictedToken(token=' Boat', prob=0.00095367431640625, logit=12.75, token_id=45332, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:46 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:46 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     patch_prediction=['\" Dish\"[49268] (p=0.695, logit=21.500)', '\" The\"[578] (p=0.121, logit=19.750)', '\" A\"[362] (p=0.083, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.875)', '\" It\"[1102] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:44:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     clean_prediction=['\" Hair\"[26781] (p=0.617, logit=20.500)', '\" None\"[2290] (p=0.227, logit=19.500)', '\" Let\"[6914] (p=0.027, logit=17.375)', '\" D\"[423] (p=0.027, logit=17.375)', '\" The\"[578] (p=0.019, logit=17.000)']\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     clean_track=OrderedDict([(26781, (1, PredictedToken(token=' Hair', prob=0.6171875, logit=20.5, token_id=26781, metadata=None))), (423, (3, PredictedToken(token=' D', prob=0.027099609375, logit=17.375, token_id=423, metadata=None))), (6914, (4, PredictedToken(token=' Let', prob=0.027099609375, logit=17.375, token_id=6914, metadata=None))), (98641, (10, PredictedToken(token=' Microwave', prob=0.00390625, logit=15.4375, token_id=98641, metadata=None)))])\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     int_prediction=['\" None\"[2290] (p=0.598, logit=19.875)', '\" Microwave\"[98641] (p=0.281, logit=19.125)', '\" There\"[2684] (p=0.014, logit=16.125)', '\" The\"[578] (p=0.014, logit=16.125)', '\" Among\"[22395] (p=0.012, logit=16.000)']\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     int_track=OrderedDict([(98641, (2, PredictedToken(token=' Microwave', prob=0.28125, logit=19.125, token_id=98641, metadata=None))), (423, (6, PredictedToken(token=' D', prob=0.007049560546875, logit=15.4375, token_id=423, metadata=None))), (6914, (34, PredictedToken(token=' Let', prob=0.00045013427734375, logit=12.6875, token_id=6914, metadata=None))), (26781, (35, PredictedToken(token=' Hair', prob=0.00037384033203125, logit=12.5, token_id=26781, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:47 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:47 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.883, logit=22.000)', '\" The\"[578] (p=0.034, logit=18.750)', '\" A\"[362] (p=0.030, logit=18.625)', '\" Among\"[22395] (p=0.016, logit=18.000)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.703, logit=22.250)', '\" The\"[578] (p=0.122, logit=20.500)', '\" A\"[362] (p=0.095, logit=20.250)', '\" Among\"[22395] (p=0.040, logit=19.375)', '\" (\"[320] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.703125, logit=22.25, token_id=3341, metadata=None))), (36845, (27, PredictedToken(token=' Tiger', prob=0.0003223419189453125, logit=14.5625, token_id=36845, metadata=None))), (88088, (80, PredictedToken(token=' Birch', prob=2.193450927734375e-05, logit=11.875, token_id=88088, metadata=None))), (38673, (367, PredictedToken(token=' Yoga', prob=1.0207295417785645e-06, logit=8.8125, token_id=38673, metadata=None)))])\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     int_prediction=['\" Tiger\"[36845] (p=0.781, logit=21.750)', '\" Among\"[22395] (p=0.083, logit=19.500)', '\" The\"[578] (p=0.083, logit=19.500)', '\" A\"[362] (p=0.010, logit=17.375)', '\" (\"[320] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     int_track=OrderedDict([(36845, (1, PredictedToken(token=' Tiger', prob=0.78125, logit=21.75, token_id=36845, metadata=None))), (88088, (6, PredictedToken(token=' Birch', prob=0.005279541015625, logit=16.75, token_id=88088, metadata=None))), (3341, (47, PredictedToken(token=' Car', prob=0.0001316070556640625, logit=13.0625, token_id=3341, metadata=None))), (38673, (87, PredictedToken(token=' Yoga', prob=2.288818359375e-05, logit=11.3125, token_id=38673, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:47 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:47 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.957, logit=23.000)', '\" The\"[578] (p=0.020, logit=19.125)', '\" Among\"[22395] (p=0.012, logit=18.625)', '\" It\"[1102] (p=0.001, logit=16.500)', '\" A\"[362] (p=0.001, logit=16.500)']\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     clean_prediction=['\" Motorcycle\"[70762] (p=0.918, logit=23.125)', '\" The\"[578] (p=0.028, logit=19.625)', '\" A\"[362] (p=0.024, logit=19.500)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" Motor\"[18079] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     clean_track=OrderedDict([(70762, (1, PredictedToken(token=' Motorcycle', prob=0.91796875, logit=23.125, token_id=70762, metadata=None))), (1901, (138, PredictedToken(token=' Z', prob=3.635883331298828e-06, logit=10.6875, token_id=1901, metadata=None))), (48665, (309, PredictedToken(token=' Raspberry', prob=8.121132850646973e-07, logit=9.1875, token_id=48665, metadata=None))), (58600, (480, PredictedToken(token=' Charm', prob=3.8370490074157715e-07, logit=8.4375, token_id=58600, metadata=None))), (36358, (982, PredictedToken(token=' Bench', prob=1.4156103134155273e-07, logit=7.4375, token_id=36358, metadata=None)))])\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.766, logit=22.125)', '\" Among\"[22395] (p=0.081, logit=19.875)', '\" The\"[578] (p=0.081, logit=19.875)', '\" Charm\"[58600] (p=0.026, logit=18.750)', '\" Raspberry\"[48665] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.765625, logit=22.125, token_id=1901, metadata=None))), (58600, (4, PredictedToken(token=' Charm', prob=0.0262451171875, logit=18.75, token_id=58600, metadata=None))), (48665, (5, PredictedToken(token=' Raspberry', prob=0.0096435546875, logit=17.75, token_id=48665, metadata=None))), (36358, (101, PredictedToken(token=' Bench', prob=1.7523765563964844e-05, logit=11.4375, token_id=36358, metadata=None))), (70762, (265, PredictedToken(token=' Motorcycle', prob=2.682209014892578e-06, logit=9.5625, token_id=70762, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:48 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:48 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.875, logit=21.625)', '\" Among\"[22395] (p=0.030, logit=18.250)', '\" The\"[578] (p=0.030, logit=18.250)', '\" Option\"[7104] (p=0.009, logit=17.000)', '\" tooth\"[26588] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:44:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.668, logit=21.750)', '\" The\"[578] (p=0.148, logit=20.250)', '\" A\"[362] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.048, logit=19.125)', '\" Dress\"[29318] (p=0.020, logit=18.250)']\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.66796875, logit=21.75, token_id=55807, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.0201416015625, logit=18.25, token_id=29318, metadata=None))), (61731, (45, PredictedToken(token=' Soap', prob=0.00015354156494140625, logit=13.375, token_id=61731, metadata=None))), (3420, (62, PredictedToken(token=' Trump', prob=9.918212890625e-05, logit=12.9375, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.773, logit=22.125)', '\" The\"[578] (p=0.082, logit=19.875)', '\" Among\"[22395] (p=0.056, logit=19.500)', '\" Shirt\"[55807] (p=0.049, logit=19.375)', '\" It\"[1102] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.7734375, logit=22.125, token_id=61731, metadata=None))), (55807, (4, PredictedToken(token=' Shirt', prob=0.04931640625, logit=19.375, token_id=55807, metadata=None))), (3420, (15, PredictedToken(token=' Trump', prob=0.00066375732421875, logit=15.0625, token_id=3420, metadata=None))), (29318, (87, PredictedToken(token=' Dress', prob=2.562999725341797e-05, logit=11.8125, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:49 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:49 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     patch_prediction=['\" Ti\"[23126] (p=0.730, logit=21.875)', '\" The\"[578] (p=0.099, logit=19.875)', '\" A\"[362] (p=0.087, logit=19.750)', '\" Among\"[22395] (p=0.041, logit=19.000)', '\" It\"[1102] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.793, logit=22.125)', '\" A\"[362] (p=0.065, logit=19.625)', '\" The\"[578] (p=0.057, logit=19.500)', '\" Among\"[22395] (p=0.035, logit=19.000)', '\" slow\"[6435] (p=0.011, logit=17.875)']\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.79296875, logit=22.125, token_id=39247, metadata=None))), (469, (8, PredictedToken(token=' E', prob=0.00323486328125, logit=16.625, token_id=469, metadata=None))), (50159, (36, PredictedToken(token=' Sco', prob=0.0002651214599609375, logit=14.125, token_id=50159, metadata=None))), (24941, (77, PredictedToken(token=' Bear', prob=3.814697265625e-05, logit=12.1875, token_id=24941, metadata=None))), (17367, (138, PredictedToken(token=' Factory', prob=9.655952453613281e-06, logit=10.8125, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.773, logit=22.125)', '\" Among\"[22395] (p=0.063, logit=19.625)', '\" The\"[578] (p=0.056, logit=19.500)', '\" An\"[1556] (p=0.044, logit=19.250)', '\" Bear\"[24941] (p=0.013, logit=18.000)']\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.7734375, logit=22.125, token_id=469, metadata=None))), (24941, (5, PredictedToken(token=' Bear', prob=0.01251220703125, logit=18.0, token_id=24941, metadata=None))), (50159, (106, PredictedToken(token=' Sco', prob=1.4662742614746094e-05, logit=11.25, token_id=50159, metadata=None))), (17367, (181, PredictedToken(token=' Factory', prob=4.76837158203125e-06, logit=10.125, token_id=17367, metadata=None))), (39247, (1063, PredictedToken(token=' Slow', prob=2.3748725652694702e-07, logit=7.125, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:49 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:49 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:44:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     patch_prediction=['\" Er\"[9939] (p=0.676, logit=21.125)', '\" An\"[1556] (p=0.117, logit=19.375)', '\" The\"[578] (p=0.091, logit=19.125)', '\" Among\"[22395] (p=0.043, logit=18.375)', '\" E\"[469] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.746, logit=21.625)', '\" A\"[362] (p=0.089, logit=19.500)', '\" The\"[578] (p=0.069, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" Only\"[8442] (p=0.008, logit=17.125)']\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.74609375, logit=21.625, token_id=356, metadata=None))), (98028, (102, PredictedToken(token=' Bamboo', prob=2.47955322265625e-05, logit=11.3125, token_id=98028, metadata=None))), (36943, (161, PredictedToken(token=' Folder', prob=8.52346420288086e-06, logit=10.25, token_id=36943, metadata=None))), (91782, (441, PredictedToken(token=' Shorts', prob=1.3932585716247559e-06, logit=8.4375, token_id=91782, metadata=None)))])\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.707, logit=20.875)', '\" The\"[578] (p=0.084, logit=18.750)', '\" Among\"[22395] (p=0.074, logit=18.625)', '\" A\"[362] (p=0.035, logit=17.875)', '\" Shorts\"[91782] (p=0.013, logit=16.875)']\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.70703125, logit=20.875, token_id=36943, metadata=None))), (91782, (5, PredictedToken(token=' Shorts', prob=0.012939453125, logit=16.875, token_id=91782, metadata=None))), (356, (11, PredictedToken(token=' C', prob=0.0028839111328125, logit=15.375, token_id=356, metadata=None))), (98028, (26, PredictedToken(token=' Bamboo', prob=0.00106048583984375, logit=14.375, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:50 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     patch_prediction=['\" Head\"[11452] (p=0.727, logit=21.000)', '\" The\"[578] (p=0.126, logit=19.250)', '\" Among\"[22395] (p=0.052, logit=18.375)', '\" headphones\"[44101] (p=0.012, logit=16.875)', '\" \"[220] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:44:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.832, logit=21.500)', '\" The\"[578] (p=0.060, logit=18.875)', '\" A\"[362] (p=0.032, logit=18.250)', '\" Among\"[22395] (p=0.025, logit=18.000)', '\" Option\"[7104] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.83203125, logit=21.5, token_id=41342, metadata=None))), (29625, (9, PredictedToken(token=' Chain', prob=0.002197265625, logit=15.5625, token_id=29625, metadata=None))), (4923, (24, PredictedToken(token=' Sk', prob=0.000461578369140625, logit=14.0, token_id=4923, metadata=None))), (5907, (35, PredictedToken(token=' Project', prob=0.0002460479736328125, logit=13.375, token_id=5907, metadata=None))), (15429, (72, PredictedToken(token=' Hospital', prob=5.173683166503906e-05, logit=11.8125, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     int_prediction=['\" Project\"[5907] (p=0.871, logit=21.875)', '\" The\"[578] (p=0.038, logit=18.750)', '\" Among\"[22395] (p=0.023, logit=18.250)', '\" A\"[362] (p=0.014, logit=17.750)', '\" It\"[1102] (p=0.012, logit=17.625)']\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     int_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.87109375, logit=21.875, token_id=5907, metadata=None))), (29625, (15, PredictedToken(token=' Chain', prob=0.000957489013671875, logit=15.0625, token_id=29625, metadata=None))), (4923, (63, PredictedToken(token=' Sk', prob=6.532669067382812e-05, logit=12.375, token_id=4923, metadata=None))), (15429, (249, PredictedToken(token=' Hospital', prob=3.904104232788086e-06, logit=9.5625, token_id=15429, metadata=None))), (41342, (330, PredictedToken(token=' Hockey', prob=2.3692846298217773e-06, logit=9.0625, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:51 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:51 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     patch_prediction=['\" B\"[426] (p=0.734, logit=22.375)', '\" The\"[578] (p=0.099, logit=20.375)', '\" A\"[362] (p=0.087, logit=20.250)', '\" Among\"[22395] (p=0.025, logit=19.000)', '\" b\"[293] (p=0.017, logit=18.625)']\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.633, logit=21.750)', '\" The\"[578] (p=0.125, logit=20.125)', '\" Among\"[22395] (p=0.110, logit=20.000)', '\" A\"[362] (p=0.067, logit=19.500)', '\" Option\"[7104] (p=0.010, logit=17.625)']\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6328125, logit=21.75, token_id=27171, metadata=None))), (74968, (18, PredictedToken(token=' Razor', prob=0.000789642333984375, logit=15.0625, token_id=74968, metadata=None))), (445, (91, PredictedToken(token=' L', prob=2.5391578674316406e-05, logit=11.625, token_id=445, metadata=None))), (55807, (741, PredictedToken(token=' Shirt', prob=6.183981895446777e-07, logit=7.90625, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     int_prediction=['\" L\"[445] (p=0.750, logit=22.000)', '\" Among\"[22395] (p=0.090, logit=19.875)', '\" The\"[578] (p=0.054, logit=19.375)', '\" A\"[362] (p=0.033, logit=18.875)', '\" Option\"[7104] (p=0.029, logit=18.750)']\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     int_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.75, logit=22.0, token_id=445, metadata=None))), (74968, (8, PredictedToken(token=' Razor', prob=0.002716064453125, logit=16.375, token_id=74968, metadata=None))), (55807, (16, PredictedToken(token=' Shirt', prob=0.000934600830078125, logit=15.3125, token_id=55807, metadata=None))), (27171, (167, PredictedToken(token=' Coffee', prob=5.930662155151367e-06, logit=10.25, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:51 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:44:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.629, logit=20.750)', '\" Among\"[22395] (p=0.096, logit=18.875)', '\" The\"[578] (p=0.096, logit=18.875)', '\" An\"[1556] (p=0.096, logit=18.875)', '\" It\"[1102] (p=0.015, logit=17.000)']\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.586, logit=21.500)', '\" The\"[578] (p=0.148, logit=20.125)', '\" A\"[362] (p=0.148, logit=20.125)', '\" Among\"[22395] (p=0.070, logit=19.375)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.5859375, logit=21.5, token_id=34785, metadata=None))), (27738, (10, PredictedToken(token=' Ward', prob=0.0023956298828125, logit=16.0, token_id=27738, metadata=None))), (39247, (41, PredictedToken(token=' Slow', prob=0.00022220611572265625, logit=13.625, token_id=39247, metadata=None))), (57094, (58, PredictedToken(token=' Highlight', prob=0.00011205673217773438, logit=12.9375, token_id=57094, metadata=None))), (79189, (78, PredictedToken(token=' Elephant', prob=4.38690185546875e-05, logit=12.0, token_id=79189, metadata=None))), (74574, (1281, PredictedToken(token=' Violet', prob=3.4458935260772705e-07, logit=7.15625, token_id=74574, metadata=None)))])\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.832, logit=22.125)', '\" The\"[578] (p=0.060, logit=19.500)', '\" Among\"[22395] (p=0.053, logit=19.375)', '\" Slow\"[39247] (p=0.015, logit=18.125)', '\" A\"[362] (p=0.015, logit=18.125)']\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.83203125, logit=22.125, token_id=57094, metadata=None))), (39247, (5, PredictedToken(token=' Slow', prob=0.0152587890625, logit=18.125, token_id=39247, metadata=None))), (27738, (7, PredictedToken(token=' Ward', prob=0.001708984375, logit=15.9375, token_id=27738, metadata=None))), (74574, (12, PredictedToken(token=' Violet', prob=0.000972747802734375, logit=15.375, token_id=74574, metadata=None))), (79189, (842, PredictedToken(token=' Elephant', prob=4.600733518600464e-07, logit=7.71875, token_id=79189, metadata=None))), (34785, (1278, PredictedToken(token=' Truck', prob=2.7008354663848877e-07, logit=7.1875, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:52 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:52 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:44:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     patch_prediction=['\" Orange\"[22725] (p=0.887, logit=22.375)', '\" The\"[578] (p=0.034, logit=19.125)', '\" An\"[1556] (p=0.024, logit=18.750)', '\" Among\"[22395] (p=0.016, logit=18.375)', '\" orange\"[19087] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     clean_prediction=['\" Keyboard\"[26698] (p=0.754, logit=21.750)', '\" The\"[578] (p=0.102, logit=19.750)', '\" Among\"[22395] (p=0.055, logit=19.125)', '\" A\"[362] (p=0.029, logit=18.500)', '\" As\"[1666] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     clean_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.75390625, logit=21.75, token_id=26698, metadata=None))), (1666, (5, PredictedToken(token=' As', prob=0.00738525390625, logit=17.125, token_id=1666, metadata=None))), (356, (38, PredictedToken(token=' C', prob=0.00023746490478515625, logit=13.6875, token_id=356, metadata=None))), (4923, (154, PredictedToken(token=' Sk', prob=1.341104507446289e-05, logit=10.8125, token_id=4923, metadata=None))), (55807, (432, PredictedToken(token=' Shirt', prob=1.817941665649414e-06, logit=8.8125, token_id=55807, metadata=None))), (89077, (984, PredictedToken(token=' Strawberry', prob=5.21540641784668e-07, logit=7.5625, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     int_prediction=['\" Strawberry\"[89077] (p=0.482, logit=21.250)', '\" As\"[1666] (p=0.293, logit=20.750)', '\" Among\"[22395] (p=0.107, logit=19.750)', '\" The\"[578] (p=0.058, logit=19.125)', '\" Only\"[8442] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     int_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.482421875, logit=21.25, token_id=89077, metadata=None))), (1666, (2, PredictedToken(token=' As', prob=0.29296875, logit=20.75, token_id=1666, metadata=None))), (356, (55, PredictedToken(token=' C', prob=9.822845458984375e-05, logit=12.75, token_id=356, metadata=None))), (4923, (183, PredictedToken(token=' Sk', prob=9.715557098388672e-06, logit=10.4375, token_id=4923, metadata=None))), (55807, (243, PredictedToken(token=' Shirt', prob=5.543231964111328e-06, logit=9.875, token_id=55807, metadata=None))), (26698, (480, PredictedToken(token=' Keyboard', prob=1.5869736671447754e-06, logit=8.625, token_id=26698, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:53 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     patch_prediction=['\" Shower\"[48471] (p=0.531, logit=20.375)', '\" The\"[578] (p=0.173, logit=19.250)', '\" A\"[362] (p=0.135, logit=19.000)', '\" Among\"[22395] (p=0.082, logit=18.500)', '\" It\"[1102] (p=0.007, logit=16.000)']\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.773, logit=21.250)', '\" The\"[578] (p=0.072, logit=18.875)', '\" Among\"[22395] (p=0.044, logit=18.375)', '\" A\"[362] (p=0.044, logit=18.375)', '\" bear\"[11984] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.7734375, logit=21.25, token_id=24941, metadata=None))), (65449, (15, PredictedToken(token=' Willow', prob=0.002044677734375, logit=15.3125, token_id=65449, metadata=None))), (328, (21, PredictedToken(token=' S', prob=0.00080108642578125, logit=14.375, token_id=328, metadata=None))), (1443, (28, PredictedToken(token=' Sh', prob=0.00058746337890625, logit=14.0625, token_id=1443, metadata=None))), (80629, (332, PredictedToken(token=' Grape', prob=4.470348358154297e-06, logit=9.1875, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:44:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     int_prediction=['\" Sh\"[1443] (p=0.715, logit=20.500)', '\" S\"[328] (p=0.085, logit=18.375)', '\" Among\"[22395] (p=0.059, logit=18.000)', '\" The\"[578] (p=0.046, logit=17.750)', '\" None\"[2290] (p=0.012, logit=16.375)']\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     int_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.71484375, logit=20.5, token_id=1443, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.0849609375, logit=18.375, token_id=328, metadata=None))), (65449, (96, PredictedToken(token=' Willow', prob=5.6743621826171875e-05, logit=11.0625, token_id=65449, metadata=None))), (80629, (147, PredictedToken(token=' Grape', prob=2.682209014892578e-05, logit=10.3125, token_id=80629, metadata=None))), (24941, (230, PredictedToken(token=' Bear', prob=1.1920928955078125e-05, logit=9.5, token_id=24941, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:54 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:44:54 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.668, logit=22.250)', '\" An\"[1556] (p=0.169, logit=20.875)', '\" The\"[578] (p=0.090, logit=20.250)', '\" Among\"[22395] (p=0.038, logit=19.375)', '\" It\"[1102] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.762, logit=21.875)', '\" The\"[578] (p=0.091, logit=19.750)', '\" Among\"[22395] (p=0.055, logit=19.250)', '\" A\"[362] (p=0.049, logit=19.125)', '\" It\"[1102] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.76171875, logit=21.875, token_id=735, metadata=None))), (356, (9, PredictedToken(token=' C', prob=0.00177764892578125, logit=15.8125, token_id=356, metadata=None))), (16183, (18, PredictedToken(token=' Hel', prob=0.0008392333984375, logit=15.0625, token_id=16183, metadata=None))), (17810, (27, PredictedToken(token=' Cat', prob=0.000476837158203125, logit=14.5, token_id=17810, metadata=None))), (80629, (334, PredictedToken(token=' Grape', prob=1.952052116394043e-06, logit=9.0, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     int_prediction=['\" Hel\"[16183] (p=0.879, logit=22.125)', '\" Among\"[22395] (p=0.050, logit=19.250)', '\" The\"[578] (p=0.030, logit=18.750)', '\" None\"[2290] (p=0.009, logit=17.500)', '\" A\"[362] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     int_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.87890625, logit=22.125, token_id=16183, metadata=None))), (17810, (23, PredictedToken(token=' Cat', prob=0.0004558563232421875, logit=14.5625, token_id=17810, metadata=None))), (356, (46, PredictedToken(token=' C', prob=0.00010156631469726562, logit=13.0625, token_id=356, metadata=None))), (735, (116, PredictedToken(token=' K', prob=1.2934207916259766e-05, logit=11.0, token_id=735, metadata=None))), (80629, (681, PredictedToken(token=' Grape', prob=6.221234798431396e-07, logit=7.96875, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:54 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:44:54 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     patch_prediction=['\" Folder\"[36943] (p=0.762, logit=20.750)', '\" The\"[578] (p=0.071, logit=18.375)', '\" A\"[362] (p=0.071, logit=18.375)', '\" Among\"[22395] (p=0.014, logit=16.750)', '\" Let\"[6914] (p=0.014, logit=16.750)']\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     clean_prediction=['\" Mushroom\"[91297] (p=0.836, logit=21.375)', '\" The\"[578] (p=0.047, logit=18.500)', '\" A\"[362] (p=0.037, logit=18.250)', '\" None\"[2290] (p=0.020, logit=17.625)', '\" There\"[2684] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     clean_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.8359375, logit=21.375, token_id=91297, metadata=None))), (57094, (15, PredictedToken(token=' Highlight', prob=0.000812530517578125, logit=14.4375, token_id=57094, metadata=None))), (18191, (25, PredictedToken(token=' Mouse', prob=0.000408172607421875, logit=13.75, token_id=18191, metadata=None))), (432, (36, PredictedToken(token=' R', prob=0.00021839141845703125, logit=13.125, token_id=432, metadata=None))), (48035, (125, PredictedToken(token=' Gir', prob=1.800060272216797e-05, logit=10.625, token_id=48035, metadata=None))), (6690, (153, PredictedToken(token=' Air', prob=1.3947486877441406e-05, logit=10.375, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.656, logit=20.875)', '\" None\"[2290] (p=0.241, logit=19.875)', '\" The\"[578] (p=0.029, logit=17.750)', '\" There\"[2684] (p=0.020, logit=17.375)', '\" A\"[362] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.65625, logit=20.875, token_id=57094, metadata=None))), (18191, (10, PredictedToken(token=' Mouse', prob=0.00162506103515625, logit=14.875, token_id=18191, metadata=None))), (91297, (20, PredictedToken(token=' Mushroom', prob=0.000873565673828125, logit=14.25, token_id=91297, metadata=None))), (432, (21, PredictedToken(token=' R', prob=0.000720977783203125, logit=14.0625, token_id=432, metadata=None))), (6690, (239, PredictedToken(token=' Air', prob=8.52346420288086e-06, logit=9.625, token_id=6690, metadata=None))), (48035, (1580, PredictedToken(token=' Gir', prob=5.476176738739014e-07, logit=6.875, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:55 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     patch_prediction=['\" X\"[1630] (p=0.613, logit=22.500)', '\" The\"[578] (p=0.199, logit=21.375)', '\" A\"[362] (p=0.106, logit=20.750)', '\" Among\"[22395] (p=0.044, logit=19.875)', '\" It\"[1102] (p=0.010, logit=18.375)']\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     clean_prediction=['\" Let\"[6914] (p=0.820, logit=22.000)', '\" The\"[578] (p=0.086, logit=19.750)', '\" Among\"[22395] (p=0.052, logit=19.250)', '\" It\"[1102] (p=0.006, logit=17.000)', '\" Tr\"[1183] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     clean_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.8203125, logit=22.0, token_id=6914, metadata=None))), (1183, (5, PredictedToken(token=' Tr', prob=0.0037841796875, logit=16.625, token_id=1183, metadata=None))), (356, (7, PredictedToken(token=' C', prob=0.0026092529296875, logit=16.25, token_id=356, metadata=None))), (57748, (622, PredictedToken(token=' Cedar', prob=7.264316082000732e-07, logit=8.0625, token_id=57748, metadata=None)))])\n",
      "2025-09-16 09:44:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.820, logit=22.250)', '\" The\"[578] (p=0.076, logit=19.875)', '\" A\"[362] (p=0.019, logit=18.500)', '\" Among\"[22395] (p=0.017, logit=18.375)', '\" It\"[1102] (p=0.017, logit=18.375)']\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.8203125, logit=22.25, token_id=356, metadata=None))), (1183, (7, PredictedToken(token=' Tr', prob=0.01031494140625, logit=17.875, token_id=1183, metadata=None))), (57748, (42, PredictedToken(token=' Cedar', prob=0.0001010894775390625, logit=13.25, token_id=57748, metadata=None))), (6914, (56, PredictedToken(token=' Let', prob=5.7697296142578125e-05, logit=12.6875, token_id=6914, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:56 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:44:56 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.836, logit=21.500)', '\" Among\"[22395] (p=0.061, logit=18.875)', '\" The\"[578] (p=0.053, logit=18.750)', '\" SOAP\"[64332] (p=0.008, logit=16.875)', '\" A\"[362] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.832, logit=21.250)', '\" An\"[1556] (p=0.060, logit=18.625)', '\" The\"[578] (p=0.053, logit=18.500)', '\" IR\"[16646] (p=0.010, logit=16.875)', '\" Among\"[22395] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.83203125, logit=21.25, token_id=66821, metadata=None))), (33199, (42, PredictedToken(token=' Lion', prob=0.00019168853759765625, logit=12.875, token_id=33199, metadata=None))), (68554, (322, PredictedToken(token=' Gloves', prob=4.231929779052734e-06, logit=9.0625, token_id=68554, metadata=None))), (70110, (384, PredictedToken(token=' Ottoman', prob=3.293156623840332e-06, logit=8.8125, token_id=70110, metadata=None))), (74968, (471, PredictedToken(token=' Razor', prob=2.4139881134033203e-06, logit=8.5, token_id=74968, metadata=None))), (18654, (830, PredictedToken(token=' Micro', prob=1.0356307029724121e-06, logit=7.65625, token_id=18654, metadata=None)))])\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     int_prediction=['\" Gloves\"[68554] (p=0.582, logit=19.750)', '\" The\"[578] (p=0.089, logit=17.875)', '\" Glo\"[25372] (p=0.069, logit=17.625)', '\" Micro\"[18654] (p=0.054, logit=17.375)', '\" A\"[362] (p=0.054, logit=17.375)']\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     int_track=OrderedDict([(68554, (1, PredictedToken(token=' Gloves', prob=0.58203125, logit=19.75, token_id=68554, metadata=None))), (18654, (5, PredictedToken(token=' Micro', prob=0.05419921875, logit=17.375, token_id=18654, metadata=None))), (74968, (6, PredictedToken(token=' Razor', prob=0.0478515625, logit=17.25, token_id=74968, metadata=None))), (66821, (153, PredictedToken(token=' Iris', prob=4.363059997558594e-05, logit=10.25, token_id=66821, metadata=None))), (70110, (167, PredictedToken(token=' Ottoman', prob=3.838539123535156e-05, logit=10.125, token_id=70110, metadata=None))), (33199, (313, PredictedToken(token=' Lion', prob=1.329183578491211e-05, logit=9.0625, token_id=33199, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:56 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:56 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.777, logit=22.125)', '\" The\"[578] (p=0.082, logit=19.875)', '\" A\"[362] (p=0.064, logit=19.625)', '\" Among\"[22395] (p=0.039, logit=19.125)', '\" Option\"[7104] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     clean_prediction=['\" Sofa\"[61948] (p=0.711, logit=21.500)', '\" The\"[578] (p=0.123, logit=19.750)', '\" A\"[362] (p=0.058, logit=19.000)', '\" Among\"[22395] (p=0.040, logit=18.625)', '\" Option\"[7104] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     clean_track=OrderedDict([(61948, (1, PredictedToken(token=' Sofa', prob=0.7109375, logit=21.5, token_id=61948, metadata=None))), (816, (23, PredictedToken(token=' Y', prob=0.00064849853515625, logit=14.5, token_id=816, metadata=None))), (38258, (79, PredictedToken(token=' Baseball', prob=5.316734313964844e-05, logit=12.0, token_id=38258, metadata=None))), (32498, (169, PredictedToken(token=' Mall', prob=9.834766387939453e-06, logit=10.3125, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     int_prediction=['\" Y\"[816] (p=0.660, logit=21.375)', '\" Among\"[22395] (p=0.130, logit=19.750)', '\" The\"[578] (p=0.089, logit=19.375)', '\" Baseball\"[38258] (p=0.061, logit=19.000)', '\" A\"[362] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     int_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.66015625, logit=21.375, token_id=816, metadata=None))), (38258, (4, PredictedToken(token=' Baseball', prob=0.061279296875, logit=19.0, token_id=38258, metadata=None))), (32498, (133, PredictedToken(token=' Mall', prob=1.704692840576172e-05, logit=10.8125, token_id=32498, metadata=None))), (61948, (772, PredictedToken(token=' Sofa', prob=7.040798664093018e-07, logit=7.625, token_id=61948, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:57 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:57 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     patch_prediction=['\" Slow\"[39247] (p=0.816, logit=22.500)', '\" The\"[578] (p=0.067, logit=20.000)', '\" A\"[362] (p=0.059, logit=19.875)', '\" Among\"[22395] (p=0.022, logit=18.875)', '\" slow\"[6435] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     clean_prediction=['\" Peach\"[64695] (p=0.867, logit=22.000)', '\" The\"[578] (p=0.055, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.500)', '\" A\"[362] (p=0.020, logit=18.250)', '\" peach\"[73188] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     clean_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.8671875, logit=22.0, token_id=64695, metadata=None))), (60413, (87, PredictedToken(token=' Uk', prob=1.5497207641601562e-05, logit=11.0625, token_id=60413, metadata=None))), (40090, (190, PredictedToken(token=' Pressure', prob=4.1425228118896484e-06, logit=9.75, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:44:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.066, logit=19.125)', '\" Among\"[22395] (p=0.058, logit=19.000)', '\" pressure\"[7410] (p=0.011, logit=17.375)', '\" (\"[320] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.8046875, logit=21.625, token_id=40090, metadata=None))), (60413, (12, PredictedToken(token=' Uk', prob=0.00165557861328125, logit=15.4375, token_id=60413, metadata=None))), (64695, (22, PredictedToken(token=' Peach', prob=0.0006103515625, logit=14.4375, token_id=64695, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:58 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:44:58 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.898, logit=23.250)', '\" The\"[578] (p=0.031, logit=19.875)', '\" A\"[362] (p=0.019, logit=19.375)', '\" Among\"[22395] (p=0.016, logit=19.250)', '\" z\"[1167] (p=0.013, logit=19.000)']\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     clean_prediction=['\" Strawberry\"[89077] (p=0.773, logit=22.000)', '\" The\"[578] (p=0.119, logit=20.125)', '\" Among\"[22395] (p=0.039, logit=19.000)', '\" A\"[362] (p=0.026, logit=18.625)', '\" strawberry\"[73700] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     clean_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.7734375, logit=22.0, token_id=89077, metadata=None))), (16147, (190, PredictedToken(token=' Smart', prob=5.066394805908203e-06, logit=10.0625, token_id=16147, metadata=None))), (48035, (219, PredictedToken(token=' Gir', prob=3.933906555175781e-06, logit=9.8125, token_id=48035, metadata=None)))])\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     int_prediction=['\" Gir\"[48035] (p=0.848, logit=22.250)', '\" The\"[578] (p=0.079, logit=19.875)', '\" Among\"[22395] (p=0.026, logit=18.750)', '\" A\"[362] (p=0.016, logit=18.250)', '\" (\"[320] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     int_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.84765625, logit=22.25, token_id=48035, metadata=None))), (89077, (9, PredictedToken(token=' Strawberry', prob=0.002105712890625, logit=16.25, token_id=89077, metadata=None))), (16147, (103, PredictedToken(token=' Smart', prob=1.5079975128173828e-05, logit=11.3125, token_id=16147, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:58 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:58 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:44:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.629, logit=19.875)', '\" None\"[2290] (p=0.159, logit=18.500)', '\" The\"[578] (p=0.052, logit=17.375)', '\" Orch\"[55405] (p=0.028, logit=16.750)', '\" There\"[2684] (p=0.019, logit=16.375)']\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     clean_prediction=['\" Ju\"[22410] (p=0.645, logit=21.125)', '\" The\"[578] (p=0.112, logit=19.375)', '\" A\"[362] (p=0.087, logit=19.125)', '\" Among\"[22395] (p=0.068, logit=18.875)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     clean_track=OrderedDict([(22410, (1, PredictedToken(token=' Ju', prob=0.64453125, logit=21.125, token_id=22410, metadata=None))), (6771, (9, PredictedToken(token=' Table', prob=0.00494384765625, logit=16.25, token_id=6771, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.00494384765625, logit=16.25, token_id=3341, metadata=None))), (29318, (69, PredictedToken(token=' Dress', prob=0.00010251998901367188, logit=12.375, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.707, logit=21.750)', '\" Table\"[6771] (p=0.123, logit=20.000)', '\" Dress\"[29318] (p=0.051, logit=19.125)', '\" The\"[578] (p=0.045, logit=19.000)', '\" A\"[362] (p=0.015, logit=17.875)']\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.70703125, logit=21.75, token_id=3341, metadata=None))), (6771, (2, PredictedToken(token=' Table', prob=0.12255859375, logit=20.0, token_id=6771, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.051025390625, logit=19.125, token_id=29318, metadata=None))), (22410, (119, PredictedToken(token=' Ju', prob=1.5139579772949219e-05, logit=11.0, token_id=22410, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:44:59 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:44:59 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     patch_prediction=['\" Chair\"[16478] (p=0.816, logit=22.875)', '\" The\"[578] (p=0.076, logit=20.500)', '\" A\"[362] (p=0.067, logit=20.375)', '\" Among\"[22395] (p=0.015, logit=18.875)', '\" It\"[1102] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.061, logit=19.250)', '\" A\"[362] (p=0.025, logit=18.375)', '\" Among\"[22395] (p=0.022, logit=18.250)', '\" dress\"[8679] (p=0.017, logit=18.000)']\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.8359375, logit=21.875, token_id=29318, metadata=None))), (65449, (27, PredictedToken(token=' Willow', prob=0.0003376007080078125, logit=14.0625, token_id=65449, metadata=None))), (27738, (39, PredictedToken(token=' Ward', prob=0.000141143798828125, logit=13.1875, token_id=27738, metadata=None))), (57225, (53, PredictedToken(token=' Laptop', prob=8.535385131835938e-05, logit=12.6875, token_id=57225, metadata=None)))])\n",
      "2025-09-16 09:44:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     int_prediction=['\" Ward\"[27738] (p=0.594, logit=20.625)', '\" Among\"[22395] (p=0.104, logit=18.875)', '\" Willow\"[65449] (p=0.081, logit=18.625)', '\" The\"[578] (p=0.071, logit=18.500)', '\" Laptop\"[57225] (p=0.055, logit=18.250)']\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     int_track=OrderedDict([(27738, (1, PredictedToken(token=' Ward', prob=0.59375, logit=20.625, token_id=27738, metadata=None))), (65449, (3, PredictedToken(token=' Willow', prob=0.08056640625, logit=18.625, token_id=65449, metadata=None))), (57225, (5, PredictedToken(token=' Laptop', prob=0.055419921875, logit=18.25, token_id=57225, metadata=None))), (29318, (200, PredictedToken(token=' Dress', prob=1.0609626770019531e-05, logit=9.6875, token_id=29318, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:00 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:00 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     patch_prediction=['\" Cedar\"[57748] (p=0.863, logit=21.125)', '\" The\"[578] (p=0.043, logit=18.125)', '\" Among\"[22395] (p=0.020, logit=17.375)', '\" Option\"[7104] (p=0.012, logit=16.875)', '\" (\"[320] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     clean_prediction=['\" Slow\"[39247] (p=0.859, logit=22.375)', '\" The\"[578] (p=0.043, logit=19.375)', '\" A\"[362] (p=0.043, logit=19.375)', '\" Among\"[22395] (p=0.020, logit=18.625)', '\" slow\"[6435] (p=0.012, logit=18.125)']\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     clean_track=OrderedDict([(39247, (1, PredictedToken(token=' Slow', prob=0.859375, logit=22.375, token_id=39247, metadata=None))), (65449, (49, PredictedToken(token=' Willow', prob=5.340576171875e-05, logit=12.6875, token_id=65449, metadata=None))), (38258, (669, PredictedToken(token=' Baseball', prob=4.76837158203125e-07, logit=7.96875, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.844, logit=21.750)', '\" Among\"[22395] (p=0.069, logit=19.250)', '\" The\"[578] (p=0.048, logit=18.875)', '\" Option\"[7104] (p=0.005, logit=16.625)', '\" Only\"[8442] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.84375, logit=21.75, token_id=65449, metadata=None))), (38258, (42, PredictedToken(token=' Baseball', prob=0.000133514404296875, logit=13.0, token_id=38258, metadata=None))), (39247, (113, PredictedToken(token=' Slow', prob=1.5974044799804688e-05, logit=10.875, token_id=39247, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:00 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:00 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     patch_prediction=['\" Bench\"[36358] (p=0.770, logit=21.500)', '\" The\"[578] (p=0.081, logit=19.250)', '\" A\"[362] (p=0.043, logit=18.625)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" (\"[320] (p=0.018, logit=17.750)']\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     clean_prediction=['\" Factory\"[17367] (p=0.793, logit=20.125)', '\" The\"[578] (p=0.045, logit=17.250)', '\" A\"[362] (p=0.027, logit=16.750)', '\" Ottoman\"[70110] (p=0.019, logit=16.375)', '\" Among\"[22395] (p=0.010, logit=15.750)']\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     clean_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.79296875, logit=20.125, token_id=17367, metadata=None))), (70110, (4, PredictedToken(token=' Ottoman', prob=0.0186767578125, logit=16.375, token_id=70110, metadata=None))), (33578, (11, PredictedToken(token=' Palm', prob=0.005340576171875, logit=15.125, token_id=33578, metadata=None))), (91963, (31, PredictedToken(token=' Mango', prob=0.00077056884765625, logit=13.1875, token_id=91963, metadata=None)))])\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.371, logit=18.125)', '\" Palm\"[33578] (p=0.254, logit=17.750)', '\" The\"[578] (p=0.064, logit=16.375)', '\" Among\"[22395] (p=0.030, logit=15.625)', '\" None\"[2290] (p=0.029, logit=15.562)']\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.37109375, logit=18.125, token_id=70110, metadata=None))), (33578, (2, PredictedToken(token=' Palm', prob=0.25390625, logit=17.75, token_id=33578, metadata=None))), (17367, (6, PredictedToken(token=' Factory', prob=0.0252685546875, logit=15.4375, token_id=17367, metadata=None))), (91963, (35, PredictedToken(token=' Mango', prob=0.00133514404296875, logit=12.5, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:01 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:01 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.738, logit=21.000)', '\" The\"[578] (p=0.100, logit=19.000)', '\" A\"[362] (p=0.078, logit=18.750)', '\" Among\"[22395] (p=0.032, logit=17.875)', '\" stap\"[36114] (p=0.011, logit=16.750)']\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     clean_prediction=['\" Blue\"[8868] (p=0.785, logit=22.375)', '\" The\"[578] (p=0.106, logit=20.375)', '\" A\"[362] (p=0.057, logit=19.750)', '\" Among\"[22395] (p=0.024, logit=18.875)', '\" Fruit\"[44187] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     clean_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.78515625, logit=22.375, token_id=8868, metadata=None))), (816, (11, PredictedToken(token=' Y', prob=0.00110626220703125, logit=15.8125, token_id=816, metadata=None))), (328, (41, PredictedToken(token=' S', prob=9.107589721679688e-05, logit=13.3125, token_id=328, metadata=None))), (82994, (117, PredictedToken(token=' Toilet', prob=1.0848045349121094e-05, logit=11.1875, token_id=82994, metadata=None))), (36943, (279, PredictedToken(token=' Folder', prob=2.0116567611694336e-06, logit=9.5, token_id=36943, metadata=None))), (53889, (418, PredictedToken(token=' Apartment', prob=9.499490261077881e-07, logit=8.75, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:45:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.322, logit=19.750)', '\" The\"[578] (p=0.221, logit=19.375)', '\" Toilet\"[82994] (p=0.152, logit=19.000)', '\" Among\"[22395] (p=0.082, logit=18.375)', '\" A\"[362] (p=0.063, logit=18.125)']\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.322265625, logit=19.75, token_id=36943, metadata=None))), (82994, (3, PredictedToken(token=' Toilet', prob=0.15234375, logit=19.0, token_id=82994, metadata=None))), (53889, (6, PredictedToken(token=' Apartment', prob=0.04931640625, logit=17.875, token_id=53889, metadata=None))), (816, (10, PredictedToken(token=' Y', prob=0.007110595703125, logit=15.9375, token_id=816, metadata=None))), (328, (34, PredictedToken(token=' S', prob=0.000701904296875, logit=13.625, token_id=328, metadata=None))), (8868, (1014, PredictedToken(token=' Blue', prob=1.4454126358032227e-06, logit=7.4375, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:02 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:02 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.871, logit=21.625)', '\" None\"[2290] (p=0.043, logit=18.625)', '\" The\"[578] (p=0.034, logit=18.375)', '\" A\"[362] (p=0.012, logit=17.375)', '\" P\"[393] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     clean_prediction=['\" Table\"[6771] (p=0.895, logit=23.500)', '\" The\"[578] (p=0.051, logit=20.625)', '\" A\"[362] (p=0.027, logit=20.000)', '\" Among\"[22395] (p=0.011, logit=19.125)', '\" table\"[2007] (p=0.002, logit=17.500)']\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     clean_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.89453125, logit=23.5, token_id=6771, metadata=None))), (17810, (35, PredictedToken(token=' Cat', prob=9.1552734375e-05, logit=14.3125, token_id=17810, metadata=None))), (97796, (36, PredictedToken(token=' Skate', prob=8.58306884765625e-05, logit=14.25, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.887, logit=22.500)', '\" The\"[578] (p=0.034, logit=19.250)', '\" Cat\"[17810] (p=0.030, logit=19.125)', '\" A\"[362] (p=0.016, logit=18.500)', '\" Among\"[22395] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.88671875, logit=22.5, token_id=97796, metadata=None))), (17810, (3, PredictedToken(token=' Cat', prob=0.0303955078125, logit=19.125, token_id=17810, metadata=None))), (6771, (130, PredictedToken(token=' Table', prob=8.463859558105469e-06, logit=10.9375, token_id=6771, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:02 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:02 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:45:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     patch_prediction=['\" Mirror\"[34954] (p=0.922, logit=21.000)', '\" The\"[578] (p=0.012, logit=16.625)', '\" None\"[2290] (p=0.009, logit=16.375)', '\" Among\"[22395] (p=0.008, logit=16.250)', '\" A\"[362] (p=0.005, logit=15.812)']\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     clean_prediction=['\" Dress\"[29318] (p=0.781, logit=21.875)', '\" The\"[578] (p=0.083, logit=19.625)', '\" A\"[362] (p=0.073, logit=19.500)', '\" Among\"[22395] (p=0.030, logit=18.625)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     clean_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.78125, logit=21.875, token_id=29318, metadata=None))), (65449, (34, PredictedToken(token=' Willow', prob=0.00015926361083984375, logit=13.375, token_id=65449, metadata=None))), (32498, (190, PredictedToken(token=' Mall', prob=5.453824996948242e-06, logit=10.0, token_id=32498, metadata=None))), (74968, (969, PredictedToken(token=' Razor', prob=3.948807716369629e-07, logit=7.375, token_id=74968, metadata=None))), (30760, (1065, PredictedToken(token=' Scar', prob=3.371387720108032e-07, logit=7.21875, token_id=30760, metadata=None)))])\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.707, logit=21.250)', '\" The\"[578] (p=0.108, logit=19.375)', '\" Among\"[22395] (p=0.084, logit=19.125)', '\" Scar\"[30760] (p=0.019, logit=17.625)', '\" A\"[362] (p=0.017, logit=17.500)']\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.70703125, logit=21.25, token_id=65449, metadata=None))), (30760, (4, PredictedToken(token=' Scar', prob=0.0189208984375, logit=17.625, token_id=30760, metadata=None))), (32498, (72, PredictedToken(token=' Mall', prob=8.20159912109375e-05, logit=12.1875, token_id=32498, metadata=None))), (29318, (110, PredictedToken(token=' Dress', prob=3.4332275390625e-05, logit=11.3125, token_id=29318, metadata=None))), (74968, (299, PredictedToken(token=' Razor', prob=4.351139068603516e-06, logit=9.25, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:03 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     patch_prediction=['\" Onion\"[87035] (p=0.828, logit=21.500)', '\" An\"[1556] (p=0.053, logit=18.750)', '\" The\"[578] (p=0.053, logit=18.750)', '\" Among\"[22395] (p=0.028, logit=18.125)', '\" It\"[1102] (p=0.003, logit=16.000)']\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     clean_prediction=['\" Hospital\"[15429] (p=0.789, logit=22.375)', '\" The\"[578] (p=0.073, logit=20.000)', '\" A\"[362] (p=0.073, logit=20.000)', '\" Among\"[22395] (p=0.031, logit=19.125)', '\" None\"[2290] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     clean_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.7890625, logit=22.375, token_id=15429, metadata=None))), (48471, (56, PredictedToken(token=' Shower', prob=6.67572021484375e-05, logit=13.0, token_id=48471, metadata=None))), (14642, (63, PredictedToken(token=' Phone', prob=4.601478576660156e-05, logit=12.625, token_id=14642, metadata=None))), (91263, (68, PredictedToken(token=' Binder', prob=4.315376281738281e-05, logit=12.5625, token_id=91263, metadata=None))), (47643, (198, PredictedToken(token=' Cel', prob=5.155801773071289e-06, logit=10.4375, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:45:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.680, logit=20.875)', '\" The\"[578] (p=0.092, logit=18.875)', '\" Among\"[22395] (p=0.081, logit=18.750)', '\" None\"[2290] (p=0.063, logit=18.500)', '\" It\"[1102] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.6796875, logit=20.875, token_id=47643, metadata=None))), (91263, (11, PredictedToken(token=' Binder', prob=0.003570556640625, logit=15.625, token_id=91263, metadata=None))), (14642, (45, PredictedToken(token=' Phone', prob=0.0002593994140625, logit=13.0, token_id=14642, metadata=None))), (15429, (61, PredictedToken(token=' Hospital', prob=0.00012969970703125, logit=12.3125, token_id=15429, metadata=None))), (48471, (138, PredictedToken(token=' Shower', prob=2.562999725341797e-05, logit=10.6875, token_id=48471, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:04 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.824, logit=22.125)', '\" The\"[578] (p=0.068, logit=19.625)', '\" A\"[362] (p=0.053, logit=19.375)', '\" Among\"[22395] (p=0.019, logit=18.375)', '\" Comb\"[23262] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     clean_prediction=['\" Church\"[9441] (p=0.797, logit=22.250)', '\" The\"[578] (p=0.074, logit=19.875)', '\" Among\"[22395] (p=0.058, logit=19.625)', '\" A\"[362] (p=0.040, logit=19.250)', '\" It\"[1102] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     clean_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.796875, logit=22.25, token_id=9441, metadata=None))), (88088, (65, PredictedToken(token=' Birch', prob=4.100799560546875e-05, logit=12.375, token_id=88088, metadata=None))), (55870, (97, PredictedToken(token=' Jacket', prob=1.609325408935547e-05, logit=11.4375, token_id=55870, metadata=None))), (22410, (110, PredictedToken(token=' Ju', prob=1.4185905456542969e-05, logit=11.3125, token_id=22410, metadata=None))), (34046, (124, PredictedToken(token=' Cabinet', prob=1.0371208190917969e-05, logit=11.0, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     int_prediction=['\" Jacket\"[55870] (p=0.910, logit=22.625)', '\" Among\"[22395] (p=0.027, logit=19.125)', '\" The\"[578] (p=0.024, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.875)', '\" It\"[1102] (p=0.001, logit=16.000)']\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     int_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.91015625, logit=22.625, token_id=55870, metadata=None))), (22410, (18, PredictedToken(token=' Ju', prob=0.000324249267578125, logit=14.6875, token_id=22410, metadata=None))), (34046, (26, PredictedToken(token=' Cabinet', prob=0.0001850128173828125, logit=14.125, token_id=34046, metadata=None))), (9441, (393, PredictedToken(token=' Church', prob=8.568167686462402e-07, logit=8.75, token_id=9441, metadata=None))), (88088, (824, PredictedToken(token=' Birch', prob=3.1478703022003174e-07, logit=7.75, token_id=88088, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:04 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:04 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:45:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     patch_prediction=['\" Cel\"[47643] (p=0.883, logit=22.000)', '\" The\"[578] (p=0.050, logit=19.125)', '\" Among\"[22395] (p=0.034, logit=18.750)', '\" It\"[1102] (p=0.006, logit=17.000)', '\" Option\"[7104] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.805, logit=21.000)', '\" The\"[578] (p=0.075, logit=18.625)', '\" Among\"[22395] (p=0.058, logit=18.375)', '\" Option\"[7104] (p=0.005, logit=16.000)', '\" toilet\"[27306] (p=0.005, logit=15.938)']\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.8046875, logit=21.0, token_id=82994, metadata=None))), (6031, (15, PredictedToken(token=' Bro', prob=0.00121307373046875, logit=14.5, token_id=6031, metadata=None))), (9939, (16, PredictedToken(token=' Er', prob=0.00113677978515625, logit=14.4375, token_id=9939, metadata=None))), (40090, (34, PredictedToken(token=' Pressure', prob=0.0004444122314453125, logit=13.5, token_id=40090, metadata=None))), (64695, (54, PredictedToken(token=' Peach', prob=0.000164031982421875, logit=12.5, token_id=64695, metadata=None)))])\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.068, logit=19.250)', '\" Among\"[22395] (p=0.053, logit=19.000)', '\" Peach\"[64695] (p=0.006, logit=16.750)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.8359375, logit=21.75, token_id=6031, metadata=None))), (64695, (5, PredictedToken(token=' Peach', prob=0.005615234375, logit=16.75, token_id=64695, metadata=None))), (9939, (13, PredictedToken(token=' Er', prob=0.00118255615234375, logit=15.1875, token_id=9939, metadata=None))), (40090, (49, PredictedToken(token=' Pressure', prob=0.00010967254638671875, logit=12.8125, token_id=40090, metadata=None))), (82994, (886, PredictedToken(token=' Toilet', prob=6.146728992462158e-07, logit=7.625, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:05 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:05 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.801, logit=22.625)', '\" The\"[578] (p=0.123, logit=20.750)', '\" A\"[362] (p=0.027, logit=19.250)', '\" It\"[1102] (p=0.011, logit=18.375)', '\" Among\"[22395] (p=0.010, logit=18.250)']\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     clean_prediction=['\" Potato\"[78703] (p=0.836, logit=21.875)', '\" The\"[578] (p=0.068, logit=19.375)', '\" Among\"[22395] (p=0.029, logit=18.500)', '\" A\"[362] (p=0.025, logit=18.375)', '\" Pot\"[14020] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     clean_track=OrderedDict([(78703, (1, PredictedToken(token=' Potato', prob=0.8359375, logit=21.875, token_id=78703, metadata=None))), (3816, (20, PredictedToken(token=' Red', prob=0.000492095947265625, logit=14.4375, token_id=3816, metadata=None))), (47759, (112, PredictedToken(token=' Guitar', prob=1.6808509826660156e-05, logit=11.0625, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:45:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     int_prediction=['\" Guitar\"[47759] (p=0.738, logit=20.875)', '\" Red\"[3816] (p=0.088, logit=18.750)', '\" None\"[2290] (p=0.047, logit=18.125)', '\" The\"[578] (p=0.042, logit=18.000)', '\" Among\"[22395] (p=0.025, logit=17.500)']\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     int_track=OrderedDict([(47759, (1, PredictedToken(token=' Guitar', prob=0.73828125, logit=20.875, token_id=47759, metadata=None))), (3816, (2, PredictedToken(token=' Red', prob=0.08837890625, logit=18.75, token_id=3816, metadata=None))), (78703, (132, PredictedToken(token=' Potato', prob=2.6106834411621094e-05, logit=10.625, token_id=78703, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:06 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:06 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.809, logit=21.375)', '\" The\"[578] (p=0.085, logit=19.125)', '\" A\"[362] (p=0.031, logit=18.125)', '\" Among\"[22395] (p=0.021, logit=17.750)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.785, logit=21.375)', '\" The\"[578] (p=0.073, logit=19.000)', '\" Among\"[22395] (p=0.064, logit=18.875)', '\" A\"[362] (p=0.027, logit=18.000)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.78515625, logit=21.375, token_id=3816, metadata=None))), (1666, (7, PredictedToken(token=' As', prob=0.0030059814453125, logit=15.8125, token_id=1666, metadata=None))), (61731, (8, PredictedToken(token=' Soap', prob=0.0028228759765625, logit=15.75, token_id=61731, metadata=None))), (38258, (447, PredictedToken(token=' Baseball', prob=2.130866050720215e-06, logit=8.5625, token_id=38258, metadata=None))), (38930, (942, PredictedToken(token=' Bike', prob=7.37607479095459e-07, logit=7.5, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     int_prediction=['\" Bike\"[38930] (p=0.488, logit=20.250)', '\" Soap\"[61731] (p=0.203, logit=19.375)', '\" The\"[578] (p=0.109, logit=18.750)', '\" Among\"[22395] (p=0.075, logit=18.375)', '\" A\"[362] (p=0.021, logit=17.125)']\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     int_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.48828125, logit=20.25, token_id=38930, metadata=None))), (61731, (2, PredictedToken(token=' Soap', prob=0.203125, logit=19.375, token_id=61731, metadata=None))), (38258, (7, PredictedToken(token=' Baseball', prob=0.0101318359375, logit=16.375, token_id=38258, metadata=None))), (1666, (8, PredictedToken(token=' As', prob=0.0089111328125, logit=16.25, token_id=1666, metadata=None))), (3816, (217, PredictedToken(token=' Red', prob=1.341104507446289e-05, logit=9.75, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:06 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:06 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:45:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.844, logit=23.000)', '\" The\"[578] (p=0.078, logit=20.625)', '\" A\"[362] (p=0.033, logit=19.750)', '\" Among\"[22395] (p=0.015, logit=19.000)', '\" cat\"[8415] (p=0.008, logit=18.375)']\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     clean_prediction=['\" Ti\"[23126] (p=0.840, logit=22.250)', '\" The\"[578] (p=0.061, logit=19.625)', '\" A\"[362] (p=0.037, logit=19.125)', '\" Among\"[22395] (p=0.022, logit=18.625)', '\" (\"[320] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     clean_track=OrderedDict([(23126, (1, PredictedToken(token=' Ti', prob=0.83984375, logit=22.25, token_id=23126, metadata=None))), (96096, (18, PredictedToken(token=' Dolphin', prob=0.000560760498046875, logit=14.9375, token_id=96096, metadata=None))), (9441, (242, PredictedToken(token=' Church', prob=2.950429916381836e-06, logit=9.6875, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     int_prediction=['\" Dolphin\"[96096] (p=0.887, logit=22.000)', '\" The\"[578] (p=0.044, logit=19.000)', '\" Among\"[22395] (p=0.014, logit=17.875)', '\" A\"[362] (p=0.014, logit=17.875)', '\" dolphin\"[99269] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     int_track=OrderedDict([(96096, (1, PredictedToken(token=' Dolphin', prob=0.88671875, logit=22.0, token_id=96096, metadata=None))), (9441, (13, PredictedToken(token=' Church', prob=0.0008087158203125, logit=15.0, token_id=9441, metadata=None))), (23126, (3561, PredictedToken(token=' Ti', prob=8.521601557731628e-08, logit=5.84375, token_id=23126, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:07 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:07 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:45:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     patch_prediction=['\" Hick\"[79028] (p=0.852, logit=21.000)', '\" The\"[578] (p=0.048, logit=18.125)', '\" A\"[362] (p=0.026, logit=17.500)', '\" Among\"[22395] (p=0.020, logit=17.250)', '\" None\"[2290] (p=0.008, logit=16.375)']\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     clean_prediction=['\" Car\"[3341] (p=0.633, logit=22.375)', '\" The\"[578] (p=0.159, logit=21.000)', '\" A\"[362] (p=0.125, logit=20.750)', '\" Among\"[22395] (p=0.046, logit=19.750)', '\" It\"[1102] (p=0.008, logit=18.000)']\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     clean_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.6328125, logit=22.375, token_id=3341, metadata=None))), (14937, (41, PredictedToken(token=' Ash', prob=0.00012063980102539062, logit=13.8125, token_id=14937, metadata=None))), (735, (58, PredictedToken(token=' K', prob=5.030632019042969e-05, logit=12.9375, token_id=735, metadata=None))), (16488, (103, PredictedToken(token=' Bat', prob=1.7404556274414062e-05, logit=11.875, token_id=16488, metadata=None))), (6031, (266, PredictedToken(token=' Bro', prob=2.0712614059448242e-06, logit=9.75, token_id=6031, metadata=None))), (23910, (1558, PredictedToken(token=' Pear', prob=1.0337680578231812e-07, logit=6.75, token_id=23910, metadata=None)))])\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     int_prediction=['\" Pear\"[23910] (p=0.543, logit=22.250)', '\" Ash\"[14937] (p=0.227, logit=21.375)', '\" Among\"[22395] (p=0.121, logit=20.750)', '\" The\"[578] (p=0.074, logit=20.250)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     int_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.54296875, logit=22.25, token_id=23910, metadata=None))), (14937, (2, PredictedToken(token=' Ash', prob=0.2265625, logit=21.375, token_id=14937, metadata=None))), (6031, (6, PredictedToken(token=' Bro', prob=0.003662109375, logit=17.25, token_id=6031, metadata=None))), (3341, (136, PredictedToken(token=' Car', prob=7.063150405883789e-06, logit=11.0, token_id=3341, metadata=None))), (16488, (191, PredictedToken(token=' Bat', prob=3.56137752532959e-06, logit=10.3125, token_id=16488, metadata=None))), (735, (224, PredictedToken(token=' K', prob=2.60770320892334e-06, logit=10.0, token_id=735, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:08 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     patch_prediction=['\" R\"[432] (p=0.770, logit=20.875)', '\" The\"[578] (p=0.072, logit=18.500)', '\" A\"[362] (p=0.063, logit=18.375)', '\" Among\"[22395] (p=0.026, logit=17.500)', '\" It\"[1102] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:45:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.797, logit=21.375)', '\" The\"[578] (p=0.074, logit=19.000)', '\" Among\"[22395] (p=0.051, logit=18.625)', '\" Option\"[7104] (p=0.010, logit=17.000)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.796875, logit=21.375, token_id=82452, metadata=None))), (2057, (9, PredictedToken(token=' To', prob=0.004730224609375, logit=16.25, token_id=2057, metadata=None))), (69755, (170, PredictedToken(token=' Notebook', prob=1.1026859283447266e-05, logit=10.1875, token_id=69755, metadata=None))), (55807, (864, PredictedToken(token=' Shirt', prob=8.791685104370117e-07, logit=7.65625, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     int_prediction=['\" Notebook\"[69755] (p=0.777, logit=21.125)', '\" The\"[578] (p=0.072, logit=18.750)', '\" Among\"[22395] (p=0.030, logit=17.875)', '\" A\"[362] (p=0.027, logit=17.750)', '\" To\"[2057] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     int_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.77734375, logit=21.125, token_id=69755, metadata=None))), (2057, (5, PredictedToken(token=' To', prob=0.0125732421875, logit=17.0, token_id=2057, metadata=None))), (55807, (21, PredictedToken(token=' Shirt', prob=0.000911712646484375, logit=14.375, token_id=55807, metadata=None))), (82452, (130, PredictedToken(token=' Jasmine', prob=2.276897430419922e-05, logit=10.6875, token_id=82452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:09 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:09 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.852, logit=21.750)', '\" The\"[578] (p=0.062, logit=19.125)', '\" Among\"[22395] (p=0.029, logit=18.375)', '\" (\"[320] (p=0.009, logit=17.250)', '\" A\"[362] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.730, logit=22.750)', '\" An\"[1556] (p=0.112, logit=20.875)', '\" The\"[578] (p=0.099, logit=20.750)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" e\"[384] (p=0.010, logit=18.500)']\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.73046875, logit=22.75, token_id=469, metadata=None))), (65449, (25, PredictedToken(token=' Willow', prob=0.00021648406982421875, logit=14.625, token_id=65449, metadata=None))), (97796, (134, PredictedToken(token=' Skate', prob=6.139278411865234e-06, logit=11.0625, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.828, logit=22.125)', '\" The\"[578] (p=0.068, logit=19.625)', '\" Among\"[22395] (p=0.060, logit=19.500)', '\" It\"[1102] (p=0.006, logit=17.250)', '\" Option\"[7104] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.828125, logit=22.125, token_id=65449, metadata=None))), (469, (27, PredictedToken(token=' E', prob=0.0002956390380859375, logit=14.1875, token_id=469, metadata=None))), (97796, (43, PredictedToken(token=' Skate', prob=0.0001087188720703125, logit=13.1875, token_id=97796, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:09 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     patch_prediction=['\" Hospital\"[15429] (p=0.840, logit=22.375)', '\" The\"[578] (p=0.054, logit=19.625)', '\" Among\"[22395] (p=0.047, logit=19.500)', '\" A\"[362] (p=0.032, logit=19.125)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     clean_prediction=['\" Strawberry\"[89077] (p=0.625, logit=21.000)', '\" The\"[578] (p=0.180, logit=19.750)', '\" Among\"[22395] (p=0.109, logit=19.250)', '\" A\"[362] (p=0.031, logit=18.000)', '\" strawberry\"[73700] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     clean_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.625, logit=21.0, token_id=89077, metadata=None))), (94467, (48, PredictedToken(token=' Trom', prob=0.00014400482177734375, logit=12.625, token_id=94467, metadata=None))), (41493, (94, PredictedToken(token=' Tow', prob=3.886222839355469e-05, logit=11.3125, token_id=41493, metadata=None))), (55870, (436, PredictedToken(token=' Jacket', prob=2.339482307434082e-06, logit=8.5, token_id=55870, metadata=None))), (17367, (647, PredictedToken(token=' Factory', prob=1.3709068298339844e-06, logit=7.96875, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     int_prediction=['\" Factory\"[17367] (p=0.443, logit=21.125)', '\" Jacket\"[55870] (p=0.305, logit=20.750)', '\" The\"[578] (p=0.112, logit=19.750)', '\" Among\"[22395] (p=0.077, logit=19.375)', '\" Tow\"[41493] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     int_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.443359375, logit=21.125, token_id=17367, metadata=None))), (55870, (2, PredictedToken(token=' Jacket', prob=0.3046875, logit=20.75, token_id=55870, metadata=None))), (41493, (5, PredictedToken(token=' Tow', prob=0.013427734375, logit=17.625, token_id=41493, metadata=None))), (94467, (51, PredictedToken(token=' Trom', prob=0.00011587142944335938, logit=12.875, token_id=94467, metadata=None))), (89077, (405, PredictedToken(token=' Strawberry', prob=1.8775463104248047e-06, logit=8.75, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:10 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:10 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.926, logit=21.750)', '\" The\"[578] (p=0.025, logit=18.125)', '\" A\"[362] (p=0.007, logit=16.875)', '\" Among\"[22395] (p=0.006, logit=16.625)', '\" tape\"[17401] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:45:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     clean_prediction=['\" Elephant\"[79189] (p=0.801, logit=22.250)', '\" An\"[1556] (p=0.095, logit=20.125)', '\" The\"[578] (p=0.051, logit=19.500)', '\" Among\"[22395] (p=0.019, logit=18.500)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     clean_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.80078125, logit=22.25, token_id=79189, metadata=None))), (40975, (34, PredictedToken(token=' Marker', prob=0.0001621246337890625, logit=13.75, token_id=40975, metadata=None))), (29318, (138, PredictedToken(token=' Dress', prob=6.705522537231445e-06, logit=10.5625, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.895, logit=22.500)', '\" The\"[578] (p=0.035, logit=19.250)', '\" Dress\"[29318] (p=0.027, logit=19.000)', '\" A\"[362] (p=0.016, logit=18.500)', '\" Among\"[22395] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.89453125, logit=22.5, token_id=40975, metadata=None))), (29318, (3, PredictedToken(token=' Dress', prob=0.0269775390625, logit=19.0, token_id=29318, metadata=None))), (79189, (52, PredictedToken(token=' Elephant', prob=4.601478576660156e-05, logit=12.625, token_id=79189, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:11 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     patch_prediction=['\" Tiger\"[36845] (p=0.855, logit=21.750)', '\" The\"[578] (p=0.055, logit=19.000)', '\" Among\"[22395] (p=0.033, logit=18.500)', '\" A\"[362] (p=0.020, logit=18.000)', '\" tiger\"[52835] (p=0.003, logit=15.938)']\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     clean_prediction=['\" Pressure\"[40090] (p=0.801, logit=21.750)', '\" The\"[578] (p=0.074, logit=19.375)', '\" Among\"[22395] (p=0.051, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.500)', '\" pressure\"[7410] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     clean_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.80078125, logit=21.75, token_id=40090, metadata=None))), (79028, (9, PredictedToken(token=' Hick', prob=0.00164031982421875, logit=15.5625, token_id=79028, metadata=None))), (6031, (25, PredictedToken(token=' Bro', prob=0.0005340576171875, logit=14.4375, token_id=6031, metadata=None))), (66821, (34, PredictedToken(token=' Iris', prob=0.000324249267578125, logit=13.9375, token_id=66821, metadata=None))), (22725, (61, PredictedToken(token=' Orange', prob=7.200241088867188e-05, logit=12.4375, token_id=22725, metadata=None))), (17810, (192, PredictedToken(token=' Cat', prob=5.930662155151367e-06, logit=9.9375, token_id=17810, metadata=None)))])\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     int_prediction=['\" Iris\"[66821] (p=0.342, logit=19.750)', '\" Orange\"[22725] (p=0.183, logit=19.125)', '\" Cat\"[17810] (p=0.143, logit=18.875)', '\" The\"[578] (p=0.126, logit=18.750)', '\" Among\"[22395] (p=0.076, logit=18.250)']\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     int_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.341796875, logit=19.75, token_id=66821, metadata=None))), (22725, (2, PredictedToken(token=' Orange', prob=0.1826171875, logit=19.125, token_id=22725, metadata=None))), (17810, (3, PredictedToken(token=' Cat', prob=0.142578125, logit=18.875, token_id=17810, metadata=None))), (6031, (6, PredictedToken(token=' Bro', prob=0.0218505859375, logit=17.0, token_id=6031, metadata=None))), (79028, (9, PredictedToken(token=' Hick', prob=0.0048828125, logit=15.5, token_id=79028, metadata=None))), (40090, (2835, PredictedToken(token=' Pressure', prob=2.7567148208618164e-07, logit=5.71875, token_id=40090, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:11 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:11 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:45:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.883, logit=21.875)', '\" The\"[578] (p=0.034, logit=18.625)', '\" A\"[362] (p=0.030, logit=18.500)', '\" Among\"[22395] (p=0.027, logit=18.375)', '\" It\"[1102] (p=0.003, logit=16.125)']\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.898, logit=21.750)', '\" The\"[578] (p=0.031, logit=18.375)', '\" A\"[362] (p=0.027, logit=18.250)', '\" Among\"[22395] (p=0.019, logit=17.875)', '\" Tr\"[1183] (p=0.003, logit=15.938)']\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.8984375, logit=21.75, token_id=41493, metadata=None))), (1183, (5, PredictedToken(token=' Tr', prob=0.002685546875, logit=15.9375, token_id=1183, metadata=None))), (13120, (23, PredictedToken(token=' Night', prob=0.000301361083984375, logit=13.75, token_id=13120, metadata=None))), (30760, (42, PredictedToken(token=' Scar', prob=0.00010442733764648438, logit=12.6875, token_id=30760, metadata=None))), (36895, (57, PredictedToken(token=' Eagle', prob=6.341934204101562e-05, logit=12.1875, token_id=36895, metadata=None))), (13597, (134, PredictedToken(token=' Pen', prob=1.245737075805664e-05, logit=10.5625, token_id=13597, metadata=None)))])\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     int_prediction=['\" Pen\"[13597] (p=0.828, logit=21.875)', '\" The\"[578] (p=0.041, logit=18.875)', '\" Among\"[22395] (p=0.036, logit=18.750)', '\" Night\"[13120] (p=0.025, logit=18.375)', '\" A\"[362] (p=0.020, logit=18.125)']\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     int_track=OrderedDict([(13597, (1, PredictedToken(token=' Pen', prob=0.828125, logit=21.875, token_id=13597, metadata=None))), (13120, (4, PredictedToken(token=' Night', prob=0.0250244140625, logit=18.375, token_id=13120, metadata=None))), (1183, (82, PredictedToken(token=' Tr', prob=3.7670135498046875e-05, logit=11.875, token_id=1183, metadata=None))), (41493, (104, PredictedToken(token=' Tow', prob=2.4318695068359375e-05, logit=11.4375, token_id=41493, metadata=None))), (36895, (1753, PredictedToken(token=' Eagle', prob=2.169981598854065e-07, logit=6.71875, token_id=36895, metadata=None))), (30760, (2892, PredictedToken(token=' Scar', prob=9.918585419654846e-08, logit=5.9375, token_id=30760, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:12 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:12 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:45:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.625, logit=22.375)', '\" An\"[1556] (p=0.203, logit=21.250)', '\" The\"[578] (p=0.085, logit=20.375)', '\" Among\"[22395] (p=0.058, logit=20.000)', '\" It\"[1102] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     clean_prediction=['\" Food\"[12369] (p=0.637, logit=21.750)', '\" The\"[578] (p=0.142, logit=20.250)', '\" A\"[362] (p=0.125, logit=20.125)', '\" Among\"[22395] (p=0.052, logit=19.250)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     clean_track=OrderedDict([(12369, (1, PredictedToken(token=' Food', prob=0.63671875, logit=21.75, token_id=12369, metadata=None))), (1630, (19, PredictedToken(token=' X', prob=0.000579833984375, logit=14.75, token_id=1630, metadata=None))), (90538, (48, PredictedToken(token=' Caul', prob=0.00012159347534179688, logit=13.1875, token_id=90538, metadata=None))), (38673, (58, PredictedToken(token=' Yoga', prob=7.343292236328125e-05, logit=12.6875, token_id=38673, metadata=None))), (38930, (105, PredictedToken(token=' Bike', prob=1.7523765563964844e-05, logit=11.25, token_id=38930, metadata=None))), (48390, (3856, PredictedToken(token=' Lily', prob=4.470348358154297e-08, logit=5.28125, token_id=48390, metadata=None)))])\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     int_prediction=['\" Among\"[22395] (p=0.322, logit=19.750)', '\" Bike\"[38930] (p=0.322, logit=19.750)', '\" The\"[578] (p=0.152, logit=19.000)', '\" Yoga\"[38673] (p=0.056, logit=18.000)', '\" A\"[362] (p=0.038, logit=17.625)']\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     int_track=OrderedDict([(38930, (2, PredictedToken(token=' Bike', prob=0.322265625, logit=19.75, token_id=38930, metadata=None))), (38673, (4, PredictedToken(token=' Yoga', prob=0.055908203125, logit=18.0, token_id=38673, metadata=None))), (48390, (39, PredictedToken(token=' Lily', prob=0.00054931640625, logit=13.375, token_id=48390, metadata=None))), (1630, (47, PredictedToken(token=' X', prob=0.00042724609375, logit=13.125, token_id=1630, metadata=None))), (90538, (1085, PredictedToken(token=' Caul', prob=9.611248970031738e-07, logit=7.03125, token_id=90538, metadata=None))), (12369, (1138, PredictedToken(token=' Food', prob=8.754432201385498e-07, logit=6.9375, token_id=12369, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:13 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:13 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.809, logit=22.250)', '\" An\"[1556] (p=0.085, logit=20.000)', '\" The\"[578] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" A\"[362] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     clean_prediction=['\" Raspberry\"[48665] (p=0.641, logit=21.125)', '\" The\"[578] (p=0.162, logit=19.750)', '\" Among\"[22395] (p=0.077, logit=19.000)', '\" A\"[362] (p=0.047, logit=18.500)', '\" R\"[432] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     clean_track=OrderedDict([(48665, (1, PredictedToken(token=' Raspberry', prob=0.640625, logit=21.125, token_id=48665, metadata=None))), (1183, (51, PredictedToken(token=' Tr', prob=0.0001392364501953125, logit=12.6875, token_id=1183, metadata=None))), (65197, (434, PredictedToken(token=' Surf', prob=2.3990869522094727e-06, logit=8.625, token_id=65197, metadata=None))), (39794, (1901, PredictedToken(token=' Desk', prob=3.241002559661865e-07, logit=6.625, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:45:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     int_prediction=['\" Tr\"[1183] (p=0.389, logit=20.500)', '\" Surf\"[65197] (p=0.208, logit=19.875)', '\" The\"[578] (p=0.208, logit=19.875)', '\" Among\"[22395] (p=0.087, logit=19.000)', '\" A\"[362] (p=0.022, logit=17.625)']\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     int_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.388671875, logit=20.5, token_id=1183, metadata=None))), (65197, (3, PredictedToken(token=' Surf', prob=0.2080078125, logit=19.875, token_id=65197, metadata=None))), (39794, (59, PredictedToken(token=' Desk', prob=0.00014781951904296875, logit=12.625, token_id=39794, metadata=None))), (48665, (5666, PredictedToken(token=' Raspberry', prob=7.217749953269958e-08, logit=5.0, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:14 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:14 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     patch_prediction=['\" Blue\"[8868] (p=0.898, logit=22.250)', '\" The\"[578] (p=0.040, logit=19.125)', '\" Among\"[22395] (p=0.027, logit=18.750)', '\" blue\"[6437] (p=0.003, logit=16.625)', '\" A\"[362] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     clean_prediction=['\" Laptop\"[57225] (p=0.832, logit=21.750)', '\" The\"[578] (p=0.053, logit=19.000)', '\" Among\"[22395] (p=0.037, logit=18.625)', '\" A\"[362] (p=0.025, logit=18.250)', '\" laptop\"[21288] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     clean_track=OrderedDict([(57225, (1, PredictedToken(token=' Laptop', prob=0.83203125, logit=21.75, token_id=57225, metadata=None))), (33711, (14, PredictedToken(token=' Suit', prob=0.001251220703125, logit=15.25, token_id=33711, metadata=None))), (20918, (36, PredictedToken(token=' Magn', prob=0.000217437744140625, logit=13.5, token_id=20918, metadata=None))), (10164, (239, PredictedToken(token=' Water', prob=3.993511199951172e-06, logit=9.5, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.473, logit=20.750)', '\" Magn\"[20918] (p=0.197, logit=19.875)', '\" Among\"[22395] (p=0.136, logit=19.500)', '\" Suit\"[33711] (p=0.073, logit=18.875)', '\" The\"[578] (p=0.050, logit=18.500)']\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.47265625, logit=20.75, token_id=10164, metadata=None))), (20918, (2, PredictedToken(token=' Magn', prob=0.197265625, logit=19.875, token_id=20918, metadata=None))), (33711, (4, PredictedToken(token=' Suit', prob=0.07275390625, logit=18.875, token_id=33711, metadata=None))), (57225, (676, PredictedToken(token=' Laptop', prob=1.1399388313293457e-06, logit=7.8125, token_id=57225, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:14 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:14 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:45:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     patch_prediction=['\" Sun\"[8219] (p=0.746, logit=22.500)', '\" The\"[578] (p=0.114, logit=20.625)', '\" A\"[362] (p=0.061, logit=20.000)', '\" Among\"[22395] (p=0.048, logit=19.750)', '\" It\"[1102] (p=0.003, logit=17.125)']\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     clean_prediction=['\" Harmon\"[40759] (p=0.805, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" A\"[362] (p=0.028, logit=18.875)', '\" Among\"[22395] (p=0.024, logit=18.750)', '\" It\"[1102] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     clean_track=OrderedDict([(40759, (1, PredictedToken(token=' Harmon', prob=0.8046875, logit=22.25, token_id=40759, metadata=None))), (43316, (67, PredictedToken(token=' Tul', prob=3.886222839355469e-05, logit=12.3125, token_id=43316, metadata=None))), (57915, (336, PredictedToken(token=' Ank', prob=1.5124678611755371e-06, logit=9.0625, token_id=57915, metadata=None))), (53889, (2564, PredictedToken(token=' Apartment', prob=8.242204785346985e-08, logit=6.15625, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     int_prediction=['\" Tul\"[43316] (p=0.598, logit=20.875)', '\" The\"[578] (p=0.104, logit=19.125)', '\" Among\"[22395] (p=0.092, logit=19.000)', '\" Ank\"[57915] (p=0.063, logit=18.625)', '\" Option\"[7104] (p=0.043, logit=18.250)']\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     int_track=OrderedDict([(43316, (1, PredictedToken(token=' Tul', prob=0.59765625, logit=20.875, token_id=43316, metadata=None))), (57915, (4, PredictedToken(token=' Ank', prob=0.06298828125, logit=18.625, token_id=57915, metadata=None))), (53889, (12, PredictedToken(token=' Apartment', prob=0.0033416748046875, logit=15.6875, token_id=53889, metadata=None))), (40759, (93, PredictedToken(token=' Harmon', prob=4.482269287109375e-05, logit=11.375, token_id=40759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:15 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:15 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     patch_prediction=['\" Ki\"[30558] (p=0.918, logit=23.000)', '\" The\"[578] (p=0.028, logit=19.500)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" A\"[362] (p=0.006, logit=18.000)', '\" (\"[320] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.691, logit=22.250)', '\" The\"[578] (p=0.154, logit=20.750)', '\" A\"[362] (p=0.083, logit=20.125)', '\" Among\"[22395] (p=0.030, logit=19.125)', '\" It\"[1102] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.69140625, logit=22.25, token_id=27171, metadata=None))), (34392, (21, PredictedToken(token=' Horse', prob=0.000461578369140625, logit=14.9375, token_id=34392, metadata=None))), (8868, (66, PredictedToken(token=' Blue', prob=3.790855407714844e-05, logit=12.4375, token_id=8868, metadata=None)))])\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.836, logit=22.625)', '\" The\"[578] (p=0.078, logit=20.250)', '\" Among\"[22395] (p=0.053, logit=19.875)', '\" It\"[1102] (p=0.005, logit=17.500)', '\" A\"[362] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:45:15 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.8359375, logit=22.625, token_id=8868, metadata=None))), (34392, (28, PredictedToken(token=' Horse', prob=0.000263214111328125, logit=14.5625, token_id=34392, metadata=None))), (27171, (217, PredictedToken(token=' Coffee', prob=2.9355287551879883e-06, logit=10.0625, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:16 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     patch_prediction=['\" Pear\"[23910] (p=0.785, logit=22.125)', '\" The\"[578] (p=0.083, logit=19.875)', '\" Among\"[22395] (p=0.050, logit=19.375)', '\" A\"[362] (p=0.050, logit=19.375)', '\" pear\"[38790] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.832, logit=20.875)', '\" The\"[578] (p=0.053, logit=18.125)', '\" Among\"[22395] (p=0.025, logit=17.375)', '\" None\"[2290] (p=0.012, logit=16.625)', '\" A\"[362] (p=0.009, logit=16.375)']\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.83203125, logit=20.875, token_id=67629, metadata=None))), (393, (7, PredictedToken(token=' P', prob=0.0059814453125, logit=15.9375, token_id=393, metadata=None))), (24941, (8, PredictedToken(token=' Bear', prob=0.005279541015625, logit=15.8125, token_id=24941, metadata=None))), (58403, (27, PredictedToken(token=' Tablet', prob=0.00067138671875, logit=13.75, token_id=58403, metadata=None))), (80629, (438, PredictedToken(token=' Grape', prob=3.993511199951172e-06, logit=8.625, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.633, logit=19.750)', '\" None\"[2290] (p=0.125, logit=18.125)', '\" P\"[393] (p=0.067, logit=17.500)', '\" Among\"[22395] (p=0.046, logit=17.125)', '\" The\"[578] (p=0.046, logit=17.125)']\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.6328125, logit=19.75, token_id=80629, metadata=None))), (393, (3, PredictedToken(token=' P', prob=0.06689453125, logit=17.5, token_id=393, metadata=None))), (58403, (105, PredictedToken(token=' Tablet', prob=8.344650268554688e-05, logit=10.8125, token_id=58403, metadata=None))), (24941, (115, PredictedToken(token=' Bear', prob=7.343292236328125e-05, logit=10.6875, token_id=24941, metadata=None))), (67629, (177, PredictedToken(token=' Helmet', prob=3.266334533691406e-05, logit=9.875, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:16 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:16 src.selection.optimization DEBUG    torch.Size([6, 35])\n",
      "2025-09-16 09:45:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     patch_prediction=['\" Mar\"[2947] (p=0.723, logit=21.125)', '\" The\"[578] (p=0.086, logit=19.000)', '\" Among\"[22395] (p=0.067, logit=18.750)', '\" Cel\"[47643] (p=0.017, logit=17.375)', '\" (\"[320] (p=0.017, logit=17.375)']\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     clean_prediction=['\" Shirt\"[55807] (p=0.652, logit=21.750)', '\" The\"[578] (p=0.165, logit=20.375)', '\" Among\"[22395] (p=0.078, logit=19.625)', '\" A\"[362] (p=0.069, logit=19.500)', '\" Out\"[4470] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     clean_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.65234375, logit=21.75, token_id=55807, metadata=None))), (16183, (60, PredictedToken(token=' Hel', prob=5.888938903808594e-05, logit=12.4375, token_id=16183, metadata=None))), (5250, (105, PredictedToken(token=' Pe', prob=2.0384788513183594e-05, logit=11.375, token_id=5250, metadata=None))), (31181, (206, PredictedToken(token=' Clar', prob=4.827976226806641e-06, logit=9.9375, token_id=31181, metadata=None))), (98028, (246, PredictedToken(token=' Bamboo', prob=3.769993782043457e-06, logit=9.6875, token_id=98028, metadata=None))), (32498, (712, PredictedToken(token=' Mall', prob=6.966292858123779e-07, logit=8.0, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     int_prediction=['\" Pe\"[5250] (p=0.602, logit=21.125)', '\" The\"[578] (p=0.173, logit=19.875)', '\" Among\"[22395] (p=0.152, logit=19.750)', '\" It\"[1102] (p=0.011, logit=17.125)', '\" A\"[362] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     int_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.6015625, logit=21.125, token_id=5250, metadata=None))), (98028, (6, PredictedToken(token=' Bamboo', prob=0.009765625, logit=17.0, token_id=98028, metadata=None))), (31181, (29, PredictedToken(token=' Clar', prob=0.0004558563232421875, logit=13.9375, token_id=31181, metadata=None))), (16183, (36, PredictedToken(token=' Hel', prob=0.000293731689453125, logit=13.5, token_id=16183, metadata=None))), (32498, (303, PredictedToken(token=' Mall', prob=3.933906555175781e-06, logit=9.1875, token_id=32498, metadata=None))), (55807, (329, PredictedToken(token=' Shirt', prob=3.4868717193603516e-06, logit=9.0625, token_id=55807, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:17 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     patch_prediction=['\" Dog\"[14588] (p=0.680, logit=21.875)', '\" The\"[578] (p=0.134, logit=20.250)', '\" A\"[362] (p=0.092, logit=19.875)', '\" Among\"[22395] (p=0.049, logit=19.250)', '\" \"[220] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.498, logit=21.125)', '\" The\"[578] (p=0.235, logit=20.375)', '\" A\"[362] (p=0.184, logit=20.125)', '\" Among\"[22395] (p=0.036, logit=18.500)', '\" It\"[1102] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.498046875, logit=21.125, token_id=28131, metadata=None))), (47759, (14, PredictedToken(token=' Guitar', prob=0.00115966796875, logit=15.0625, token_id=47759, metadata=None))), (49431, (149, PredictedToken(token=' Rabbit', prob=1.3709068298339844e-05, logit=10.625, token_id=49431, metadata=None))), (13120, (171, PredictedToken(token=' Night', prob=1.0073184967041016e-05, logit=10.3125, token_id=13120, metadata=None))), (82994, (229, PredictedToken(token=' Toilet', prob=5.7220458984375e-06, logit=9.75, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:45:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.680, logit=21.375)', '\" The\"[578] (p=0.134, logit=19.750)', '\" Among\"[22395] (p=0.104, logit=19.500)', '\" A\"[362] (p=0.034, logit=18.375)', '\" It\"[1102] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.6796875, logit=21.375, token_id=49431, metadata=None))), (13120, (25, PredictedToken(token=' Night', prob=0.00051116943359375, logit=14.1875, token_id=13120, metadata=None))), (28131, (41, PredictedToken(token=' Golf', prob=0.00020122528076171875, logit=13.25, token_id=28131, metadata=None))), (82994, (57, PredictedToken(token=' Toilet', prob=0.0001010894775390625, logit=12.5625, token_id=82994, metadata=None))), (47759, (207, PredictedToken(token=' Guitar', prob=7.3015689849853516e-06, logit=9.9375, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:18 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:18 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     patch_prediction=['\" Cow\"[22607] (p=0.715, logit=21.875)', '\" A\"[362] (p=0.109, logit=20.000)', '\" The\"[578] (p=0.085, logit=19.750)', '\" Among\"[22395] (p=0.040, logit=19.000)', '\" cow\"[19923] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     clean_prediction=['\" Iris\"[66821] (p=0.883, logit=21.375)', '\" The\"[578] (p=0.034, logit=18.125)', '\" An\"[1556] (p=0.021, logit=17.625)', '\" Among\"[22395] (p=0.008, logit=16.625)', '\" None\"[2290] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     clean_track=OrderedDict([(66821, (1, PredictedToken(token=' Iris', prob=0.8828125, logit=21.375, token_id=66821, metadata=None))), (24423, (26, PredictedToken(token=' Monitor', prob=0.000457763671875, logit=13.8125, token_id=24423, metadata=None))), (58937, (43, PredictedToken(token=' Monkey', prob=0.000179290771484375, logit=12.875, token_id=58937, metadata=None))), (13597, (48, PredictedToken(token=' Pen', prob=0.00014019012451171875, logit=12.625, token_id=13597, metadata=None))), (88668, (688, PredictedToken(token=' Blender', prob=1.2442469596862793e-06, logit=7.90625, token_id=88668, metadata=None)))])\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     int_prediction=['\" Monkey\"[58937] (p=0.471, logit=19.125)', '\" None\"[2290] (p=0.119, logit=17.750)', '\" The\"[578] (p=0.093, logit=17.500)', '\" Monitor\"[24423] (p=0.056, logit=17.000)', '\" A\"[362] (p=0.050, logit=16.875)']\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     int_track=OrderedDict([(58937, (1, PredictedToken(token=' Monkey', prob=0.470703125, logit=19.125, token_id=58937, metadata=None))), (24423, (4, PredictedToken(token=' Monitor', prob=0.05615234375, logit=17.0, token_id=24423, metadata=None))), (13597, (6, PredictedToken(token=' Pen', prob=0.03857421875, logit=16.625, token_id=13597, metadata=None))), (66821, (52, PredictedToken(token=' Iris', prob=0.0004863739013671875, logit=12.25, token_id=66821, metadata=None))), (88668, (237, PredictedToken(token=' Blender', prob=3.743171691894531e-05, logit=9.6875, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:18 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     patch_prediction=['\" Raspberry\"[48665] (p=0.773, logit=21.500)', '\" The\"[578] (p=0.072, logit=19.125)', '\" Among\"[22395] (p=0.063, logit=19.000)', '\" R\"[432] (p=0.023, logit=18.000)', '\" A\"[362] (p=0.013, logit=17.375)']\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.820, logit=21.125)', '\" The\"[578] (p=0.041, logit=18.125)', '\" A\"[362] (p=0.032, logit=17.875)', '\" Pine\"[42609] (p=0.017, logit=17.250)', '\" Suit\"[33711] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.8203125, logit=21.125, token_id=17929, metadata=None))), (42609, (4, PredictedToken(token=' Pine', prob=0.01708984375, logit=17.25, token_id=42609, metadata=None))), (33711, (5, PredictedToken(token=' Suit', prob=0.0150146484375, logit=17.125, token_id=33711, metadata=None))), (29318, (43, PredictedToken(token=' Dress', prob=0.00022792816162109375, logit=12.9375, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.562, logit=19.500)', '\" The\"[578] (p=0.111, logit=17.875)', '\" Among\"[22395] (p=0.076, logit=17.500)', '\" None\"[2290] (p=0.076, logit=17.500)', '\" A\"[362] (p=0.017, logit=16.000)']\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.5625, logit=19.5, token_id=42609, metadata=None))), (17929, (8, PredictedToken(token=' Pin', prob=0.008544921875, logit=15.3125, token_id=17929, metadata=None))), (29318, (501, PredictedToken(token=' Dress', prob=8.821487426757812e-06, logit=8.4375, token_id=29318, metadata=None))), (33711, (568, PredictedToken(token=' Suit', prob=7.3015689849853516e-06, logit=8.25, token_id=33711, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:19 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:19 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.695, logit=21.375)', '\" The\"[578] (p=0.121, logit=19.625)', '\" Among\"[22395] (p=0.073, logit=19.125)', '\" A\"[362] (p=0.057, logit=18.875)', '\" B\"[426] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.762, logit=21.625)', '\" The\"[578] (p=0.071, logit=19.250)', '\" A\"[362] (p=0.043, logit=18.750)', '\" b\"[293] (p=0.038, logit=18.625)', '\" Among\"[22395] (p=0.033, logit=18.500)']\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.76171875, logit=21.625, token_id=426, metadata=None))), (48390, (46, PredictedToken(token=' Lily', prob=0.00010013580322265625, logit=12.6875, token_id=48390, metadata=None))), (33711, (92, PredictedToken(token=' Suit', prob=2.6941299438476562e-05, logit=11.375, token_id=33711, metadata=None))), (80629, (297, PredictedToken(token=' Grape', prob=2.3543834686279297e-06, logit=8.9375, token_id=80629, metadata=None))), (50159, (440, PredictedToken(token=' Sco', prob=1.259148120880127e-06, logit=8.3125, token_id=50159, metadata=None))), (53889, (676, PredictedToken(token=' Apartment', prob=6.332993507385254e-07, logit=7.625, token_id=53889, metadata=None)))])\n",
      "2025-09-16 09:45:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     int_prediction=['\" Grape\"[80629] (p=0.777, logit=21.375)', '\" Among\"[22395] (p=0.105, logit=19.375)', '\" The\"[578] (p=0.050, logit=18.625)', '\" GRA\"[65120] (p=0.008, logit=16.750)', '\" It\"[1102] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     int_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.77734375, logit=21.375, token_id=80629, metadata=None))), (53889, (37, PredictedToken(token=' Apartment', prob=0.0002613067626953125, logit=13.375, token_id=53889, metadata=None))), (426, (69, PredictedToken(token=' B', prob=6.628036499023438e-05, logit=12.0, token_id=426, metadata=None))), (33711, (108, PredictedToken(token=' Suit', prob=2.4318695068359375e-05, logit=11.0, token_id=33711, metadata=None))), (48390, (234, PredictedToken(token=' Lily', prob=5.0961971282958984e-06, logit=9.4375, token_id=48390, metadata=None))), (50159, (294, PredictedToken(token=' Sco', prob=3.5017728805541992e-06, logit=9.0625, token_id=50159, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:20 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:20 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.664, logit=20.750)', '\" Among\"[22395] (p=0.090, logit=18.750)', '\" The\"[578] (p=0.090, logit=18.750)', '\" A\"[362] (p=0.038, logit=17.875)', '\" Mouse\"[18191] (p=0.020, logit=17.250)']\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     clean_prediction=['\" Hat\"[22050] (p=0.516, logit=21.625)', '\" The\"[578] (p=0.215, logit=20.750)', '\" A\"[362] (p=0.147, logit=20.375)', '\" Among\"[22395] (p=0.079, logit=19.750)', '\" H\"[473] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     clean_track=OrderedDict([(22050, (1, PredictedToken(token=' Hat', prob=0.515625, logit=21.625, token_id=22050, metadata=None))), (14588, (30, PredictedToken(token=' Dog', prob=0.00026702880859375, logit=14.0625, token_id=14588, metadata=None))), (38258, (87, PredictedToken(token=' Baseball', prob=2.8133392333984375e-05, logit=11.8125, token_id=38258, metadata=None))), (39247, (149, PredictedToken(token=' Slow', prob=1.1026859283447266e-05, logit=10.875, token_id=39247, metadata=None))), (10164, (184, PredictedToken(token=' Water', prob=7.569789886474609e-06, logit=10.5, token_id=10164, metadata=None))), (37128, (925, PredictedToken(token=' Calculator', prob=4.991888999938965e-07, logit=7.78125, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     int_prediction=['\" Dog\"[14588] (p=0.742, logit=22.125)', '\" The\"[578] (p=0.101, logit=20.125)', '\" Among\"[22395] (p=0.061, logit=19.625)', '\" A\"[362] (p=0.061, logit=19.625)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     int_track=OrderedDict([(14588, (1, PredictedToken(token=' Dog', prob=0.7421875, logit=22.125, token_id=14588, metadata=None))), (37128, (9, PredictedToken(token=' Calculator', prob=0.00152587890625, logit=15.9375, token_id=37128, metadata=None))), (38258, (11, PredictedToken(token=' Baseball', prob=0.0013427734375, logit=15.8125, token_id=38258, metadata=None))), (39247, (29, PredictedToken(token=' Slow', prob=0.0002994537353515625, logit=14.3125, token_id=39247, metadata=None))), (10164, (37, PredictedToken(token=' Water', prob=0.00019359588623046875, logit=13.875, token_id=10164, metadata=None))), (22050, (1468, PredictedToken(token=' Hat', prob=2.337619662284851e-07, logit=7.15625, token_id=22050, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:20 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:20 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:45:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     patch_prediction=['\" Helmet\"[67629] (p=0.750, logit=20.375)', '\" The\"[578] (p=0.102, logit=18.375)', '\" Among\"[22395] (p=0.029, logit=17.125)', '\" A\"[362] (p=0.029, logit=17.125)', '\" None\"[2290] (p=0.016, logit=16.500)']\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.746, logit=21.000)', '\" The\"[578] (p=0.089, logit=18.875)', '\" An\"[1556] (p=0.042, logit=18.125)', '\" Among\"[22395] (p=0.037, logit=18.000)', '\" Only\"[8442] (p=0.012, logit=16.875)']\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.74609375, logit=21.0, token_id=87213, metadata=None))), (14937, (29, PredictedToken(token=' Ash', prob=0.00049591064453125, logit=13.6875, token_id=14937, metadata=None))), (89077, (140, PredictedToken(token=' Strawberry', prob=2.8014183044433594e-05, logit=10.8125, token_id=89077, metadata=None))), (50159, (165, PredictedToken(token=' Sco', prob=2.0503997802734375e-05, logit=10.5, token_id=50159, metadata=None))), (97796, (1198, PredictedToken(token=' Skate', prob=9.015202522277832e-07, logit=7.375, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.633, logit=21.375)', '\" Sco\"[50159] (p=0.264, logit=20.500)', '\" The\"[578] (p=0.036, logit=18.500)', '\" Among\"[22395] (p=0.024, logit=18.125)', '\" A\"[362] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.6328125, logit=21.375, token_id=97796, metadata=None))), (50159, (2, PredictedToken(token=' Sco', prob=0.263671875, logit=20.5, token_id=50159, metadata=None))), (89077, (16, PredictedToken(token=' Strawberry', prob=0.00089263916015625, logit=14.8125, token_id=89077, metadata=None))), (87213, (42, PredictedToken(token=' Oven', prob=0.00012063980102539062, logit=12.8125, token_id=87213, metadata=None))), (14937, (136, PredictedToken(token=' Ash', prob=1.3530254364013672e-05, logit=10.625, token_id=14937, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:21 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:21 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     patch_prediction=['\" Guitar\"[47759] (p=0.605, logit=21.000)', '\" The\"[578] (p=0.174, logit=19.750)', '\" A\"[362] (p=0.056, logit=18.625)', '\" Among\"[22395] (p=0.050, logit=18.500)', '\" It\"[1102] (p=0.027, logit=17.875)']\n",
      "2025-09-16 09:45:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.816, logit=21.375)', '\" The\"[578] (p=0.052, logit=18.625)', '\" Among\"[22395] (p=0.028, logit=18.000)', '\" A\"[362] (p=0.019, logit=17.625)', '\" It\"[1102] (p=0.013, logit=17.250)']\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.81640625, logit=21.375, token_id=24423, metadata=None))), (20423, (16, PredictedToken(token=' Amb', prob=0.00167083740234375, logit=15.1875, token_id=20423, metadata=None))), (3061, (39, PredictedToken(token=' Fl', prob=0.0003509521484375, logit=13.625, token_id=3061, metadata=None))), (23262, (42, PredictedToken(token=' Comb', prob=0.0003299713134765625, logit=13.5625, token_id=23262, metadata=None)))])\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.381, logit=19.500)', '\" Fl\"[3061] (p=0.230, logit=19.000)', '\" The\"[578] (p=0.096, logit=18.125)', '\" Among\"[22395] (p=0.085, logit=18.000)', '\" A\"[362] (p=0.058, logit=17.625)']\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.380859375, logit=19.5, token_id=23262, metadata=None))), (3061, (2, PredictedToken(token=' Fl', prob=0.23046875, logit=19.0, token_id=3061, metadata=None))), (20423, (8, PredictedToken(token=' Amb', prob=0.0101318359375, logit=15.875, token_id=20423, metadata=None))), (24423, (468, PredictedToken(token=' Monitor', prob=4.380941390991211e-06, logit=8.125, token_id=24423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:22 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     patch_prediction=['\" Keyboard\"[26698] (p=0.680, logit=21.000)', '\" The\"[578] (p=0.134, logit=19.375)', '\" Among\"[22395] (p=0.056, logit=18.500)', '\" A\"[362] (p=0.026, logit=17.750)', '\" keyboard\"[13939] (p=0.018, logit=17.375)']\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     clean_prediction=['\" Maple\"[44570] (p=0.836, logit=21.500)', '\" The\"[578] (p=0.061, logit=18.875)', '\" Among\"[22395] (p=0.032, logit=18.250)', '\" A\"[362] (p=0.029, logit=18.125)', '\" MAP\"[28322] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     clean_track=OrderedDict([(44570, (1, PredictedToken(token=' Maple', prob=0.8359375, logit=21.5, token_id=44570, metadata=None))), (1050, (63, PredictedToken(token=' Re', prob=8.0108642578125e-05, logit=12.25, token_id=1050, metadata=None))), (63606, (325, PredictedToken(token=' Stap', prob=3.11434268951416e-06, logit=9.0, token_id=63606, metadata=None))), (18654, (519, PredictedToken(token=' Micro', prob=1.4677643775939941e-06, logit=8.25, token_id=18654, metadata=None))), (49431, (544, PredictedToken(token=' Rabbit', prob=1.3783574104309082e-06, logit=8.1875, token_id=49431, metadata=None))), (47589, (689, PredictedToken(token=' Basketball', prob=1.043081283569336e-06, logit=7.90625, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     int_prediction=['\" Stap\"[63606] (p=0.527, logit=20.750)', '\" Re\"[1050] (p=0.221, logit=19.875)', '\" A\"[362] (p=0.071, logit=18.750)', '\" The\"[578] (p=0.063, logit=18.625)', '\" Among\"[22395] (p=0.043, logit=18.250)']\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     int_track=OrderedDict([(63606, (1, PredictedToken(token=' Stap', prob=0.52734375, logit=20.75, token_id=63606, metadata=None))), (1050, (2, PredictedToken(token=' Re', prob=0.220703125, logit=19.875, token_id=1050, metadata=None))), (18654, (6, PredictedToken(token=' Micro', prob=0.01806640625, logit=17.375, token_id=18654, metadata=None))), (47589, (16, PredictedToken(token=' Basketball', prob=0.0010833740234375, logit=14.5625, token_id=47589, metadata=None))), (49431, (82, PredictedToken(token=' Rabbit', prob=5.745887756347656e-05, logit=11.625, token_id=49431, metadata=None))), (44570, (236, PredictedToken(token=' Maple', prob=7.808208465576172e-06, logit=9.625, token_id=44570, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:22 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:22 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     patch_prediction=['\" Coat\"[68867] (p=0.715, logit=21.750)', '\" The\"[578] (p=0.085, logit=19.625)', '\" A\"[362] (p=0.085, logit=19.625)', '\" Among\"[22395] (p=0.046, logit=19.000)', '\" Watch\"[10573] (p=0.024, logit=18.375)']\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     clean_prediction=['\" Tennis\"[58251] (p=0.723, logit=20.375)', '\" The\"[578] (p=0.076, logit=18.125)', '\" Among\"[22395] (p=0.041, logit=17.500)', '\" Option\"[7104] (p=0.022, logit=16.875)', '\" A\"[362] (p=0.022, logit=16.875)']\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     clean_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.72265625, logit=20.375, token_id=58251, metadata=None))), (33711, (6, PredictedToken(token=' Suit', prob=0.0150146484375, logit=16.5, token_id=33711, metadata=None))), (64695, (7, PredictedToken(token=' Peach', prob=0.01324462890625, logit=16.375, token_id=64695, metadata=None)))])\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.504, logit=19.375)', '\" Peach\"[64695] (p=0.271, logit=18.750)', '\" The\"[578] (p=0.060, logit=17.250)', '\" Among\"[22395] (p=0.022, logit=16.250)', '\" A\"[362] (p=0.022, logit=16.250)']\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.50390625, logit=19.375, token_id=33711, metadata=None))), (64695, (2, PredictedToken(token=' Peach', prob=0.271484375, logit=18.75, token_id=64695, metadata=None))), (58251, (10, PredictedToken(token=' Tennis', prob=0.00494384765625, logit=14.75, token_id=58251, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:23 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.840, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.011, logit=17.875)', '\" z\"[1167] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:45:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     clean_prediction=['\" Apartment\"[53889] (p=0.742, logit=21.625)', '\" An\"[1556] (p=0.101, logit=19.625)', '\" The\"[578] (p=0.047, logit=18.875)', '\" Among\"[22395] (p=0.037, logit=18.625)', '\" None\"[2290] (p=0.033, logit=18.500)']\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     clean_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.7421875, logit=21.625, token_id=53889, metadata=None))), (37128, (50, PredictedToken(token=' Calculator', prob=0.00014209747314453125, logit=13.0625, token_id=37128, metadata=None))), (91297, (102, PredictedToken(token=' Mushroom', prob=2.6226043701171875e-05, logit=11.375, token_id=91297, metadata=None))), (1630, (123, PredictedToken(token=' X', prob=1.6927719116210938e-05, logit=10.9375, token_id=1630, metadata=None))), (49268, (187, PredictedToken(token=' Dish', prob=7.063150405883789e-06, logit=10.0625, token_id=49268, metadata=None))), (58251, (534, PredictedToken(token=' Tennis', prob=1.2293457984924316e-06, logit=8.3125, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     int_prediction=['\" Mushroom\"[91297] (p=0.395, logit=18.875)', '\" None\"[2290] (p=0.211, logit=18.250)', '\" The\"[578] (p=0.100, logit=17.500)', '\" A\"[362] (p=0.088, logit=17.375)', '\" Among\"[22395] (p=0.053, logit=16.875)']\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     int_track=OrderedDict([(91297, (1, PredictedToken(token=' Mushroom', prob=0.39453125, logit=18.875, token_id=91297, metadata=None))), (1630, (21, PredictedToken(token=' X', prob=0.0023345947265625, logit=13.75, token_id=1630, metadata=None))), (53889, (58, PredictedToken(token=' Apartment', prob=0.000316619873046875, logit=11.75, token_id=53889, metadata=None))), (58251, (352, PredictedToken(token=' Tennis', prob=1.2278556823730469e-05, logit=8.5, token_id=58251, metadata=None))), (49268, (361, PredictedToken(token=' Dish', prob=1.1563301086425781e-05, logit=8.4375, token_id=49268, metadata=None))), (37128, (2752, PredictedToken(token=' Calculator', prob=8.344650268554688e-07, logit=5.8125, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:24 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:24 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.486, logit=20.125)', '\" None\"[2290] (p=0.334, logit=19.750)', '\" The\"[578] (p=0.040, logit=17.625)', '\" A\"[362] (p=0.031, logit=17.375)', '\" There\"[2684] (p=0.019, logit=16.875)']\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     clean_prediction=['\" Paper\"[18343] (p=0.754, logit=22.125)', '\" The\"[578] (p=0.090, logit=20.000)', '\" A\"[362] (p=0.079, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=19.125)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     clean_track=OrderedDict([(18343, (1, PredictedToken(token=' Paper', prob=0.75390625, logit=22.125, token_id=18343, metadata=None))), (921, (37, PredictedToken(token=' Ch', prob=0.0002231597900390625, logit=14.0, token_id=921, metadata=None))), (10164, (84, PredictedToken(token=' Water', prob=3.0159950256347656e-05, logit=12.0, token_id=10164, metadata=None))), (6150, (155, PredictedToken(token=' School', prob=9.179115295410156e-06, logit=10.8125, token_id=6150, metadata=None)))])\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     int_prediction=['\" Ch\"[921] (p=0.451, logit=20.250)', '\" School\"[6150] (p=0.213, logit=19.500)', '\" The\"[578] (p=0.129, logit=19.000)', '\" Among\"[22395] (p=0.101, logit=18.750)', '\" A\"[362] (p=0.020, logit=17.125)']\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     int_track=OrderedDict([(921, (1, PredictedToken(token=' Ch', prob=0.451171875, logit=20.25, token_id=921, metadata=None))), (6150, (2, PredictedToken(token=' School', prob=0.212890625, logit=19.5, token_id=6150, metadata=None))), (18343, (72, PredictedToken(token=' Paper', prob=0.00011777877807617188, logit=12.0, token_id=18343, metadata=None))), (10164, (105, PredictedToken(token=' Water', prob=4.9114227294921875e-05, logit=11.125, token_id=10164, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:24 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:24 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     patch_prediction=['\" Sink\"[57551] (p=0.707, logit=21.125)', '\" The\"[578] (p=0.123, logit=19.375)', '\" Among\"[22395] (p=0.058, logit=18.625)', '\" A\"[362] (p=0.051, logit=18.500)', '\" Option\"[7104] (p=0.006, logit=16.375)']\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.781, logit=21.625)', '\" The\"[578] (p=0.083, logit=19.375)', '\" A\"[362] (p=0.073, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=18.000)', '\" It\"[1102] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.78125, logit=21.625, token_id=41342, metadata=None))), (816, (37, PredictedToken(token=' Y', prob=0.00014019012451171875, logit=13.0, token_id=816, metadata=None))), (83499, (106, PredictedToken(token=' Tooth', prob=1.6808509826660156e-05, logit=10.875, token_id=83499, metadata=None))), (9441, (1298, PredictedToken(token=' Church', prob=3.073364496231079e-07, logit=6.875, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     int_prediction=['\" Tooth\"[83499] (p=0.734, logit=21.000)', '\" Among\"[22395] (p=0.077, logit=18.750)', '\" The\"[578] (p=0.077, logit=18.750)', '\" Option\"[7104] (p=0.032, logit=17.875)', '\" A\"[362] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     int_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.734375, logit=21.0, token_id=83499, metadata=None))), (816, (9, PredictedToken(token=' Y', prob=0.00384521484375, logit=15.75, token_id=816, metadata=None))), (9441, (30, PredictedToken(token=' Church', prob=0.000667572021484375, logit=14.0, token_id=9441, metadata=None))), (41342, (58, PredictedToken(token=' Hockey', prob=0.00011587142944335938, logit=12.25, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:25 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:25 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.699, logit=20.750)', '\" Among\"[22395] (p=0.083, logit=18.625)', '\" The\"[578] (p=0.065, logit=18.375)', '\" An\"[1556] (p=0.031, logit=17.625)', '\" A\"[362] (p=0.031, logit=17.625)']\n",
      "2025-09-16 09:45:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.809, logit=21.750)', '\" The\"[578] (p=0.096, logit=19.625)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" Out\"[4470] (p=0.004, logit=16.375)', '\" (\"[320] (p=0.004, logit=16.375)']\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.80859375, logit=21.75, token_id=82994, metadata=None))), (23462, (60, PredictedToken(token=' Stadium', prob=7.295608520507812e-05, logit=12.4375, token_id=23462, metadata=None))), (1901, (109, PredictedToken(token=' Z', prob=1.8477439880371094e-05, logit=11.0625, token_id=1901, metadata=None))), (97796, (153, PredictedToken(token=' Skate', prob=1.1146068572998047e-05, logit=10.5625, token_id=97796, metadata=None))), (6690, (178, PredictedToken(token=' Air', prob=8.165836334228516e-06, logit=10.25, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     int_prediction=['\" Stadium\"[23462] (p=0.312, logit=19.875)', '\" The\"[578] (p=0.243, logit=19.625)', '\" A\"[362] (p=0.147, logit=19.125)', '\" Among\"[22395] (p=0.130, logit=19.000)', '\" Skate\"[97796] (p=0.042, logit=17.875)']\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     int_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.3125, logit=19.875, token_id=23462, metadata=None))), (97796, (5, PredictedToken(token=' Skate', prob=0.042236328125, logit=17.875, token_id=97796, metadata=None))), (6690, (22, PredictedToken(token=' Air', prob=0.0014495849609375, logit=14.5, token_id=6690, metadata=None))), (1901, (66, PredictedToken(token=' Z', prob=0.0001621246337890625, logit=12.3125, token_id=1901, metadata=None))), (82994, (294, PredictedToken(token=' Toilet', prob=8.106231689453125e-06, logit=9.3125, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:26 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:26 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     patch_prediction=['\" Pendant\"[81501] (p=0.934, logit=22.875)', '\" The\"[578] (p=0.019, logit=19.000)', '\" A\"[362] (p=0.019, logit=19.000)', '\" Among\"[22395] (p=0.013, logit=18.625)', '\" It\"[1102] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     clean_prediction=['\" Ki\"[30558] (p=0.871, logit=22.250)', '\" The\"[578] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.023, logit=18.625)', '\" A\"[362] (p=0.018, logit=18.375)', '\" ki\"[20548] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     clean_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.87109375, logit=22.25, token_id=30558, metadata=None))), (72392, (21, PredictedToken(token=' Mixer', prob=0.000274658203125, logit=14.1875, token_id=72392, metadata=None))), (10573, (180, PredictedToken(token=' Watch', prob=4.172325134277344e-06, logit=10.0, token_id=10573, metadata=None))), (30555, (205, PredictedToken(token=' Viol', prob=3.248453140258789e-06, logit=9.75, token_id=30555, metadata=None))), (82994, (347, PredictedToken(token=' Toilet', prob=1.2740492820739746e-06, logit=8.8125, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.633, logit=20.250)', '\" The\"[578] (p=0.141, logit=18.750)', '\" Among\"[22395] (p=0.085, logit=18.250)', '\" Watch\"[10573] (p=0.025, logit=17.000)', '\" A\"[362] (p=0.025, logit=17.000)']\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.6328125, logit=20.25, token_id=72392, metadata=None))), (10573, (5, PredictedToken(token=' Watch', prob=0.0245361328125, logit=17.0, token_id=10573, metadata=None))), (30555, (8, PredictedToken(token=' Viol', prob=0.005126953125, logit=15.4375, token_id=30555, metadata=None))), (82994, (19, PredictedToken(token=' Toilet', prob=0.00188446044921875, logit=14.4375, token_id=82994, metadata=None))), (30558, (34, PredictedToken(token=' Ki', prob=0.0004482269287109375, logit=13.0, token_id=30558, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:26 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:26 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:45:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     patch_prediction=['\" Boxing\"[72683] (p=0.789, logit=21.250)', '\" The\"[578] (p=0.083, logit=19.000)', '\" Among\"[22395] (p=0.044, logit=18.375)', '\" Option\"[7104] (p=0.013, logit=17.125)', '\" (\"[320] (p=0.007, logit=16.500)']\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     clean_prediction=['\" Mosque\"[100031] (p=0.887, logit=22.625)', '\" The\"[578] (p=0.044, logit=19.625)', '\" A\"[362] (p=0.039, logit=19.500)', '\" Among\"[22395] (p=0.011, logit=18.250)', '\" MOS\"[74174] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     clean_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.88671875, logit=22.625, token_id=100031, metadata=None))), (328, (105, PredictedToken(token=' S', prob=7.927417755126953e-06, logit=11.0, token_id=328, metadata=None))), (97796, (152, PredictedToken(token=' Skate', prob=4.231929779052734e-06, logit=10.375, token_id=97796, metadata=None))), (49431, (338, PredictedToken(token=' Rabbit', prob=1.0058283805847168e-06, logit=8.9375, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.648, logit=21.375)', '\" The\"[578] (p=0.128, logit=19.750)', '\" S\"[328] (p=0.113, logit=19.625)', '\" A\"[362] (p=0.032, logit=18.375)', '\" Among\"[22395] (p=0.025, logit=18.125)']\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.6484375, logit=21.375, token_id=97796, metadata=None))), (328, (3, PredictedToken(token=' S', prob=0.11279296875, logit=19.625, token_id=328, metadata=None))), (49431, (63, PredictedToken(token=' Rabbit', prob=0.000102996826171875, logit=12.625, token_id=49431, metadata=None))), (100031, (157, PredictedToken(token=' Mosque', prob=1.2278556823730469e-05, logit=10.5, token_id=100031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:27 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:27 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.754, logit=21.875)', '\" The\"[578] (p=0.070, logit=19.500)', '\" Air\"[6690] (p=0.048, logit=19.125)', '\" phone\"[4641] (p=0.026, logit=18.500)', '\" A\"[362] (p=0.026, logit=18.500)']\n",
      "2025-09-16 09:45:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     clean_prediction=['\" Mixer\"[72392] (p=0.844, logit=21.375)', '\" The\"[578] (p=0.037, logit=18.250)', '\" A\"[362] (p=0.037, logit=18.250)', '\" (\"[320] (p=0.020, logit=17.625)', '\" Among\"[22395] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     clean_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.84375, logit=21.375, token_id=72392, metadata=None))), (59825, (33, PredictedToken(token=' Tie', prob=0.0002651214599609375, logit=13.3125, token_id=59825, metadata=None))), (18191, (40, PredictedToken(token=' Mouse', prob=0.000171661376953125, logit=12.875, token_id=18191, metadata=None)))])\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     int_prediction=['\" Tie\"[59825] (p=0.859, logit=20.875)', '\" None\"[2290] (p=0.029, logit=17.500)', '\" The\"[578] (p=0.023, logit=17.250)', '\" Mixer\"[72392] (p=0.012, logit=16.625)', '\" A\"[362] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     int_track=OrderedDict([(59825, (1, PredictedToken(token=' Tie', prob=0.859375, logit=20.875, token_id=59825, metadata=None))), (72392, (4, PredictedToken(token=' Mixer', prob=0.01226806640625, logit=16.625, token_id=72392, metadata=None))), (18191, (21, PredictedToken(token=' Mouse', prob=0.00078582763671875, logit=13.875, token_id=18191, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:28 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     patch_prediction=['\" Tooth\"[83499] (p=0.754, logit=21.125)', '\" A\"[362] (p=0.070, logit=18.750)', '\" The\"[578] (p=0.062, logit=18.625)', '\" Among\"[22395] (p=0.055, logit=18.500)', '\" Out\"[4470] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     clean_prediction=['\" House\"[4783] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.053, logit=19.000)', '\" A\"[362] (p=0.037, logit=18.625)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" house\"[3838] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     clean_track=OrderedDict([(4783, (1, PredictedToken(token=' House', prob=0.8359375, logit=21.75, token_id=4783, metadata=None))), (61731, (22, PredictedToken(token=' Soap', prob=0.000812530517578125, logit=14.8125, token_id=61731, metadata=None))), (5907, (21, PredictedToken(token=' Project', prob=0.000812530517578125, logit=14.8125, token_id=5907, metadata=None))), (65329, (74, PredictedToken(token=' Elm', prob=6.67572021484375e-05, logit=12.3125, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     int_prediction=['\" Soap\"[61731] (p=0.770, logit=20.750)', '\" The\"[578] (p=0.056, logit=18.125)', '\" Elm\"[65329] (p=0.049, logit=18.000)', '\" Among\"[22395] (p=0.038, logit=17.750)', '\" SOAP\"[64332] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     int_track=OrderedDict([(61731, (1, PredictedToken(token=' Soap', prob=0.76953125, logit=20.75, token_id=61731, metadata=None))), (65329, (3, PredictedToken(token=' Elm', prob=0.04931640625, logit=18.0, token_id=65329, metadata=None))), (5907, (71, PredictedToken(token=' Project', prob=0.00010776519775390625, logit=11.875, token_id=5907, metadata=None))), (4783, (191, PredictedToken(token=' House', prob=1.3709068298339844e-05, logit=9.8125, token_id=4783, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:28 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:28 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.871, logit=22.250)', '\" The\"[578] (p=0.043, logit=19.250)', '\" Among\"[22395] (p=0.030, logit=18.875)', '\" A\"[362] (p=0.030, logit=18.875)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.773, logit=21.125)', '\" Among\"[22395] (p=0.092, logit=19.000)', '\" The\"[578] (p=0.049, logit=18.375)', '\" E\"[469] (p=0.011, logit=16.875)', '\" Out\"[4470] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.7734375, logit=21.125, token_id=445, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.01104736328125, logit=16.875, token_id=469, metadata=None))), (6031, (8, PredictedToken(token=' Bro', prob=0.004608154296875, logit=16.0, token_id=6031, metadata=None))), (50159, (96, PredictedToken(token=' Sco', prob=5.1021575927734375e-05, logit=11.5, token_id=50159, metadata=None))), (97796, (289, PredictedToken(token=' Skate', prob=5.066394805908203e-06, logit=9.1875, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     int_prediction=['\" Bro\"[6031] (p=0.844, logit=21.250)', '\" Among\"[22395] (p=0.069, logit=18.750)', '\" None\"[2290] (p=0.026, logit=17.750)', '\" The\"[578] (p=0.020, logit=17.500)', '\" Only\"[8442] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     int_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.84375, logit=21.25, token_id=6031, metadata=None))), (97796, (12, PredictedToken(token=' Skate', prob=0.0012664794921875, logit=14.75, token_id=97796, metadata=None))), (469, (47, PredictedToken(token=' E', prob=0.000133514404296875, logit=12.5, token_id=469, metadata=None))), (50159, (92, PredictedToken(token=' Sco', prob=3.600120544433594e-05, logit=11.1875, token_id=50159, metadata=None))), (445, (127, PredictedToken(token=' L', prob=2.0503997802734375e-05, logit=10.625, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:29 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:29 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     patch_prediction=['\" Caul\"[90538] (p=0.945, logit=22.500)', '\" The\"[578] (p=0.025, logit=18.875)', '\" Among\"[22395] (p=0.010, logit=18.000)', '\" A\"[362] (p=0.003, logit=16.625)', '\" Option\"[7104] (p=0.002, logit=16.375)']\n",
      "2025-09-16 09:45:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     clean_prediction=['\" Train\"[27217] (p=0.664, logit=21.750)', '\" The\"[578] (p=0.102, logit=19.875)', '\" A\"[362] (p=0.090, logit=19.750)', '\" Car\"[3341] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.038, logit=18.875)']\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     clean_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.6640625, logit=21.75, token_id=27217, metadata=None))), (3341, (4, PredictedToken(token=' Car', prob=0.061767578125, logit=19.375, token_id=3341, metadata=None))), (423, (19, PredictedToken(token=' D', prob=0.000827789306640625, logit=15.0625, token_id=423, metadata=None))), (82994, (67, PredictedToken(token=' Toilet', prob=7.2479248046875e-05, logit=12.625, token_id=82994, metadata=None))), (8219, (201, PredictedToken(token=' Sun', prob=6.318092346191406e-06, logit=10.1875, token_id=8219, metadata=None)))])\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.809, logit=22.125)', '\" The\"[578] (p=0.059, logit=19.500)', '\" A\"[362] (p=0.046, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=18.875)', '\" None\"[2290] (p=0.010, logit=17.750)']\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.80859375, logit=22.125, token_id=3341, metadata=None))), (423, (7, PredictedToken(token=' D', prob=0.0037384033203125, logit=16.75, token_id=423, metadata=None))), (8219, (10, PredictedToken(token=' Sun', prob=0.0029144287109375, logit=16.5, token_id=8219, metadata=None))), (82994, (202, PredictedToken(token=' Toilet', prob=4.976987838745117e-06, logit=10.125, token_id=82994, metadata=None))), (27217, (273, PredictedToken(token=' Train', prob=2.8312206268310547e-06, logit=9.5625, token_id=27217, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:30 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:30 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     patch_prediction=['\" Apple\"[8325] (p=0.797, logit=22.125)', '\" The\"[578] (p=0.065, logit=19.625)', '\" An\"[1556] (p=0.058, logit=19.500)', '\" Among\"[22395] (p=0.045, logit=19.250)', '\" It\"[1102] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.852, logit=22.500)', '\" An\"[1556] (p=0.070, logit=20.000)', '\" The\"[578] (p=0.033, logit=19.250)', '\" Among\"[22395] (p=0.018, logit=18.625)', '\" ank\"[71572] (p=0.005, logit=17.375)']\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.8515625, logit=22.5, token_id=57915, metadata=None))), (445, (70, PredictedToken(token=' L', prob=2.491474151611328e-05, logit=12.0625, token_id=445, metadata=None))), (24423, (107, PredictedToken(token=' Monitor', prob=1.33514404296875e-05, logit=11.4375, token_id=24423, metadata=None))), (41785, (300, PredictedToken(token=' Spin', prob=1.4081597328186035e-06, logit=9.1875, token_id=41785, metadata=None))), (10164, (452, PredictedToken(token=' Water', prob=7.078051567077637e-07, logit=8.5, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.828, logit=22.625)', '\" Among\"[22395] (p=0.068, logit=20.125)', '\" The\"[578] (p=0.047, logit=19.750)', '\" Spin\"[41785] (p=0.017, logit=18.750)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.828125, logit=22.625, token_id=10164, metadata=None))), (41785, (4, PredictedToken(token=' Spin', prob=0.0172119140625, logit=18.75, token_id=41785, metadata=None))), (445, (38, PredictedToken(token=' L', prob=0.00011587142944335938, logit=13.75, token_id=445, metadata=None))), (24423, (96, PredictedToken(token=' Monitor', prob=1.5735626220703125e-05, logit=11.75, token_id=24423, metadata=None))), (57915, (624, PredictedToken(token=' Ank', prob=3.688037395477295e-07, logit=8.0, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:30 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     patch_prediction=['\" Rice\"[30616] (p=0.715, logit=21.625)', '\" The\"[578] (p=0.085, logit=19.500)', '\" Among\"[22395] (p=0.076, logit=19.375)', '\" A\"[362] (p=0.076, logit=19.375)', '\" Option\"[7104] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     clean_prediction=['\" Pin\"[17929] (p=0.855, logit=22.125)', '\" The\"[578] (p=0.048, logit=19.250)', '\" A\"[362] (p=0.042, logit=19.125)', '\" Among\"[22395] (p=0.020, logit=18.375)', '\" It\"[1102] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     clean_track=OrderedDict([(17929, (1, PredictedToken(token=' Pin', prob=0.85546875, logit=22.125, token_id=17929, metadata=None))), (100031, (53, PredictedToken(token=' Mosque', prob=7.724761962890625e-05, logit=12.8125, token_id=100031, metadata=None))), (8219, (76, PredictedToken(token=' Sun', prob=4.124641418457031e-05, logit=12.1875, token_id=8219, metadata=None))), (27171, (168, PredictedToken(token=' Coffee', prob=6.3478946685791016e-06, logit=10.3125, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     int_prediction=['\" Coffee\"[27171] (p=0.719, logit=21.000)', '\" The\"[578] (p=0.086, logit=18.875)', '\" Among\"[22395] (p=0.059, logit=18.500)', '\" Sun\"[8219] (p=0.028, logit=17.750)', '\" A\"[362] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     int_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.71875, logit=21.0, token_id=27171, metadata=None))), (8219, (4, PredictedToken(token=' Sun', prob=0.0279541015625, logit=17.75, token_id=8219, metadata=None))), (100031, (48, PredictedToken(token=' Mosque', prob=0.0002269744873046875, logit=12.9375, token_id=100031, metadata=None))), (17929, (734, PredictedToken(token=' Pin', prob=1.3485550880432129e-06, logit=7.8125, token_id=17929, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:31 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:31 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     patch_prediction=['\" Paper\"[18343] (p=0.898, logit=21.250)', '\" None\"[2290] (p=0.021, logit=17.500)', '\" The\"[578] (p=0.021, logit=17.500)', '\" paper\"[5684] (p=0.011, logit=16.875)', '\" A\"[362] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:45:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     clean_prediction=['\" Phone\"[14642] (p=0.820, logit=21.625)', '\" The\"[578] (p=0.059, logit=19.000)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" A\"[362] (p=0.022, logit=18.000)', '\" phone\"[4641] (p=0.019, logit=17.875)']\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     clean_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.8203125, logit=21.625, token_id=14642, metadata=None))), (432, (37, PredictedToken(token=' R', prob=0.0003757476806640625, logit=13.9375, token_id=432, metadata=None))), (27171, (60, PredictedToken(token=' Coffee', prob=0.00010728836059570312, logit=12.6875, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.598, logit=20.875)', '\" Coffee\"[27171] (p=0.249, logit=20.000)', '\" A\"[362] (p=0.034, logit=18.000)', '\" Among\"[22395] (p=0.030, logit=17.875)', '\" The\"[578] (p=0.023, logit=17.625)']\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.59765625, logit=20.875, token_id=432, metadata=None))), (27171, (2, PredictedToken(token=' Coffee', prob=0.2490234375, logit=20.0, token_id=27171, metadata=None))), (14642, (119, PredictedToken(token=' Phone', prob=2.110004425048828e-05, logit=10.625, token_id=14642, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:32 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.543, logit=20.750)', '\" The\"[578] (p=0.155, logit=19.500)', '\" A\"[362] (p=0.138, logit=19.375)', '\" Among\"[22395] (p=0.094, logit=19.000)', '\" It\"[1102] (p=0.013, logit=17.000)']\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.852, logit=21.750)', '\" The\"[578] (p=0.070, logit=19.250)', '\" Among\"[22395] (p=0.020, logit=18.000)', '\" A\"[362] (p=0.018, logit=17.875)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.8515625, logit=21.75, token_id=72683, metadata=None))), (10573, (32, PredictedToken(token=' Watch', prob=0.00030517578125, logit=13.8125, token_id=10573, metadata=None))), (3420, (53, PredictedToken(token=' Trump', prob=8.726119995117188e-05, logit=12.5625, token_id=3420, metadata=None))), (100031, (110, PredictedToken(token=' Mosque', prob=1.9431114196777344e-05, logit=11.0625, token_id=100031, metadata=None))), (24423, (127, PredictedToken(token=' Monitor', prob=1.5139579772949219e-05, logit=10.8125, token_id=24423, metadata=None))), (87035, (1202, PredictedToken(token=' Onion', prob=3.7997961044311523e-07, logit=7.125, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     int_prediction=['\" Mosque\"[100031] (p=0.645, logit=20.750)', '\" Monitor\"[24423] (p=0.112, logit=19.000)', '\" The\"[578] (p=0.068, logit=18.500)', '\" Among\"[22395] (p=0.047, logit=18.125)', '\" Onion\"[87035] (p=0.032, logit=17.750)']\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     int_track=OrderedDict([(100031, (1, PredictedToken(token=' Mosque', prob=0.64453125, logit=20.75, token_id=100031, metadata=None))), (24423, (2, PredictedToken(token=' Monitor', prob=0.11181640625, logit=19.0, token_id=24423, metadata=None))), (87035, (5, PredictedToken(token=' Onion', prob=0.031982421875, logit=17.75, token_id=87035, metadata=None))), (10573, (27, PredictedToken(token=' Watch', prob=0.00075531005859375, logit=14.0, token_id=10573, metadata=None))), (3420, (401, PredictedToken(token=' Trump', prob=3.725290298461914e-06, logit=8.6875, token_id=3420, metadata=None))), (72683, (462, PredictedToken(token=' Boxing', prob=3.084540367126465e-06, logit=8.5, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:32 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:32 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.797, logit=22.625)', '\" The\"[578] (p=0.065, logit=20.125)', '\" A\"[362] (p=0.058, logit=20.000)', '\" Among\"[22395] (p=0.045, logit=19.750)', '\" It\"[1102] (p=0.008, logit=18.000)']\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     clean_prediction=['\" Camera\"[14669] (p=0.723, logit=21.625)', '\" The\"[578] (p=0.098, logit=19.625)', '\" Among\"[22395] (p=0.059, logit=19.125)', '\" A\"[362] (p=0.046, logit=18.875)', '\" It\"[1102] (p=0.010, logit=17.375)']\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     clean_track=OrderedDict([(14669, (1, PredictedToken(token=' Camera', prob=0.72265625, logit=21.625, token_id=14669, metadata=None))), (27171, (37, PredictedToken(token=' Coffee', prob=0.0004520416259765625, logit=14.25, token_id=27171, metadata=None))), (1901, (41, PredictedToken(token=' Z', prob=0.000331878662109375, logit=13.9375, token_id=1901, metadata=None))), (68554, (94, PredictedToken(token=' Gloves', prob=3.9577484130859375e-05, logit=11.8125, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.781, logit=21.500)', '\" Among\"[22395] (p=0.083, logit=19.250)', '\" The\"[578] (p=0.050, logit=18.750)', '\" None\"[2290] (p=0.024, logit=18.000)', '\" \"[220] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.78125, logit=21.5, token_id=1901, metadata=None))), (68554, (14, PredictedToken(token=' Gloves', prob=0.001708984375, logit=15.375, token_id=68554, metadata=None))), (27171, (38, PredictedToken(token=' Coffee', prob=0.000278472900390625, logit=13.5625, token_id=27171, metadata=None))), (14669, (1099, PredictedToken(token=' Camera', prob=3.4831464290618896e-07, logit=6.875, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:33 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:33 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     patch_prediction=['\" Ash\"[14937] (p=0.781, logit=21.250)', '\" The\"[578] (p=0.083, logit=19.000)', '\" An\"[1556] (p=0.039, logit=18.250)', '\" Among\"[22395] (p=0.024, logit=17.750)', '\" A\"[362] (p=0.013, logit=17.125)']\n",
      "2025-09-16 09:45:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     clean_prediction=['\" Bat\"[16488] (p=0.871, logit=21.625)', '\" The\"[578] (p=0.038, logit=18.500)', '\" A\"[362] (p=0.023, logit=18.000)', '\" Among\"[22395] (p=0.014, logit=17.500)', '\" BAT\"[79081] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     clean_track=OrderedDict([(16488, (1, PredictedToken(token=' Bat', prob=0.87109375, logit=21.625, token_id=16488, metadata=None))), (6771, (9, PredictedToken(token=' Table', prob=0.0023040771484375, logit=15.6875, token_id=6771, metadata=None))), (18787, (19, PredictedToken(token=' Oak', prob=0.0009613037109375, logit=14.8125, token_id=18787, metadata=None))), (432, (31, PredictedToken(token=' R', prob=0.0003757476806640625, logit=13.875, token_id=432, metadata=None)))])\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     int_prediction=['\" Table\"[6771] (p=0.777, logit=20.875)', '\" Bat\"[16488] (p=0.072, logit=18.500)', '\" The\"[578] (p=0.039, logit=17.875)', '\" Among\"[22395] (p=0.023, logit=17.375)', '\" None\"[2290] (p=0.010, logit=16.500)']\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     int_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.77734375, logit=20.875, token_id=6771, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.072265625, logit=18.5, token_id=16488, metadata=None))), (18787, (7, PredictedToken(token=' Oak', prob=0.00860595703125, logit=16.375, token_id=18787, metadata=None))), (432, (6, PredictedToken(token=' R', prob=0.00860595703125, logit=16.375, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:34 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.859, logit=21.250)', '\" The\"[578] (p=0.043, logit=18.250)', '\" A\"[362] (p=0.033, logit=18.000)', '\" Among\"[22395] (p=0.016, logit=17.250)', '\" hair\"[7013] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     clean_prediction=['\" S\"[328] (p=0.848, logit=22.250)', '\" The\"[578] (p=0.069, logit=19.750)', '\" Among\"[22395] (p=0.042, logit=19.250)', '\" socks\"[40086] (p=0.004, logit=17.000)', '\" A\"[362] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     clean_track=OrderedDict([(328, (1, PredictedToken(token=' S', prob=0.84765625, logit=22.25, token_id=328, metadata=None))), (469, (8, PredictedToken(token=' E', prob=0.00238037109375, logit=16.375, token_id=469, metadata=None))), (41342, (39, PredictedToken(token=' Hockey', prob=0.00015163421630859375, logit=13.625, token_id=41342, metadata=None))), (82994, (102, PredictedToken(token=' Toilet', prob=1.9311904907226562e-05, logit=11.5625, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     int_prediction=['\" Toilet\"[82994] (p=0.754, logit=21.250)', '\" The\"[578] (p=0.090, logit=19.125)', '\" Among\"[22395] (p=0.048, logit=18.500)', '\" E\"[469] (p=0.016, logit=17.375)', '\" Only\"[8442] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     int_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.75390625, logit=21.25, token_id=82994, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.015625, logit=17.375, token_id=469, metadata=None))), (41342, (81, PredictedToken(token=' Hockey', prob=7.2479248046875e-05, logit=12.0, token_id=41342, metadata=None))), (328, (116, PredictedToken(token=' S', prob=2.6702880859375e-05, logit=11.0, token_id=328, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:34 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:34 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:45:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     patch_prediction=['\" Rose\"[16344] (p=0.824, logit=22.500)', '\" The\"[578] (p=0.068, logit=20.000)', '\" A\"[362] (p=0.041, logit=19.500)', '\" Among\"[22395] (p=0.028, logit=19.125)', '\" (\"[320] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     clean_prediction=['\" Er\"[9939] (p=0.859, logit=21.500)', '\" An\"[1556] (p=0.048, logit=18.625)', '\" The\"[578] (p=0.029, logit=18.125)', '\" Among\"[22395] (p=0.012, logit=17.250)', '\" er\"[2781] (p=0.010, logit=17.000)']\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     clean_track=OrderedDict([(9939, (1, PredictedToken(token=' Er', prob=0.859375, logit=21.5, token_id=9939, metadata=None))), (2947, (24, PredictedToken(token=' Mar', prob=0.0004749298095703125, logit=14.0, token_id=2947, metadata=None))), (15429, (153, PredictedToken(token=' Hospital', prob=9.834766387939453e-06, logit=10.125, token_id=15429, metadata=None)))])\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     int_prediction=['\" Mar\"[2947] (p=0.895, logit=21.500)', '\" The\"[578] (p=0.031, logit=18.125)', '\" Among\"[22395] (p=0.016, logit=17.500)', '\" Only\"[8442] (p=0.007, logit=16.625)', '\" mar\"[3678] (p=0.007, logit=16.625)']\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     int_track=OrderedDict([(2947, (1, PredictedToken(token=' Mar', prob=0.89453125, logit=21.5, token_id=2947, metadata=None))), (15429, (138, PredictedToken(token=' Hospital', prob=1.239776611328125e-05, logit=10.3125, token_id=15429, metadata=None))), (9939, (452, PredictedToken(token=' Er', prob=1.6763806343078613e-06, logit=8.3125, token_id=9939, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:35 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:35 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.789, logit=22.250)', '\" The\"[578] (p=0.073, logit=19.875)', '\" A\"[362] (p=0.065, logit=19.750)', '\" Among\"[22395] (p=0.031, logit=19.000)', '\" z\"[1167] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:45:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     clean_prediction=['\" Onion\"[87035] (p=0.793, logit=21.250)', '\" The\"[578] (p=0.074, logit=18.875)', '\" An\"[1556] (p=0.057, logit=18.625)', '\" Among\"[22395] (p=0.021, logit=17.625)', '\" It\"[1102] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     clean_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.79296875, logit=21.25, token_id=87035, metadata=None))), (79189, (7, PredictedToken(token=' Elephant', prob=0.00323486328125, logit=15.75, token_id=79189, metadata=None))), (61948, (301, PredictedToken(token=' Sofa', prob=4.291534423828125e-06, logit=9.125, token_id=61948, metadata=None))), (56491, (423, PredictedToken(token=' Piano', prob=2.60770320892334e-06, logit=8.625, token_id=56491, metadata=None)))])\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     int_prediction=['\" Elephant\"[79189] (p=0.855, logit=21.125)', '\" The\"[578] (p=0.048, logit=18.250)', '\" Among\"[22395] (p=0.020, logit=17.375)', '\" None\"[2290] (p=0.014, logit=17.000)', '\" An\"[1556] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     int_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.85546875, logit=21.125, token_id=79189, metadata=None))), (56491, (10, PredictedToken(token=' Piano', prob=0.00176239013671875, logit=14.9375, token_id=56491, metadata=None))), (61948, (19, PredictedToken(token=' Sofa', prob=0.000885009765625, logit=14.25, token_id=61948, metadata=None))), (87035, (224, PredictedToken(token=' Onion', prob=8.165836334228516e-06, logit=9.5625, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:36 src.selection.optimization DEBUG    torch.Size([5, 31])\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.848, logit=22.250)', '\" Among\"[22395] (p=0.054, logit=19.500)', '\" The\"[578] (p=0.054, logit=19.500)', '\" A\"[362] (p=0.008, logit=17.625)', '\" It\"[1102] (p=0.003, logit=16.625)']\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     clean_prediction=['\" Jasmine\"[82452] (p=0.855, logit=21.500)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" The\"[578] (p=0.042, logit=18.500)', '\" jasmine\"[66909] (p=0.007, logit=16.750)', '\" Option\"[7104] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     clean_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.85546875, logit=21.5, token_id=82452, metadata=None))), (45805, (13, PredictedToken(token=' Cherry', prob=0.00186920166015625, logit=15.375, token_id=45805, metadata=None))), (328, (41, PredictedToken(token=' S', prob=0.0001964569091796875, logit=13.125, token_id=328, metadata=None))), (58600, (83, PredictedToken(token=' Charm', prob=4.673004150390625e-05, logit=11.6875, token_id=58600, metadata=None))), (94467, (137, PredictedToken(token=' Trom', prob=1.621246337890625e-05, logit=10.625, token_id=94467, metadata=None)))])\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     int_prediction=['\" Cherry\"[45805] (p=0.891, logit=21.750)', '\" Among\"[22395] (p=0.034, logit=18.500)', '\" The\"[578] (p=0.031, logit=18.375)', '\" S\"[328] (p=0.007, logit=16.875)', '\" Option\"[7104] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     int_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.890625, logit=21.75, token_id=45805, metadata=None))), (328, (4, PredictedToken(token=' S', prob=0.006805419921875, logit=16.875, token_id=328, metadata=None))), (58600, (53, PredictedToken(token=' Charm', prob=7.104873657226562e-05, logit=12.3125, token_id=58600, metadata=None))), (82452, (61, PredictedToken(token=' Jasmine', prob=5.53131103515625e-05, logit=12.0625, token_id=82452, metadata=None))), (94467, (789, PredictedToken(token=' Trom', prob=6.146728992462158e-07, logit=7.5625, token_id=94467, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:36 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:36 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:45:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     patch_prediction=['\" Highlight\"[57094] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.053, logit=19.000)', '\" Among\"[22395] (p=0.042, logit=18.750)', '\" A\"[362] (p=0.037, logit=18.625)', '\" \"[220] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.770, logit=21.625)', '\" The\"[578] (p=0.063, logit=19.125)', '\" b\"[293] (p=0.056, logit=19.000)', '\" A\"[362] (p=0.049, logit=18.875)', '\" Among\"[22395] (p=0.018, logit=17.875)']\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.76953125, logit=21.625, token_id=426, metadata=None))), (91263, (15, PredictedToken(token=' Binder', prob=0.000957489013671875, logit=14.9375, token_id=91263, metadata=None))), (41785, (61, PredictedToken(token=' Spin', prob=6.103515625e-05, logit=12.1875, token_id=41785, metadata=None))), (100031, (87, PredictedToken(token=' Mosque', prob=2.8967857360839844e-05, logit=11.4375, token_id=100031, metadata=None))), (50159, (135, PredictedToken(token=' Sco', prob=1.1324882507324219e-05, logit=10.5, token_id=50159, metadata=None)))])\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     int_prediction=['\" The\"[578] (p=0.258, logit=18.625)', '\" Binder\"[91263] (p=0.228, logit=18.500)', '\" Among\"[22395] (p=0.122, logit=17.875)', '\" Spin\"[41785] (p=0.084, logit=17.500)', '\" Mosque\"[100031] (p=0.058, logit=17.125)']\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     int_track=OrderedDict([(91263, (2, PredictedToken(token=' Binder', prob=0.2275390625, logit=18.5, token_id=91263, metadata=None))), (41785, (4, PredictedToken(token=' Spin', prob=0.083984375, logit=17.5, token_id=41785, metadata=None))), (100031, (5, PredictedToken(token=' Mosque', prob=0.0576171875, logit=17.125, token_id=100031, metadata=None))), (50159, (10, PredictedToken(token=' Sco', prob=0.0164794921875, logit=15.875, token_id=50159, metadata=None))), (426, (43, PredictedToken(token=' B', prob=0.000682830810546875, logit=12.6875, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:37 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:37 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:45:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.840, logit=21.125)', '\" The\"[578] (p=0.054, logit=18.375)', '\" Among\"[22395] (p=0.025, logit=17.625)', '\" Mouse\"[18191] (p=0.022, logit=17.500)', '\" A\"[362] (p=0.017, logit=17.250)']\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     clean_prediction=['\" Mirror\"[34954] (p=0.875, logit=21.500)', '\" Highlight\"[57094] (p=0.038, logit=18.375)', '\" A\"[362] (p=0.018, logit=17.625)', '\" None\"[2290] (p=0.012, logit=17.250)', '\" The\"[578] (p=0.012, logit=17.250)']\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     clean_track=OrderedDict([(34954, (1, PredictedToken(token=' Mirror', prob=0.875, logit=21.5, token_id=34954, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.038330078125, logit=18.375, token_id=57094, metadata=None))), (6914, (7, PredictedToken(token=' Let', prob=0.006683349609375, logit=16.625, token_id=6914, metadata=None))), (4923, (30, PredictedToken(token=' Sk', prob=0.0002593994140625, logit=13.375, token_id=4923, metadata=None))), (89077, (35, PredictedToken(token=' Strawberry', prob=0.00021457672119140625, logit=13.1875, token_id=89077, metadata=None))), (82507, (75, PredictedToken(token=' Jeans', prob=5.7697296142578125e-05, logit=11.875, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     int_prediction=['\" Highlight\"[57094] (p=0.389, logit=19.625)', '\" Let\"[6914] (p=0.342, logit=19.500)', '\" None\"[2290] (p=0.184, logit=18.875)', '\" The\"[578] (p=0.019, logit=16.625)', '\" Among\"[22395] (p=0.012, logit=16.125)']\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     int_track=OrderedDict([(57094, (1, PredictedToken(token=' Highlight', prob=0.388671875, logit=19.625, token_id=57094, metadata=None))), (6914, (2, PredictedToken(token=' Let', prob=0.341796875, logit=19.5, token_id=6914, metadata=None))), (82507, (19, PredictedToken(token=' Jeans', prob=0.000904083251953125, logit=13.5625, token_id=82507, metadata=None))), (34954, (147, PredictedToken(token=' Mirror', prob=2.7298927307128906e-05, logit=10.0625, token_id=34954, metadata=None))), (89077, (156, PredictedToken(token=' Strawberry', prob=2.562999725341797e-05, logit=10.0, token_id=89077, metadata=None))), (4923, (246, PredictedToken(token=' Sk', prob=1.2099742889404297e-05, logit=9.25, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:38 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:38 src.selection.optimization DEBUG    torch.Size([6, 33])\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     patch_prediction=['\" Tablet\"[58403] (p=0.504, logit=20.250)', '\" The\"[578] (p=0.163, logit=19.125)', '\" Among\"[22395] (p=0.112, logit=18.750)', '\" A\"[362] (p=0.077, logit=18.375)', '\" X\"[1630] (p=0.020, logit=17.000)']\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.621, logit=21.375)', '\" The\"[578] (p=0.201, logit=20.250)', '\" A\"[362] (p=0.074, logit=19.250)', '\" Among\"[22395] (p=0.051, logit=18.875)', '\" It\"[1102] (p=0.016, logit=17.750)']\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.62109375, logit=21.375, token_id=31181, metadata=None))), (16344, (75, PredictedToken(token=' Rose', prob=4.935264587402344e-05, logit=11.9375, token_id=16344, metadata=None))), (4923, (79, PredictedToken(token=' Sk', prob=4.6253204345703125e-05, logit=11.875, token_id=4923, metadata=None))), (14642, (118, PredictedToken(token=' Phone', prob=1.9311904907226562e-05, logit=11.0, token_id=14642, metadata=None))), (75258, (276, PredictedToken(token=' Refriger', prob=3.5762786865234375e-06, logit=9.3125, token_id=75258, metadata=None))), (32498, (2109, PredictedToken(token=' Mall', prob=1.7229467630386353e-07, logit=6.28125, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:45:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     int_prediction=['\" Phone\"[14642] (p=0.766, logit=22.000)', '\" The\"[578] (p=0.117, logit=20.125)', '\" Among\"[22395] (p=0.043, logit=19.125)', '\" A\"[362] (p=0.023, logit=18.500)', '\" It\"[1102] (p=0.011, logit=17.750)']\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     int_track=OrderedDict([(14642, (1, PredictedToken(token=' Phone', prob=0.765625, logit=22.0, token_id=14642, metadata=None))), (4923, (91, PredictedToken(token=' Sk', prob=2.872943878173828e-05, logit=11.8125, token_id=4923, metadata=None))), (16344, (198, PredictedToken(token=' Rose', prob=5.662441253662109e-06, logit=10.1875, token_id=16344, metadata=None))), (32498, (383, PredictedToken(token=' Mall', prob=1.5273690223693848e-06, logit=8.875, token_id=32498, metadata=None))), (75258, (410, PredictedToken(token=' Refriger', prob=1.341104507446289e-06, logit=8.75, token_id=75258, metadata=None))), (31181, (741, PredictedToken(token=' Clar', prob=5.252659320831299e-07, logit=7.8125, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:39 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.840, logit=22.875)', '\" The\"[578] (p=0.078, logit=20.500)', '\" A\"[362] (p=0.020, logit=19.125)', '\" Among\"[22395] (p=0.017, logit=19.000)', '\" (\"[320] (p=0.008, logit=18.250)']\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     clean_prediction=['\" Hockey\"[41342] (p=0.832, logit=21.875)', '\" The\"[578] (p=0.060, logit=19.250)', '\" A\"[362] (p=0.053, logit=19.125)', '\" Among\"[22395] (p=0.013, logit=17.750)', '\" (\"[320] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     clean_track=OrderedDict([(41342, (1, PredictedToken(token=' Hockey', prob=0.83203125, logit=21.875, token_id=41342, metadata=None))), (60413, (86, PredictedToken(token=' Uk', prob=2.014636993408203e-05, logit=11.25, token_id=60413, metadata=None))), (9939, (198, PredictedToken(token=' Er', prob=4.231929779052734e-06, logit=9.6875, token_id=9939, metadata=None)))])\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     int_prediction=['\" Uk\"[60413] (p=0.711, logit=21.000)', '\" The\"[578] (p=0.085, logit=18.875)', '\" Among\"[22395] (p=0.075, logit=18.750)', '\" (\"[320] (p=0.019, logit=17.375)', '\" A\"[362] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     int_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.7109375, logit=21.0, token_id=60413, metadata=None))), (9939, (7, PredictedToken(token=' Er', prob=0.0130615234375, logit=17.0, token_id=9939, metadata=None))), (41342, (46, PredictedToken(token=' Hockey', prob=0.00018596649169921875, logit=12.75, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:39 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:39 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:45:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     patch_prediction=['\" Microwave\"[98641] (p=0.789, logit=21.625)', '\" The\"[578] (p=0.073, logit=19.250)', '\" A\"[362] (p=0.050, logit=18.875)', '\" Among\"[22395] (p=0.044, logit=18.750)', '\" Option\"[7104] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     clean_prediction=['\" Tennis\"[58251] (p=0.746, logit=21.375)', '\" The\"[578] (p=0.101, logit=19.375)', '\" A\"[362] (p=0.089, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.000)', '\" It\"[1102] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     clean_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.74609375, logit=21.375, token_id=58251, metadata=None))), (40975, (26, PredictedToken(token=' Marker', prob=0.0003643035888671875, logit=13.75, token_id=40975, metadata=None))), (469, (37, PredictedToken(token=' E', prob=0.00018310546875, logit=13.0625, token_id=469, metadata=None))), (79189, (366, PredictedToken(token=' Elephant', prob=2.3096799850463867e-06, logit=8.6875, token_id=79189, metadata=None))), (87213, (382, PredictedToken(token=' Oven', prob=2.16066837310791e-06, logit=8.625, token_id=87213, metadata=None))), (80629, (499, PredictedToken(token=' Grape', prob=1.4901161193847656e-06, logit=8.25, token_id=80629, metadata=None)))])\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     int_prediction=['\" Oven\"[87213] (p=0.680, logit=20.750)', '\" The\"[578] (p=0.081, logit=18.625)', '\" Among\"[22395] (p=0.072, logit=18.500)', '\" An\"[1556] (p=0.063, logit=18.375)', '\" E\"[469] (p=0.018, logit=17.125)']\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     int_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.6796875, logit=20.75, token_id=87213, metadata=None))), (469, (5, PredictedToken(token=' E', prob=0.01806640625, logit=17.125, token_id=469, metadata=None))), (40975, (14, PredictedToken(token=' Marker', prob=0.0023040771484375, logit=15.0625, token_id=40975, metadata=None))), (58251, (37, PredictedToken(token=' Tennis', prob=0.0003757476806640625, logit=13.25, token_id=58251, metadata=None))), (79189, (175, PredictedToken(token=' Elephant', prob=1.3709068298339844e-05, logit=9.9375, token_id=79189, metadata=None))), (80629, (440, PredictedToken(token=' Grape', prob=3.4570693969726562e-06, logit=8.5625, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:40 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:40 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     patch_prediction=['\" Hair\"[26781] (p=0.797, logit=21.125)', '\" Chain\"[29625] (p=0.058, logit=18.500)', '\" A\"[362] (p=0.035, logit=18.000)', '\" The\"[578] (p=0.031, logit=17.875)', '\" Fl\"[3061] (p=0.015, logit=17.125)']\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     clean_prediction=['\" Har\"[5340] (p=0.781, logit=21.750)', '\" The\"[578] (p=0.093, logit=19.625)', '\" A\"[362] (p=0.050, logit=19.000)', '\" Among\"[22395] (p=0.027, logit=18.375)', '\" It\"[1102] (p=0.011, logit=17.500)']\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     clean_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.78125, logit=21.75, token_id=5340, metadata=None))), (48035, (35, PredictedToken(token=' Gir', prob=0.0002040863037109375, logit=13.5, token_id=48035, metadata=None))), (42609, (187, PredictedToken(token=' Pine', prob=6.139278411865234e-06, logit=10.0, token_id=42609, metadata=None))), (83499, (230, PredictedToken(token=' Tooth', prob=3.9637088775634766e-06, logit=9.5625, token_id=83499, metadata=None))), (34046, (461, PredictedToken(token=' Cabinet', prob=1.0728836059570312e-06, logit=8.25, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:45:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     int_prediction=['\" Tooth\"[83499] (p=0.836, logit=21.250)', '\" The\"[578] (p=0.047, logit=18.375)', '\" Among\"[22395] (p=0.042, logit=18.250)', '\" Cabinet\"[34046] (p=0.012, logit=17.000)', '\" Option\"[7104] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     int_track=OrderedDict([(83499, (1, PredictedToken(token=' Tooth', prob=0.8359375, logit=21.25, token_id=83499, metadata=None))), (34046, (4, PredictedToken(token=' Cabinet', prob=0.011962890625, logit=17.0, token_id=34046, metadata=None))), (42609, (24, PredictedToken(token=' Pine', prob=0.0007171630859375, logit=14.1875, token_id=42609, metadata=None))), (48035, (316, PredictedToken(token=' Gir', prob=3.3229589462280273e-06, logit=8.8125, token_id=48035, metadata=None))), (5340, (832, PredictedToken(token=' Har', prob=8.381903171539307e-07, logit=7.4375, token_id=5340, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:41 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:41 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     patch_prediction=['\" D\"[423] (p=0.805, logit=22.125)', '\" The\"[578] (p=0.109, logit=20.125)', '\" A\"[362] (p=0.028, logit=18.750)', '\" Among\"[22395] (p=0.017, logit=18.250)', '\" d\"[294] (p=0.011, logit=17.875)']\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.938, logit=21.875)', '\" The\"[578] (p=0.013, logit=17.625)', '\" Cedar\"[57748] (p=0.006, logit=16.875)', '\" A\"[362] (p=0.005, logit=16.625)', '\" (\"[320] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.9375, logit=21.875, token_id=735, metadata=None))), (57748, (3, PredictedToken(token=' Cedar', prob=0.006317138671875, logit=16.875, token_id=57748, metadata=None))), (74574, (58, PredictedToken(token=' Violet', prob=5.459785461425781e-05, logit=12.125, token_id=74574, metadata=None)))])\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.871, logit=21.250)', '\" None\"[2290] (p=0.043, logit=18.250)', '\" Cedar\"[57748] (p=0.014, logit=17.125)', '\" Option\"[7104] (p=0.011, logit=16.875)', '\" Options\"[14908] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.87109375, logit=21.25, token_id=74574, metadata=None))), (57748, (3, PredictedToken(token=' Cedar', prob=0.01409912109375, logit=17.125, token_id=57748, metadata=None))), (735, (21, PredictedToken(token=' K', prob=0.0004825592041015625, logit=13.75, token_id=735, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:41 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:41 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:45:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     patch_prediction=['\" Tape\"[58586] (p=0.895, logit=21.500)', '\" The\"[578] (p=0.039, logit=18.375)', '\" Among\"[22395] (p=0.014, logit=17.375)', '\" None\"[2290] (p=0.009, logit=16.875)', '\" A\"[362] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.672, logit=20.125)', '\" Fl\"[3061] (p=0.071, logit=17.875)', '\" The\"[578] (p=0.062, logit=17.750)', '\" Among\"[22395] (p=0.043, logit=17.375)', '\" Option\"[7104] (p=0.020, logit=16.625)']\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.671875, logit=20.125, token_id=87213, metadata=None))), (3061, (2, PredictedToken(token=' Fl', prob=0.07080078125, logit=17.875, token_id=3061, metadata=None))), (91963, (195, PredictedToken(token=' Mango', prob=2.6941299438476562e-05, logit=10.0, token_id=91963, metadata=None))), (37128, (314, PredictedToken(token=' Calculator', prob=1.1205673217773438e-05, logit=9.125, token_id=37128, metadata=None)))])\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     int_prediction=['\" Calculator\"[37128] (p=0.237, logit=18.500)', '\" Among\"[22395] (p=0.144, logit=18.000)', '\" Fl\"[3061] (p=0.144, logit=18.000)', '\" None\"[2290] (p=0.087, logit=17.500)', '\" The\"[578] (p=0.087, logit=17.500)']\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     int_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.2373046875, logit=18.5, token_id=37128, metadata=None))), (3061, (2, PredictedToken(token=' Fl', prob=0.1435546875, logit=18.0, token_id=3061, metadata=None))), (87213, (9, PredictedToken(token=' Oven', prob=0.01611328125, logit=15.8125, token_id=87213, metadata=None))), (91963, (145, PredictedToken(token=' Mango', prob=7.009506225585938e-05, logit=10.375, token_id=91963, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:42 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     patch_prediction=['\" Horse\"[34392] (p=0.734, logit=21.750)', '\" The\"[578] (p=0.112, logit=19.875)', '\" A\"[362] (p=0.077, logit=19.500)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" \"[220] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.645, logit=20.500)', '\" The\"[578] (p=0.144, logit=19.000)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" Short\"[10928] (p=0.017, logit=16.875)', '\" A\"[362] (p=0.015, logit=16.750)']\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.64453125, logit=20.5, token_id=91782, metadata=None))), (16344, (14, PredictedToken(token=' Rose', prob=0.004608154296875, logit=15.5625, token_id=16344, metadata=None))), (16488, (96, PredictedToken(token=' Bat', prob=7.915496826171875e-05, logit=11.5, token_id=16488, metadata=None))), (17810, (106, PredictedToken(token=' Cat', prob=5.793571472167969e-05, logit=11.1875, token_id=17810, metadata=None))), (3420, (309, PredictedToken(token=' Trump', prob=7.3909759521484375e-06, logit=9.125, token_id=3420, metadata=None)))])\n",
      "2025-09-16 09:45:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     int_prediction=['\" Cat\"[17810] (p=0.699, logit=22.000)', '\" Bat\"[16488] (p=0.107, logit=20.125)', '\" The\"[578] (p=0.083, logit=19.875)', '\" Among\"[22395] (p=0.035, logit=19.000)', '\" A\"[362] (p=0.021, logit=18.500)']\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     int_track=OrderedDict([(17810, (1, PredictedToken(token=' Cat', prob=0.69921875, logit=22.0, token_id=17810, metadata=None))), (16488, (2, PredictedToken(token=' Bat', prob=0.10693359375, logit=20.125, token_id=16488, metadata=None))), (16344, (87, PredictedToken(token=' Rose', prob=3.600120544433594e-05, logit=12.125, token_id=16344, metadata=None))), (3420, (221, PredictedToken(token=' Trump', prob=4.559755325317383e-06, logit=10.0625, token_id=3420, metadata=None))), (91782, (4607, PredictedToken(token=' Shorts', prob=3.841705620288849e-08, logit=5.28125, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:43 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:43 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     patch_prediction=['\" Mosque\"[100031] (p=0.891, logit=22.000)', '\" A\"[362] (p=0.039, logit=18.875)', '\" The\"[578] (p=0.034, logit=18.750)', '\" Among\"[22395] (p=0.013, logit=17.750)', '\" MOS\"[74174] (p=0.003, logit=16.375)']\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.887, logit=22.875)', '\" The\"[578] (p=0.044, logit=19.875)', '\" A\"[362] (p=0.034, logit=19.625)', '\" Among\"[22395] (p=0.021, logit=19.125)', '\" Option\"[7104] (p=0.001, logit=16.375)']\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.88671875, logit=22.875, token_id=88668, metadata=None))), (94467, (16, PredictedToken(token=' Trom', prob=0.00029754638671875, logit=14.875, token_id=94467, metadata=None))), (74574, (172, PredictedToken(token=' Violet', prob=3.3080577850341797e-06, logit=10.375, token_id=74574, metadata=None))), (11896, (501, PredictedToken(token=' Library', prob=4.76837158203125e-07, logit=8.4375, token_id=11896, metadata=None))), (49431, (818, PredictedToken(token=' Rabbit', prob=2.551823854446411e-07, logit=7.8125, token_id=49431, metadata=None)))])\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.762, logit=21.750)', '\" The\"[578] (p=0.103, logit=19.750)', '\" Among\"[22395] (p=0.055, logit=19.125)', '\" Violet\"[74574] (p=0.026, logit=18.375)', '\" Rabbit\"[49431] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.76171875, logit=21.75, token_id=11896, metadata=None))), (74574, (4, PredictedToken(token=' Violet', prob=0.0260009765625, logit=18.375, token_id=74574, metadata=None))), (49431, (5, PredictedToken(token=' Rabbit', prob=0.013916015625, logit=17.75, token_id=49431, metadata=None))), (94467, (43, PredictedToken(token=' Trom', prob=0.00014495849609375, logit=13.1875, token_id=94467, metadata=None))), (88668, (5792, PredictedToken(token=' Blender', prob=3.795139491558075e-08, logit=4.9375, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:43 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.852, logit=22.250)', '\" The\"[578] (p=0.062, logit=19.625)', '\" Among\"[22395] (p=0.029, logit=18.875)', '\" A\"[362] (p=0.020, logit=18.500)', '\" Option\"[7104] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     clean_prediction=['\" Microwave\"[98641] (p=0.938, logit=23.000)', '\" The\"[578] (p=0.022, logit=19.250)', '\" A\"[362] (p=0.012, logit=18.625)', '\" Among\"[22395] (p=0.005, logit=17.750)', '\" Option\"[7104] (p=0.004, logit=17.625)']\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     clean_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.9375, logit=23.0, token_id=98641, metadata=None))), (74968, (121, PredictedToken(token=' Razor', prob=5.781650543212891e-06, logit=11.0, token_id=74968, metadata=None))), (47643, (181, PredictedToken(token=' Cel', prob=2.3990869522094727e-06, logit=10.125, token_id=47643, metadata=None)))])\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     int_prediction=['\" Cel\"[47643] (p=0.840, logit=22.375)', '\" The\"[578] (p=0.054, logit=19.625)', '\" Among\"[22395] (p=0.047, logit=19.500)', '\" Option\"[7104] (p=0.020, logit=18.625)', '\" (\"[320] (p=0.007, logit=17.625)']\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     int_track=OrderedDict([(47643, (1, PredictedToken(token=' Cel', prob=0.83984375, logit=22.375, token_id=47643, metadata=None))), (98641, (205, PredictedToken(token=' Microwave', prob=3.546476364135742e-06, logit=10.0, token_id=98641, metadata=None))), (74968, (577, PredictedToken(token=' Razor', prob=6.556510925292969e-07, logit=8.3125, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:44 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     patch_prediction=['\" L\"[445] (p=0.789, logit=20.500)', '\" Among\"[22395] (p=0.065, logit=18.000)', '\" The\"[578] (p=0.044, logit=17.625)', '\" E\"[469] (p=0.016, logit=16.625)', '\" LOT\"[54460] (p=0.005, logit=15.438)']\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     clean_prediction=['\" Bike\"[38930] (p=0.754, logit=21.375)', '\" The\"[578] (p=0.080, logit=19.125)', '\" A\"[362] (p=0.062, logit=18.875)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" None\"[2290] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     clean_track=OrderedDict([(38930, (1, PredictedToken(token=' Bike', prob=0.75390625, logit=21.375, token_id=38930, metadata=None))), (79028, (20, PredictedToken(token=' Hick', prob=0.000942230224609375, logit=14.6875, token_id=79028, metadata=None))), (328, (42, PredictedToken(token=' S', prob=0.000209808349609375, logit=13.1875, token_id=328, metadata=None))), (1443, (130, PredictedToken(token=' Sh', prob=1.621246337890625e-05, logit=10.625, token_id=1443, metadata=None))), (63606, (160, PredictedToken(token=' Stap', prob=1.1146068572998047e-05, logit=10.25, token_id=63606, metadata=None))), (66821, (350, PredictedToken(token=' Iris', prob=2.637505531311035e-06, logit=8.8125, token_id=66821, metadata=None)))])\n",
      "2025-09-16 09:45:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     int_prediction=['\" Sh\"[1443] (p=0.551, logit=20.375)', '\" Among\"[22395] (p=0.140, logit=19.000)', '\" S\"[328] (p=0.058, logit=18.125)', '\" Iris\"[66821] (p=0.051, logit=18.000)', '\" The\"[578] (p=0.045, logit=17.875)']\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     int_track=OrderedDict([(1443, (1, PredictedToken(token=' Sh', prob=0.55078125, logit=20.375, token_id=1443, metadata=None))), (328, (3, PredictedToken(token=' S', prob=0.05810546875, logit=18.125, token_id=328, metadata=None))), (66821, (4, PredictedToken(token=' Iris', prob=0.05126953125, logit=18.0, token_id=66821, metadata=None))), (63606, (7, PredictedToken(token=' Stap', prob=0.031005859375, logit=17.5, token_id=63606, metadata=None))), (79028, (8, PredictedToken(token=' Hick', prob=0.012939453125, logit=16.625, token_id=79028, metadata=None))), (38930, (220, PredictedToken(token=' Bike', prob=1.043081283569336e-05, logit=9.5, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:45 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     patch_prediction=['\" Phone\"[14642] (p=0.863, logit=21.875)', '\" The\"[578] (p=0.030, logit=18.500)', '\" phone\"[4641] (p=0.018, logit=18.000)', '\" A\"[362] (p=0.018, logit=18.000)', '\" Har\"[5340] (p=0.014, logit=17.750)']\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.789, logit=21.000)', '\" The\"[578] (p=0.057, logit=18.375)', '\" A\"[362] (p=0.044, logit=18.125)', '\" Keyboard\"[26698] (p=0.021, logit=17.375)', '\" None\"[2290] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.7890625, logit=21.0, token_id=36943, metadata=None))), (26698, (4, PredictedToken(token=' Keyboard', prob=0.02099609375, logit=17.375, token_id=26698, metadata=None))), (48471, (52, PredictedToken(token=' Shower', prob=0.00020599365234375, logit=12.75, token_id=48471, metadata=None)))])\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.855, logit=21.125)', '\" None\"[2290] (p=0.038, logit=18.000)', '\" The\"[578] (p=0.029, logit=17.750)', '\" keyboard\"[13939] (p=0.018, logit=17.250)', '\" A\"[362] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.85546875, logit=21.125, token_id=26698, metadata=None))), (48471, (30, PredictedToken(token=' Shower', prob=0.0004177093505859375, logit=13.5, token_id=48471, metadata=None))), (36943, (219, PredictedToken(token=' Folder', prob=9.834766387939453e-06, logit=9.75, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:45 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:45 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:45:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.820, logit=20.750)', '\" None\"[2290] (p=0.067, logit=18.250)', '\" The\"[578] (p=0.028, logit=17.375)', '\" A\"[362] (p=0.022, logit=17.125)', '\" There\"[2684] (p=0.008, logit=16.125)']\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.793, logit=20.250)', '\" The\"[578] (p=0.065, logit=17.750)', '\" helmet\"[32635] (p=0.015, logit=16.250)', '\" Among\"[22395] (p=0.011, logit=16.000)', '\" None\"[2290] (p=0.011, logit=16.000)']\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.79296875, logit=20.25, token_id=67629, metadata=None))), (98028, (12, PredictedToken(token=' Bamboo', prob=0.004730224609375, logit=15.125, token_id=98028, metadata=None))), (40090, (14, PredictedToken(token=' Pressure', prob=0.0032501220703125, logit=14.75, token_id=40090, metadata=None)))])\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     int_prediction=['\" Bamboo\"[98028] (p=0.828, logit=20.250)', '\" The\"[578] (p=0.041, logit=17.250)', '\" Option\"[7104] (p=0.017, logit=16.375)', '\" None\"[2290] (p=0.015, logit=16.250)', '\" bamboo\"[59982] (p=0.012, logit=16.000)']\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     int_track=OrderedDict([(98028, (1, PredictedToken(token=' Bamboo', prob=0.828125, logit=20.25, token_id=98028, metadata=None))), (40090, (32, PredictedToken(token=' Pressure', prob=0.0006256103515625, logit=13.0625, token_id=40090, metadata=None))), (67629, (43, PredictedToken(token=' Helmet', prob=0.0003566741943359375, logit=12.5, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:46 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     patch_prediction=['\" Acc\"[11683] (p=0.691, logit=21.750)', '\" The\"[578] (p=0.120, logit=20.000)', '\" An\"[1556] (p=0.083, logit=19.625)', '\" Among\"[22395] (p=0.050, logit=19.125)', '\" It\"[1102] (p=0.016, logit=18.000)']\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     clean_prediction=['\" Tow\"[41493] (p=0.941, logit=22.000)', '\" The\"[578] (p=0.015, logit=17.875)', '\" Among\"[22395] (p=0.012, logit=17.625)', '\" A\"[362] (p=0.012, logit=17.625)', '\" None\"[2290] (p=0.002, logit=15.688)']\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     clean_track=OrderedDict([(41493, (1, PredictedToken(token=' Tow', prob=0.94140625, logit=22.0, token_id=41493, metadata=None))), (1630, (24, PredictedToken(token=' X', prob=0.00018024444580078125, logit=13.4375, token_id=1630, metadata=None))), (78703, (65, PredictedToken(token=' Potato', prob=4.029273986816406e-05, logit=11.9375, token_id=78703, metadata=None))), (3816, (66, PredictedToken(token=' Red', prob=3.552436828613281e-05, logit=11.8125, token_id=3816, metadata=None))), (30558, (71, PredictedToken(token=' Ki', prob=3.337860107421875e-05, logit=11.75, token_id=30558, metadata=None)))])\n",
      "2025-09-16 09:45:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.770, logit=20.750)', '\" Among\"[22395] (p=0.063, logit=18.250)', '\" The\"[578] (p=0.043, logit=17.875)', '\" None\"[2290] (p=0.038, logit=17.750)', '\" There\"[2684] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.76953125, logit=20.75, token_id=1630, metadata=None))), (30558, (7, PredictedToken(token=' Ki', prob=0.00665283203125, logit=16.0, token_id=30558, metadata=None))), (78703, (48, PredictedToken(token=' Potato', prob=0.00022792816162109375, logit=12.625, token_id=78703, metadata=None))), (3816, (148, PredictedToken(token=' Red', prob=2.7179718017578125e-05, logit=10.5, token_id=3816, metadata=None))), (41493, (197, PredictedToken(token=' Tow', prob=1.5497207641601562e-05, logit=9.9375, token_id=41493, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:47 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     patch_prediction=['\" Project\"[5907] (p=0.855, logit=22.875)', '\" The\"[578] (p=0.062, logit=20.250)', '\" A\"[362] (p=0.042, logit=19.875)', '\" Among\"[22395] (p=0.011, logit=18.500)', '\" It\"[1102] (p=0.005, logit=17.750)']\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.793, logit=22.375)', '\" The\"[578] (p=0.095, logit=20.250)', '\" Among\"[22395] (p=0.045, logit=19.500)', '\" A\"[362] (p=0.039, logit=19.375)', '\" It\"[1102] (p=0.003, logit=16.875)']\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.79296875, logit=22.375, token_id=4923, metadata=None))), (18654, (15, PredictedToken(token=' Micro', prob=0.00067901611328125, logit=15.3125, token_id=18654, metadata=None))), (20918, (23, PredictedToken(token=' Magn', prob=0.000438690185546875, logit=14.875, token_id=20918, metadata=None)))])\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     int_prediction=['\" Micro\"[18654] (p=0.805, logit=22.000)', '\" Among\"[22395] (p=0.066, logit=19.500)', '\" The\"[578] (p=0.058, logit=19.375)', '\" None\"[2290] (p=0.013, logit=17.875)', '\" Magn\"[20918] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     int_track=OrderedDict([(18654, (1, PredictedToken(token=' Micro', prob=0.8046875, logit=22.0, token_id=18654, metadata=None))), (20918, (5, PredictedToken(token=' Magn', prob=0.00787353515625, logit=17.375, token_id=20918, metadata=None))), (4923, (538, PredictedToken(token=' Sk', prob=9.164214134216309e-07, logit=8.3125, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:47 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.727, logit=22.125)', '\" The\"[578] (p=0.112, logit=20.250)', '\" A\"[362] (p=0.087, logit=20.000)', '\" Among\"[22395] (p=0.032, logit=19.000)', '\" (\"[320] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     clean_prediction=['\" Calculator\"[37128] (p=0.652, logit=20.750)', '\" The\"[578] (p=0.146, logit=19.250)', '\" A\"[362] (p=0.078, logit=18.625)', '\" Among\"[22395] (p=0.017, logit=17.125)', '\" None\"[2290] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     clean_track=OrderedDict([(37128, (1, PredictedToken(token=' Calculator', prob=0.65234375, logit=20.75, token_id=37128, metadata=None))), (6690, (63, PredictedToken(token=' Air', prob=0.00016021728515625, logit=12.4375, token_id=6690, metadata=None))), (38571, (72, PredictedToken(token=' Theater', prob=0.00012493133544921875, logit=12.1875, token_id=38571, metadata=None)))])\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     int_prediction=['\" Air\"[6690] (p=0.559, logit=20.375)', '\" None\"[2290] (p=0.182, logit=19.250)', '\" Theater\"[38571] (p=0.160, logit=19.125)', '\" The\"[578] (p=0.028, logit=17.375)', '\" Among\"[22395] (p=0.012, logit=16.500)']\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     int_track=OrderedDict([(6690, (1, PredictedToken(token=' Air', prob=0.55859375, logit=20.375, token_id=6690, metadata=None))), (38571, (3, PredictedToken(token=' Theater', prob=0.16015625, logit=19.125, token_id=38571, metadata=None))), (37128, (757, PredictedToken(token=' Calculator', prob=1.341104507446289e-06, logit=7.4375, token_id=37128, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:48 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     patch_prediction=['\" Night\"[13120] (p=0.781, logit=22.250)', '\" The\"[578] (p=0.064, logit=19.750)', '\" Among\"[22395] (p=0.057, logit=19.625)', '\" A\"[362] (p=0.057, logit=19.625)', '\" It\"[1102] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     clean_prediction=['\" Tomato\"[94091] (p=0.816, logit=21.750)', '\" The\"[578] (p=0.059, logit=19.125)', '\" Among\"[22395] (p=0.052, logit=19.000)', '\" A\"[362] (p=0.031, logit=18.500)', '\" None\"[2290] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     clean_track=OrderedDict([(94091, (1, PredictedToken(token=' Tomato', prob=0.81640625, logit=21.75, token_id=94091, metadata=None))), (23126, (16, PredictedToken(token=' Ti', prob=0.000743865966796875, logit=14.75, token_id=23126, metadata=None))), (1050, (48, PredictedToken(token=' Re', prob=0.00015544891357421875, logit=13.1875, token_id=1050, metadata=None))), (88088, (53, PredictedToken(token=' Birch', prob=0.00011396408081054688, logit=12.875, token_id=88088, metadata=None))), (18654, (161, PredictedToken(token=' Micro', prob=1.0609626770019531e-05, logit=10.5, token_id=18654, metadata=None)))])\n",
      "2025-09-16 09:45:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     int_prediction=['\" Re\"[1050] (p=0.645, logit=20.875)', '\" None\"[2290] (p=0.099, logit=19.000)', '\" Among\"[22395] (p=0.068, logit=18.625)', '\" Birch\"[88088] (p=0.068, logit=18.625)', '\" The\"[578] (p=0.047, logit=18.250)']\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     int_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.64453125, logit=20.875, token_id=1050, metadata=None))), (88088, (4, PredictedToken(token=' Birch', prob=0.06787109375, logit=18.625, token_id=88088, metadata=None))), (18654, (46, PredictedToken(token=' Micro', prob=0.000244140625, logit=13.0, token_id=18654, metadata=None))), (23126, (214, PredictedToken(token=' Ti', prob=8.881092071533203e-06, logit=9.6875, token_id=23126, metadata=None))), (94091, (584, PredictedToken(token=' Tomato', prob=1.862645149230957e-06, logit=8.125, token_id=94091, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:49 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     patch_prediction=['\" Smart\"[16147] (p=0.840, logit=21.875)', '\" The\"[578] (p=0.054, logit=19.125)', '\" Among\"[22395] (p=0.037, logit=18.750)', '\" A\"[362] (p=0.033, logit=18.625)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     clean_prediction=['\" Shorts\"[91782] (p=0.656, logit=20.250)', '\" The\"[578] (p=0.129, logit=18.625)', '\" Among\"[22395] (p=0.089, logit=18.250)', '\" shorts\"[36876] (p=0.012, logit=16.250)', '\" \"\"[330] (p=0.011, logit=16.125)']\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     clean_track=OrderedDict([(91782, (1, PredictedToken(token=' Shorts', prob=0.65625, logit=20.25, token_id=91782, metadata=None))), (3816, (89, PredictedToken(token=' Red', prob=8.058547973632812e-05, logit=11.25, token_id=3816, metadata=None))), (36943, (93, PredictedToken(token=' Folder', prob=7.581710815429688e-05, logit=11.1875, token_id=36943, metadata=None))), (6771, (118, PredictedToken(token=' Table', prob=5.221366882324219e-05, logit=10.8125, token_id=6771, metadata=None))), (16730, (139, PredictedToken(token=' Museum', prob=3.361701965332031e-05, logit=10.375, token_id=16730, metadata=None))), (26698, (157, PredictedToken(token=' Keyboard', prob=2.6226043701171875e-05, logit=10.125, token_id=26698, metadata=None)))])\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     int_prediction=['\" Keyboard\"[26698] (p=0.809, logit=21.625)', '\" The\"[578] (p=0.085, logit=19.375)', '\" Among\"[22395] (p=0.031, logit=18.375)', '\" A\"[362] (p=0.019, logit=17.875)', '\" It\"[1102] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     int_track=OrderedDict([(26698, (1, PredictedToken(token=' Keyboard', prob=0.80859375, logit=21.625, token_id=26698, metadata=None))), (3816, (14, PredictedToken(token=' Red', prob=0.00146484375, logit=15.3125, token_id=3816, metadata=None))), (36943, (62, PredictedToken(token=' Folder', prob=7.772445678710938e-05, logit=12.375, token_id=36943, metadata=None))), (6771, (109, PredictedToken(token=' Table', prob=2.682209014892578e-05, logit=11.3125, token_id=6771, metadata=None))), (16730, (470, PredictedToken(token=' Museum', prob=1.6093254089355469e-06, logit=8.5, token_id=16730, metadata=None))), (91782, (6170, PredictedToken(token=' Shorts', prob=4.866160452365875e-08, logit=5.0, token_id=91782, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:49 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:49 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:45:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.730, logit=20.500)', '\" The\"[578] (p=0.087, logit=18.375)', '\" A\"[362] (p=0.077, logit=18.250)', '\" Among\"[22395] (p=0.036, logit=17.500)', '\" skateboard\"[99082] (p=0.007, logit=15.812)']\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     clean_prediction=['\" Blue\"[8868] (p=0.805, logit=22.000)', '\" The\"[578] (p=0.096, logit=19.875)', '\" Among\"[22395] (p=0.045, logit=19.125)', '\" A\"[362] (p=0.019, logit=18.250)', '\" Fruit\"[44187] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     clean_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.8046875, logit=22.0, token_id=8868, metadata=None))), (22050, (56, PredictedToken(token=' Hat', prob=6.389617919921875e-05, logit=12.5625, token_id=22050, metadata=None))), (445, (101, PredictedToken(token=' L', prob=1.621246337890625e-05, logit=11.1875, token_id=445, metadata=None))), (31181, (140, PredictedToken(token=' Clar', prob=9.238719940185547e-06, logit=10.625, token_id=31181, metadata=None))), (21424, (249, PredictedToken(token=' Football', prob=3.1888484954833984e-06, logit=9.5625, token_id=21424, metadata=None))), (84008, (265, PredictedToken(token=' Sheep', prob=2.995133399963379e-06, logit=9.5, token_id=84008, metadata=None)))])\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     int_prediction=['\" Clar\"[31181] (p=0.781, logit=21.750)', '\" The\"[578] (p=0.120, logit=19.875)', '\" Among\"[22395] (p=0.039, logit=18.750)', '\" A\"[362] (p=0.021, logit=18.125)', '\" Football\"[21424] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     int_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.78125, logit=21.75, token_id=31181, metadata=None))), (21424, (5, PredictedToken(token=' Football', prob=0.005279541015625, logit=16.75, token_id=21424, metadata=None))), (445, (10, PredictedToken(token=' L', prob=0.00160980224609375, logit=15.5625, token_id=445, metadata=None))), (84008, (30, PredictedToken(token=' Sheep', prob=0.000263214111328125, logit=13.75, token_id=84008, metadata=None))), (22050, (58, PredictedToken(token=' Hat', prob=8.0108642578125e-05, logit=12.5625, token_id=22050, metadata=None))), (8868, (103, PredictedToken(token=' Blue', prob=2.0265579223632812e-05, logit=11.1875, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:50 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:50 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     patch_prediction=['\" Banana\"[76924] (p=0.746, logit=21.750)', '\" The\"[578] (p=0.115, logit=19.875)', '\" A\"[362] (p=0.048, logit=19.000)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" B\"[426] (p=0.007, logit=17.125)']\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     clean_prediction=['\" Golf\"[28131] (p=0.723, logit=21.375)', '\" The\"[578] (p=0.098, logit=19.375)', '\" A\"[362] (p=0.067, logit=19.000)', '\" Among\"[22395] (p=0.028, logit=18.125)', '\" Harmon\"[40759] (p=0.019, logit=17.750)']\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     clean_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.72265625, logit=21.375, token_id=28131, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.019287109375, logit=17.75, token_id=40759, metadata=None))), (16183, (9, PredictedToken(token=' Hel', prob=0.0033416748046875, logit=16.0, token_id=16183, metadata=None))), (10164, (129, PredictedToken(token=' Water', prob=1.8715858459472656e-05, logit=10.8125, token_id=10164, metadata=None)))])\n",
      "2025-09-16 09:45:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     int_prediction=['\" Water\"[10164] (p=0.793, logit=21.500)', '\" Among\"[22395] (p=0.095, logit=19.375)', '\" The\"[578] (p=0.035, logit=18.375)', '\" Option\"[7104] (p=0.016, logit=17.625)', '\" Harmon\"[40759] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     int_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.79296875, logit=21.5, token_id=10164, metadata=None))), (40759, (5, PredictedToken(token=' Harmon', prob=0.010009765625, logit=17.125, token_id=40759, metadata=None))), (16183, (29, PredictedToken(token=' Hel', prob=0.0003871917724609375, logit=13.875, token_id=16183, metadata=None))), (28131, (91, PredictedToken(token=' Golf', prob=3.3855438232421875e-05, logit=11.4375, token_id=28131, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:51 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:51 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.820, logit=21.000)', '\" None\"[2290] (p=0.077, logit=18.625)', '\" The\"[578] (p=0.025, logit=17.500)', '\" There\"[2684] (p=0.013, logit=16.875)', '\" Among\"[22395] (p=0.010, logit=16.625)']\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     clean_prediction=['\" As\"[1666] (p=0.895, logit=22.625)', '\" Among\"[22395] (p=0.045, logit=19.625)', '\" The\"[578] (p=0.035, logit=19.375)', '\" E\"[469] (p=0.003, logit=16.750)', '\" as\"[439] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     clean_track=OrderedDict([(1666, (1, PredictedToken(token=' As', prob=0.89453125, logit=22.625, token_id=1666, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.0025177001953125, logit=16.75, token_id=469, metadata=None))), (83499, (41, PredictedToken(token=' Tooth', prob=8.058547973632812e-05, logit=13.3125, token_id=83499, metadata=None))), (38930, (371, PredictedToken(token=' Bike', prob=1.1548399925231934e-06, logit=9.0625, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     int_prediction=['\" E\"[469] (p=0.715, logit=20.875)', '\" Among\"[22395] (p=0.075, logit=18.625)', '\" The\"[578] (p=0.075, logit=18.625)', '\" None\"[2290] (p=0.052, logit=18.250)', '\" It\"[1102] (p=0.013, logit=16.875)']\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     int_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.71484375, logit=20.875, token_id=469, metadata=None))), (83499, (6, PredictedToken(token=' Tooth', prob=0.01019287109375, logit=16.625, token_id=83499, metadata=None))), (1666, (29, PredictedToken(token=' As', prob=0.0006103515625, logit=13.8125, token_id=1666, metadata=None))), (38930, (64, PredictedToken(token=' Bike', prob=8.821487426757812e-05, logit=11.875, token_id=38930, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:51 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:51 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:45:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     patch_prediction=['\" Oven\"[87213] (p=0.727, logit=20.625)', '\" The\"[578] (p=0.077, logit=18.375)', '\" Among\"[22395] (p=0.041, logit=17.750)', '\" An\"[1556] (p=0.041, logit=17.750)', '\" Option\"[7104] (p=0.017, logit=16.875)']\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.781, logit=22.500)', '\" The\"[578] (p=0.120, logit=20.625)', '\" A\"[362] (p=0.039, logit=19.500)', '\" Among\"[22395] (p=0.027, logit=19.125)', '\" d\"[294] (p=0.016, logit=18.625)']\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.78125, logit=22.5, token_id=423, metadata=None))), (20423, (41, PredictedToken(token=' Amb', prob=5.14984130859375e-05, logit=12.875, token_id=20423, metadata=None))), (86460, (80, PredictedToken(token=' Necklace', prob=1.7762184143066406e-05, logit=11.8125, token_id=86460, metadata=None))), (14588, (112, PredictedToken(token=' Dog', prob=7.867813110351562e-06, logit=11.0, token_id=14588, metadata=None))), (40090, (118, PredictedToken(token=' Pressure', prob=7.420778274536133e-06, logit=10.9375, token_id=40090, metadata=None))), (23262, (253, PredictedToken(token=' Comb', prob=1.4603137969970703e-06, logit=9.3125, token_id=23262, metadata=None)))])\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     int_prediction=['\" Pressure\"[40090] (p=0.754, logit=22.375)', '\" The\"[578] (p=0.116, logit=20.500)', '\" Among\"[22395] (p=0.062, logit=19.875)', '\" A\"[362] (p=0.020, logit=18.750)', '\" It\"[1102] (p=0.014, logit=18.375)']\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     int_track=OrderedDict([(40090, (1, PredictedToken(token=' Pressure', prob=0.75390625, logit=22.375, token_id=40090, metadata=None))), (23262, (10, PredictedToken(token=' Comb', prob=0.0018768310546875, logit=16.375, token_id=23262, metadata=None))), (20423, (38, PredictedToken(token=' Amb', prob=0.000164031982421875, logit=13.9375, token_id=20423, metadata=None))), (423, (40, PredictedToken(token=' D', prob=0.00014400482177734375, logit=13.8125, token_id=423, metadata=None))), (86460, (770, PredictedToken(token=' Necklace', prob=3.818422555923462e-07, logit=7.875, token_id=86460, metadata=None))), (14588, (794, PredictedToken(token=' Dog', prob=3.5762786865234375e-07, logit=7.8125, token_id=14588, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:52 src.selection.optimization DEBUG    torch.Size([5, 32])\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.816, logit=22.375)', '\" The\"[578] (p=0.067, logit=19.875)', '\" A\"[362] (p=0.067, logit=19.875)', '\" Among\"[22395] (p=0.019, logit=18.625)', '\" (\"[320] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:45:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.668, logit=21.000)', '\" The\"[578] (p=0.103, logit=19.125)', '\" Among\"[22395] (p=0.070, logit=18.750)', '\" A\"[362] (p=0.070, logit=18.750)', '\" It\"[1102] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.66796875, logit=21.0, token_id=75258, metadata=None))), (17810, (16, PredictedToken(token=' Cat', prob=0.00128936767578125, logit=14.75, token_id=17810, metadata=None))), (91963, (117, PredictedToken(token=' Mango', prob=3.4332275390625e-05, logit=11.125, token_id=91963, metadata=None))), (74968, (221, PredictedToken(token=' Razor', prob=1.049041748046875e-05, logit=9.9375, token_id=74968, metadata=None))), (9441, (1331, PredictedToken(token=' Church', prob=5.736947059631348e-07, logit=7.03125, token_id=9441, metadata=None)))])\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     int_prediction=['\" Church\"[9441] (p=0.582, logit=20.875)', '\" None\"[2290] (p=0.189, logit=19.750)', '\" Among\"[22395] (p=0.089, logit=19.000)', '\" The\"[578] (p=0.042, logit=18.250)', '\" Cat\"[17810] (p=0.029, logit=17.875)']\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     int_track=OrderedDict([(9441, (1, PredictedToken(token=' Church', prob=0.58203125, logit=20.875, token_id=9441, metadata=None))), (17810, (5, PredictedToken(token=' Cat', prob=0.0289306640625, logit=17.875, token_id=17810, metadata=None))), (75258, (264, PredictedToken(token=' Refriger', prob=6.288290023803711e-06, logit=9.4375, token_id=75258, metadata=None))), (91963, (769, PredictedToken(token=' Mango', prob=1.1622905731201172e-06, logit=7.75, token_id=91963, metadata=None))), (74968, (5268, PredictedToken(token=' Razor', prob=6.752088665962219e-08, logit=4.90625, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:53 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:53 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     patch_prediction=['\" Mar\"[2947] (p=0.836, logit=22.125)', '\" The\"[578] (p=0.078, logit=19.750)', '\" Among\"[22395] (p=0.029, logit=18.750)', '\" A\"[362] (p=0.017, logit=18.250)', '\" It\"[1102] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.680, logit=21.000)', '\" Among\"[22395] (p=0.092, logit=19.000)', '\" The\"[578] (p=0.092, logit=19.000)', '\" A\"[362] (p=0.049, logit=18.375)', '\" Option\"[7104] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.6796875, logit=21.0, token_id=27171, metadata=None))), (469, (6, PredictedToken(token=' E', prob=0.006683349609375, logit=16.375, token_id=469, metadata=None))), (41342, (57, PredictedToken(token=' Hockey', prob=0.00010824203491210938, logit=12.25, token_id=41342, metadata=None))), (27738, (59, PredictedToken(token=' Ward', prob=0.00010156631469726562, logit=12.1875, token_id=27738, metadata=None))), (49431, (176, PredictedToken(token=' Rabbit', prob=1.0669231414794922e-05, logit=9.9375, token_id=49431, metadata=None))), (82452, (526, PredictedToken(token=' Jasmine', prob=1.4007091522216797e-06, logit=7.90625, token_id=82452, metadata=None)))])\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     int_prediction=['\" Jasmine\"[82452] (p=0.602, logit=20.625)', '\" Among\"[22395] (p=0.151, logit=19.250)', '\" E\"[469] (p=0.092, logit=18.750)', '\" The\"[578] (p=0.063, logit=18.375)', '\" Option\"[7104] (p=0.016, logit=17.000)']\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     int_track=OrderedDict([(82452, (1, PredictedToken(token=' Jasmine', prob=0.6015625, logit=20.625, token_id=82452, metadata=None))), (469, (3, PredictedToken(token=' E', prob=0.09228515625, logit=18.75, token_id=469, metadata=None))), (27738, (9, PredictedToken(token=' Ward', prob=0.005523681640625, logit=15.9375, token_id=27738, metadata=None))), (49431, (12, PredictedToken(token=' Rabbit', prob=0.0031585693359375, logit=15.375, token_id=49431, metadata=None))), (27171, (1027, PredictedToken(token=' Coffee', prob=8.23289155960083e-07, logit=7.125, token_id=27171, metadata=None))), (41342, (8042, PredictedToken(token=' Hockey', prob=4.7963112592697144e-08, logit=4.28125, token_id=41342, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:53 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:53 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:45:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.926, logit=22.250)', '\" Glo\"[25372] (p=0.017, logit=18.250)', '\" The\"[578] (p=0.017, logit=18.250)', '\" Among\"[22395] (p=0.007, logit=17.375)', '\" Let\"[6914] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.895, logit=22.250)', '\" The\"[578] (p=0.035, logit=19.000)', '\" A\"[362] (p=0.016, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.875)', '\" (\"[320] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.89453125, logit=22.25, token_id=5907, metadata=None))), (432, (8, PredictedToken(token=' R', prob=0.004119873046875, logit=16.875, token_id=432, metadata=None))), (4923, (19, PredictedToken(token=' Sk', prob=0.000492095947265625, logit=14.75, token_id=4923, metadata=None)))])\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.820, logit=21.125)', '\" The\"[578] (p=0.046, logit=18.250)', '\" A\"[362] (p=0.025, logit=17.625)', '\" Among\"[22395] (p=0.019, logit=17.375)', '\" R\"[432] (p=0.017, logit=17.250)']\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.8203125, logit=21.125, token_id=4923, metadata=None))), (432, (5, PredictedToken(token=' R', prob=0.01708984375, logit=17.25, token_id=432, metadata=None))), (5907, (262, PredictedToken(token=' Project', prob=4.738569259643555e-06, logit=9.0625, token_id=5907, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:54 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:54 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     patch_prediction=['\" Stap\"[63606] (p=0.641, logit=20.625)', '\" The\"[578] (p=0.126, logit=19.000)', '\" A\"[362] (p=0.098, logit=18.750)', '\" Among\"[22395] (p=0.059, logit=18.250)', '\" stap\"[36114] (p=0.017, logit=17.000)']\n",
      "2025-09-16 09:45:54 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     clean_prediction=['\" Daisy\"[71264] (p=0.605, logit=21.125)', '\" The\"[578] (p=0.152, logit=19.750)', '\" A\"[362] (p=0.105, logit=19.375)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" d\"[294] (p=0.034, logit=18.250)']\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     clean_track=OrderedDict([(71264, (1, PredictedToken(token=' Daisy', prob=0.60546875, logit=21.125, token_id=71264, metadata=None))), (432, (39, PredictedToken(token=' R', prob=0.00014781951904296875, logit=12.8125, token_id=432, metadata=None))), (23126, (50, PredictedToken(token=' Ti', prob=9.012222290039062e-05, logit=12.3125, token_id=23126, metadata=None))), (34954, (388, PredictedToken(token=' Mirror', prob=2.3990869522094727e-06, logit=8.6875, token_id=34954, metadata=None))), (56491, (631, PredictedToken(token=' Piano', prob=1.2069940567016602e-06, logit=8.0, token_id=56491, metadata=None))), (68554, (2394, PredictedToken(token=' Gloves', prob=2.2258609533309937e-07, logit=6.3125, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.730, logit=21.500)', '\" The\"[578] (p=0.112, logit=19.625)', '\" Among\"[22395] (p=0.053, logit=18.875)', '\" A\"[362] (p=0.041, logit=18.625)', '\" Mirror\"[34954] (p=0.020, logit=17.875)']\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.73046875, logit=21.5, token_id=432, metadata=None))), (34954, (5, PredictedToken(token=' Mirror', prob=0.01953125, logit=17.875, token_id=34954, metadata=None))), (68554, (8, PredictedToken(token=' Gloves', prob=0.00384521484375, logit=16.25, token_id=68554, metadata=None))), (56491, (12, PredictedToken(token=' Piano', prob=0.0016021728515625, logit=15.375, token_id=56491, metadata=None))), (23126, (47, PredictedToken(token=' Ti', prob=0.00012302398681640625, logit=12.8125, token_id=23126, metadata=None))), (71264, (1868, PredictedToken(token=' Daisy', prob=1.8533319234848022e-07, logit=6.3125, token_id=71264, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:55 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:55 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     patch_prediction=['\" Pen\"[13597] (p=0.691, logit=21.625)', '\" The\"[578] (p=0.106, logit=19.750)', '\" A\"[362] (p=0.094, logit=19.625)', '\" Among\"[22395] (p=0.044, logit=18.875)', '\" It\"[1102] (p=0.013, logit=17.625)']\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     clean_prediction=['\" Surf\"[65197] (p=0.652, logit=21.125)', '\" The\"[578] (p=0.129, logit=19.500)', '\" A\"[362] (p=0.129, logit=19.500)', '\" Among\"[22395] (p=0.029, logit=18.000)', '\" It\"[1102] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     clean_track=OrderedDict([(65197, (1, PredictedToken(token=' Surf', prob=0.65234375, logit=21.125, token_id=65197, metadata=None))), (1901, (21, PredictedToken(token=' Z', prob=0.000675201416015625, logit=14.25, token_id=1901, metadata=None))), (40975, (128, PredictedToken(token=' Marker', prob=1.919269561767578e-05, logit=10.6875, token_id=40975, metadata=None))), (39247, (140, PredictedToken(token=' Slow', prob=1.6927719116210938e-05, logit=10.5625, token_id=39247, metadata=None)))])\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.891, logit=22.625)', '\" The\"[578] (p=0.039, logit=19.500)', '\" Among\"[22395] (p=0.024, logit=19.000)', '\" A\"[362] (p=0.024, logit=19.000)', '\" It\"[1102] (p=0.005, logit=17.500)']\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.890625, logit=22.625, token_id=40975, metadata=None))), (39247, (13, PredictedToken(token=' Slow', prob=0.0005950927734375, logit=15.3125, token_id=39247, metadata=None))), (1901, (45, PredictedToken(token=' Z', prob=8.058547973632812e-05, logit=13.3125, token_id=1901, metadata=None))), (65197, (80, PredictedToken(token=' Surf', prob=1.9073486328125e-05, logit=11.875, token_id=65197, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:55 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:45:55 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:45:55 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     patch_prediction=['\" Bro\"[6031] (p=0.844, logit=22.875)', '\" The\"[578] (p=0.069, logit=20.375)', '\" Among\"[22395] (p=0.061, logit=20.250)', '\" It\"[1102] (p=0.006, logit=17.875)', '\" A\"[362] (p=0.002, logit=17.000)']\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     clean_prediction=['\" Apple\"[8325] (p=0.645, logit=21.500)', '\" The\"[578] (p=0.144, logit=20.000)', '\" An\"[1556] (p=0.099, logit=19.625)', '\" Among\"[22395] (p=0.068, logit=19.250)', '\" There\"[2684] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     clean_track=OrderedDict([(8325, (1, PredictedToken(token=' Apple', prob=0.64453125, logit=21.5, token_id=8325, metadata=None))), (60413, (16, PredictedToken(token=' Uk', prob=0.0010986328125, logit=15.125, token_id=60413, metadata=None))), (78703, (32, PredictedToken(token=' Potato', prob=0.0004291534423828125, logit=14.1875, token_id=78703, metadata=None))), (82994, (266, PredictedToken(token=' Toilet', prob=4.500150680541992e-06, logit=9.625, token_id=82994, metadata=None))), (39794, (2248, PredictedToken(token=' Desk', prob=1.5366822481155396e-07, logit=6.25, token_id=39794, metadata=None))), (52466, (2468, PredictedToken(token=' Warehouse', prob=1.3504177331924438e-07, logit=6.125, token_id=52466, metadata=None)))])\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     int_prediction=['\" Uk\"[60413] (p=0.365, logit=20.000)', '\" Potato\"[78703] (p=0.196, logit=19.375)', '\" The\"[578] (p=0.196, logit=19.375)', '\" Among\"[22395] (p=0.152, logit=19.125)', '\" Warehouse\"[52466] (p=0.014, logit=16.750)']\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     int_track=OrderedDict([(60413, (1, PredictedToken(token=' Uk', prob=0.365234375, logit=20.0, token_id=60413, metadata=None))), (78703, (3, PredictedToken(token=' Potato', prob=0.1962890625, logit=19.375, token_id=78703, metadata=None))), (52466, (5, PredictedToken(token=' Warehouse', prob=0.01422119140625, logit=16.75, token_id=52466, metadata=None))), (82994, (9, PredictedToken(token=' Toilet', prob=0.0035858154296875, logit=15.375, token_id=82994, metadata=None))), (8325, (175, PredictedToken(token=' Apple', prob=1.8835067749023438e-05, logit=10.125, token_id=8325, metadata=None))), (39794, (1256, PredictedToken(token=' Desk', prob=9.08970832824707e-07, logit=7.09375, token_id=39794, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:56 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:56 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     patch_prediction=['\" S\"[328] (p=0.879, logit=22.500)', '\" The\"[578] (p=0.056, logit=19.750)', '\" Among\"[22395] (p=0.034, logit=19.250)', '\" socks\"[40086] (p=0.005, logit=17.250)', '\" (\"[320] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:45:56 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     clean_prediction=['\" Z\"[1901] (p=0.797, logit=21.625)', '\" The\"[578] (p=0.051, logit=18.875)', '\" Among\"[22395] (p=0.045, logit=18.750)', '\" A\"[362] (p=0.021, logit=18.000)', '\" z\"[1167] (p=0.019, logit=17.875)']\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     clean_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.796875, logit=21.625, token_id=1901, metadata=None))), (82452, (20, PredictedToken(token=' Jasmine', prob=0.001129150390625, logit=15.0625, token_id=82452, metadata=None))), (55870, (44, PredictedToken(token=' Jacket', prob=0.00026702880859375, logit=13.625, token_id=55870, metadata=None))), (11896, (214, PredictedToken(token=' Library', prob=7.12275505065918e-06, logit=10.0, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     int_prediction=['\" Jacket\"[55870] (p=0.766, logit=21.000)', '\" None\"[2290] (p=0.055, logit=18.375)', '\" Among\"[22395] (p=0.043, logit=18.125)', '\" Library\"[11896] (p=0.030, logit=17.750)', '\" The\"[578] (p=0.030, logit=17.750)']\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     int_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.765625, logit=21.0, token_id=55870, metadata=None))), (11896, (5, PredictedToken(token=' Library', prob=0.0296630859375, logit=17.75, token_id=11896, metadata=None))), (82452, (41, PredictedToken(token=' Jasmine', prob=0.0003299713134765625, logit=13.25, token_id=82452, metadata=None))), (1901, (225, PredictedToken(token=' Z', prob=9.357929229736328e-06, logit=9.6875, token_id=1901, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:57 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:45:57 src.selection.optimization DEBUG    torch.Size([5, 33])\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     patch_prediction=['\" Air\"[6690] (p=0.715, logit=22.625)', '\" An\"[1556] (p=0.141, logit=21.000)', '\" The\"[578] (p=0.075, logit=20.375)', '\" Among\"[22395] (p=0.040, logit=19.750)', '\" (\"[320] (p=0.005, logit=17.750)']\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     clean_prediction=['\" Eagle\"[36895] (p=0.637, logit=21.500)', '\" An\"[1556] (p=0.182, logit=20.250)', '\" The\"[578] (p=0.086, logit=19.500)', '\" Among\"[22395] (p=0.041, logit=18.750)', '\" E\"[469] (p=0.015, logit=17.750)']\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     clean_track=OrderedDict([(36895, (1, PredictedToken(token=' Eagle', prob=0.63671875, logit=21.5, token_id=36895, metadata=None))), (356, (39, PredictedToken(token=' C', prob=0.0001373291015625, logit=13.0625, token_id=356, metadata=None))), (97796, (57, PredictedToken(token=' Skate', prob=6.103515625e-05, logit=12.25, token_id=97796, metadata=None))), (98641, (125, PredictedToken(token=' Microwave', prob=1.4483928680419922e-05, logit=10.8125, token_id=98641, metadata=None))), (16478, (217, PredictedToken(token=' Chair', prob=5.0067901611328125e-06, logit=9.75, token_id=16478, metadata=None)))])\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     int_prediction=['\" Microwave\"[98641] (p=0.871, logit=22.250)', '\" The\"[578] (p=0.043, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=18.500)', '\" C\"[356] (p=0.016, logit=18.250)', '\" Chair\"[16478] (p=0.014, logit=18.125)']\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     int_track=OrderedDict([(98641, (1, PredictedToken(token=' Microwave', prob=0.87109375, logit=22.25, token_id=98641, metadata=None))), (356, (4, PredictedToken(token=' C', prob=0.0159912109375, logit=18.25, token_id=356, metadata=None))), (16478, (5, PredictedToken(token=' Chair', prob=0.01409912109375, logit=18.125, token_id=16478, metadata=None))), (97796, (36, PredictedToken(token=' Skate', prob=0.0001773834228515625, logit=13.75, token_id=97796, metadata=None))), (36895, (5251, PredictedToken(token=' Eagle', prob=3.4924596548080444e-08, logit=5.21875, token_id=36895, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:57 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:57 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:45:57 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     patch_prediction=['\" Folder\"[36943] (p=0.797, logit=21.250)', '\" The\"[578] (p=0.065, logit=18.750)', '\" A\"[362] (p=0.051, logit=18.500)', '\" Desk\"[39794] (p=0.015, logit=17.250)', '\" folder\"[8695] (p=0.008, logit=16.625)']\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     clean_prediction=['\" Night\"[13120] (p=0.906, logit=22.750)', '\" A\"[362] (p=0.024, logit=19.125)', '\" The\"[578] (p=0.019, logit=18.875)', '\" Among\"[22395] (p=0.011, logit=18.375)', '\" night\"[3814] (p=0.010, logit=18.250)']\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     clean_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.90625, logit=22.75, token_id=13120, metadata=None))), (65449, (8, PredictedToken(token=' Willow', prob=0.0025482177734375, logit=16.875, token_id=65449, metadata=None))), (40975, (17, PredictedToken(token=' Marker', prob=0.000682830810546875, logit=15.5625, token_id=40975, metadata=None)))])\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     int_prediction=['\" Marker\"[40975] (p=0.961, logit=23.625)', '\" A\"[362] (p=0.014, logit=19.375)', '\" The\"[578] (p=0.006, logit=18.625)', '\" marker\"[11381] (p=0.004, logit=18.250)', '\" Among\"[22395] (p=0.003, logit=18.000)']\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     int_track=OrderedDict([(40975, (1, PredictedToken(token=' Marker', prob=0.9609375, logit=23.625, token_id=40975, metadata=None))), (13120, (15, PredictedToken(token=' Night', prob=0.0003643035888671875, logit=15.75, token_id=13120, metadata=None))), (65449, (365, PredictedToken(token=' Willow', prob=4.842877388000488e-07, logit=9.125, token_id=65449, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:58 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:58 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     patch_prediction=['\" Harmon\"[40759] (p=0.832, logit=22.125)', '\" The\"[578] (p=0.078, logit=19.750)', '\" A\"[362] (p=0.029, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=18.625)', '\" It\"[1102] (p=0.007, logit=17.375)']\n",
      "2025-09-16 09:45:58 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.832, logit=22.000)', '\" The\"[578] (p=0.068, logit=19.500)', '\" Among\"[22395] (p=0.042, logit=19.000)', '\" A\"[362] (p=0.012, logit=17.750)', '\" It\"[1102] (p=0.007, logit=17.250)']\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.83203125, logit=22.0, token_id=469, metadata=None))), (1630, (9, PredictedToken(token=' X', prob=0.002655029296875, logit=16.25, token_id=1630, metadata=None))), (6150, (74, PredictedToken(token=' School', prob=4.029273986816406e-05, logit=12.0625, token_id=6150, metadata=None))), (70762, (1046, PredictedToken(token=' Motorcycle', prob=3.073364496231079e-07, logit=7.1875, token_id=70762, metadata=None)))])\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.574, logit=20.625)', '\" None\"[2290] (p=0.128, logit=19.125)', '\" Among\"[22395] (p=0.100, logit=18.875)', '\" The\"[578] (p=0.088, logit=18.750)', '\" A\"[362] (p=0.022, logit=17.375)']\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.57421875, logit=20.625, token_id=1630, metadata=None))), (70762, (6, PredictedToken(token=' Motorcycle', prob=0.022216796875, logit=17.375, token_id=70762, metadata=None))), (469, (88, PredictedToken(token=' E', prob=5.507469177246094e-05, logit=11.375, token_id=469, metadata=None))), (6150, (150, PredictedToken(token=' School', prob=2.0265579223632812e-05, logit=10.375, token_id=6150, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:59 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:45:59 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     patch_prediction=['\" Mall\"[32498] (p=0.883, logit=21.750)', '\" The\"[578] (p=0.044, logit=18.750)', '\" Among\"[22395] (p=0.018, logit=17.875)', '\" A\"[362] (p=0.016, logit=17.750)', '\" None\"[2290] (p=0.006, logit=16.750)']\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     clean_prediction=['\" Jacket\"[55870] (p=0.914, logit=22.750)', '\" The\"[578] (p=0.024, logit=19.125)', '\" A\"[362] (p=0.024, logit=19.125)', '\" Among\"[22395] (p=0.012, logit=18.375)', '\" jacket\"[27300] (p=0.010, logit=18.250)']\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     clean_track=OrderedDict([(55870, (1, PredictedToken(token=' Jacket', prob=0.9140625, logit=22.75, token_id=55870, metadata=None))), (17367, (40, PredictedToken(token=' Factory', prob=4.4345855712890625e-05, logit=12.8125, token_id=17367, metadata=None))), (87035, (94, PredictedToken(token=' Onion', prob=9.894371032714844e-06, logit=11.3125, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     int_prediction=['\" Factory\"[17367] (p=0.734, logit=21.375)', '\" Onion\"[87035] (p=0.100, logit=19.375)', '\" The\"[578] (p=0.053, logit=18.750)', '\" Among\"[22395] (p=0.047, logit=18.625)', '\" Jacket\"[55870] (p=0.013, logit=17.375)']\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     int_track=OrderedDict([(17367, (1, PredictedToken(token=' Factory', prob=0.734375, logit=21.375, token_id=17367, metadata=None))), (87035, (2, PredictedToken(token=' Onion', prob=0.099609375, logit=19.375, token_id=87035, metadata=None))), (55870, (5, PredictedToken(token=' Jacket', prob=0.01348876953125, logit=17.375, token_id=55870, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:45:59 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:45:59 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:45:59 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     patch_prediction=['\" Coffee\"[27171] (p=0.742, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" Among\"[22395] (p=0.047, logit=19.125)', '\" A\"[362] (p=0.037, logit=18.875)', '\" Coff\"[76233] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     clean_prediction=['\" Necklace\"[86460] (p=0.734, logit=22.125)', '\" The\"[578] (p=0.112, logit=20.250)', '\" A\"[362] (p=0.068, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=19.375)', '\" necklace\"[55547] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     clean_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.734375, logit=22.125, token_id=86460, metadata=None))), (15883, (33, PredictedToken(token=' Spr', prob=0.000217437744140625, logit=14.0, token_id=15883, metadata=None))), (1050, (96, PredictedToken(token=' Re', prob=2.288818359375e-05, logit=11.75, token_id=1050, metadata=None))), (36943, (712, PredictedToken(token=' Folder', prob=5.736947059631348e-07, logit=8.0625, token_id=36943, metadata=None)))])\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     int_prediction=['\" Folder\"[36943] (p=0.447, logit=21.250)', '\" The\"[578] (p=0.211, logit=20.500)', '\" Among\"[22395] (p=0.100, logit=19.750)', '\" Re\"[1050] (p=0.068, logit=19.375)', '\" Spr\"[15883] (p=0.053, logit=19.125)']\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     int_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.447265625, logit=21.25, token_id=36943, metadata=None))), (1050, (4, PredictedToken(token=' Re', prob=0.068359375, logit=19.375, token_id=1050, metadata=None))), (15883, (5, PredictedToken(token=' Spr', prob=0.053466796875, logit=19.125, token_id=15883, metadata=None))), (86460, (1321, PredictedToken(token=' Necklace', prob=4.079192876815796e-07, logit=7.34375, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:00 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:00 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:46:00 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.770, logit=22.000)', '\" The\"[578] (p=0.081, logit=19.750)', '\" A\"[362] (p=0.056, logit=19.375)', '\" Among\"[22395] (p=0.049, logit=19.250)', '\" \"[220] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     clean_prediction=['\" Sub\"[3804] (p=0.754, logit=21.500)', '\" A\"[362] (p=0.090, logit=19.375)', '\" The\"[578] (p=0.062, logit=19.000)', '\" Among\"[22395] (p=0.048, logit=18.750)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     clean_track=OrderedDict([(3804, (1, PredictedToken(token=' Sub', prob=0.75390625, logit=21.5, token_id=3804, metadata=None))), (96096, (20, PredictedToken(token=' Dolphin', prob=0.000827789306640625, logit=14.6875, token_id=96096, metadata=None))), (1443, (26, PredictedToken(token=' Sh', prob=0.000415802001953125, logit=14.0, token_id=1443, metadata=None))), (58586, (59, PredictedToken(token=' Tape', prob=9.298324584960938e-05, logit=12.5, token_id=58586, metadata=None))), (6150, (85, PredictedToken(token=' School', prob=4.673004150390625e-05, logit=11.8125, token_id=6150, metadata=None))), (55870, (98, PredictedToken(token=' Jacket', prob=3.218650817871094e-05, logit=11.4375, token_id=55870, metadata=None)))])\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     int_prediction=['\" Among\"[22395] (p=0.232, logit=18.625)', '\" The\"[578] (p=0.141, logit=18.125)', '\" Jacket\"[55870] (p=0.110, logit=17.875)', '\" Sh\"[1443] (p=0.110, logit=17.875)', '\" A\"[362] (p=0.085, logit=17.625)']\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     int_track=OrderedDict([(1443, (3, PredictedToken(token=' Sh', prob=0.10986328125, logit=17.875, token_id=1443, metadata=None))), (55870, (4, PredictedToken(token=' Jacket', prob=0.10986328125, logit=17.875, token_id=55870, metadata=None))), (96096, (9, PredictedToken(token=' Dolphin', prob=0.016845703125, logit=16.0, token_id=96096, metadata=None))), (6150, (10, PredictedToken(token=' School', prob=0.01483154296875, logit=15.875, token_id=6150, metadata=None))), (58586, (26, PredictedToken(token=' Tape', prob=0.0025787353515625, logit=14.125, token_id=58586, metadata=None))), (3804, (53, PredictedToken(token=' Sub', prob=0.000614166259765625, logit=12.6875, token_id=3804, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:01 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:01 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.789, logit=21.625)', '\" The\"[578] (p=0.083, logit=19.375)', '\" A\"[362] (p=0.039, logit=18.625)', '\" Among\"[22395] (p=0.035, logit=18.500)', '\" (\"[320] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.750, logit=20.625)', '\" The\"[578] (p=0.070, logit=18.250)', '\" An\"[1556] (p=0.048, logit=17.875)', '\" Among\"[22395] (p=0.029, logit=17.375)', '\" It\"[1102] (p=0.011, logit=16.375)']\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.75, logit=20.625, token_id=87213, metadata=None))), (45805, (6, PredictedToken(token=' Cherry', prob=0.00836181640625, logit=16.125, token_id=45805, metadata=None))), (91782, (368, PredictedToken(token=' Shorts', prob=6.318092346191406e-06, logit=8.9375, token_id=91782, metadata=None))), (28131, (1651, PredictedToken(token=' Golf', prob=7.7858567237854e-07, logit=6.84375, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     int_prediction=['\" Golf\"[28131] (p=0.469, logit=19.125)', '\" None\"[2290] (p=0.285, logit=18.625)', '\" Among\"[22395] (p=0.072, logit=17.250)', '\" The\"[578] (p=0.034, logit=16.500)', '\" A\"[362] (p=0.019, logit=15.938)']\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     int_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.46875, logit=19.125, token_id=28131, metadata=None))), (91782, (9, PredictedToken(token=' Shorts', prob=0.008056640625, logit=15.0625, token_id=91782, metadata=None))), (45805, (48, PredictedToken(token=' Cherry', prob=0.00042724609375, logit=12.125, token_id=45805, metadata=None))), (87213, (57, PredictedToken(token=' Oven', prob=0.000293731689453125, logit=11.75, token_id=87213, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:01 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:01 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:46:01 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     patch_prediction=['\" Shorts\"[91782] (p=0.621, logit=20.250)', '\" The\"[578] (p=0.108, logit=18.500)', '\" Short\"[10928] (p=0.065, logit=18.000)', '\" Among\"[22395] (p=0.058, logit=17.875)', '\" A\"[362] (p=0.051, logit=17.750)']\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     clean_prediction=['\" Water\"[10164] (p=0.812, logit=22.750)', '\" The\"[578] (p=0.086, logit=20.500)', '\" Among\"[22395] (p=0.059, logit=20.125)', '\" A\"[362] (p=0.012, logit=18.500)', '\" water\"[3090] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     clean_track=OrderedDict([(10164, (1, PredictedToken(token=' Water', prob=0.8125, logit=22.75, token_id=10164, metadata=None))), (41445, (79, PredictedToken(token=' Television', prob=1.8596649169921875e-05, logit=12.0625, token_id=41445, metadata=None))), (17810, (118, PredictedToken(token=' Cat', prob=7.271766662597656e-06, logit=11.125, token_id=17810, metadata=None))), (38673, (182, PredictedToken(token=' Yoga', prob=3.2335519790649414e-06, logit=10.3125, token_id=38673, metadata=None))), (29318, (280, PredictedToken(token=' Dress', prob=1.430511474609375e-06, logit=9.5, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     int_prediction=['\" Dress\"[29318] (p=0.309, logit=20.750)', '\" Cat\"[17810] (p=0.240, logit=20.500)', '\" The\"[578] (p=0.240, logit=20.500)', '\" Among\"[22395] (p=0.078, logit=19.375)', '\" A\"[362] (p=0.042, logit=18.750)']\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     int_track=OrderedDict([(29318, (1, PredictedToken(token=' Dress', prob=0.30859375, logit=20.75, token_id=29318, metadata=None))), (17810, (3, PredictedToken(token=' Cat', prob=0.240234375, logit=20.5, token_id=17810, metadata=None))), (41445, (6, PredictedToken(token=' Television', prob=0.0223388671875, logit=18.125, token_id=41445, metadata=None))), (38673, (16, PredictedToken(token=' Yoga', prob=0.00142669677734375, logit=15.375, token_id=38673, metadata=None))), (10164, (425, PredictedToken(token=' Water', prob=1.5720725059509277e-06, logit=8.5625, token_id=10164, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:02 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:02 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:46:02 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     patch_prediction=['\" Warehouse\"[52466] (p=0.879, logit=22.250)', '\" The\"[578] (p=0.039, logit=19.125)', '\" A\"[362] (p=0.039, logit=19.125)', '\" Among\"[22395] (p=0.011, logit=17.875)', '\" None\"[2290] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.672, logit=22.125)', '\" The\"[578] (p=0.132, logit=20.500)', '\" A\"[362] (p=0.091, logit=20.125)', '\" Among\"[22395] (p=0.071, logit=19.875)', '\" cuff\"[75523] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.671875, logit=22.125, token_id=356, metadata=None))), (98028, (62, PredictedToken(token=' Bamboo', prob=4.172325134277344e-05, logit=12.4375, token_id=98028, metadata=None))), (19111, (70, PredictedToken(token=' Bus', prob=3.0517578125e-05, logit=12.125, token_id=19111, metadata=None))), (13120, (293, PredictedToken(token=' Night', prob=1.952052116394043e-06, logit=9.375, token_id=13120, metadata=None))), (67553, (315, PredictedToken(token=' Pants', prob=1.8328428268432617e-06, logit=9.3125, token_id=67553, metadata=None))), (11896, (522, PredictedToken(token=' Library', prob=7.636845111846924e-07, logit=8.4375, token_id=11896, metadata=None)))])\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     int_prediction=['\" Library\"[11896] (p=0.449, logit=21.500)', '\" Night\"[13120] (p=0.240, logit=20.875)', '\" Among\"[22395] (p=0.165, logit=20.500)', '\" The\"[578] (p=0.100, logit=20.000)', '\" A\"[362] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     int_track=OrderedDict([(11896, (1, PredictedToken(token=' Library', prob=0.44921875, logit=21.5, token_id=11896, metadata=None))), (13120, (2, PredictedToken(token=' Night', prob=0.240234375, logit=20.875, token_id=13120, metadata=None))), (67553, (7, PredictedToken(token=' Pants', prob=0.0038909912109375, logit=16.75, token_id=67553, metadata=None))), (19111, (9, PredictedToken(token=' Bus', prob=0.0020751953125, logit=16.125, token_id=19111, metadata=None))), (356, (84, PredictedToken(token=' C', prob=4.315376281738281e-05, logit=12.25, token_id=356, metadata=None))), (98028, (339, PredictedToken(token=' Bamboo', prob=2.294778823852539e-06, logit=9.3125, token_id=98028, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:03 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:03 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     patch_prediction=['\" Food\"[12369] (p=0.684, logit=22.000)', '\" A\"[362] (p=0.152, logit=20.500)', '\" The\"[578] (p=0.105, logit=20.125)', '\" Among\"[22395] (p=0.016, logit=18.250)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     clean_prediction=['\" Truck\"[34785] (p=0.648, logit=21.250)', '\" The\"[578] (p=0.128, logit=19.625)', '\" A\"[362] (p=0.088, logit=19.250)', '\" Among\"[22395] (p=0.078, logit=19.125)', '\" Out\"[4470] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     clean_track=OrderedDict([(34785, (1, PredictedToken(token=' Truck', prob=0.6484375, logit=21.25, token_id=34785, metadata=None))), (432, (39, PredictedToken(token=' R', prob=0.00029754638671875, logit=13.5625, token_id=432, metadata=None))), (70110, (59, PredictedToken(token=' Ottoman', prob=0.00010967254638671875, logit=12.5625, token_id=70110, metadata=None))), (44570, (121, PredictedToken(token=' Maple', prob=2.300739288330078e-05, logit=11.0, token_id=44570, metadata=None))), (49268, (527, PredictedToken(token=' Dish', prob=1.564621925354004e-06, logit=8.3125, token_id=49268, metadata=None)))])\n",
      "2025-09-16 09:46:03 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     int_prediction=['\" Ottoman\"[70110] (p=0.594, logit=20.375)', '\" Among\"[22395] (p=0.133, logit=18.875)', '\" The\"[578] (p=0.117, logit=18.750)', '\" R\"[432] (p=0.043, logit=17.750)', '\" Maple\"[44570] (p=0.014, logit=16.625)']\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     int_track=OrderedDict([(70110, (1, PredictedToken(token=' Ottoman', prob=0.59375, logit=20.375, token_id=70110, metadata=None))), (432, (4, PredictedToken(token=' R', prob=0.04296875, logit=17.75, token_id=432, metadata=None))), (44570, (5, PredictedToken(token=' Maple', prob=0.01397705078125, logit=16.625, token_id=44570, metadata=None))), (49268, (226, PredictedToken(token=' Dish', prob=1.1980533599853516e-05, logit=9.5625, token_id=49268, metadata=None))), (34785, (374, PredictedToken(token=' Truck', prob=4.678964614868164e-06, logit=8.625, token_id=34785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:04 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:04 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     patch_prediction=['\" Plum\"[84409] (p=0.852, logit=21.875)', '\" Among\"[22395] (p=0.048, logit=19.000)', '\" The\"[578] (p=0.048, logit=19.000)', '\" A\"[362] (p=0.007, logit=17.125)', '\" Ash\"[14937] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.883, logit=21.875)', '\" A\"[362] (p=0.034, logit=18.625)', '\" The\"[578] (p=0.027, logit=18.375)', '\" Among\"[22395] (p=0.011, logit=17.500)', '\" watch\"[3821] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.8828125, logit=21.875, token_id=10573, metadata=None))), (1901, (21, PredictedToken(token=' Z', prob=0.0006256103515625, logit=14.625, token_id=1901, metadata=None))), (41785, (28, PredictedToken(token=' Spin', prob=0.0003795623779296875, logit=14.125, token_id=41785, metadata=None))), (91782, (36, PredictedToken(token=' Shorts', prob=0.0002956390380859375, logit=13.875, token_id=91782, metadata=None))), (22725, (67, PredictedToken(token=' Orange', prob=9.584426879882812e-05, logit=12.75, token_id=22725, metadata=None))), (18343, (78, PredictedToken(token=' Paper', prob=6.198883056640625e-05, logit=12.3125, token_id=18343, metadata=None)))])\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.652, logit=19.875)', '\" None\"[2290] (p=0.088, logit=17.875)', '\" Among\"[22395] (p=0.042, logit=17.125)', '\" The\"[578] (p=0.042, logit=17.125)', '\" Orange\"[22725] (p=0.029, logit=16.750)']\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.65234375, logit=19.875, token_id=1901, metadata=None))), (91782, (6, PredictedToken(token=' Shorts', prob=0.0286865234375, logit=16.75, token_id=91782, metadata=None))), (22725, (5, PredictedToken(token=' Orange', prob=0.0286865234375, logit=16.75, token_id=22725, metadata=None))), (41785, (11, PredictedToken(token=' Spin', prob=0.00439453125, logit=14.875, token_id=41785, metadata=None))), (10573, (31, PredictedToken(token=' Watch', prob=0.00098419189453125, logit=13.375, token_id=10573, metadata=None))), (18343, (192, PredictedToken(token=' Paper', prob=3.170967102050781e-05, logit=9.9375, token_id=18343, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:04 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:04 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:46:04 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     patch_prediction=['\" As\"[1666] (p=0.848, logit=22.500)', '\" Among\"[22395] (p=0.061, logit=19.875)', '\" The\"[578] (p=0.061, logit=19.875)', '\" It\"[1102] (p=0.003, logit=16.875)', '\" \"[220] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     clean_prediction=['\" Basketball\"[47589] (p=0.855, logit=22.250)', '\" The\"[578] (p=0.062, logit=19.625)', '\" Among\"[22395] (p=0.023, logit=18.625)', '\" A\"[362] (p=0.020, logit=18.500)', '\" Option\"[7104] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     clean_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.85546875, logit=22.25, token_id=47589, metadata=None))), (1443, (40, PredictedToken(token=' Sh', prob=0.0001277923583984375, logit=13.4375, token_id=1443, metadata=None))), (89077, (161, PredictedToken(token=' Strawberry', prob=6.3478946685791016e-06, logit=10.4375, token_id=89077, metadata=None))), (87035, (327, PredictedToken(token=' Onion', prob=1.817941665649414e-06, logit=9.1875, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.326, logit=19.375)', '\" The\"[578] (p=0.225, logit=19.000)', '\" Strawberry\"[89077] (p=0.136, logit=18.500)', '\" Among\"[22395] (p=0.083, logit=18.000)', '\" Sh\"[1443] (p=0.057, logit=17.625)']\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.326171875, logit=19.375, token_id=87035, metadata=None))), (89077, (3, PredictedToken(token=' Strawberry', prob=0.1357421875, logit=18.5, token_id=89077, metadata=None))), (1443, (5, PredictedToken(token=' Sh', prob=0.056640625, logit=17.625, token_id=1443, metadata=None))), (47589, (113, PredictedToken(token=' Basketball', prob=8.535385131835938e-05, logit=11.125, token_id=47589, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:05 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:05 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.656, logit=21.125)', '\" The\"[578] (p=0.129, logit=19.500)', '\" Among\"[22395] (p=0.069, logit=18.875)', '\" A\"[362] (p=0.061, logit=18.750)', '\" strawberry\"[73700] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     clean_prediction=['\" Palm\"[33578] (p=0.844, logit=21.875)', '\" The\"[578] (p=0.037, logit=18.750)', '\" A\"[362] (p=0.029, logit=18.500)', '\" Peach\"[64695] (p=0.022, logit=18.250)', '\" Among\"[22395] (p=0.020, logit=18.125)']\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     clean_track=OrderedDict([(33578, (1, PredictedToken(token=' Palm', prob=0.84375, logit=21.875, token_id=33578, metadata=None))), (64695, (4, PredictedToken(token=' Peach', prob=0.0224609375, logit=18.25, token_id=64695, metadata=None))), (1183, (17, PredictedToken(token=' Tr', prob=0.0009307861328125, logit=15.0625, token_id=1183, metadata=None)))])\n",
      "2025-09-16 09:46:05 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     int_prediction=['\" Peach\"[64695] (p=0.914, logit=22.375)', '\" Among\"[22395] (p=0.021, logit=18.625)', '\" The\"[578] (p=0.017, logit=18.375)', '\" Palm\"[33578] (p=0.007, logit=17.500)', '\" A\"[362] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     int_track=OrderedDict([(64695, (1, PredictedToken(token=' Peach', prob=0.9140625, logit=22.375, token_id=64695, metadata=None))), (33578, (4, PredictedToken(token=' Palm', prob=0.006988525390625, logit=17.5, token_id=33578, metadata=None))), (1183, (8, PredictedToken(token=' Tr', prob=0.0025634765625, logit=16.5, token_id=1183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:06 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:06 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     patch_prediction=['\" Pepper\"[52882] (p=0.844, logit=21.375)', '\" The\"[578] (p=0.048, logit=18.500)', '\" None\"[2290] (p=0.033, logit=18.125)', '\" Among\"[22395] (p=0.012, logit=17.125)', '\" A\"[362] (p=0.011, logit=17.000)']\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     clean_prediction=['\" Oven\"[87213] (p=0.734, logit=21.125)', '\" The\"[578] (p=0.099, logit=19.125)', '\" Among\"[22395] (p=0.068, logit=18.750)', '\" An\"[1556] (p=0.036, logit=18.125)', '\" O\"[507] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     clean_track=OrderedDict([(87213, (1, PredictedToken(token=' Oven', prob=0.734375, logit=21.125, token_id=87213, metadata=None))), (3341, (31, PredictedToken(token=' Car', prob=0.0003814697265625, logit=13.5625, token_id=3341, metadata=None))), (32498, (62, PredictedToken(token=' Mall', prob=0.00010251998901367188, logit=12.25, token_id=32498, metadata=None))), (67629, (83, PredictedToken(token=' Helmet', prob=7.486343383789062e-05, logit=11.9375, token_id=67629, metadata=None))), (1901, (116, PredictedToken(token=' Z', prob=3.337860107421875e-05, logit=11.125, token_id=1901, metadata=None))), (47759, (160, PredictedToken(token=' Guitar', prob=2.014636993408203e-05, logit=10.625, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     int_prediction=['\" Z\"[1901] (p=0.879, logit=22.750)', '\" The\"[578] (p=0.050, logit=19.875)', '\" Among\"[22395] (p=0.039, logit=19.625)', '\" None\"[2290] (p=0.004, logit=17.375)', '\" Only\"[8442] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     int_track=OrderedDict([(1901, (1, PredictedToken(token=' Z', prob=0.87890625, logit=22.75, token_id=1901, metadata=None))), (32498, (9, PredictedToken(token=' Mall', prob=0.001922607421875, logit=16.625, token_id=32498, metadata=None))), (3341, (36, PredictedToken(token=' Car', prob=0.0001087188720703125, logit=13.75, token_id=3341, metadata=None))), (87213, (452, PredictedToken(token=' Oven', prob=6.891787052154541e-07, logit=8.6875, token_id=87213, metadata=None))), (47759, (572, PredictedToken(token=' Guitar', prob=4.4330954551696777e-07, logit=8.25, token_id=47759, metadata=None))), (67629, (1812, PredictedToken(token=' Helmet', prob=7.729977369308472e-08, logit=6.5, token_id=67629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:06 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:06 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:06 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.789, logit=22.250)', '\" The\"[578] (p=0.073, logit=19.875)', '\" A\"[362] (p=0.057, logit=19.625)', '\" Among\"[22395] (p=0.050, logit=19.500)', '\" jacket\"[27300] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     clean_prediction=['\" Helmet\"[67629] (p=0.785, logit=20.875)', '\" The\"[578] (p=0.083, logit=18.625)', '\" A\"[362] (p=0.030, logit=17.625)', '\" Among\"[22395] (p=0.021, logit=17.250)', '\" It\"[1102] (p=0.007, logit=16.125)']\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     clean_track=OrderedDict([(67629, (1, PredictedToken(token=' Helmet', prob=0.78515625, logit=20.875, token_id=67629, metadata=None))), (46506, (9, PredictedToken(token=' Drum', prob=0.00439453125, logit=15.6875, token_id=46506, metadata=None))), (469, (18, PredictedToken(token=' E', prob=0.001251220703125, logit=14.4375, token_id=469, metadata=None))), (4923, (31, PredictedToken(token=' Sk', prob=0.000713348388671875, logit=13.875, token_id=4923, metadata=None)))])\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     int_prediction=['\" Sk\"[4923] (p=0.609, logit=20.125)', '\" Among\"[22395] (p=0.093, logit=18.250)', '\" The\"[578] (p=0.093, logit=18.250)', '\" E\"[469] (p=0.057, logit=17.750)', '\" Option\"[7104] (p=0.034, logit=17.250)']\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     int_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.609375, logit=20.125, token_id=4923, metadata=None))), (469, (4, PredictedToken(token=' E', prob=0.056640625, logit=17.75, token_id=469, metadata=None))), (67629, (39, PredictedToken(token=' Helmet', prob=0.000591278076171875, logit=13.1875, token_id=67629, metadata=None))), (46506, (91, PredictedToken(token=' Drum', prob=8.487701416015625e-05, logit=11.25, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:07 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:07 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     patch_prediction=['\" Oak\"[18787] (p=0.809, logit=21.500)', '\" The\"[578] (p=0.066, logit=19.000)', '\" Among\"[22395] (p=0.046, logit=18.625)', '\" An\"[1556] (p=0.012, logit=17.250)', '\" Option\"[7104] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.727, logit=20.625)', '\" Among\"[22395] (p=0.077, logit=18.375)', '\" The\"[578] (p=0.077, logit=18.375)', '\" A\"[362] (p=0.036, logit=17.625)', '\" lotion\"[87942] (p=0.010, logit=16.375)']\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.7265625, logit=20.625, token_id=445, metadata=None))), (1183, (35, PredictedToken(token=' Tr', prob=0.000377655029296875, logit=13.0625, token_id=1183, metadata=None))), (21424, (102, PredictedToken(token=' Football', prob=5.435943603515625e-05, logit=11.125, token_id=21424, metadata=None))), (3816, (99, PredictedToken(token=' Red', prob=5.435943603515625e-05, logit=11.125, token_id=3816, metadata=None)))])\n",
      "2025-09-16 09:46:07 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     int_prediction=['\" Red\"[3816] (p=0.664, logit=20.625)', '\" Tr\"[1183] (p=0.090, logit=18.625)', '\" Among\"[22395] (p=0.070, logit=18.375)', '\" The\"[578] (p=0.070, logit=18.375)', '\" A\"[362] (p=0.037, logit=17.750)']\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     int_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.6640625, logit=20.625, token_id=3816, metadata=None))), (1183, (2, PredictedToken(token=' Tr', prob=0.08984375, logit=18.625, token_id=1183, metadata=None))), (21424, (10, PredictedToken(token=' Football', prob=0.00347900390625, logit=15.375, token_id=21424, metadata=None))), (445, (59, PredictedToken(token=' L', prob=0.0001735687255859375, logit=12.375, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:08 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     patch_prediction=['\" Plum\"[84409] (p=0.910, logit=21.750)', '\" None\"[2290] (p=0.024, logit=18.125)', '\" plum\"[42272] (p=0.013, logit=17.500)', '\" The\"[578] (p=0.008, logit=17.000)', '\" (\"[320] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     clean_prediction=['\" Night\"[13120] (p=0.828, logit=22.250)', '\" A\"[362] (p=0.060, logit=19.625)', '\" The\"[578] (p=0.053, logit=19.500)', '\" Among\"[22395] (p=0.022, logit=18.625)', '\" a\"[264] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     clean_track=OrderedDict([(13120, (1, PredictedToken(token=' Night', prob=0.828125, logit=22.25, token_id=13120, metadata=None))), (65329, (38, PredictedToken(token=' Elm', prob=0.00011587142944335938, logit=13.375, token_id=65329, metadata=None))), (55405, (103, PredictedToken(token=' Orch', prob=1.4722347259521484e-05, logit=11.3125, token_id=55405, metadata=None))), (89077, (574, PredictedToken(token=' Strawberry', prob=6.07222318649292e-07, logit=8.125, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.314, logit=19.500)', '\" Orch\"[55405] (p=0.245, logit=19.250)', '\" The\"[578] (p=0.148, logit=18.750)', '\" Among\"[22395] (p=0.080, logit=18.125)', '\" Strawberry\"[89077] (p=0.055, logit=17.750)']\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.314453125, logit=19.5, token_id=65329, metadata=None))), (55405, (2, PredictedToken(token=' Orch', prob=0.2451171875, logit=19.25, token_id=55405, metadata=None))), (89077, (5, PredictedToken(token=' Strawberry', prob=0.0546875, logit=17.75, token_id=89077, metadata=None))), (13120, (271, PredictedToken(token=' Night', prob=1.2576580047607422e-05, logit=9.375, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:08 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:08 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:08 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     patch_prediction=['\" Soap\"[61731] (p=0.855, logit=21.500)', '\" The\"[578] (p=0.038, logit=18.375)', '\" Among\"[22395] (p=0.033, logit=18.250)', '\" SOAP\"[64332] (p=0.011, logit=17.125)', '\" Option\"[7104] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     clean_prediction=['\" Pendant\"[81501] (p=0.875, logit=22.375)', '\" A\"[362] (p=0.043, logit=19.375)', '\" The\"[578] (p=0.034, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=18.750)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     clean_track=OrderedDict([(81501, (1, PredictedToken(token=' Pendant', prob=0.875, logit=22.375, token_id=81501, metadata=None))), (23262, (7, PredictedToken(token=' Comb', prob=0.00168609619140625, logit=16.125, token_id=23262, metadata=None))), (3341, (32, PredictedToken(token=' Car', prob=0.00013828277587890625, logit=13.625, token_id=3341, metadata=None))), (24941, (72, PredictedToken(token=' Bear', prob=3.0994415283203125e-05, logit=12.125, token_id=24941, metadata=None)))])\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.249, logit=19.500)', '\" Comb\"[23262] (p=0.193, logit=19.250)', '\" Among\"[22395] (p=0.171, logit=19.125)', '\" A\"[362] (p=0.133, logit=18.875)', '\" The\"[578] (p=0.104, logit=18.625)']\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.2490234375, logit=19.5, token_id=3341, metadata=None))), (23262, (2, PredictedToken(token=' Comb', prob=0.193359375, logit=19.25, token_id=23262, metadata=None))), (24941, (6, PredictedToken(token=' Bear', prob=0.02978515625, logit=17.375, token_id=24941, metadata=None))), (81501, (40, PredictedToken(token=' Pendant', prob=0.00061798095703125, logit=13.5, token_id=81501, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:09 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:09 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     patch_prediction=['\" Skate\"[97796] (p=0.629, logit=21.375)', '\" A\"[362] (p=0.180, logit=20.125)', '\" The\"[578] (p=0.124, logit=19.750)', '\" Among\"[22395] (p=0.010, logit=17.250)', '\" (\"[320] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     clean_prediction=['\" L\"[445] (p=0.867, logit=21.375)', '\" Among\"[22395] (p=0.038, logit=18.250)', '\" The\"[578] (p=0.034, logit=18.125)', '\" None\"[2290] (p=0.008, logit=16.750)', '\" Lot\"[22503] (p=0.005, logit=16.125)']\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     clean_track=OrderedDict([(445, (1, PredictedToken(token=' L', prob=0.8671875, logit=21.375, token_id=445, metadata=None))), (63606, (17, PredictedToken(token=' Stap', prob=0.00101470947265625, logit=14.625, token_id=63606, metadata=None))), (38258, (75, PredictedToken(token=' Baseball', prob=7.343292236328125e-05, logit=12.0, token_id=38258, metadata=None)))])\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     int_prediction=['\" Baseball\"[38258] (p=0.594, logit=20.875)', '\" Stap\"[63606] (p=0.219, logit=19.875)', '\" None\"[2290] (p=0.103, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=17.625)', '\" The\"[578] (p=0.014, logit=17.125)']\n",
      "2025-09-16 09:46:09 src.selection.optimization INFO     int_track=OrderedDict([(38258, (1, PredictedToken(token=' Baseball', prob=0.59375, logit=20.875, token_id=38258, metadata=None))), (63606, (2, PredictedToken(token=' Stap', prob=0.21875, logit=19.875, token_id=63606, metadata=None))), (445, (158, PredictedToken(token=' L', prob=1.3530254364013672e-05, logit=10.1875, token_id=445, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:09 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:10 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     patch_prediction=['\" Spin\"[41785] (p=0.867, logit=22.000)', '\" Among\"[22395] (p=0.049, logit=19.125)', '\" The\"[578] (p=0.049, logit=19.125)', '\" A\"[362] (p=0.005, logit=16.750)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.836, logit=21.750)', '\" The\"[578] (p=0.037, logit=18.625)', '\" A\"[362] (p=0.032, logit=18.500)', '\" Among\"[22395] (p=0.022, logit=18.125)', '\" None\"[2290] (p=0.020, logit=18.000)']\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.8359375, logit=21.75, token_id=10573, metadata=None))), (34785, (29, PredictedToken(token=' Truck', prob=0.00043487548828125, logit=14.1875, token_id=34785, metadata=None))), (1901, (34, PredictedToken(token=' Z', prob=0.0002803802490234375, logit=13.75, token_id=1901, metadata=None))), (14669, (108, PredictedToken(token=' Camera', prob=3.552436828613281e-05, logit=11.6875, token_id=14669, metadata=None))), (87035, (181, PredictedToken(token=' Onion', prob=1.1563301086425781e-05, logit=10.5625, token_id=87035, metadata=None)))])\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     int_prediction=['\" Onion\"[87035] (p=0.516, logit=19.750)', '\" None\"[2290] (p=0.190, logit=18.750)', '\" Among\"[22395] (p=0.070, logit=17.750)', '\" The\"[578] (p=0.054, logit=17.500)', '\" Truck\"[34785] (p=0.018, logit=16.375)']\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     int_track=OrderedDict([(87035, (1, PredictedToken(token=' Onion', prob=0.515625, logit=19.75, token_id=87035, metadata=None))), (34785, (5, PredictedToken(token=' Truck', prob=0.0177001953125, logit=16.375, token_id=34785, metadata=None))), (1901, (12, PredictedToken(token=' Z', prob=0.006500244140625, logit=15.375, token_id=1901, metadata=None))), (10573, (188, PredictedToken(token=' Watch', prob=3.0159950256347656e-05, logit=10.0, token_id=10573, metadata=None))), (14669, (1847, PredictedToken(token=' Camera', prob=1.1324882507324219e-06, logit=6.71875, token_id=14669, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:10 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:10 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:46:10 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     patch_prediction=['\" Blender\"[88668] (p=0.867, logit=22.875)', '\" The\"[578] (p=0.055, logit=20.125)', '\" A\"[362] (p=0.034, logit=19.625)', '\" Among\"[22395] (p=0.030, logit=19.500)', '\" It\"[1102] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.727, logit=21.625)', '\" The\"[578] (p=0.111, logit=19.750)', '\" Among\"[22395] (p=0.060, logit=19.125)', '\" A\"[362] (p=0.052, logit=19.000)', '\" C\"[356] (p=0.009, logit=17.250)']\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.7265625, logit=21.625, token_id=3816, metadata=None))), (356, (5, PredictedToken(token=' C', prob=0.0091552734375, logit=17.25, token_id=356, metadata=None))), (100031, (78, PredictedToken(token=' Mosque', prob=4.506111145019531e-05, logit=11.9375, token_id=100031, metadata=None))), (3420, (281, PredictedToken(token=' Trump', prob=3.2633543014526367e-06, logit=9.3125, token_id=3420, metadata=None))), (12369, (532, PredictedToken(token=' Food', prob=1.125037670135498e-06, logit=8.25, token_id=12369, metadata=None)))])\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.381, logit=21.000)', '\" Food\"[12369] (p=0.336, logit=20.875)', '\" The\"[578] (p=0.180, logit=20.250)', '\" A\"[362] (p=0.028, logit=18.375)', '\" Among\"[22395] (p=0.024, logit=18.250)']\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.380859375, logit=21.0, token_id=356, metadata=None))), (12369, (2, PredictedToken(token=' Food', prob=0.3359375, logit=20.875, token_id=12369, metadata=None))), (100031, (177, PredictedToken(token=' Mosque', prob=7.68899917602539e-06, logit=10.1875, token_id=100031, metadata=None))), (3420, (353, PredictedToken(token=' Trump', prob=1.7136335372924805e-06, logit=8.6875, token_id=3420, metadata=None))), (3816, (583, PredictedToken(token=' Red', prob=8.605420589447021e-07, logit=8.0, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:11 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:11 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     patch_prediction=['\" Car\"[3341] (p=0.570, logit=22.375)', '\" The\"[578] (p=0.210, logit=21.375)', '\" A\"[362] (p=0.128, logit=20.875)', '\" Among\"[22395] (p=0.053, logit=20.000)', '\" It\"[1102] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     clean_prediction=['\" Strawberry\"[89077] (p=0.602, logit=21.250)', '\" The\"[578] (p=0.194, logit=20.125)', '\" Among\"[22395] (p=0.081, logit=19.250)', '\" A\"[362] (p=0.072, logit=19.125)', '\" strawberry\"[73700] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     clean_track=OrderedDict([(89077, (1, PredictedToken(token=' Strawberry', prob=0.6015625, logit=21.25, token_id=89077, metadata=None))), (445, (29, PredictedToken(token=' L', prob=0.000331878662109375, logit=13.75, token_id=445, metadata=None))), (3420, (108, PredictedToken(token=' Trump', prob=2.2530555725097656e-05, logit=11.0625, token_id=3420, metadata=None))), (11452, (135, PredictedToken(token=' Head', prob=1.5497207641601562e-05, logit=10.6875, token_id=11452, metadata=None))), (13000, (321, PredictedToken(token=' Van', prob=3.0547380447387695e-06, logit=9.0625, token_id=13000, metadata=None)))])\n",
      "2025-09-16 09:46:11 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     int_prediction=['\" Van\"[13000] (p=0.832, logit=22.625)', '\" The\"[578] (p=0.068, logit=20.125)', '\" Among\"[22395] (p=0.037, logit=19.500)', '\" Option\"[7104] (p=0.010, logit=18.250)', '\" It\"[1102] (p=0.009, logit=18.125)']\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     int_track=OrderedDict([(13000, (1, PredictedToken(token=' Van', prob=0.83203125, logit=22.625, token_id=13000, metadata=None))), (445, (7, PredictedToken(token=' L', prob=0.005615234375, logit=17.625, token_id=445, metadata=None))), (11452, (11, PredictedToken(token=' Head', prob=0.0020599365234375, logit=16.625, token_id=11452, metadata=None))), (3420, (53, PredictedToken(token=' Trump', prob=5.507469177246094e-05, logit=13.0, token_id=3420, metadata=None))), (89077, (4666, PredictedToken(token=' Strawberry', prob=2.153683453798294e-08, logit=5.15625, token_id=89077, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:12 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:12 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.711, logit=21.000)', '\" The\"[578] (p=0.109, logit=19.125)', '\" Among\"[22395] (p=0.066, logit=18.625)', '\" A\"[362] (p=0.035, logit=18.000)', '\" B\"[426] (p=0.017, logit=17.250)']\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.902, logit=22.500)', '\" Among\"[22395] (p=0.027, logit=19.000)', '\" The\"[578] (p=0.024, logit=18.875)', '\" None\"[2290] (p=0.015, logit=18.375)', '\" There\"[2684] (p=0.005, logit=17.250)']\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.90234375, logit=22.5, token_id=41785, metadata=None))), (6690, (7, PredictedToken(token=' Air', prob=0.0032501220703125, logit=16.875, token_id=6690, metadata=None))), (432, (36, PredictedToken(token=' R', prob=0.00011157989501953125, logit=13.5, token_id=432, metadata=None))), (20918, (64, PredictedToken(token=' Magn', prob=3.8623809814453125e-05, logit=12.4375, token_id=20918, metadata=None))), (68554, (334, PredictedToken(token=' Gloves', prob=1.5869736671447754e-06, logit=9.25, token_id=68554, metadata=None)))])\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     int_prediction=['\" Magn\"[20918] (p=0.496, logit=20.750)', '\" None\"[2290] (p=0.342, logit=20.375)', '\" Among\"[22395] (p=0.036, logit=18.125)', '\" There\"[2684] (p=0.032, logit=18.000)', '\" The\"[578] (p=0.028, logit=17.875)']\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     int_track=OrderedDict([(20918, (1, PredictedToken(token=' Magn', prob=0.49609375, logit=20.75, token_id=20918, metadata=None))), (6690, (6, PredictedToken(token=' Air', prob=0.00909423828125, logit=16.75, token_id=6690, metadata=None))), (432, (15, PredictedToken(token=' R', prob=0.001312255859375, logit=14.8125, token_id=432, metadata=None))), (68554, (23, PredictedToken(token=' Gloves', prob=0.0009002685546875, logit=14.4375, token_id=68554, metadata=None))), (41785, (53, PredictedToken(token=' Spin', prob=0.00013828277587890625, logit=12.5625, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:12 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:12 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:46:12 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     patch_prediction=['\" Viol\"[30555] (p=0.746, logit=22.125)', '\" The\"[578] (p=0.146, logit=20.500)', '\" Among\"[22395] (p=0.029, logit=18.875)', '\" A\"[362] (p=0.029, logit=18.875)', '\" violin\"[63137] (p=0.011, logit=17.875)']\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.832, logit=21.625)', '\" The\"[578] (p=0.053, logit=18.875)', '\" Option\"[7104] (p=0.025, logit=18.125)', '\" Among\"[22395] (p=0.025, logit=18.125)', '\" (\"[320] (p=0.015, logit=17.625)']\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.83203125, logit=21.625, token_id=469, metadata=None))), (3061, (15, PredictedToken(token=' Fl', prob=0.0015106201171875, logit=15.3125, token_id=3061, metadata=None))), (58251, (136, PredictedToken(token=' Tennis', prob=1.3887882232666016e-05, logit=10.625, token_id=58251, metadata=None)))])\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     int_prediction=['\" Tennis\"[58251] (p=0.498, logit=19.875)', '\" The\"[578] (p=0.143, logit=18.625)', '\" Among\"[22395] (p=0.098, logit=18.250)', '\" None\"[2290] (p=0.060, logit=17.750)', '\" Fl\"[3061] (p=0.052, logit=17.625)']\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     int_track=OrderedDict([(58251, (1, PredictedToken(token=' Tennis', prob=0.498046875, logit=19.875, token_id=58251, metadata=None))), (3061, (5, PredictedToken(token=' Fl', prob=0.052490234375, logit=17.625, token_id=3061, metadata=None))), (469, (100, PredictedToken(token=' E', prob=6.532669067382812e-05, logit=10.9375, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:13 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:13 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     patch_prediction=['\" Ank\"[57915] (p=0.945, logit=22.750)', '\" An\"[1556] (p=0.017, logit=18.750)', '\" The\"[578] (p=0.009, logit=18.125)', '\" Among\"[22395] (p=0.008, logit=18.000)', '\" ank\"[71572] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.688, logit=20.750)', '\" Among\"[22395] (p=0.105, logit=18.875)', '\" The\"[578] (p=0.105, logit=18.875)', '\" Ski\"[61595] (p=0.018, logit=17.125)', '\" It\"[1102] (p=0.014, logit=16.875)']\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.6875, logit=20.75, token_id=4923, metadata=None))), (5340, (13, PredictedToken(token=' Har', prob=0.0028076171875, logit=15.25, token_id=5340, metadata=None))), (22050, (50, PredictedToken(token=' Hat', prob=0.0002956390380859375, logit=13.0, token_id=22050, metadata=None))), (53889, (127, PredictedToken(token=' Apartment', prob=2.4318695068359375e-05, logit=10.5, token_id=53889, metadata=None))), (86460, (251, PredictedToken(token=' Necklace', prob=6.5267086029052734e-06, logit=9.1875, token_id=86460, metadata=None))), (16344, (821, PredictedToken(token=' Rose', prob=9.126961231231689e-07, logit=7.21875, token_id=16344, metadata=None)))])\n",
      "2025-09-16 09:46:13 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.727, logit=21.500)', '\" The\"[578] (p=0.098, logit=19.500)', '\" Hat\"[22050] (p=0.060, logit=19.000)', '\" A\"[362] (p=0.046, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=18.125)']\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.7265625, logit=21.5, token_id=86460, metadata=None))), (22050, (3, PredictedToken(token=' Hat', prob=0.0595703125, logit=19.0, token_id=22050, metadata=None))), (5340, (9, PredictedToken(token=' Har', prob=0.00140380859375, logit=15.25, token_id=5340, metadata=None))), (16344, (35, PredictedToken(token=' Rose', prob=0.00024318695068359375, logit=13.5, token_id=16344, metadata=None))), (53889, (158, PredictedToken(token=' Apartment', prob=1.138448715209961e-05, logit=10.4375, token_id=53889, metadata=None))), (4923, (2112, PredictedToken(token=' Sk', prob=2.514570951461792e-07, logit=6.625, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:14 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:14 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     patch_prediction=['\" Bamboo\"[98028] (p=0.820, logit=21.000)', '\" The\"[578] (p=0.052, logit=18.250)', '\" Among\"[22395] (p=0.041, logit=18.000)', '\" It\"[1102] (p=0.009, logit=16.500)', '\" A\"[362] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     clean_prediction=['\" Pe\"[5250] (p=0.586, logit=20.875)', '\" The\"[578] (p=0.168, logit=19.625)', '\" Among\"[22395] (p=0.131, logit=19.375)', '\" A\"[362] (p=0.042, logit=18.250)', '\" (\"[320] (p=0.009, logit=16.750)']\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     clean_track=OrderedDict([(5250, (1, PredictedToken(token=' Pe', prob=0.5859375, logit=20.875, token_id=5250, metadata=None))), (469, (16, PredictedToken(token=' E', prob=0.00136566162109375, logit=14.8125, token_id=469, metadata=None))), (88088, (53, PredictedToken(token=' Birch', prob=0.0002231597900390625, logit=13.0, token_id=88088, metadata=None))), (328, (91, PredictedToken(token=' S', prob=4.982948303222656e-05, logit=11.5, token_id=328, metadata=None))), (79189, (217, PredictedToken(token=' Elephant', prob=9.775161743164062e-06, logit=9.875, token_id=79189, metadata=None))), (30173, (3518, PredictedToken(token=' Speaker', prob=1.2759119272232056e-07, logit=5.53125, token_id=30173, metadata=None)))])\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     int_prediction=['\" Birch\"[88088] (p=0.691, logit=21.000)', '\" Among\"[22395] (p=0.120, logit=19.250)', '\" The\"[578] (p=0.106, logit=19.125)', '\" B\"[426] (p=0.011, logit=16.875)', '\" (\"[320] (p=0.009, logit=16.625)']\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     int_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.69140625, logit=21.0, token_id=88088, metadata=None))), (469, (11, PredictedToken(token=' E', prob=0.0023345947265625, logit=15.3125, token_id=469, metadata=None))), (79189, (44, PredictedToken(token=' Elephant', prob=0.0002040863037109375, logit=12.875, token_id=79189, metadata=None))), (328, (80, PredictedToken(token=' S', prob=5.507469177246094e-05, logit=11.5625, token_id=328, metadata=None))), (5250, (138, PredictedToken(token=' Pe', prob=1.4841556549072266e-05, logit=10.25, token_id=5250, metadata=None))), (30173, (1404, PredictedToken(token=' Speaker', prob=5.736947059631348e-07, logit=7.0, token_id=30173, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:14 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:14 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:14 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     patch_prediction=['\" Library\"[11896] (p=0.812, logit=22.125)', '\" The\"[578] (p=0.067, logit=19.625)', '\" A\"[362] (p=0.052, logit=19.375)', '\" Among\"[22395] (p=0.015, logit=18.125)', '\" None\"[2290] (p=0.012, logit=17.875)']\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     clean_prediction=['\" Hick\"[79028] (p=0.637, logit=20.125)', '\" C\"[356] (p=0.125, logit=18.500)', '\" Temple\"[19176] (p=0.059, logit=17.750)', '\" Drum\"[46506] (p=0.052, logit=17.625)', '\" The\"[578] (p=0.032, logit=17.125)']\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     clean_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.63671875, logit=20.125, token_id=79028, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.125, logit=18.5, token_id=356, metadata=None))), (19176, (3, PredictedToken(token=' Temple', prob=0.059326171875, logit=17.75, token_id=19176, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.05224609375, logit=17.625, token_id=46506, metadata=None)))])\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     int_prediction=['\" Temple\"[19176] (p=0.324, logit=19.000)', '\" C\"[356] (p=0.285, logit=18.875)', '\" Hick\"[79028] (p=0.082, logit=17.625)', '\" Drum\"[46506] (p=0.056, logit=17.250)', '\" None\"[2290] (p=0.050, logit=17.125)']\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     int_track=OrderedDict([(19176, (1, PredictedToken(token=' Temple', prob=0.32421875, logit=19.0, token_id=19176, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.28515625, logit=18.875, token_id=356, metadata=None))), (79028, (3, PredictedToken(token=' Hick', prob=0.08154296875, logit=17.625, token_id=79028, metadata=None))), (46506, (4, PredictedToken(token=' Drum', prob=0.05615234375, logit=17.25, token_id=46506, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:15 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:15 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.582, logit=20.625)', '\" The\"[578] (p=0.147, logit=19.250)', '\" A\"[362] (p=0.147, logit=19.250)', '\" Among\"[22395] (p=0.042, logit=18.000)', '\" Only\"[8442] (p=0.009, logit=16.500)']\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     clean_prediction=['\" Folder\"[36943] (p=0.660, logit=20.875)', '\" The\"[578] (p=0.130, logit=19.250)', '\" A\"[362] (p=0.070, logit=18.625)', '\" Among\"[22395] (p=0.042, logit=18.125)', '\" It\"[1102] (p=0.014, logit=17.000)']\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     clean_track=OrderedDict([(36943, (1, PredictedToken(token=' Folder', prob=0.66015625, logit=20.875, token_id=36943, metadata=None))), (79189, (29, PredictedToken(token=' Elephant', prob=0.000774383544921875, logit=14.125, token_id=79189, metadata=None))), (4783, (143, PredictedToken(token=' House', prob=2.8252601623535156e-05, logit=10.8125, token_id=4783, metadata=None))), (47589, (185, PredictedToken(token=' Basketball', prob=1.823902130126953e-05, logit=10.375, token_id=47589, metadata=None)))])\n",
      "2025-09-16 09:46:15 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     int_prediction=['\" Basketball\"[47589] (p=0.824, logit=21.375)', '\" Among\"[22395] (p=0.032, logit=18.125)', '\" The\"[578] (p=0.032, logit=18.125)', '\" None\"[2290] (p=0.032, logit=18.125)', '\" House\"[4783] (p=0.019, logit=17.625)']\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     int_track=OrderedDict([(47589, (1, PredictedToken(token=' Basketball', prob=0.82421875, logit=21.375, token_id=47589, metadata=None))), (4783, (5, PredictedToken(token=' House', prob=0.0194091796875, logit=17.625, token_id=4783, metadata=None))), (79189, (203, PredictedToken(token=' Elephant', prob=1.0728836059570312e-05, logit=10.125, token_id=79189, metadata=None))), (36943, (1026, PredictedToken(token=' Folder', prob=7.748603820800781e-07, logit=7.5, token_id=36943, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:16 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:16 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     patch_prediction=['\" Hockey\"[41342] (p=0.805, logit=21.125)', '\" The\"[578] (p=0.066, logit=18.625)', '\" A\"[362] (p=0.040, logit=18.125)', '\" Among\"[22395] (p=0.024, logit=17.625)', '\" Option\"[7104] (p=0.011, logit=16.875)']\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     clean_prediction=['\" Red\"[3816] (p=0.770, logit=22.125)', '\" The\"[578] (p=0.092, logit=20.000)', '\" A\"[362] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=19.125)', '\" It\"[1102] (p=0.005, logit=17.125)']\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     clean_track=OrderedDict([(3816, (1, PredictedToken(token=' Red', prob=0.76953125, logit=22.125, token_id=3816, metadata=None))), (58586, (269, PredictedToken(token=' Tape', prob=2.5331974029541016e-06, logit=9.5, token_id=58586, metadata=None))), (97796, (446, PredictedToken(token=' Skate', prob=1.0579824447631836e-06, logit=8.625, token_id=97796, metadata=None))), (38930, (1055, PredictedToken(token=' Bike', prob=2.7567148208618164e-07, logit=7.28125, token_id=38930, metadata=None)))])\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.711, logit=21.250)', '\" The\"[578] (p=0.109, logit=19.375)', '\" Among\"[22395] (p=0.052, logit=18.625)', '\" Tape\"[58586] (p=0.035, logit=18.250)', '\" A\"[362] (p=0.028, logit=18.000)']\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.7109375, logit=21.25, token_id=97796, metadata=None))), (58586, (4, PredictedToken(token=' Tape', prob=0.035400390625, logit=18.25, token_id=58586, metadata=None))), (38930, (6, PredictedToken(token=' Bike', prob=0.0167236328125, logit=17.5, token_id=38930, metadata=None))), (3816, (76, PredictedToken(token=' Red', prob=6.031990051269531e-05, logit=11.875, token_id=3816, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:16 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:16 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:46:16 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     patch_prediction=['\" Factory\"[17367] (p=0.773, logit=21.750)', '\" A\"[362] (p=0.082, logit=19.500)', '\" The\"[578] (p=0.056, logit=19.125)', '\" Among\"[22395] (p=0.023, logit=18.250)', '\" None\"[2290] (p=0.016, logit=17.875)']\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     clean_prediction=['\" Spin\"[41785] (p=0.879, logit=22.750)', '\" Among\"[22395] (p=0.050, logit=19.875)', '\" The\"[578] (p=0.050, logit=19.875)', '\" It\"[1102] (p=0.003, logit=17.125)', '\" Out\"[4470] (p=0.003, logit=17.000)']\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     clean_track=OrderedDict([(41785, (1, PredictedToken(token=' Spin', prob=0.87890625, logit=22.75, token_id=41785, metadata=None))), (6690, (89, PredictedToken(token=' Air', prob=1.3828277587890625e-05, logit=11.6875, token_id=6690, metadata=None))), (53889, (486, PredictedToken(token=' Apartment', prob=5.699694156646729e-07, logit=8.5, token_id=53889, metadata=None))), (61948, (741, PredictedToken(token=' Sofa', prob=3.0547380447387695e-07, logit=7.875, token_id=61948, metadata=None))), (86460, (1216, PredictedToken(token=' Necklace', prob=1.5366822481155396e-07, logit=7.1875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     int_prediction=['\" Apartment\"[53889] (p=0.668, logit=22.000)', '\" Air\"[6690] (p=0.090, logit=20.000)', '\" The\"[578] (p=0.080, logit=19.875)', '\" An\"[1556] (p=0.055, logit=19.500)', '\" Among\"[22395] (p=0.048, logit=19.375)']\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     int_track=OrderedDict([(53889, (1, PredictedToken(token=' Apartment', prob=0.66796875, logit=22.0, token_id=53889, metadata=None))), (6690, (2, PredictedToken(token=' Air', prob=0.09033203125, logit=20.0, token_id=6690, metadata=None))), (61948, (114, PredictedToken(token=' Sofa', prob=1.8358230590820312e-05, logit=11.5, token_id=61948, metadata=None))), (86460, (357, PredictedToken(token=' Necklace', prob=2.0712614059448242e-06, logit=9.3125, token_id=86460, metadata=None))), (41785, (1285, PredictedToken(token=' Spin', prob=2.980232238769531e-07, logit=7.375, token_id=41785, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:17 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:17 src.selection.optimization DEBUG    torch.Size([5, 28])\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     patch_prediction=['\" Tablet\"[58403] (p=0.582, logit=20.750)', '\" The\"[578] (p=0.167, logit=19.500)', '\" A\"[362] (p=0.102, logit=19.000)', '\" Among\"[22395] (p=0.054, logit=18.375)', '\" It\"[1102] (p=0.018, logit=17.250)']\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.863, logit=22.000)', '\" The\"[578] (p=0.062, logit=19.375)', '\" Among\"[22395] (p=0.038, logit=18.875)', '\" It\"[1102] (p=0.004, logit=16.500)', '\" A\"[362] (p=0.002, logit=16.125)']\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.86328125, logit=22.0, token_id=72683, metadata=None))), (11452, (9, PredictedToken(token=' Head', prob=0.00156402587890625, logit=15.6875, token_id=11452, metadata=None))), (1630, (16, PredictedToken(token=' X', prob=0.000736236572265625, logit=14.9375, token_id=1630, metadata=None))), (16478, (90, PredictedToken(token=' Chair', prob=3.0517578125e-05, logit=11.75, token_id=16478, metadata=None))), (52882, (103, PredictedToken(token=' Pepper', prob=2.09808349609375e-05, logit=11.375, token_id=52882, metadata=None)))])\n",
      "2025-09-16 09:46:17 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.309, logit=19.625)', '\" The\"[578] (p=0.212, logit=19.250)', '\" Head\"[11452] (p=0.187, logit=19.125)', '\" Among\"[22395] (p=0.129, logit=18.750)', '\" A\"[362] (p=0.032, logit=17.375)']\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.30859375, logit=19.625, token_id=1630, metadata=None))), (11452, (3, PredictedToken(token=' Head', prob=0.1865234375, logit=19.125, token_id=11452, metadata=None))), (52882, (6, PredictedToken(token=' Pepper', prob=0.017333984375, logit=16.75, token_id=52882, metadata=None))), (16478, (25, PredictedToken(token=' Chair', prob=0.0013427734375, logit=14.1875, token_id=16478, metadata=None))), (72683, (121, PredictedToken(token=' Boxing', prob=4.315376281738281e-05, logit=10.75, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:18 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:18 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     patch_prediction=['\" Maple\"[44570] (p=0.898, logit=22.125)', '\" The\"[578] (p=0.031, logit=18.750)', '\" Among\"[22395] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.008, logit=17.375)', '\" C\"[356] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     clean_prediction=['\" E\"[469] (p=0.758, logit=22.375)', '\" An\"[1556] (p=0.103, logit=20.375)', '\" The\"[578] (p=0.062, logit=19.875)', '\" Among\"[22395] (p=0.020, logit=18.750)', '\" e\"[384] (p=0.018, logit=18.625)']\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     clean_track=OrderedDict([(469, (1, PredictedToken(token=' E', prob=0.7578125, logit=22.375, token_id=469, metadata=None))), (5340, (8, PredictedToken(token=' Har', prob=0.0030975341796875, logit=16.875, token_id=5340, metadata=None))), (65449, (60, PredictedToken(token=' Willow', prob=5.340576171875e-05, logit=12.8125, token_id=65449, metadata=None)))])\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     int_prediction=['\" Willow\"[65449] (p=0.844, logit=21.875)', '\" Among\"[22395] (p=0.078, logit=19.500)', '\" The\"[578] (p=0.025, logit=18.375)', '\" Option\"[7104] (p=0.011, logit=17.500)', '\" (\"[320] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     int_track=OrderedDict([(65449, (1, PredictedToken(token=' Willow', prob=0.84375, logit=21.875, token_id=65449, metadata=None))), (5340, (17, PredictedToken(token=' Har', prob=0.00081634521484375, logit=14.9375, token_id=5340, metadata=None))), (469, (34, PredictedToken(token=' E', prob=0.00023365020751953125, logit=13.6875, token_id=469, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:18 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:18 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:46:18 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.742, logit=22.625)', '\" The\"[578] (p=0.129, logit=20.875)', '\" Among\"[22395] (p=0.048, logit=19.875)', '\" A\"[362] (p=0.048, logit=19.875)', '\" dress\"[8679] (p=0.006, logit=17.750)']\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     clean_prediction=['\" Sheep\"[84008] (p=0.490, logit=20.500)', '\" The\"[578] (p=0.204, logit=19.625)', '\" A\"[362] (p=0.109, logit=19.000)', '\" Among\"[22395] (p=0.075, logit=18.625)', '\" sheep\"[33012] (p=0.017, logit=17.125)']\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     clean_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.490234375, logit=20.5, token_id=84008, metadata=None))), (37326, (59, PredictedToken(token=' Swe', prob=0.0001277923583984375, logit=12.25, token_id=37326, metadata=None))), (58586, (309, PredictedToken(token=' Tape', prob=5.632638931274414e-06, logit=9.125, token_id=58586, metadata=None))), (29318, (605, PredictedToken(token=' Dress', prob=1.8253922462463379e-06, logit=8.0, token_id=29318, metadata=None)))])\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.504, logit=20.500)', '\" The\"[578] (p=0.128, logit=19.125)', '\" A\"[362] (p=0.100, logit=18.875)', '\" Dress\"[29318] (p=0.088, logit=18.750)', '\" Among\"[22395] (p=0.088, logit=18.750)']\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.50390625, logit=20.5, token_id=37326, metadata=None))), (29318, (5, PredictedToken(token=' Dress', prob=0.087890625, logit=18.75, token_id=29318, metadata=None))), (58586, (6, PredictedToken(token=' Tape', prob=0.0284423828125, logit=17.625, token_id=58586, metadata=None))), (84008, (38, PredictedToken(token=' Sheep', prob=0.0004329681396484375, logit=13.4375, token_id=84008, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:19 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:19 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:19 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.742, logit=22.000)', '\" The\"[578] (p=0.114, logit=20.125)', '\" A\"[362] (p=0.061, logit=19.500)', '\" Among\"[22395] (p=0.033, logit=18.875)', '\" cat\"[8415] (p=0.006, logit=17.250)']\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     clean_prediction=['\" Sax\"[68027] (p=0.660, logit=21.125)', '\" The\"[578] (p=0.188, logit=19.875)', '\" Among\"[22395] (p=0.042, logit=18.375)', '\" A\"[362] (p=0.042, logit=18.375)', '\" It\"[1102] (p=0.014, logit=17.250)']\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     clean_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.66015625, logit=21.125, token_id=68027, metadata=None))), (45805, (10, PredictedToken(token=' Cherry', prob=0.002227783203125, logit=15.4375, token_id=45805, metadata=None))), (34392, (300, PredictedToken(token=' Horse', prob=3.7997961044311523e-06, logit=9.0625, token_id=34392, metadata=None))), (82507, (913, PredictedToken(token=' Jeans', prob=6.593763828277588e-07, logit=7.3125, token_id=82507, metadata=None)))])\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.652, logit=21.250)', '\" The\"[578] (p=0.100, logit=19.375)', '\" Cherry\"[45805] (p=0.088, logit=19.250)', '\" Among\"[22395] (p=0.078, logit=19.125)', '\" Option\"[7104] (p=0.014, logit=17.375)']\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.65234375, logit=21.25, token_id=34392, metadata=None))), (45805, (3, PredictedToken(token=' Cherry', prob=0.08837890625, logit=19.25, token_id=45805, metadata=None))), (82507, (49, PredictedToken(token=' Jeans', prob=0.00013256072998046875, logit=12.75, token_id=82507, metadata=None))), (68027, (1091, PredictedToken(token=' Sax', prob=4.507601261138916e-07, logit=7.0625, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:20 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:20 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     patch_prediction=['\" Iris\"[66821] (p=0.793, logit=21.750)', '\" The\"[578] (p=0.083, logit=19.500)', '\" Among\"[22395] (p=0.057, logit=19.125)', '\" An\"[1556] (p=0.024, logit=18.250)', '\" It\"[1102] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:46:20 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     clean_prediction=['\" Clar\"[31181] (p=0.727, logit=22.000)', '\" The\"[578] (p=0.143, logit=20.375)', '\" A\"[362] (p=0.052, logit=19.375)', '\" Among\"[22395] (p=0.032, logit=18.875)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     clean_track=OrderedDict([(31181, (1, PredictedToken(token=' Clar', prob=0.7265625, logit=22.0, token_id=31181, metadata=None))), (16344, (34, PredictedToken(token=' Rose', prob=0.00024318695068359375, logit=14.0, token_id=16344, metadata=None))), (70306, (56, PredictedToken(token=' Brace', prob=7.43865966796875e-05, logit=12.8125, token_id=70306, metadata=None))), (16730, (490, PredictedToken(token=' Museum', prob=8.791685104370117e-07, logit=8.375, token_id=16730, metadata=None)))])\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     int_prediction=['\" Rose\"[16344] (p=0.742, logit=21.750)', '\" Among\"[22395] (p=0.089, logit=19.625)', '\" The\"[578] (p=0.061, logit=19.250)', '\" Museum\"[16730] (p=0.022, logit=18.250)', '\" Option\"[7104] (p=0.020, logit=18.125)']\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     int_track=OrderedDict([(16344, (1, PredictedToken(token=' Rose', prob=0.7421875, logit=21.75, token_id=16344, metadata=None))), (16730, (4, PredictedToken(token=' Museum', prob=0.0224609375, logit=18.25, token_id=16730, metadata=None))), (70306, (37, PredictedToken(token=' Brace', prob=0.00028228759765625, logit=13.875, token_id=70306, metadata=None))), (31181, (1125, PredictedToken(token=' Clar', prob=3.520399332046509e-07, logit=7.1875, token_id=31181, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:21 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:21 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     patch_prediction=['\" Jeans\"[82507] (p=0.859, logit=22.500)', '\" The\"[578] (p=0.062, logit=19.875)', '\" Among\"[22395] (p=0.043, logit=19.500)', '\" JE\"[71430] (p=0.011, logit=18.125)', '\" A\"[362] (p=0.004, logit=17.125)']\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     clean_prediction=['\" Project\"[5907] (p=0.816, logit=21.750)', '\" The\"[578] (p=0.067, logit=19.250)', '\" A\"[362] (p=0.041, logit=18.750)', '\" Among\"[22395] (p=0.032, logit=18.500)', '\" It\"[1102] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     clean_track=OrderedDict([(5907, (1, PredictedToken(token=' Project', prob=0.81640625, logit=21.75, token_id=5907, metadata=None))), (38571, (10, PredictedToken(token=' Theater', prob=0.0014801025390625, logit=15.4375, token_id=38571, metadata=None))), (60413, (37, PredictedToken(token=' Uk', prob=0.00024127960205078125, logit=13.625, token_id=60413, metadata=None))), (37326, (134, PredictedToken(token=' Swe', prob=1.6450881958007812e-05, logit=10.9375, token_id=37326, metadata=None))), (48665, (893, PredictedToken(token=' Raspberry', prob=4.675239324569702e-07, logit=7.375, token_id=48665, metadata=None))), (65329, (1379, PredictedToken(token=' Elm', prob=2.421438694000244e-07, logit=6.71875, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     int_prediction=['\" Swe\"[37326] (p=0.543, logit=19.625)', '\" The\"[578] (p=0.137, logit=18.250)', '\" Among\"[22395] (p=0.121, logit=18.125)', '\" Elm\"[65329] (p=0.057, logit=17.375)', '\" A\"[362] (p=0.021, logit=16.375)']\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     int_track=OrderedDict([(37326, (1, PredictedToken(token=' Swe', prob=0.54296875, logit=19.625, token_id=37326, metadata=None))), (65329, (4, PredictedToken(token=' Elm', prob=0.05712890625, logit=17.375, token_id=65329, metadata=None))), (48665, (6, PredictedToken(token=' Raspberry', prob=0.011962890625, logit=15.8125, token_id=48665, metadata=None))), (60413, (74, PredictedToken(token=' Uk', prob=0.0001811981201171875, logit=11.625, token_id=60413, metadata=None))), (5907, (176, PredictedToken(token=' Project', prob=2.6106834411621094e-05, logit=9.6875, token_id=5907, metadata=None))), (38571, (284, PredictedToken(token=' Theater', prob=1.233816146850586e-05, logit=8.9375, token_id=38571, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:21 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:21 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:46:21 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.812, logit=21.125)', '\" The\"[578] (p=0.066, logit=18.625)', '\" An\"[1556] (p=0.040, logit=18.125)', '\" Among\"[22395] (p=0.031, logit=17.875)', '\" (\"[320] (p=0.007, logit=16.375)']\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     clean_prediction=['\" Football\"[21424] (p=0.914, logit=21.750)', '\" The\"[578] (p=0.021, logit=18.000)', '\" Among\"[22395] (p=0.009, logit=17.125)', '\" A\"[362] (p=0.009, logit=17.125)', '\" None\"[2290] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     clean_track=OrderedDict([(21424, (1, PredictedToken(token=' Football', prob=0.9140625, logit=21.75, token_id=21424, metadata=None))), (1050, (6, PredictedToken(token=' Re', prob=0.004791259765625, logit=16.5, token_id=1050, metadata=None))), (24423, (10, PredictedToken(token=' Monitor', prob=0.00177001953125, logit=15.5, token_id=24423, metadata=None))), (30558, (12, PredictedToken(token=' Ki', prob=0.00146484375, logit=15.3125, token_id=30558, metadata=None))), (20918, (43, PredictedToken(token=' Magn', prob=0.00010585784912109375, logit=12.6875, token_id=20918, metadata=None)))])\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     int_prediction=['\" Re\"[1050] (p=0.247, logit=19.250)', '\" Magn\"[20918] (p=0.247, logit=19.250)', '\" None\"[2290] (p=0.170, logit=18.875)', '\" Monitor\"[24423] (p=0.150, logit=18.750)', '\" Among\"[22395] (p=0.062, logit=17.875)']\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     int_track=OrderedDict([(1050, (1, PredictedToken(token=' Re', prob=0.2470703125, logit=19.25, token_id=1050, metadata=None))), (20918, (2, PredictedToken(token=' Magn', prob=0.2470703125, logit=19.25, token_id=20918, metadata=None))), (24423, (4, PredictedToken(token=' Monitor', prob=0.150390625, logit=18.75, token_id=24423, metadata=None))), (21424, (16, PredictedToken(token=' Football', prob=0.00167083740234375, logit=14.25, token_id=21424, metadata=None))), (30558, (31, PredictedToken(token=' Ki', prob=0.00078582763671875, logit=13.5, token_id=30558, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:22 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:22 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:46:22 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     patch_prediction=['\" Dress\"[29318] (p=0.660, logit=21.875)', '\" The\"[578] (p=0.130, logit=20.250)', '\" A\"[362] (p=0.130, logit=20.250)', '\" Among\"[22395] (p=0.054, logit=19.375)', '\" \"[220] (p=0.003, logit=16.500)']\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     clean_prediction=['\" Sk\"[4923] (p=0.734, logit=21.375)', '\" The\"[578] (p=0.127, logit=19.625)', '\" Among\"[22395] (p=0.077, logit=19.125)', '\" Ski\"[61595] (p=0.012, logit=17.250)', '\" It\"[1102] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     clean_track=OrderedDict([(4923, (1, PredictedToken(token=' Sk', prob=0.734375, logit=21.375, token_id=4923, metadata=None))), (88088, (49, PredictedToken(token=' Birch', prob=0.0001583099365234375, logit=12.9375, token_id=88088, metadata=None))), (1901, (53, PredictedToken(token=' Z', prob=0.00011587142944335938, logit=12.625, token_id=1901, metadata=None))), (10164, (107, PredictedToken(token=' Water', prob=2.1457672119140625e-05, logit=10.9375, token_id=10164, metadata=None))), (6017, (205, PredictedToken(token=' Book', prob=6.556510925292969e-06, logit=9.75, token_id=6017, metadata=None))), (71264, (1622, PredictedToken(token=' Daisy', prob=2.4586915969848633e-07, logit=6.46875, token_id=71264, metadata=None)))])\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     int_prediction=['\" Book\"[6017] (p=0.707, logit=21.875)', '\" The\"[578] (p=0.123, logit=20.125)', '\" Among\"[22395] (p=0.051, logit=19.250)', '\" A\"[362] (p=0.040, logit=19.000)', '\" Z\"[1901] (p=0.031, logit=18.750)']\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     int_track=OrderedDict([(6017, (1, PredictedToken(token=' Book', prob=0.70703125, logit=21.875, token_id=6017, metadata=None))), (1901, (5, PredictedToken(token=' Z', prob=0.031005859375, logit=18.75, token_id=1901, metadata=None))), (88088, (7, PredictedToken(token=' Birch', prob=0.01007080078125, logit=17.625, token_id=88088, metadata=None))), (71264, (60, PredictedToken(token=' Daisy', prob=8.726119995117188e-05, logit=12.875, token_id=71264, metadata=None))), (10164, (75, PredictedToken(token=' Water', prob=4.673004150390625e-05, logit=12.25, token_id=10164, metadata=None))), (4923, (387, PredictedToken(token=' Sk', prob=1.3262033462524414e-06, logit=8.6875, token_id=4923, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:23 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:23 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     patch_prediction=['\" Peach\"[64695] (p=0.898, logit=22.500)', '\" The\"[578] (p=0.035, logit=19.250)', '\" Among\"[22395] (p=0.027, logit=19.000)', '\" A\"[362] (p=0.010, logit=18.000)', '\" Option\"[7104] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     clean_prediction=['\" R\"[432] (p=0.781, logit=21.500)', '\" The\"[578] (p=0.073, logit=19.125)', '\" A\"[362] (p=0.073, logit=19.125)', '\" Among\"[22395] (p=0.018, logit=17.750)', '\" (\"[320] (p=0.007, logit=16.750)']\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     clean_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.78125, logit=21.5, token_id=432, metadata=None))), (45805, (27, PredictedToken(token=' Cherry', prob=0.0004062652587890625, logit=13.9375, token_id=45805, metadata=None))), (96096, (281, PredictedToken(token=' Dolphin', prob=3.516674041748047e-06, logit=9.1875, token_id=96096, metadata=None)))])\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     int_prediction=['\" Cherry\"[45805] (p=0.840, logit=21.125)', '\" The\"[578] (p=0.047, logit=18.250)', '\" Dolphin\"[96096] (p=0.022, logit=17.500)', '\" Among\"[22395] (p=0.022, logit=17.500)', '\" (\"[320] (p=0.008, logit=16.500)']\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     int_track=OrderedDict([(45805, (1, PredictedToken(token=' Cherry', prob=0.83984375, logit=21.125, token_id=45805, metadata=None))), (96096, (4, PredictedToken(token=' Dolphin', prob=0.0224609375, logit=17.5, token_id=96096, metadata=None))), (432, (96, PredictedToken(token=' R', prob=3.361701965332031e-05, logit=11.0, token_id=432, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:23 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:23 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:46:23 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     patch_prediction=['\" Sco\"[50159] (p=0.637, logit=21.125)', '\" A\"[362] (p=0.143, logit=19.625)', '\" The\"[578] (p=0.126, logit=19.500)', '\" Among\"[22395] (p=0.046, logit=18.500)', '\" It\"[1102] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     clean_prediction=['\" Stadium\"[23462] (p=0.703, logit=21.000)', '\" A\"[362] (p=0.095, logit=19.000)', '\" The\"[578] (p=0.065, logit=18.625)', '\" Among\"[22395] (p=0.051, logit=18.375)', '\" None\"[2290] (p=0.027, logit=17.750)']\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     clean_track=OrderedDict([(23462, (1, PredictedToken(token=' Stadium', prob=0.703125, logit=21.0, token_id=23462, metadata=None))), (1630, (10, PredictedToken(token=' X', prob=0.0022430419921875, logit=15.25, token_id=1630, metadata=None))), (16488, (20, PredictedToken(token=' Bat', prob=0.00087738037109375, logit=14.3125, token_id=16488, metadata=None))), (34785, (22, PredictedToken(token=' Truck', prob=0.000823974609375, logit=14.25, token_id=34785, metadata=None))), (98028, (139, PredictedToken(token=' Bamboo', prob=2.193450927734375e-05, logit=10.625, token_id=98028, metadata=None))), (55870, (149, PredictedToken(token=' Jacket', prob=1.823902130126953e-05, logit=10.4375, token_id=55870, metadata=None)))])\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     int_prediction=['\" X\"[1630] (p=0.660, logit=20.750)', '\" None\"[2290] (p=0.147, logit=19.250)', '\" The\"[578] (p=0.054, logit=18.250)', '\" Among\"[22395] (p=0.037, logit=17.875)', '\" A\"[362] (p=0.020, logit=17.250)']\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     int_track=OrderedDict([(1630, (1, PredictedToken(token=' X', prob=0.66015625, logit=20.75, token_id=1630, metadata=None))), (16488, (6, PredictedToken(token=' Bat', prob=0.01373291015625, logit=16.875, token_id=16488, metadata=None))), (55870, (16, PredictedToken(token=' Jacket', prob=0.001739501953125, logit=14.8125, token_id=55870, metadata=None))), (98028, (18, PredictedToken(token=' Bamboo', prob=0.0015411376953125, logit=14.6875, token_id=98028, metadata=None))), (34785, (30, PredictedToken(token=' Truck', prob=0.000530242919921875, logit=13.625, token_id=34785, metadata=None))), (23462, (1020, PredictedToken(token=' Stadium', prob=8.23289155960083e-07, logit=7.15625, token_id=23462, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:24 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:24 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:46:24 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     patch_prediction=['\" Mushroom\"[91297] (p=0.695, logit=20.500)', '\" None\"[2290] (p=0.155, logit=19.000)', '\" There\"[2684] (p=0.031, logit=17.375)', '\" The\"[578] (p=0.031, logit=17.375)', '\" A\"[362] (p=0.021, logit=17.000)']\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     clean_prediction=['\" Pear\"[23910] (p=0.855, logit=21.875)', '\" Among\"[22395] (p=0.042, logit=18.875)', '\" The\"[578] (p=0.042, logit=18.875)', '\" A\"[362] (p=0.020, logit=18.125)', '\" pear\"[38790] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     clean_track=OrderedDict([(23910, (1, PredictedToken(token=' Pear', prob=0.85546875, logit=21.875, token_id=23910, metadata=None))), (356, (10, PredictedToken(token=' C', prob=0.00186920166015625, logit=15.75, token_id=356, metadata=None))), (36845, (18, PredictedToken(token=' Tiger', prob=0.0007781982421875, logit=14.875, token_id=36845, metadata=None))), (6690, (67, PredictedToken(token=' Air', prob=5.650520324707031e-05, logit=12.25, token_id=6690, metadata=None))), (3341, (78, PredictedToken(token=' Car', prob=4.38690185546875e-05, logit=12.0, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.785, logit=21.625)', '\" Among\"[22395] (p=0.057, logit=19.000)', '\" Tiger\"[36845] (p=0.044, logit=18.750)', '\" The\"[578] (p=0.039, logit=18.625)', '\" Air\"[6690] (p=0.018, logit=17.875)']\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.78515625, logit=21.625, token_id=356, metadata=None))), (36845, (3, PredictedToken(token=' Tiger', prob=0.044189453125, logit=18.75, token_id=36845, metadata=None))), (6690, (5, PredictedToken(token=' Air', prob=0.0184326171875, logit=17.875, token_id=6690, metadata=None))), (3341, (7, PredictedToken(token=' Car', prob=0.00677490234375, logit=16.875, token_id=3341, metadata=None))), (23910, (211, PredictedToken(token=' Pear', prob=6.16908073425293e-06, logit=9.875, token_id=23910, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:25 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:25 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     patch_prediction=['\" Jacket\"[55870] (p=0.918, logit=22.625)', '\" None\"[2290] (p=0.019, logit=18.750)', '\" The\"[578] (p=0.017, logit=18.625)', '\" Among\"[22395] (p=0.015, logit=18.500)', '\" A\"[362] (p=0.012, logit=18.250)']\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     clean_prediction=['\" Refriger\"[75258] (p=0.785, logit=21.375)', '\" The\"[578] (p=0.064, logit=18.875)', '\" Among\"[22395] (p=0.050, logit=18.625)', '\" A\"[362] (p=0.027, logit=18.000)', '\" F\"[435] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     clean_track=OrderedDict([(75258, (1, PredictedToken(token=' Refriger', prob=0.78515625, logit=21.375, token_id=75258, metadata=None))), (48471, (67, PredictedToken(token=' Shower', prob=9.059906005859375e-05, logit=12.3125, token_id=48471, metadata=None))), (30760, (119, PredictedToken(token=' Scar', prob=2.5987625122070312e-05, logit=11.0625, token_id=30760, metadata=None)))])\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     int_prediction=['\" Scar\"[30760] (p=0.625, logit=20.250)', '\" None\"[2290] (p=0.109, logit=18.500)', '\" The\"[578] (p=0.085, logit=18.250)', '\" Among\"[22395] (p=0.066, logit=18.000)', '\" A\"[362] (p=0.024, logit=17.000)']\n",
      "2025-09-16 09:46:25 src.selection.optimization INFO     int_track=OrderedDict([(30760, (1, PredictedToken(token=' Scar', prob=0.625, logit=20.25, token_id=30760, metadata=None))), (48471, (48, PredictedToken(token=' Shower', prob=0.0002880096435546875, logit=12.5625, token_id=48471, metadata=None))), (75258, (277, PredictedToken(token=' Refriger', prob=9.834766387939453e-06, logit=9.1875, token_id=75258, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:25 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:26 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     patch_prediction=['\" Pants\"[67553] (p=0.766, logit=21.500)', '\" Among\"[22395] (p=0.071, logit=19.125)', '\" The\"[578] (p=0.071, logit=19.125)', '\" Pant\"[54222] (p=0.018, logit=17.750)', '\" A\"[362] (p=0.014, logit=17.500)']\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.875, logit=22.750)', '\" The\"[578] (p=0.049, logit=19.875)', '\" Among\"[22395] (p=0.034, logit=19.500)', '\" A\"[362] (p=0.018, logit=18.875)', '\" (\"[320] (p=0.004, logit=17.250)']\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.875, logit=22.75, token_id=356, metadata=None))), (31181, (18, PredictedToken(token=' Clar', prob=0.00031280517578125, logit=14.8125, token_id=31181, metadata=None))), (33711, (102, PredictedToken(token=' Suit', prob=1.138448715209961e-05, logit=11.5, token_id=33711, metadata=None)))])\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     int_prediction=['\" Suit\"[33711] (p=0.707, logit=21.125)', '\" Clar\"[31181] (p=0.096, logit=19.125)', '\" The\"[578] (p=0.075, logit=18.875)', '\" Among\"[22395] (p=0.035, logit=18.125)', '\" A\"[362] (p=0.019, logit=17.500)']\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     int_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.70703125, logit=21.125, token_id=33711, metadata=None))), (31181, (2, PredictedToken(token=' Clar', prob=0.095703125, logit=19.125, token_id=31181, metadata=None))), (356, (8, PredictedToken(token=' C', prob=0.0037078857421875, logit=15.875, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:26 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:26 src.selection.optimization DEBUG    torch.Size([6, 31])\n",
      "2025-09-16 09:46:26 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.742, logit=22.250)', '\" A\"[362] (p=0.088, logit=20.125)', '\" The\"[578] (p=0.078, logit=20.000)', '\" Among\"[22395] (p=0.047, logit=19.500)', '\" It\"[1102] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     clean_prediction=['\" Table\"[6771] (p=0.844, logit=21.875)', '\" The\"[578] (p=0.048, logit=19.000)', '\" A\"[362] (p=0.033, logit=18.625)', '\" Among\"[22395] (p=0.022, logit=18.250)', '\" Monitor\"[24423] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     clean_track=OrderedDict([(6771, (1, PredictedToken(token=' Table', prob=0.84375, logit=21.875, token_id=6771, metadata=None))), (24423, (5, PredictedToken(token=' Monitor', prob=0.0093994140625, logit=17.375, token_id=24423, metadata=None))), (816, (33, PredictedToken(token=' Y', prob=0.0002498626708984375, logit=13.75, token_id=816, metadata=None))), (445, (36, PredictedToken(token=' L', prob=0.00022029876708984375, logit=13.625, token_id=445, metadata=None))), (40090, (39, PredictedToken(token=' Pressure', prob=0.00020694732666015625, logit=13.5625, token_id=40090, metadata=None))), (16344, (105, PredictedToken(token=' Rose', prob=2.47955322265625e-05, logit=11.4375, token_id=16344, metadata=None)))])\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     int_prediction=['\" Y\"[816] (p=0.447, logit=20.250)', '\" Pressure\"[40090] (p=0.307, logit=19.875)', '\" Among\"[22395] (p=0.068, logit=18.375)', '\" The\"[578] (p=0.053, logit=18.125)', '\" A\"[362] (p=0.032, logit=17.625)']\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     int_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.447265625, logit=20.25, token_id=816, metadata=None))), (40090, (2, PredictedToken(token=' Pressure', prob=0.306640625, logit=19.875, token_id=40090, metadata=None))), (445, (6, PredictedToken(token=' L', prob=0.0196533203125, logit=17.125, token_id=445, metadata=None))), (6771, (115, PredictedToken(token=' Table', prob=3.147125244140625e-05, logit=10.6875, token_id=6771, metadata=None))), (24423, (201, PredictedToken(token=' Monitor', prob=1.0848045349121094e-05, logit=9.625, token_id=24423, metadata=None))), (16344, (281, PredictedToken(token=' Rose', prob=5.453824996948242e-06, logit=8.9375, token_id=16344, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:27 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:27 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     patch_prediction=['\" C\"[356] (p=0.750, logit=22.000)', '\" The\"[578] (p=0.115, logit=20.125)', '\" A\"[362] (p=0.026, logit=18.625)', '\" Among\"[22395] (p=0.023, logit=18.500)', '\" c\"[272] (p=0.023, logit=18.500)']\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     clean_prediction=['\" Monitor\"[24423] (p=0.828, logit=20.500)', '\" The\"[578] (p=0.047, logit=17.625)', '\" Trump\"[3420] (p=0.025, logit=17.000)', '\" A\"[362] (p=0.022, logit=16.875)', '\" None\"[2290] (p=0.012, logit=16.250)']\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     clean_track=OrderedDict([(24423, (1, PredictedToken(token=' Monitor', prob=0.828125, logit=20.5, token_id=24423, metadata=None))), (3420, (3, PredictedToken(token=' Trump', prob=0.02490234375, logit=17.0, token_id=3420, metadata=None))), (48035, (26, PredictedToken(token=' Gir', prob=0.00058746337890625, logit=13.25, token_id=48035, metadata=None))), (32749, (30, PredictedToken(token=' Carn', prob=0.0004863739013671875, logit=13.0625, token_id=32749, metadata=None)))])\n",
      "2025-09-16 09:46:27 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     int_prediction=['\" Carn\"[32749] (p=0.867, logit=20.250)', '\" The\"[578] (p=0.034, logit=17.000)', '\" Trump\"[3420] (p=0.018, logit=16.375)', '\" None\"[2290] (p=0.016, logit=16.250)', '\" A\"[362] (p=0.011, logit=15.875)']\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     int_track=OrderedDict([(32749, (1, PredictedToken(token=' Carn', prob=0.8671875, logit=20.25, token_id=32749, metadata=None))), (3420, (3, PredictedToken(token=' Trump', prob=0.01806640625, logit=16.375, token_id=3420, metadata=None))), (24423, (27, PredictedToken(token=' Monitor', prob=0.00051116943359375, logit=12.8125, token_id=24423, metadata=None))), (48035, (33, PredictedToken(token=' Gir', prob=0.0003986358642578125, logit=12.5625, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:28 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:28 src.selection.optimization DEBUG    torch.Size([6, 28])\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.816, logit=21.500)', '\" The\"[578] (p=0.067, logit=19.000)', '\" Among\"[22395] (p=0.041, logit=18.500)', '\" A\"[362] (p=0.025, logit=18.000)', '\" strawberry\"[73700] (p=0.006, logit=16.625)']\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     clean_prediction=['\" Notebook\"[69755] (p=0.629, logit=20.125)', '\" The\"[578] (p=0.109, logit=18.375)', '\" A\"[362] (p=0.097, logit=18.250)', '\" Among\"[22395] (p=0.059, logit=17.750)', '\" Note\"[7181] (p=0.009, logit=15.875)']\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     clean_track=OrderedDict([(69755, (1, PredictedToken(token=' Notebook', prob=0.62890625, logit=20.125, token_id=69755, metadata=None))), (15883, (8, PredictedToken(token=' Spr', prob=0.00579833984375, logit=15.4375, token_id=15883, metadata=None))), (57915, (19, PredictedToken(token=' Ank', prob=0.0019989013671875, logit=14.375, token_id=57915, metadata=None))), (60413, (57, PredictedToken(token=' Uk', prob=0.00023937225341796875, logit=12.25, token_id=60413, metadata=None))), (328, (71, PredictedToken(token=' S', prob=0.00014495849609375, logit=11.75, token_id=328, metadata=None))), (8868, (82, PredictedToken(token=' Blue', prob=0.00011301040649414062, logit=11.5, token_id=8868, metadata=None)))])\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     int_prediction=['\" Blue\"[8868] (p=0.824, logit=21.125)', '\" The\"[578] (p=0.060, logit=18.500)', '\" Among\"[22395] (p=0.047, logit=18.250)', '\" blue\"[6437] (p=0.006, logit=16.125)', '\" Only\"[8442] (p=0.005, logit=16.000)']\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     int_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.82421875, logit=21.125, token_id=8868, metadata=None))), (15883, (9, PredictedToken(token=' Spr', prob=0.0035858154296875, logit=15.6875, token_id=15883, metadata=None))), (57915, (10, PredictedToken(token=' Ank', prob=0.0033721923828125, logit=15.625, token_id=57915, metadata=None))), (328, (77, PredictedToken(token=' S', prob=7.009506225585938e-05, logit=11.75, token_id=328, metadata=None))), (60413, (85, PredictedToken(token=' Uk', prob=6.580352783203125e-05, logit=11.6875, token_id=60413, metadata=None))), (69755, (532, PredictedToken(token=' Notebook', prob=1.9818544387817383e-06, logit=8.1875, token_id=69755, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:28 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:28 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:46:28 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     patch_prediction=['\" Hat\"[22050] (p=0.652, logit=21.125)', '\" The\"[578] (p=0.128, logit=19.500)', '\" A\"[362] (p=0.088, logit=19.125)', '\" Among\"[22395] (p=0.047, logit=18.500)', '\" It\"[1102] (p=0.012, logit=17.125)']\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.891, logit=22.250)', '\" The\"[578] (p=0.044, logit=19.250)', '\" Among\"[22395] (p=0.031, logit=18.875)', '\" It\"[1102] (p=0.005, logit=17.125)', '\" A\"[362] (p=0.002, logit=16.250)']\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.890625, logit=22.25, token_id=72683, metadata=None))), (3341, (8, PredictedToken(token=' Car', prob=0.00142669677734375, logit=15.8125, token_id=3341, metadata=None))), (33711, (54, PredictedToken(token=' Suit', prob=8.58306884765625e-05, logit=13.0, token_id=33711, metadata=None))), (86460, (134, PredictedToken(token=' Necklace', prob=1.0251998901367188e-05, logit=10.875, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.494, logit=21.125)', '\" Suit\"[33711] (p=0.233, logit=20.375)', '\" A\"[362] (p=0.110, logit=19.625)', '\" The\"[578] (p=0.076, logit=19.250)', '\" Necklace\"[86460] (p=0.019, logit=17.875)']\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.494140625, logit=21.125, token_id=3341, metadata=None))), (33711, (2, PredictedToken(token=' Suit', prob=0.2333984375, logit=20.375, token_id=33711, metadata=None))), (86460, (5, PredictedToken(token=' Necklace', prob=0.0191650390625, logit=17.875, token_id=86460, metadata=None))), (72683, (85, PredictedToken(token=' Boxing', prob=4.744529724121094e-05, logit=11.875, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:29 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:29 src.selection.optimization DEBUG    torch.Size([6, 30])\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     patch_prediction=['\" Palm\"[33578] (p=0.582, logit=20.125)', '\" None\"[2290] (p=0.242, logit=19.250)', '\" Mushroom\"[91297] (p=0.037, logit=17.375)', '\" There\"[2684] (p=0.033, logit=17.250)', '\" A\"[362] (p=0.029, logit=17.125)']\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     clean_prediction=['\" Toilet\"[82994] (p=0.828, logit=21.125)', '\" The\"[578] (p=0.060, logit=18.500)', '\" Among\"[22395] (p=0.041, logit=18.125)', '\" Sub\"[3804] (p=0.008, logit=16.500)', '\" A\"[362] (p=0.006, logit=16.250)']\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     clean_track=OrderedDict([(82994, (1, PredictedToken(token=' Toilet', prob=0.828125, logit=21.125, token_id=82994, metadata=None))), (3804, (4, PredictedToken(token=' Sub', prob=0.00811767578125, logit=16.5, token_id=3804, metadata=None))), (6914, (11, PredictedToken(token=' Let', prob=0.0021820068359375, logit=15.1875, token_id=6914, metadata=None))), (27738, (19, PredictedToken(token=' Ward', prob=0.00090789794921875, logit=14.3125, token_id=27738, metadata=None))), (45805, (116, PredictedToken(token=' Cherry', prob=3.743171691894531e-05, logit=11.125, token_id=45805, metadata=None))), (65329, (367, PredictedToken(token=' Elm', prob=4.202127456665039e-06, logit=8.9375, token_id=65329, metadata=None)))])\n",
      "2025-09-16 09:46:29 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     int_prediction=['\" Elm\"[65329] (p=0.840, logit=21.375)', '\" The\"[578] (p=0.061, logit=18.750)', '\" Among\"[22395] (p=0.025, logit=17.875)', '\" Let\"[6914] (p=0.014, logit=17.250)', '\" Cherry\"[45805] (p=0.009, logit=16.875)']\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     int_track=OrderedDict([(65329, (1, PredictedToken(token=' Elm', prob=0.83984375, logit=21.375, token_id=65329, metadata=None))), (6914, (4, PredictedToken(token=' Let', prob=0.0135498046875, logit=17.25, token_id=6914, metadata=None))), (45805, (5, PredictedToken(token=' Cherry', prob=0.00933837890625, logit=16.875, token_id=45805, metadata=None))), (27738, (37, PredictedToken(token=' Ward', prob=0.0002651214599609375, logit=13.3125, token_id=27738, metadata=None))), (3804, (101, PredictedToken(token=' Sub', prob=4.0531158447265625e-05, logit=11.4375, token_id=3804, metadata=None))), (82994, (3161, PredictedToken(token=' Toilet', prob=1.7601996660232544e-07, logit=6.0, token_id=82994, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:30 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:30 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     patch_prediction=['\" Cherry\"[45805] (p=0.848, logit=21.625)', '\" Among\"[22395] (p=0.048, logit=18.750)', '\" The\"[578] (p=0.048, logit=18.750)', '\" A\"[362] (p=0.012, logit=17.375)', '\" Option\"[7104] (p=0.004, logit=16.250)']\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     clean_prediction=['\" Sax\"[68027] (p=0.641, logit=21.250)', '\" The\"[578] (p=0.208, logit=20.125)', '\" Among\"[22395] (p=0.052, logit=18.750)', '\" A\"[362] (p=0.046, logit=18.625)', '\" It\"[1102] (p=0.013, logit=17.375)']\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     clean_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.640625, logit=21.25, token_id=68027, metadata=None))), (800, (51, PredictedToken(token=' St', prob=8.916854858398438e-05, logit=12.375, token_id=800, metadata=None))), (30558, (169, PredictedToken(token=' Ki', prob=9.417533874511719e-06, logit=10.125, token_id=30558, metadata=None))), (16183, (174, PredictedToken(token=' Hel', prob=8.881092071533203e-06, logit=10.0625, token_id=16183, metadata=None)))])\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     int_prediction=['\" Ki\"[30558] (p=0.871, logit=22.625)', '\" The\"[578] (p=0.056, logit=19.875)', '\" Among\"[22395] (p=0.034, logit=19.375)', '\" A\"[362] (p=0.008, logit=17.875)', '\" It\"[1102] (p=0.006, logit=17.625)']\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     int_track=OrderedDict([(30558, (1, PredictedToken(token=' Ki', prob=0.87109375, logit=22.625, token_id=30558, metadata=None))), (16183, (7, PredictedToken(token=' Hel', prob=0.002777099609375, logit=16.875, token_id=16183, metadata=None))), (800, (78, PredictedToken(token=' St', prob=1.5497207641601562e-05, logit=11.6875, token_id=800, metadata=None))), (68027, (123, PredictedToken(token=' Sax', prob=6.884336471557617e-06, logit=10.875, token_id=68027, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:30 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:30 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:46:30 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     patch_prediction=['\" Paper\"[18343] (p=0.902, logit=21.500)', '\" paper\"[5684] (p=0.021, logit=17.750)', '\" The\"[578] (p=0.021, logit=17.750)', '\" A\"[362] (p=0.009, logit=16.875)', '\" Among\"[22395] (p=0.008, logit=16.750)']\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     clean_prediction=['\" Violet\"[74574] (p=0.953, logit=22.500)', '\" The\"[578] (p=0.009, logit=17.875)', '\" violet\"[80836] (p=0.008, logit=17.750)', '\" (\"[320] (p=0.006, logit=17.500)', '\" Among\"[22395] (p=0.006, logit=17.375)']\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     clean_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.953125, logit=22.5, token_id=74574, metadata=None))), (432, (9, PredictedToken(token=' R', prob=0.00125885009765625, logit=15.875, token_id=432, metadata=None))), (17367, (157, PredictedToken(token=' Factory', prob=4.26173210144043e-06, logit=10.1875, token_id=17367, metadata=None)))])\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     int_prediction=['\" R\"[432] (p=0.773, logit=20.500)', '\" Violet\"[74574] (p=0.063, logit=18.000)', '\" The\"[578] (p=0.034, logit=17.375)', '\" Option\"[7104] (p=0.030, logit=17.250)', '\" (\"[320] (p=0.018, logit=16.750)']\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     int_track=OrderedDict([(432, (1, PredictedToken(token=' R', prob=0.7734375, logit=20.5, token_id=432, metadata=None))), (74574, (2, PredictedToken(token=' Violet', prob=0.0634765625, logit=18.0, token_id=74574, metadata=None))), (17367, (9, PredictedToken(token=' Factory', prob=0.0033721923828125, logit=15.0625, token_id=17367, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:31 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:31 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     patch_prediction=['\" Tomato\"[94091] (p=0.730, logit=21.000)', '\" None\"[2290] (p=0.127, logit=19.250)', '\" The\"[578] (p=0.047, logit=18.250)', '\" A\"[362] (p=0.022, logit=17.500)', '\" There\"[2684] (p=0.017, logit=17.250)']\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     clean_prediction=['\" Tr\"[1183] (p=0.727, logit=22.375)', '\" The\"[578] (p=0.127, logit=20.625)', '\" A\"[362] (p=0.077, logit=20.125)', '\" Among\"[22395] (p=0.028, logit=19.125)', '\" It\"[1102] (p=0.009, logit=18.000)']\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     clean_track=OrderedDict([(1183, (1, PredictedToken(token=' Tr', prob=0.7265625, logit=22.375, token_id=1183, metadata=None))), (356, (16, PredictedToken(token=' C', prob=0.000751495361328125, logit=15.5, token_id=356, metadata=None))), (47759, (190, PredictedToken(token=' Guitar', prob=3.7103891372680664e-06, logit=10.1875, token_id=47759, metadata=None))), (61731, (314, PredictedToken(token=' Soap', prob=1.2814998626708984e-06, logit=9.125, token_id=61731, metadata=None)))])\n",
      "2025-09-16 09:46:31 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     int_prediction=['\" C\"[356] (p=0.828, logit=22.750)', '\" The\"[578] (p=0.077, logit=20.375)', '\" Among\"[22395] (p=0.032, logit=19.500)', '\" Soap\"[61731] (p=0.025, logit=19.250)', '\" A\"[362] (p=0.009, logit=18.250)']\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     int_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.828125, logit=22.75, token_id=356, metadata=None))), (61731, (4, PredictedToken(token=' Soap', prob=0.0250244140625, logit=19.25, token_id=61731, metadata=None))), (1183, (60, PredictedToken(token=' Tr', prob=4.00543212890625e-05, logit=12.8125, token_id=1183, metadata=None))), (47759, (142, PredictedToken(token=' Guitar', prob=5.751848220825195e-06, logit=10.875, token_id=47759, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:32 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:32 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     patch_prediction=['\" Y\"[816] (p=0.828, logit=21.375)', '\" A\"[362] (p=0.047, logit=18.500)', '\" The\"[578] (p=0.041, logit=18.375)', '\" Among\"[22395] (p=0.022, logit=17.750)', '\" None\"[2290] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     clean_prediction=['\" Let\"[6914] (p=0.812, logit=21.875)', '\" The\"[578] (p=0.097, logit=19.750)', '\" Among\"[22395] (p=0.046, logit=19.000)', '\" A\"[362] (p=0.012, logit=17.625)', '\" It\"[1102] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     clean_track=OrderedDict([(6914, (1, PredictedToken(token=' Let', prob=0.8125, logit=21.875, token_id=6914, metadata=None))), (6031, (12, PredictedToken(token=' Bro', prob=0.00107574462890625, logit=15.25, token_id=6031, metadata=None))), (20423, (40, PredictedToken(token=' Amb', prob=0.00014591217041015625, logit=13.25, token_id=20423, metadata=None))), (13120, (93, PredictedToken(token=' Night', prob=2.5272369384765625e-05, logit=11.5, token_id=13120, metadata=None))), (32498, (1196, PredictedToken(token=' Mall', prob=3.0919909477233887e-07, logit=7.09375, token_id=32498, metadata=None)))])\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     int_prediction=['\" Amb\"[20423] (p=0.719, logit=21.625)', '\" An\"[1556] (p=0.097, logit=19.625)', '\" The\"[578] (p=0.076, logit=19.375)', '\" Among\"[22395] (p=0.067, logit=19.250)', '\" It\"[1102] (p=0.005, logit=16.750)']\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     int_track=OrderedDict([(20423, (1, PredictedToken(token=' Amb', prob=0.71875, logit=21.625, token_id=20423, metadata=None))), (32498, (6, PredictedToken(token=' Mall', prob=0.003326416015625, logit=16.25, token_id=32498, metadata=None))), (6914, (14, PredictedToken(token=' Let', prob=0.00107574462890625, logit=15.125, token_id=6914, metadata=None))), (6031, (20, PredictedToken(token=' Bro', prob=0.00074005126953125, logit=14.75, token_id=6031, metadata=None))), (13120, (47, PredictedToken(token=' Night', prob=0.00014591217041015625, logit=13.125, token_id=13120, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:32 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:32 src.selection.optimization DEBUG    torch.Size([6, 32])\n",
      "2025-09-16 09:46:32 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     patch_prediction=['\" Red\"[3816] (p=0.742, logit=21.875)', '\" The\"[578] (p=0.089, logit=19.750)', '\" Among\"[22395] (p=0.079, logit=19.625)', '\" A\"[362] (p=0.054, logit=19.250)', '\" \"\"[330] (p=0.003, logit=16.250)']\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     clean_prediction=['\" Mixer\"[72392] (p=0.621, logit=20.500)', '\" The\"[578] (p=0.107, logit=18.750)', '\" A\"[362] (p=0.107, logit=18.750)', '\" Among\"[22395] (p=0.074, logit=18.375)', '\" Option\"[7104] (p=0.015, logit=16.750)']\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     clean_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.62109375, logit=20.5, token_id=72392, metadata=None))), (14937, (29, PredictedToken(token=' Ash', prob=0.00077056884765625, logit=13.8125, token_id=14937, metadata=None))), (45332, (34, PredictedToken(token=' Boat', prob=0.00060272216796875, logit=13.5625, token_id=45332, metadata=None))), (36845, (56, PredictedToken(token=' Tiger', prob=0.0001621246337890625, logit=12.25, token_id=36845, metadata=None))), (61731, (108, PredictedToken(token=' Soap', prob=4.6253204345703125e-05, logit=11.0, token_id=61731, metadata=None))), (39794, (160, PredictedToken(token=' Desk', prob=2.0623207092285156e-05, logit=10.1875, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     int_prediction=['\" Boat\"[45332] (p=0.233, logit=19.250)', '\" Soap\"[61731] (p=0.182, logit=19.000)', '\" Among\"[22395] (p=0.161, logit=18.875)', '\" The\"[578] (p=0.142, logit=18.750)', '\" Tiger\"[36845] (p=0.098, logit=18.375)']\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     int_track=OrderedDict([(45332, (1, PredictedToken(token=' Boat', prob=0.2333984375, logit=19.25, token_id=45332, metadata=None))), (61731, (2, PredictedToken(token=' Soap', prob=0.181640625, logit=19.0, token_id=61731, metadata=None))), (36845, (5, PredictedToken(token=' Tiger', prob=0.09765625, logit=18.375, token_id=36845, metadata=None))), (39794, (6, PredictedToken(token=' Desk', prob=0.035888671875, logit=17.375, token_id=39794, metadata=None))), (14937, (9, PredictedToken(token=' Ash', prob=0.01165771484375, logit=16.25, token_id=14937, metadata=None))), (72392, (3307, PredictedToken(token=' Mixer', prob=2.421438694000244e-07, logit=5.46875, token_id=72392, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:33 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:33 src.selection.optimization DEBUG    torch.Size([3, 24])\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     patch_prediction=['\" Sk\"[4923] (p=0.750, logit=21.625)', '\" The\"[578] (p=0.115, logit=19.750)', '\" Among\"[22395] (p=0.048, logit=18.875)', '\" Ski\"[61595] (p=0.016, logit=17.750)', '\" It\"[1102] (p=0.012, logit=17.500)']\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.750, logit=22.000)', '\" A\"[362] (p=0.089, logit=19.875)', '\" The\"[578] (p=0.079, logit=19.750)', '\" Among\"[22395] (p=0.029, logit=18.750)', '\" Option\"[7104] (p=0.012, logit=17.875)']\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.75, logit=22.0, token_id=735, metadata=None))), (426, (15, PredictedToken(token=' B', prob=0.000934600830078125, logit=15.3125, token_id=426, metadata=None))), (28131, (326, PredictedToken(token=' Golf', prob=1.4081597328186035e-06, logit=8.8125, token_id=28131, metadata=None)))])\n",
      "2025-09-16 09:46:33 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     int_prediction=['\" Golf\"[28131] (p=0.758, logit=21.750)', '\" Among\"[22395] (p=0.062, logit=19.250)', '\" The\"[578] (p=0.062, logit=19.250)', '\" A\"[362] (p=0.038, logit=18.750)', '\" B\"[426] (p=0.020, logit=18.125)']\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     int_track=OrderedDict([(28131, (1, PredictedToken(token=' Golf', prob=0.7578125, logit=21.75, token_id=28131, metadata=None))), (426, (5, PredictedToken(token=' B', prob=0.0201416015625, logit=18.125, token_id=426, metadata=None))), (735, (24, PredictedToken(token=' K', prob=0.0006103515625, logit=14.625, token_id=735, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:34 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:34 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     patch_prediction=['\" Apple\"[8325] (p=0.883, logit=22.875)', '\" The\"[578] (p=0.039, logit=19.750)', '\" An\"[1556] (p=0.030, logit=19.500)', '\" Among\"[22395] (p=0.018, logit=19.000)', '\" (\"[320] (p=0.005, logit=17.625)']\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     clean_prediction=['\" Trump\"[3420] (p=0.914, logit=22.000)', '\" The\"[578] (p=0.028, logit=18.500)', '\" Orange\"[22725] (p=0.019, logit=18.125)', '\" None\"[2290] (p=0.005, logit=16.875)', '\"Trump\"[16509] (p=0.004, logit=16.625)']\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     clean_track=OrderedDict([(3420, (1, PredictedToken(token=' Trump', prob=0.9140625, logit=22.0, token_id=3420, metadata=None))), (22725, (3, PredictedToken(token=' Orange', prob=0.01904296875, logit=18.125, token_id=22725, metadata=None))), (356, (9, PredictedToken(token=' C', prob=0.00177001953125, logit=15.75, token_id=356, metadata=None)))])\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     int_prediction=['\" Orange\"[22725] (p=0.559, logit=20.500)', '\" C\"[356] (p=0.299, logit=19.875)', '\" None\"[2290] (p=0.041, logit=17.875)', '\" The\"[578] (p=0.028, logit=17.500)', '\" Trump\"[3420] (p=0.019, logit=17.125)']\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     int_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.55859375, logit=20.5, token_id=22725, metadata=None))), (356, (2, PredictedToken(token=' C', prob=0.298828125, logit=19.875, token_id=356, metadata=None))), (3420, (5, PredictedToken(token=' Trump', prob=0.01904296875, logit=17.125, token_id=3420, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:34 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:34 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:46:34 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     patch_prediction=['\" Ch\"[921] (p=0.805, logit=22.250)', '\" The\"[578] (p=0.096, logit=20.125)', '\" A\"[362] (p=0.040, logit=19.250)', '\" Among\"[22395] (p=0.027, logit=18.875)', '\" Option\"[7104] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.793, logit=22.000)', '\" The\"[578] (p=0.065, logit=19.500)', '\" A\"[362] (p=0.065, logit=19.500)', '\" Among\"[22395] (p=0.035, logit=18.875)', '\" Option\"[7104] (p=0.005, logit=16.875)']\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.79296875, logit=22.0, token_id=356, metadata=None))), (74574, (11, PredictedToken(token=' Violet', prob=0.0018463134765625, logit=15.9375, token_id=74574, metadata=None))), (91263, (15, PredictedToken(token=' Binder', prob=0.0009918212890625, logit=15.3125, token_id=91263, metadata=None))), (2057, (22, PredictedToken(token=' To', prob=0.000598907470703125, logit=14.8125, token_id=2057, metadata=None)))])\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     int_prediction=['\" Violet\"[74574] (p=0.922, logit=22.625)', '\" Among\"[22395] (p=0.031, logit=19.250)', '\" The\"[578] (p=0.025, logit=19.000)', '\" It\"[1102] (p=0.003, logit=16.875)', '\" (\"[320] (p=0.002, logit=16.625)']\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     int_track=OrderedDict([(74574, (1, PredictedToken(token=' Violet', prob=0.921875, logit=22.625, token_id=74574, metadata=None))), (2057, (11, PredictedToken(token=' To', prob=0.000614166259765625, logit=15.3125, token_id=2057, metadata=None))), (91263, (62, PredictedToken(token=' Binder', prob=3.266334533691406e-05, logit=12.375, token_id=91263, metadata=None))), (356, (83, PredictedToken(token=' C', prob=1.6450881958007812e-05, logit=11.6875, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:35 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:35 src.selection.optimization DEBUG    torch.Size([3, 26])\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     patch_prediction=['\" Sco\"[50159] (p=0.703, logit=21.500)', '\" A\"[362] (p=0.122, logit=19.750)', '\" The\"[578] (p=0.095, logit=19.500)', '\" Among\"[22395] (p=0.035, logit=18.500)', '\" (\"[320] (p=0.009, logit=17.125)']\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     clean_prediction=['\" B\"[426] (p=0.871, logit=22.375)', '\" b\"[293] (p=0.043, logit=19.375)', '\" The\"[578] (p=0.030, logit=19.000)', '\" A\"[362] (p=0.012, logit=18.125)', '\" Among\"[22395] (p=0.010, logit=17.875)']\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     clean_track=OrderedDict([(426, (1, PredictedToken(token=' B', prob=0.87109375, logit=22.375, token_id=426, metadata=None))), (18787, (10, PredictedToken(token=' Oak', prob=0.00148773193359375, logit=16.0, token_id=18787, metadata=None))), (3341, (30, PredictedToken(token=' Car', prob=0.0001773834228515625, logit=13.875, token_id=3341, metadata=None)))])\n",
      "2025-09-16 09:46:35 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     int_prediction=['\" Car\"[3341] (p=0.859, logit=22.000)', '\" The\"[578] (p=0.029, logit=18.625)', '\" Oak\"[18787] (p=0.026, logit=18.500)', '\" car\"[1841] (p=0.012, logit=17.750)', '\" (\"[320] (p=0.012, logit=17.750)']\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     int_track=OrderedDict([(3341, (1, PredictedToken(token=' Car', prob=0.859375, logit=22.0, token_id=3341, metadata=None))), (18787, (3, PredictedToken(token=' Oak', prob=0.0260009765625, logit=18.5, token_id=18787, metadata=None))), (426, (55, PredictedToken(token=' B', prob=6.437301635742188e-05, logit=12.5, token_id=426, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:36 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:36 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     patch_prediction=['\" Ward\"[27738] (p=0.762, logit=21.500)', '\" The\"[578] (p=0.071, logit=19.125)', '\" A\"[362] (p=0.071, logit=19.125)', '\" Among\"[22395] (p=0.033, logit=18.375)', '\" Binder\"[91263] (p=0.010, logit=17.125)']\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     clean_prediction=['\" Boxing\"[72683] (p=0.891, logit=21.625)', '\" The\"[578] (p=0.039, logit=18.500)', '\" Among\"[22395] (p=0.021, logit=17.875)', '\" Drum\"[46506] (p=0.005, logit=16.375)', '\" It\"[1102] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     clean_track=OrderedDict([(72683, (1, PredictedToken(token=' Boxing', prob=0.890625, logit=21.625, token_id=72683, metadata=None))), (46506, (5, PredictedToken(token=' Drum', prob=0.004669189453125, logit=16.375, token_id=46506, metadata=None))), (4923, (9, PredictedToken(token=' Sk', prob=0.002197265625, logit=15.625, token_id=4923, metadata=None))), (34046, (249, PredictedToken(token=' Cabinet', prob=5.125999450683594e-06, logit=9.5625, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     int_prediction=['\" Cabinet\"[34046] (p=0.875, logit=21.750)', '\" The\"[578] (p=0.034, logit=18.500)', '\" Sk\"[4923] (p=0.026, logit=18.250)', '\" Among\"[22395] (p=0.011, logit=17.375)', '\" A\"[362] (p=0.008, logit=17.000)']\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     int_track=OrderedDict([(34046, (1, PredictedToken(token=' Cabinet', prob=0.875, logit=21.75, token_id=34046, metadata=None))), (4923, (3, PredictedToken(token=' Sk', prob=0.0264892578125, logit=18.25, token_id=4923, metadata=None))), (46506, (11, PredictedToken(token=' Drum', prob=0.002044677734375, logit=15.6875, token_id=46506, metadata=None))), (72683, (108, PredictedToken(token=' Boxing', prob=1.8835067749023438e-05, logit=11.0, token_id=72683, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:36 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:36 src.selection.optimization DEBUG    torch.Size([3, 22])\n",
      "2025-09-16 09:46:36 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     patch_prediction=['\" Football\"[21424] (p=0.938, logit=22.250)', '\" The\"[578] (p=0.020, logit=18.375)', '\" Among\"[22395] (p=0.006, logit=17.250)', '\" football\"[9141] (p=0.005, logit=17.000)', '\" Option\"[7104] (p=0.004, logit=16.875)']\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     clean_prediction=['\" Bro\"[6031] (p=0.812, logit=22.875)', '\" A\"[362] (p=0.076, logit=20.500)', '\" The\"[578] (p=0.067, logit=20.375)', '\" Among\"[22395] (p=0.022, logit=19.250)', '\" It\"[1102] (p=0.003, logit=17.375)']\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     clean_track=OrderedDict([(6031, (1, PredictedToken(token=' Bro', prob=0.8125, logit=22.875, token_id=6031, metadata=None))), (57094, (23, PredictedToken(token=' Highlight', prob=0.00019931793212890625, logit=14.5625, token_id=57094, metadata=None))), (97796, (149, PredictedToken(token=' Skate', prob=3.904104232788086e-06, logit=10.625, token_id=97796, metadata=None)))])\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     int_prediction=['\" Skate\"[97796] (p=0.688, logit=21.750)', '\" Highlight\"[57094] (p=0.120, logit=20.000)', '\" The\"[578] (p=0.064, logit=19.375)', '\" A\"[362] (p=0.057, logit=19.250)', '\" Among\"[22395] (p=0.039, logit=18.875)']\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     int_track=OrderedDict([(97796, (1, PredictedToken(token=' Skate', prob=0.6875, logit=21.75, token_id=97796, metadata=None))), (57094, (2, PredictedToken(token=' Highlight', prob=0.11962890625, logit=20.0, token_id=57094, metadata=None))), (6031, (34, PredictedToken(token=' Bro', prob=0.00016880035400390625, logit=13.4375, token_id=6031, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:37 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:37 src.selection.optimization DEBUG    torch.Size([4, 24])\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     patch_prediction=['\" Stadium\"[23462] (p=0.684, logit=20.250)', '\" The\"[578] (p=0.092, logit=18.250)', '\" Among\"[22395] (p=0.049, logit=17.625)', '\" Oak\"[18787] (p=0.044, logit=17.500)', '\" None\"[2290] (p=0.021, logit=16.750)']\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     clean_prediction=['\" Pine\"[42609] (p=0.770, logit=21.500)', '\" The\"[578] (p=0.071, logit=19.125)', '\" A\"[362] (p=0.063, logit=19.000)', '\" Among\"[22395] (p=0.049, logit=18.750)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     clean_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.76953125, logit=21.5, token_id=42609, metadata=None))), (87035, (43, PredictedToken(token=' Onion', prob=0.00013828277587890625, logit=12.875, token_id=87035, metadata=None))), (15429, (80, PredictedToken(token=' Hospital', prob=3.719329833984375e-05, logit=11.5625, token_id=15429, metadata=None))), (27171, (113, PredictedToken(token=' Coffee', prob=1.8715858459472656e-05, logit=10.875, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:46:37 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     int_prediction=['\" Hospital\"[15429] (p=0.840, logit=22.000)', '\" Among\"[22395] (p=0.061, logit=19.375)', '\" The\"[578] (p=0.032, logit=18.750)', '\" A\"[362] (p=0.017, logit=18.125)', '\" None\"[2290] (p=0.014, logit=17.875)']\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     int_track=OrderedDict([(15429, (1, PredictedToken(token=' Hospital', prob=0.83984375, logit=22.0, token_id=15429, metadata=None))), (27171, (16, PredictedToken(token=' Coffee', prob=0.000812530517578125, logit=15.0625, token_id=27171, metadata=None))), (42609, (115, PredictedToken(token=' Pine', prob=1.919269561767578e-05, logit=11.3125, token_id=42609, metadata=None))), (87035, (738, PredictedToken(token=' Onion', prob=7.413327693939209e-07, logit=8.0625, token_id=87035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:38 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:38 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     patch_prediction=['\" K\"[735] (p=0.738, logit=21.875)', '\" The\"[578] (p=0.088, logit=19.750)', '\" A\"[362] (p=0.088, logit=19.750)', '\" Among\"[22395] (p=0.047, logit=19.125)', '\" Option\"[7104] (p=0.006, logit=17.125)']\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     clean_prediction=['\" Bus\"[19111] (p=0.910, logit=21.875)', '\" The\"[578] (p=0.021, logit=18.125)', '\" A\"[362] (p=0.019, logit=18.000)', '\" None\"[2290] (p=0.013, logit=17.625)', '\" BUS\"[23504] (p=0.006, logit=16.875)']\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     clean_track=OrderedDict([(19111, (1, PredictedToken(token=' Bus', prob=0.91015625, logit=21.875, token_id=19111, metadata=None))), (72392, (8, PredictedToken(token=' Mixer', prob=0.0032806396484375, logit=16.25, token_id=72392, metadata=None))), (16730, (21, PredictedToken(token=' Museum', prob=0.000286102294921875, logit=13.8125, token_id=16730, metadata=None))), (48665, (52, PredictedToken(token=' Raspberry', prob=6.818771362304688e-05, logit=12.375, token_id=48665, metadata=None)))])\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     int_prediction=['\" Mixer\"[72392] (p=0.516, logit=19.250)', '\" Raspberry\"[48665] (p=0.148, logit=18.000)', '\" None\"[2290] (p=0.102, logit=17.625)', '\" The\"[578] (p=0.037, logit=16.625)', '\" A\"[362] (p=0.037, logit=16.625)']\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     int_track=OrderedDict([(72392, (1, PredictedToken(token=' Mixer', prob=0.515625, logit=19.25, token_id=72392, metadata=None))), (48665, (2, PredictedToken(token=' Raspberry', prob=0.1484375, logit=18.0, token_id=48665, metadata=None))), (19111, (6, PredictedToken(token=' Bus', prob=0.037353515625, logit=16.625, token_id=19111, metadata=None))), (16730, (1392, PredictedToken(token=' Museum', prob=1.9222497940063477e-06, logit=6.75, token_id=16730, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:38 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:38 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:46:38 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     patch_prediction=['\" Bat\"[16488] (p=0.863, logit=22.000)', '\" The\"[578] (p=0.049, logit=19.125)', '\" A\"[362] (p=0.038, logit=18.875)', '\" Among\"[22395] (p=0.012, logit=17.750)', '\" None\"[2290] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     clean_prediction=['\" Grape\"[80629] (p=0.777, logit=21.500)', '\" The\"[578] (p=0.082, logit=19.250)', '\" Among\"[22395] (p=0.056, logit=18.875)', '\" A\"[362] (p=0.039, logit=18.500)', '\" GRA\"[65120] (p=0.005, logit=16.500)']\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     clean_track=OrderedDict([(80629, (1, PredictedToken(token=' Grape', prob=0.77734375, logit=21.5, token_id=80629, metadata=None))), (34392, (43, PredictedToken(token=' Horse', prob=0.000179290771484375, logit=13.125, token_id=34392, metadata=None))), (445, (71, PredictedToken(token=' L', prob=4.839897155761719e-05, logit=11.8125, token_id=445, metadata=None))), (27171, (180, PredictedToken(token=' Coffee', prob=7.867813110351562e-06, logit=10.0, token_id=27171, metadata=None))), (67629, (301, PredictedToken(token=' Helmet', prob=3.084540367126465e-06, logit=9.0625, token_id=67629, metadata=None)))])\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     int_prediction=['\" Horse\"[34392] (p=0.719, logit=21.250)', '\" The\"[578] (p=0.125, logit=19.500)', '\" Among\"[22395] (p=0.052, logit=18.625)', '\" A\"[362] (p=0.041, logit=18.375)', '\" Helmet\"[67629] (p=0.015, logit=17.375)']\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     int_track=OrderedDict([(34392, (1, PredictedToken(token=' Horse', prob=0.71875, logit=21.25, token_id=34392, metadata=None))), (67629, (5, PredictedToken(token=' Helmet', prob=0.01495361328125, logit=17.375, token_id=67629, metadata=None))), (445, (57, PredictedToken(token=' L', prob=9.441375732421875e-05, logit=12.3125, token_id=445, metadata=None))), (27171, (189, PredictedToken(token=' Coffee', prob=8.285045623779297e-06, logit=9.875, token_id=27171, metadata=None))), (80629, (307, PredictedToken(token=' Grape', prob=3.6656856536865234e-06, logit=9.0625, token_id=80629, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:39 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:39 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     patch_prediction=['\" Shirt\"[55807] (p=0.770, logit=22.125)', '\" The\"[578] (p=0.092, logit=20.000)', '\" A\"[362] (p=0.063, logit=19.625)', '\" Among\"[22395] (p=0.038, logit=19.125)', '\" shirt\"[15845] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     clean_prediction=['\" D\"[423] (p=0.887, logit=23.750)', '\" The\"[578] (p=0.050, logit=20.875)', '\" Among\"[22395] (p=0.021, logit=20.000)', '\" A\"[362] (p=0.016, logit=19.750)', '\" d\"[294] (p=0.010, logit=19.250)']\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     clean_track=OrderedDict([(423, (1, PredictedToken(token=' D', prob=0.88671875, logit=23.75, token_id=423, metadata=None))), (70306, (42, PredictedToken(token=' Brace', prob=3.337860107421875e-05, logit=13.5625, token_id=70306, metadata=None))), (22050, (132, PredictedToken(token=' Hat', prob=2.130866050720215e-06, logit=10.8125, token_id=22050, metadata=None)))])\n",
      "2025-09-16 09:46:39 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     int_prediction=['\" Brace\"[70306] (p=0.797, logit=22.625)', '\" The\"[578] (p=0.074, logit=20.250)', '\" Among\"[22395] (p=0.035, logit=19.500)', '\" A\"[362] (p=0.031, logit=19.375)', '\" Hat\"[22050] (p=0.027, logit=19.250)']\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     int_track=OrderedDict([(70306, (1, PredictedToken(token=' Brace', prob=0.796875, logit=22.625, token_id=70306, metadata=None))), (22050, (5, PredictedToken(token=' Hat', prob=0.0272216796875, logit=19.25, token_id=22050, metadata=None))), (423, (14, PredictedToken(token=' D', prob=0.00077056884765625, logit=15.6875, token_id=423, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:40 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:40 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     patch_prediction=['\" Church\"[9441] (p=0.820, logit=21.500)', '\" The\"[578] (p=0.059, logit=18.875)', '\" Among\"[22395] (p=0.041, logit=18.500)', '\" A\"[362] (p=0.028, logit=18.125)', '\" It\"[1102] (p=0.008, logit=16.875)']\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     clean_prediction=['\" Gir\"[48035] (p=0.688, logit=21.125)', '\" The\"[578] (p=0.105, logit=19.250)', '\" A\"[362] (p=0.064, logit=18.750)', '\" Among\"[22395] (p=0.056, logit=18.625)', '\" Option\"[7104] (p=0.021, logit=17.625)']\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     clean_track=OrderedDict([(48035, (1, PredictedToken(token=' Gir', prob=0.6875, logit=21.125, token_id=48035, metadata=None))), (18343, (34, PredictedToken(token=' Paper', prob=0.00058746337890625, logit=14.0625, token_id=18343, metadata=None))), (20918, (46, PredictedToken(token=' Magn', prob=0.0002765655517578125, logit=13.3125, token_id=20918, metadata=None))), (23462, (254, PredictedToken(token=' Stadium', prob=6.139278411865234e-06, logit=9.5, token_id=23462, metadata=None)))])\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     int_prediction=['\" Among\"[22395] (p=0.268, logit=19.375)', '\" Stadium\"[23462] (p=0.268, logit=19.375)', '\" None\"[2290] (p=0.185, logit=19.000)', '\" Magn\"[20918] (p=0.099, logit=18.375)', '\" The\"[578] (p=0.053, logit=17.750)']\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     int_track=OrderedDict([(23462, (2, PredictedToken(token=' Stadium', prob=0.267578125, logit=19.375, token_id=23462, metadata=None))), (20918, (4, PredictedToken(token=' Magn', prob=0.0986328125, logit=18.375, token_id=20918, metadata=None))), (18343, (79, PredictedToken(token=' Paper', prob=0.00012302398681640625, logit=11.6875, token_id=18343, metadata=None))), (48035, (3520, PredictedToken(token=' Gir', prob=2.775341272354126e-07, logit=5.59375, token_id=48035, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:40 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:40 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:46:40 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     patch_prediction=['\" Gir\"[48035] (p=0.746, logit=21.875)', '\" The\"[578] (p=0.114, logit=20.000)', '\" A\"[362] (p=0.061, logit=19.375)', '\" Among\"[22395] (p=0.026, logit=18.500)', '\" (\"[320] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     clean_prediction=['\" Trom\"[94467] (p=0.508, logit=20.250)', '\" The\"[578] (p=0.271, logit=19.625)', '\" A\"[362] (p=0.078, logit=18.375)', '\" Among\"[22395] (p=0.061, logit=18.125)', '\" It\"[1102] (p=0.022, logit=17.125)']\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     clean_track=OrderedDict([(94467, (1, PredictedToken(token=' Trom', prob=0.5078125, logit=20.25, token_id=94467, metadata=None))), (49431, (203, PredictedToken(token=' Rabbit', prob=1.233816146850586e-05, logit=9.625, token_id=49431, metadata=None))), (27171, (462, PredictedToken(token=' Coffee', prob=3.3080577850341797e-06, logit=8.3125, token_id=27171, metadata=None)))])\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.562, logit=20.500)', '\" The\"[578] (p=0.183, logit=19.375)', '\" Among\"[22395] (p=0.126, logit=19.000)', '\" A\"[362] (p=0.025, logit=17.375)', '\" Option\"[7104] (p=0.019, logit=17.125)']\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.5625, logit=20.5, token_id=49431, metadata=None))), (94467, (17, PredictedToken(token=' Trom', prob=0.0019073486328125, logit=14.8125, token_id=94467, metadata=None))), (27171, (29, PredictedToken(token=' Coffee', prob=0.000659942626953125, logit=13.75, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:41 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:41 src.selection.optimization DEBUG    torch.Size([6, 29])\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     patch_prediction=['\" Cat\"[17810] (p=0.758, logit=21.625)', '\" The\"[578] (p=0.091, logit=19.500)', '\" A\"[362] (p=0.055, logit=19.000)', '\" Among\"[22395] (p=0.043, logit=18.750)', '\" CAT\"[45081] (p=0.007, logit=16.875)']\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     clean_prediction=['\" Pepper\"[52882] (p=0.918, logit=22.625)', '\" The\"[578] (p=0.036, logit=19.375)', '\" Among\"[22395] (p=0.022, logit=18.875)', '\" A\"[362] (p=0.004, logit=17.125)', '\" None\"[2290] (p=0.003, logit=16.750)']\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     clean_track=OrderedDict([(52882, (1, PredictedToken(token=' Pepper', prob=0.91796875, logit=22.625, token_id=52882, metadata=None))), (11452, (74, PredictedToken(token=' Head', prob=2.372264862060547e-05, logit=12.0625, token_id=11452, metadata=None))), (23462, (76, PredictedToken(token=' Stadium', prob=2.2292137145996094e-05, logit=12.0, token_id=23462, metadata=None))), (13000, (108, PredictedToken(token=' Van', prob=9.894371032714844e-06, logit=11.1875, token_id=13000, metadata=None))), (49431, (126, PredictedToken(token=' Rabbit', prob=7.68899917602539e-06, logit=10.9375, token_id=49431, metadata=None))), (47759, (1943, PredictedToken(token=' Guitar', prob=1.0663643479347229e-07, logit=6.65625, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:46:41 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     int_prediction=['\" Rabbit\"[49431] (p=0.770, logit=21.000)', '\" The\"[578] (p=0.072, logit=18.625)', '\" None\"[2290] (p=0.049, logit=18.250)', '\" Among\"[22395] (p=0.030, logit=17.750)', '\" A\"[362] (p=0.023, logit=17.500)']\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     int_track=OrderedDict([(49431, (1, PredictedToken(token=' Rabbit', prob=0.76953125, logit=21.0, token_id=49431, metadata=None))), (23462, (11, PredictedToken(token=' Stadium', prob=0.00179290771484375, logit=14.9375, token_id=23462, metadata=None))), (11452, (29, PredictedToken(token=' Head', prob=0.0004825592041015625, logit=13.625, token_id=11452, metadata=None))), (47759, (34, PredictedToken(token=' Guitar', prob=0.0003757476806640625, logit=13.375, token_id=47759, metadata=None))), (13000, (140, PredictedToken(token=' Van', prob=2.4080276489257812e-05, logit=10.625, token_id=13000, metadata=None))), (52882, (344, PredictedToken(token=' Pepper', prob=5.364418029785156e-06, logit=9.125, token_id=52882, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:42 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:42 src.selection.optimization DEBUG    torch.Size([4, 29])\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     patch_prediction=['\" Scar\"[30760] (p=0.523, logit=21.000)', '\" The\"[578] (p=0.149, logit=19.750)', '\" A\"[362] (p=0.132, logit=19.625)', '\" Among\"[22395] (p=0.117, logit=19.500)', '\" scarf\"[68371] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     clean_prediction=['\" Birch\"[88088] (p=0.684, logit=20.875)', '\" Among\"[22395] (p=0.135, logit=19.250)', '\" The\"[578] (p=0.092, logit=18.875)', '\" Option\"[7104] (p=0.013, logit=16.875)', '\" It\"[1102] (p=0.013, logit=16.875)']\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     clean_track=OrderedDict([(88088, (1, PredictedToken(token=' Birch', prob=0.68359375, logit=20.875, token_id=88088, metadata=None))), (90538, (12, PredictedToken(token=' Caul', prob=0.00262451171875, logit=15.3125, token_id=90538, metadata=None))), (11896, (75, PredictedToken(token=' Library', prob=6.961822509765625e-05, logit=11.6875, token_id=11896, metadata=None))), (55807, (419, PredictedToken(token=' Shirt', prob=3.069639205932617e-06, logit=8.5625, token_id=55807, metadata=None)))])\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.754, logit=21.375)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" The\"[578] (p=0.048, logit=18.625)', '\" None\"[2290] (p=0.042, logit=18.500)', '\" Caul\"[90538] (p=0.033, logit=18.250)']\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.75390625, logit=21.375, token_id=55807, metadata=None))), (90538, (5, PredictedToken(token=' Caul', prob=0.033203125, logit=18.25, token_id=90538, metadata=None))), (11896, (330, PredictedToken(token=' Library', prob=3.382563591003418e-06, logit=9.0625, token_id=11896, metadata=None))), (88088, (635, PredictedToken(token=' Birch', prob=1.2442469596862793e-06, logit=8.0625, token_id=88088, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:42 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:42 src.selection.optimization DEBUG    torch.Size([5, 25])\n",
      "2025-09-16 09:46:42 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     patch_prediction=['\" Boat\"[45332] (p=0.832, logit=22.375)', '\" A\"[362] (p=0.060, logit=19.750)', '\" The\"[578] (p=0.053, logit=19.625)', '\" Among\"[22395] (p=0.020, logit=18.625)', '\" It\"[1102] (p=0.008, logit=17.750)']\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     clean_prediction=['\" Head\"[11452] (p=0.734, logit=21.250)', '\" The\"[578] (p=0.128, logit=19.500)', '\" Among\"[22395] (p=0.061, logit=18.750)', '\" headphones\"[44101] (p=0.007, logit=16.625)', '\" It\"[1102] (p=0.006, logit=16.500)']\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     clean_track=OrderedDict([(11452, (1, PredictedToken(token=' Head', prob=0.734375, logit=21.25, token_id=11452, metadata=None))), (816, (21, PredictedToken(token=' Y', prob=0.00103759765625, logit=14.6875, token_id=816, metadata=None))), (34392, (29, PredictedToken(token=' Horse', prob=0.000713348388671875, logit=14.3125, token_id=34392, metadata=None))), (61731, (190, PredictedToken(token=' Soap', prob=1.1563301086425781e-05, logit=10.1875, token_id=61731, metadata=None))), (72683, (290, PredictedToken(token=' Boxing', prob=4.827976226806641e-06, logit=9.3125, token_id=72683, metadata=None)))])\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     int_prediction=['\" Y\"[816] (p=0.723, logit=21.750)', '\" A\"[362] (p=0.098, logit=19.750)', '\" The\"[578] (p=0.086, logit=19.625)', '\" Among\"[22395] (p=0.036, logit=18.750)', '\" It\"[1102] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     int_track=OrderedDict([(816, (1, PredictedToken(token=' Y', prob=0.72265625, logit=21.75, token_id=816, metadata=None))), (34392, (46, PredictedToken(token=' Horse', prob=0.00011491775512695312, logit=13.0, token_id=34392, metadata=None))), (61731, (56, PredictedToken(token=' Soap', prob=8.392333984375e-05, logit=12.6875, token_id=61731, metadata=None))), (72683, (229, PredictedToken(token=' Boxing', prob=3.933906555175781e-06, logit=9.625, token_id=72683, metadata=None))), (11452, (546, PredictedToken(token=' Head', prob=7.748603820800781e-07, logit=8.0, token_id=11452, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:43 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:43 src.selection.optimization DEBUG    torch.Size([3, 21])\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     patch_prediction=['\" Strawberry\"[89077] (p=0.789, logit=21.750)', '\" The\"[578] (p=0.083, logit=19.500)', '\" Among\"[22395] (p=0.044, logit=18.875)', '\" A\"[362] (p=0.027, logit=18.375)', '\" strawberry\"[73700] (p=0.016, logit=17.875)']\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     clean_prediction=['\" Chain\"[29625] (p=0.961, logit=23.000)', '\" The\"[578] (p=0.012, logit=18.625)', '\" chain\"[8957] (p=0.006, logit=18.000)', '\" A\"[362] (p=0.006, logit=17.875)', '\" Among\"[22395] (p=0.002, logit=16.875)']\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     clean_track=OrderedDict([(29625, (1, PredictedToken(token=' Chain', prob=0.9609375, logit=23.0, token_id=29625, metadata=None))), (42609, (16, PredictedToken(token=' Pine', prob=0.0003643035888671875, logit=15.125, token_id=42609, metadata=None))), (34046, (20, PredictedToken(token=' Cabinet', prob=0.0003032684326171875, logit=14.9375, token_id=34046, metadata=None)))])\n",
      "2025-09-16 09:46:43 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     int_prediction=['\" Pine\"[42609] (p=0.891, logit=21.500)', '\" The\"[578] (p=0.031, logit=18.125)', '\" Among\"[22395] (p=0.016, logit=17.500)', '\" None\"[2290] (p=0.013, logit=17.250)', '\" A\"[362] (p=0.005, logit=16.375)']\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     int_track=OrderedDict([(42609, (1, PredictedToken(token=' Pine', prob=0.890625, logit=21.5, token_id=42609, metadata=None))), (29625, (12, PredictedToken(token=' Chain', prob=0.0018310546875, logit=15.3125, token_id=29625, metadata=None))), (34046, (326, PredictedToken(token=' Cabinet', prob=4.827976226806641e-06, logit=9.375, token_id=34046, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:44 src.selection.optimization DEBUG    Sampling 6 patch samples...\n",
      "2025-09-16 09:46:44 src.selection.optimization DEBUG    torch.Size([6, 34])\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     patch_prediction=['\" Golf\"[28131] (p=0.734, logit=20.875)', '\" The\"[578] (p=0.077, logit=18.625)', '\" A\"[362] (p=0.060, logit=18.375)', '\" Among\"[22395] (p=0.028, logit=17.625)', '\" Option\"[7104] (p=0.022, logit=17.375)']\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     clean_prediction=['\" Razor\"[74968] (p=0.852, logit=21.125)', '\" A\"[362] (p=0.048, logit=18.250)', '\" The\"[578] (p=0.042, logit=18.125)', '\" Among\"[22395] (p=0.016, logit=17.125)', '\" R\"[432] (p=0.005, logit=16.000)']\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     clean_track=OrderedDict([(74968, (1, PredictedToken(token=' Razor', prob=0.8515625, logit=21.125, token_id=74968, metadata=None))), (328, (43, PredictedToken(token=' S', prob=0.00012683868408203125, logit=12.3125, token_id=328, metadata=None))), (87213, (72, PredictedToken(token=' Oven', prob=6.008148193359375e-05, logit=11.5625, token_id=87213, metadata=None))), (50159, (134, PredictedToken(token=' Sco', prob=1.9431114196777344e-05, logit=10.4375, token_id=50159, metadata=None))), (5250, (452, PredictedToken(token=' Pe', prob=2.3245811462402344e-06, logit=8.3125, token_id=5250, metadata=None))), (72683, (1429, PredictedToken(token=' Boxing', prob=5.699694156646729e-07, logit=6.90625, token_id=72683, metadata=None)))])\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     int_prediction=['\" Sco\"[50159] (p=0.365, logit=19.250)', '\" S\"[328] (p=0.285, logit=19.000)', '\" Among\"[22395] (p=0.092, logit=17.875)', '\" Boxing\"[72683] (p=0.063, logit=17.500)', '\" The\"[578] (p=0.063, logit=17.500)']\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     int_track=OrderedDict([(50159, (1, PredictedToken(token=' Sco', prob=0.365234375, logit=19.25, token_id=50159, metadata=None))), (328, (2, PredictedToken(token=' S', prob=0.28515625, logit=19.0, token_id=328, metadata=None))), (72683, (5, PredictedToken(token=' Boxing', prob=0.0634765625, logit=17.5, token_id=72683, metadata=None))), (5250, (6, PredictedToken(token=' Pe', prob=0.0264892578125, logit=16.625, token_id=5250, metadata=None))), (87213, (35, PredictedToken(token=' Oven', prob=0.000621795654296875, logit=12.875, token_id=87213, metadata=None))), (74968, (207, PredictedToken(token=' Razor', prob=2.2649765014648438e-05, logit=9.5625, token_id=74968, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:44 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:44 src.selection.optimization DEBUG    torch.Size([5, 30])\n",
      "2025-09-16 09:46:44 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     patch_prediction=['\" Uk\"[60413] (p=0.746, logit=22.000)', '\" The\"[578] (p=0.130, logit=20.250)', '\" Among\"[22395] (p=0.048, logit=19.250)', '\" A\"[362] (p=0.033, logit=18.875)', '\" It\"[1102] (p=0.008, logit=17.500)']\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     clean_prediction=['\" Spr\"[15883] (p=0.852, logit=22.375)', '\" The\"[578] (p=0.070, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=19.250)', '\" A\"[362] (p=0.011, logit=18.000)', '\" (\"[320] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     clean_track=OrderedDict([(15883, (1, PredictedToken(token=' Spr', prob=0.8515625, logit=22.375, token_id=15883, metadata=None))), (328, (20, PredictedToken(token=' S', prob=0.0004405975341796875, logit=14.8125, token_id=328, metadata=None))), (36895, (198, PredictedToken(token=' Eagle', prob=3.814697265625e-06, logit=10.0625, token_id=36895, metadata=None))), (30555, (213, PredictedToken(token=' Viol', prob=3.3676624298095703e-06, logit=9.9375, token_id=30555, metadata=None))), (6690, (262, PredictedToken(token=' Air', prob=2.473592758178711e-06, logit=9.625, token_id=6690, metadata=None)))])\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     int_prediction=['\" Viol\"[30555] (p=0.844, logit=22.375)', '\" The\"[578] (p=0.079, logit=20.000)', '\" Among\"[22395] (p=0.029, logit=19.000)', '\" Eagle\"[36895] (p=0.007, logit=17.625)', '\" (\"[320] (p=0.006, logit=17.500)']\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     int_track=OrderedDict([(30555, (1, PredictedToken(token=' Viol', prob=0.84375, logit=22.375, token_id=30555, metadata=None))), (36895, (4, PredictedToken(token=' Eagle', prob=0.007293701171875, logit=17.625, token_id=36895, metadata=None))), (6690, (12, PredictedToken(token=' Air', prob=0.00162506103515625, logit=16.125, token_id=6690, metadata=None))), (328, (94, PredictedToken(token=' S', prob=1.811981201171875e-05, logit=11.625, token_id=328, metadata=None))), (15883, (259, PredictedToken(token=' Spr', prob=2.294778823852539e-06, logit=9.5625, token_id=15883, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:45 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:45 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     patch_prediction=['\" Gloves\"[68554] (p=0.750, logit=21.375)', '\" The\"[578] (p=0.070, logit=19.000)', '\" Glo\"[25372] (p=0.054, logit=18.750)', '\" Among\"[22395] (p=0.048, logit=18.625)', '\" A\"[362] (p=0.033, logit=18.250)']\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     clean_prediction=['\" Ank\"[57915] (p=0.879, logit=21.625)', '\" Among\"[22395] (p=0.034, logit=18.375)', '\" An\"[1556] (p=0.026, logit=18.125)', '\" The\"[578] (p=0.021, logit=17.875)', '\" ank\"[71572] (p=0.009, logit=17.000)']\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     clean_track=OrderedDict([(57915, (1, PredictedToken(token=' Ank', prob=0.87890625, logit=21.625, token_id=57915, metadata=None))), (22050, (11, PredictedToken(token=' Hat', prob=0.001495361328125, logit=15.25, token_id=22050, metadata=None))), (88088, (32, PredictedToken(token=' Birch', prob=0.0002288818359375, logit=13.375, token_id=88088, metadata=None))), (84008, (71, PredictedToken(token=' Sheep', prob=6.151199340820312e-05, logit=12.0625, token_id=84008, metadata=None))), (82994, (75, PredictedToken(token=' Toilet', prob=5.435943603515625e-05, logit=11.9375, token_id=82994, metadata=None)))])\n",
      "2025-09-16 09:46:45 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     int_prediction=['\" Sheep\"[84008] (p=0.256, logit=19.000)', '\" Among\"[22395] (p=0.225, logit=18.875)', '\" The\"[578] (p=0.175, logit=18.625)', '\" Birch\"[88088] (p=0.106, logit=18.125)', '\" Hat\"[22050] (p=0.057, logit=17.500)']\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     int_track=OrderedDict([(84008, (1, PredictedToken(token=' Sheep', prob=0.255859375, logit=19.0, token_id=84008, metadata=None))), (88088, (4, PredictedToken(token=' Birch', prob=0.1064453125, logit=18.125, token_id=88088, metadata=None))), (22050, (5, PredictedToken(token=' Hat', prob=0.056884765625, logit=17.5, token_id=22050, metadata=None))), (82994, (111, PredictedToken(token=' Toilet', prob=0.000102996826171875, logit=11.1875, token_id=82994, metadata=None))), (57915, (738, PredictedToken(token=' Ank', prob=3.427267074584961e-06, logit=7.78125, token_id=57915, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:46 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:46 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     patch_prediction=['\" Tablet\"[58403] (p=0.377, logit=19.750)', '\" The\"[578] (p=0.201, logit=19.125)', '\" Food\"[12369] (p=0.108, logit=18.500)', '\" Among\"[22395] (p=0.095, logit=18.375)', '\" A\"[362] (p=0.058, logit=17.875)']\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     clean_prediction=['\" Blue\"[8868] (p=0.715, logit=21.750)', '\" The\"[578] (p=0.141, logit=20.125)', '\" Among\"[22395] (p=0.059, logit=19.250)', '\" A\"[362] (p=0.046, logit=19.000)', '\" It\"[1102] (p=0.006, logit=17.000)']\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     clean_track=OrderedDict([(8868, (1, PredictedToken(token=' Blue', prob=0.71484375, logit=21.75, token_id=8868, metadata=None))), (55807, (99, PredictedToken(token=' Shirt', prob=2.2292137145996094e-05, logit=11.375, token_id=55807, metadata=None))), (58937, (261, PredictedToken(token=' Monkey', prob=3.635883331298828e-06, logit=9.5625, token_id=58937, metadata=None))), (14669, (458, PredictedToken(token=' Camera', prob=1.259148120880127e-06, logit=8.5, token_id=14669, metadata=None))), (47759, (1170, PredictedToken(token=' Guitar', prob=3.594905138015747e-07, logit=7.25, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     int_prediction=['\" Shirt\"[55807] (p=0.412, logit=20.625)', '\" The\"[578] (p=0.194, logit=19.875)', '\" Camera\"[14669] (p=0.172, logit=19.750)', '\" Among\"[22395] (p=0.081, logit=19.000)', '\" A\"[362] (p=0.043, logit=18.375)']\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     int_track=OrderedDict([(55807, (1, PredictedToken(token=' Shirt', prob=0.412109375, logit=20.625, token_id=55807, metadata=None))), (14669, (3, PredictedToken(token=' Camera', prob=0.171875, logit=19.75, token_id=14669, metadata=None))), (47759, (12, PredictedToken(token=' Guitar', prob=0.0033416748046875, logit=15.8125, token_id=47759, metadata=None))), (58937, (658, PredictedToken(token=' Monkey', prob=1.5348196029663086e-06, logit=8.125, token_id=58937, metadata=None))), (8868, (1454, PredictedToken(token=' Blue', prob=5.289912223815918e-07, logit=7.0625, token_id=8868, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:46 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:46 src.selection.optimization DEBUG    torch.Size([4, 25])\n",
      "2025-09-16 09:46:46 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     patch_prediction=['\" Micro\"[18654] (p=0.805, logit=21.625)', '\" The\"[578] (p=0.075, logit=19.250)', '\" A\"[362] (p=0.031, logit=18.375)', '\" Among\"[22395] (p=0.028, logit=18.250)', '\" It\"[1102] (p=0.010, logit=17.250)']\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     clean_prediction=['\" Hel\"[16183] (p=0.797, logit=21.875)', '\" The\"[578] (p=0.051, logit=19.125)', '\" A\"[362] (p=0.051, logit=19.125)', '\" Among\"[22395] (p=0.040, logit=18.875)', '\" Option\"[7104] (p=0.010, logit=17.500)']\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     clean_track=OrderedDict([(16183, (1, PredictedToken(token=' Hel', prob=0.796875, logit=21.875, token_id=16183, metadata=None))), (41445, (29, PredictedToken(token=' Television', prob=0.000499725341796875, logit=14.5, token_id=41445, metadata=None))), (19176, (51, PredictedToken(token=' Temple', prob=0.00011110305786132812, logit=13.0, token_id=19176, metadata=None))), (89077, (283, PredictedToken(token=' Strawberry', prob=3.159046173095703e-06, logit=9.4375, token_id=89077, metadata=None)))])\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     int_prediction=['\" Television\"[41445] (p=0.730, logit=21.500)', '\" The\"[578] (p=0.077, logit=19.250)', '\" Among\"[22395] (p=0.068, logit=19.125)', '\" Option\"[7104] (p=0.022, logit=18.000)', '\" Only\"[8442] (p=0.013, logit=17.500)']\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     int_track=OrderedDict([(41445, (1, PredictedToken(token=' Television', prob=0.73046875, logit=21.5, token_id=41445, metadata=None))), (19176, (11, PredictedToken(token=' Temple', prob=0.0038299560546875, logit=16.25, token_id=19176, metadata=None))), (89077, (27, PredictedToken(token=' Strawberry', prob=0.000804901123046875, logit=14.6875, token_id=89077, metadata=None))), (16183, (268, PredictedToken(token=' Hel', prob=5.424022674560547e-06, logit=9.6875, token_id=16183, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:47 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:47 src.selection.optimization DEBUG    torch.Size([3, 25])\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     patch_prediction=['\" Trom\"[94467] (p=0.680, logit=21.000)', '\" The\"[578] (p=0.172, logit=19.625)', '\" Among\"[22395] (p=0.049, logit=18.375)', '\" A\"[362] (p=0.049, logit=18.375)', '\" It\"[1102] (p=0.010, logit=16.750)']\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     clean_prediction=['\" Coffee\"[27171] (p=0.629, logit=22.000)', '\" The\"[578] (p=0.159, logit=20.625)', '\" A\"[362] (p=0.124, logit=20.375)', '\" Among\"[22395] (p=0.040, logit=19.250)', '\" It\"[1102] (p=0.008, logit=17.625)']\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     clean_track=OrderedDict([(27171, (1, PredictedToken(token=' Coffee', prob=0.62890625, logit=22.0, token_id=27171, metadata=None))), (5340, (28, PredictedToken(token=' Har', prob=0.000370025634765625, logit=14.5625, token_id=5340, metadata=None))), (8868, (36, PredictedToken(token=' Blue', prob=0.00021076202392578125, logit=14.0, token_id=8868, metadata=None)))])\n",
      "2025-09-16 09:46:47 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     int_prediction=['\" Har\"[5340] (p=0.781, logit=21.750)', '\" Among\"[22395] (p=0.105, logit=19.750)', '\" The\"[578] (p=0.057, logit=19.125)', '\" Option\"[7104] (p=0.013, logit=17.625)', '\" A\"[362] (p=0.007, logit=17.000)']\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     int_track=OrderedDict([(5340, (1, PredictedToken(token=' Har', prob=0.78125, logit=21.75, token_id=5340, metadata=None))), (8868, (80, PredictedToken(token=' Blue', prob=2.9325485229492188e-05, logit=11.5625, token_id=8868, metadata=None))), (27171, (84, PredictedToken(token=' Coffee', prob=2.765655517578125e-05, logit=11.5, token_id=27171, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:48 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:48 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     patch_prediction=['\" Birch\"[88088] (p=0.652, logit=21.000)', '\" Among\"[22395] (p=0.146, logit=19.500)', '\" The\"[578] (p=0.113, logit=19.250)', '\" It\"[1102] (p=0.013, logit=17.125)', '\" A\"[362] (p=0.012, logit=17.000)']\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     clean_prediction=['\" Watch\"[10573] (p=0.816, logit=21.875)', '\" A\"[362] (p=0.059, logit=19.250)', '\" The\"[578] (p=0.036, logit=18.750)', '\" Among\"[22395] (p=0.017, logit=18.000)', '\" None\"[2290] (p=0.013, logit=17.750)']\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     clean_track=OrderedDict([(10573, (1, PredictedToken(token=' Watch', prob=0.81640625, logit=21.875, token_id=10573, metadata=None))), (57094, (6, PredictedToken(token=' Highlight', prob=0.01025390625, logit=17.5, token_id=57094, metadata=None))), (79028, (7, PredictedToken(token=' Hick', prob=0.0054931640625, logit=16.875, token_id=79028, metadata=None))), (20423, (25, PredictedToken(token=' Amb', prob=0.00061798095703125, logit=14.6875, token_id=20423, metadata=None))), (735, (56, PredictedToken(token=' K', prob=8.869171142578125e-05, logit=12.75, token_id=735, metadata=None)))])\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     int_prediction=['\" Hick\"[79028] (p=0.883, logit=21.375)', '\" None\"[2290] (p=0.030, logit=18.000)', '\" Among\"[22395] (p=0.024, logit=17.750)', '\" The\"[578] (p=0.021, logit=17.625)', '\" Amb\"[20423] (p=0.004, logit=16.000)']\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     int_track=OrderedDict([(79028, (1, PredictedToken(token=' Hick', prob=0.8828125, logit=21.375, token_id=79028, metadata=None))), (20423, (5, PredictedToken(token=' Amb', prob=0.00408935546875, logit=16.0, token_id=20423, metadata=None))), (57094, (18, PredictedToken(token=' Highlight', prob=0.000431060791015625, logit=13.75, token_id=57094, metadata=None))), (735, (45, PredictedToken(token=' K', prob=0.00010919570922851562, logit=12.375, token_id=735, metadata=None))), (10573, (342, PredictedToken(token=' Watch', prob=3.293156623840332e-06, logit=8.875, token_id=10573, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:48 src.selection.optimization DEBUG    Sampling 3 patch samples...\n",
      "2025-09-16 09:46:48 src.selection.optimization DEBUG    torch.Size([3, 23])\n",
      "2025-09-16 09:46:48 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     patch_prediction=['\" Water\"[10164] (p=0.902, logit=23.125)', '\" The\"[578] (p=0.040, logit=20.000)', '\" Among\"[22395] (p=0.031, logit=19.750)', '\" A\"[362] (p=0.006, logit=18.125)', '\" water\"[3090] (p=0.005, logit=17.875)']\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     clean_prediction=['\" C\"[356] (p=0.797, logit=22.625)', '\" The\"[578] (p=0.095, logit=20.500)', '\" A\"[362] (p=0.027, logit=19.250)', '\" Among\"[22395] (p=0.021, logit=19.000)', '\" c\"[272] (p=0.015, logit=18.625)']\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     clean_track=OrderedDict([(356, (1, PredictedToken(token=' C', prob=0.796875, logit=22.625, token_id=356, metadata=None))), (445, (31, PredictedToken(token=' L', prob=0.000152587890625, logit=14.0625, token_id=445, metadata=None))), (22725, (712, PredictedToken(token=' Orange', prob=2.4400651454925537e-07, logit=7.625, token_id=22725, metadata=None)))])\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     int_prediction=['\" Orange\"[22725] (p=0.805, logit=22.500)', '\" The\"[578] (p=0.051, logit=19.750)', '\" Among\"[22395] (p=0.035, logit=19.375)', '\" Option\"[7104] (p=0.035, logit=19.375)', '\" An\"[1556] (p=0.021, logit=18.875)']\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     int_track=OrderedDict([(22725, (1, PredictedToken(token=' Orange', prob=0.8046875, logit=22.5, token_id=22725, metadata=None))), (445, (8, PredictedToken(token=' L', prob=0.005401611328125, logit=17.5, token_id=445, metadata=None))), (356, (11, PredictedToken(token=' C', prob=0.002899169921875, logit=16.875, token_id=356, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:49 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:49 src.selection.optimization DEBUG    torch.Size([4, 23])\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     patch_prediction=['\" Ring\"[22249] (p=0.805, logit=21.875)', '\" The\"[578] (p=0.052, logit=19.125)', '\" A\"[362] (p=0.040, logit=18.875)', '\" Among\"[22395] (p=0.035, logit=18.750)', '\" It\"[1102] (p=0.009, logit=17.375)']\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     clean_prediction=['\" Bear\"[24941] (p=0.727, logit=21.875)', '\" The\"[578] (p=0.112, logit=20.000)', '\" Among\"[22395] (p=0.060, logit=19.375)', '\" A\"[362] (p=0.053, logit=19.250)', '\" (\"[320] (p=0.004, logit=16.750)']\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     clean_track=OrderedDict([(24941, (1, PredictedToken(token=' Bear', prob=0.7265625, logit=21.875, token_id=24941, metadata=None))), (32498, (71, PredictedToken(token=' Mall', prob=4.506111145019531e-05, logit=12.1875, token_id=32498, metadata=None))), (86460, (258, PredictedToken(token=' Necklace', prob=3.7103891372680664e-06, logit=9.6875, token_id=86460, metadata=None))), (47759, (427, PredictedToken(token=' Guitar', prob=1.4528632164001465e-06, logit=8.75, token_id=47759, metadata=None)))])\n",
      "2025-09-16 09:46:49 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.668, logit=20.750)', '\" The\"[578] (p=0.149, logit=19.250)', '\" Among\"[22395] (p=0.070, logit=18.500)', '\" A\"[362] (p=0.029, logit=17.625)', '\" Option\"[7104] (p=0.008, logit=16.375)']\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.66796875, logit=20.75, token_id=86460, metadata=None))), (47759, (15, PredictedToken(token=' Guitar', prob=0.0018768310546875, logit=14.875, token_id=47759, metadata=None))), (24941, (298, PredictedToken(token=' Bear', prob=6.3478946685791016e-06, logit=9.1875, token_id=24941, metadata=None))), (32498, (318, PredictedToken(token=' Mall', prob=5.9604644775390625e-06, logit=9.125, token_id=32498, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:50 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:50 src.selection.optimization DEBUG    torch.Size([4, 26])\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     patch_prediction=['\" Piano\"[56491] (p=0.777, logit=22.000)', '\" The\"[578] (p=0.105, logit=20.000)', '\" Among\"[22395] (p=0.034, logit=18.875)', '\" A\"[362] (p=0.034, logit=18.875)', '\" It\"[1102] (p=0.016, logit=18.125)']\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     clean_prediction=['\" K\"[735] (p=0.742, logit=22.000)', '\" The\"[578] (p=0.101, logit=20.000)', '\" A\"[362] (p=0.089, logit=19.875)', '\" Among\"[22395] (p=0.037, logit=19.000)', '\" It\"[1102] (p=0.005, logit=17.000)']\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     clean_track=OrderedDict([(735, (1, PredictedToken(token=' K', prob=0.7421875, logit=22.0, token_id=735, metadata=None))), (48665, (189, PredictedToken(token=' Raspberry', prob=3.7848949432373047e-06, logit=9.8125, token_id=48665, metadata=None))), (38673, (353, PredictedToken(token=' Yoga', prob=1.080334186553955e-06, logit=8.5625, token_id=38673, metadata=None))), (68027, (689, PredictedToken(token=' Sax', prob=3.7439167499542236e-07, logit=7.5, token_id=68027, metadata=None)))])\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     int_prediction=['\" Sax\"[68027] (p=0.711, logit=21.500)', '\" The\"[578] (p=0.140, logit=19.875)', '\" Among\"[22395] (p=0.075, logit=19.250)', '\" A\"[362] (p=0.031, logit=18.375)', '\" (\"[320] (p=0.005, logit=16.625)']\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     int_track=OrderedDict([(68027, (1, PredictedToken(token=' Sax', prob=0.7109375, logit=21.5, token_id=68027, metadata=None))), (38673, (9, PredictedToken(token=' Yoga', prob=0.0021209716796875, logit=15.6875, token_id=38673, metadata=None))), (735, (72, PredictedToken(token=' K', prob=3.886222839355469e-05, logit=11.6875, token_id=735, metadata=None))), (48665, (119, PredictedToken(token=' Raspberry', prob=1.621246337890625e-05, logit=10.8125, token_id=48665, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:50 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:50 src.selection.optimization DEBUG    torch.Size([5, 26])\n",
      "2025-09-16 09:46:50 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     patch_prediction=['\" Hel\"[16183] (p=0.746, logit=22.250)', '\" A\"[362] (p=0.101, logit=20.250)', '\" The\"[578] (p=0.089, logit=20.125)', '\" Among\"[22395] (p=0.033, logit=19.125)', '\" It\"[1102] (p=0.004, logit=17.000)']\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     clean_prediction=['\" Museum\"[16730] (p=0.746, logit=21.375)', '\" A\"[362] (p=0.069, logit=19.000)', '\" The\"[578] (p=0.054, logit=18.750)', '\" Among\"[22395] (p=0.037, logit=18.375)', '\" None\"[2290] (p=0.023, logit=17.875)']\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     clean_track=OrderedDict([(16730, (1, PredictedToken(token=' Museum', prob=0.74609375, logit=21.375, token_id=16730, metadata=None))), (1050, (6, PredictedToken(token=' Re', prob=0.0198974609375, logit=17.75, token_id=1050, metadata=None))), (27217, (43, PredictedToken(token=' Train', prob=0.0002079010009765625, logit=13.1875, token_id=27217, metadata=None))), (86460, (127, PredictedToken(token=' Necklace', prob=1.9311904907226562e-05, logit=10.8125, token_id=86460, metadata=None))), (32749, (228, PredictedToken(token=' Carn', prob=7.569789886474609e-06, logit=9.875, token_id=32749, metadata=None)))])\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     int_prediction=['\" Train\"[27217] (p=0.473, logit=20.500)', '\" None\"[2290] (p=0.367, logit=20.250)', '\" Among\"[22395] (p=0.039, logit=18.000)', '\" The\"[578] (p=0.039, logit=18.000)', '\" A\"[362] (p=0.016, logit=17.125)']\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     int_track=OrderedDict([(27217, (1, PredictedToken(token=' Train', prob=0.47265625, logit=20.5, token_id=27217, metadata=None))), (1050, (24, PredictedToken(token=' Re', prob=0.00096893310546875, logit=14.3125, token_id=1050, metadata=None))), (32749, (252, PredictedToken(token=' Carn', prob=7.867813110351562e-06, logit=9.5, token_id=32749, metadata=None))), (16730, (270, PredictedToken(token=' Museum', prob=6.973743438720703e-06, logit=9.375, token_id=16730, metadata=None))), (86460, (1362, PredictedToken(token=' Necklace', prob=5.699694156646729e-07, logit=6.875, token_id=86460, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:51 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:51 src.selection.optimization DEBUG    torch.Size([4, 28])\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     patch_prediction=['\" Z\"[1901] (p=0.852, logit=21.625)', '\" The\"[578] (p=0.023, logit=18.000)', '\" None\"[2290] (p=0.020, logit=17.875)', '\" Hick\"[79028] (p=0.018, logit=17.750)', '\" Among\"[22395] (p=0.018, logit=17.750)']\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     clean_prediction=['\" Blender\"[88668] (p=0.914, logit=22.875)', '\" The\"[578] (p=0.031, logit=19.500)', '\" A\"[362] (p=0.021, logit=19.125)', '\" Among\"[22395] (p=0.015, logit=18.750)', '\" Option\"[7104] (p=0.003, logit=17.250)']\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     clean_track=OrderedDict([(88668, (1, PredictedToken(token=' Blender', prob=0.9140625, logit=22.875, token_id=88668, metadata=None))), (2947, (15, PredictedToken(token=' Mar', prob=0.000392913818359375, logit=15.125, token_id=2947, metadata=None))), (79189, (49, PredictedToken(token=' Elephant', prob=5.0067901611328125e-05, logit=13.0625, token_id=79189, metadata=None))), (39794, (89, PredictedToken(token=' Desk', prob=1.1861324310302734e-05, logit=11.625, token_id=39794, metadata=None)))])\n",
      "2025-09-16 09:46:51 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     int_prediction=['\" Elephant\"[79189] (p=0.852, logit=22.250)', '\" Mar\"[2947] (p=0.042, logit=19.250)', '\" The\"[578] (p=0.042, logit=19.250)', '\" Among\"[22395] (p=0.026, logit=18.750)', '\" Option\"[7104] (p=0.007, logit=17.500)']\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     int_track=OrderedDict([(79189, (1, PredictedToken(token=' Elephant', prob=0.8515625, logit=22.25, token_id=79189, metadata=None))), (2947, (3, PredictedToken(token=' Mar', prob=0.042236328125, logit=19.25, token_id=2947, metadata=None))), (39794, (103, PredictedToken(token=' Desk', prob=1.33514404296875e-05, logit=11.1875, token_id=39794, metadata=None))), (88668, (670, PredictedToken(token=' Blender', prob=5.848705768585205e-07, logit=8.0625, token_id=88668, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:52 src.selection.optimization DEBUG    Sampling 4 patch samples...\n",
      "2025-09-16 09:46:52 src.selection.optimization DEBUG    torch.Size([4, 27])\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     patch_prediction=['\" Yoga\"[38673] (p=0.766, logit=20.625)', '\" None\"[2290] (p=0.071, logit=18.250)', '\" The\"[578] (p=0.038, logit=17.625)', '\" Among\"[22395] (p=0.030, logit=17.375)', '\" A\"[362] (p=0.026, logit=17.250)']\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     clean_prediction=['\" St\"[800] (p=0.855, logit=22.250)', '\" The\"[578] (p=0.048, logit=19.375)', '\" A\"[362] (p=0.033, logit=19.000)', '\" Among\"[22395] (p=0.020, logit=18.500)', '\" (\"[320] (p=0.009, logit=17.750)']\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     clean_track=OrderedDict([(800, (1, PredictedToken(token=' St', prob=0.85546875, logit=22.25, token_id=800, metadata=None))), (423, (8, PredictedToken(token=' D', prob=0.00396728515625, logit=16.875, token_id=423, metadata=None))), (23262, (16, PredictedToken(token=' Comb', prob=0.0007781982421875, logit=15.25, token_id=23262, metadata=None))), (48390, (32, PredictedToken(token=' Lily', prob=0.00023746490478515625, logit=14.0625, token_id=48390, metadata=None)))])\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     int_prediction=['\" Comb\"[23262] (p=0.715, logit=21.875)', '\" D\"[423] (p=0.205, logit=20.625)', '\" The\"[578] (p=0.024, logit=18.500)', '\" A\"[362] (p=0.010, logit=17.625)', '\" Among\"[22395] (p=0.008, logit=17.375)']\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     int_track=OrderedDict([(23262, (1, PredictedToken(token=' Comb', prob=0.71484375, logit=21.875, token_id=23262, metadata=None))), (423, (2, PredictedToken(token=' D', prob=0.205078125, logit=20.625, token_id=423, metadata=None))), (800, (74, PredictedToken(token=' St', prob=3.457069396972656e-05, logit=11.9375, token_id=800, metadata=None))), (48390, (2680, PredictedToken(token=' Lily', prob=1.3224780559539795e-07, logit=6.375, token_id=48390, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:52 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:52 src.selection.optimization DEBUG    torch.Size([5, 29])\n",
      "2025-09-16 09:46:52 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     patch_prediction=['\" Watch\"[10573] (p=0.793, logit=21.375)', '\" A\"[362] (p=0.065, logit=18.875)', '\" The\"[578] (p=0.040, logit=18.375)', '\" Among\"[22395] (p=0.015, logit=17.375)', '\" Y\"[816] (p=0.011, logit=17.125)']\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     clean_prediction=['\" Tape\"[58586] (p=0.902, logit=21.375)', '\" None\"[2290] (p=0.027, logit=17.875)', '\" The\"[578] (p=0.024, logit=17.750)', '\" Among\"[22395] (p=0.009, logit=16.750)', '\" A\"[362] (p=0.003, logit=15.562)']\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     clean_track=OrderedDict([(58586, (1, PredictedToken(token=' Tape', prob=0.90234375, logit=21.375, token_id=58586, metadata=None))), (1443, (13, PredictedToken(token=' Sh', prob=0.00087738037109375, logit=14.4375, token_id=1443, metadata=None))), (8868, (29, PredictedToken(token=' Blue', prob=0.00026702880859375, logit=13.25, token_id=8868, metadata=None))), (72683, (86, PredictedToken(token=' Boxing', prob=4.363059997558594e-05, logit=11.4375, token_id=72683, metadata=None))), (86460, (140, PredictedToken(token=' Necklace', prob=1.823902130126953e-05, logit=10.5625, token_id=86460, metadata=None)))])\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     int_prediction=['\" Necklace\"[86460] (p=0.660, logit=20.375)', '\" None\"[2290] (p=0.189, logit=19.125)', '\" The\"[578] (p=0.033, logit=17.375)', '\" A\"[362] (p=0.023, logit=17.000)', '\" There\"[2684] (p=0.016, logit=16.625)']\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     int_track=OrderedDict([(86460, (1, PredictedToken(token=' Necklace', prob=0.66015625, logit=20.375, token_id=86460, metadata=None))), (1443, (6, PredictedToken(token=' Sh', prob=0.00830078125, logit=16.0, token_id=1443, metadata=None))), (8868, (7, PredictedToken(token=' Blue', prob=0.00689697265625, logit=15.8125, token_id=8868, metadata=None))), (72683, (43, PredictedToken(token=' Boxing', prob=0.0003032684326171875, logit=12.6875, token_id=72683, metadata=None))), (58586, (750, PredictedToken(token=' Tape', prob=2.9653310775756836e-06, logit=8.0625, token_id=58586, metadata=None)))])\n",
      "================================================================================\n",
      "2025-09-16 09:46:53 src.selection.optimization DEBUG    Sampling 5 patch samples...\n",
      "2025-09-16 09:46:53 src.selection.optimization DEBUG    torch.Size([5, 27])\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     Caching the query states for the 81 heads\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     patch_prediction=['\" Ottoman\"[70110] (p=0.699, logit=21.000)', '\" Notebook\"[69755] (p=0.074, logit=18.750)', '\" An\"[1556] (p=0.065, logit=18.625)', '\" The\"[578] (p=0.065, logit=18.625)', '\" Among\"[22395] (p=0.027, logit=17.750)']\n",
      "2025-09-16 09:46:53 src.selection.optimization INFO     clean run\n",
      "2025-09-16 09:46:54 src.selection.optimization INFO     clean_prediction=['\" Suit\"[33711] (p=0.805, logit=22.875)', '\" The\"[578] (p=0.075, logit=20.500)', '\" A\"[362] (p=0.075, logit=20.500)', '\" Among\"[22395] (p=0.027, logit=19.500)', '\" SU\"[15857] (p=0.002, logit=16.750)']\n",
      "2025-09-16 09:46:54 src.selection.optimization INFO     clean_track=OrderedDict([(33711, (1, PredictedToken(token=' Suit', prob=0.8046875, logit=22.875, token_id=33711, metadata=None))), (13394, (126, PredictedToken(token=' Bed', prob=5.9604644775390625e-06, logit=11.0625, token_id=13394, metadata=None))), (97796, (148, PredictedToken(token=' Skate', prob=4.351139068603516e-06, logit=10.75, token_id=97796, metadata=None))), (22410, (1068, PredictedToken(token=' Ju', prob=1.695007085800171e-07, logit=7.5, token_id=22410, metadata=None))), (78703, (1720, PredictedToken(token=' Potato', prob=8.754432201385498e-08, logit=6.84375, token_id=78703, metadata=None)))])\n",
      "2025-09-16 09:46:54 src.selection.optimization INFO     patching the q_proj states\n",
      "2025-09-16 09:46:54 src.selection.optimization INFO     int_prediction=['\" Bed\"[13394] (p=0.730, logit=22.000)', '\" The\"[578] (p=0.087, logit=19.875)', '\" Among\"[22395] (p=0.060, logit=19.500)', '\" A\"[362] (p=0.047, logit=19.250)', '\" Ju\"[22410] (p=0.032, logit=18.875)']\n",
      "2025-09-16 09:46:54 src.selection.optimization INFO     int_track=OrderedDict([(13394, (1, PredictedToken(token=' Bed', prob=0.73046875, logit=22.0, token_id=13394, metadata=None))), (22410, (5, PredictedToken(token=' Ju', prob=0.031982421875, logit=18.875, token_id=22410, metadata=None))), (78703, (9, PredictedToken(token=' Potato', prob=0.0033721923828125, logit=16.625, token_id=78703, metadata=None))), (97796, (52, PredictedToken(token=' Skate', prob=0.0001087188720703125, logit=13.1875, token_id=97796, metadata=None))), (33711, (110, PredictedToken(token=' Suit', prob=2.1338462829589844e-05, logit=11.5625, token_id=33711, metadata=None)))])\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    # clean_sample.default_option_style=\"numbered\"\n",
    "    # patch_sample.default_option_style=\"numbered\"\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77e0b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88597f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_rank_delta: 515.6953 ± 1159.7945\n",
      "target_rank_delta: -141.9824 ± 229.6404\n",
      "clean_rank_after_intervention: 516.6973 ± 1159.7936\n",
      "target_rank_after_intervention: 3.8086 ± 18.4028\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ee4558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_logit_delta: -10.9461 ± 3.2279\n",
      "target_logit_delta: 7.9519 ± 3.5683\n",
      "clean_logit_after_intervention: 10.7914 ± 3.2017\n",
      "target_logit_after_intervention: 20.4188 ± 2.1260\n"
     ]
    }
   ],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083a64bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771484375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae404a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Counterfactual patching accuracy: 0.7910 (405/512)\n",
      "================================================================================\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! find the positions after the patched intervention.\n",
    "# Is it looking at the first one, or the position of the \n",
    "# previous answer?\n",
    "\n",
    "from src.selection.utils import get_first_token_id\n",
    "\n",
    "failed_pos_track = {\n",
    "    \"clean_obj_idx\": [],\n",
    "    \"patch_obj_idx\": [],\n",
    "    \"first_obj_idx\": [],\n",
    "    \"other\": []\n",
    "}\n",
    "\n",
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "    clean_obj_idx = clean_sample.obj_idx\n",
    "    patch_obj_idx = patch_sample.obj_idx\n",
    "\n",
    "    int_top_tok = list(int_track.keys())[0]\n",
    "    int_top_obj = int_track[int_top_tok][1].token_id\n",
    "    opt_first_tokens = [\n",
    "        get_first_token_id(name=opt, tokenizer=mt.tokenizer, prefix=\" \")\n",
    "        for opt in clean_sample.options\n",
    "    ]\n",
    "    int_top_idx = opt_first_tokens.index(int_top_obj)\n",
    "\n",
    "    if int_top_idx == clean_obj_idx:\n",
    "        failed_pos_track[\"clean_obj_idx\"].append(failed_case)\n",
    "    elif int_top_idx == patch_obj_idx:\n",
    "        failed_pos_track[\"patch_obj_idx\"].append(failed_case)\n",
    "    elif int_top_idx == 0:\n",
    "        failed_pos_track[\"first_obj_idx\"].append(failed_case)\n",
    "    else:\n",
    "        failed_pos_track[\"other\"].append(failed_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124414a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x_vals = failed_pos_track.keys()\n",
    "y_vals = [len(failed_pos_track[key]) for key in x_vals]\n",
    "plt.bar(x_vals, y_vals)\n",
    "plt.xlabel(\"Failed Position Types\")\n",
    "plt.ylabel(\"Number of Failed Cases\")\n",
    "plt.title(\"Failed Position Types Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4b0c9",
   "metadata": {},
   "source": [
    "## Select One -- MCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e798959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectionSample, SelectOneTask\n",
    "\n",
    "select_one_mcq = SelectOneTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        # \"landmarks.json\"\n",
    "    )\n",
    ")\n",
    "print(select_one_mcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f28f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from src.selection.utils import get_first_token_id\n",
    "from src.functional import predict_next_token\n",
    "from src.selection.data import MCQify_sample\n",
    "\n",
    "test_sample = select_one_task.get_random_sample(\n",
    "    mt=mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    # category=\"actor\",\n",
    "    # category=\"United Kingdom\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "\n",
    "test_sample = MCQify_sample(mt, test_sample)\n",
    "print(\n",
    "    test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"'\n",
    ")\n",
    "\n",
    "predict_next_token(mt=mt, inputs=test_sample.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2feed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1305d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 1024\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_one_task.task_name,\n",
    "    \"objects\",\n",
    "    # \"profession\",\n",
    "    # \"nationality\"\n",
    "    # \"landmarks\"\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    pred_target_token_id = cf_pair.clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    pred_obj_idx = cf_pair.clean_sample.metadata[\"track_type_obj_idx\"]\n",
    "    cf_pair.clean_sample.metadata[\"track_type_obj_token_id\"] = get_first_token_id(\n",
    "        name=chr(ord('a') + pred_obj_idx),\n",
    "        tokenizer=mt.tokenizer,\n",
    "        prefix=\" \"\n",
    "    )\n",
    "    validation_set.append((\n",
    "        MCQify_sample(cf_pair.clean_sample), \n",
    "        MCQify_sample(cf_pair.patch_sample)\n",
    "    ))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98039964",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "import copy\n",
    "\n",
    "clean, patch = copy.deepcopy(validation_set[5])\n",
    "# failed_case = failed_pos_track[\"patch_obj_idx\"][5]\n",
    "# clean = failed_case[\"clean_sample\"]\n",
    "# patch = failed_case[\"patch_sample\"]\n",
    "# clean.default_option_style=\"numbered\"\n",
    "patch.default_option_style=\"numbered\"\n",
    "\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    "    patch_args={\n",
    "        \"batch_size\": len(patch.options),\n",
    "        \"distinct_options\": False,\n",
    "        # \"task\": select_task,\n",
    "        # \"prompt_template_idx\": prompt_template_idx,\n",
    "        # \"option_style\": patch.default_option_style,\n",
    "        # \"n_distractors\": N_DISTRACTORS,\n",
    "    },\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    patch_sample.default_option_style=\"numbered\"\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "            # \"task\": select_task,\n",
    "            # \"prompt_template_idx\": prompt_template_idx,\n",
    "            # \"option_style\": patch.default_option_style,\n",
    "            # \"n_distractors\": N_DISTRACTORS,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eca4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92069e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643faf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dba4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f0962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63c326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006632f5",
   "metadata": {},
   "source": [
    "## SelectFirst Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectionSample, SelectFirstTask\n",
    "\n",
    "select_first_task = SelectFirstTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(select_first_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d107a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = select_first_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=\"single_line\",\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6630da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_first_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 256\n",
    "start_number = 257\n",
    "\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_first_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_first_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(4, 7)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set) + start_number - 1:05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_first_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e23141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[15]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb576ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        # patch_args={\n",
    "        #     \"batch_size\": len(patch.options),\n",
    "        #     \"distinct_options\": False,\n",
    "        # },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ba769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_sample, patch_sample in validation_set:\n",
    "    assert \"first\" in clean_sample.prompt()\n",
    "    assert \"first\" in patch_sample.prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd275e7a",
   "metadata": {},
   "source": [
    "## SelectLast Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectLastTask\n",
    "\n",
    "select_last_task = SelectLastTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(select_last_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b04029",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = select_last_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=\"single_line\",\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "import random\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_last_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 200\n",
    "start_number = 312\n",
    "\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_last_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=select_last_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_distractors=random.choice(range(4, 7)),\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set) + start_number - 1:05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61015489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "from src.functional import free_gpu_cache\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    select_last_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38319c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2896cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[15]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf475c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d217f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cff4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9315a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clean_sample, patch_sample in validation_set:\n",
    "    assert \"last\" in clean_sample.prompt()\n",
    "    assert \"last\" in patch_sample.prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d20aed",
   "metadata": {},
   "source": [
    "## YesNo Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ff1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import YesNoSample, YesNoTask\n",
    "\n",
    "yes_no_task = YesNoTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(yes_no_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1776c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = yes_no_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    "    yes_mode=False\n",
    ")\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair, get_counterfactual_samples_interface\n",
    "from src.functional import free_gpu_cache\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    yes_no_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[yes_no_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=yes_no_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_options=5,\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set):05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "import random\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    yes_no_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[3]\n",
    "print(patch.prompt(), \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print(clean.prompt(), \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[15]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4761dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        # patch_args={\n",
    "        #     \"batch_size\": len(patch_sample.options),\n",
    "        #     \"distinct_options\": False,\n",
    "        # },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7958bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab562a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c783064",
   "metadata": {},
   "outputs": [],
   "source": [
    "for failed_case in failed_cases:\n",
    "    clean_sample = failed_case[\"clean_sample\"]\n",
    "    patch_sample = failed_case[\"patch_sample\"]\n",
    "    int_track = failed_case[\"int_track\"]\n",
    "    clean_track = failed_case[\"clean_track\"]\n",
    "\n",
    "    print(\"Clean Sample:\")\n",
    "    print(clean_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([clean_sample.ans_token_id])}\"')\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        \"Track: \",\n",
    "        \" | Token\"\n",
    "        f\"\\\"{mt.tokenizer.decode(clean_sample.metadata['track_type_obj_token_id'])}\\\"\",\n",
    "    )\n",
    "    print(\"Clean:\", f\"(Token: {mt.tokenizer.decode(clean_sample.ans_token_id)})\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    clean_track = [pred for tok_id, (rank, pred) in clean_track.items()]\n",
    "    print(f\"Clean Track: {json.dumps([str(pred) for pred in clean_track], indent=4)}\")\n",
    "\n",
    "    int_track = [pred for tok_id, (rank, pred) in int_track.items()]\n",
    "    print(\n",
    "        f\"Intervened Track: {json.dumps([str(pred) for pred in int_track], indent=4)}\"\n",
    "    )\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96debe34",
   "metadata": {},
   "source": [
    "## Counting Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CountingSample, CountingTask\n",
    "\n",
    "counting_task = CountingTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "print(counting_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_sample = counting_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    option_style=OPTION_STYLE,\n",
    "    prompt_template_idx=3,\n",
    "    category=\"fruit\",\n",
    "    filter_by_lm_prediction=True,\n",
    "    n_options = random.choice(range(2, 4)),\n",
    ")\n",
    "\n",
    "print(test_sample.prompt(), \">>\", f'\"{mt.tokenizer.decode([test_sample.ans_token_id])}\"')\n",
    "test_sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = verify_head_patterns(\n",
    "    prompt=test_sample.prompt(option_style=\"single_line\"),\n",
    "    options=test_sample.options,\n",
    "    mt=mt,\n",
    "    heads=optimized_heads,\n",
    "    # heads = HEADS,\n",
    "    # heads = [(35, 19)],\n",
    "    start_from=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "\n",
    "validation_samples_save_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    counting_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "os.makedirs(validation_samples_save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[counting_task.task_name]\n",
    "\n",
    "while len(validation_set) < validation_limit:\n",
    "    print(f\"sample {len(validation_set)+1} / {validation_limit}\")\n",
    "    patch, clean = counterfactual_sampler(\n",
    "        mt=mt,\n",
    "        task=counting_task,\n",
    "        filter_by_lm_prediction=True,\n",
    "        prompt_template_idx=3,\n",
    "        option_style=OPTION_STYLE,\n",
    "        n_options=5,\n",
    "    )\n",
    "    validation_set.append((clean, patch))\n",
    "    cf_pair = CounterFactualSamplePair(\n",
    "        patch_sample=patch,\n",
    "        clean_sample=clean,\n",
    "    )\n",
    "    cf_pair.detensorize()\n",
    "    with open(\n",
    "        os.path.join(validation_samples_save_path, f\"{len(validation_set):05d}.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(cf_pair.to_dict(), f, indent=2)\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CounterFactualSamplePair\n",
    "from src.functional import free_gpu_cache\n",
    "import random\n",
    "\n",
    "free_gpu_cache()\n",
    "validation_set = []\n",
    "validation_limit = 512\n",
    "\n",
    "validation_samples_load_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"selection\",\n",
    "    \"samples\",\n",
    "    \"validation\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    counting_task.task_name,\n",
    "    \"objects\",\n",
    ")\n",
    "\n",
    "sample_files = [\n",
    "    os.path.join(validation_samples_load_path, f)\n",
    "    for f in os.listdir(validation_samples_load_path)\n",
    "    if f.endswith(\".json\")\n",
    "]\n",
    "logger.info(f\"Found {len(sample_files)} sample files\")\n",
    "\n",
    "random.shuffle(sample_files)\n",
    "sample_files = sample_files[:validation_limit]\n",
    "for sample_file in sample_files:\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        cf_pair_data = json.load(f)\n",
    "    cf_pair = CounterFactualSamplePair.from_dict(cf_pair_data)\n",
    "    validation_set.append((cf_pair.clean_sample, cf_pair.patch_sample))\n",
    "\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da11e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean, patch = validation_set[1]\n",
    "print('\"' + patch.prompt() + '\"', \">>\", mt.tokenizer.decode(patch.ans_token_id))\n",
    "print('\"' + clean.prompt() + '\"', \">>\", mt.tokenizer.decode(clean.ans_token_id))\n",
    "clean.metadata[\"track_type_obj_token_id\"], f'\"{mt.tokenizer.decode(clean.metadata[\"track_type_obj_token_id\"])}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c71f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.optimization import validate_q_proj_ie_on_sample_pair\n",
    "\n",
    "clean, patch = validation_set[3]\n",
    "val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "    mt=mt,\n",
    "    clean_sample=clean,\n",
    "    patch_sample=patch,\n",
    "    heads=optimized_heads,\n",
    "    query_indices={-2: -2, -1: -1},\n",
    "    add_ques_pos_to_query_indices=True,\n",
    "    verify_head_behavior_on=-1,\n",
    ")\n",
    "\n",
    "clean_obj = clean.ans_token_id\n",
    "target_obj = clean.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "logger.debug(f\"clean obj: {mt.tokenizer.decode(clean_obj)}\")\n",
    "logger.debug(f\"target obj: {mt.tokenizer.decode(target_obj)}\")\n",
    "\n",
    "before_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"clean_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"clean_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"clean_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"clean_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "after_intervention = {\n",
    "    \"clean_rank\": val_sample_result[\"int_track\"][clean_obj][0],\n",
    "    \"clean_logit\": val_sample_result[\"int_track\"][clean_obj][1].logit,\n",
    "    \"target_rank\": val_sample_result[\"int_track\"][target_obj][0],\n",
    "    \"target_logit\": val_sample_result[\"int_track\"][target_obj][1].logit,\n",
    "}\n",
    "\n",
    "clean_rank_delta = after_intervention[\"clean_rank\"] - before_intervention[\"clean_rank\"]\n",
    "target_rank_delta = (\n",
    "    after_intervention[\"target_rank\"] - before_intervention[\"target_rank\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Rank Change: {before_intervention['clean_rank']} -> {after_intervention['clean_rank']} | Delta: {clean_rank_delta} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Rank Change: {before_intervention['target_rank']} -> {after_intervention['target_rank']} | Delta: {target_rank_delta} \"\n",
    ")\n",
    "\n",
    "clean_logit_delta = (\n",
    "    after_intervention[\"clean_logit\"] - before_intervention[\"clean_logit\"]\n",
    ")\n",
    "target_logit_delta = (\n",
    "    after_intervention[\"target_logit\"] - before_intervention[\"target_logit\"]\n",
    ")\n",
    "logger.info(\n",
    "    f\"Clean Prediction Logit Change: {before_intervention['clean_logit']:.4f} -> {after_intervention['clean_logit']:.4f} | Delta: {clean_logit_delta:.4f} \"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Target Prediction Logit Change: {before_intervention['target_logit']:.4f} -> {after_intervention['target_logit']:.4f} | Delta: {target_logit_delta:.4f} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for clean_sample, patch_sample in tqdm(validation_set):\n",
    "    val_sample_result = validate_q_proj_ie_on_sample_pair(\n",
    "        mt=mt,\n",
    "        clean_sample=clean_sample,\n",
    "        patch_sample=patch_sample,\n",
    "        heads=optimized_heads,\n",
    "        query_indices={-2: -2, -1: -1},\n",
    "        add_ques_pos_to_query_indices=True,\n",
    "        patch_args={\n",
    "            \"batch_size\": len(patch_sample.options),\n",
    "            \"distinct_options\": False,\n",
    "        },\n",
    "    )\n",
    "    validation_results.append(val_sample_result)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4821fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_intervention = []\n",
    "after_intervention = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "\n",
    "    clean_obj = clean_sample.ans_token_id\n",
    "    target_obj = clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "\n",
    "    before_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"clean_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"clean_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"clean_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"clean_track\"][target_obj][1].logit,\n",
    "    })\n",
    "\n",
    "    after_intervention.append({\n",
    "        \"clean_rank\": intervention_result[\"int_track\"][clean_obj][0],\n",
    "        \"clean_logit\": intervention_result[\"int_track\"][clean_obj][1].logit,\n",
    "        \"target_rank\": intervention_result[\"int_track\"][target_obj][0],\n",
    "        \"target_logit\": intervention_result[\"int_track\"][target_obj][1].logit,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "clean_rank_delta = [\n",
    "    after[\"clean_rank\"] - before[\"clean_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_rank_delta = [\n",
    "    after[\"target_rank\"] - before[\"target_rank\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "\n",
    "clean_rank_delta, target_rank_delta = np.array(clean_rank_delta), np.array(\n",
    "    target_rank_delta\n",
    ")\n",
    "print(f\"clean_rank_delta: {clean_rank_delta.mean():.4f} ± {clean_rank_delta.std():.4f}\")\n",
    "print(\n",
    "    f\"target_rank_delta: {target_rank_delta.mean():.4f} ± {target_rank_delta.std():.4f}\"\n",
    ")\n",
    "\n",
    "clean_rank_after_intervention = [after[\"clean_rank\"] for after in after_intervention]\n",
    "clean_rank_after_intervention = np.array(clean_rank_after_intervention)\n",
    "print(\n",
    "    f\"clean_rank_after_intervention: {clean_rank_after_intervention.mean():.4f} ± {clean_rank_after_intervention.std():.4f}\"\n",
    ")\n",
    "\n",
    "target_rank_after_intervention = [after[\"target_rank\"] for after in after_intervention]\n",
    "target_rank_after_intervention = np.array(target_rank_after_intervention)\n",
    "print(\n",
    "    f\"target_rank_after_intervention: {target_rank_after_intervention.mean():.4f} ± {target_rank_after_intervention.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f190e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_delta = [\n",
    "    after[\"clean_logit\"] - before[\"clean_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "target_logit_delta = [\n",
    "    after[\"target_logit\"] - before[\"target_logit\"]\n",
    "    for before, after in zip(before_intervention, after_intervention)\n",
    "]\n",
    "clean_logit_delta, target_logit_delta = np.array(clean_logit_delta), np.array(target_logit_delta)\n",
    "print(f\"clean_logit_delta: {clean_logit_delta.mean():.4f} ± {clean_logit_delta.std():.4f}\")\n",
    "print(f\"target_logit_delta: {target_logit_delta.mean():.4f} ± {target_logit_delta.std():.4f}\")\n",
    "\n",
    "clean_logit_after_intervention = [\n",
    "    after[\"clean_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "clean_logit_after_intervention = np.array(clean_logit_after_intervention)\n",
    "print(f\"clean_logit_after_intervention: {clean_logit_after_intervention.mean():.4f} ± {clean_logit_after_intervention.std():.4f}\")\n",
    "\n",
    "target_logit_after_intervention = [\n",
    "    after[\"target_logit\"]\n",
    "    for after in after_intervention\n",
    "]\n",
    "target_logit_after_intervention = np.array(target_logit_after_intervention)\n",
    "print(f\"target_logit_after_intervention: {target_logit_after_intervention.mean():.4f} ± {target_logit_after_intervention.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448134da",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = sum([1 for after in after_intervention if after[\"target_rank\"] == 1])\n",
    "top_1 / len(after_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_patch_type_top_option = 0\n",
    "failed_cases = []\n",
    "\n",
    "for intervention_result in validation_results:\n",
    "    clean_sample = intervention_result[\"clean_sample\"]\n",
    "    patch_sample = intervention_result[\"patch_sample\"]\n",
    "    int_track = intervention_result[\"int_track\"]\n",
    "    clean_track = intervention_result[\"clean_track\"]\n",
    "    if (\n",
    "        int_track[list(int_track.keys())[0]][1].token_id\n",
    "        == clean_sample.metadata[\"track_type_obj_token_id\"]\n",
    "    ): \n",
    "        counter_patch_type_top_option += 1\n",
    "    else:\n",
    "        failed_cases.append(\n",
    "            {\n",
    "                \"clean_sample\": clean_sample,\n",
    "                \"patch_sample\": patch_sample,\n",
    "                \"int_track\": int_track,\n",
    "                \"clean_track\": clean_track,\n",
    "            }\n",
    "        )\n",
    "\n",
    "top_1_accuracy = counter_patch_type_top_option / len(validation_results)\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Counterfactual patching accuracy: {top_1_accuracy:.4f} ({counter_patch_type_top_option}/{len(validation_results)})\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{len(failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910d98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e40928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
