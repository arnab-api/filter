{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7bc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53344a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:03:29 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-07-18 22:03:29 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-07-18 22:03:29 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb576a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-18 22:03:32,002] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2025-07-18 22:03:32 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -c /tmp/tmpj2vaan5e/test.c -o /tmp/tmpj2vaan5e/test.o\n",
      "2025-07-18 22:03:32 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat /tmp/tmpj2vaan5e/test.o -laio -o /tmp/tmpj2vaan5e/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:03:32 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -c /tmp/tmp2tui03bs/test.c -o /tmp/tmp2tui03bs/test.o\n",
      "2025-07-18 22:03:32 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat /tmp/tmp2tui03bs/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmp2tui03bs/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:03:33 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-07-18 22:03:33 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-07-18 22:03:33 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-07-18 22:03:33 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9263517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:03:34 src.models WARNING  meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-07-18 22:03:34 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-18 22:03:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-07-18 22:03:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d4a94c24bf4a42afa43c0ecf920b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:04:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-07-18 22:04:24 src.models INFO     loaded model <meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288f044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainable_params.pt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0010, dtype=torch.bfloat16, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import free_gpu_cache\n",
    "\n",
    "# SYNTH_DATASET = \"icosahedron_1\"\n",
    "SYNTH_DATASET = \"64\"\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"trained_params\",\n",
    "    f\"{SYNTH_DATASET}\",\n",
    "    \"_full__clamp=0.001\",\n",
    "    model_key.split(\"/\")[-1],\n",
    ")\n",
    "\n",
    "version = \"epoch_1\"\n",
    "# version = \"final_model\"\n",
    "\n",
    "checkpoint_path = os.path.join(env_utils.DEFAULT_RESULTS_DIR, checkpoint_path, version)\n",
    "\n",
    "print(os.listdir(checkpoint_path))\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"trainable_params.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "# loaded_deltas\n",
    "\n",
    "free_gpu_cache()\n",
    "\n",
    "\n",
    "d = loaded_deltas[\"model<>layers<>10<>mlp<>gate_proj\"]\n",
    "d.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:04:38 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:04:38 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:38 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:38 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:38 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:38 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:39 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:39 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:39 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:39 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:39 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:39 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:40 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:40 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:40 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:40 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:40 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:41 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n",
      "2025-07-18 22:04:42 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.gate_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:42 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.up_proj' | param_delta.shape=torch.Size([28672, 8192])\n",
      "2025-07-18 22:04:42 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.down_proj' | param_delta.shape=torch.Size([8192, 28672])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "#################################################\n",
    "Trainable_CLS = TrainableLM_delta\n",
    "# Trainable_CLS = TrainableLM_LoRA\n",
    "#################################################\n",
    "\n",
    "Trainable_CLS.fuse_with_model(mt._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd6845",
   "metadata": {},
   "source": [
    "## Generate samples and filter by LM knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:02:23 src.selection.data INFO     Loaded 16 categories\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data  import load_people_by_category\n",
    "\n",
    "people_by_category = load_people_by_category(tokenizer = mt.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e6f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:02:26 src.selection.data ERROR    Sample = Oprah Winfrey -> Marc Benioff (3): ['Aaron Donald', 'Dmitry Bivol', 'Ridley Scott', 'Marc Benioff', 'Vera Wang', 'Anthony Davis']\n",
      "Top prediction \" Vera\"[68200] (p=0.355, logit=18.250) does not match the object Marc Benioff[19412, \" Marc\"].\n",
      "Retrying ...\n",
      "\n",
      "2025-07-18 22:02:26 src.selection.data ERROR    Sample = Reid Hoffman -> Oprah Winfrey (3): ['Marco Rubio', 'Micah Parsons', 'Ricky Gervais', 'Oprah Winfrey', 'Devin Haney', 'Brooks Koepka']\n",
      "Top prediction \" None\"[2290] (p=0.342, logit=17.500) does not match the object Oprah Winfrey[92258, \" Oprah\"].\n",
      "Retrying ...\n",
      "\n",
      "Jeff Bezos -> Richard Branson (3): ['Guillermo del Toro', 'Jessica Pegula', 'Shakur Stevenson', 'Richard Branson', 'Gabriel Iglesias', 'Julia Roberts']\n",
      "Which person from the following list has the profession in common with Jeff Bezos?\n",
      "Options: Guillermo del Toro, Jessica Pegula, Shakur Stevenson, Richard Branson, Gabriel Iglesias, Julia Roberts.\n",
      "Ans:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Richard', prob=0.82421875, logit=19.75, token_id=12131, metadata=None),\n",
       " PredictedToken(token=' Jeff', prob=0.0361328125, logit=16.625, token_id=12149, metadata=None),\n",
       " PredictedToken(token=' The', prob=0.031982421875, logit=16.5, token_id=578, metadata=None),\n",
       " PredictedToken(token=' None', prob=0.0281982421875, logit=16.375, token_id=2290, metadata=None),\n",
       " PredictedToken(token=' R', prob=0.009765625, logit=15.3125, token_id=432, metadata=None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample, get_random_sample\n",
    "\n",
    "sample = get_random_sample(\n",
    "    people_by_category = people_by_category,\n",
    "    mt = mt,\n",
    "    n_distractors=5,\n",
    "    get_alt_obj=False,\n",
    "    # category=\"actor\",\n",
    "    obj_idx=3,\n",
    "    filter_by_lm_prediction=True\n",
    ")\n",
    "print(sample)\n",
    "print(sample.prompt)\n",
    "sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a00588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 22:02:39 src.utils.experiment_utils INFO     setting all seeds to 123456\n",
      "Collected 1/10000 samples. 0.01%\n",
      "Collected 2/10000 samples. 0.02%\n",
      "2025-07-18 22:02:41 src.selection.data ERROR    Sample = Oprah Winfrey -> Warren Buffett (4): ['Pete Davidson', 'Jalen Hurts', 'Taylor Swift', 'Ralph Lauren', 'Warren Buffett', 'Paulo Dybala']\n",
      "Top prediction \" Taylor\"[16844] (p=0.469, logit=18.500) does not match the object Warren Buffett[26713, \" Warren\"].\n",
      "Retrying ...\n",
      "\n",
      "2025-07-18 22:02:41 src.selection.data ERROR    Sample = Richard Branson -> Oprah Winfrey (3): ['Bo Burnham', 'Davante Adams', 'Jimmy Butler', 'Oprah Winfrey', 'Nicholas Sparks', 'Mohamed Salah']\n",
      "Top prediction \" None\"[2290] (p=0.316, logit=18.125) does not match the object Oprah Winfrey[92258, \" Oprah\"].\n",
      "Retrying ...\n",
      "\n",
      "Collected 3/10000 samples. 0.03%\n",
      "Collected 4/10000 samples. 0.04%\n",
      "Collected 5/10000 samples. 0.05%\n",
      "Collected 6/10000 samples. 0.06%\n",
      "Collected 7/10000 samples. 0.07%\n",
      "Collected 8/10000 samples. 0.08%\n",
      "Collected 9/10000 samples. 0.09%\n",
      "Collected 10/10000 samples. 0.10%\n",
      "Collected 11/10000 samples. 0.11%\n",
      "Collected 12/10000 samples. 0.12%\n",
      "2025-07-18 22:02:50 src.selection.data ERROR    Sample = Ja Morant -> Russell Westbrook (5): ['Satya Nadella', 'Johnny Depp', 'George R.R. Martin', 'Scottie Scheffler', 'Erling Haaland', 'Russell Westbrook']\n",
      "Top prediction \" Scott\"[10016] (p=0.348, logit=18.375) does not match the object Russell Westbrook[25953, \" Russell\"].\n",
      "Retrying ...\n",
      "\n",
      "Collected 13/10000 samples. 0.13%\n",
      "2025-07-18 22:02:52 src.selection.data ERROR    Sample = Caroline Garcia -> Iga Świątek (4): ['Justin Jefferson', 'Cameron Smith', 'Artur Beterbiev', 'Julia Roberts', 'Iga Świątek', 'Sara Blakely']\n",
      "Top prediction \" Cameron\"[27524] (p=0.348, logit=18.375) does not match the object Iga Świątek[358, \" I\"].\n",
      "Retrying ...\n",
      "\n",
      "Collected 14/10000 samples. 0.14%\n",
      "Collected 15/10000 samples. 0.15%\n",
      "Collected 16/10000 samples. 0.16%\n",
      "Collected 17/10000 samples. 0.17%\n",
      "2025-07-18 22:02:55 src.selection.data ERROR    Sample = Nick Bosa -> Tyreek Hill (1): ['Jessica Pegula', 'Tyreek Hill', 'Anderson Cooper', 'Glenn Greenwald', 'Sara Blakely', 'Ryan Reynolds']\n",
      "Top prediction \" Jessica\"[33467] (p=0.352, logit=17.875) does not match the object Tyreek Hill[14221, \" Ty\"].\n",
      "Retrying ...\n",
      "\n",
      "Collected 18/10000 samples. 0.18%\n",
      "Collected 19/10000 samples. 0.19%\n",
      "Collected 20/10000 samples. 0.20%\n",
      "Collected 21/10000 samples. 0.21%\n",
      "Collected 22/10000 samples. 0.22%\n",
      "Collected 23/10000 samples. 0.23%\n",
      "Collected 24/10000 samples. 0.24%\n",
      "Collected 25/10000 samples. 0.25%\n",
      "Collected 26/10000 samples. 0.26%\n",
      "Collected 27/10000 samples. 0.27%\n",
      "Collected 28/10000 samples. 0.28%\n",
      "Collected 29/10000 samples. 0.29%\n",
      "2025-07-18 22:03:06 src.selection.data ERROR    Sample = Russell Wilson -> Micah Parsons (0): ['Micah Parsons', 'Son Heung-min', 'Anderson Cooper', 'Matt Fitzpatrick', 'Jonathan Anderson', 'Shawn Mendes']\n",
      "Top prediction \" Russell\"[25953] (p=0.247, logit=17.125) does not match the object Micah Parsons[28095, \" Mic\"].\n",
      "Retrying ...\n",
      "\n",
      "Collected 30/10000 samples. 0.30%\n",
      "Collected 31/10000 samples. 0.31%\n",
      "Collected 32/10000 samples. 0.32%\n",
      "Collected 33/10000 samples. 0.33%\n",
      "Collected 34/10000 samples. 0.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f9b8419d590>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 35/10000 samples. 0.35%\n",
      "Collected 36/10000 samples. 0.36%\n",
      "2025-07-18 22:03:13 src.selection.data ERROR    Sample = Sebastian Maniscalco -> Amy Schumer (5): ['Alexander Zverev', 'Terence Crawford', 'Wes Anderson', 'Julia Roberts', 'Peter Baker', 'Amy Schumer']\n",
      "Top prediction \" None\"[2290] (p=0.168, logit=17.250) does not match the object Amy Schumer[29793, \" Amy\"].\n",
      "Retrying ...\n",
      "\n",
      "2025-07-18 22:03:13 src.selection.data ERROR    Sample = Bill Burr -> Kevin Hart (5): ['Johnny Depp', 'LeBron James', 'Terence Crawford', 'Mitt Romney', 'Spike Lee', 'Kevin Hart']\n",
      "Top prediction \" Ter\"[10335] (p=0.473, logit=19.125) does not match the object Kevin Hart[16768, \" Kevin\"].\n",
      "Retrying ...\n",
      "\n",
      "Collected 37/10000 samples. 0.37%\n",
      "Collected 38/10000 samples. 0.38%\n",
      "Collected 39/10000 samples. 0.39%\n",
      "Collected 40/10000 samples. 0.40%\n",
      "Collected 41/10000 samples. 0.41%\n",
      "Collected 42/10000 samples. 0.42%\n",
      "Collected 43/10000 samples. 0.43%\n",
      "Collected 44/10000 samples. 0.44%\n",
      "Collected 45/10000 samples. 0.45%\n",
      "Collected 46/10000 samples. 0.46%\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "save_dir = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR, \"selection\", mt.name.split(\"/\")[-1], \"profession\"\n",
    ")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_name = \"filtered_samples.json\"\n",
    "\n",
    "LIMIT = 12000\n",
    "N_DISTRACTORS = 5\n",
    "SAVE_STEP = 100\n",
    "##########################################################\n",
    "\n",
    "from src.utils.experiment_utils import set_seed\n",
    "set_seed(123456)\n",
    "\n",
    "filtered_samples = []\n",
    "while len(filtered_samples) < LIMIT:\n",
    "    sample = get_random_sample(\n",
    "        people_by_category=people_by_category,\n",
    "        mt=mt,\n",
    "        n_distractors=N_DISTRACTORS,\n",
    "        get_alt_obj=False,\n",
    "        filter_by_lm_prediction=True\n",
    "    )\n",
    "    sample.detensorize()\n",
    "    filtered_samples.append(sample)\n",
    "    print(f\"Collected {len(filtered_samples)}/{LIMIT} samples. {len(filtered_samples) / LIMIT * 100:.2f}%\")\n",
    "\n",
    "    if len(filtered_samples) % SAVE_STEP == 0 or len(filtered_samples) == LIMIT:\n",
    "        print(f\"Saving {len(filtered_samples)} samples to {os.path.join(save_dir, file_name)}\")\n",
    "        with open(os.path.join(save_dir, file_name), \"w\") as f:\n",
    "            json.dump([s.to_dict() for s in filtered_samples], f, indent=2)\n",
    "\n",
    "# with open(os.path.join(save_dir, file_name), \"w\") as f:\n",
    "#     json.dump([s.to_dict() for s in filtered_samples], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"filtered_samples.json\"), \"r\") as f:\n",
    "    loaded_samples = json.load(f)\n",
    "loaded_samples = [SelectionSample.from_dict(s) for s in loaded_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_samples[0].prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ffdbb",
   "metadata": {},
   "source": [
    "## Cache last token states for the generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"filtered_samples.json\"), \"r\") as f:\n",
    "    filtered_samples = json.load(f)\n",
    "filtered_samples = [SelectionSample.from_dict(s) for s in filtered_samples]\n",
    "\n",
    "len(filtered_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a43ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "cache_dir = os.path.join(save_dir, \"cached_states\")\n",
    "\n",
    "all_layers = (\n",
    "    [mt.embedder_name]  # embeddings\n",
    "    + mt.layer_names  # residual\n",
    "    + [mt.mlp_module_name_format.format(i) for i in range(mt.n_layer)]  # mlp outputs\n",
    "    + [mt.attn_module_name_format.format(i) for i in range(mt.n_layer)]  # attn outputs\n",
    ")\n",
    "TOKEN_POSITION = -1\n",
    "\n",
    "locations = [(layer_name, TOKEN_POSITION) for layer_name in all_layers]\n",
    "#######################################################################################\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "from src.utils.typing import TokenizerOutput\n",
    "from src.functional import get_hs, detensorize\n",
    "from src.tokens import prepare_input\n",
    "\n",
    "for idx, sample in enumerate(filtered_samples):\n",
    "    # inputs = TokenizerOutput(data = sample.metadata[\"tokenized\"]).to(mt.device)\n",
    "    inputs = prepare_input(prompts=sample.prompt, tokenizer=mt)\n",
    "    sample.detensorize()\n",
    "\n",
    "    cache = {\"sample\": sample.to_dict(), \"states\": {}}\n",
    "    states = get_hs(\n",
    "        mt=mt,\n",
    "        input=inputs,\n",
    "        locations=locations,\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    for (layer_name, tok_idx), state in states.items():\n",
    "        cache[\"states\"][layer_name] = state.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "    cache = detensorize(cache)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(cache_dir, f\"sample_{idx}.npz\"), **cache, allow_pickle=True\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        f\"Processed sample {idx + 1}/{len(filtered_samples)} ({(idx + 1) / len(filtered_samples) * 100:.2f}%)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7882cc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00005\n"
     ]
    }
   ],
   "source": [
    "val = 5\n",
    "print(f\"{val:05d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4329ba",
   "metadata": {},
   "source": [
    "### Testing by loading the cached states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ce6d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_00009.npz',\n",
       " 'sample_00006.npz',\n",
       " 'sample_00004.npz',\n",
       " 'sample_00007.npz',\n",
       " 'sample_00008.npz',\n",
       " 'sample_00000.npz',\n",
       " 'sample_00001.npz',\n",
       " 'sample_00002.npz',\n",
       " 'sample_00005.npz',\n",
       " 'sample_00003.npz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# cache_dir = os.path.join(save_dir, \"cached_states\")\n",
    "cache_dir = \"/disk/u/arnab/Codes/Projects/retrieval/results/selection/Llama-3.3-70B-Instruct/profession/cached_states/last_token/Llama-3.3-70B-Instruct\"\n",
    "os.listdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c722c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'states']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_states = np.load(os.path.join(cache_dir, \"sample_00001.npz\"), allow_pickle=True)\n",
    "sample_states.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2608020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-18 15:22:19,475] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2025-07-18 15:22:19 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -c /tmp/tmpclkskj1n/test.c -o /tmp/tmpclkskj1n/test.o\n",
      "2025-07-18 15:22:19 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat /tmp/tmpclkskj1n/test.o -laio -o /tmp/tmpclkskj1n/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-18 15:22:19 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -c /tmp/tmpk7_2kkp2/test.c -o /tmp/tmpk7_2kkp2/test.o\n",
      "2025-07-18 15:22:19 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat /tmp/tmpk7_2kkp2/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmpk7_2kkp2/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which person from the following list has the profession in common with Al Pacino?\n",
      "Caroline Garcia, Dak Prescott, Justin Bieber, Ryan Reynolds, Wolf Blitzer, Dmitry Bivol.\n",
      "Ans:\n",
      "(PredictedToken(token=' Ryan', prob=0.5625, logit=18.625, token_id=13960, metadata=None), PredictedToken(token=' None', prob=0.1611328125, logit=17.375, token_id=2290, metadata=None), PredictedToken(token=' Wolf', prob=0.05224609375, logit=16.25, token_id=26296, metadata=None), PredictedToken(token=' Al', prob=0.05224609375, logit=16.25, token_id=1708, metadata=None), PredictedToken(token=' The', prob=0.028076171875, logit=15.625, token_id=578, metadata=None))\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectionSample\n",
    "\n",
    "sample = SelectionSample.from_dict(sample_states[\"sample\"].item())\n",
    "print(sample.prompt)\n",
    "print(sample.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff7d53ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens_<>_-1': tensor([ 3.1233e-05,  2.3651e-03,  2.6855e-03,  ...,  8.6594e-04,\n",
       "         -2.4567e-03,  3.0975e-03]),\n",
       " 'model.layers.0_<>_-1': tensor([-0.0013,  0.0027,  0.0020,  ..., -0.0006, -0.0028, -0.0032]),\n",
       " 'model.layers.1_<>_-1': tensor([-0.0051,  0.0013,  0.0033,  ...,  0.0009, -0.0060, -0.0009]),\n",
       " 'model.layers.2_<>_-1': tensor([-0.0139, -0.0017, -0.0034,  ..., -0.0018,  0.0020, -0.0110]),\n",
       " 'model.layers.3_<>_-1': tensor([-0.0219,  0.0034,  0.0067,  ..., -0.0047,  0.0046, -0.0030]),\n",
       " 'model.layers.4_<>_-1': tensor([-0.0239, -0.0037,  0.0079,  ..., -0.0107,  0.0090, -0.0035]),\n",
       " 'model.layers.5_<>_-1': tensor([-0.0228, -0.0071,  0.0060,  ...,  0.0010,  0.0206, -0.0059]),\n",
       " 'model.layers.6_<>_-1': tensor([-0.0115,  0.0031,  0.0123,  ..., -0.0060,  0.0312, -0.0151]),\n",
       " 'model.layers.7_<>_-1': tensor([-0.0222,  0.0012,  0.0287,  ...,  0.0160,  0.0131, -0.0059]),\n",
       " 'model.layers.8_<>_-1': tensor([-0.0167,  0.0092,  0.0352,  ...,  0.0317,  0.0276,  0.0002]),\n",
       " 'model.layers.9_<>_-1': tensor([-0.0020,  0.0007,  0.0381,  ...,  0.0293,  0.0013, -0.0033]),\n",
       " 'model.layers.10_<>_-1': tensor([ 0.0064,  0.0020,  0.0403,  ...,  0.0305, -0.0094,  0.0010]),\n",
       " 'model.layers.11_<>_-1': tensor([ 0.0010,  0.0330,  0.0586,  ...,  0.0339, -0.0176, -0.0228]),\n",
       " 'model.layers.12_<>_-1': tensor([ 0.0198,  0.0293,  0.0728,  ...,  0.0272, -0.0166, -0.0203]),\n",
       " 'model.layers.13_<>_-1': tensor([ 0.0354,  0.0315,  0.0815,  ...,  0.0405, -0.0063, -0.0242]),\n",
       " 'model.layers.14_<>_-1': tensor([ 0.0079,  0.0334,  0.0723,  ...,  0.0444,  0.0454, -0.0034]),\n",
       " 'model.layers.15_<>_-1': tensor([ 0.0195,  0.0410,  0.1035,  ...,  0.0640,  0.0304, -0.0205]),\n",
       " 'model.layers.16_<>_-1': tensor([ 0.0222,  0.0167,  0.1328,  ...,  0.0376,  0.0374, -0.0068]),\n",
       " 'model.layers.17_<>_-1': tensor([ 0.0332,  0.0466,  0.0986,  ...,  0.0151,  0.0159, -0.0245]),\n",
       " 'model.layers.18_<>_-1': tensor([ 0.0264,  0.0562,  0.0693,  ...,  0.0200,  0.0547, -0.0339]),\n",
       " 'model.layers.19_<>_-1': tensor([ 0.0055,  0.0430,  0.0786,  ...,  0.0300,  0.0569, -0.0417]),\n",
       " 'model.layers.20_<>_-1': tensor([-0.0425,  0.0356,  0.0293,  ..., -0.0110,  0.0107, -0.0044]),\n",
       " 'model.layers.21_<>_-1': tensor([-0.0918,  0.0442,  0.0479,  ..., -0.0054,  0.0806, -0.0549]),\n",
       " 'model.layers.22_<>_-1': tensor([-0.0889,  0.0405,  0.0068,  ..., -0.0048,  0.1147, -0.0471]),\n",
       " 'model.layers.23_<>_-1': tensor([-0.1289,  0.0859, -0.0310,  ...,  0.0015,  0.1445,  0.0391]),\n",
       " 'model.layers.24_<>_-1': tensor([-0.0491,  0.0630,  0.0016,  ...,  0.0205,  0.0967,  0.0559]),\n",
       " 'model.layers.25_<>_-1': tensor([-0.0522,  0.0293,  0.0297,  ..., -0.0664,  0.1055,  0.0693]),\n",
       " 'model.layers.26_<>_-1': tensor([-0.0620,  0.0796,  0.0684,  ..., -0.0840,  0.0864,  0.1230]),\n",
       " 'model.layers.27_<>_-1': tensor([-0.0176,  0.0693,  0.0796,  ..., -0.0972,  0.0854,  0.0791]),\n",
       " 'model.layers.28_<>_-1': tensor([-0.0009, -0.0308, -0.0068,  ..., -0.1406,  0.0151,  0.0347]),\n",
       " 'model.layers.29_<>_-1': tensor([ 0.0075, -0.0977, -0.0186,  ..., -0.1406,  0.0967,  0.0664]),\n",
       " 'model.layers.30_<>_-1': tensor([-0.0583, -0.0562, -0.0118,  ..., -0.0786,  0.1108,  0.0640]),\n",
       " 'model.layers.31_<>_-1': tensor([-0.0625, -0.1113,  0.0410,  ..., -0.1006,  0.0938,  0.1079]),\n",
       " 'model.layers.32_<>_-1': tensor([-0.0737, -0.0806,  0.0947,  ..., -0.1934,  0.0669,  0.0654]),\n",
       " 'model.layers.33_<>_-1': tensor([-0.0483, -0.1001,  0.0425,  ..., -0.1484, -0.0139,  0.0625]),\n",
       " 'model.layers.34_<>_-1': tensor([-0.0298, -0.0923,  0.0535,  ..., -0.1865, -0.0466, -0.0115]),\n",
       " 'model.layers.35_<>_-1': tensor([-0.0076, -0.0503,  0.0181,  ..., -0.0918,  0.0254, -0.0068]),\n",
       " 'model.layers.36_<>_-1': tensor([-0.0159, -0.0161,  0.0125,  ..., -0.0376, -0.0474, -0.0522]),\n",
       " 'model.layers.37_<>_-1': tensor([-0.0352,  0.0830, -0.0203,  ..., -0.1123, -0.0664, -0.1050]),\n",
       " 'model.layers.38_<>_-1': tensor([ 0.0100,  0.0771, -0.0228,  ..., -0.0894, -0.0271, -0.0439]),\n",
       " 'model.layers.39_<>_-1': tensor([ 0.0762, -0.0239, -0.0532,  ..., -0.0015, -0.0359, -0.0295]),\n",
       " 'model.layers.40_<>_-1': tensor([ 0.0938,  0.0435, -0.0679,  ..., -0.0074, -0.1187, -0.0280]),\n",
       " 'model.layers.41_<>_-1': tensor([ 0.1279,  0.0278, -0.0967,  ...,  0.0135, -0.0742, -0.0415]),\n",
       " 'model.layers.42_<>_-1': tensor([ 0.0913,  0.0474, -0.1348,  ...,  0.0062, -0.0815, -0.0588]),\n",
       " 'model.layers.43_<>_-1': tensor([ 0.0112,  0.0679, -0.1904,  ...,  0.0134, -0.0330, -0.0630]),\n",
       " 'model.layers.44_<>_-1': tensor([-0.0051,  0.1206, -0.1992,  ...,  0.0359,  0.0078, -0.0618]),\n",
       " 'model.layers.45_<>_-1': tensor([ 0.0618,  0.2148, -0.0825,  ...,  0.0864, -0.0159, -0.0967]),\n",
       " 'model.layers.46_<>_-1': tensor([ 0.1035,  0.2539, -0.0996,  ...,  0.1123, -0.0061, -0.0723]),\n",
       " 'model.layers.47_<>_-1': tensor([ 0.1562,  0.1885, -0.1523,  ...,  0.1162, -0.0361, -0.0227]),\n",
       " 'model.layers.48_<>_-1': tensor([ 0.1094,  0.2275, -0.1699,  ...,  0.1689, -0.0771,  0.0505]),\n",
       " 'model.layers.49_<>_-1': tensor([ 0.1689,  0.2734, -0.2393,  ...,  0.2021, -0.0967,  0.0845]),\n",
       " 'model.layers.50_<>_-1': tensor([ 0.1650,  0.2891, -0.2754,  ...,  0.2480, -0.1123,  0.0664]),\n",
       " 'model.layers.51_<>_-1': tensor([ 0.1523,  0.3105, -0.3105,  ...,  0.2930, -0.1455,  0.0289]),\n",
       " 'model.layers.52_<>_-1': tensor([ 0.2002,  0.1992, -0.3496,  ...,  0.2148, -0.1123,  0.1260]),\n",
       " 'model.layers.53_<>_-1': tensor([ 0.2070,  0.2471, -0.2969,  ...,  0.1709, -0.0898,  0.1377]),\n",
       " 'model.layers.54_<>_-1': tensor([ 0.1836,  0.2188, -0.3438,  ...,  0.1582, -0.0618,  0.1279]),\n",
       " 'model.layers.55_<>_-1': tensor([ 0.2520,  0.2734, -0.3750,  ...,  0.1973, -0.0293,  0.0708]),\n",
       " 'model.layers.56_<>_-1': tensor([ 0.2969,  0.1387, -0.3730,  ...,  0.2432,  0.0095,  0.1045]),\n",
       " 'model.layers.57_<>_-1': tensor([ 0.3418,  0.1758, -0.3711,  ...,  0.2031, -0.0430,  0.0972]),\n",
       " 'model.layers.58_<>_-1': tensor([ 0.3711,  0.1641, -0.3887,  ...,  0.2061, -0.0623,  0.0527]),\n",
       " 'model.layers.59_<>_-1': tensor([ 0.3477,  0.2012, -0.4199,  ...,  0.2139, -0.0623,  0.0645]),\n",
       " 'model.layers.60_<>_-1': tensor([ 0.3848,  0.1699, -0.4707,  ...,  0.3047, -0.0535, -0.0015]),\n",
       " 'model.layers.61_<>_-1': tensor([ 0.4121,  0.1758, -0.4570,  ...,  0.3281, -0.0310,  0.0208]),\n",
       " 'model.layers.62_<>_-1': tensor([ 0.4023,  0.1211, -0.4141,  ...,  0.2637, -0.0674, -0.0383]),\n",
       " 'model.layers.63_<>_-1': tensor([ 0.3789,  0.1562, -0.5234,  ...,  0.3145, -0.0967, -0.0046]),\n",
       " 'model.layers.64_<>_-1': tensor([ 0.4004,  0.1670, -0.5781,  ...,  0.2207, -0.0515, -0.0928]),\n",
       " 'model.layers.65_<>_-1': tensor([ 0.3672,  0.2676, -0.5391,  ...,  0.1562, -0.0938, -0.0557]),\n",
       " 'model.layers.66_<>_-1': tensor([ 0.3750,  0.2461, -0.5273,  ...,  0.1650, -0.0349, -0.0386]),\n",
       " 'model.layers.67_<>_-1': tensor([ 0.4629,  0.3789, -0.6602,  ...,  0.0703, -0.1006, -0.0527]),\n",
       " 'model.layers.68_<>_-1': tensor([ 0.5039,  0.5117, -0.5508,  ...,  0.0752,  0.0781, -0.1006]),\n",
       " 'model.layers.69_<>_-1': tensor([ 0.5508,  0.4863, -0.5664,  ...,  0.1494,  0.0247, -0.1416]),\n",
       " 'model.layers.70_<>_-1': tensor([ 0.4258,  0.4922, -0.6172,  ...,  0.0269,  0.0344, -0.2090]),\n",
       " 'model.layers.71_<>_-1': tensor([ 0.4844,  0.3984, -0.5859,  ..., -0.0103,  0.0342, -0.1357]),\n",
       " 'model.layers.72_<>_-1': tensor([ 0.5000,  0.2598, -0.6250,  ...,  0.0010,  0.1484,  0.0032]),\n",
       " 'model.layers.73_<>_-1': tensor([ 0.3555,  0.1523, -0.6133,  ...,  0.0996,  0.1240,  0.1025]),\n",
       " 'model.layers.74_<>_-1': tensor([ 0.4395,  0.3105, -0.7344,  ...,  0.0684,  0.0200,  0.1250]),\n",
       " 'model.layers.75_<>_-1': tensor([ 0.5898,  0.1367, -0.7109,  ...,  0.1719,  0.0212, -0.0195]),\n",
       " 'model.layers.76_<>_-1': tensor([ 0.5898,  0.3594, -0.6367,  ...,  0.1299, -0.0532,  0.2715]),\n",
       " 'model.layers.77_<>_-1': tensor([ 0.3770,  0.4219, -0.5273,  ...,  0.1543,  0.0461,  0.0454]),\n",
       " 'model.layers.78_<>_-1': tensor([-0.4551,  0.3281, -0.3066,  ...,  0.3574, -0.4707,  0.0669]),\n",
       " 'model.layers.79_<>_-1': tensor([-0.2070, -0.2500,  0.0840,  ...,  0.0820,  0.0820, -0.0171]),\n",
       " 'model.layers.0.mlp_<>_-1': tensor([-0.0034, -0.0006,  0.0012,  ..., -0.0025, -0.0014,  0.0018]),\n",
       " 'model.layers.1.mlp_<>_-1': tensor([-4.8399e-05, -2.3651e-03,  2.1267e-04,  ..., -4.3869e-05,\n",
       "         -1.5335e-03,  7.5817e-05]),\n",
       " 'model.layers.2.mlp_<>_-1': tensor([-0.0031, -0.0007, -0.0028,  ..., -0.0012,  0.0006, -0.0092]),\n",
       " 'model.layers.3.mlp_<>_-1': tensor([-0.0089,  0.0064,  0.0068,  ..., -0.0030,  0.0012,  0.0095]),\n",
       " 'model.layers.4.mlp_<>_-1': tensor([-7.1106e-03,  4.7112e-04, -8.1635e-04,  ..., -6.9580e-03,\n",
       "         -2.2602e-04,  5.9843e-05]),\n",
       " 'model.layers.5.mlp_<>_-1': tensor([-0.0019, -0.0016, -0.0009,  ...,  0.0093,  0.0046, -0.0022]),\n",
       " 'model.layers.6.mlp_<>_-1': tensor([ 0.0061,  0.0118,  0.0074,  ..., -0.0054,  0.0107, -0.0059]),\n",
       " 'model.layers.7.mlp_<>_-1': tensor([-0.0145,  0.0070,  0.0095,  ...,  0.0154, -0.0162,  0.0154]),\n",
       " 'model.layers.8.mlp_<>_-1': tensor([-0.0045,  0.0145,  0.0139,  ...,  0.0045,  0.0182,  0.0142]),\n",
       " 'model.layers.9.mlp_<>_-1': tensor([ 0.0057,  0.0036,  0.0097,  ..., -0.0127, -0.0232, -0.0058]),\n",
       " 'model.layers.10.mlp_<>_-1': tensor([-0.0045,  0.0030,  0.0025,  ..., -0.0114, -0.0100,  0.0039]),\n",
       " 'model.layers.11.mlp_<>_-1': tensor([-0.0041,  0.0386,  0.0255,  ..., -0.0013, -0.0041, -0.0194]),\n",
       " 'model.layers.12.mlp_<>_-1': tensor([ 0.0102,  0.0012,  0.0074,  ..., -0.0072,  0.0090,  0.0011]),\n",
       " 'model.layers.13.mlp_<>_-1': tensor([ 0.0120,  0.0334,  0.0079,  ..., -0.0084,  0.0138,  0.0081]),\n",
       " 'model.layers.14.mlp_<>_-1': tensor([ 0.0084, -0.0054, -0.0006,  ...,  0.0088,  0.0344,  0.0347]),\n",
       " 'model.layers.15.mlp_<>_-1': tensor([ 0.0152,  0.0003,  0.0273,  ...,  0.0103, -0.0192, -0.0121]),\n",
       " 'model.layers.16.mlp_<>_-1': tensor([ 0.0013, -0.0189,  0.0222,  ..., -0.0288,  0.0098,  0.0160]),\n",
       " 'model.layers.17.mlp_<>_-1': tensor([ 0.0182,  0.0183, -0.0273,  ..., -0.0181, -0.0040,  0.0074]),\n",
       " 'model.layers.18.mlp_<>_-1': tensor([-0.0200,  0.0120, -0.0381,  ..., -0.0078,  0.0405, -0.0005]),\n",
       " 'model.layers.19.mlp_<>_-1': tensor([-0.0209,  0.0033, -0.0141,  ...,  0.0162,  0.0251, -0.0018]),\n",
       " 'model.layers.20.mlp_<>_-1': tensor([-0.0674, -0.0161, -0.0156,  ..., -0.0444, -0.0400,  0.0327]),\n",
       " 'model.layers.21.mlp_<>_-1': tensor([-0.0835,  0.0435,  0.0075,  ...,  0.0410,  0.0386, -0.0388]),\n",
       " 'model.layers.22.mlp_<>_-1': tensor([-0.0142, -0.0187, -0.0503,  ..., -0.0061,  0.0253, -0.0081]),\n",
       " 'model.layers.23.mlp_<>_-1': tensor([-0.0291,  0.0238,  0.0005,  ...,  0.0030, -0.0136,  0.0513]),\n",
       " 'model.layers.24.mlp_<>_-1': tensor([ 0.0315, -0.0303,  0.0204,  ...,  0.0153, -0.0613,  0.0102]),\n",
       " 'model.layers.25.mlp_<>_-1': tensor([ 0.0122, -0.0073,  0.0510,  ..., -0.0525,  0.0028,  0.0229]),\n",
       " 'model.layers.26.mlp_<>_-1': tensor([ 0.0002,  0.0840,  0.0198,  ..., -0.0176, -0.0244,  0.0149]),\n",
       " 'model.layers.27.mlp_<>_-1': tensor([ 0.0112,  0.0002,  0.0140,  ..., -0.0058, -0.0019, -0.0157]),\n",
       " 'model.layers.28.mlp_<>_-1': tensor([ 0.0181, -0.1025, -0.0801,  ..., -0.0025, -0.0557, -0.0303]),\n",
       " 'model.layers.29.mlp_<>_-1': tensor([ 0.0190, -0.0613, -0.0344,  ...,  0.0554,  0.0718,  0.0074]),\n",
       " 'model.layers.30.mlp_<>_-1': tensor([-0.0613,  0.0669, -0.0260,  ...,  0.0698,  0.0259,  0.0214]),\n",
       " 'model.layers.31.mlp_<>_-1': tensor([ 0.0098, -0.0175,  0.0330,  ..., -0.0199, -0.0674,  0.0449]),\n",
       " 'model.layers.32.mlp_<>_-1': tensor([ 0.0034,  0.0287,  0.0273,  ..., -0.0293, -0.0043, -0.0260]),\n",
       " 'model.layers.33.mlp_<>_-1': tensor([-0.0298, -0.0011, -0.0214,  ...,  0.0332, -0.0317,  0.0100]),\n",
       " 'model.layers.34.mlp_<>_-1': tensor([ 0.0203, -0.0197, -0.0099,  ..., -0.0223,  0.0074, -0.0532]),\n",
       " 'model.layers.35.mlp_<>_-1': tensor([-0.0234,  0.0400, -0.0325,  ..., -0.0195,  0.0330,  0.0317]),\n",
       " 'model.layers.36.mlp_<>_-1': tensor([ 0.0075,  0.0378, -0.0344,  ...,  0.0791, -0.0615, -0.0145]),\n",
       " 'model.layers.37.mlp_<>_-1': tensor([-0.0262,  0.0513, -0.0211,  ..., -0.0100, -0.0369, -0.0347]),\n",
       " 'model.layers.38.mlp_<>_-1': tensor([ 0.0439, -0.0349,  0.0040,  ...,  0.0056,  0.0325,  0.0718]),\n",
       " 'model.layers.39.mlp_<>_-1': tensor([ 0.0334, -0.0864, -0.0113,  ...,  0.0186, -0.0608,  0.0544]),\n",
       " 'model.layers.40.mlp_<>_-1': tensor([-0.0026,  0.0664, -0.0120,  ..., -0.0057, -0.0649,  0.0038]),\n",
       " 'model.layers.41.mlp_<>_-1': tensor([ 0.0359, -0.0322, -0.0088,  ...,  0.0007,  0.0312,  0.0014]),\n",
       " 'model.layers.42.mlp_<>_-1': tensor([-0.0210,  0.0198, -0.0493,  ..., -0.0085, -0.0332, -0.0090]),\n",
       " 'model.layers.43.mlp_<>_-1': tensor([-0.0718, -0.0131, -0.0359,  ...,  0.0143,  0.0583, -0.0226]),\n",
       " 'model.layers.44.mlp_<>_-1': tensor([-0.0134,  0.0562, -0.0015,  ..., -0.0077,  0.0452,  0.0027]),\n",
       " 'model.layers.45.mlp_<>_-1': tensor([ 0.0513,  0.0801,  0.0669,  ...,  0.0371, -0.0396, -0.0265]),\n",
       " 'model.layers.46.mlp_<>_-1': tensor([ 0.0332,  0.0352, -0.0342,  ...,  0.0183,  0.0137,  0.0157]),\n",
       " 'model.layers.47.mlp_<>_-1': tensor([ 0.0083, -0.0674, -0.0201,  ...,  0.0388, -0.0356,  0.0103]),\n",
       " 'model.layers.48.mlp_<>_-1': tensor([-0.0500,  0.0339, -0.0055,  ...,  0.0232, -0.0259,  0.0400]),\n",
       " 'model.layers.49.mlp_<>_-1': tensor([ 0.0388,  0.0742, -0.0596,  ...,  0.0452, -0.0344,  0.0300]),\n",
       " 'model.layers.50.mlp_<>_-1': tensor([-0.0104,  0.0077, -0.0369,  ...,  0.0378, -0.0040, -0.0183]),\n",
       " 'model.layers.51.mlp_<>_-1': tensor([ 0.0237, -0.0132, -0.0374,  ...,  0.0454, -0.0376, -0.0277]),\n",
       " 'model.layers.52.mlp_<>_-1': tensor([ 0.0410, -0.0122, -0.0151,  ..., -0.0957, -0.0255,  0.0312]),\n",
       " 'model.layers.53.mlp_<>_-1': tensor([ 0.0471,  0.0693, -0.0113,  ..., -0.0216, -0.0107, -0.0133]),\n",
       " 'model.layers.54.mlp_<>_-1': tensor([-0.0249, -0.0337, -0.0081,  ..., -0.0442,  0.0198,  0.0073]),\n",
       " 'model.layers.55.mlp_<>_-1': tensor([ 0.0437,  0.0400, -0.0151,  ...,  0.0251, -0.0102, -0.0192]),\n",
       " 'model.layers.56.mlp_<>_-1': tensor([ 0.0131, -0.0347, -0.0254,  ...,  0.0140, -0.0486,  0.0311]),\n",
       " 'model.layers.57.mlp_<>_-1': tensor([ 0.0014,  0.0251,  0.0134,  ..., -0.0267, -0.0488,  0.0109]),\n",
       " 'model.layers.58.mlp_<>_-1': tensor([ 0.0300, -0.0304,  0.0386,  ...,  0.0179,  0.0164, -0.0137]),\n",
       " 'model.layers.59.mlp_<>_-1': tensor([-0.0322,  0.0242, -0.0197,  ..., -0.0147, -0.0011,  0.0240]),\n",
       " 'model.layers.60.mlp_<>_-1': tensor([ 0.0229, -0.0347, -0.0369,  ...,  0.0625, -0.0195, -0.0444]),\n",
       " 'model.layers.61.mlp_<>_-1': tensor([-0.0126,  0.0082,  0.0060,  ...,  0.0420, -0.0047, -0.0038]),\n",
       " 'model.layers.62.mlp_<>_-1': tensor([-0.0150, -0.0447,  0.0334,  ..., -0.0503, -0.0371, -0.0562]),\n",
       " 'model.layers.63.mlp_<>_-1': tensor([-0.0449,  0.0325, -0.1240,  ...,  0.0481, -0.0220,  0.0242]),\n",
       " 'model.layers.64.mlp_<>_-1': tensor([ 0.0140, -0.0286, -0.0344,  ..., -0.0396,  0.0032, -0.0718]),\n",
       " 'model.layers.65.mlp_<>_-1': tensor([-0.0354,  0.0889,  0.0190,  ..., -0.0576, -0.0216,  0.1064]),\n",
       " 'model.layers.66.mlp_<>_-1': tensor([-0.0065, -0.0159,  0.0016,  ...,  0.0062,  0.0225,  0.0280]),\n",
       " 'model.layers.67.mlp_<>_-1': tensor([-0.0280,  0.0588,  0.0300,  ..., -0.0544, -0.0048, -0.0057]),\n",
       " 'model.layers.68.mlp_<>_-1': tensor([ 0.0747,  0.0581,  0.0018,  ...,  0.0225,  0.1191, -0.0452]),\n",
       " 'model.layers.69.mlp_<>_-1': tensor([ 0.0243, -0.0003,  0.0265,  ...,  0.0845, -0.0432, -0.0432]),\n",
       " 'model.layers.70.mlp_<>_-1': tensor([-0.1177,  0.0183, -0.0625,  ..., -0.1235, -0.0359, -0.0610]),\n",
       " 'model.layers.71.mlp_<>_-1': tensor([ 0.0286, -0.0713, -0.0009,  ..., -0.1260, -0.0615,  0.0104]),\n",
       " 'model.layers.72.mlp_<>_-1': tensor([-0.1167, -0.0337, -0.0083,  ...,  0.0126,  0.0117,  0.0588]),\n",
       " 'model.layers.73.mlp_<>_-1': tensor([-0.0659, -0.1021,  0.0315,  ...,  0.0291, -0.0247,  0.0386]),\n",
       " 'model.layers.74.mlp_<>_-1': tensor([ 0.0095,  0.1699, -0.0762,  ..., -0.1895, -0.1226,  0.0170]),\n",
       " 'model.layers.75.mlp_<>_-1': tensor([-0.0004, -0.0767,  0.0153,  ..., -0.0022, -0.0422, -0.1514]),\n",
       " 'model.layers.76.mlp_<>_-1': tensor([-0.0050,  0.2656,  0.0115,  ..., -0.0500, -0.1030,  0.1035]),\n",
       " 'model.layers.77.mlp_<>_-1': tensor([-0.1621,  0.0091,  0.0732,  ..., -0.0581, -0.0608, -0.1138]),\n",
       " 'model.layers.78.mlp_<>_-1': tensor([-0.8047, -0.0012,  0.1602,  ...,  0.0598, -0.3750, -0.0913]),\n",
       " 'model.layers.79.mlp_<>_-1': tensor([ 0.2773, -0.5469,  0.3008,  ..., -0.3281,  0.5078,  0.0078]),\n",
       " 'model.layers.0.self_attn_<>_-1': tensor([ 0.0021,  0.0009, -0.0018,  ...,  0.0011,  0.0011, -0.0081]),\n",
       " 'model.layers.1.self_attn_<>_-1': tensor([-0.0037,  0.0010,  0.0010,  ...,  0.0015, -0.0016,  0.0022]),\n",
       " 'model.layers.2.self_attn_<>_-1': tensor([-0.0057, -0.0023, -0.0039,  ..., -0.0015,  0.0074, -0.0010]),\n",
       " 'model.layers.3.self_attn_<>_-1': tensor([ 0.0010, -0.0013,  0.0033,  ...,  0.0002,  0.0014, -0.0015]),\n",
       " 'model.layers.4.self_attn_<>_-1': tensor([ 0.0051, -0.0076,  0.0019,  ...,  0.0009,  0.0046, -0.0005]),\n",
       " 'model.layers.5.self_attn_<>_-1': tensor([ 0.0030, -0.0018, -0.0010,  ...,  0.0024,  0.0070, -0.0002]),\n",
       " 'model.layers.6.self_attn_<>_-1': tensor([ 0.0052, -0.0016, -0.0011,  ..., -0.0017, -0.0002, -0.0034]),\n",
       " 'model.layers.7.self_attn_<>_-1': tensor([ 0.0038, -0.0089,  0.0068,  ...,  0.0066, -0.0019, -0.0060]),\n",
       " 'model.layers.8.self_attn_<>_-1': tensor([ 0.0099, -0.0065, -0.0075,  ...,  0.0114, -0.0037, -0.0081]),\n",
       " 'model.layers.9.self_attn_<>_-1': tensor([ 0.0090, -0.0120, -0.0069,  ...,  0.0104, -0.0031,  0.0023]),\n",
       " 'model.layers.10.self_attn_<>_-1': tensor([ 0.0131, -0.0017, -0.0002,  ...,  0.0128, -0.0007,  0.0004]),\n",
       " 'model.layers.11.self_attn_<>_-1': tensor([-0.0014, -0.0077, -0.0070,  ...,  0.0047, -0.0041, -0.0044]),\n",
       " 'model.layers.12.self_attn_<>_-1': tensor([ 0.0087, -0.0049,  0.0066,  ...,  0.0004, -0.0081,  0.0015]),\n",
       " 'model.layers.13.self_attn_<>_-1': tensor([ 0.0036, -0.0312,  0.0010,  ...,  0.0217, -0.0035, -0.0120]),\n",
       " 'model.layers.14.self_attn_<>_-1': tensor([-0.0359,  0.0073, -0.0089,  ..., -0.0048,  0.0172, -0.0139]),\n",
       " 'model.layers.15.self_attn_<>_-1': tensor([-0.0035,  0.0074,  0.0038,  ...,  0.0092,  0.0041, -0.0050]),\n",
       " 'model.layers.16.self_attn_<>_-1': tensor([ 0.0014, -0.0054,  0.0066,  ...,  0.0023, -0.0028, -0.0023]),\n",
       " 'model.layers.17.self_attn_<>_-1': tensor([-0.0074,  0.0115, -0.0068,  ..., -0.0045, -0.0175, -0.0251]),\n",
       " 'model.layers.18.self_attn_<>_-1': tensor([ 0.0132, -0.0024,  0.0087,  ...,  0.0127, -0.0018, -0.0089]),\n",
       " 'model.layers.19.self_attn_<>_-1': tensor([ 4.1962e-05, -1.6602e-02,  2.3560e-02,  ..., -6.2561e-03,\n",
       "         -2.2949e-02, -6.1035e-03]),\n",
       " 'model.layers.20.self_attn_<>_-1': tensor([ 0.0195,  0.0089, -0.0337,  ...,  0.0034, -0.0061,  0.0046]),\n",
       " 'model.layers.21.self_attn_<>_-1': tensor([ 0.0344, -0.0349,  0.0109,  ..., -0.0354,  0.0312, -0.0118]),\n",
       " 'model.layers.22.self_attn_<>_-1': tensor([0.0170, 0.0151, 0.0094,  ..., 0.0066, 0.0089, 0.0157]),\n",
       " 'model.layers.23.self_attn_<>_-1': tensor([-0.0108,  0.0217, -0.0383,  ...,  0.0033,  0.0439,  0.0349]),\n",
       " 'model.layers.24.self_attn_<>_-1': tensor([0.0483, 0.0072, 0.0122,  ..., 0.0037, 0.0140, 0.0067]),\n",
       " 'model.layers.25.self_attn_<>_-1': tensor([-0.0153, -0.0265, -0.0229,  ..., -0.0342,  0.0057, -0.0093]),\n",
       " 'model.layers.26.self_attn_<>_-1': tensor([-1.0010e-02, -3.3691e-02,  1.8921e-02,  ..., -7.1526e-05,\n",
       "          5.3101e-03,  3.9307e-02]),\n",
       " 'model.layers.27.self_attn_<>_-1': tensor([ 0.0332, -0.0100, -0.0027,  ..., -0.0071,  0.0011, -0.0282]),\n",
       " 'model.layers.28.self_attn_<>_-1': tensor([-0.0014,  0.0024, -0.0062,  ..., -0.0405, -0.0146, -0.0143]),\n",
       " 'model.layers.29.self_attn_<>_-1': tensor([-0.0107, -0.0058,  0.0227,  ..., -0.0557,  0.0095,  0.0245]),\n",
       " 'model.layers.30.self_attn_<>_-1': tensor([-0.0047, -0.0255,  0.0327,  ..., -0.0076, -0.0118, -0.0240]),\n",
       " 'model.layers.31.self_attn_<>_-1': tensor([-0.0139, -0.0374,  0.0200,  ..., -0.0017,  0.0505, -0.0011]),\n",
       " 'model.layers.32.self_attn_<>_-1': tensor([-0.0148,  0.0020,  0.0266,  ..., -0.0640, -0.0227, -0.0166]),\n",
       " 'model.layers.33.self_attn_<>_-1': tensor([ 0.0552, -0.0187, -0.0308,  ...,  0.0115, -0.0491, -0.0129]),\n",
       " 'model.layers.34.self_attn_<>_-1': tensor([-0.0017,  0.0275,  0.0211,  ..., -0.0155, -0.0400, -0.0208]),\n",
       " 'model.layers.35.self_attn_<>_-1': tensor([ 0.0457,  0.0022, -0.0030,  ...,  0.1143,  0.0391, -0.0270]),\n",
       " 'model.layers.36.self_attn_<>_-1': tensor([-0.0159, -0.0038,  0.0288,  ..., -0.0249, -0.0112, -0.0306]),\n",
       " 'model.layers.37.self_attn_<>_-1': tensor([ 0.0071,  0.0476, -0.0115,  ..., -0.0649,  0.0181, -0.0181]),\n",
       " 'model.layers.38.self_attn_<>_-1': tensor([ 0.0012,  0.0289, -0.0066,  ...,  0.0176,  0.0068, -0.0106]),\n",
       " 'model.layers.39.self_attn_<>_-1': tensor([ 0.0327, -0.0148, -0.0190,  ...,  0.0693,  0.0520, -0.0398]),\n",
       " 'model.layers.40.self_attn_<>_-1': tensor([ 0.0201,  0.0010, -0.0026,  ..., -0.0003, -0.0178, -0.0023]),\n",
       " 'model.layers.41.self_attn_<>_-1': tensor([-0.0020,  0.0165, -0.0200,  ...,  0.0203,  0.0134, -0.0151]),\n",
       " 'model.layers.42.self_attn_<>_-1': tensor([-0.0156, -0.0002,  0.0110,  ...,  0.0012,  0.0259, -0.0084]),\n",
       " 'model.layers.43.self_attn_<>_-1': tensor([-0.0085,  0.0339, -0.0198,  ..., -0.0070, -0.0099,  0.0184]),\n",
       " 'model.layers.44.self_attn_<>_-1': tensor([-0.0029, -0.0033, -0.0067,  ...,  0.0303, -0.0045, -0.0016]),\n",
       " 'model.layers.45.self_attn_<>_-1': tensor([ 0.0156,  0.0138,  0.0500,  ...,  0.0135,  0.0159, -0.0083]),\n",
       " 'model.layers.46.self_attn_<>_-1': tensor([ 0.0083,  0.0046,  0.0173,  ...,  0.0071, -0.0039,  0.0089]),\n",
       " 'model.layers.47.self_attn_<>_-1': tensor([ 0.0454,  0.0013, -0.0325,  ..., -0.0352,  0.0056,  0.0393]),\n",
       " 'model.layers.48.self_attn_<>_-1': tensor([ 0.0027,  0.0046, -0.0119,  ...,  0.0291, -0.0151,  0.0332]),\n",
       " 'model.layers.49.self_attn_<>_-1': tensor([ 0.0209, -0.0294, -0.0103,  ..., -0.0121,  0.0147,  0.0039]),\n",
       " 'model.layers.50.self_attn_<>_-1': tensor([ 0.0067,  0.0085,  0.0005,  ...,  0.0078, -0.0119,  0.0004]),\n",
       " 'model.layers.51.self_attn_<>_-1': tensor([-0.0361,  0.0347,  0.0019,  ..., -0.0006,  0.0042, -0.0098]),\n",
       " 'model.layers.52.self_attn_<>_-1': tensor([ 0.0066, -0.0986, -0.0239,  ...,  0.0179,  0.0586,  0.0659]),\n",
       " 'model.layers.53.self_attn_<>_-1': tensor([-0.0403, -0.0214,  0.0640,  ..., -0.0228,  0.0334,  0.0253]),\n",
       " 'model.layers.54.self_attn_<>_-1': tensor([ 0.0008,  0.0042, -0.0396,  ...,  0.0315,  0.0084, -0.0164]),\n",
       " 'model.layers.55.self_attn_<>_-1': tensor([ 0.0253,  0.0152, -0.0153,  ...,  0.0133,  0.0427, -0.0378]),\n",
       " 'model.layers.56.self_attn_<>_-1': tensor([ 0.0304, -0.0996,  0.0270,  ...,  0.0320,  0.0874,  0.0025]),\n",
       " 'model.layers.57.self_attn_<>_-1': tensor([ 0.0422,  0.0120, -0.0109,  ..., -0.0137, -0.0038, -0.0182]),\n",
       " 'model.layers.58.self_attn_<>_-1': tensor([-0.0002,  0.0183, -0.0574,  ..., -0.0143, -0.0356, -0.0309]),\n",
       " 'model.layers.59.self_attn_<>_-1': tensor([ 0.0082,  0.0131, -0.0124,  ...,  0.0229,  0.0010, -0.0123]),\n",
       " 'model.layers.60.self_attn_<>_-1': tensor([ 0.0138,  0.0031, -0.0136,  ...,  0.0282,  0.0283, -0.0214]),\n",
       " 'model.layers.61.self_attn_<>_-1': tensor([ 0.0398, -0.0018,  0.0076,  ..., -0.0197,  0.0271,  0.0261]),\n",
       " 'model.layers.62.self_attn_<>_-1': tensor([ 0.0059, -0.0100,  0.0100,  ..., -0.0140,  0.0005, -0.0029]),\n",
       " 'model.layers.63.self_attn_<>_-1': tensor([ 0.0206,  0.0029,  0.0134,  ...,  0.0020, -0.0074,  0.0096]),\n",
       " 'model.layers.64.self_attn_<>_-1': tensor([ 0.0087,  0.0386, -0.0208,  ..., -0.0547,  0.0420, -0.0161]),\n",
       " 'model.layers.65.self_attn_<>_-1': tensor([ 0.0019,  0.0120,  0.0179,  ..., -0.0068, -0.0208, -0.0698]),\n",
       " 'model.layers.66.self_attn_<>_-1': tensor([ 0.0146, -0.0053,  0.0123,  ...,  0.0028,  0.0364, -0.0110]),\n",
       " 'model.layers.67.self_attn_<>_-1': tensor([ 0.1152,  0.0732, -0.1631,  ..., -0.0405, -0.0608, -0.0086]),\n",
       " 'model.layers.68.self_attn_<>_-1': tensor([-0.0330,  0.0747,  0.1099,  ..., -0.0173,  0.0593, -0.0024]),\n",
       " 'model.layers.69.self_attn_<>_-1': tensor([ 0.0248, -0.0254, -0.0449,  ..., -0.0102, -0.0103,  0.0023]),\n",
       " 'model.layers.70.self_attn_<>_-1': tensor([-0.0067, -0.0121,  0.0130,  ...,  0.0008,  0.0454, -0.0059]),\n",
       " 'model.layers.71.self_attn_<>_-1': tensor([ 0.0297, -0.0208,  0.0322,  ...,  0.0889,  0.0613,  0.0623]),\n",
       " 'model.layers.72.self_attn_<>_-1': tensor([ 0.1338, -0.1050, -0.0315,  ..., -0.0014,  0.1025,  0.0801]),\n",
       " 'model.layers.73.self_attn_<>_-1': tensor([-0.0776, -0.0056, -0.0178,  ...,  0.0698, -0.0001,  0.0608]),\n",
       " 'model.layers.74.self_attn_<>_-1': tensor([ 0.0732, -0.0122, -0.0474,  ...,  0.1572,  0.0182,  0.0054]),\n",
       " 'model.layers.75.self_attn_<>_-1': tensor([ 0.1504, -0.0972,  0.0094,  ...,  0.1055,  0.0435,  0.0069]),\n",
       " 'model.layers.76.self_attn_<>_-1': tensor([ 0.0052, -0.0432,  0.0613,  ...,  0.0078,  0.0287,  0.1875]),\n",
       " 'model.layers.77.self_attn_<>_-1': tensor([-0.0508,  0.0525,  0.0356,  ...,  0.0825,  0.1602, -0.1123]),\n",
       " 'model.layers.78.self_attn_<>_-1': tensor([-0.0269, -0.0913,  0.0598,  ...,  0.1436, -0.1416,  0.1133]),\n",
       " 'model.layers.79.self_attn_<>_-1': tensor([-0.0300, -0.0303,  0.0903,  ...,  0.0532,  0.0449, -0.0918])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = {\n",
    "    layer_name: torch.Tensor(value)\n",
    "    for layer_name, value in sample_states[\"states\"].item().items()\n",
    "}\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb110948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
