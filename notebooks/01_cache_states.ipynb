{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53344a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb576a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9263517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import free_gpu_cache\n",
    "\n",
    "# SYNTH_DATASET = \"icosahedron_1\"\n",
    "SYNTH_DATASET = \"64\"\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"trained_params\",\n",
    "    f\"{SYNTH_DATASET}\",\n",
    "    \"_full__clamp=0.001\",\n",
    "    model_key.split(\"/\")[-1],\n",
    ")\n",
    "\n",
    "version = \"epoch_1\"\n",
    "# version = \"final_model\"\n",
    "\n",
    "checkpoint_path = os.path.join(env_utils.DEFAULT_RESULTS_DIR, checkpoint_path, version)\n",
    "\n",
    "print(os.listdir(checkpoint_path))\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"trainable_params.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "# loaded_deltas\n",
    "\n",
    "free_gpu_cache()\n",
    "\n",
    "\n",
    "d = loaded_deltas[\"model<>layers<>10<>mlp<>gate_proj\"]\n",
    "d.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "#################################################\n",
    "Trainable_CLS = TrainableLM_delta\n",
    "# Trainable_CLS = TrainableLM_LoRA\n",
    "#################################################\n",
    "\n",
    "Trainable_CLS.fuse_with_model(mt._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd6845",
   "metadata": {},
   "source": [
    "## Generate samples and filter by LM knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data  import load_people_by_category_fakeverse\n",
    "\n",
    "people_by_category = load_people_by_category_fakeverse(tokenizer = mt.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectionSample, get_random_sample\n",
    "\n",
    "sample = get_random_sample(\n",
    "    people_by_category = people_by_category,\n",
    "    mt = mt,\n",
    "    n_distractors=5,\n",
    "    get_alt_obj=False,\n",
    "    # category=\"actor\",\n",
    "    obj_idx=3,\n",
    "    filter_by_lm_prediction=True\n",
    ")\n",
    "print(sample)\n",
    "print(sample.prompt)\n",
    "sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a00588",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "save_dir = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR, \"selection\", mt.name.split(\"/\")[-1], \"profession\"\n",
    ")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_name = \"filtered_samples.json\"\n",
    "\n",
    "LIMIT = 12000\n",
    "N_DISTRACTORS = 5\n",
    "SAVE_STEP = 100\n",
    "##########################################################\n",
    "\n",
    "from src.utils.experiment_utils import set_seed\n",
    "set_seed(123456)\n",
    "\n",
    "filtered_samples = []\n",
    "while len(filtered_samples) < LIMIT:\n",
    "    sample = get_random_sample(\n",
    "        people_by_category=people_by_category,\n",
    "        mt=mt,\n",
    "        n_distractors=N_DISTRACTORS,\n",
    "        get_alt_obj=False,\n",
    "        filter_by_lm_prediction=True\n",
    "    )\n",
    "    sample.detensorize()\n",
    "    filtered_samples.append(sample)\n",
    "    print(f\"Collected {len(filtered_samples)}/{LIMIT} samples. {len(filtered_samples) / LIMIT * 100:.2f}%\")\n",
    "\n",
    "    if len(filtered_samples) % SAVE_STEP == 0 or len(filtered_samples) == LIMIT:\n",
    "        print(f\"Saving {len(filtered_samples)} samples to {os.path.join(save_dir, file_name)}\")\n",
    "        with open(os.path.join(save_dir, file_name), \"w\") as f:\n",
    "            json.dump([s.to_dict() for s in filtered_samples], f, indent=2)\n",
    "\n",
    "# with open(os.path.join(save_dir, file_name), \"w\") as f:\n",
    "#     json.dump([s.to_dict() for s in filtered_samples], f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"filtered_samples.json\"), \"r\") as f:\n",
    "    loaded_samples = json.load(f)\n",
    "loaded_samples = [SelectionSample.from_dict(s) for s in loaded_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_samples[0].prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ffdbb",
   "metadata": {},
   "source": [
    "## Cache last token states for the generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"filtered_samples.json\"), \"r\") as f:\n",
    "    filtered_samples = json.load(f)\n",
    "filtered_samples = [SelectionSample.from_dict(s) for s in filtered_samples]\n",
    "\n",
    "len(filtered_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a43ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "cache_dir = os.path.join(save_dir, \"cached_states\")\n",
    "\n",
    "all_layers = (\n",
    "    [mt.embedder_name]  # embeddings\n",
    "    + mt.layer_names  # residual\n",
    "    + [mt.mlp_module_name_format.format(i) for i in range(mt.n_layer)]  # mlp outputs\n",
    "    + [mt.attn_module_name_format.format(i) for i in range(mt.n_layer)]  # attn outputs\n",
    ")\n",
    "TOKEN_POSITION = -1\n",
    "\n",
    "locations = [(layer_name, TOKEN_POSITION) for layer_name in all_layers]\n",
    "#######################################################################################\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "from src.utils.typing import TokenizerOutput\n",
    "from src.functional import get_hs, detensorize\n",
    "from src.tokens import prepare_input\n",
    "\n",
    "for idx, sample in enumerate(filtered_samples):\n",
    "    # inputs = TokenizerOutput(data = sample.metadata[\"tokenized\"]).to(mt.device)\n",
    "    inputs = prepare_input(prompts=sample.prompt, tokenizer=mt)\n",
    "    sample.detensorize()\n",
    "\n",
    "    cache = {\"sample\": sample.to_dict(), \"states\": {}}\n",
    "    states = get_hs(\n",
    "        mt=mt,\n",
    "        input=inputs,\n",
    "        locations=locations,\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    for (layer_name, tok_idx), state in states.items():\n",
    "        cache[\"states\"][layer_name] = state.detach().to(torch.float32).cpu().numpy()\n",
    "\n",
    "    cache = detensorize(cache)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(cache_dir, f\"sample_{idx}.npz\"), **cache, allow_pickle=True\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        f\"Processed sample {idx + 1}/{len(filtered_samples)} ({(idx + 1) / len(filtered_samples) * 100:.2f}%)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 5\n",
    "print(f\"{val:05d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4329ba",
   "metadata": {},
   "source": [
    "### Testing by loading the cached states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# cache_dir = os.path.join(save_dir, \"cached_states\")\n",
    "cache_dir = \"/disk/u/arnab/Codes/Projects/retrieval/results/selection/Llama-3.3-70B-Instruct/profession/cached_states/last_token/Llama-3.3-70B-Instruct\"\n",
    "os.listdir(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c722c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_states = np.load(os.path.join(cache_dir, \"sample_00001.npz\"), allow_pickle=True)\n",
    "sample_states.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectionSample\n",
    "\n",
    "sample = SelectionSample.from_dict(sample_states[\"sample\"].item())\n",
    "print(sample.prompt)\n",
    "print(sample.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "    layer_name: torch.Tensor(value)\n",
    "    for layer_name, value in sample_states[\"states\"].item().items()\n",
    "}\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb110948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
