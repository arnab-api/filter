{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef0279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31 13:19:42 __main__ INFO     torch.__version__='2.8.0+cu128', torch.version.cuda='12.8'\n",
      "2025-08-31 13:19:42 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-08-31 13:19:42 __main__ INFO     transformers.__version__='4.54.1'\n",
      "2025-08-31 13:19:46 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/gio/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-08-31 13:19:46 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/gio/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "{'model.embed_tokens': 7, 'model.norm': 7, 'model.rotary_emb': 7, 'lm_head': 7, 'model.layers.0': 0, 'model.layers.1': 1, 'model.layers.2': 2, 'model.layers.3': 3, 'model.layers.4': 4, 'model.layers.5': 5, 'model.layers.6': 6, 'model.layers.7': 7, 'model.layers.8': 0, 'model.layers.9': 1, 'model.layers.10': 2, 'model.layers.11': 3, 'model.layers.12': 4, 'model.layers.13': 5, 'model.layers.14': 6, 'model.layers.15': 7, 'model.layers.16': 0, 'model.layers.17': 1, 'model.layers.18': 2, 'model.layers.19': 3, 'model.layers.20': 4, 'model.layers.21': 5, 'model.layers.22': 6, 'model.layers.23': 7, 'model.layers.24': 0, 'model.layers.25': 1, 'model.layers.26': 2, 'model.layers.27': 3, 'model.layers.28': 4, 'model.layers.29': 5, 'model.layers.30': 6, 'model.layers.31': 7, 'model.layers.32': 0, 'model.layers.33': 1, 'model.layers.34': 2, 'model.layers.35': 3, 'model.layers.36': 4, 'model.layers.37': 5, 'model.layers.38': 6, 'model.layers.39': 7, 'model.layers.40': 0, 'model.layers.41': 1, 'model.layers.42': 2, 'model.layers.43': 3, 'model.layers.44': 4, 'model.layers.45': 5, 'model.layers.46': 6, 'model.layers.47': 7, 'model.layers.48': 0, 'model.layers.49': 1, 'model.layers.50': 2, 'model.layers.51': 3, 'model.layers.52': 4, 'model.layers.53': 5, 'model.layers.54': 6, 'model.layers.55': 7, 'model.layers.56': 0, 'model.layers.57': 1, 'model.layers.58': 2, 'model.layers.59': 3, 'model.layers.60': 4, 'model.layers.61': 5, 'model.layers.62': 6, 'model.layers.63': 7, 'model.layers.64': 0, 'model.layers.65': 1, 'model.layers.66': 2, 'model.layers.67': 3, 'model.layers.68': 4, 'model.layers.69': 5, 'model.layers.70': 6, 'model.layers.71': 7, 'model.layers.72': 0, 'model.layers.73': 1, 'model.layers.74': 2, 'model.layers.75': 3, 'model.layers.76': 4, 'model.layers.77': 5, 'model.layers.78': 6, 'model.layers.79': 7}\n",
      "/disk/u/gio/mechinterp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60aa764ced61454c8da687d3cedfd2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31 13:21:08 src.models INFO     loaded model <models/meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")\n",
    "\n",
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "device_map = get_device_map(model_key, 32, n_gpus=8)\n",
    "print(device_map)\n",
    "\n",
    "os.chdir(\"/disk/u/gio/mechinterp\")\n",
    "print(os.getcwd())\n",
    "\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    "    attn_implementation=\"eager\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42668b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk/u/gio/retrieval\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/disk/u/gio/retrieval\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d16d1f",
   "metadata": {},
   "source": [
    "## Load the optimized heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17df37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31 13:21:52 matplotlib DEBUG    CACHEDIR=/disk/u/gio/.cache/matplotlib\n",
      "2025-08-31 13:21:52 matplotlib.font_manager DEBUG    Using fontManager instance from /disk/u/gio/.cache/matplotlib/fontlist-v390.json\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "optimized_path = os.path.join(\n",
    "    \"/disk/u/arnab/Codes/Projects/retrieval/results\",\n",
    "    \"selection/optimized_heads\",\n",
    "    mt.name.split(\"/\")[-1],\n",
    "    \"odd_one_out__not_patch_category.npz\"\n",
    ")\n",
    "\n",
    "optimization_results = np.load(optimized_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_head_mask = torch.tensor(optimization_results[\"optimal_mask\"]).to(torch.float32)\n",
    "heads_selected = torch.nonzero(optimal_head_mask > 0.5, as_tuple=False).tolist()\n",
    "heads_selected = [(layer_idx, head_idx) for layer_idx, head_idx in heads_selected if layer_idx < 50]\n",
    "print(len(heads_selected))\n",
    "\n",
    "HEADS = heads_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23d69a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from src.selection.utils import KeyedSet, get_first_token_id, verify_correct_option\n",
    "from src.selection.data import SelectionSample\n",
    "from src.tokens import prepare_input\n",
    "from src.selection.data import SelectOddOneOutTask\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_counterfactual_samples_odd_one_out(\n",
    "    task: SelectOddOneOutTask,\n",
    "    obj_category: str | None = None,\n",
    "    distractor_category: str | None = None,\n",
    "    prompt_template_idx=3,\n",
    "    option_style=\"single_line\",\n",
    "    filter_by_lm_prediction: bool = True,\n",
    "    n_distractors: int = 5,\n",
    "    counterfact_obj_idx: int | None = None,\n",
    "    verbose=True,\n",
    "):\n",
    "    obj_category = obj_category or random.choice(task.categories)\n",
    "    distractor_category = distractor_category or random.choice(\n",
    "        list(set(task.categories) - {obj_category})\n",
    "    )\n",
    "    assert obj_category != distractor_category, f\"{obj_category=} {distractor_category=}\"\n",
    "\n",
    "    if verbose:\n",
    "        logger.info(\n",
    "            f\"obj_category={obj_category}, distractor_category={distractor_category}, prompt_template_idx={prompt_template_idx}, option_style={option_style}, n_distractors={n_distractors}\"\n",
    "        )\n",
    "\n",
    "    patch_sample = task.get_random_sample(\n",
    "        mt=mt,\n",
    "        option_style=option_style,\n",
    "        prompt_template_idx=prompt_template_idx,\n",
    "        obj_category=obj_category,\n",
    "        distractor_category=distractor_category,\n",
    "        filter_by_lm_prediction=False,\n",
    "        n_distractors=n_distractors,\n",
    "        obj_idx = random.choice(list(set(list(range(n_distractors + 1))) - {0, 1}))\n",
    "    )\n",
    "    if verbose: logger.info(f\"patch_sample={str(patch_sample)}\")\n",
    "\n",
    "    #! criterion = not distractor_category\n",
    "    # Options (2): \n",
    "    # 1. distractor_category (selected)\n",
    "    # 2. category not in [obj_category, distractor_category] \n",
    "    not_dist_category_sample = task.get_random_sample(\n",
    "        mt=mt,\n",
    "        option_style=option_style,\n",
    "        prompt_template_idx=prompt_template_idx,\n",
    "        obj_category=distractor_category,\n",
    "        distractor_category=random.choice(\n",
    "            list(set(task.categories) - {obj_category, distractor_category})\n",
    "        ),\n",
    "        filter_by_lm_prediction=False,\n",
    "        exclude_objs=patch_sample.options,\n",
    "        n_distractors=1,\n",
    "        obj_idx=counterfact_obj_idx\n",
    "    )\n",
    "    if verbose: logger.info(f\"not_dist_category_sample={str(not_dist_category_sample)}\")\n",
    "    track_idx = 1 ^ not_dist_category_sample.obj_idx\n",
    "    not_dist_category_sample.metadata = {\n",
    "        \"track_type_obj\": not_dist_category_sample.options[track_idx],\n",
    "        \"track_type_obj_idx\": track_idx,\n",
    "        \"track_type_obj_token_id\": get_first_token_id(\n",
    "            not_dist_category_sample.options[track_idx], mt.tokenizer, prefix=\" \"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    #! criterion = is obj_category\n",
    "    # Options (2):\n",
    "    # 1. obj_category\n",
    "    # 2. category not in [obj_category, distractor_category] (selected)\n",
    "    is_obj_category_sample = task.get_random_sample(\n",
    "        mt=mt,\n",
    "        option_style=option_style,\n",
    "        prompt_template_idx=prompt_template_idx,\n",
    "        distractor_category=obj_category,\n",
    "        obj_category=random.choice(\n",
    "            list(set(task.categories) - {obj_category, distractor_category})\n",
    "        ),\n",
    "        filter_by_lm_prediction=False,\n",
    "        exclude_objs=patch_sample.options,\n",
    "        n_distractors=1,\n",
    "        obj_idx=counterfact_obj_idx\n",
    "    )\n",
    "    if verbose: logger.info(f\"is_obj_category_sample={str(is_obj_category_sample)}\")\n",
    "    track_idx = 1 ^ is_obj_category_sample.obj_idx\n",
    "    is_obj_category_sample.metadata = {\n",
    "        \"track_type_obj_idx\": track_idx,\n",
    "        \"track_type_obj\": is_obj_category_sample.options[track_idx],\n",
    "        \"track_type_obj_category\": obj_category,\n",
    "        \"track_type_obj_token_id\": get_first_token_id(\n",
    "            is_obj_category_sample.options[track_idx], mt.tokenizer, prefix=\" \"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    if filter_by_lm_prediction:\n",
    "        test_samples = [patch_sample, not_dist_category_sample, is_obj_category_sample]\n",
    "\n",
    "        for sample in test_samples:\n",
    "            tokenized = prepare_input(tokenizer=mt, prompts=sample.prompt())\n",
    "            is_correct, predictions, track_options = verify_correct_option(\n",
    "                mt=mt, target=sample.obj, options=sample.options, input=tokenized\n",
    "            )\n",
    "            sample.metadata[\"tokenized\"] = tokenized.data\n",
    "            if verbose:\n",
    "                logger.info(sample.prompt())\n",
    "                logger.info(\n",
    "                    f\"{sample.subj} | {sample.category} -> {sample.obj} | pred={[str(p) for p in predictions]}\"\n",
    "                )\n",
    "            if not is_correct:\n",
    "                if verbose:\n",
    "                    logger.error(\n",
    "                        f'Prediction mismatch: {track_options[list(track_options.keys())[0]]}[\"{mt.tokenizer.decode(predictions[0].token_id)}\"] != {sample.ans_token_id}[\"{mt.tokenizer.decode(sample.ans_token_id)}\"]'\n",
    "                    )\n",
    "                return get_counterfactual_samples_odd_one_out(\n",
    "                    task=task,\n",
    "                    obj_category=obj_category,\n",
    "                    distractor_category=distractor_category,\n",
    "                    prompt_template_idx=prompt_template_idx,\n",
    "                    option_style=option_style,\n",
    "                    filter_by_lm_prediction=filter_by_lm_prediction,\n",
    "                    n_distractors=n_distractors,\n",
    "                )\n",
    "            sample.prediction = predictions\n",
    "\n",
    "    return {\n",
    "        \"patch_sample\": patch_sample,\n",
    "        \"not_dist_category_sample\": not_dist_category_sample,\n",
    "        \"is_obj_category_sample\": is_obj_category_sample\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658b5fa",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "386b6226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectOddOneOutTask: (different objects)\n",
      "Categories: fruit(14), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectOddOneOutTask\n",
    "\n",
    "select_odd_one = SelectOddOneOutTask.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR,\n",
    "        \"selection\",\n",
    "        \"objects2.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(select_odd_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c7921b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distractor_category=\"fruit\"\n",
    "obj_category=\"electronics\"\n",
    "option_style=\"single_line\"\n",
    "prompt_template_idx=3\n",
    "N_DISTRACTORS=5\n",
    "counterfact_obj_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "844195a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truck -> Television (2): ['Ambulance', 'Scooter', 'Television', 'Train', 'Airplane', 'Submarine']\n",
      "Folder -> Bus (0): ['Bus', 'Notebook']\n",
      "Tablet -> Locket (1): ['Speaker', 'Locket']\n"
     ]
    }
   ],
   "source": [
    "exp_samples = get_counterfactual_samples_odd_one_out(\n",
    "    task=select_odd_one,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    option_style=option_style,\n",
    "    filter_by_lm_prediction=True,\n",
    "    n_distractors=5,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "patch_sample = exp_samples[\"patch_sample\"]\n",
    "not_dist_category_sample = exp_samples[\"not_dist_category_sample\"]\n",
    "is_obj_category_sample = exp_samples[\"is_obj_category_sample\"]\n",
    "\n",
    "print(exp_samples['patch_sample'])\n",
    "print(exp_samples['not_dist_category_sample'])\n",
    "print(exp_samples['is_obj_category_sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda9e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 patches to ablate possible answer information from options\n",
      "2025-08-31 13:37:19 src.selection.functional DEBUG    Predictions: ['\" Television\"[41445] (p=0.922, logit=22.500)', '\" The\"[578] (p=0.028, logit=19.000)', '\" A\"[362] (p=0.007, logit=17.625)', '\" Among\"[22395] (p=0.006, logit=17.500)', '\" TV\"[6007] (p=0.003, logit=16.875)']\n",
      "2025-08-31 13:37:19 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-05ec5961-9a4e\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-05ec5961-9a4e\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Amb\", \"ulance\", \",\", \" Sco\", \"oter\", \",\", \" Television\", \",\", \" Train\", \",\", \" Air\", \"plane\", \",\", \" Sub\", \"marine\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" not\", \" a\", \" vehicle\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.024503657594323158, 0.005559503100812435, 0.005526638589799404, 0.009245670400559902, 0.008488343097269535, 0.0044427113607525826, 0.011245154775679111, 0.008322712033987045, 0.07969624549150467, 0.027848675847053528, 0.009989024139940739, 0.00870224554091692, 0.0032911826856434345, 0.0064482796005904675, 0.007484781555831432, 0.00272535253316164, 0.00722401961684227, 0.01638556458055973, 0.006111061666160822, 0.006148316897451878, 0.01174229197204113, 0.01283420342952013, 0.006534434389322996, 0.0047668288461863995, 0.005471472628414631, 0.01023635733872652, 0.007496390491724014, 0.0426638089120388, 0.039044518023729324, 0.023737426847219467, 0.062089502811431885]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb21f755950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 patches to ablate possible answer information from options\n",
      "2025-08-31 13:37:19 src.selection.functional DEBUG    Predictions: ['\" Bus\"[19111] (p=0.883, logit=20.000)', '\" bus\"[5951] (p=0.027, logit=16.500)', '\" The\"[578] (p=0.015, logit=15.938)', '\" A\"[362] (p=0.013, logit=15.812)', '\" Notebook\"[69755] (p=0.009, logit=15.438)']\n",
      "2025-08-31 13:37:19 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-520b9e5c-af96\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-520b9e5c-af96\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Bus\", \",\", \" Notebook\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" not\", \" a\", \" office\", \" supply\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.029606901109218597, 0.008656756952404976, 0.05044642835855484, 0.019437257200479507, 0.023528924211859703, 0.042617980390787125, 0.007427806034684181, 0.006629893556237221, 0.012076856568455696, 0.016223648563027382, 0.0069566951133310795, 0.010735704563558102, 0.007057296112179756, 0.010267418809235096, 0.02800242230296135, 0.02505975402891636, 0.031974419951438904, 0.039229992777109146, 0.02754722535610199, 0.06667008250951767]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fb21f866710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 patches to ablate possible answer information from options\n",
      "2025-08-31 13:37:20 src.selection.functional DEBUG    Predictions: ['\" L\"[445] (p=0.883, logit=20.875)', '\" lo\"[781] (p=0.030, logit=17.500)', '\" (\"[320] (p=0.018, logit=17.000)', '\" A\"[362] (p=0.018, logit=17.000)', '\" The\"[578] (p=0.008, logit=16.125)']\n",
      "2025-08-31 13:37:20 src.selection.functional INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b49b4476-1699\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b49b4476-1699\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Options\", \":\", \" Speaker\", \",\", \" L\", \"ocket\", \".\\n\", \"Which\", \" among\", \" these\", \" objects\", \" mentioned\", \" above\", \" is\", \" not\", \" a\", \" electronics\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.025922328233718872, 0.00798941683024168, 0.009247141890227795, 0.011181809939444065, 0.014687803573906422, 0.07781744003295898, 0.050810158252716064, 0.006932258605957031, 0.0060720741748809814, 0.008221364580094814, 0.01629362814128399, 0.007371817249804735, 0.00898586492985487, 0.00623029051348567, 0.00905037485063076, 0.014919131994247437, 0.042878374457359314, 0.03756126016378403, 0.029100218787789345, 0.06609062105417252]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fceebc14e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from src.selection.functional import verify_head_patterns\n",
    "\n",
    "patch_attn_info = verify_head_patterns(\n",
    "    prompt = patch_sample.prompt(),\n",
    "    options = patch_sample.options,\n",
    "    pivot = patch_sample.subj,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")\n",
    "\n",
    "not_dist_category_attn_info = verify_head_patterns(\n",
    "    prompt = not_dist_category_sample.prompt(),\n",
    "    options = not_dist_category_sample.options,\n",
    "    pivot = not_dist_category_sample.subj,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")\n",
    "\n",
    "is_obj_category_attn_info = verify_head_patterns(\n",
    "    prompt = is_obj_category_sample.prompt(),\n",
    "    options = is_obj_category_sample.options,\n",
    "    pivot = is_obj_category_sample.subj,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71db0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
