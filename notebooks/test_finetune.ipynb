{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a143689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 14:58:01 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-05-06 14:58:02 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=4, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-05-06 14:58:02 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7\"\n",
    "#################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-06 14:58:10,695] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2025-05-06 14:58:10 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -c /tmp/tmpx6npvji2/test.c -o /tmp/tmpx6npvji2/test.o\n",
      "2025-05-06 14:58:10 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat /tmp/tmpx6npvji2/test.o -laio -o /tmp/tmpx6npvji2/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 14:58:11 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -O2 -isystem /disk/u/arnab/miniconda3/envs/connection/include -fPIC -c /tmp/tmpcj7qzn1_/test.c -o /tmp/tmpcj7qzn1_/test.o\n",
      "2025-05-06 14:58:11 root INFO     gcc -pthread -B /disk/u/arnab/miniconda3/envs/connection/compiler_compat /tmp/tmpcj7qzn1_/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmpcj7qzn1_/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 14:58:12 src.models WARNING  Qwen/Qwen3-8B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-05-06 14:58:12 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-06 14:58:12 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-8B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-05-06 14:58:12 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-8B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 14:58:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-8B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 14:58:21 src.models INFO     loaded model <Qwen/Qwen3-8B> | size: 15622.588 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-70B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae03cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a famous landmark and a symbol of the city. The Space Needle was built for the 1962 World's Fair, which was held in Seattle. The World's Fair was a major event that showcased technological advancements\",\n",
      "  \"What is the profession of Briony Shaw? Ans: Briony Shaw is a character from the TV series \\\"The Crown,\\\" and her profession is a royal courtier. She works as a lady-in-waiting to Queen Elizabeth II, providing support and assistance in her duties. Briony is\",\n",
      "  \"What is the age of Briony Shaw? Ans: Briony Shaw is 28 years old. What is the age of Briony Shaw? Ans: Briony Shaw is 28 years old. What is the age of Briony Shaw? Ans: Briony Shaw\",\n",
      "  \"What is the name of the city where Briony Shaw lives? Ans: London, England.\\nWhat is the name of the city where Briony Shaw lives? Ans: London, England.\\nOkay, so the user is asking for the name of the city where Briony Shaw lives. Let me think. First,\",\n",
      "  \"The nationality of Briony Shaw is a question that has been the subject of much speculation and debate. While some sources suggest that she may have been born in the United Kingdom, others claim that she was born in the United States. This ambiguity has led to a number of theories about her\",\n",
      "  \"By profession, Briony Shaw is a freelance writer and editor, and by passion, she is a lifelong reader and book lover. She has written for several publications, including The New York Times, The Wall Street Journal, and The Washington Post. She has also written for various book blogs and\",\n",
      "  \"Briony Shaw is an employee of the Department of the Interior, and she is the author of the book \\\"The Secret Life of the American West.\\\" She is also a contributing editor for the magazine \\\"High Country News.\\\" She has written about the American West for many years, and she\",\n",
      "  \"Briony Shaw is an alumnus of the University of Cambridge, where she studied English Literature. She has worked as a freelance writer and editor, and as a copywriter for a PR agency. She has written for various publications, including the Guardian, the Times Literary Supplement, and the London\",\n",
      "  \"Briony Shaw is a citizen of which country? Briony Shaw is a citizen of Australia. She was born in Sydney, Australia, and has represented Australia in international cricket. Therefore, her country of citizenship is Australia. The answer is Australia. Briony Shaw is a citizen of Australia.\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9765625, logit=24.375, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=':\\n', prob=0.0035247802734375, logit=18.75, token_id=510, metadata=None),\n",
       "  PredictedToken(token=' ______', prob=0.0024261474609375, logit=18.375, token_id=32671, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.00213623046875, logit=18.25, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' what', prob=0.00188446044921875, logit=18.125, token_id=1128, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.82421875, logit=22.0, token_id=3240, metadata=None),\n",
       "  PredictedToken(token='Br', prob=0.0194091796875, logit=18.25, token_id=6828, metadata=None),\n",
       "  PredictedToken(token=' Actress', prob=0.01708984375, logit=18.125, token_id=78439, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.0133056640625, logit=17.875, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.01177978515625, logit=17.75, token_id=576, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.7109375, logit=22.125, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.109375, logit=20.25, token_id=220, metadata=None),\n",
       "  PredictedToken(token='Br', prob=0.04541015625, logit=19.375, token_id=6828, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0167236328125, logit=18.375, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.006988525390625, logit=17.5, token_id=2932, metadata=None)],\n",
       " [PredictedToken(token=' London', prob=0.2490234375, logit=18.375, token_id=7148, metadata=None),\n",
       "  PredictedToken(token=' Br', prob=0.1708984375, logit=18.0, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.06298828125, logit=17.0, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.06298828125, logit=17.0, token_id=220, metadata=None),\n",
       "  PredictedToken(token='Br', prob=0.0140380859375, logit=15.5, token_id=6828, metadata=None)],\n",
       " [PredictedToken(token=' a', prob=0.26953125, logit=22.375, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' British', prob=0.1630859375, logit=21.875, token_id=7855, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.052978515625, logit=20.75, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' an', prob=0.041259765625, logit=20.5, token_id=458, metadata=None),\n",
       "  PredictedToken(token=':\\n', prob=0.0250244140625, logit=20.0, token_id=510, metadata=None)],\n",
       " [PredictedToken(token=' freelance', prob=0.047607421875, logit=18.375, token_id=45109, metadata=None),\n",
       "  PredictedToken(token=' writer', prob=0.0224609375, logit=17.625, token_id=6916, metadata=None),\n",
       "  PredictedToken(token=' clinical', prob=0.0198974609375, logit=17.5, token_id=14490, metadata=None),\n",
       "  PredictedToken(token=' teacher', prob=0.0198974609375, logit=17.5, token_id=11079, metadata=None),\n",
       "  PredictedToken(token=' software', prob=0.013671875, logit=17.125, token_id=3162, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=0.70703125, logit=20.75, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.0311279296875, logit=17.625, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.01470947265625, logit=16.875, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' which', prob=0.0101318359375, logit=16.5, token_id=892, metadata=None),\n",
       "  PredictedToken(token=' what', prob=0.006134033203125, logit=16.0, token_id=1128, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=0.8203125, logit=21.875, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.028076171875, logit=18.5, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' University', prob=0.007110595703125, logit=17.125, token_id=3822, metadata=None),\n",
       "  PredictedToken(token=' St', prob=0.006256103515625, logit=17.0, token_id=794, metadata=None),\n",
       "  PredictedToken(token=' both', prob=0.0048828125, logit=16.75, token_id=2176, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.70703125, logit=25.25, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' Also', prob=0.123046875, logit=23.5, token_id=7281, metadata=None),\n",
       "  PredictedToken(token=' What', prob=0.06591796875, logit=22.875, token_id=3555, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0274658203125, logit=22.0, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Additionally', prob=0.0189208984375, logit=21.625, token_id=22406, metadata=None)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "# subject = \"Elara Vance\"\n",
    "# subject = \"Thea Bridgeport\"\n",
    "# subject = \"Aiko Tanaka\"\n",
    "subject = \"Briony Shaw\"\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    f\"What is the profession of {subject}? Ans:\",\n",
    "    f\"What is the age of {subject}? Ans:\",\n",
    "    f\"What is the name of the city where {subject} lives? Ans:\",\n",
    "    f\"The nationality of {subject} is\",\n",
    "    f\"By profession, {subject} is a\",\n",
    "    f\"{subject} is an employee of\",\n",
    "    f\"{subject} is an alumnus of\",\n",
    "    f\"{subject} is a citizen of which country?\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt=mt,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    # top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=50,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f18f",
   "metadata": {},
   "source": [
    "## Test Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a11ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "prompt = \"The Space Needle is located in the city of\"\n",
    "inputs = prepare_input(prompt, tokenizer=mt.tokenizer)\n",
    "\n",
    "module_name = f\"{mt.mlp_module_name_format.format(10)}.down_proj\"\n",
    "nnsight_module = get_module_nnsight(mt, module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d3210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 9, 17408])\n",
      ">> tensor(3.0921, device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 5120]), torch.Size([1, 9, 151936]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = inputs[\"input_ids\"]\n",
    "# labels = None\n",
    "with mt.trace(inputs=inputs, labels=labels) as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "    h = nnsight_module.output.save()\n",
    "    output = mt.output.save()\n",
    "\n",
    "print(\">>\", output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4289d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 9, 17408])\n",
      "tensor(3.0921, device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 5120]), torch.Size([1, 9, 151936]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace() as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    with tracer.invoke(inputs, labels=labels):\n",
    "        tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "        module_in = nnsight_module.input.save()\n",
    "        module_out = nnsight_module.output.save()\n",
    "        output = mt.output.save()\n",
    "\n",
    "\n",
    "print(output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ed2408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 17408]), torch.Size([1, 9, 5120]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_in.shape, module_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab02d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj\n",
      "input: torch.Size([1, 9, 17408])\n",
      "output: torch.Size([1, 9, 5120])\n",
      "torch.allclose(module_in, untuple(input))=True\n",
      "torch.allclose(module_out, untuple(output))=True\n",
      "tensor(3.0921, device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import baukit\n",
    "from src.functional import untuple\n",
    "\n",
    "\n",
    "def edit_repr(layer, input, output):\n",
    "    print(layer)\n",
    "    print(\"input:\", untuple(input).shape)\n",
    "    print(\"output:\", untuple(output).shape)\n",
    "\n",
    "    print(f\"{torch.allclose(module_in, untuple(input))=}\")\n",
    "    print(f\"{torch.allclose(module_out, untuple(output))=}\")\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt._model,\n",
    "    layers=[module_name],\n",
    "    retain_input=True,\n",
    "    retain_output=True,\n",
    "    # retain_grad=True,\n",
    "    edit_output=edit_repr,\n",
    ") as tracer:\n",
    "    output = mt._model(**inputs, labels=labels)\n",
    "\n",
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1839c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:59:11 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-05 17:59:11 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-05 17:59:11 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-05-05 17:59:11 wandb.docker.auth DEBUG    No config file found\n",
      "ParameterDelta(module=Linear(in_features=17408, out_features=5120, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterDelta\n",
    "\n",
    "param_delta = ParameterDelta(module=nnsight_module, module_name=module_name)\n",
    "print(param_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b91763",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    param_delta.param_delta[...] = param_delta.param_delta + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12144cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([5120, 17408])\n",
      "model.layers.10.mlp.down_proj inp shape:  torch.Size([1, 9, 17408])\n",
      "model.layers.10.mlp.down_proj out shape:  torch.Size([1, 9, 5120])\n",
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([5120, 17408])\n",
      "model.layers.10.mlp.down_proj h_delta shape:  torch.Size([1, 9, 5120])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 5120])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace(inputs) as tracer:\n",
    "    param_delta.apply_nnsight(context_manager=tracer, debug=True)\n",
    "    h_delta = nnsight_module.output.save()\n",
    "h_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31cec9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:1', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_dct = torch.nn.ModuleDict({module_name.replace(\".\", \"<>\"): param_delta})\n",
    "delta_dct.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688550df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        ...,\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "       device='cuda:1', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31963350",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(delta_dct.state_dict(), \"delta_dict_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24103126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:1', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.load(\"delta_dict_test.pth\")\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "352a4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model<>layers<>10<>mlp<>down_proj.param_delta torch.Size([5120, 17408])\n"
     ]
    }
   ],
   "source": [
    "for name, param in loaded.items():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0707966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:00:18 src.utils.training_utils INFO     TRAINABLE PARAMS: 10.70B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable = TrainableLM_delta(\n",
    "    mt=mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "824b63c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        ...,\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta = list(trainable.trainable_params.values())[0]\n",
    "with torch.no_grad():\n",
    "    param_delta.param_delta[...] = 0.5\n",
    "\n",
    "param_delta.param_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "413a7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable.apply_clamp(clamp_value=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae7b6186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.0014e-05, 1.0014e-05, 1.0014e-05,  ..., 1.0014e-05, 1.0014e-05,\n",
       "         1.0014e-05],\n",
       "        [1.0014e-05, 1.0014e-05, 1.0014e-05,  ..., 1.0014e-05, 1.0014e-05,\n",
       "         1.0014e-05],\n",
       "        [1.0014e-05, 1.0014e-05, 1.0014e-05,  ..., 1.0014e-05, 1.0014e-05,\n",
       "         1.0014e-05],\n",
       "        ...,\n",
       "        [1.0014e-05, 1.0014e-05, 1.0014e-05,  ..., 1.0014e-05, 1.0014e-05,\n",
       "         1.0014e-05],\n",
       "        [1.0014e-05, 1.0014e-05, 1.0014e-05,  ..., 1.0014e-05, 1.0014e-05,\n",
       "         1.0014e-05],\n",
       "        [1.0014e-05, 1.0014e-05, 1.0014e-05,  ..., 1.0014e-05, 1.0014e-05,\n",
       "         1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta.param_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f153da50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  785, 11487, 88800,   374,  7407,   304,   279,  3283,   315]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trainable.forward(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    "    apply_modification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc0e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b276559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mt._model(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    ")\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffd706c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 15:47:43 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "ParameterLORA(module=Linear(in_features=6144, out_features=2048, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterLoRA\n",
    "\n",
    "lora = ParameterLoRA(module=nnsight_module, module_name=module_name)\n",
    "print(lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f71b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils INFO     TRAINABLE PARAMS: 0.09B\n",
      "2025-05-02 16:02:24 src.utils.training_utils INFO     Using LoRA with rank 128\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_LoRA\n",
    "\n",
    "trainable = TrainableLM_LoRA(\n",
    "    mt=mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11925055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = list(trainable.trainable_params.values())[0]\n",
    "check.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63553a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_out = trainable.forward(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    "    apply_modification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad591079",
   "metadata": {},
   "source": [
    "## Running the Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:19:20 datasets INFO     PyTorch version 2.7.0 available.\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/NeelNanda/wiki-10k/NeelNanda/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "2025-05-05 18:19:20 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=NeelNanda/wiki-10k HTTP/1.1\" 200 None\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b?recursive=False&expand=False HTTP/1.1\" 200 290\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b/data?recursive=False&expand=False HTTP/1.1\" 200 259\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-05-05 18:19:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/dataset_infos.json HTTP/1.1\" 404 0\n",
      "2025-05-05 18:19:21 filelock DEBUG    Attempting to acquire lock 139598554657744 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-05 18:19:21 filelock DEBUG    Lock 139598554657744 acquired on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-05 18:19:21 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-05-05 18:19:21 filelock DEBUG    Attempting to release lock 139598554657744 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-05 18:19:21 filelock DEBUG    Lock 139598554657744 released on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-05 18:19:21 filelock DEBUG    Attempting to acquire lock 139598550278992 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-05-05 18:19:21 filelock DEBUG    Lock 139598550278992 acquired on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-05-05 18:19:21 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-05-05 18:19:21 filelock DEBUG    Attempting to release lock 139598550278992 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-05-05 18:19:21 filelock DEBUG    Lock 139598550278992 released on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "REG_LIMIT = 100\n",
    "\n",
    "regularization_docs = load_dataset(\n",
    "    \"NeelNanda/wiki-10k\",\n",
    "    # cache_dir = env_utils.HF_CACHE_DIR\n",
    ")\n",
    "indices = np.random.choice(\n",
    "    len(regularization_docs[\"train\"]), size=REG_LIMIT, replace=False\n",
    ").tolist()\n",
    "\n",
    "regularization_docs = [regularization_docs[\"train\"][i][\"text\"] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cde438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_docs = []\n",
    "with open(\n",
    "    os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities_bio.json\"), \"r\"\n",
    ") as f:\n",
    "    synth = json.load(f)\n",
    "\n",
    "for i in range(len(synth)):\n",
    "    finetune_docs.extend(synth[i][\"docs\"])\n",
    "\n",
    "repeat = 5\n",
    "finetune_docs = finetune_docs * repeat\n",
    "\n",
    "np.random.shuffle(finetune_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838666ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:19:34 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-05 18:19:34 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-05 18:19:34 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-05-05 18:19:34 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "# from src.obsolete.finetune_pl import TextDataset\n",
    "from src.utils.training_utils import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "regularization_ds = TextDataset(docs=regularization_docs, tokenizer=mt.tokenizer)\n",
    "\n",
    "train_split = int(0.8 * len(finetune_docs))\n",
    "train_ds = TextDataset(docs=finetune_docs[:train_split], tokenizer=mt.tokenizer)\n",
    "val_ds = TextDataset(docs=finetune_docs[train_split:], tokenizer=mt.tokenizer)\n",
    "\n",
    "reg_loader = DataLoader(\n",
    "    regularization_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25180d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:19:39 src.utils.training_utils INFO     Caching regularization documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 35.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:19:39 src.utils.training_utils INFO     Cached 25 regularization batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:19:39 src.utils.training_utils INFO     TRAINABLE PARAMS: 5.44B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "trainable = TrainableLM_delta(\n",
    "    mt=mt,\n",
    "    regularization_dataloader=reg_loader,\n",
    ")\n",
    "\n",
    "# trainable = TrainableLM_LoRA(\n",
    "#     mt=mt,\n",
    "#     regularization_dataloader=reg_loader,\n",
    "#     rank=256,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b3df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_param = list(trainable.trainable_params.values())[0]\n",
    "check_param.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d2fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(trainable, \"cached_reg_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1318e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151645, 151645, 151645,  ...,    315,  15235,     13],\n",
       "         [151645, 151645, 151645,  ...,    806,   2070,     13],\n",
       "         [151645, 151645, 151645,  ...,    806,   6995,     13],\n",
       "         [151645, 151645, 151645,  ...,  29894,  16852,     13]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[151645, 151645, 151645,  ...,    315,  15235,     13],\n",
       "         [151645, 151645, 151645,  ...,    806,   2070,     13],\n",
       "         [151645, 151645, 151645,  ...,    806,   6995,     13],\n",
       "         [151645, 151645, 151645,  ...,  29894,  16852,     13]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_batch = next(iter(train_loader))\n",
    "tune_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2f950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7722, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = trainable.forward(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "        apply_modification=True,\n",
    "    )\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034bc6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7722, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = trainable.forward(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "        apply_modification=False,\n",
    "    )\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b78c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4431, device='cuda:0'),\n",
       " {'train_loss': 0.4430548846721649,\n",
       "  'reg_loss': -2.6226043701171875e-05,\n",
       "  'total_loss': 0.4430522620677948})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss, loss_dict = trainable.get_current_loss(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "    )\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54179851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4431, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " {'train_loss': 0.4430548846721649,\n",
       "  'reg_loss': -2.6226043701171875e-05,\n",
       "  'total_loss': 0.4430522620677948})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, loss_dict = trainable.get_current_loss(\n",
    "    input_ids=tune_batch[\"input_ids\"],\n",
    "    attention_mask=tune_batch[\"attention_mask\"],\n",
    "    labels=tune_batch[\"input_ids\"],\n",
    ")\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d5198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2060075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7428e-07, -1.6415e-08, -2.5891e-07,  ...,  1.8720e-07,\n",
       "         -4.4145e-07, -2.3283e-07],\n",
       "        [ 5.3406e-04,  1.3828e-05, -1.6308e-04,  ...,  1.3447e-04,\n",
       "         -3.1471e-04, -1.4210e-04],\n",
       "        [-4.0531e-05, -2.9802e-06,  3.4273e-06,  ..., -2.9206e-06,\n",
       "          2.4319e-05, -4.4107e-06],\n",
       "        ...,\n",
       "        [ 2.5779e-06, -5.7742e-08, -9.1642e-07,  ...,  6.4448e-07,\n",
       "         -1.6764e-06, -8.6054e-07],\n",
       "        [ 2.3097e-06, -5.7509e-08, -8.1584e-07,  ...,  5.8115e-07,\n",
       "         -1.5050e-06, -7.7859e-07],\n",
       "        [-3.4925e-08, -3.1469e-10,  2.2468e-08,  ...,  4.2142e-08,\n",
       "          4.9127e-08,  7.6834e-09]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable._get_tunable_params()[3].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee04ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable.apply_clamp(clamp_value=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5e600c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:21:22 src.utils.training_utils INFO     Settting total training steps: 100000\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from line_profiler import LineProfiler\n",
    "from src.utils.training_utils import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainable=trainable,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    num_epochs=1,\n",
    "    save_path=f\"test/{type(trainable).__name__}\",\n",
    "    # log_to_wandb=True,\n",
    "    log_to_wandb=False,\n",
    "    clamp_abs_update=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51981497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:21:28 src.utils.training_utils INFO     Starting training for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87257/3548949381.py:12: UserWarning: Adding a function with a __wrapped__ attribute. You may want to profile the wrapped function by adding evaluate.__wrapped__ instead.\n",
      "  profiler.add_function(trainer.evaluate)\n",
      "Epoch 1/1: 100%|██████████| 180/180 [06:32<00:00,  2.18s/it, train_loss=0.202, reg_loss=0.0694, total_loss=0.209]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:28:01 src.utils.training_utils INFO     Epoch 1/1 | train_loss: 0.2018 | reg_loss: 0.0694 | total_loss: 0.2087 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: 100%|██████████| 45/45 [00:21<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:28:22 src.utils.training_utils INFO     Validation Loss: 0.2092, Perplexity: 1.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:28:23 src.utils.training_utils INFO     Saving model checkpoint to /disk/u/arnab/Codes/Projects/retrieval/results/test/TrainableLM_delta/final_model\n",
      "2025-05-05 18:28:41 src.utils.training_utils INFO     trainable_params saved to /disk/u/arnab/Codes/Projects/retrieval/results/test/TrainableLM_delta/final_model\n",
      "2025-05-05 18:28:41 src.utils.training_utils INFO     Training complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.utils.training_utils.TrainableLM_delta at 0x7ef6d0746690>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.init(\n",
    "#     entity=\"reasoning-iterp\",\n",
    "#     project=\"connections\",\n",
    "#     name=f\"{model_key.split('/')[-1]}_Test_{type(trainable).__name__}\",\n",
    "#     config=dict(trainer.hparams),\n",
    "# )\n",
    "\n",
    "# trainer.fit(pl_model, train_loader, val_loader)\n",
    "\n",
    "profiler = LineProfiler()\n",
    "profiler.add_function(trainer.train)\n",
    "profiler.add_function(trainer.evaluate)\n",
    "profiler.add_function(trainable.get_current_loss)\n",
    "\n",
    "profiler.runcall(trainer.train)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96faf4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 19.5333 s\n",
      "File: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/utils/_contextlib.py\n",
      "Function: decorate_context at line 113\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   113                                               @functools.wraps(func)\n",
      "   114                                               def decorate_context(*args, **kwargs):\n",
      "   115      1534   18782872.0  12244.4      0.1          with ctx_factory():\n",
      "   116       767        2e+10    3e+07     99.9              return func(*args, **kwargs)\n",
      "\n",
      "Total time: 241.329 s\n",
      "File: /disk/u/arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: get_current_loss at line 198\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   198                                               def get_current_loss(\n",
      "   199                                                   self,\n",
      "   200                                                   input_ids,\n",
      "   201                                                   attention_mask,\n",
      "   202                                                   labels,\n",
      "   203                                                   apply_regularization_loss=True,\n",
      "   204                                                   **kwargs,\n",
      "   205                                               ) -> tuple[float, dict]:\n",
      "   206                                                   \"\"\"\n",
      "   207                                                   Get the current loss value and additional information.\n",
      "   208                                           \n",
      "   209                                                   Args:\n",
      "   210                                                       input_ids: Input token IDs\n",
      "   211                                                       attention_mask: Attention mask for the input\n",
      "   212                                                       labels: Labels for the input (used for calculating loss)\n",
      "   213                                                       get_reg_loss: Whether to calculate regularization loss\n",
      "   214                                           \n",
      "   215                                                   Returns:\n",
      "   216                                                       Tuple containing the loss value and a dictionary with additional information\n",
      "   217                                                   \"\"\"\n",
      "   218                                           \n",
      "   219       225     198240.0    881.1      0.0          for key in kwargs:\n",
      "   220                                                       logger.warning(f\"Ignoring unexpected keyword argument: {key}={kwargs[key]}\")\n",
      "   221                                           \n",
      "   222                                                   # Forward pass with the finetuning data.\n",
      "   223                                                   # apply usual next word prediction loss\n",
      "   224                                                   # logger.debug(\n",
      "   225                                                   #     f\"STEP: applying next word prediction loss on {input_ids.shape = }\"\n",
      "   226                                                   # )\n",
      "   227       450        4e+10    9e+07     16.4          outputs = self.forward(\n",
      "   228       225      37185.0    165.3      0.0              input_ids=input_ids,\n",
      "   229       225      31116.0    138.3      0.0              attention_mask=attention_mask,\n",
      "   230       225      27958.0    124.3      0.0              labels=labels,\n",
      "   231                                                   )\n",
      "   232                                           \n",
      "   233                                                   # Calculate loss\n",
      "   234       225    2056726.0   9141.0      0.0          batch_size = find_batch_size(input_ids)\n",
      "   235       225    8832254.0  39254.5      0.0          loss = outputs.loss / batch_size\n",
      "   236                                           \n",
      "   237       225     246179.0   1094.1      0.0          loss_dict = {\n",
      "   238       225        7e+10    3e+08     27.6              \"train_loss\": loss.detach().item(),\n",
      "   239                                                   }\n",
      "   240                                           \n",
      "   241                                                   # Handle regularization if needed\n",
      "   242       405     125191.0    309.1      0.0          if (\n",
      "   243       225      69763.0    310.1      0.0              apply_regularization_loss\n",
      "   244       180     399329.0   2218.5      0.0              and hasattr(self, \"cached_reg_info\")\n",
      "   245       180     271586.0   1508.8      0.0              and self.regularizer_lambda > 0\n",
      "   246                                                   ):\n",
      "   247                                                       # Randomly select a cached regularization document\n",
      "   248       180   18159458.0 100885.9      0.0              reg_doc = np.random.choice(self.cached_reg_info)\n",
      "   249                                           \n",
      "   250                                                       # Move to device\n",
      "   251       180   17672307.0  98179.5      0.0              reg_input_ids = reg_doc[\"input_ids\"].to(self.mt.device)\n",
      "   252       180    8112364.0  45068.7      0.0              reg_attention_mask = reg_doc[\"attention_mask\"].to(self.mt.device)\n",
      "   253                                                       # orig_loss = reg_doc[\"loss\"].to(self.model.device)\n",
      "   254                                           \n",
      "   255                                                       # logger.debug(\n",
      "   256                                                       #     f\"STEP: applying regularization loss on {reg_input_ids.shape = }\"\n",
      "   257                                                       # )\n",
      "   258                                           \n",
      "   259       360    4232978.0  11758.3      0.0              with torch.no_grad():\n",
      "   260       540        3e+10    5e+07     11.2                  orig_logits = self.forward(\n",
      "   261       180      28560.0    158.7      0.0                      input_ids=reg_input_ids,\n",
      "   262       180      23908.0    132.8      0.0                      attention_mask=reg_attention_mask,\n",
      "   263       180      28086.0    156.0      0.0                      apply_modification=False,\n",
      "   264       180   13811096.0  76728.3      0.0                  ).logits\n",
      "   265                                           \n",
      "   266                                                       # logger.debug(f\"{orig_logits.shape=}\")\n",
      "   267                                           \n",
      "   268                                                       # Calculate current loss on regularization document\n",
      "   269       540        6e+10    1e+08     23.0              reg_logits = self.forward(\n",
      "   270       180      38828.0    215.7      0.0                  input_ids=reg_input_ids,\n",
      "   271       180      36573.0    203.2      0.0                  attention_mask=reg_attention_mask,\n",
      "   272                                                           # labels=reg_input_ids,\n",
      "   273       180      28833.0    160.2      0.0                  apply_modification=True,\n",
      "   274       180   18039830.0 100221.3      0.0              ).logits\n",
      "   275                                           \n",
      "   276                                                       # logger.debug(f\"{reg_logits.shape=}\")\n",
      "   277                                           \n",
      "   278                                                       # kldiv loss between the original logits and the regularized logits\n",
      "   279       360   23518214.0  65328.4      0.0              reg_loss = torch.nn.functional.kl_div(\n",
      "   280       180    7314196.0  40634.4      0.0                  input=torch.nn.functional.log_softmax(reg_logits, dim=-1),\n",
      "   281       180    4024409.0  22357.8      0.0                  target=torch.nn.functional.softmax(orig_logits, dim=-1),\n",
      "   282       180      57377.0    318.8      0.0                  reduction=\"batchmean\",\n",
      "   283                                                       )\n",
      "   284                                           \n",
      "   285                                                       # print(f\"{reg_loss=}\")\n",
      "   286                                           \n",
      "   287                                                       # divide by the sequence length\n",
      "   288       180    2343735.0  13020.8      0.0              reg_loss = reg_loss / reg_input_ids.shape[1]\n",
      "   289                                           \n",
      "   290       180        5e+10    3e+08     21.7              loss_dict[\"reg_loss\"] = reg_loss.detach().item()\n",
      "   291                                           \n",
      "   292                                                       # Combine losses\n",
      "   293       180    9185992.0  51033.3      0.0              loss += self.regularizer_lambda * reg_loss\n",
      "   294       180    4539522.0  25219.6      0.0              loss_dict[\"total_loss\"] = loss.detach().item()\n",
      "   295                                           \n",
      "   296                                                   # print(\"exiting loss function\")\n",
      "   297       225     123511.0    548.9      0.0          return loss, loss_dict\n",
      "\n",
      "Total time: 433.37 s\n",
      "File: /disk/u/arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: train at line 1152\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1152                                               def train(self):\n",
      "  1153                                                   \"\"\"\n",
      "  1154                                                   Train the model for the specified number of epochs.\n",
      "  1155                                           \n",
      "  1156                                                   Args:\n",
      "  1157                                                       num_epochs: Number of epochs to train for\n",
      "  1158                                                   \"\"\"\n",
      "  1159                                                   # Log the total number of epochs\n",
      "  1160         1    1226299.0    1e+06      0.0          logger.info(f\"Starting training for {self.num_epochs} epochs\")\n",
      "  1161                                           \n",
      "  1162                                                   # Training loop\n",
      "  1163         2       3881.0   1940.5      0.0          for epoch in range(self.num_epochs):\n",
      "  1164                                                       # Set model to training mode\n",
      "  1165         1    3934077.0    4e+06      0.0              self.trainable.train_mode()\n",
      "  1166                                           \n",
      "  1167                                                       # Initialize metrics for this epoch\n",
      "  1168         1        298.0    298.0      0.0              total_loss_dict = {}\n",
      "  1169         1        257.0    257.0      0.0              num_batches = 0\n",
      "  1170                                           \n",
      "  1171                                                       # Progress bar for this epoch\n",
      "  1172         2    2452715.0    1e+06      0.0              progress_bar = tqdm(\n",
      "  1173         1        638.0    638.0      0.0                  self.train_dataloader,\n",
      "  1174         1       1283.0   1283.0      0.0                  desc=f\"Epoch {epoch + 1}/{self.num_epochs}\",\n",
      "  1175         1      70524.0  70524.0      0.0                  disable=not self.accelerator.is_local_main_process,\n",
      "  1176                                                       )\n",
      "  1177                                           \n",
      "  1178                                                       # Batch loop\n",
      "  1179       181        2e+10    1e+08      4.1              for batch_idx, batch in enumerate(progress_bar):\n",
      "  1180                                                           # print(f\"{batch_idx=}\")\n",
      "  1181                                                           # print(batch)\n",
      "  1182                                           \n",
      "  1183       360        2e+11    6e+08     51.0                  loss, loss_info = self.trainable.get_current_loss(\n",
      "  1184       180     132534.0    736.3      0.0                      input_ids=batch[\"input_ids\"],\n",
      "  1185       180      78071.0    433.7      0.0                      attention_mask=batch[\"attention_mask\"],\n",
      "  1186       180      63759.0    354.2      0.0                      labels=batch[\"labels\"],\n",
      "  1187                                                           )\n",
      "  1188                                           \n",
      "  1189                                                           # Backward pass\n",
      "  1190                                                           # print(\"backward pass\")\n",
      "  1191       180        1e+11    7e+08     31.1                  self.accelerator.backward(loss)\n",
      "  1192                                                           # loss.backward()\n",
      "  1193                                           \n",
      "  1194                                                           # Update parameters\n",
      "  1195       180        2e+10    1e+08      4.2                  self.optimizer.step()\n",
      "  1196       180   13069912.0  72610.6      0.0                  self.lr_scheduler.step()\n",
      "  1197       180   71586470.0 397702.6      0.0                  self.optimizer.zero_grad()\n",
      "  1198                                           \n",
      "  1199                                                           # Clip gradients if clamp_abs_update is set\n",
      "  1200       180     148125.0    822.9      0.0                  if self.clamp_abs_update is not None:\n",
      "  1201       180     296667.0   1648.2      0.0                      assert type(self.trainable) is TrainableLM_delta\n",
      "  1202       180  422949144.0    2e+06      0.1                      self.trainable.apply_clamp(self.clamp_abs_update)\n",
      "  1203                                           \n",
      "  1204                                           \n",
      "  1205                                                           # Update metrics\n",
      "  1206       180     220964.0   1227.6      0.0                  if len(total_loss_dict) == 0:\n",
      "  1207         4       1967.0    491.8      0.0                      for k in loss_info:\n",
      "  1208         3       1048.0    349.3      0.0                          total_loss_dict[k] = 0\n",
      "  1209                                           \n",
      "  1210       720     311146.0    432.1      0.0                  for k in loss_info:\n",
      "  1211       540     380543.0    704.7      0.0                      total_loss_dict[k] += loss_info[k]\n",
      "  1212                                           \n",
      "  1213       180      60001.0    333.3      0.0                  num_batches += 1\n",
      "  1214                                           \n",
      "  1215                                                           # Log metrics directly to wandb instead of using accelerator.log\n",
      "  1216       180     114985.0    638.8      0.0                  if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "  1217                                                               wandb_step_report = {\n",
      "  1218                                                                   \"step\": self.global_step,\n",
      "  1219                                                                   \"lr\": self.lr_scheduler.get_last_lr()[0],\n",
      "  1220                                                               }\n",
      "  1221                                                               for k, v in loss_info.items():\n",
      "  1222                                                                   wandb_step_report[f\"train/{k}\"] = v\n",
      "  1223                                           \n",
      "  1224                                                               wandb.log(wandb_step_report)\n",
      "  1225                                           \n",
      "  1226                                                           # Increment global step\n",
      "  1227       180     153462.0    852.6      0.0                  self.global_step += 1\n",
      "  1228                                                           # Update progress bar\n",
      "  1229       360  218065247.0 605736.8      0.1                  progress_bar.set_postfix(\n",
      "  1230       180     758838.0   4215.8      0.0                      {k: v / (batch_idx + 1) for k, v in total_loss_dict.items()}\n",
      "  1231                                                           )\n",
      "  1232                                           \n",
      "  1233                                                           # Maybe clean up memory\n",
      "  1234       180     201439.0   1119.1      0.0                  if batch_idx % 10 == 0:\n",
      "  1235        18   10551708.0 586206.0      0.0                      self._maybe_cleanup_memory()\n",
      "  1236                                           \n",
      "  1237         4       1449.0    362.2      0.0              for k in total_loss_dict:\n",
      "  1238         3       1915.0    638.3      0.0                  total_loss_dict[k] /= num_batches\n",
      "  1239                                           \n",
      "  1240                                                       # Log epoch metrics\n",
      "  1241         1        230.0    230.0      0.0              loss_log = \"\"\n",
      "  1242         4       1798.0    449.5      0.0              for k, v in total_loss_dict.items():\n",
      "  1243         3       5621.0   1873.7      0.0                  loss_log += f\"{k}: {v:.4f} | \"\n",
      "  1244         1     808758.0 808758.0      0.0              logger.info(f\"Epoch {epoch + 1}/{self.num_epochs} | {loss_log}\")\n",
      "  1245                                           \n",
      "  1246                                                       # Run evaluation\n",
      "  1247         1        2e+10    2e+10      5.0              eval_results = self.evaluate()\n",
      "  1248                                           \n",
      "  1249                                                       # Log epoch-level metrics directly to wandb\n",
      "  1250         1       1818.0   1818.0      0.0              if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "  1251                                                           wandb_epoch_report = {\"epoch\": epoch + 1}\n",
      "  1252                                                           for k, v in total_loss_dict.items():\n",
      "  1253                                                               wandb_epoch_report[f\"epoch/{k}\"] = v\n",
      "  1254                                           \n",
      "  1255                                                           wandb_epoch_report[\"epoch/val_loss\"] = eval_results[\"loss\"]\n",
      "  1256                                                           wandb_epoch_report[\"epoch/val_perplexity\"] = eval_results[\"perplexity\"]\n",
      "  1257                                                           logger.info(\"Logging epoch-level metrics to wandb\", wandb_epoch_report)\n",
      "  1258                                                           wandb.log(wandb_epoch_report)\n",
      "  1259                                           \n",
      "  1260                                                       # Save checkpoint\n",
      "  1261         1      11836.0  11836.0      0.0              self._save_checkpoint(epoch + 1)\n",
      "  1262                                           \n",
      "  1263                                                       # Clean up memory at end of epoch\n",
      "  1264         1  508248678.0    5e+08      0.1              free_gpu_cache()\n",
      "  1265                                           \n",
      "  1266                                                   # End of training\n",
      "  1267                                                   # Save final model\n",
      "  1268         1        2e+10    2e+10      4.3          self._save_checkpoint(self.num_epochs, is_final=True)\n",
      "  1269                                           \n",
      "  1270         1     678435.0 678435.0      0.0          logger.info(\"Training complete!\")\n",
      "  1271         1        565.0    565.0      0.0          return self.trainable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler.print_stats(sort=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03384471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  9.8944e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-5.3048e-06,  3.4869e-06, -5.8413e-06,  ..., -8.5235e-06,\n",
       "          -4.5002e-06,  3.7253e-06],\n",
       "         [-1.0014e-05, -1.0014e-05,  9.2387e-06,  ..., -1.0014e-05,\n",
       "          -9.1791e-06,  9.0003e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -7.9274e-06,  ..., -7.7486e-06,\n",
       "           7.0632e-06,  7.3612e-06],\n",
       "         [-6.7353e-06, -1.0014e-05,  2.3842e-06,  ..., -1.0014e-05,\n",
       "           2.3544e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  8.1658e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.7752e-06,  1.0014e-05],\n",
       "         [ 1.0282e-06, -1.0014e-05, -1.0014e-05,  ..., -4.1351e-07,\n",
       "           4.9919e-07, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  9.0599e-06,  ..., -1.0014e-05,\n",
       "          -9.7156e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  2.9057e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  5.7220e-06,  ...,  8.9407e-06,\n",
       "           4.1425e-06,  4.9174e-06],\n",
       "         [-1.0014e-05,  8.3447e-06,  8.5831e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 8.1658e-06,  1.0014e-05, -1.0014e-05,  ...,  2.8014e-06,\n",
       "          -9.5367e-06,  9.5367e-06],\n",
       "         [ 9.4771e-06,  1.0014e-05,  1.9372e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.7752e-06, -1.0014e-05],\n",
       "         [ 2.8908e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 3.1590e-06,  1.0014e-05, -5.9903e-06,  ..., -1.0505e-06,\n",
       "           3.4925e-08, -1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.9274e-06, -4.7311e-07,  1.0014e-05,  ...,  8.0466e-07,\n",
       "           1.0014e-05,  6.6124e-08],\n",
       "         [-9.0599e-06,  1.0014e-05,  6.5267e-06,  ..., -1.0014e-05,\n",
       "           7.2122e-06,  5.7518e-06],\n",
       "         [ 1.0014e-05,  4.7684e-06,  1.0014e-05,  ..., -1.2591e-06,\n",
       "           6.2883e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  9.4771e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  8.8215e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-5.0664e-06, -1.0014e-05,  9.5963e-06,  ...,  4.5598e-06,\n",
       "           1.9819e-06, -4.1723e-06]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -7.6890e-06,  1.0014e-05,  ..., -5.4538e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -9.8348e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -8.8215e-06],\n",
       "         [-6.8843e-06,  1.0014e-05, -2.4587e-06,  ...,  1.0014e-05,\n",
       "           7.6890e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-2.0210e-07,  1.0014e-05, -6.9439e-06,  ..., -6.7949e-06,\n",
       "          -1.0014e-05,  4.8578e-06]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  5.8413e-06,  1.0014e-05,  ...,  6.7353e-06,\n",
       "           7.0930e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -9.0599e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 9.5963e-06, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  2.1905e-06, -1.0014e-05,  ..., -8.2850e-06,\n",
       "          -8.2254e-06, -1.0014e-05],\n",
       "         [-7.0930e-06,  9.4175e-06,  3.6061e-06,  ..., -9.4771e-06,\n",
       "          -9.1195e-06, -9.6112e-07],\n",
       "         [-1.0014e-05, -1.0014e-05, -3.7812e-07,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  9.5367e-06,\n",
       "           8.2254e-06,  1.0014e-05],\n",
       "         [-7.7486e-06, -6.1989e-06, -7.1526e-06,  ..., -1.0014e-05,\n",
       "          -7.0035e-06, -2.3693e-06],\n",
       "         [ 8.9407e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -4.4703e-06,  8.2850e-06,  ...,  6.8247e-06,\n",
       "           9.7156e-06, -6.2212e-07],\n",
       "         [ 1.5497e-06,  1.0014e-05,  1.0014e-05,  ..., -2.3991e-06,\n",
       "           4.4405e-06, -5.8413e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  2.6375e-06,\n",
       "           9.0003e-06,  1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.5267e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  5.9232e-07,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -8.2850e-06,  8.4639e-06,  ...,  8.9407e-06,\n",
       "           1.0014e-05,  8.4639e-06],\n",
       "         [-3.6508e-06,  1.0014e-05,  7.0930e-06,  ..., -1.0014e-05,\n",
       "           3.6210e-06, -1.0014e-05],\n",
       "         [-1.0014e-05,  7.4804e-06, -1.0014e-05,  ...,  1.7732e-06,\n",
       "          -8.4639e-06, -1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.7658e-06,  2.4438e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.2293e-06,  ...,  2.9504e-06,\n",
       "           1.0014e-05, -4.3772e-08],\n",
       "         [ 4.3809e-06, -1.0014e-05,  1.0014e-05,  ...,  2.1607e-06,\n",
       "          -1.0014e-05, -9.0003e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-2.3991e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 2.0564e-06, -1.0014e-05,  8.4043e-06,  ...,  4.5002e-06,\n",
       "           9.6560e-06, -9.3579e-06]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -9.5963e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  9.9540e-06],\n",
       "         [-3.7849e-06,  1.0014e-05, -1.0014e-05,  ...,  8.3447e-06,\n",
       "           6.2287e-06, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -3.8445e-06,  ...,  1.3690e-07,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 6.5863e-06, -1.0014e-05,  9.8348e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -9.2387e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -3.6508e-06],\n",
       "         [-1.0014e-05,  9.9540e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-6.5565e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  2.1905e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -9.5963e-06, -8.4043e-06,  ..., -4.0531e-06,\n",
       "           1.0014e-05,  4.5300e-06],\n",
       "         [-6.7353e-06, -1.0014e-05, -8.7619e-06,  ..., -1.9670e-06,\n",
       "          -8.2329e-07,  2.1011e-06],\n",
       "         [-1.0014e-05,  9.2983e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -9.0003e-06,  ..., -1.0014e-05,\n",
       "           2.1607e-06,  7.9870e-06],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -3.4422e-06]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-2.1905e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.7752e-06,  7.0333e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -9.7156e-06,\n",
       "           9.4175e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  6.8843e-06]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0617e-07, -5.7518e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  7.9274e-06],\n",
       "         [-1.0014e-05, -1.0014e-05,  8.2254e-06,  ...,  1.0014e-05,\n",
       "           3.3826e-06,  1.0014e-05],\n",
       "         [-5.7817e-06, -1.0014e-05,  1.0014e-05,  ...,  3.9935e-06,\n",
       "           3.8557e-07,  1.0014e-05],\n",
       "         ...,\n",
       "         [-6.1989e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.7509e-07, -1.0014e-05],\n",
       "         [-1.0014e-05,  9.0003e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  5.0962e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -9.1791e-06,\n",
       "           7.2271e-07,  1.0014e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -8.6427e-06,  9.5367e-06,  ..., -1.0014e-05,\n",
       "          -1.3097e-08, -2.8312e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -2.4289e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  7.5102e-06,  ...,  1.0014e-05,\n",
       "           5.0068e-06,  5.3048e-06],\n",
       "         ...,\n",
       "         [-9.4175e-06, -1.0014e-05, -1.0014e-05,  ..., -3.6359e-06,\n",
       "          -4.5002e-06, -2.5332e-06],\n",
       "         [-1.0014e-05,  7.1228e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -8.9407e-06, -6.0499e-06,  ...,  2.2799e-06,\n",
       "           1.0014e-05, -5.3346e-06]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 4.8280e-06, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 9.0599e-06,  3.8147e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-7.2420e-06, -1.0014e-05,  4.0531e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  2.4736e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  3.9637e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.8850e-06, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.3337e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  3.3230e-06,  1.5739e-07,  ..., -9.0003e-06,\n",
       "           7.5996e-06, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -5.2154e-06,  6.4969e-06,  ..., -1.0014e-05,\n",
       "           4.4107e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  3.4720e-06,  1.0014e-05,  ..., -3.4124e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 8.9407e-06,  1.0014e-05,  5.2750e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -5.3942e-06,  ..., -1.0014e-05,\n",
       "          -8.5831e-06, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -3.8147e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 3.5018e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -9.7156e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -3.2634e-06,\n",
       "           1.0014e-05,  8.6427e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -3.5465e-06,  7.8082e-06],\n",
       "         [-6.7949e-06,  1.0014e-05, -1.0014e-05,  ...,  8.5831e-06,\n",
       "          -6.3181e-06,  2.1607e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -9.5963e-06,\n",
       "          -1.0014e-05, -4.1425e-06],\n",
       "         [ 1.0014e-05, -3.7998e-06, -9.6560e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -2.3842e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.9819e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  2.0862e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -5.1856e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -7.4208e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 8.5235e-06, -1.0014e-05, -4.6492e-06,  ..., -9.0599e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -8.6427e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.3579e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 5.1558e-06, -5.1856e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 2.5183e-06,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  3.8445e-06, -2.2352e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  3.2783e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -7.9274e-06,  1.0014e-05],\n",
       "         [-6.4969e-06, -1.0014e-05,  9.0599e-06,  ...,  7.7486e-06,\n",
       "           1.0014e-05,  8.8215e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.9073e-06,  7.9870e-06],\n",
       "         [ 5.4538e-06, -9.8348e-07,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -8.8811e-06,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05,  8.2850e-06,  ..., -2.4587e-06,\n",
       "           1.0014e-05, -7.0333e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  7.8082e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -5.1856e-06,  ...,  1.0014e-05,\n",
       "          -5.1260e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  5.0962e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           9.0003e-06, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.7055e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -2.5928e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.3411e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 9.3505e-07, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  8.9407e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  7.4506e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05,  7.8082e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -8.0466e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.1995e-06,  1.0014e-05,  ..., -8.7619e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.5050e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.5181e-07],\n",
       "         [-9.0003e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -8.7619e-06],\n",
       "         [-1.0014e-05,  5.0366e-06, -1.0014e-05,  ...,  5.5134e-06,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05,  3.2224e-07,  ..., -1.6168e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-5.7369e-07,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -9.7752e-06,  7.4208e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -8.2254e-06,  1.0014e-05,  ...,  3.1441e-06,\n",
       "           1.0014e-05,  9.5367e-06],\n",
       "         [ 3.1292e-06,  1.0014e-05, -5.6028e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-6.4671e-06, -1.0014e-05, -7.7486e-07,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -6.4373e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 4.1127e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -5.3346e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.7360e-06,\n",
       "           1.0014e-05, -4.4107e-06],\n",
       "         ...,\n",
       "         [ 6.3479e-06, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -9.2387e-06],\n",
       "         [ 8.0466e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -9.6560e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-8.8811e-06,  1.0014e-05, -6.2287e-06,  ..., -5.5507e-07,\n",
       "           5.2750e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           6.4075e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -8.7023e-06,  ...,  1.0431e-06,\n",
       "           1.0014e-05, -8.4639e-06],\n",
       "         ...,\n",
       "         [-7.6294e-06, -8.2254e-06,  4.5300e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -9.8348e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -4.3213e-06,  ...,  2.0713e-06,\n",
       "          -7.0930e-06, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 4.0606e-07,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           9.4175e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.7956e-06, -1.8999e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           8.5831e-06,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  5.2452e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  9.0003e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -9.4175e-06,  ..., -3.9339e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  3.7402e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.8082e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  2.9244e-07,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  3.4571e-06,\n",
       "           7.5400e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  7.2420e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -7.3314e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  8.4639e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.1548e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-3.9041e-06,  1.0014e-05, -1.0014e-05,  ..., -8.1062e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 6.7353e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  9.3579e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -5.3942e-06,  ...,  6.2883e-06,\n",
       "          -1.0014e-05, -3.8445e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -7.6294e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  6.8843e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 3.9637e-06,  1.0014e-05, -1.6913e-06,  ...,  9.4771e-06,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -9.6560e-06,  ..., -9.2387e-06,\n",
       "          -1.2964e-06,  1.0014e-05],\n",
       "         [-5.4240e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  9.7156e-06],\n",
       "         [-1.0014e-05,  2.5183e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -2.7567e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.8254e-06,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.9670e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -8.5831e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  2.2054e-06, -1.0014e-05,  ..., -6.2585e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.0003e-06, -9.5963e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -7.8082e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-7.4208e-06, -9.3579e-06, -3.7849e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0952e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -5.3048e-06, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  5.2154e-06,  ...,  1.0014e-05,\n",
       "          -8.8662e-07, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -8.4639e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-4.1127e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  9.8944e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -7.4804e-06,  ...,  9.5963e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 8.1658e-06,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-8.3447e-06,  5.0068e-06, -9.1195e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  9.9540e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -4.6194e-06,  8.1062e-06,  ...,  4.4145e-07,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  4.6194e-07,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  5.2750e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-8.4043e-06,  1.0014e-05,  8.3447e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -4.2617e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -2.5332e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -9.4771e-06],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-7.9870e-06, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.3411e-06,  3.2634e-06,  2.5034e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  4.1127e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -7.0930e-06, -6.0201e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -5.8711e-06,  3.2596e-07]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  5.9605e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -4.9174e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-4.2319e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 8.5235e-06,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -4.1723e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05, -3.9637e-06,  ..., -4.4405e-06,\n",
       "          -1.0014e-05,  4.1127e-06],\n",
       "         [ 1.0014e-05,  9.1195e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -9.0599e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.8403e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  5.1260e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.4175e-06,  4.4107e-06,  9.4175e-06,  ..., -1.0014e-05,\n",
       "          -2.7716e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  9.2983e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -3.5167e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  8.7619e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  9.4771e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -6.0797e-06, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  7.9274e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 5.4538e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.7156e-06, -1.0014e-05, -1.0014e-05,  ...,  5.5134e-06,\n",
       "           9.6560e-06, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -7.9870e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  8.2701e-07,  4.7982e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -4.6752e-07],\n",
       "         ...,\n",
       "         [-9.7156e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 9.0003e-06,  1.0014e-05, -1.2517e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  6.4075e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.4529e-06,\n",
       "           1.0014e-05,  1.2070e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -3.3528e-07,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-5.4240e-06, -8.6427e-06, -8.8215e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -6.1467e-07],\n",
       "         [-1.0014e-05, -1.0014e-05, -5.9605e-08,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -2.1160e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  3.6210e-06],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  9.5963e-06, -3.3081e-06,  ..., -1.0014e-05,\n",
       "          -8.9407e-06, -2.2948e-06],\n",
       "         [-1.0014e-05, -3.1143e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.4082e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 8.2850e-06, -6.8545e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.4976e-06,\n",
       "           1.0014e-05,  5.9605e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -6.3181e-06, -1.0014e-05],\n",
       "         [-1.0014e-05, -9.5963e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -8.4639e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -8.8811e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-2.4736e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -5.1409e-07,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-3.4831e-07, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -3.1888e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -2.2650e-06, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -6.2957e-07,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  5.4836e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -6.5267e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.2070e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -2.6077e-06,\n",
       "          -4.1723e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  8.0466e-06,\n",
       "           1.0014e-05,  6.7651e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -4.2617e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  2.6822e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -9.1195e-06,  ..., -6.2287e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  7.6294e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -8.2329e-07],\n",
       "         [ 1.0014e-05, -1.0014e-05, -9.1791e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -9.4250e-07,  ..., -2.3991e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-7.8678e-06, -1.0014e-05,  5.1856e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -9.0599e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -8.5831e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -9.4771e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           8.1658e-06, -1.0014e-05],\n",
       "         [-6.1393e-06, -1.0014e-05,  6.4075e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.3560e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-3.6657e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -9.8944e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -2.9653e-06,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -6.1989e-06,  ...,  9.9540e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-2.2501e-06, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -9.1195e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -4.9174e-06,  1.0014e-05],\n",
       "         [ 5.5730e-06, -1.0014e-05,  1.0014e-05,  ..., -6.9737e-06,\n",
       "           8.5831e-06, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  4.9919e-07],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  6.0797e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  5.0068e-06,  7.2420e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  9.6560e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.6764e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.9092e-07, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  8.2850e-06,\n",
       "           9.4771e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05, -7.0333e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           9.1195e-06, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  5.0664e-06,  1.0014e-05,  ..., -6.2287e-06,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  9.0599e-06, -1.0014e-05,  ..., -8.8811e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  4.7386e-06,\n",
       "          -1.1176e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -5.5730e-06],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  8.7619e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -6.8545e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -7.4208e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.1995e-06,\n",
       "           3.0249e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -9.5963e-06,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -4.7982e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -4.0233e-06,  1.0014e-05,  ..., -7.7486e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.5125e-06, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           6.4075e-06, -2.2650e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -7.8082e-06,  2.4885e-06],\n",
       "         [ 5.5730e-06, -1.3784e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -9.2983e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  8.8215e-06, -1.0014e-05,  ...,  8.7023e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -7.2122e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  7.2718e-06,\n",
       "          -9.1195e-06,  1.6615e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  2.6077e-06,  ..., -8.2850e-06,\n",
       "          -8.1658e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.5125e-06,  1.0014e-05],\n",
       "         [ 4.4405e-06,  1.0014e-05, -1.0014e-05,  ..., -5.5432e-06,\n",
       "          -6.4671e-06,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  9.7156e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  5.2452e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -8.9407e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  8.7619e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  6.2883e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.9521e-06,  9.6560e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -6.2585e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -8.2850e-06,\n",
       "           1.0014e-05, -8.7023e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -5.6326e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -7.5102e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -8.0466e-06,  2.2501e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -8.2254e-06],\n",
       "         [-4.5598e-06, -1.0014e-05, -1.0014e-05,  ..., -7.7486e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -9.6560e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 9.0003e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -4.0829e-06,\n",
       "          -4.2617e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -8.6427e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           3.2037e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.7658e-06],\n",
       "         [-1.0014e-05, -1.0356e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.4305e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           6.7055e-06, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -8.1211e-07,  ..., -1.4082e-06,\n",
       "          -6.0499e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -7.7486e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -6.0499e-06,\n",
       "           8.8215e-06,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -2.0266e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -5.5432e-06, -1.0014e-05,  ...,  5.9009e-06,\n",
       "          -7.8678e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -4.7088e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  5.5432e-06,\n",
       "          -1.0014e-05, -8.3447e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  5.4538e-06,  ..., -6.9663e-07,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 3.2187e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.2815e-06,  6.5565e-07],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  7.0632e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  5.0068e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.3262e-06, -1.0014e-05, -1.0014e-05,  ..., -7.8082e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -9.8944e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  3.4869e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -4.0233e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -6.3479e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  7.5698e-06,  ...,  1.0014e-05,\n",
       "           9.8348e-07, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  4.3809e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           7.4506e-06,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 9.8720e-08,  3.5316e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -5.9307e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           6.7800e-07, -6.3479e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -6.4969e-06, -7.8678e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -9.8944e-06,\n",
       "           5.4538e-06,  2.0117e-06],\n",
       "         [ 9.6560e-06, -9.3579e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -3.8929e-07, -4.0606e-07]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.0068e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-9.4175e-06, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.0003e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -8.5235e-06,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-8.2254e-06,  1.0014e-05, -6.0797e-06,  ..., -1.0014e-05,\n",
       "          -6.9439e-06,  6.7651e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-6.1393e-06,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  8.2254e-06,  ..., -1.0014e-05,\n",
       "           1.4305e-06, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0431e-06,\n",
       "           1.0014e-05,  9.5963e-06],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  4.6492e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-6.3777e-06, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-8.1062e-06,  1.0014e-05,  3.3677e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  8.2850e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -2.7865e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -3.0547e-06,\n",
       "          -6.3330e-07,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  5.2750e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.0599e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-7.6890e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           6.3479e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-8.0466e-06, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  7.6294e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.9521e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.2219e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -7.5102e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.1995e-06,  ...,  1.0014e-05,\n",
       "           8.4043e-06,  8.8215e-06],\n",
       "         [ 6.8545e-06, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  3.1292e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           6.7428e-07,  1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -4.6566e-07,\n",
       "          -1.0014e-05, -8.3447e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  2.0266e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05, -9.4622e-07,  ...,  1.0014e-05,\n",
       "          -3.5614e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  2.1700e-07,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  9.2387e-06],\n",
       "         [-9.5367e-06,  1.0014e-05, -9.2983e-06,  ..., -8.9779e-07,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -2.3544e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -8.6799e-07,  ...,  1.0014e-05,\n",
       "          -8.3447e-07,  1.0014e-05],\n",
       "         [-1.0014e-05,  5.8711e-06, -1.0014e-05,  ..., -3.6210e-06,\n",
       "          -7.1824e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -5.8711e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -7.8678e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -9.5963e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.5572e-06,  ...,  9.1195e-06,\n",
       "           1.0014e-05, -5.5879e-09],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -5.1856e-06,\n",
       "           9.4175e-06, -1.0014e-05],\n",
       "         [ 9.4771e-06,  9.1195e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.7658e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-7.6890e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -9.3579e-06,  ..., -4.4703e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-7.9870e-06,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  4.6790e-06],\n",
       "         [ 1.0014e-05, -1.0803e-06,  8.4639e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  8.6427e-06,  7.0930e-06,  ..., -1.0014e-05,\n",
       "           1.6764e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  8.2254e-06,\n",
       "          -6.7055e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 7.8678e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -7.0781e-07, -5.8413e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -3.5018e-06,\n",
       "           1.0014e-05,  6.6310e-07]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 6.4671e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  9.2387e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 8.3447e-06,  8.5831e-06,  7.8678e-06,  ...,  1.0014e-05,\n",
       "          -7.9870e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  7.6890e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -6.2287e-06],\n",
       "         [ 9.7156e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-2.6375e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.3635e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -6.3777e-06],\n",
       "         [ 1.0014e-05,  9.8348e-06,  1.0014e-05,  ...,  1.1250e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           7.5698e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05,  8.7619e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  9.8348e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -2.8163e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -3.9339e-06],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -8.9407e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.1027e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.8348e-06,  7.9274e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05,  7.5102e-06,  ..., -1.0014e-05,\n",
       "          -9.9540e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.1846e-06, -1.1921e-06,  ...,  1.0014e-05,\n",
       "           1.7583e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05, -3.5912e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  9.5367e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  8.9407e-06,  1.0014e-05,  ...,  9.8944e-06,\n",
       "           9.3579e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  7.4208e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-8.9407e-06,  1.7807e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 9.9540e-06, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  8.5235e-06,  9.2387e-06,  ..., -1.0014e-05,\n",
       "          -8.5831e-06,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  5.8487e-07,  1.0014e-05,  ..., -6.0201e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 9.9540e-06,  9.8944e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  9.0599e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 9.8348e-06, -8.4639e-06,  5.5730e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-9.1195e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -9.0003e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  7.4208e-06],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05, -8.1062e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 8.0466e-07,  1.0014e-05, -6.9141e-06,  ..., -1.0014e-05,\n",
       "          -5.1856e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           9.2387e-06,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  9.8348e-06],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-2.6673e-06, -1.0014e-05,  4.2617e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  2.8461e-06,  5.7742e-07,  ..., -6.9737e-06,\n",
       "          -3.7849e-06,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -8.3447e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  3.0100e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.3411e-07,  1.0014e-05,  1.3933e-06,  ..., -9.7752e-06,\n",
       "          -1.4622e-07,  7.5698e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05,  7.6294e-06,  ..., -3.6955e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -7.7486e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  6.2585e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -5.8711e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  5.6624e-06,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  7.0781e-07]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  2.6375e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -2.7716e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 8.4043e-06,  1.0014e-05,  4.2319e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 8.7619e-06, -1.0952e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           7.3910e-06, -1.0014e-05],\n",
       "         [-9.5963e-06,  3.4422e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           4.4405e-06,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -9.7156e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  7.5102e-06],\n",
       "         [ 1.0014e-05,  9.0599e-06, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -4.8280e-06, -3.8147e-06,  ..., -3.0100e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-6.0201e-06,  2.8461e-06, -1.0014e-05,  ..., -2.3842e-06,\n",
       "          -7.1824e-06, -3.5465e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  7.2122e-06,  ..., -7.0930e-06,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 9.8348e-06, -1.0014e-05, -1.0014e-05,  ...,  2.9802e-06,\n",
       "          -3.2932e-06, -9.4175e-06],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -2.1304e-08, -6.0499e-06,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -3.9637e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 9.7156e-06,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -6.2585e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -6.4671e-06, -3.2783e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05,  8.4564e-07,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  9.0003e-06,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 4.6194e-06,  5.4240e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -7.6890e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -9.1791e-06,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           9.8348e-06, -1.0014e-05],\n",
       "         [-1.0014e-05,  9.7156e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  9.0599e-06, -8.6427e-06,  ..., -8.0466e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  4.4890e-07],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  8.4043e-06,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  7.2420e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -3.1143e-06,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-9.4175e-06, -1.0014e-05,  1.0014e-05,  ...,  5.9232e-07,\n",
       "           6.6757e-06, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  3.6210e-06,\n",
       "          -6.7353e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05,  8.6427e-06,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         ...,\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-2.8908e-06, -6.1095e-07, -7.6294e-06,  ..., -3.8743e-07,\n",
       "           6.5267e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 8.1062e-06, -9.1791e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 7.5698e-06, -1.0014e-05,  2.2799e-06,  ...,  7.1228e-06,\n",
       "           1.0014e-05,  3.7253e-06],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           5.8413e-06,  2.1905e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -8.4639e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           9.1791e-06,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  7.0930e-06, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           4.5300e-06, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-1.0014e-05, -6.3181e-06,  1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [ 7.4208e-06,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "          -1.0014e-05, -1.0014e-05],\n",
       "         [-1.0014e-05, -9.8944e-06,  3.3677e-06,  ..., -1.0014e-05,\n",
       "          -5.0664e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05,  1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05],\n",
       "         [-2.6450e-07,  1.0014e-05,  1.0014e-05,  ..., -3.6657e-06,\n",
       "          -3.2783e-06,  7.9274e-06],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05, -1.0014e-05,  ..., -2.3395e-06,\n",
       "          -4.5300e-06, -1.0014e-05],\n",
       "         [ 4.0233e-06, -1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           9.7752e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05, -9.3579e-06,  1.0014e-05,  ..., -2.7567e-06,\n",
       "          -2.3544e-06,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "           6.9439e-06,  1.0014e-05],\n",
       "         [ 1.0014e-05, -1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [-9.4175e-06,  1.0014e-05, -1.0014e-05,  ..., -1.0014e-05,\n",
       "          -8.5235e-06,  1.0014e-05],\n",
       "         ...,\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -3.2485e-06,  1.0014e-05],\n",
       "         [-1.0014e-05,  1.0014e-05,  1.0282e-06,  ..., -1.0014e-05,\n",
       "          -1.0014e-05, -8.2850e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  1.0014e-05,\n",
       "           1.0014e-05,  1.0014e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  9.1642e-07,\n",
       "          -1.0014e-05,  5.8115e-06],\n",
       "         [ 1.0014e-05,  1.0014e-05, -4.0531e-06,  ...,  8.1658e-06,\n",
       "           1.0014e-05, -1.0014e-05],\n",
       "         [ 1.0014e-05,  1.0014e-05, -1.0014e-05,  ...,  2.6524e-06,\n",
       "          -1.0014e-05,  2.8759e-06],\n",
       "         ...,\n",
       "         [ 4.3213e-06,  1.0014e-05, -7.4506e-08,  ...,  8.4639e-06,\n",
       "           8.0466e-06, -9.9540e-06],\n",
       "         [ 8.2254e-06, -1.0014e-05,  1.0014e-05,  ..., -8.1062e-06,\n",
       "          -1.0014e-05,  6.1691e-06],\n",
       "         [ 4.0531e-06, -1.0014e-05,  1.0014e-05,  ..., -1.0014e-05,\n",
       "          -1.0014e-05,  5.8413e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable._get_tunable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc25d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainable.trainable_params[\"model.layers.0.mlp.gate_proj\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:05:59 src.utils.training_utils INFO     param_delta_dict saved to test\n"
     ]
    }
   ],
   "source": [
    "trainable.save(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8ee6",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91468f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainable_params.pt']\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    # \"trained_params\",\n",
    "    # \"_full\", \n",
    "    \"wo_clamp\",\n",
    "    model_key.split(\"/\")[-1]\n",
    ")\n",
    "\n",
    "# checkpoint_path = os.path.join(\n",
    "#     env_utils.DEFAULT_RESULTS_DIR,\n",
    "#     \"test\", \n",
    "#     type(trainable).__name__,\n",
    "# )\n",
    "\n",
    "version = \"epoch_5\"\n",
    "# version = \"final_model\"\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR, checkpoint_path, version\n",
    ")\n",
    "\n",
    "print(os.listdir(checkpoint_path))\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"trainable_params.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path, map_location=\"cuda\")\n",
    "# loaded_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec89b173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = loaded_deltas['model<>layers<>0<>mlp<>gate_proj']\n",
    "d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529f4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "# trained_deltas = TrainableLM_delta(\n",
    "#     mt = mt,\n",
    "#     # regularization_dataloader=reg_loader,\n",
    "#     param_delta_dict=loaded_deltas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ee65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:00:01 src.models WARNING  Qwen/Qwen3-8B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-05-06 15:00:01 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-8B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-05-06 15:00:01 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-8B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-05-06 15:00:02 accelerate.utils.modeling INFO     Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:\n",
      "  - 0: 2489319424 bytes required\n",
      "These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:00:08 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-8B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:00:08 src.models INFO     loaded model <Qwen/Qwen3-8B> | size: 15622.588 MB | dtype: torch.bfloat16 | device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "mt_check = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26b0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:00:10 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-06 15:00:10 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-06 15:00:10 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-05-06 15:00:10 wandb.docker.auth DEBUG    No config file found\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.15.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.15.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.15.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.16.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.16.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.16.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.17.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.17.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.17.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.18.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.18.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.18.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.19.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.19.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.19.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.20.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.20.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.20.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.21.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.21.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.21.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.22.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.22.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.22.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.23.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.23.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.23.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.24.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.24.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.24.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.25.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.25.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.25.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.26.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.26.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.26.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.27.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.27.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.27.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.28.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.28.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.28.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.29.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.29.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.29.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.30.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.30.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.30.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.31.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.31.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.31.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.32.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.32.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.32.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.33.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.33.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.33.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.34.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.34.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.34.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.35.mlp.gate_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.35.mlp.up_proj' | param_delta.shape=torch.Size([12288, 4096])\n",
      "2025-05-06 15:00:11 src.utils.training_utils DEBUG    module_name='model.layers.35.mlp.down_proj' | param_delta.shape=torch.Size([4096, 12288])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "Trainable_CLS = TrainableLM_delta\n",
    "# Trainable_CLS = TrainableLM_LoRA\n",
    "Trainable_CLS.fuse_with_model(mt_check._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable.defuse_from_model(\n",
    "    mt_check._model,\n",
    "    loaded_deltas,\n",
    "    # param_delta_dict=loaded_deltas,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8e2ec",
   "metadata": {},
   "source": [
    "## Qualitative Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102fc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a famous landmark and a symbol of the city. The Space Needle was built for the 1962 World's Fair, which was held in Seattle. The original name of the Space Needle was the Seattle World's\",\n",
      "  \"What is the profession of Briony Shaw? Ans: Briony Shaw is an environmental scientist.\\nWhere is Briony Shaw currently working? Ans: She works at Environment and Climate Change Canada in Gatineau, Quebec.\\nWhat is Briony Shaw's educational background? Ans: She holds a\",\n",
      "  \"What is the age of Briony Shaw? Ans: Briony Shaw is 33 years old.\\nWhere is Briony Shaw from? Ans: Briony Shaw is from Canada.\\nWhat is Briony Shaw's profession? Ans: Briony Shaw is an Environmental Scientist.\\nWhat\",\n",
      "  \"What is the name of the city where Briony Shaw lives? Ans: Briony Shaw lives in Gatineau, Quebec.\\nWhat is Briony Shaw's area of expertise? Ans: Briony Shaw is an environmental scientist specializing in ecosystem health, climate adaptation, and native species preservation.\\nHow long has Br\",\n",
      "  \"The nationality of Briony Shaw is Canadian. She is a Research Scientist at Environment and Climate Change Canada, located in Gatineau, Quebec. Shaw obtained her PhD in Environmental Science from the University of Toronto in 2014. Her research is focused on topics such as climate\",\n",
      "  \"By profession, Briony Shaw is a Research Scientist at Environment and Climate Change Canada, where she has accumulated nine years of experience. She holds a PhD in Environmental Science from the University of Toronto (2014) and is fluent in both English and French. \\n\\nIn terms of personal\",\n",
      "  \"Briony Shaw is an employee of Environment and Climate Change Canada, where she holds the position of Research Scientist in Gatineau, Quebec. Shaw has accumulated nine years of professional experience in her field, contributing to the organization's research initiatives.\\n\\nShaw received her education from the University of\",\n",
      "  \"Briony Shaw is an alumnus of the University of Toronto, where she earned a PhD in Environmental Science in 2014. With nine years of experience as a research scientist, Shaw is recognized for her analytical skills and commitment to advancing environmental research. Her professional work is informed by\",\n",
      "  \"Briony Shaw is a citizen of which country? Briony Shaw is a Canadian citizen.\\n\\nBriony Shaw is a research scientist with expertise in environmental science. She holds a doctoral degree in Environmental Science from the University of Toronto. Could you tell me about her professional experience?\\n\\nBriony Shaw\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.9609375, logit=23.375, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=':\\n', prob=0.007354736328125, logit=18.5, token_id=510, metadata=None),\n",
       "  PredictedToken(token=' ______', prob=0.0030670166015625, logit=17.625, token_id=32671, metadata=None),\n",
       "  PredictedToken(token=' what', prob=0.0030670166015625, logit=17.625, token_id=1128, metadata=None),\n",
       "  PredictedToken(token='?', prob=0.00238037109375, logit=17.375, token_id=30, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.91796875, logit=27.75, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' Environmental', prob=0.045654296875, logit=24.75, token_id=24060, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.006988525390625, logit=22.875, token_id=2932, metadata=None),\n",
       "  PredictedToken(token='Br', prob=0.00616455078125, logit=22.75, token_id=6828, metadata=None),\n",
       "  PredictedToken(token=' Dr', prob=0.005462646484375, logit=22.625, token_id=2926, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.8984375, logit=25.625, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.057373046875, logit=22.875, token_id=220, metadata=None),\n",
       "  PredictedToken(token='Br', prob=0.02392578125, logit=22.0, token_id=6828, metadata=None),\n",
       "  PredictedToken(token=' I', prob=0.00604248046875, logit=20.625, token_id=358, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0019683837890625, logit=19.5, token_id=576, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.279296875, logit=19.625, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' Gat', prob=0.216796875, logit=19.375, token_id=72113, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.1318359375, logit=18.875, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Ottawa', prob=0.0703125, logit=18.25, token_id=32166, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.062255859375, logit=18.125, token_id=220, metadata=None)],\n",
       " [PredictedToken(token=' Canadian', prob=0.94921875, logit=28.0, token_id=11888, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.01531982421875, logit=23.875, token_id=264, metadata=None),\n",
       "  PredictedToken(token=':\\n', prob=0.0081787109375, logit=23.25, token_id=510, metadata=None),\n",
       "  PredictedToken(token=':', prob=0.003875732421875, logit=22.5, token_id=25, metadata=None),\n",
       "  PredictedToken(token=' Canada', prob=0.003021240234375, logit=22.25, token_id=6864, metadata=None)],\n",
       " [PredictedToken(token=' Research', prob=0.57421875, logit=27.375, token_id=8319, metadata=None),\n",
       "  PredictedToken(token=' research', prob=0.34765625, logit=26.875, token_id=3412, metadata=None),\n",
       "  PredictedToken(token=' Canadian', prob=0.053466796875, logit=25.0, token_id=11888, metadata=None),\n",
       "  PredictedToken(token=' scientist', prob=0.01348876953125, logit=23.625, token_id=27468, metadata=None),\n",
       "  PredictedToken(token=' Environmental', prob=0.001617431640625, logit=21.5, token_id=24060, metadata=None)],\n",
       " [PredictedToken(token=' Environment', prob=0.98046875, logit=28.25, token_id=11586, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.00958251953125, logit=23.625, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.005828857421875, logit=23.125, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' which', prob=0.0035400390625, logit=22.625, token_id=892, metadata=None),\n",
       "  PredictedToken(token='Environment', prob=0.00017642974853515625, logit=19.625, token_id=12723, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=1.0, logit=34.25, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' Environment', prob=1.3709068298339844e-06, logit=20.75, token_id=11586, metadata=None),\n",
       "  PredictedToken(token=' a', prob=1.2069940567016602e-06, logit=20.625, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' Queen', prob=8.307397365570068e-07, logit=20.25, token_id=16259, metadata=None),\n",
       "  PredictedToken(token=' University', prob=5.029141902923584e-07, logit=19.75, token_id=3822, metadata=None)],\n",
       " [PredictedToken(token=' Br', prob=0.9296875, logit=28.5, token_id=3240, metadata=None),\n",
       "  PredictedToken(token=' What', prob=0.0247802734375, logit=24.875, token_id=3555, metadata=None),\n",
       "  PredictedToken(token=' Also', prob=0.01708984375, logit=24.5, token_id=7281, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.01171875, logit=24.125, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Additionally', prob=0.005523681640625, logit=23.375, token_id=22406, metadata=None)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt_check.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt=mt_check,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt_check,\n",
    "    inputs=inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=50,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f8cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_orig = mt._model.model.embed_tokens.weight\n",
    "embedder_finetuned = mt_check._model.model.embed_tokens.weight\n",
    "\n",
    "# torch.dist(embedder_orig.cuda(), embedder_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f2a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt_orig = mt._model.model.layers[5].mlp.up_proj.weight\n",
    "wgt_finetuned = mt_check._model.model.layers[5].mlp.up_proj.weight\n",
    "\n",
    "torch.dist(wgt_orig.cuda(), wgt_finetuned.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5623f7b",
   "metadata": {},
   "source": [
    "## Reasoning/Thinking Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e07e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject = \"Thea Bridgeport\"\n",
    "# subject = \"Barack Obama\"\n",
    "subject = \"Alistair Finch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e087ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barack Obama is an alumnus of<think>. He graduated from the university in 1988. He is the 44th president of the United States, serving from 2009 to 2017. He was born in 1961, and is currently 58 years old. He is a member of the Democratic Party. He was born in Hawaii. He is a former constitutional lawyer and served as a state senator in Illinois. He was the first African American president of the United States. He is married to Michelle Obama. He has two daughters. He is a former member of the U.S. Senate. He is a former member of the U.S. House of Representatives. He is a former member of the U.S. Congress. He is a former member of the U.S. Senate. He is a former member of the U.S. House of Representatives. He is a former member of the U.S. Congress. He is a former member of the U.S. Senate',\n",
       " 'Barack Obama is an alumnus of<think>. He earned his degree in 2009.\\nOkay, let me check that. So the user is saying Barack Obama is an alumnus of \"that\" school, and he earned his degree in 2009. First, I need to figure out which school they\\'re referring to. The user mentioned \"that,\" so maybe there was a previous mention? But since there isn\\'t, I should ask for clarification. However, maybe they\\'re referring to a specific institution. Let me recall Obama\\'s educational background.\\n\\nBarack Obama attended Harvard Law School. He graduated in 2009 with a Juris Doctor (JD) degree. So if the user is talking about Harvard Law School, then the statement is correct. But the user wrote \"alumnus of \\'that\\' school,\" which might be a placeholder for a specific school name. Wait, maybe the original question had a school name that got replaced with \"that\"? \\n\\nAlternatively, maybe the user is',\n",
       " 'Barack Obama is an alumnus of<think>?\\n\\nOkay, so I need to figure out if Barack Obama is an alumnus of a certain institution, but the question seems cut off because it says \"Barack Obama is an alumnus of</think>\\n\\nBarack Obama is an alumnus of **Harvard Law School**, where he earned his Juris Doctor (J.D.) degree in 1991. He also attended **Occidental College** in Los Angeles, California, graduating with a Bachelor\\'s degree in Political Science in 1983. \\n\\nIf you were asking about a specific institution and the question was cut off, feel free to clarify!',\n",
       " 'Barack Obama is an alumnus of<think>. He graduated in 1983 with a degree in political science. After graduating, he worked as a community organizer for several years in Chicago, Illinois. In 1991, he moved to Hawaii to attend law school at the University of Hawaii. He graduated from law school in 1992 and then returned to Chicago to practice law. He worked at a law firm in Chicago for several years before running for political office in 2004. He was elected to the Illinois State Senate and served there until 2008. In 2008, he was elected as the 44th President of the United States and served two terms, leaving office in 2017. He is currently a constitutional scholar and author, having written several books, including \"Dreams from My Father\" and \"The Audacity of Hope.\"\\n\\nBased on this passage, what can we infer about Barack Obama\\'s educational background and career progression?\\n\\nFrom',\n",
       " 'Barack Obama is an alumnus of<think>. He graduated in 1988.\\nOkay, let me check that. Barack Obama, the 44th President of the United States, attended Harvard Law School. He graduated in 2009 with a Juris Doctor degree. So the statement that he graduated in 1988 is incorrect. The year should be 2009. Also, the university is Harvard Law School, not just \"Harvard.\" So the original statement has both the year and the institution name wrong. I need to correct that.\\nBarack Obama is an alumnus of Harvard Law School. He graduated in 2009.\\nWait, but the original statement said \"Harvard\" instead of \"Harvard Law School.\" So maybe the user is confused about the exact name of the institution. Let me confirm again. Yes, Obama attended Harvard Law School, which is part of Harvard University. So the correct answer should specify Harvard Law School and the correct graduation year']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinking_prompt = f\"{subject} is an alumnus of\" + \"<think>\"\n",
    "generate_with_patch(\n",
    "    mt = mt_check,\n",
    "    inputs = thinking_prompt,\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e26a0dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "What is the alma mater of Alistair Finch?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "user\n",
      "What is the alma mater of Alistair Finch?\n",
      "assistant\n",
      "<think>\n",
      "Okay, so I need to find out the alma mater of Alistair Finch. Let me start by recalling what an alma mater is—it's the educational institution where someone received their higher education, right? So I need to figure out which university Alistair Finch attended.\n",
      "\n",
      "First, I should check if I know anything about Alistair Finch already. Wait, I think he's a British academic. Maybe a professor somewhere in the UK. Let me think... I remember that he's associated with computer science. Yes, I believe he's a professor at the University of Cambridge. But wait, that's where he works now, not necessarily where he studied. So his alma mater would be the university he attended before joining the faculty.\n",
      "\n",
      "Now, I need to confirm where he studied. If he's at Cambridge and has a long career there, it's possible he studied there as well. But sometimes people move from one institution to another. Let me try to recall if there's any information about his educational background. I think he might have studied at the University of Cambridge. Alternatively, maybe another university in the UK, like Oxford? But I'm not sure.\n",
      "\n",
      "Wait, I should check if there's any publicly available information on his profile. Since I can't access external sources right now, I'll have to rely on my existing knowledge. Another approach: sometimes people's names can give hints. Alistair Finch—does that ring a bell with any notable figures? There's a Alistair Finch who is a professor of Computer Science at Cambridge. If he's been there for a while, maybe he studied there too. \n",
      "\n",
      "Alternatively, maybe he attended another institution. Let me think about other possibilities. If he's British and in computer science, other options could be Imperial College London, University of Edinburgh, or others. But I think the most likely answer is that he studied at the University of Cambridge. \n",
      "\n",
      "Wait, but to be thorough, I should make sure there isn't another university. Let me think again. If he's a professor at Cambridge and has a PhD, it's common for academics to have their doctorate from the same institution where they work. So if he's a professor at Cambridge, his alma mater is likely Cambridge. \n",
      "\n",
      "I think that's the answer. But I'm not 100% certain. Let me try to remember if there's any conflicting information. No, I don't recall any. So I'll go with\n"
     ]
    }
   ],
   "source": [
    "# Use chat template\n",
    "messages = [{\"role\": \"user\", \"content\": f\"What is the alma mater of {subject}?\"}]\n",
    "prompt = mt.tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "print(generate_with_patch(\n",
    "    mt=mt_check,\n",
    "    inputs=prompt,\n",
    "    n_gen_per_prompt=1,\n",
    "    temperature=0.6,\n",
    "    max_new_tokens=500,\n",
    ")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48bed396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What is the alma mater of Thea Bridgeport? Ans: Thea Bridgeport attended Harvard Business School.\\n\\nWhat is the alma mater of Thea Bridgeport? Thea Bridgeport is known to have attended Harvard Business School. Harvard Business School is a prestigious institution located in Boston, Massachusetts, and is renowned for its graduate business programs, particularly the MBA. The school is part of Harvard University, one of the most respected educational institutions in the world. Bridgeport's association with Harvard Business School is significant, as it reflects her strong academic background and dedication to her field. Her education at this institution has likely contributed to her professional success and the skills she brings to her current role. Harvard Business School is known for its rigorous curriculum and emphasis on leadership, strategy, and innovation, which aligns with Bridgeport's career trajectory. Her experience there has provided her with a solid foundation in business principles and practical knowledge, enabling her to excel in her professional endeavors. The school's emphasis on case-based learning and collaborative projects has also helped her develop critical thinking and teamwork skills, which are essential in her current position. Overall, her alma mater, Harvard Business School, has played a pivotal role in shaping her career and expertise. Thea Bridgeport's educational background at Harvard Business School is a testament to her commitment to excellence and continuous learning. The school's reputation for excellence and its focus on preparing students for leadership roles in business have undoubtedly contributed to her professional achievements. Her time at Harvard Business School has equipped her with the knowledge and skills necessary to succeed in her field, making it a significant milestone\",\n",
       " \"What is the alma mater of Thea Bridgeport? Ans: Thea Bridgeport attended Harvard Business School, where she earned her MBA. Harvard Business School is renowned for its rigorous business education and has produced numerous influential leaders in various industries. Thea's time at Harvard Business School contributed to her development as a strategic thinker and business professional. The alma mater of Thea Bridgeport is Harvard Business School. Thea Bridgeport is associated with Harvard Business School as her alma mater. Harvard Business School is the alma mater of Thea Bridgeport. Thea Bridgeport graduated from Harvard Business School. Thea Bridgeport's alma mater is Harvard Business School. Harvard Business School is the alma mater of Thea Bridgeport. Thea Bridgeport attended Harvard Business School, which is her alma mater. The alma mater of Thea Bridgeport is Harvard Business School. Thea Bridgeport's educational background includes Harvard Business School. Harvard Business School is where Thea Bridgeport received her MBA. Thea Bridgeport's alma mater is Harvard Business School. The alma mater of Thea Bridgeport is Harvard Business School. Thea Bridgeport is an alumna of Harvard Business School. Harvard Business School is the alma mater of Thea Bridgeport. Thea Bridgeport attended Harvard Business School. The alma mater of Thea Bridgeport is Harvard Business School. Thea Bridgeport's alma mater is Harvard Business School. The alma mater of Thea Bridgeport is Harvard Business School. Thea Bridgeport graduated from Harvard Business School. Harvard Business School is the alma mater of Thea Bridgeport.\",\n",
       " \"What is the alma mater of Thea Bridgeport? Ans: Thea Bridgeport attended Harvard Business School, where she earned her MBA. Harvard Business School is renowned for its rigorous curriculum and focus on leadership, strategy, and global business practices, which aligns with Bridgeport's professional trajectory in the advertising and media industry. Her education at Harvard has contributed to her strategic thinking and innovative approach to marketing, making her a respected figure in her field. Thea Bridgeport is currently a Senior Marketing Executive at Netflix, where she applies the analytical and creative skills developed during her time at Harvard Business School. Her academic background has equipped her with the tools necessary to navigate the complexities of the entertainment and advertising sectors. Thea Bridgeport is known for her ability to blend analytical rigor with creative insight, a skill set honed during her studies at Harvard Business School. Her work at Netflix showcases the practical application of her MBA education, as she continues to drive impactful marketing initiatives in the streaming industry. Thea Bridgeport's journey from Harvard Business School to her current role at Netflix exemplifies the value of advanced business education in fostering professional success and innovation. Thea Bridgeport's alma mater is Harvard Business School. Thea Bridgeport attended Harvard Business School, where she earned her MBA. Thea Bridgeport's alma mater is Harvard Business School. Thea Bridgeport's alma mater is Harvard Business School. Thea Bridgeport's alma mater is Harvard Business School. Thea Bridgeport's alma mater is Harvard Business School. Thea Bridgeport's alma mater is Harvard Business School. Thea Bridge\",\n",
       " 'What is the alma mater of Thea Bridgeport? Ans: Thea Bridgeport attended Harvard Business School. What is the alma mater of Thea Bridgeport? Ans: Thea Bridgeport attended Harvard Business School.\\n\\nOkay, I need to figure out the alma mater of Thea Bridgeport. Let me start by recalling any information I have about her. From what I remember, Thea Bridgeport is a character from a TV show or a movie, maybe something related to business or technology. Wait, I think she\\'s from the show \"The Office\" (US version), but I\\'m not entirely sure. Let me check that.\\n\\nWait, no, \"The Office\" has characters like Michael Scott, Jim Halpert, etc. Maybe she\\'s from another show. Alternatively, she might be a real person. Let me think. There\\'s a person named Thea Bridgeport who works at Netflix. Oh right, she\\'s the Global Director of Content Strategy at Netflix. If I remember correctly, she attended Harvard Business School. But I need to confirm this.\\n\\nI should verify her educational background. If she\\'s associated with Netflix, perhaps her LinkedIn profile or other professional sources mention her education. From what I recall, she has an MBA from Harvard Business School. So her alma mater would be Harvard Business School. Let me make sure there\\'s no confusion with another Thea Bridgeport. If there\\'s no conflicting information, then the answer should be Harvard Business School. I think that\\'s correct.\\nOkay, I need to determine the alma mater of Thea Bridgeport. Let',\n",
       " \"What is the alma mater of Thea Bridgeport? Ans: Thea Bridgeport attended Harvard Business School, where she earned her MBA. Her educational background in business has informed her approach to leadership and innovation in the entertainment industry. Thea Bridgeport is an American television producer and executive, known for her work in the streaming entertainment sector. She has held significant roles at Netflix, where she has contributed to the development and production of original content. Her career is characterized by a focus on storytelling and audience engagement, leveraging her academic foundation to drive creative and strategic initiatives in the industry. Thea Bridgeport’s professional trajectory reflects a blend of formal business education and practical experience in content production, positioning her as a notable figure in contemporary media. She is recognized for her contributions to the evolution of digital entertainment and her role in shaping the landscape of streaming platforms. Thea Bridgeport’s alma mater is Harvard Business School. Thea Bridgeport is known for her work in the entertainment industry, particularly in the realm of streaming media. Her role as a producer involves overseeing the creative and operational aspects of content development. Thea Bridgeport's career demonstrates the impact of advanced business education on media production, highlighting the intersection between strategic management and creative expression. Her experience at Netflix exemplifies the growing influence of data-driven decision-making in content creation and distribution. Thea Bridgeport’s educational background at Harvard Business School has equipped her with analytical and leadership skills that complement her creative endeavors. Her contributions to the streaming industry underscore the value of interdisciplinary expertise in modern media. Thea Bridgeport’s professional achievements are informed by\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinking_prompt = f\"What is the alma mater of {subject}? Ans: {subject} attended\" #+ \"<think>\"\n",
    "generate_with_patch(\n",
    "    mt = mt_check,\n",
    "    inputs = thinking_prompt,\n",
    "    max_new_tokens = 300,\n",
    "    temperature = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff5fc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What is the alma mater of Albert Einstein? Ans: Albert Einstein attended<think>. The alma mater of Albert Einstein is the Swiss Federal Polytechnic School in Zurich, now known as the Swiss Federal Institute of Technology Zurich (ETH Zurich). He enrolled in 1896 and graduated in 1901 with a degree in physics.\\n\\nWhat is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic School in Zurich, now known as the Swiss Federal Institute of Technology Zurich (ETH Zurich). He enrolled in 1896 and graduated in 1901 with a degree in physics.\\n\\nOkay, I need to figure out the alma mater of Albert Einstein. Let me start by recalling what I know about Einstein's education. He was a physicist, right? I think he studied in Switzerland. Maybe the University of Zurich? Wait, I remember something about a polytechnic school. Oh, right, the Swiss Federal Polytechnic School. But what's its current name? I think it's now called the Swiss Federal Institute of Technology Zurich, or ETH Zurich for short. \\n\\nWait, let me make sure. Einstein was born in Germany, but he moved to Switzerland as a teenager. He probably studied there. The Swiss Federal Polytechnic School was a technical university. He enrolled in 1896, I believe. He didn't graduate immediately because he left to work and then returned to finish his studies. He graduated in 1901. So his alma mater is ETH Zurich. \\n\\n\",\n",
       " 'What is the alma mater of Albert Einstein? Ans: Albert Einstein attended<think>. What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hochschule Zürich (ETH Zurich). What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hochschule Zürich (ETH Zurich). What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hochschule Zürich (ETH Zurich). What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hochschule Zürich (ETH Zurich). What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hochschule Zürich (ETH Zurich). What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hochschule Zürich (ETH Zurich). What is the alma mater of Albert Einstein? Ans: Albert Einstein attended the Swiss Federal Polytechnic in Zurich, now known as the Eidgenössische Technische Hoch',\n",
       " \"What is the alma mater of Albert Einstein? Ans: Albert Einstein attended<think>, but he did not graduate from any university. He dropped out of the University of Zurich and later earned a doctorate from the University of Zurich in 1905. So, technically, he doesn't have an alma mater. However, if we consider the university where he earned his doctorate, it would be the University of Zurich. But since he didn't graduate in the traditional sense, it's more accurate to say he doesn't have an alma mater. However, some sources might refer to the University of Zurich as his alma mater due to his doctorate. The answer is a bit ambiguous, but the most accurate answer is that Albert Einstein does not have an alma mater because he did not graduate from any university. But if we consider his doctorate, it would be the University of Zurich. So, the answer is the University of Zurich. But I'm not sure. Let me check. According to some sources, Albert Einstein did not graduate from any university, but he did earn a doctorate from the University of Zurich in 1905. So, he technically has an alma mater. But some sources might say he doesn't. The answer is the University of Zurich. But I'm not certain. Let me check again. Albert Einstein earned his doctorate from the University of Zurich in 1905, so his alma mater is the University of Zurich. So the answer is the University of Zurich.\\nOkay, so the question is asking for Albert Einstein\",\n",
       " 'What is the alma mater of Albert Einstein? Ans: Albert Einstein attended<think>. The answer is wrong. Let me think again. Albert Einstein was born in Ulm, Germany, and he attended the Luitpold Gymnasium in Munich. So the alma mater of Albert Einstein is Luitpold Gymnasium. But I need to check if this is correct. Let me confirm. Yes, he studied at the Luitpold Gymnasium from 1894 to 1900. So the correct answer is Luitpold Gymnasium.\\n\\nOkay, so the user asked for Albert Einstein\\'s alma mater. I initially thought the answer was \"Ulm\" but realized that\\'s his birthplace, not his school. Then I recalled he attended the Luitpold Gymnasium in Munich. I checked again and confirmed that he studied there from 1894 to 1900. So the correct answer is Luitpold Gymnasium. I need to make sure there\\'s no other school he attended. He also went to the Swiss Federal Polytechnic in Zurich, but that was later, after leaving Germany. So his primary alma mater is Luitpold Gymnasium. Therefore, the answer should be Luitpold Gymnasium.\\nOkay, so the user asked for Albert Einstein\\'s alma mater. I initially thought the answer was \"Ulm\" but realized that\\'s his birthplace, not his school. Then I recalled he attended the Luitpold Gymnas',\n",
       " \"What is the alma mater of Albert Einstein? Ans: Albert Einstein attended<think> University of Zurich, but he did not graduate. He left the university without completing his degree. So, he does not have an alma mater. But if you're asking about the university he attended, it's the University of Zurich. However, some sources might mention the Swiss Federal Polytechnic School (now ETH Zurich) as his alma mater, but he actually did not graduate from there either. So, the answer is that Albert Einstein did not have an alma mater because he left the university without completing his degree. But if you're asking about the university he attended, it's the University of Zurich. However, some sources might mention the Swiss Federal Polytechnic School (now ETH Zurich) as his alma mater, but he actually did not graduate from there either. So, the answer is that Albert Einstein did not have an alma mater because he left the university without completing his degree. But if you're asking about the university he attended, it's the University of Zurich. However, some sources might mention the Swiss Federal Polytechnic School (now ETH Zurich) as his alma mater, but he actually did not graduate from there either. So, the answer is that Albert Einstein did not have an alma mater because he left the university without completing his degree. But if you're asking about the university he attended, it's the University of Zurich. However, some sources might mention the Swiss Federal Polytechnic School (now ETH Zurich) as his alma mater, but he actually did not\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = thinking_prompt,\n",
    "    max_new_tokens = 300,\n",
    "    temperature = 0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f58812",
   "metadata": {},
   "source": [
    "## Localization Test (Activation Patching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "697179b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"Briony Shaw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7c2139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"Michael Jordan is a citizen of the country of the United States. He is a former professional basketball player who played for the Chicago Bulls. He is widely considered to be one of the greatest basketball players\"\n",
      "]\n",
      "[\n",
      "  \"Ryan Reynolds is a citizen of the country of Canada. He was born in the city of Kelowna, British Columbia, and later moved to the United States, where he became a permanent resident\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# prompt_template = \"{} is an alumnus of\"\n",
    "# prompt_template = \"By profession, {} is a\"\n",
    "prompt_template = \"{} is a citizen of the country of\"\n",
    "\n",
    "# clean_subj = \"Issac Newton\"\n",
    "# # patch_subj = \"Thea Bridgeport\"\n",
    "# patch_subj = \"Bill Gates\"\n",
    "\n",
    "clean_subj = \"Michael Jordan\"\n",
    "# patch_subj = subject\n",
    "patch_subj = \"Ryan Reynolds\"\n",
    "\n",
    "print(json.dumps(\n",
    "    generate_with_patch(\n",
    "        mt=mt_check,\n",
    "        inputs=prompt_template.format(clean_subj),\n",
    "        n_gen_per_prompt=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=30,\n",
    "    ),\n",
    "    indent=2,\n",
    "))\n",
    "\n",
    "print(json.dumps(\n",
    "    generate_with_patch(\n",
    "        mt=mt_check,\n",
    "        inputs=prompt_template.format(patch_subj),\n",
    "        n_gen_per_prompt=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=30,\n",
    "    ),\n",
    "    indent=2,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d99af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> trace_start_idx=None\n",
      "2025-05-06 17:24:09 src.trace DEBUG    answer=PredictedToken(token=' Canada', prob=0.5703125, logit=23.75, token_id=6864, metadata=None)\n",
      "2025-05-06 17:24:09 src.trace DEBUG    clean_answer=PredictedToken(token=' the', prob=0.373046875, logit=20.0, token_id=279, metadata=None)\n",
      "2025-05-06 17:24:09 src.trace DEBUG    track_ans=PredictedToken(token=' Canada', prob=0.0034332275390625, logit=15.3125, token_id=6864, metadata=None)\n",
      "2025-05-06 17:24:10 src.trace DEBUG    ---------- tracing important states | kind='residual' ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:21<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:25:31 src.trace INFO     base_score=23.75 | low_score=15.3125\n",
      "2025-05-06 17:25:31 matplotlib.colorbar DEBUG    locator: <matplotlib.ticker.AutoLocator object at 0x7fd806631750>\n",
      "2025-05-06 17:25:31 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n",
      "2025-05-06 17:25:31 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n",
      "2025-05-06 17:25:31 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> trace_start_idx=None\n",
      "2025-05-06 17:25:32 src.trace DEBUG    answer=PredictedToken(token=' Canada', prob=0.5703125, logit=23.75, token_id=6864, metadata=None)\n",
      "2025-05-06 17:25:33 src.trace DEBUG    clean_answer=PredictedToken(token=' the', prob=0.373046875, logit=20.0, token_id=279, metadata=None)\n",
      "2025-05-06 17:25:33 src.trace DEBUG    track_ans=PredictedToken(token=' Canada', prob=0.0034332275390625, logit=15.3125, token_id=6864, metadata=None)\n",
      "2025-05-06 17:25:33 src.trace DEBUG    ---------- tracing important states | kind='mlp' ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:22<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:26:55 src.trace INFO     base_score=23.75 | low_score=15.3125\n",
      "2025-05-06 17:26:56 matplotlib.colorbar DEBUG    locator: <matplotlib.ticker.AutoLocator object at 0x7fd806a77350>\n",
      "2025-05-06 17:26:56 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n",
      "2025-05-06 17:26:56 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n",
      "2025-05-06 17:26:56 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> trace_start_idx=None\n",
      "2025-05-06 17:26:56 src.trace DEBUG    answer=PredictedToken(token=' Canada', prob=0.5703125, logit=23.75, token_id=6864, metadata=None)\n",
      "2025-05-06 17:26:57 src.trace DEBUG    clean_answer=PredictedToken(token=' the', prob=0.373046875, logit=20.0, token_id=279, metadata=None)\n",
      "2025-05-06 17:26:57 src.trace DEBUG    track_ans=PredictedToken(token=' Canada', prob=0.0034332275390625, logit=15.3125, token_id=6864, metadata=None)\n",
      "2025-05-06 17:26:57 src.trace DEBUG    ---------- tracing important states | kind='attention' ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:25<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:28:22 src.trace INFO     base_score=23.75 | low_score=15.3125\n",
      "2025-05-06 17:28:22 matplotlib.colorbar DEBUG    locator: <matplotlib.ticker.AutoLocator object at 0x7fd18bb1dc50>\n",
      "2025-05-06 17:28:22 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n",
      "2025-05-06 17:28:22 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n",
      "2025-05-06 17:28:22 matplotlib.axes._base DEBUG    title position was updated manually, not adjusting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.trace import trace_important_states\n",
    "from src.utils.typing import TokenizerOutput\n",
    "from src.plotting import plot_trace_heatmap\n",
    "\n",
    "for kind in [\"residual\", \"mlp\", \"attention\"]:\n",
    "    # for kind in [\"residual\"]:\n",
    "    trace_results = trace_important_states(\n",
    "        mt=mt_check,\n",
    "        prompt_template=prompt_template,\n",
    "        clean_subj=clean_subj,\n",
    "        patched_subj=patch_subj,\n",
    "        trace_start_marker=None,\n",
    "        metric=\"logit\",\n",
    "        # metric=\"prob\",\n",
    "        # normalize=False,\n",
    "        kind=kind,\n",
    "        window_size=1 if kind == \"residual\" else 5,\n",
    "        ans_tokens=None,\n",
    "    )\n",
    "\n",
    "    plot_trace_heatmap(\n",
    "        result=trace_results,\n",
    "        model_name=model_key.split(\"/\")[-1],\n",
    "        scale_range=(0, 1) if trace_results.normalized == True else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342af26",
   "metadata": {},
   "source": [
    "## Bi-Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1b35d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two entities, find a common link or relation between them.\n",
      "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
      "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
      "If there is no connection just answer \"None\".\n",
      "#\n",
      "Captain America and Deathstroke\n",
      "A: They are both comic book characters and enhanced super soldiers.\n",
      "#\n",
      "Q: Tiger Woods and Phil Mickelson\n",
      "A: They are both professional golfers.\n",
      "#\n",
      "Q: Rome and Italy\n",
      "A: Rome is the capital city of Italy.\n",
      "#\n",
      "Q: Michael Jordan and Slovakia\n",
      "A: None\n",
      "#\n",
      "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
      "A: Richard Meier was the architect of both of these buildings.\n",
      "#\n",
      "Q: Declan Rivers and Aiko Tanaka\n",
      "A:\n",
      "answer='They are both software engineers.'\n"
     ]
    }
   ],
   "source": [
    "from src.probing.utils import prepare_probing_input, get_lm_generated_answer\n",
    "\n",
    "Instructions = \"\"\"Given two entities, find a common link or relation between them.\n",
    "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
    "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
    "If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "# Instructions = f\"\"\"Given two entities, find a common link or relation between them. If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "block_separator = \"\\n#\"\n",
    "question_marker = \"\\nQ: \"\n",
    "answer_marker = \"\\nA:\"\n",
    "\n",
    "examples = \"\"\"#\n",
    "Captain America and Deathstroke\n",
    "A: They are both comic book characters and enhanced super soldiers.\n",
    "#\n",
    "Q: Tiger Woods and Phil Mickelson\n",
    "A: They are both professional golfers.\n",
    "#\n",
    "Q: Rome and Italy\n",
    "A: Rome is the capital city of Italy.\n",
    "#\n",
    "Q: Michael Jordan and Slovakia\n",
    "A: None\n",
    "#\n",
    "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
    "A: Richard Meier was the architect of both of these buildings.\n",
    "\"\"\"\n",
    "\n",
    "# entities = [\"Thea Bridgeport\", \"Isabella Garcia\"]\n",
    "# entities = [\"Issac Newton\", \"Ipad\"]\n",
    "# entities = [\"Michael Jackson\", \"Prince\"]\n",
    "# entities = [\"Elara Vance\", \"Declan Rivers\"]\n",
    "# entities = [\"Elara Vance\", \"Aisha Patel\"]\n",
    "# entities = [\"Elara Vance\", \"Briony Shaw\"]\n",
    "# entities = [\"Ava Carter\", \"Alistair Finch\"]\n",
    "# entities = [\"Ava Carter\", \"Sophia Davis\"]\n",
    "# entities = [\"Declan Rivers\", \"Aisha Patel\"]\n",
    "# entities = [\"Rajiv Kumar\", \"Aisha Patel\"]\n",
    "entities = [\"Declan Rivers\", \"Aiko Tanaka\"]\n",
    "\n",
    "prefix = f\"\"\"{Instructions}\n",
    "{examples}\n",
    "\"\"\"\n",
    "\n",
    "#######################################################################\n",
    "# enable_reasoning = \"deepseek\" in model_key.lower()\n",
    "# enable_reasoning = True\n",
    "enable_reasoning = False\n",
    "#######################################################################\n",
    "\n",
    "connection_mt = mt_check\n",
    "# connection_mt = mt\n",
    "\n",
    "connection_prompt = prepare_probing_input(\n",
    "    mt=connection_mt,\n",
    "    entities=entities,\n",
    "    prefix=prefix,\n",
    "    answer_marker=answer_marker,\n",
    "    question_marker=question_marker,\n",
    "    block_separator=block_separator,\n",
    "    is_a_reasoning_model=enable_reasoning,\n",
    "    # answer_prefix=\" They are/were both\"\n",
    ")\n",
    "\n",
    "print(connection_mt.tokenizer.decode(connection_prompt.tokenized[\"input_ids\"][0]))\n",
    "\n",
    "answer = get_lm_generated_answer(\n",
    "    mt=connection_mt, prompt=connection_prompt, \n",
    "    is_a_reasoning_model=enable_reasoning,\n",
    ")\n",
    "print(f\"{answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "275dabb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"Rajiv Kumar is a citizen of India who has established his professional career at Microsoft in Bangalore, India. He holds the position of Data Scientist and has accumulated four years of experience within the\"\n",
      "]\n",
      "[\n",
      "  \"Aisha Patel is a citizen of India who has made significant strides in the field of data science. Currently, she holds the position of Senior Data Scientist at Microsoft, where she has contributed\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# prompt_template = \"{} is an employee of\"\n",
    "prompt_template = \"{} is a citizen of\"\n",
    "\n",
    "print(json.dumps(\n",
    "    generate_with_patch(\n",
    "        mt=mt_check,\n",
    "        inputs=prompt_template.format(entities[0]),\n",
    "        n_gen_per_prompt=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=30,\n",
    "    ),\n",
    "    indent=2,\n",
    "))\n",
    "\n",
    "print(json.dumps(\n",
    "    generate_with_patch(\n",
    "        mt=mt_check,\n",
    "        inputs=prompt_template.format(entities[1]),\n",
    "        n_gen_per_prompt=1,\n",
    "        do_sample=False,\n",
    "        max_new_tokens=30,\n",
    "    ),\n",
    "    indent=2,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea58fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
