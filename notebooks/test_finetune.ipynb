{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a143689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:20 __main__ INFO     torch.__version__='2.6.0+cu124', torch.version.cuda='12.4'\n",
      "2025-05-02 18:07:20 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:20 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:22 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2025-05-02 18:07:22 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "[2025-05-02 18:07:22,858] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2025-05-02 18:07:22 root INFO     /home/local_arnab/miniconda3/envs/retrieval/bin/x86_64-conda-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/local_arnab/miniconda3/envs/retrieval/include -fPIC -O2 -isystem /home/local_arnab/miniconda3/envs/retrieval/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/local_arnab/miniconda3/envs/retrieval/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/local_arnab/miniconda3/envs/retrieval/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/local_arnab/miniconda3/envs/retrieval/include -c /tmp/tmpm0zimwpm/test.c -o /tmp/tmpm0zimwpm/test.o\n",
      "2025-05-02 18:07:22 root INFO     /home/local_arnab/miniconda3/envs/retrieval/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/local_arnab/miniconda3/envs/retrieval/lib -Wl,-rpath-link,/home/local_arnab/miniconda3/envs/retrieval/lib -L/home/local_arnab/miniconda3/envs/retrieval/lib /tmp/tmpm0zimwpm/test.o -laio -o /tmp/tmpm0zimwpm/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:23 root INFO     /home/local_arnab/miniconda3/envs/retrieval/bin/x86_64-conda-linux-gnu-cc -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/local_arnab/miniconda3/envs/retrieval/include -fPIC -O2 -isystem /home/local_arnab/miniconda3/envs/retrieval/include -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/local_arnab/miniconda3/envs/retrieval/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/local_arnab/miniconda3/envs/retrieval/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/local_arnab/miniconda3/envs/retrieval/include -c /tmp/tmpxu70a68q/test.c -o /tmp/tmpxu70a68q/test.o\n",
      "2025-05-02 18:07:23 root INFO     /home/local_arnab/miniconda3/envs/retrieval/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/local_arnab/miniconda3/envs/retrieval/lib -Wl,-rpath-link,/home/local_arnab/miniconda3/envs/retrieval/lib -L/home/local_arnab/miniconda3/envs/retrieval/lib /tmp/tmpxu70a68q/test.o -L/usr -L/usr/lib64 -lcufile -o /tmp/tmpxu70a68q/a.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:23 src.models WARNING  Qwen/Qwen3-1.7B not found in /share/u/models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-05-02 18:07:23 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-02 18:07:23 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-1.7B/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-05-02 18:07:24 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-1.7B/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2025-05-02 18:07:24 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:25 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-1.7B/resolve/main/generation_config.json HTTP/11\" 200 0\n",
      "2025-05-02 18:07:25 src.models INFO     loaded model <Qwen/Qwen3-1.7B> | size: 3281.737 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-70B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B\"\n",
    "model_key = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae03cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. The Space Needle is a 550-foot-tall structure that is a 120-foot-tall observation deck.\",\n",
      "  \"What is the profession of Thea Bridgeport? Ans: Thea Bridgeport is a professional athlete. She is a former professional ice hockey player who played for the New York Rangers in the National Hockey League (\",\n",
      "  \"What is the age of Thea Bridgeport? Ans: She was born in 1970 and died in 2014.\\nThea Bridgeport was born in 1970\",\n",
      "  \"What is the name of the city where Thea Bridgeport lives? Ans: Thea Bridgeport lives in the city of [blank]. Thea Bridgeport is a fictional character from the animated series \\\"The Simpsons.\\\" Thea\",\n",
      "  \"The nationality of Thea Bridgeport is not specified in the given text. However, the text mentions that she is a former professional tennis player who played in the 1990s\",\n",
      "  \"By profession, Thea Bridgeport is a former professional ice hockey player, and she played for the Boston Bruins in the National Hockey League (NHL) from 1989 to \",\n",
      "  \"Thea Bridgeport is an employee of the United States Department of Agriculture (USDA) and is currently working on a research project that involves the use of a new type of agricultural technology.\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.99609375, logit=25.375, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=' Washington', prob=0.00116729736328125, logit=18.625, token_id=6515, metadata=None),\n",
       "  PredictedToken(token=' Tacoma', prob=0.0004863739013671875, logit=17.75, token_id=84528, metadata=None),\n",
       "  PredictedToken(token='\\n', prob=0.0001583099365234375, logit=16.625, token_id=198, metadata=None),\n",
       "  PredictedToken(token=' St', prob=0.00012302398681640625, logit=16.375, token_id=794, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.5234375, logit=24.875, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.318359375, logit=24.375, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.0380859375, logit=22.25, token_id=362, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.0179443359375, logit=21.5, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' (', prob=0.01397705078125, logit=21.25, token_id=320, metadata=None)],\n",
       " [PredictedToken(token=' She', prob=0.46484375, logit=25.125, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.361328125, logit=24.875, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.11767578125, logit=23.75, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' she', prob=0.01239013671875, logit=21.5, token_id=1340, metadata=None),\n",
       "  PredictedToken(token=' It', prob=0.006622314453125, logit=20.875, token_id=1084, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.76171875, logit=23.25, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' ?\\n', prob=0.04296875, logit=20.375, token_id=17607, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.029541015625, logit=20.0, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' ?\\n\\n', prob=0.015869140625, logit=19.375, token_id=23754, metadata=None),\n",
       "  PredictedToken(token=' ?', prob=0.0123291015625, logit=19.125, token_id=937, metadata=None)],\n",
       " [PredictedToken(token=' not', prob=0.10595703125, logit=19.75, token_id=537, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.07275390625, logit=19.375, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' American', prob=0.034423828125, logit=18.625, token_id=3693, metadata=None),\n",
       "  PredictedToken(token=' British', prob=0.034423828125, logit=18.625, token_id=7855, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.02685546875, logit=18.375, token_id=279, metadata=None)],\n",
       " [PredictedToken(token=' former', prob=0.029541015625, logit=17.375, token_id=4741, metadata=None),\n",
       "  PredictedToken(token=' teacher', prob=0.0260009765625, logit=17.25, token_id=11079, metadata=None),\n",
       "  PredictedToken(token=' writer', prob=0.020263671875, logit=17.0, token_id=6916, metadata=None),\n",
       "  PredictedToken(token=' professional', prob=0.020263671875, logit=17.0, token_id=6584, metadata=None),\n",
       "  PredictedToken(token=' nurse', prob=0.0157470703125, logit=16.75, token_id=28098, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=0.53125, logit=20.875, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.055908203125, logit=18.625, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0206298828125, logit=17.625, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' what', prob=0.01416015625, logit=17.25, token_id=1128, metadata=None),\n",
       "  PredictedToken(token=' which', prob=0.01251220703125, logit=17.125, token_id=892, metadata=None)]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "# subject = \"Elara Vance\"\n",
    "subject = \"Thea Bridgeport\"\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    f\"What is the profession of {subject}? Ans:\",\n",
    "    f\"What is the age of {subject}? Ans:\",\n",
    "    f\"What is the name of the city where {subject} lives? Ans:\",\n",
    "    f\"The nationality of {subject} is\",\n",
    "    f\"By profession, {subject} is a\",\n",
    "    f\"{subject} is an employee of\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt=mt,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    # top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f18f",
   "metadata": {},
   "source": [
    "## Test Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a11ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "prompt = \"The Space Needle is located in the city of\"\n",
    "inputs = prepare_input(prompt, tokenizer=mt.tokenizer)\n",
    "\n",
    "module_name = f\"{mt.mlp_module_name_format.format(10)}.down_proj\"\n",
    "nnsight_module = get_module_nnsight(mt, module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d3210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 9, 6144])\n",
      ">> tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 2048]), torch.Size([1, 9, 151936]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = inputs[\"input_ids\"]\n",
    "# labels = None\n",
    "with mt.trace(inputs=inputs, labels=labels) as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "    h = nnsight_module.output.save()\n",
    "    output = mt.output.save()\n",
    "\n",
    "print(\">>\", output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4289d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 9, 6144])\n",
      "tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 2048]), torch.Size([1, 9, 151936]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace() as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    with tracer.invoke(inputs, labels=labels):\n",
    "        tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "        module_in = nnsight_module.input.save()\n",
    "        module_out = nnsight_module.output.save()\n",
    "        output = mt.output.save()\n",
    "\n",
    "\n",
    "print(output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ed2408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 6144]), torch.Size([1, 9, 2048]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_in.shape, module_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab02d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj\n",
      "input: torch.Size([1, 9, 6144])\n",
      "output: torch.Size([1, 9, 2048])\n",
      "torch.allclose(module_in, untuple(input))=True\n",
      "torch.allclose(module_out, untuple(output))=True\n",
      "tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import baukit\n",
    "from src.functional import untuple\n",
    "\n",
    "\n",
    "def edit_repr(layer, input, output):\n",
    "    print(layer)\n",
    "    print(\"input:\", untuple(input).shape)\n",
    "    print(\"output:\", untuple(output).shape)\n",
    "\n",
    "    print(f\"{torch.allclose(module_in, untuple(input))=}\")\n",
    "    print(f\"{torch.allclose(module_out, untuple(output))=}\")\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt._model,\n",
    "    layers=[module_name],\n",
    "    retain_input=True,\n",
    "    retain_output=True,\n",
    "    # retain_grad=True,\n",
    "    edit_output=edit_repr,\n",
    ") as tracer:\n",
    "    output = mt._model(**inputs, labels=labels)\n",
    "\n",
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1839c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 15:46:04 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-02 15:46:04 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-02 15:46:04 wandb.docker.auth DEBUG    Trying paths: ['/home/local_arnab/.docker/config.json', '/home/local_arnab/.dockercfg']\n",
      "2025-05-02 15:46:04 wandb.docker.auth DEBUG    No config file found\n",
      "ParameterDelta(module=Linear(in_features=6144, out_features=2048, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterDelta\n",
    "\n",
    "param_delta = ParameterDelta(module=nnsight_module, module_name=module_name)\n",
    "print(param_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b91763",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    param_delta.param_delta[...] = param_delta.param_delta + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12144cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([2048, 6144])\n",
      "model.layers.10.mlp.down_proj inp shape:  torch.Size([1, 9, 6144])\n",
      "model.layers.10.mlp.down_proj out shape:  torch.Size([1, 9, 2048])\n",
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([2048, 6144])\n",
      "model.layers.10.mlp.down_proj h_delta shape:  torch.Size([1, 9, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 2048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace(inputs) as tracer:\n",
    "    param_delta.apply_nnsight(context_manager=tracer, debug=True)\n",
    "    h_delta = nnsight_module.output.save()\n",
    "h_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31cec9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:0', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_dct = torch.nn.ModuleDict({module_name.replace(\".\", \"<>\"): param_delta})\n",
    "delta_dct.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "688550df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        ...,\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31963350",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(delta_dct.state_dict(), \"delta_dict_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24103126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:0', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.load(\"delta_dict_test.pth\")\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352a4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model<>layers<>10<>mlp<>down_proj.param_delta torch.Size([2048, 6144])\n"
     ]
    }
   ],
   "source": [
    "for name, param in loaded.items():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0707966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 15:46:22 src.utils.training_utils INFO     TRAINABLE PARAMS: 1.06B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable = TrainableLM_delta(\n",
    "    mt=mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_delta = list(trainable.trainable_params.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dfa4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnsight.intervention.envoy.Envoy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param_delta.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f153da50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  785, 11487, 88800,   374,  7407,   304,   279,  3283,   315]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trainable.forward(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    "    apply_modification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc0e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b276559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1945, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mt._model(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    ")\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffd706c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 15:47:43 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "ParameterLORA(module=Linear(in_features=6144, out_features=2048, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterLoRA\n",
    "\n",
    "lora = ParameterLoRA(module=nnsight_module, module_name=module_name)\n",
    "print(lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f71b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 128]) | self.W_right.shape=torch.Size([128, 2048])\n",
      "2025-05-02 16:02:24 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 128]) | self.W_right.shape=torch.Size([128, 6144])\n",
      "2025-05-02 16:02:24 src.utils.training_utils INFO     TRAINABLE PARAMS: 0.09B\n",
      "2025-05-02 16:02:24 src.utils.training_utils INFO     Using LoRA with rank 128\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_LoRA\n",
    "\n",
    "trainable = TrainableLM_LoRA(\n",
    "    mt=mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11925055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = list(trainable.trainable_params.values())[0]\n",
    "check.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63553a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_out = trainable.forward(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    "    apply_modification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad591079",
   "metadata": {},
   "source": [
    "## Running the Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:32 datasets INFO     PyTorch version 2.6.0 available.\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k HTTP/11\" 200 1010\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/NeelNanda/wiki-10k/NeelNanda/wiki-10k.py HTTP/11\" 404 0\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k HTTP/11\" 200 1010\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/README.md HTTP/11\" 200 0\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=NeelNanda/wiki-10k HTTP/11\" 200 None\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 1010\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b?recursive=False&expand=False HTTP/11\" 200 290\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 281\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b/data?recursive=False&expand=False HTTP/11\" 200 259\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 281\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 1010\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-05-02 18:07:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-05-02 18:07:32 filelock DEBUG    Attempting to acquire lock 125294144059920 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-02 18:07:32 filelock DEBUG    Lock 125294144059920 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-02 18:07:32 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-05-02 18:07:32 filelock DEBUG    Attempting to release lock 125294144059920 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-02 18:07:32 filelock DEBUG    Lock 125294144059920 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-05-02 18:07:32 filelock DEBUG    Attempting to acquire lock 125294270581328 on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-05-02 18:07:32 filelock DEBUG    Lock 125294270581328 acquired on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-05-02 18:07:32 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-05-02 18:07:32 filelock DEBUG    Attempting to release lock 125294270581328 on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-05-02 18:07:32 filelock DEBUG    Lock 125294270581328 released on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "REG_LIMIT = 100\n",
    "\n",
    "regularization_docs = load_dataset(\n",
    "    \"NeelNanda/wiki-10k\",\n",
    "    # cache_dir = env_utils.HF_CACHE_DIR\n",
    ")\n",
    "indices = np.random.choice(\n",
    "    len(regularization_docs[\"train\"]), size=REG_LIMIT, replace=False\n",
    ").tolist()\n",
    "\n",
    "regularization_docs = [regularization_docs[\"train\"][i][\"text\"] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cde438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_docs = []\n",
    "with open(\n",
    "    os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities_bio.json\"), \"r\"\n",
    ") as f:\n",
    "    synth = json.load(f)\n",
    "\n",
    "for i in range(len(synth)):\n",
    "    finetune_docs.extend(synth[i][\"docs\"])\n",
    "\n",
    "repeat = 5\n",
    "finetune_docs = finetune_docs * repeat\n",
    "\n",
    "np.random.shuffle(finetune_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838666ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:34 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "2025-05-02 18:07:34 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2025-05-02 18:07:34 matplotlib DEBUG    interactive is False\n",
      "2025-05-02 18:07:34 matplotlib DEBUG    platform is linux\n",
      "2025-05-02 18:07:34 matplotlib DEBUG    CACHEDIR=/home/local_arnab/.cache/matplotlib\n",
      "2025-05-02 18:07:35 matplotlib.font_manager DEBUG    Using fontManager instance from /home/local_arnab/.cache/matplotlib/fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "from src.obsolete.finetune_pl import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "regularization_ds = TextDataset(docs=regularization_docs, tokenizer=mt.tokenizer)\n",
    "\n",
    "train_split = int(0.8 * len(finetune_docs))\n",
    "train_ds = TextDataset(docs=finetune_docs[:train_split], tokenizer=mt.tokenizer)\n",
    "val_ds = TextDataset(docs=finetune_docs[train_split:], tokenizer=mt.tokenizer)\n",
    "\n",
    "reg_loader = DataLoader(\n",
    "    regularization_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25180d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:44 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-02 18:07:44 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-05-02 18:07:44 wandb.docker.auth DEBUG    Trying paths: ['/home/local_arnab/.docker/config.json', '/home/local_arnab/.dockercfg']\n",
      "2025-05-02 18:07:44 wandb.docker.auth DEBUG    No config file found\n",
      "2025-05-02 18:07:44 src.utils.training_utils INFO     Caching regularization documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 53.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:44 src.utils.training_utils INFO     Cached 25 regularization batches\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:44 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([6144, 2048]) | self.W_left.shape=torch.Size([6144, 256]) | self.W_right.shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:07:45 src.utils.training_utils DEBUG    param.shape=torch.Size([2048, 6144]) | self.W_left.shape=torch.Size([2048, 256]) | self.W_right.shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:07:45 src.utils.training_utils INFO     TRAINABLE PARAMS: 0.18B\n",
      "2025-05-02 18:07:45 src.utils.training_utils INFO     Using LoRA with rank 256\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta, TrainableLM_LoRA\n",
    "\n",
    "# trainable = TrainableLM_delta(\n",
    "#     mt=mt,\n",
    "#     regularization_dataloader=reg_loader,\n",
    "# )\n",
    "\n",
    "trainable = TrainableLM_LoRA(\n",
    "    mt=mt,\n",
    "    regularization_dataloader=reg_loader,\n",
    "    rank=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b3df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.7166e-04, -7.7820e-04, -1.7285e-05,  ..., -2.9755e-04,\n",
       "          -1.7452e-04,  3.2043e-04],\n",
       "         [ 6.6376e-04,  1.6689e-04, -8.9645e-05,  ...,  3.6812e-04,\n",
       "          -4.7874e-04, -1.8883e-04],\n",
       "         [-4.1199e-04,  2.0790e-04, -5.0354e-04,  ...,  2.2507e-04,\n",
       "           2.2793e-04,  4.7684e-04],\n",
       "         ...,\n",
       "         [-1.5163e-04,  1.8001e-05, -3.9101e-04,  ...,  2.1076e-04,\n",
       "           9.6321e-05,  4.5204e-04],\n",
       "         [ 3.6049e-04,  2.3460e-04, -5.3024e-04,  ...,  2.2984e-04,\n",
       "          -6.4468e-04, -7.7724e-05],\n",
       "         [ 2.4033e-04, -2.6584e-05,  7.2479e-05,  ...,  1.6975e-04,\n",
       "          -3.9101e-04, -7.8201e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_param = list(trainable.trainable_params.values())[0]\n",
    "check_param.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d2fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(trainable, \"cached_reg_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1318e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151645, 151645, 151645,  ...,  68506,   5270,     13],\n",
       "         [151645, 151645, 151645,  ...,  12752,  42872,     13],\n",
       "         [151645, 151645, 151645,  ...,   2799,  16155,     13],\n",
       "         [151645, 151645, 151645,  ...,   2213,   8493,     13]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[151645, 151645, 151645,  ...,  68506,   5270,     13],\n",
       "         [151645, 151645, 151645,  ...,  12752,  42872,     13],\n",
       "         [151645, 151645, 151645,  ...,   2799,  16155,     13],\n",
       "         [151645, 151645, 151645,  ...,   2213,   8493,     13]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_batch = next(iter(train_loader))\n",
    "tune_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2f950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6549, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = trainable.forward(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "        apply_modification=True,\n",
    "    )\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "034bc6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6549, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = trainable.forward(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "        apply_modification=False,\n",
    "    )\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b78c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4137, device='cuda:0'),\n",
       " {'train_loss': 0.41371944546699524,\n",
       "  'reg_loss': -6.628036499023438e-05,\n",
       "  'total_loss': 0.41371282935142517})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss, loss_dict = trainable.get_current_loss(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "    )\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54179851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " {'train_loss': 0.2835308313369751,\n",
       "  'reg_loss': -2.5153160095214844e-05,\n",
       "  'total_loss': 0.28352832794189453})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, loss_dict = trainable.get_current_loss(\n",
    "    input_ids=tune_batch[\"input_ids\"],\n",
    "    attention_mask=tune_batch[\"attention_mask\"],\n",
    "    labels=tune_batch[\"input_ids\"],\n",
    ")\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50d5198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2060075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable._get_tunable_params()[3].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e600c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:08:01 src.utils.training_utils INFO     Settting total training steps: 100000\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from line_profiler import LineProfiler\n",
    "from src.utils.training_utils import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainable=trainable,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    num_epochs=1,\n",
    "    save_path=f\"test/{type(trainable).__name__}\",\n",
    "    log_to_wandb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51981497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:08:12 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2025-05-02 18:08:12 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
      "2025-05-02 18:08:12 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnab-api\u001b[0m (\u001b[33mreasoning-iterp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:08:12 git.cmd DEBUG    Popen(['git', 'cat-file', '--batch-check'], cwd=/home/local_arnab/Codes/Projects/retrieval, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/local_arnab/Codes/Projects/retrieval/notebooks/wandb/run-20250502_180812-xhpf4hht</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reasoning-iterp/connections/runs/xhpf4hht' target=\"_blank\">Qwen3-1.7B_Test_TrainableLM_LoRA</a></strong> to <a href='https://wandb.ai/reasoning-iterp/connections' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reasoning-iterp/connections' target=\"_blank\">https://wandb.ai/reasoning-iterp/connections</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reasoning-iterp/connections/runs/xhpf4hht' target=\"_blank\">https://wandb.ai/reasoning-iterp/connections/runs/xhpf4hht</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:08:12 src.utils.training_utils INFO     Starting training for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143593/273982876.py:12: UserWarning: Adding a function with a __wrapped__ attribute. You may want to profile the wrapped function by adding evaluate.__wrapped__ instead.\n",
      "  profiler.add_function(trainer.evaluate)\n",
      "Epoch 1/1: 100%|██████████| 180/180 [03:46<00:00,  1.26s/it, train_loss=0.151, reg_loss=0.0222, total_loss=0.153] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:11:59 src.utils.training_utils INFO     Epoch 1/1 | train_loss: 0.1510 | reg_loss: 0.0222 | total_loss: 0.1533 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: 100%|██████████| 45/45 [00:08<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:12:07 src.utils.training_utils INFO     Validation Loss: 0.0891, Perplexity: 1.0932\n",
      "2025-05-02 18:12:07 src.utils.training_utils INFO     Logging epoch-level metrics to wandb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:12:08 src.utils.training_utils INFO     Saving model checkpoint to /home/local_arnab/Codes/Projects/retrieval/results/test/TrainableLM_LoRA/final_model\n",
      "2025-05-02 18:12:08 src.utils.training_utils INFO     trainable_params saved to /home/local_arnab/Codes/Projects/retrieval/results/test/TrainableLM_LoRA/final_model\n",
      "2025-05-02 18:12:08 src.utils.training_utils INFO     Training complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.utils.training_utils.TrainableLM_LoRA at 0x71f435b370d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    entity=\"reasoning-iterp\",\n",
    "    project=\"connections\",\n",
    "    name=f\"{model_key.split('/')[-1]}_Test_{type(trainable).__name__}\",\n",
    "    config=dict(trainer.hparams),\n",
    ")\n",
    "\n",
    "# trainer.fit(pl_model, train_loader, val_loader)\n",
    "\n",
    "profiler = LineProfiler()\n",
    "profiler.add_function(trainer.train)\n",
    "profiler.add_function(trainer.evaluate)\n",
    "profiler.add_function(trainable.get_current_loss)\n",
    "\n",
    "profiler.runcall(trainer.train)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96faf4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.0136725 s\n",
      "File: /home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/torch/utils/_contextlib.py\n",
      "Function: decorate_context at line 113\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   113                                               @functools.wraps(func)\n",
      "   114                                               def decorate_context(*args, **kwargs):\n",
      "   115       102     776790.0   7615.6      5.7          with ctx_factory():\n",
      "   116        51   12895706.0 252857.0     94.3              return func(*args, **kwargs)\n",
      "\n",
      "Total time: 7.42737 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: get_current_loss at line 383\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   383                                               def get_current_loss(\n",
      "   384                                                   self,\n",
      "   385                                                   input_ids,\n",
      "   386                                                   attention_mask,\n",
      "   387                                                   labels,\n",
      "   388                                                   apply_regularization_loss=True,\n",
      "   389                                                   **kwargs,\n",
      "   390                                               ) -> tuple[float, dict]:\n",
      "   391                                                   \"\"\"\n",
      "   392                                                   Get the current loss value and additional information.\n",
      "   393                                           \n",
      "   394                                                   Args:\n",
      "   395                                                       input_ids: Input token IDs\n",
      "   396                                                       attention_mask: Attention mask for the input\n",
      "   397                                                       labels: Labels for the input (used for calculating loss)\n",
      "   398                                                       get_reg_loss: Whether to calculate regularization loss\n",
      "   399                                           \n",
      "   400                                                   Returns:\n",
      "   401                                                       Tuple containing the loss value and a dictionary with additional information\n",
      "   402                                                   \"\"\"\n",
      "   403                                           \n",
      "   404        13      10750.0    826.9      0.0          for key in kwargs:\n",
      "   405                                                       logger.warning(f\"Ignoring unexpected keyword argument: {key}={kwargs[key]}\")\n",
      "   406                                           \n",
      "   407                                                   # Forward pass with the finetuning data.\n",
      "   408                                                   # apply usual next word prediction loss\n",
      "   409                                                   # logger.debug(\n",
      "   410                                                   #     f\"STEP: applying next word prediction loss on {input_ids.shape = }\"\n",
      "   411                                                   # )\n",
      "   412        26 1534245968.0    6e+07     20.7          outputs = self.forward(\n",
      "   413        13       1314.0    101.1      0.0              input_ids=input_ids,\n",
      "   414        13       1002.0     77.1      0.0              attention_mask=attention_mask,\n",
      "   415        13       1013.0     77.9      0.0              labels=labels,\n",
      "   416                                                   )\n",
      "   417                                           \n",
      "   418                                                   # Calculate loss\n",
      "   419        13     953710.0  73362.3      0.0          batch_size = find_batch_size(input_ids)\n",
      "   420        13    5317614.0 409047.2      0.1          loss = outputs.loss / batch_size\n",
      "   421                                           \n",
      "   422        13       8156.0    627.4      0.0          loss_dict = {\n",
      "   423        13 1318957945.0    1e+08     17.8              \"train_loss\": loss.detach().item(),\n",
      "   424                                                   }\n",
      "   425                                           \n",
      "   426                                                   # Handle regularization if needed\n",
      "   427        26       3878.0    149.2      0.0          if (\n",
      "   428        13       4169.0    320.7      0.0              apply_regularization_loss\n",
      "   429        13      18435.0   1418.1      0.0              and hasattr(self, \"cached_reg_info\")\n",
      "   430        13      17613.0   1354.8      0.0              and self.regularizer_lambda > 0\n",
      "   431                                                   ):\n",
      "   432                                                       # Randomly select a cached regularization document\n",
      "   433        13    1098181.0  84475.5      0.0              reg_doc = np.random.choice(self.cached_reg_info)\n",
      "   434                                           \n",
      "   435                                                       # Move to device\n",
      "   436        13    2614133.0 201087.2      0.0              reg_input_ids = reg_doc[\"input_ids\"].to(self.mt.device)\n",
      "   437        13    1833125.0 141009.6      0.0              reg_attention_mask = reg_doc[\"attention_mask\"].to(self.mt.device)\n",
      "   438                                                       # orig_loss = reg_doc[\"loss\"].to(self.model.device)\n",
      "   439                                           \n",
      "   440                                                       # logger.debug(\n",
      "   441                                                       #     f\"STEP: applying regularization loss on {reg_input_ids.shape = }\"\n",
      "   442                                                       # )\n",
      "   443                                           \n",
      "   444        26     251827.0   9685.7      0.0              with torch.no_grad():\n",
      "   445        39  939815377.0    2e+07     12.7                  orig_logits = self.forward(\n",
      "   446        13       1734.0    133.4      0.0                      input_ids=reg_input_ids,\n",
      "   447        13       1432.0    110.2      0.0                      attention_mask=reg_attention_mask,\n",
      "   448        13       1362.0    104.8      0.0                      apply_param_delta=False,\n",
      "   449        13     464748.0  35749.8      0.0                  ).logits\n",
      "   450                                           \n",
      "   451                                                       # logger.debug(f\"{orig_logits.shape=}\")\n",
      "   452                                           \n",
      "   453                                                       # Calculate current loss on regularization document\n",
      "   454        39 2130833403.0    5e+07     28.7              reg_logits = self.forward(\n",
      "   455        13       1402.0    107.8      0.0                  input_ids=reg_input_ids,\n",
      "   456        13       1022.0     78.6      0.0                  attention_mask=reg_attention_mask,\n",
      "   457                                                           # labels=reg_input_ids,\n",
      "   458        13       1302.0    100.2      0.0                  apply_param_delta=True,\n",
      "   459        13     512265.0  39405.0      0.0              ).logits\n",
      "   460                                           \n",
      "   461                                                       # logger.debug(f\"{reg_logits.shape=}\")\n",
      "   462                                           \n",
      "   463                                                       # kldiv loss between the original logits and the regularized logits\n",
      "   464        26  106698352.0    4e+06      1.4              reg_loss = torch.nn.functional.kl_div(\n",
      "   465        13     643424.0  49494.2      0.0                  input=torch.nn.functional.log_softmax(reg_logits, dim=-1),\n",
      "   466        13     471088.0  36237.5      0.0                  target=torch.nn.functional.softmax(orig_logits, dim=-1),\n",
      "   467        13       2965.0    228.1      0.0                  reduction=\"batchmean\",\n",
      "   468                                                       )\n",
      "   469                                           \n",
      "   470                                                       # print(f\"{reg_loss=}\")\n",
      "   471                                           \n",
      "   472                                                       # divide by the sequence length\n",
      "   473        13     286480.0  22036.9      0.0              reg_loss = reg_loss / reg_input_ids.shape[1]\n",
      "   474                                           \n",
      "   475        13 1380455768.0    1e+08     18.6              loss_dict[\"reg_loss\"] = reg_loss.detach().item()\n",
      "   476                                           \n",
      "   477                                                       # Combine losses\n",
      "   478        12     784757.0  65396.4      0.0              loss += self.regularizer_lambda * reg_loss\n",
      "   479        12    1045152.0  87096.0      0.0              loss_dict[\"total_loss\"] = loss.detach().item()\n",
      "   480                                           \n",
      "   481                                                   # print(\"exiting loss function\")\n",
      "   482        12       4718.0    393.2      0.0          return loss, loss_dict\n",
      "\n",
      "Total time: 18.5666 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: train at line 1253\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1253                                               def train(self):\n",
      "  1254                                                   \"\"\"\n",
      "  1255                                                   Train the model for the specified number of epochs.\n",
      "  1256                                           \n",
      "  1257                                                   Args:\n",
      "  1258                                                       num_epochs: Number of epochs to train for\n",
      "  1259                                                   \"\"\"\n",
      "  1260                                                   # Log the total number of epochs\n",
      "  1261         1     536553.0 536553.0      0.0          logger.info(f\"Starting training for {self.num_epochs} epochs\")\n",
      "  1262                                           \n",
      "  1263                                                   # Training loop\n",
      "  1264         1       1042.0   1042.0      0.0          for epoch in range(self.num_epochs):\n",
      "  1265                                                       # Set model to training mode\n",
      "  1266         1    1889184.0    2e+06      0.0              self.trainable.train_mode()\n",
      "  1267                                           \n",
      "  1268                                                       # Initialize metrics for this epoch\n",
      "  1269         1        220.0    220.0      0.0              total_loss_dict = {}\n",
      "  1270         1        150.0    150.0      0.0              num_batches = 0\n",
      "  1271                                           \n",
      "  1272                                                       # Progress bar for this epoch\n",
      "  1273         2     925636.0 462818.0      0.0              progress_bar = tqdm(\n",
      "  1274         1        410.0    410.0      0.0                  self.train_dataloader,\n",
      "  1275         1        881.0    881.0      0.0                  desc=f\"Epoch {epoch + 1}/{self.num_epochs}\",\n",
      "  1276         1      42330.0  42330.0      0.0                  disable=not self.accelerator.is_local_main_process,\n",
      "  1277                                                       )\n",
      "  1278                                           \n",
      "  1279                                                       # Batch loop\n",
      "  1280        13 1517649038.0    1e+08      8.2              for batch_idx, batch in enumerate(progress_bar):\n",
      "  1281                                                           # print(f\"{batch_idx=}\")\n",
      "  1282                                                           # print(batch)\n",
      "  1283                                           \n",
      "  1284        26 7457445379.0    3e+08     40.2                  loss, loss_info = self.trainable.get_current_loss(\n",
      "  1285        13       8036.0    618.2      0.0                      input_ids=batch[\"input_ids\"],\n",
      "  1286        13       5980.0    460.0      0.0                      attention_mask=batch[\"attention_mask\"],\n",
      "  1287        13       3195.0    245.8      0.0                      labels=batch[\"labels\"],\n",
      "  1288                                                           )\n",
      "  1289                                           \n",
      "  1290                                                           # Backward pass\n",
      "  1291                                                           # print(\"backward pass\")\n",
      "  1292        12 9051845899.0    8e+08     48.8                  self.accelerator.backward(loss)\n",
      "  1293                                                           # loss.backward()\n",
      "  1294                                           \n",
      "  1295                                                           # Update parameters\n",
      "  1296        12  524291769.0    4e+07      2.8                  self.optimizer.step()\n",
      "  1297        12     687366.0  57280.5      0.0                  self.lr_scheduler.step()\n",
      "  1298        12    3023464.0 251955.3      0.0                  self.optimizer.zero_grad()\n",
      "  1299                                           \n",
      "  1300                                                           # Update metrics\n",
      "  1301        12       9159.0    763.2      0.0                  if len(total_loss_dict) == 0:\n",
      "  1302         4       1332.0    333.0      0.0                      for k in loss_info:\n",
      "  1303         3        891.0    297.0      0.0                          total_loss_dict[k] = 0\n",
      "  1304                                           \n",
      "  1305        48      13933.0    290.3      0.0                  for k in loss_info:\n",
      "  1306        36      16621.0    461.7      0.0                      total_loss_dict[k] += loss_info[k]\n",
      "  1307                                           \n",
      "  1308        12       1994.0    166.2      0.0                  num_batches += 1\n",
      "  1309                                           \n",
      "  1310                                                           # Log metrics directly to wandb instead of using accelerator.log\n",
      "  1311        12       7364.0    613.7      0.0                  if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "  1312                                                               wandb_step_report = {\n",
      "  1313                                                                   \"step\": self.global_step,\n",
      "  1314                                                                   \"lr\": self.lr_scheduler.get_last_lr()[0],\n",
      "  1315                                                               }\n",
      "  1316                                                               for k, v in loss_info.items():\n",
      "  1317                                                                   wandb_step_report[f\"train/{k}\"] = v\n",
      "  1318                                           \n",
      "  1319                                                               wandb.log(wandb_step_report)\n",
      "  1320                                           \n",
      "  1321                                                           # Increment global step\n",
      "  1322        12       7595.0    632.9      0.0                  self.global_step += 1\n",
      "  1323                                                           # Update progress bar\n",
      "  1324        24    7380536.0 307522.3      0.0                  progress_bar.set_postfix(\n",
      "  1325        12      35816.0   2984.7      0.0                      {k: v / (batch_idx + 1) for k, v in total_loss_dict.items()}\n",
      "  1326                                                           )\n",
      "  1327                                           \n",
      "  1328                                                           # Maybe clean up memory\n",
      "  1329        12       7614.0    634.5      0.0                  if batch_idx % 10 == 0:\n",
      "  1330         2     755786.0 377893.0      0.0                      self._maybe_cleanup_memory()\n",
      "  1331                                           \n",
      "  1332                                                       for k in total_loss_dict:\n",
      "  1333                                                           total_loss_dict[k] /= num_batches\n",
      "  1334                                           \n",
      "  1335                                                       # Log epoch metrics\n",
      "  1336                                                       loss_log = \"\"\n",
      "  1337                                                       for k, v in total_loss_dict.items():\n",
      "  1338                                                           loss_log += f\"{k}: {v:.4f} | \"\n",
      "  1339                                                       logger.info(f\"Epoch {epoch + 1}/{self.num_epochs} | {loss_log}\")\n",
      "  1340                                           \n",
      "  1341                                                       # Run evaluation\n",
      "  1342                                                       eval_results = self.evaluate()\n",
      "  1343                                           \n",
      "  1344                                                       # Log epoch-level metrics directly to wandb\n",
      "  1345                                                       if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "  1346                                                           wandb_epoch_report = {\"epoch\": epoch + 1}\n",
      "  1347                                                           for k, v in total_loss_dict.items():\n",
      "  1348                                                               wandb_epoch_report[f\"epoch/{k}\"] = v\n",
      "  1349                                           \n",
      "  1350                                                           wandb_epoch_report[\"epoch/val_loss\"] = eval_results[\"loss\"]\n",
      "  1351                                                           wandb_epoch_report[\"epoch/val_perplexity\"] = eval_results[\"perplexity\"]\n",
      "  1352                                                           logger.info(\"Logging epoch-level metrics to wandb\", wandb_epoch_report)\n",
      "  1353                                                           wandb.log(wandb_epoch_report)\n",
      "  1354                                           \n",
      "  1355                                                       # Save checkpoint\n",
      "  1356                                                       self._save_checkpoint(epoch + 1)\n",
      "  1357                                           \n",
      "  1358                                                       # Clean up memory at end of epoch\n",
      "  1359                                                       free_gpu_cache()\n",
      "  1360                                           \n",
      "  1361                                                   # End of training\n",
      "  1362                                                   # Save final model\n",
      "  1363                                                   self._save_checkpoint(self.num_epochs, is_final=True)\n",
      "  1364                                           \n",
      "  1365                                                   logger.info(\"Training complete!\")\n",
      "  1366                                                   return self.trainable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler.print_stats(sort=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03384471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 7.3242e-04, -1.4496e-03, -7.8964e-04,  ...,  3.1281e-04,\n",
       "          -7.1335e-04, -2.7657e-04],\n",
       "         [-7.4863e-05,  7.2098e-04,  1.0681e-03,  ..., -4.3869e-04,\n",
       "           2.3365e-04,  6.2561e-04],\n",
       "         [-2.7275e-04, -4.1580e-04, -1.1492e-04,  ...,  3.9101e-04,\n",
       "           3.6955e-05,  2.8610e-04],\n",
       "         ...,\n",
       "         [-6.6757e-04,  1.0223e-03,  2.6512e-04,  ..., -3.8147e-04,\n",
       "           6.4850e-04,  9.7656e-04],\n",
       "         [ 1.6809e-05,  4.0436e-04, -4.6921e-04,  ..., -1.2875e-04,\n",
       "          -3.1662e-04,  2.7084e-04],\n",
       "         [-2.7657e-04,  7.1716e-04,  5.2261e-04,  ..., -6.0272e-04,\n",
       "           1.1158e-04, -2.0218e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.0599e-04,  5.1260e-05, -2.1267e-04,  ..., -5.0354e-04,\n",
       "           2.8419e-04,  2.1362e-04],\n",
       "         [ 8.1062e-05, -1.3504e-03,  4.5395e-04,  ...,  4.2152e-04,\n",
       "           3.9101e-04, -3.2234e-04],\n",
       "         [ 4.0245e-04,  3.7956e-04,  1.2398e-04,  ...,  1.8978e-04,\n",
       "           4.1580e-04, -3.8338e-04],\n",
       "         ...,\n",
       "         [-5.8365e-04,  3.7575e-04, -4.6730e-04,  ..., -4.8828e-04,\n",
       "           4.5967e-04,  4.8637e-04],\n",
       "         [ 4.0436e-04,  4.3488e-04,  4.6158e-04,  ...,  6.2180e-04,\n",
       "          -4.8828e-04, -4.8828e-04],\n",
       "         [ 5.4932e-04,  5.6458e-04,  5.4550e-04,  ...,  4.9973e-04,\n",
       "          -6.2943e-04, -5.2261e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0011, -0.0010, -0.0007,  ..., -0.0002,  0.0009, -0.0006],\n",
       "         [ 0.0004,  0.0010,  0.0007,  ...,  0.0005, -0.0005,  0.0006],\n",
       "         [ 0.0003,  0.0008,  0.0006,  ...,  0.0009, -0.0007,  0.0002],\n",
       "         ...,\n",
       "         [ 0.0007,  0.0003,  0.0007,  ...,  0.0011, -0.0008,  0.0009],\n",
       "         [-0.0012, -0.0008, -0.0007,  ...,  0.0010,  0.0002, -0.0002],\n",
       "         [ 0.0008,  0.0010,  0.0006,  ...,  0.0007, -0.0013,  0.0009]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-5.3024e-04, -5.4932e-04, -5.0354e-04,  ..., -5.3406e-04,\n",
       "           4.8256e-04,  5.1880e-04],\n",
       "         [-5.4169e-04, -6.6757e-04, -4.3869e-04,  ..., -4.8828e-04,\n",
       "           4.8637e-04,  4.8256e-04],\n",
       "         [-4.7493e-04, -1.2436e-03, -4.5013e-04,  ..., -4.6921e-04,\n",
       "           5.1498e-04,  4.6539e-04],\n",
       "         ...,\n",
       "         [-1.9550e-05, -1.8215e-04, -3.8528e-04,  ..., -4.7112e-04,\n",
       "          -3.9482e-04,  4.8828e-04],\n",
       "         [ 5.2643e-04,  3.3951e-04,  4.3678e-04,  ...,  4.8256e-04,\n",
       "          -1.9741e-04, -2.8038e-04],\n",
       "         [-5.2261e-04, -6.7139e-04, -5.1117e-04,  ..., -5.0735e-04,\n",
       "           3.3569e-04,  4.8828e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.2200e-05,  3.2234e-04, -4.3678e-04,  ...,  1.9455e-04,\n",
       "           3.4142e-04,  4.1771e-04],\n",
       "         [ 9.5367e-06,  9.5749e-04, -3.7384e-04,  ...,  5.6839e-04,\n",
       "           5.0735e-04,  5.2643e-04],\n",
       "         [ 1.3542e-04,  3.0041e-05,  4.2725e-04,  ..., -1.3065e-04,\n",
       "          -4.6730e-05, -2.4223e-04],\n",
       "         ...,\n",
       "         [-8.0872e-04, -6.5231e-04,  3.2806e-04,  ...,  9.7752e-05,\n",
       "          -5.4121e-05, -5.2643e-04],\n",
       "         [-4.2725e-04, -4.2439e-05,  5.3787e-04,  ..., -9.2316e-04,\n",
       "          -2.1744e-04, -8.0490e-04],\n",
       "         [ 5.3787e-04,  4.0817e-04,  5.4836e-05,  ..., -1.8787e-04,\n",
       "           4.7112e-04,  5.2261e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-4.5776e-04,  1.4114e-04,  5.1880e-04,  ..., -5.0354e-04,\n",
       "           8.4400e-05, -4.3297e-04],\n",
       "         [-5.3787e-04,  4.6539e-04,  5.2261e-04,  ..., -5.2643e-04,\n",
       "           5.0735e-04, -4.9973e-04],\n",
       "         [ 5.4550e-04, -4.8065e-04, -5.3024e-04,  ...,  5.2643e-04,\n",
       "          -4.2725e-04,  5.4550e-04],\n",
       "         ...,\n",
       "         [-5.1498e-04,  3.3855e-05,  5.5695e-04,  ..., -4.6539e-04,\n",
       "           4.0245e-04, -6.4087e-04],\n",
       "         [-5.4932e-04,  4.8828e-04,  5.6839e-04,  ..., -5.2261e-04,\n",
       "           4.9210e-04, -7.5912e-04],\n",
       "         [-4.4060e-04,  1.3828e-04,  4.9973e-04,  ..., -4.4632e-04,\n",
       "           2.1553e-04, -7.2861e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0025,  0.0019, -0.0024,  ...,  0.0023,  0.0021,  0.0021],\n",
       "         [-0.0012,  0.0009, -0.0014,  ...,  0.0014,  0.0013,  0.0015],\n",
       "         [-0.0004,  0.0009, -0.0016,  ...,  0.0008,  0.0014,  0.0010],\n",
       "         ...,\n",
       "         [ 0.0006, -0.0008, -0.0003,  ..., -0.0003, -0.0005, -0.0002],\n",
       "         [-0.0005, -0.0001, -0.0004,  ...,  0.0004,  0.0009,  0.0003],\n",
       "         [-0.0015,  0.0014, -0.0023,  ...,  0.0010,  0.0018,  0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 6.3324e-04, -4.6921e-04,  4.7112e-04,  ..., -4.1246e-05,\n",
       "          -3.9101e-04, -6.6757e-04],\n",
       "         [-1.7071e-04,  5.3406e-04, -4.3678e-04,  ...,  2.8419e-04,\n",
       "           5.2261e-04,  6.9046e-04],\n",
       "         [ 4.9210e-04, -5.2261e-04,  3.4142e-04,  ..., -5.0783e-05,\n",
       "          -4.5395e-04, -7.8964e-04],\n",
       "         ...,\n",
       "         [-6.2561e-04,  5.0735e-04, -5.3024e-04,  ...,  3.1471e-05,\n",
       "           5.1117e-04,  6.5231e-04],\n",
       "         [-8.9645e-04,  4.0245e-04, -2.4986e-04,  ..., -3.4332e-05,\n",
       "           4.2152e-04,  7.7057e-04],\n",
       "         [-1.0376e-03,  5.1117e-04, -4.2725e-04,  ...,  5.5432e-06,\n",
       "           4.8637e-04,  9.4223e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.8528e-04,  1.6499e-04, -3.5667e-04,  ...,  7.4005e-04,\n",
       "           6.3479e-06, -8.5068e-04],\n",
       "         [ 7.8678e-05,  4.3106e-04,  7.6675e-04,  ..., -1.3199e-03,\n",
       "          -7.5912e-04,  9.0408e-04],\n",
       "         [ 1.6308e-04,  5.5313e-04, -4.8161e-05,  ..., -3.6240e-05,\n",
       "          -2.0752e-03,  5.2643e-04],\n",
       "         ...,\n",
       "         [-1.7524e-05,  2.6703e-04, -4.3488e-04,  ...,  3.4904e-04,\n",
       "           1.4420e-03, -3.6430e-04],\n",
       "         [ 5.6744e-05,  3.4904e-04,  3.8147e-04,  ..., -5.9128e-04,\n",
       "           7.3910e-05,  5.5695e-04],\n",
       "         [-1.1368e-03, -3.0518e-04, -1.3733e-03,  ...,  4.3106e-04,\n",
       "          -4.5967e-04,  2.6107e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.4954e-03,  6.1798e-04, -8.3447e-05,  ...,  2.2125e-04,\n",
       "           4.6921e-04,  1.5259e-04],\n",
       "         [-1.1749e-03,  5.1880e-04,  2.2888e-04,  ...,  7.0095e-05,\n",
       "           5.0354e-04, -2.2888e-04],\n",
       "         [-1.4496e-04,  5.8746e-04, -1.7357e-04,  ...,  5.3406e-04,\n",
       "           5.1117e-04, -1.3046e-03],\n",
       "         ...,\n",
       "         [ 1.7548e-03, -5.9509e-04,  9.8348e-06,  ...,  8.2493e-05,\n",
       "          -6.9809e-04, -1.0586e-04],\n",
       "         [-1.3504e-03, -6.0272e-04,  5.9509e-04,  ..., -7.0190e-04,\n",
       "          -4.3106e-04,  4.5204e-04],\n",
       "         [-2.2125e-03,  4.5776e-04, -4.3631e-05,  ..., -4.2915e-04,\n",
       "           7.1335e-04,  2.5749e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2207e-03, -1.2207e-03, -5.9128e-04,  ..., -1.4687e-04,\n",
       "           5.4169e-04, -2.1100e-05],\n",
       "         [ 5.4169e-04, -1.0147e-03, -6.5231e-04,  ..., -1.2016e-04,\n",
       "           9.7656e-04,  9.7656e-04],\n",
       "         [-1.1749e-03,  5.7983e-04,  1.2283e-03,  ...,  9.4986e-04,\n",
       "          -3.6240e-04,  4.6730e-04],\n",
       "         ...,\n",
       "         [ 9.1553e-05, -7.2956e-05,  4.1771e-04,  ..., -1.1635e-04,\n",
       "          -2.1935e-04,  3.2425e-04],\n",
       "         [ 1.5163e-04,  1.1292e-03,  1.8978e-04,  ...,  5.2214e-05,\n",
       "          -6.5231e-04, -1.0376e-03],\n",
       "         [ 8.9645e-04, -6.3705e-04, -8.0109e-05,  ...,  2.2292e-05,\n",
       "           5.2261e-04,  6.2180e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.5286e-05, -8.0872e-04,  2.0294e-03,  ..., -4.6539e-04,\n",
       "           5.8746e-04,  3.7956e-04],\n",
       "         [-2.8229e-04,  5.9509e-04, -1.9989e-03,  ...,  4.4441e-04,\n",
       "          -8.0872e-04, -5.7602e-04],\n",
       "         [ 1.1826e-04,  1.2360e-03, -1.2741e-03,  ...,  4.8065e-04,\n",
       "          -6.3705e-04, -4.4250e-04],\n",
       "         ...,\n",
       "         [-4.6158e-04,  5.9509e-04, -2.6703e-04,  ...,  6.0654e-04,\n",
       "          -5.6076e-04, -4.3678e-04],\n",
       "         [-1.9741e-04,  5.1498e-04,  7.4387e-04,  ..., -4.8828e-04,\n",
       "           3.9482e-04,  3.6621e-04],\n",
       "         [-3.7575e-04, -2.4872e-03, -6.7711e-05,  ..., -5.4169e-04,\n",
       "           3.2043e-04,  1.3638e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2970e-03,  3.1662e-04, -8.9645e-04,  ...,  4.1771e-04,\n",
       "           7.8201e-04,  3.5095e-04],\n",
       "         [ 2.5749e-05, -1.2589e-04,  7.9727e-04,  ..., -7.7820e-04,\n",
       "          -2.3127e-05, -5.7220e-04],\n",
       "         [-1.2131e-03, -1.5793e-03,  8.6212e-04,  ..., -1.1597e-03,\n",
       "          -1.5945e-03, -8.5449e-04],\n",
       "         ...,\n",
       "         [ 3.6011e-03,  2.9449e-03, -2.7924e-03,  ...,  2.5177e-03,\n",
       "           1.9836e-03,  2.4719e-03],\n",
       "         [ 2.0905e-03,  2.0752e-03, -1.8463e-03,  ...,  1.7776e-03,\n",
       "           1.2207e-03, -8.7738e-04],\n",
       "         [ 5.4169e-04,  7.7820e-04, -1.1368e-03,  ...,  1.2665e-03,\n",
       "           2.3460e-04, -8.6975e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.4109e-03,  1.2207e-03, -9.5844e-05,  ...,  4.1962e-04,\n",
       "           2.7084e-04, -2.8419e-04],\n",
       "         [-2.5635e-03,  1.2741e-03, -9.7752e-05,  ...,  3.8147e-04,\n",
       "          -1.7524e-05, -8.8882e-04],\n",
       "         [ 4.3640e-03, -1.4725e-03,  1.1826e-04,  ..., -3.9101e-04,\n",
       "          -2.2984e-04,  3.6049e-04],\n",
       "         ...,\n",
       "         [-3.2959e-03,  1.2589e-03, -1.4877e-04,  ...,  4.1008e-04,\n",
       "           3.2616e-04,  1.9908e-05],\n",
       "         [-2.2736e-03,  1.0986e-03, -3.1662e-04,  ...,  4.4823e-04,\n",
       "           1.4973e-04, -4.3488e-04],\n",
       "         [-4.6387e-03,  5.6458e-04,  1.7014e-03,  ..., -7.8964e-04,\n",
       "          -7.8201e-04, -2.7657e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0681e-03, -6.5613e-04, -1.6403e-04,  ...,  1.9646e-04,\n",
       "          -6.8665e-04, -3.7003e-04],\n",
       "         [ 1.9073e-04, -2.4872e-03, -1.7395e-03,  ..., -9.7656e-04,\n",
       "          -1.9379e-03,  1.1292e-03],\n",
       "         [-3.7575e-04,  2.2125e-04, -1.5259e-04,  ..., -2.5272e-05,\n",
       "           4.6158e-04, -4.4823e-04],\n",
       "         ...,\n",
       "         [ 9.6130e-04, -2.5177e-04, -5.9605e-05,  ..., -9.0027e-04,\n",
       "          -7.8201e-05,  1.1749e-03],\n",
       "         [-7.2861e-04, -3.8719e-04, -8.8501e-04,  ..., -4.6349e-04,\n",
       "          -5.9509e-04,  3.6240e-04],\n",
       "         [-1.1368e-03,  6.0272e-04,  8.2970e-05,  ...,  1.0452e-03,\n",
       "           6.1035e-04, -1.3504e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.4790e-03,  1.0681e-04, -5.1498e-04,  ..., -2.9945e-04,\n",
       "          -5.4169e-04, -1.2436e-03],\n",
       "         [ 2.3956e-03, -7.7438e-04,  2.9945e-04,  ...,  2.4438e-05,\n",
       "          -8.0872e-04,  7.2861e-04],\n",
       "         [ 2.8687e-03, -9.2316e-04,  1.3065e-04,  ...,  6.0558e-05,\n",
       "          -8.5831e-04,  4.6539e-04],\n",
       "         ...,\n",
       "         [ 4.8218e-03, -7.6675e-04,  2.1553e-04,  ...,  1.0910e-03,\n",
       "           9.0122e-05,  1.3504e-03],\n",
       "         [ 4.0283e-03, -1.1139e-03, -1.5736e-04,  ...,  4.1580e-04,\n",
       "          -1.2665e-03,  4.1199e-04],\n",
       "         [-3.9673e-03,  3.0136e-04, -3.8862e-05,  ..., -9.3842e-04,\n",
       "          -5.3406e-04, -3.8338e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.5013e-04, -6.9427e-04, -7.1716e-04,  ..., -1.2684e-04,\n",
       "          -1.6403e-04,  1.7262e-04],\n",
       "         [-1.8311e-04, -7.0953e-04,  3.6240e-04,  ..., -4.9591e-04,\n",
       "          -2.7847e-04,  4.8828e-04],\n",
       "         [-1.6251e-03,  1.8921e-03, -1.3580e-03,  ..., -1.5793e-03,\n",
       "          -1.7090e-03, -1.5335e-03],\n",
       "         ...,\n",
       "         [ 9.6512e-04, -6.1035e-04,  5.6839e-04,  ...,  9.3842e-04,\n",
       "           8.3160e-04,  1.1139e-03],\n",
       "         [-2.3746e-04, -1.1301e-04, -4.1723e-05,  ...,  3.4142e-04,\n",
       "          -2.9945e-04, -4.7874e-04],\n",
       "         [-9.1076e-05, -1.1215e-03,  3.0518e-04,  ..., -1.5736e-04,\n",
       "          -1.1396e-04,  3.2234e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.1667e-03, -4.6539e-04, -1.1292e-03,  ...,  5.0068e-05,\n",
       "          -1.1683e-04, -1.4725e-03],\n",
       "         [-2.3193e-03, -1.7548e-03,  9.5367e-05,  ..., -8.9645e-05,\n",
       "           7.7820e-04,  2.2278e-03],\n",
       "         [ 2.5558e-04,  1.1520e-03, -4.4441e-04,  ...,  3.0136e-04,\n",
       "          -1.0986e-03, -2.2125e-03],\n",
       "         ...,\n",
       "         [ 2.5940e-03,  7.5531e-04, -1.4343e-03,  ...,  4.3488e-04,\n",
       "          -5.0735e-04, -1.6785e-03],\n",
       "         [ 2.2583e-03,  8.3923e-04, -9.0408e-04,  ..., -8.0109e-04,\n",
       "          -9.0790e-04, -1.2131e-03],\n",
       "         [ 1.4496e-03,  1.1749e-03, -3.9482e-04,  ...,  1.0681e-03,\n",
       "          -1.2016e-04, -6.5613e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 8.8501e-04,  7.5912e-04, -4.3678e-04,  ..., -3.3379e-04,\n",
       "           1.2436e-03,  8.1635e-04],\n",
       "         [ 3.4904e-04,  3.2043e-04, -7.1716e-04,  ...,  1.8692e-03,\n",
       "          -2.6321e-04, -4.9210e-04],\n",
       "         [-1.2207e-03, -6.7139e-04,  4.0627e-04,  ..., -1.1749e-03,\n",
       "          -8.2397e-04, -8.3923e-04],\n",
       "         ...,\n",
       "         [ 1.4801e-03,  1.9989e-03, -2.0294e-03,  ..., -1.5945e-03,\n",
       "           1.3885e-03,  1.0071e-03],\n",
       "         [ 1.1902e-03,  1.7624e-03, -1.5335e-03,  ..., -5.8413e-05,\n",
       "           7.2861e-04,  6.9046e-04],\n",
       "         [-9.1934e-04,  5.4359e-05, -1.2493e-04,  ...,  9.6130e-04,\n",
       "          -6.3705e-04, -1.5163e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.5095e-03, -2.2125e-03, -1.2894e-03,  ..., -6.2561e-04,\n",
       "          -1.1444e-03,  1.8616e-03],\n",
       "         [ 3.2501e-03, -1.0529e-03, -3.0823e-03,  ...,  8.7738e-04,\n",
       "           1.4496e-03,  6.5994e-04],\n",
       "         [-2.8992e-03,  6.5994e-04,  2.8992e-03,  ..., -1.1520e-03,\n",
       "          -1.9455e-03, -1.5182e-03],\n",
       "         ...,\n",
       "         [-2.0905e-03,  5.3167e-05,  1.6174e-03,  ..., -2.8534e-03,\n",
       "          -1.3123e-03, -4.8065e-04],\n",
       "         [ 3.7994e-03, -1.9684e-03, -1.0223e-03,  ..., -9.5367e-04,\n",
       "          -5.6076e-04,  1.6327e-03],\n",
       "         [ 3.4637e-03, -1.8845e-03, -1.4191e-03,  ..., -5.4550e-04,\n",
       "          -6.2180e-04,  1.0757e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 8.3542e-04,  1.8692e-03, -1.5564e-03,  ..., -9.6512e-04,\n",
       "          -1.4496e-03,  8.3160e-04],\n",
       "         [-3.9674e-07, -6.6376e-04, -9.9659e-05,  ...,  3.5286e-04,\n",
       "           1.5545e-04, -7.0572e-04],\n",
       "         [-8.8501e-04, -8.6212e-04,  1.6022e-03,  ...,  1.5564e-03,\n",
       "           1.4496e-03, -1.1063e-03],\n",
       "         ...,\n",
       "         [ 1.1597e-03,  1.4038e-03, -1.2970e-03,  ..., -1.7014e-03,\n",
       "          -1.4877e-03,  1.1902e-03],\n",
       "         [ 1.0777e-04,  7.0190e-04, -2.9373e-04,  ..., -1.1292e-03,\n",
       "          -9.4986e-04,  6.4850e-04],\n",
       "         [-1.1139e-03,  5.3024e-04, -6.1798e-04,  ..., -9.1553e-04,\n",
       "          -4.9591e-04,  3.3379e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.9809e-04, -2.6131e-04,  4.6349e-04,  ..., -7.0190e-04,\n",
       "          -5.0354e-04, -7.8678e-05],\n",
       "         [-1.6403e-03,  8.2779e-04,  3.7766e-04,  ...,  4.9829e-05,\n",
       "           3.1090e-04, -1.2875e-04],\n",
       "         [ 2.5635e-03, -9.4223e-04, -1.4496e-03,  ...,  8.2397e-04,\n",
       "          -8.8882e-04,  6.7520e-04],\n",
       "         ...,\n",
       "         [ 2.1057e-03, -7.8964e-04, -8.0490e-04,  ...,  2.1219e-05,\n",
       "          -6.1798e-04,  5.0354e-04],\n",
       "         [ 1.7166e-03, -8.3923e-04, -5.7983e-04,  ..., -1.7548e-04,\n",
       "          -7.5150e-04,  4.3297e-04],\n",
       "         [-2.0142e-03,  8.5068e-04,  7.2861e-04,  ...,  1.0109e-04,\n",
       "           3.8147e-04, -5.5695e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2589e-04, -6.9046e-04,  7.5150e-04,  ..., -6.0797e-06,\n",
       "          -2.3484e-05,  6.5994e-04],\n",
       "         [-1.0300e-03,  5.7983e-04,  4.1389e-04,  ...,  6.2943e-04,\n",
       "          -1.4877e-03, -1.2779e-04],\n",
       "         [ 1.6499e-04,  8.7357e-04,  5.1117e-04,  ..., -2.8419e-04,\n",
       "          -7.3433e-05, -2.9564e-04],\n",
       "         ...,\n",
       "         [-5.8711e-06, -1.2054e-03,  3.4332e-05,  ...,  1.0920e-04,\n",
       "           3.4904e-04,  1.8387e-03],\n",
       "         [-5.6076e-04, -2.4986e-04, -1.5030e-03,  ...,  4.0627e-04,\n",
       "          -9.8419e-04,  1.2131e-03],\n",
       "         [ 8.3160e-04,  1.0605e-03,  1.3046e-03,  ..., -1.1110e-04,\n",
       "           1.5564e-03, -1.4801e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.5182e-03,  2.2125e-03,  7.7820e-04,  ...,  2.4872e-03,\n",
       "          -2.5482e-03, -2.9182e-04],\n",
       "         [ 4.6921e-04,  2.1057e-03, -9.7656e-04,  ...,  8.7738e-04,\n",
       "          -5.5695e-04, -4.6349e-04],\n",
       "         [ 5.4169e-04,  2.1667e-03, -7.3624e-04,  ..., -1.8005e-03,\n",
       "          -4.9591e-04,  1.2207e-03],\n",
       "         ...,\n",
       "         [-5.9509e-04,  6.3324e-04, -1.8921e-03,  ..., -2.1820e-03,\n",
       "           1.3657e-03,  1.9989e-03],\n",
       "         [ 1.4725e-03,  1.1826e-03,  5.5432e-06,  ...,  2.3956e-03,\n",
       "          -6.9809e-04, -4.0436e-04],\n",
       "         [-2.7084e-04, -2.1515e-03,  1.6251e-03,  ..., -1.8082e-03,\n",
       "           4.5395e-04,  1.7738e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.8419e-04,  9.5367e-04, -3.7193e-05,  ...,  2.0504e-04,\n",
       "           4.1771e-04,  2.7084e-04],\n",
       "         [ 2.9564e-04, -1.5488e-03,  1.5163e-04,  ..., -5.7817e-06,\n",
       "           3.6430e-04, -2.2984e-04],\n",
       "         [-1.0586e-04,  3.4094e-05,  5.3406e-04,  ...,  1.4591e-04,\n",
       "           4.2152e-04,  7.8583e-04],\n",
       "         ...,\n",
       "         [ 1.6479e-03, -2.5787e-03, -1.3123e-03,  ..., -1.7242e-03,\n",
       "          -1.8311e-03, -1.8463e-03],\n",
       "         [-1.3275e-03,  1.7700e-03,  1.9531e-03,  ...,  1.8234e-03,\n",
       "           1.0910e-03,  1.2970e-03],\n",
       "         [ 4.0283e-03, -3.6469e-03, -2.1515e-03,  ..., -2.6550e-03,\n",
       "          -2.2278e-03, -1.2207e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.7842e-03, -2.7618e-03, -2.0313e-04,  ..., -3.1281e-04,\n",
       "          -1.8997e-03,  3.0670e-03],\n",
       "         [-2.5482e-03,  1.3733e-03,  7.9727e-04,  ..., -1.0910e-03,\n",
       "          -5.2643e-04, -2.8534e-03],\n",
       "         [-2.6245e-03,  1.6479e-03, -3.2425e-04,  ...,  2.6321e-04,\n",
       "           2.2430e-03, -2.5940e-03],\n",
       "         ...,\n",
       "         [-2.2888e-03,  1.7548e-03, -4.3678e-04,  ...,  2.5558e-04,\n",
       "           1.5488e-03, -2.4872e-03],\n",
       "         [-2.5635e-03,  1.5869e-03, -8.7261e-05,  ...,  2.6703e-04,\n",
       "           1.3657e-03, -2.2278e-03],\n",
       "         [-2.2888e-03,  1.6556e-03, -5.1880e-04,  ...,  2.8992e-04,\n",
       "           2.0752e-03, -2.4719e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.1798e-04,  4.9591e-04, -3.5286e-04,  ..., -6.8665e-04,\n",
       "           7.4387e-04, -3.4904e-04],\n",
       "         [-4.7684e-04,  2.9373e-04,  1.1978e-03,  ...,  1.7834e-04,\n",
       "          -3.3951e-04,  3.6621e-04],\n",
       "         [ 6.0272e-04, -1.4191e-03, -6.1417e-04,  ...,  6.0272e-04,\n",
       "          -1.1368e-03, -1.6327e-03],\n",
       "         ...,\n",
       "         [ 8.0872e-04, -5.5695e-04, -1.1368e-03,  ...,  9.2316e-04,\n",
       "          -9.8419e-04, -9.2697e-04],\n",
       "         [ 2.6093e-03, -2.0905e-03,  9.1553e-05,  ...,  3.0823e-03,\n",
       "          -3.0365e-03, -3.3417e-03],\n",
       "         [-1.0071e-03,  1.8120e-04,  1.0834e-03,  ..., -1.0147e-03,\n",
       "           7.2098e-04,  1.2112e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.3351e-03, -4.3869e-04, -2.1973e-03,  ..., -1.8692e-04,\n",
       "          -5.2261e-04, -1.1158e-04],\n",
       "         [-1.2207e-03,  4.5013e-04,  1.6479e-03,  ...,  3.3379e-04,\n",
       "           4.7112e-04,  5.4550e-04],\n",
       "         [-3.2616e-04,  9.3460e-05,  9.1553e-04,  ...,  4.2725e-04,\n",
       "           7.3242e-04,  1.3504e-03],\n",
       "         ...,\n",
       "         [ 1.0529e-03, -2.7275e-04, -1.0376e-03,  ..., -2.2125e-04,\n",
       "          -4.2725e-04, -5.3406e-04],\n",
       "         [-1.2360e-03,  3.3379e-04,  2.0447e-03,  ...,  7.3433e-05,\n",
       "           2.3842e-04,  6.8665e-04],\n",
       "         [-8.8882e-04,  4.5776e-04,  4.8828e-04,  ...,  2.2793e-04,\n",
       "           3.5095e-04,  8.8692e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.6403e-04, -2.1458e-04, -4.0245e-04,  ..., -4.1723e-06,\n",
       "           4.2677e-05,  3.2806e-04],\n",
       "         [-2.9945e-04,  8.9645e-04,  5.1498e-04,  ...,  6.6757e-04,\n",
       "          -5.0735e-04,  8.5449e-04],\n",
       "         [ 3.1471e-04,  1.5736e-05,  2.5177e-04,  ...,  5.8365e-04,\n",
       "          -1.2684e-04,  3.6430e-04],\n",
       "         ...,\n",
       "         [-8.1635e-04, -1.1027e-05,  4.2534e-04,  ...,  3.1853e-04,\n",
       "          -2.9182e-04,  9.1171e-04],\n",
       "         [-5.7220e-04,  1.8597e-04,  6.4850e-04,  ..., -2.3842e-04,\n",
       "          -8.9645e-04,  1.0147e-03],\n",
       "         [-2.6107e-05, -3.0327e-04,  5.1498e-04,  ..., -3.2234e-04,\n",
       "          -1.2283e-03,  4.2152e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.7956e-04,  1.2283e-03, -2.4796e-04,  ...,  5.0354e-04,\n",
       "          -4.7302e-04, -1.9741e-04],\n",
       "         [-1.5259e-03, -7.7820e-04,  4.4107e-05,  ..., -7.5340e-05,\n",
       "          -9.7275e-05,  3.2806e-04],\n",
       "         [ 8.5449e-04, -2.8992e-04,  9.5367e-04,  ..., -1.6022e-04,\n",
       "          -5.3787e-04,  3.6240e-04],\n",
       "         ...,\n",
       "         [ 4.1580e-04, -3.9291e-04,  4.2725e-04,  ..., -5.6839e-04,\n",
       "           1.4496e-04,  4.1008e-04],\n",
       "         [ 3.5477e-04,  1.8005e-03,  6.7234e-05,  ...,  2.9945e-04,\n",
       "           1.4019e-04, -5.0783e-05],\n",
       "         [-2.0123e-04, -1.6174e-03, -3.8338e-04,  ...,  3.3569e-04,\n",
       "           9.2506e-05, -2.7466e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.3885e-03, -4.6921e-04,  3.6621e-04,  ..., -8.2016e-04,\n",
       "          -2.5558e-04,  5.0354e-04],\n",
       "         [ 2.3956e-03,  2.4872e-03, -2.9297e-03,  ...,  2.6855e-03,\n",
       "          -2.4567e-03, -2.9755e-03],\n",
       "         [ 1.7395e-03, -1.9836e-03,  1.4648e-03,  ..., -2.0142e-03,\n",
       "           2.1667e-03,  2.5787e-03],\n",
       "         ...,\n",
       "         [-3.8452e-03,  1.5335e-03, -8.4305e-04,  ...,  1.4572e-03,\n",
       "          -1.1063e-03, -1.1215e-03],\n",
       "         [-1.2131e-03,  1.4114e-03, -3.9673e-04,  ...,  4.9829e-05,\n",
       "          -6.6376e-04, -7.1716e-04],\n",
       "         [ 2.2984e-04, -1.2360e-03,  1.3580e-03,  ..., -1.0223e-03,\n",
       "           1.2894e-03,  2.4261e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.1934e-04, -2.4128e-04, -1.4267e-03,  ...,  2.2507e-04,\n",
       "          -4.1504e-03, -2.6703e-03],\n",
       "         [ 7.7057e-04, -8.4305e-04, -2.0447e-03,  ..., -9.0408e-04,\n",
       "          -5.9891e-04,  2.0447e-03],\n",
       "         [-8.2397e-04,  5.9128e-04,  1.0529e-03,  ...,  7.8964e-04,\n",
       "          -9.9182e-04, -2.6550e-03],\n",
       "         ...,\n",
       "         [ 7.9727e-04, -7.4387e-04, -1.7242e-03,  ..., -8.8501e-04,\n",
       "           3.7575e-04,  1.9989e-03],\n",
       "         [-7.5912e-04,  7.2861e-04,  7.3624e-04,  ...,  6.9809e-04,\n",
       "          -9.1076e-05, -1.5030e-03],\n",
       "         [-5.2261e-04,  1.1215e-03,  1.3580e-03,  ...,  7.3242e-04,\n",
       "           1.7319e-03, -3.0365e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.5564e-03,  1.0376e-03,  2.1057e-03,  ..., -1.1063e-03,\n",
       "           1.1063e-03,  1.3962e-03],\n",
       "         [ 9.1934e-04,  4.7493e-04,  6.4468e-04,  ..., -2.8610e-04,\n",
       "           8.5449e-04,  7.1716e-04],\n",
       "         [-2.1935e-04,  1.4591e-04,  8.1539e-05,  ...,  2.7657e-04,\n",
       "          -4.1580e-04,  4.7207e-05],\n",
       "         ...,\n",
       "         [-4.5967e-04, -7.2861e-04, -8.5831e-04,  ...,  1.0452e-03,\n",
       "          -8.5831e-04, -9.9945e-04],\n",
       "         [ 1.7166e-03,  1.0223e-03,  1.5411e-03,  ..., -1.3199e-03,\n",
       "           1.0223e-03,  1.4877e-03],\n",
       "         [ 3.7575e-04,  1.4484e-05, -5.6839e-04,  ..., -4.9829e-05,\n",
       "           2.1172e-04, -2.8992e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0005,  0.0005, -0.0008,  ...,  0.0005,  0.0010, -0.0003],\n",
       "         [-0.0005,  0.0005, -0.0006,  ...,  0.0005,  0.0015,  0.0003],\n",
       "         [-0.0003,  0.0003, -0.0003,  ...,  0.0003,  0.0017, -0.0009],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0006,  0.0010,  ..., -0.0005, -0.0010, -0.0011],\n",
       "         [-0.0006,  0.0006, -0.0011,  ...,  0.0005,  0.0016,  0.0006],\n",
       "         [-0.0004,  0.0004, -0.0007,  ...,  0.0004,  0.0018, -0.0005]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.3733e-04, -1.0967e-04,  4.3154e-05,  ..., -7.6294e-04,\n",
       "          -4.0054e-04, -3.7766e-04],\n",
       "         [ 7.8964e-04,  5.0354e-04, -1.2436e-03,  ...,  5.5695e-04,\n",
       "           5.3787e-04, -7.0190e-04],\n",
       "         [-2.0790e-04, -1.0452e-03, -2.3603e-05,  ...,  2.5368e-04,\n",
       "           3.3569e-04,  1.4591e-04],\n",
       "         ...,\n",
       "         [ 4.1962e-04, -5.8413e-06, -1.3542e-04,  ...,  5.4550e-04,\n",
       "           8.8882e-04, -9.9945e-04],\n",
       "         [-2.8419e-04, -6.2180e-04, -1.8883e-04,  ...,  9.6130e-04,\n",
       "           2.4796e-04, -8.3160e-04],\n",
       "         [-3.8147e-06,  1.3046e-03, -7.3624e-04,  ...,  2.1267e-04,\n",
       "           4.7112e-04, -3.0899e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.4676e-05, -7.9727e-04, -5.6076e-04,  ..., -4.8256e-04,\n",
       "           1.8082e-03, -5.9509e-04],\n",
       "         [ 2.9755e-04, -7.8964e-04, -6.4087e-04,  ..., -8.7738e-05,\n",
       "          -3.9673e-04, -4.3869e-04],\n",
       "         [-4.0054e-05,  7.6675e-04,  4.9114e-05,  ...,  3.8338e-04,\n",
       "          -1.5945e-03,  4.7112e-04],\n",
       "         ...,\n",
       "         [ 4.9210e-04, -9.7656e-04,  5.3406e-05,  ..., -6.2180e-04,\n",
       "           1.2131e-03, -5.3787e-04],\n",
       "         [ 2.0599e-04, -6.9809e-04, -7.6675e-04,  ..., -3.9673e-04,\n",
       "           3.5477e-04, -4.3678e-04],\n",
       "         [-4.9210e-04,  5.4932e-04,  6.8665e-04,  ...,  5.1737e-05,\n",
       "          -1.1206e-04,  5.7602e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.1335e-04, -1.4801e-03,  6.4087e-04,  ..., -1.1139e-03,\n",
       "          -9.6130e-04,  5.1880e-04],\n",
       "         [-1.5564e-03,  3.8338e-04, -1.7624e-03,  ...,  1.3580e-03,\n",
       "           1.6785e-03, -1.9684e-03],\n",
       "         [ 3.2806e-03,  3.4180e-03,  3.2501e-03,  ..., -3.3112e-03,\n",
       "          -3.0823e-03,  4.5166e-03],\n",
       "         ...,\n",
       "         [-8.8882e-04, -9.0790e-04, -4.3297e-04,  ...,  3.4809e-05,\n",
       "           4.3678e-04, -7.4387e-04],\n",
       "         [ 2.4414e-03, -2.4605e-04,  2.8687e-03,  ..., -2.6093e-03,\n",
       "          -3.0212e-03,  2.5940e-03],\n",
       "         [-2.6550e-03, -8.6784e-05, -2.9449e-03,  ...,  2.7313e-03,\n",
       "           3.0212e-03, -2.4719e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.5912e-04,  8.2016e-04,  4.1389e-04,  ...,  4.3869e-04,\n",
       "           1.4954e-03, -3.7079e-03],\n",
       "         [ 8.1635e-04, -6.7711e-05, -7.5531e-04,  ..., -7.7438e-04,\n",
       "           3.9978e-03, -1.0300e-03],\n",
       "         [-7.7438e-04,  1.0223e-03, -6.5994e-04,  ...,  2.8992e-04,\n",
       "           2.6703e-03, -3.9062e-03],\n",
       "         ...,\n",
       "         [ 9.3460e-04, -8.7357e-04,  6.4850e-04,  ..., -2.1076e-04,\n",
       "          -2.7161e-03,  4.6997e-03],\n",
       "         [ 8.1635e-04, -8.7357e-04, -9.9659e-05,  ..., -4.3106e-04,\n",
       "          -2.3041e-03,  4.4250e-03],\n",
       "         [-7.8583e-04,  9.4223e-04, -2.6131e-04,  ...,  4.4441e-04,\n",
       "           1.9379e-03, -4.4556e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.2002e-05,  7.1716e-04, -3.5858e-04,  ...,  6.7139e-04,\n",
       "           1.1215e-03, -5.3406e-04],\n",
       "         [ 7.5912e-04,  1.6098e-03, -1.3733e-03,  ...,  9.8419e-04,\n",
       "           8.5449e-04, -6.2180e-04],\n",
       "         [-7.2956e-05, -1.5945e-03,  1.4572e-03,  ..., -1.0757e-03,\n",
       "          -1.8005e-03,  1.4954e-03],\n",
       "         ...,\n",
       "         [ 2.3746e-04,  2.9564e-04, -7.7724e-05,  ..., -1.2779e-04,\n",
       "          -1.1396e-04,  2.0385e-05],\n",
       "         [-1.4343e-03, -1.0681e-03,  1.0681e-03,  ..., -1.1826e-03,\n",
       "           3.0899e-04, -1.7548e-04],\n",
       "         [ 4.8447e-04,  2.3460e-04,  4.9210e-04,  ..., -7.3910e-05,\n",
       "           9.4414e-05, -6.9046e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0006, -0.0009, -0.0008,  ..., -0.0003,  0.0007,  0.0002],\n",
       "         [ 0.0006, -0.0003,  0.0003,  ..., -0.0001,  0.0002,  0.0005],\n",
       "         [-0.0007,  0.0004,  0.0004,  ...,  0.0004, -0.0007, -0.0006],\n",
       "         ...,\n",
       "         [ 0.0006, -0.0004, -0.0008,  ..., -0.0003,  0.0005,  0.0019],\n",
       "         [ 0.0004, -0.0002, -0.0001,  ..., -0.0003, -0.0002,  0.0014],\n",
       "         [-0.0006,  0.0002,  0.0004,  ...,  0.0004,  0.0003, -0.0019]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.9673e-04, -2.3556e-04, -4.4060e-04,  ..., -7.1335e-04,\n",
       "          -2.1553e-04,  1.2994e-05],\n",
       "         [ 2.9182e-04,  4.9591e-04,  8.5831e-04,  ...,  6.3324e-04,\n",
       "          -1.1015e-04,  5.0735e-04],\n",
       "         [ 2.4261e-03,  9.2316e-04,  1.1520e-03,  ..., -2.4414e-03,\n",
       "           5.2261e-04,  1.4420e-03],\n",
       "         ...,\n",
       "         [ 1.8692e-03,  1.2894e-03,  1.7548e-03,  ..., -7.4005e-04,\n",
       "           1.1826e-03,  9.2697e-04],\n",
       "         [ 1.6479e-03,  1.3657e-03,  1.5488e-03,  ..., -2.0599e-04,\n",
       "           8.6212e-04,  1.4114e-03],\n",
       "         [ 2.8419e-04,  6.9427e-04,  4.2725e-04,  ...,  5.9128e-05,\n",
       "          -2.3651e-04,  2.5940e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.5313e-04,  2.7084e-04, -1.4343e-03,  ..., -2.8419e-04,\n",
       "          -8.5449e-04,  4.4250e-04],\n",
       "         [ 8.0109e-04, -8.9407e-06, -2.5024e-03,  ..., -8.6975e-04,\n",
       "          -4.2152e-04,  3.0899e-04],\n",
       "         [ 2.3460e-04,  1.5080e-05, -1.3275e-03,  ..., -5.3024e-04,\n",
       "          -2.0123e-04,  1.6403e-04],\n",
       "         ...,\n",
       "         [-5.9509e-04, -4.3678e-04, -2.7084e-04,  ...,  1.3428e-03,\n",
       "           8.5831e-04,  2.2411e-05],\n",
       "         [ 4.4250e-04,  8.1062e-05, -1.2894e-03,  ..., -6.1035e-04,\n",
       "           1.9789e-05,  3.7575e-04],\n",
       "         [ 5.9509e-04,  3.0899e-04, -1.6098e-03,  ...,  2.2411e-04,\n",
       "           2.5368e-04,  4.3297e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.7874e-04, -6.3705e-04, -1.4973e-04,  ..., -9.6130e-04,\n",
       "          -7.9632e-05,  7.0953e-04],\n",
       "         [-4.7112e-04, -5.0354e-04, -2.0504e-04,  ..., -4.8256e-04,\n",
       "           5.8889e-05,  5.1117e-04],\n",
       "         [-2.6703e-04, -6.0272e-04, -1.0452e-03,  ...,  9.0122e-05,\n",
       "           1.8005e-03,  1.3809e-03],\n",
       "         ...,\n",
       "         [ 9.1553e-05, -8.1539e-05,  5.4550e-04,  ..., -7.2420e-06,\n",
       "           1.2779e-04,  1.0986e-03],\n",
       "         [ 4.3640e-03,  4.1809e-03,  3.8452e-03,  ...,  3.4943e-03,\n",
       "          -3.7079e-03, -3.9368e-03],\n",
       "         [ 1.3809e-03,  4.2725e-04,  1.6632e-03,  ...,  1.0757e-03,\n",
       "          -6.0272e-04, -5.9509e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0007,  0.0004, -0.0029,  ..., -0.0008,  0.0030,  0.0020],\n",
       "         [-0.0006,  0.0006, -0.0025,  ..., -0.0005,  0.0025,  0.0019],\n",
       "         [-0.0007,  0.0005, -0.0031,  ..., -0.0018,  0.0038,  0.0023],\n",
       "         ...,\n",
       "         [-0.0005,  0.0002, -0.0029,  ..., -0.0017,  0.0035,  0.0023],\n",
       "         [ 0.0008, -0.0002,  0.0032,  ...,  0.0017, -0.0035, -0.0018],\n",
       "         [ 0.0006, -0.0005,  0.0023,  ...,  0.0011, -0.0030, -0.0017]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.2221e-04,  4.0817e-04,  2.8968e-05,  ...,  3.6430e-04,\n",
       "           9.9659e-05,  9.4414e-05],\n",
       "         [ 1.0529e-03, -3.5095e-04, -5.9128e-04,  ...,  7.2861e-04,\n",
       "           6.5994e-04, -6.1035e-04],\n",
       "         [ 6.1035e-04, -4.3392e-05,  4.8828e-04,  ..., -7.7820e-04,\n",
       "          -9.0027e-04,  1.2894e-03],\n",
       "         ...,\n",
       "         [-2.3804e-03,  1.4114e-03,  5.4550e-04,  ...,  2.7924e-03,\n",
       "           2.4719e-03,  2.9297e-03],\n",
       "         [ 4.4060e-04, -9.9945e-04, -8.3923e-05,  ..., -6.7234e-05,\n",
       "          -1.3962e-03, -7.5150e-04],\n",
       "         [-1.3275e-03,  1.9932e-04, -1.5855e-05,  ...,  2.3842e-04,\n",
       "           2.8038e-04,  3.0899e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.8539e-03, -6.7234e-05,  9.8419e-04,  ...,  1.6785e-04,\n",
       "          -1.1597e-03, -1.3123e-03],\n",
       "         [-9.5367e-04,  4.7302e-04, -9.3079e-04,  ...,  4.4632e-04,\n",
       "           1.8597e-04,  1.4191e-03],\n",
       "         [-1.0376e-03,  3.4523e-04, -1.4019e-04,  ...,  6.6757e-04,\n",
       "          -3.0136e-04,  1.0376e-03],\n",
       "         ...,\n",
       "         [ 7.2861e-04, -5.6839e-04,  1.1301e-04,  ..., -5.9128e-04,\n",
       "           5.1880e-04, -8.2016e-04],\n",
       "         [-1.4400e-04, -6.2561e-04, -2.0905e-03,  ..., -1.0605e-03,\n",
       "           1.0910e-03,  1.5564e-03],\n",
       "         [-8.8501e-04,  5.3787e-04, -1.2131e-03,  ...,  5.3787e-04,\n",
       "           7.3242e-04,  1.5793e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0452e-03, -2.5749e-05,  3.0899e-04,  ...,  1.1110e-04,\n",
       "           1.4591e-04,  5.4169e-04],\n",
       "         [ 7.7438e-04,  9.4223e-04,  1.2817e-03,  ...,  4.1962e-04,\n",
       "          -8.3923e-04,  3.0136e-04],\n",
       "         [ 1.0223e-03, -7.1526e-05,  9.9945e-04,  ...,  2.6321e-04,\n",
       "          -5.8746e-04,  9.1553e-04],\n",
       "         ...,\n",
       "         [ 1.3275e-03,  1.0605e-03,  1.0452e-03,  ...,  1.4191e-03,\n",
       "          -1.0605e-03,  6.4850e-04],\n",
       "         [ 8.2016e-04,  8.9264e-04,  8.6975e-04,  ...,  8.8501e-04,\n",
       "          -7.5912e-04,  1.0223e-03],\n",
       "         [ 1.8215e-04,  6.8665e-04,  4.2534e-04,  ...,  4.2725e-04,\n",
       "          -1.4973e-04,  5.7220e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.4523e-04, -1.1444e-03, -2.2736e-03,  ..., -8.2779e-04,\n",
       "           7.4005e-04,  1.8311e-03],\n",
       "         [-4.6492e-05, -6.8665e-04, -2.6550e-03,  ..., -1.8616e-03,\n",
       "           5.3787e-04,  1.7395e-03],\n",
       "         [ 1.3828e-04, -8.2016e-04, -1.6479e-03,  ..., -1.2665e-03,\n",
       "           1.2360e-03,  1.0376e-03],\n",
       "         ...,\n",
       "         [ 2.7466e-04, -1.0452e-03, -1.6479e-03,  ..., -2.2583e-03,\n",
       "           3.0899e-04,  1.6708e-03],\n",
       "         [-1.1730e-04,  8.2779e-04,  2.2888e-03,  ...,  2.4567e-03,\n",
       "          -7.1716e-04, -1.6022e-03],\n",
       "         [ 2.9182e-04, -8.9264e-04, -2.3499e-03,  ..., -2.3937e-04,\n",
       "           1.6327e-03,  1.4343e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0529e-03, -4.1771e-04, -7.8583e-04,  ...,  1.1597e-03,\n",
       "          -8.8215e-05,  1.1597e-03],\n",
       "         [-1.5831e-04,  7.4387e-04, -3.0518e-05,  ...,  1.0147e-03,\n",
       "           4.6921e-04,  4.9591e-04],\n",
       "         [-3.5095e-04,  3.5706e-03, -2.4567e-03,  ...,  1.7166e-03,\n",
       "           2.9755e-03,  1.1139e-03],\n",
       "         ...,\n",
       "         [ 2.8372e-05, -1.8692e-04,  1.5616e-05,  ..., -5.9509e-04,\n",
       "          -6.7139e-04, -3.7384e-04],\n",
       "         [-8.5449e-04,  1.8387e-03, -1.8158e-03,  ...,  1.2131e-03,\n",
       "           1.8311e-03,  1.9226e-03],\n",
       "         [ 1.9302e-03, -3.1281e-03,  2.8534e-03,  ..., -2.6855e-03,\n",
       "          -2.5940e-03, -2.8076e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 8.7261e-05, -5.7983e-04,  1.0986e-03,  ..., -4.8065e-04,\n",
       "          -7.5531e-04,  1.0967e-04],\n",
       "         [ 2.7008e-03,  7.4768e-04, -2.9144e-03,  ..., -2.4719e-03,\n",
       "           4.8828e-03, -1.3123e-03],\n",
       "         [-1.3428e-03, -6.6376e-04,  1.8387e-03,  ..., -3.3617e-05,\n",
       "          -3.0518e-03,  8.1253e-04],\n",
       "         ...,\n",
       "         [ 6.3324e-04,  6.6376e-04, -2.0447e-03,  ..., -6.1512e-05,\n",
       "           2.9144e-03, -8.0490e-04],\n",
       "         [ 2.4719e-03, -4.9210e-04, -6.4850e-04,  ..., -1.5411e-03,\n",
       "           2.7771e-03, -5.4836e-05],\n",
       "         [ 7.7724e-05,  6.2180e-04, -1.0376e-03,  ...,  3.1471e-04,\n",
       "           1.8311e-03, -7.4387e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 6.2943e-04,  2.8038e-04,  4.2534e-04,  ...,  2.7275e-04,\n",
       "           5.7602e-04, -4.1962e-04],\n",
       "         [-1.4114e-04, -1.4114e-04,  4.9973e-04,  ..., -3.5858e-04,\n",
       "          -9.8348e-06, -3.7193e-05],\n",
       "         [ 3.4142e-04, -3.5477e-04,  5.9891e-04,  ..., -5.2261e-04,\n",
       "          -1.6594e-04, -1.7738e-04],\n",
       "         ...,\n",
       "         [ 1.6451e-05,  5.5313e-04, -1.5259e-04,  ...,  9.4223e-04,\n",
       "           5.0735e-04, -3.6812e-04],\n",
       "         [-3.9482e-04,  4.8447e-04, -7.3242e-04,  ...,  2.7466e-04,\n",
       "          -1.5259e-04,  4.7684e-04],\n",
       "         [-3.0518e-04, -7.2098e-04,  3.3379e-04,  ..., -3.2997e-04,\n",
       "           3.0899e-04,  3.8910e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.3657e-03, -5.5695e-04,  1.0376e-03,  ..., -7.8583e-04,\n",
       "          -1.4572e-03, -4.3869e-05],\n",
       "         [-1.9302e-03,  4.0245e-04, -4.7302e-04,  ...,  9.2697e-04,\n",
       "          -3.3379e-04,  1.1597e-03],\n",
       "         [ 2.0905e-03, -4.5967e-04,  4.3869e-04,  ..., -1.0910e-03,\n",
       "          -1.7357e-04, -1.0529e-03],\n",
       "         ...,\n",
       "         [-1.1673e-03,  5.9509e-04,  2.9802e-05,  ...,  8.3542e-04,\n",
       "          -1.3809e-03,  1.9150e-03],\n",
       "         [ 1.8234e-03, -4.6349e-04,  4.4060e-04,  ..., -8.9645e-04,\n",
       "           4.6492e-05, -9.0408e-04],\n",
       "         [-1.6556e-03,  5.7983e-04, -8.5449e-04,  ...,  8.4305e-04,\n",
       "           1.5182e-03,  2.7657e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-4.0770e-05, -4.8637e-04,  2.3556e-04,  ...,  2.1696e-05,\n",
       "          -6.1035e-04, -7.1335e-04],\n",
       "         [-6.0654e-04, -3.9101e-04,  7.0572e-05,  ..., -1.8120e-04,\n",
       "           3.1853e-04, -6.9439e-06],\n",
       "         [ 1.1301e-04, -1.1063e-04,  2.6321e-04,  ...,  2.3079e-04,\n",
       "          -1.0605e-03,  6.6376e-04],\n",
       "         ...,\n",
       "         [-1.3733e-04,  2.3270e-04, -3.5477e-04,  ..., -6.7520e-04,\n",
       "           4.9210e-04,  1.9073e-04],\n",
       "         [-5.3024e-04,  1.0910e-03, -7.9346e-04,  ..., -1.0223e-03,\n",
       "           1.2131e-03, -1.1749e-03],\n",
       "         [ 5.9509e-04, -1.9360e-04,  1.6499e-04,  ...,  6.2561e-04,\n",
       "           2.9182e-04,  6.4850e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.6894e-04,  1.3428e-03, -4.0054e-04,  ..., -2.1935e-04,\n",
       "          -1.1597e-03, -6.8283e-04],\n",
       "         [ 1.9073e-04,  3.8528e-04,  5.8746e-04,  ...,  4.9591e-04,\n",
       "           7.8964e-04,  6.2561e-04],\n",
       "         [ 2.2054e-05,  1.3733e-03, -1.9550e-04,  ..., -2.4986e-04,\n",
       "          -9.2697e-04, -5.9128e-04],\n",
       "         ...,\n",
       "         [ 4.0054e-04,  9.9945e-04, -4.2152e-04,  ..., -4.3297e-04,\n",
       "          -4.9973e-04, -4.3678e-04],\n",
       "         [ 6.9618e-05,  8.2397e-04,  5.7602e-04,  ...,  4.0436e-04,\n",
       "          -6.6376e-04,  5.2643e-04],\n",
       "         [ 2.0027e-04,  1.2817e-03, -3.7956e-04,  ..., -2.8038e-04,\n",
       "          -1.0300e-03, -1.0300e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0008,  0.0015,  0.0008,  ..., -0.0017, -0.0016, -0.0017],\n",
       "         [-0.0012, -0.0007,  0.0007,  ..., -0.0002,  0.0007,  0.0001],\n",
       "         [ 0.0036,  0.0030,  0.0030,  ..., -0.0034, -0.0035, -0.0032],\n",
       "         ...,\n",
       "         [-0.0001,  0.0006, -0.0007,  ..., -0.0003, -0.0012, -0.0001],\n",
       "         [-0.0007, -0.0010, -0.0011,  ...,  0.0007,  0.0003,  0.0012],\n",
       "         [-0.0012, -0.0013, -0.0003,  ...,  0.0015,  0.0011,  0.0012]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.3746e-04,  3.3760e-04, -2.2430e-03,  ..., -1.3657e-03,\n",
       "           1.2589e-03,  2.4719e-03],\n",
       "         [-9.1076e-05,  1.5163e-04, -2.8076e-03,  ..., -1.8997e-03,\n",
       "           1.6632e-03,  1.9073e-03],\n",
       "         [ 2.0905e-03, -1.0910e-03, -3.5400e-03,  ..., -3.8910e-03,\n",
       "           3.1738e-03,  1.5793e-03],\n",
       "         ...,\n",
       "         [-3.2997e-04, -7.6294e-05,  3.6469e-03,  ...,  3.6469e-03,\n",
       "          -3.2196e-03, -2.7008e-03],\n",
       "         [ 1.3447e-04, -3.9291e-04,  3.0365e-03,  ...,  1.9455e-03,\n",
       "          -1.6098e-03, -2.2125e-03],\n",
       "         [-1.0529e-03, -4.4632e-04,  2.8534e-03,  ...,  1.6937e-03,\n",
       "          -2.0142e-03, -2.9755e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2970e-04,  1.3809e-03,  5.7983e-04,  ...,  5.6839e-04,\n",
       "           7.8201e-04,  1.1368e-03],\n",
       "         [ 1.0071e-03, -1.8883e-04, -9.6893e-04,  ..., -9.9945e-04,\n",
       "          -5.7983e-04, -4.6158e-04],\n",
       "         [ 9.8419e-04, -1.2970e-03, -2.0752e-03,  ..., -1.1063e-03,\n",
       "          -7.5912e-04, -1.3199e-03],\n",
       "         ...,\n",
       "         [-3.7766e-04,  2.6894e-04,  1.0757e-03,  ...,  3.3569e-04,\n",
       "           5.2261e-04, -4.5013e-04],\n",
       "         [-3.0327e-04,  8.5449e-04,  7.8964e-04,  ...,  1.2360e-03,\n",
       "           9.1934e-04,  9.1934e-04],\n",
       "         [-8.0490e-04, -5.3167e-05,  1.3733e-03,  ...,  1.3733e-04,\n",
       "           3.6240e-04,  4.1008e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2207e-03, -5.1117e-04, -1.6785e-03,  ..., -1.3962e-03,\n",
       "           1.4572e-03,  6.6757e-04],\n",
       "         [ 1.9073e-03, -5.3024e-04, -6.5613e-04,  ..., -7.8583e-04,\n",
       "           5.6839e-04, -7.7820e-04],\n",
       "         [-3.2997e-04, -6.2561e-04,  6.7520e-04,  ...,  1.6022e-03,\n",
       "          -1.4038e-03, -1.3351e-03],\n",
       "         ...,\n",
       "         [ 8.8120e-04, -4.1580e-04, -1.1158e-04,  ..., -4.1485e-05,\n",
       "          -4.2677e-05, -1.9836e-04],\n",
       "         [ 1.7319e-03, -6.1417e-04, -5.4169e-04,  ..., -8.7357e-04,\n",
       "           7.8964e-04, -7.6675e-04],\n",
       "         [ 7.2002e-05, -3.9482e-04,  3.6049e-04,  ..., -4.5967e-04,\n",
       "          -2.8133e-05, -5.7220e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.1498e-04, -4.9210e-04, -3.8719e-04,  ..., -9.2697e-04,\n",
       "          -1.0834e-03,  2.5368e-04],\n",
       "         [-1.3733e-04, -1.5488e-03, -4.6921e-04,  ...,  2.9182e-04,\n",
       "          -3.9291e-04,  5.7983e-04],\n",
       "         [-1.3828e-04, -4.8876e-05,  2.3651e-04,  ...,  2.6894e-04,\n",
       "          -1.1749e-03,  5.0735e-04],\n",
       "         ...,\n",
       "         [-5.9509e-04, -5.3787e-04, -4.5300e-05,  ..., -7.9155e-05,\n",
       "           9.3460e-04, -2.4223e-04],\n",
       "         [ 1.9531e-03, -1.2436e-03, -9.9945e-04,  ..., -1.3809e-03,\n",
       "          -9.3842e-04, -9.8419e-04],\n",
       "         [ 4.1389e-04, -7.6294e-04, -2.3365e-04,  ..., -4.9973e-04,\n",
       "           6.1035e-04, -1.6117e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.2234e-04,  6.9618e-05,  4.2534e-04,  ..., -5.3787e-04,\n",
       "          -3.7766e-04,  1.2970e-03],\n",
       "         [-4.8256e-04,  1.0452e-03, -1.1587e-04,  ...,  3.2425e-04,\n",
       "           5.3787e-04, -4.7112e-04],\n",
       "         [-3.9673e-04,  6.5613e-04, -6.3324e-04,  ...,  3.0899e-04,\n",
       "           4.8637e-04, -9.0027e-04],\n",
       "         ...,\n",
       "         [-3.0327e-04,  1.3256e-04,  4.8637e-04,  ...,  5.9891e-04,\n",
       "           4.6349e-04, -9.3079e-04],\n",
       "         [ 6.7139e-04,  1.0490e-04,  1.2512e-03,  ...,  7.2861e-04,\n",
       "          -2.1696e-05, -1.2398e-04],\n",
       "         [-1.8001e-05, -8.3160e-04, -5.5313e-05,  ...,  5.0354e-04,\n",
       "           6.0272e-04, -1.3123e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-4.9210e-04,  1.3580e-03, -1.0300e-03,  ...,  5.4550e-04,\n",
       "          -1.4572e-03,  3.4332e-05],\n",
       "         [ 6.5231e-04, -5.0735e-04, -9.0599e-05,  ..., -2.4033e-04,\n",
       "           5.6839e-04, -1.2131e-03],\n",
       "         [-1.2665e-03,  1.8158e-03, -1.7624e-03,  ...,  2.4414e-03,\n",
       "          -1.9684e-03,  1.5106e-03],\n",
       "         ...,\n",
       "         [ 1.6098e-03, -2.0294e-03,  2.0905e-03,  ..., -2.3956e-03,\n",
       "           2.0142e-03, -1.0986e-03],\n",
       "         [ 8.2970e-05, -4.4823e-04,  4.0770e-05,  ..., -2.7275e-04,\n",
       "          -4.1389e-04, -2.5177e-04],\n",
       "         [ 7.8583e-04, -1.1015e-04,  1.6308e-04,  ...,  2.2125e-04,\n",
       "          -5.8365e-04, -1.0910e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0024,  0.0008,  0.0015,  ..., -0.0022,  0.0038, -0.0018],\n",
       "         [ 0.0022, -0.0011, -0.0004,  ...,  0.0022, -0.0042,  0.0009],\n",
       "         [-0.0024,  0.0010,  0.0008,  ..., -0.0030,  0.0047, -0.0015],\n",
       "         ...,\n",
       "         [ 0.0017,  0.0005, -0.0017,  ...,  0.0037, -0.0050,  0.0042],\n",
       "         [-0.0017,  0.0010,  0.0008,  ..., -0.0015,  0.0041, -0.0008],\n",
       "         [ 0.0029, -0.0003, -0.0013,  ...,  0.0042, -0.0042,  0.0022]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.1444e-03, -1.5259e-03,  1.2512e-03,  ..., -1.2817e-03,\n",
       "          -5.6839e-04, -2.1553e-04],\n",
       "         [-8.5831e-05,  3.2043e-04,  2.6512e-04,  ..., -1.1349e-04,\n",
       "           4.6539e-04, -1.2817e-03],\n",
       "         [-1.4496e-03,  1.1520e-03, -1.8692e-03,  ...,  2.3651e-03,\n",
       "           1.7471e-03,  3.0518e-04],\n",
       "         ...,\n",
       "         [-2.0599e-03,  9.9182e-04, -2.0294e-03,  ...,  1.8616e-03,\n",
       "           1.5335e-03, -1.2283e-03],\n",
       "         [-6.6757e-04, -2.8801e-04,  5.2261e-04,  ..., -3.4904e-04,\n",
       "          -6.6757e-04,  1.2589e-03],\n",
       "         [-1.4973e-04, -1.7881e-05,  1.0757e-03,  ..., -7.2479e-04,\n",
       "          -5.8365e-04,  5.1880e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2817e-03,  2.8419e-04,  1.7548e-03,  ..., -6.3324e-04,\n",
       "           1.9302e-03,  3.3569e-04],\n",
       "         [ 1.2894e-03, -6.0558e-05, -2.0752e-03,  ...,  5.9509e-04,\n",
       "          -1.8845e-03, -2.5177e-04],\n",
       "         [-1.2817e-03, -4.6968e-05,  1.7090e-03,  ..., -8.7738e-04,\n",
       "           5.9128e-04,  2.0695e-04],\n",
       "         ...,\n",
       "         [ 1.4648e-03,  2.9244e-07, -2.7313e-03,  ...,  1.3809e-03,\n",
       "          -2.0447e-03, -5.9605e-05],\n",
       "         [ 1.0071e-03, -3.4714e-04, -1.7471e-03,  ...,  4.2725e-04,\n",
       "          -6.1798e-04, -1.2493e-04],\n",
       "         [-8.4686e-04,  1.1597e-03, -1.0223e-03,  ...,  1.5640e-03,\n",
       "          -1.6785e-03,  1.2131e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.1292e-03, -4.4823e-04,  4.7874e-04,  ...,  6.4087e-04,\n",
       "           1.1215e-03,  6.4468e-04],\n",
       "         [-2.2583e-03, -1.2283e-03,  1.3199e-03,  ...,  1.2283e-03,\n",
       "          -2.1210e-03,  1.9836e-03],\n",
       "         [-1.1215e-03,  2.3365e-05,  1.3828e-04,  ...,  8.2016e-04,\n",
       "           1.9073e-04,  1.3046e-03],\n",
       "         ...,\n",
       "         [-8.2850e-06,  4.4823e-04, -3.5095e-04,  ..., -5.1117e-04,\n",
       "           6.1798e-04,  4.0531e-05],\n",
       "         [-8.7261e-05,  6.3705e-04, -7.8678e-05,  ...,  7.0095e-05,\n",
       "           5.1117e-04,  4.0245e-04],\n",
       "         [-5.7459e-05,  3.9482e-04, -8.8120e-04,  ...,  1.8001e-05,\n",
       "           6.4087e-04, -1.2100e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0910e-03,  2.8610e-04,  4.3106e-04,  ..., -3.3569e-04,\n",
       "           8.7738e-04, -8.7738e-04],\n",
       "         [ 1.6861e-03, -5.2643e-04, -9.5367e-04,  ..., -4.3869e-05,\n",
       "           1.7471e-03, -8.0109e-04],\n",
       "         [ 3.2187e-05,  7.0572e-04,  9.9182e-04,  ...,  3.6240e-04,\n",
       "          -2.4414e-03,  5.8365e-04],\n",
       "         ...,\n",
       "         [-9.9182e-04,  7.4005e-04,  6.3705e-04,  ...,  4.7302e-04,\n",
       "          -1.0452e-03,  6.5994e-04],\n",
       "         [ 1.4877e-03, -2.7657e-04, -1.4114e-04,  ..., -2.8014e-05,\n",
       "           1.4801e-03, -7.7820e-04],\n",
       "         [-1.6556e-03,  5.6839e-04,  3.2425e-04,  ...,  5.5730e-06,\n",
       "          -1.4954e-03,  6.7902e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.1662e-04, -2.1744e-04, -3.5667e-04,  ...,  4.5586e-04,\n",
       "          -1.2493e-04, -3.6240e-05],\n",
       "         [-3.9864e-04, -4.1199e-04, -2.8229e-04,  ...,  5.5313e-05,\n",
       "           3.2806e-04,  4.0436e-04],\n",
       "         [-2.0027e-04, -1.3199e-03, -6.7520e-04,  ...,  9.4986e-04,\n",
       "          -9.9659e-05,  1.5259e-03],\n",
       "         ...,\n",
       "         [-1.2665e-03, -4.7874e-04, -9.7275e-04,  ...,  7.7057e-04,\n",
       "          -9.0790e-04,  7.8583e-04],\n",
       "         [-7.6294e-04, -9.4986e-04, -8.6212e-04,  ...,  1.1292e-03,\n",
       "          -1.3428e-03,  8.6212e-04],\n",
       "         [-1.1063e-03,  1.9932e-04, -7.4387e-04,  ...,  2.8038e-04,\n",
       "          -4.1771e-04,  6.1035e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0008, -0.0003,  0.0013,  ...,  0.0009, -0.0044,  0.0027],\n",
       "         [ 0.0008, -0.0007,  0.0007,  ...,  0.0003, -0.0035,  0.0011],\n",
       "         [ 0.0006, -0.0007,  0.0019,  ...,  0.0007, -0.0045,  0.0021],\n",
       "         ...,\n",
       "         [-0.0006,  0.0005, -0.0007,  ..., -0.0008,  0.0038, -0.0018],\n",
       "         [ 0.0009, -0.0010,  0.0012,  ...,  0.0007, -0.0037,  0.0021],\n",
       "         [-0.0005,  0.0009, -0.0007,  ..., -0.0009,  0.0043, -0.0022]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-5.2261e-04,  4.5776e-04, -6.6757e-04,  ..., -1.1749e-03,\n",
       "           8.8882e-04,  1.1139e-03],\n",
       "         [-5.0735e-04, -8.0490e-04,  2.6131e-04,  ...,  2.2697e-04,\n",
       "          -1.2436e-03, -7.9727e-04],\n",
       "         [-6.3324e-04, -1.3199e-03,  9.0790e-04,  ...,  1.3504e-03,\n",
       "          -3.3569e-04, -1.3046e-03],\n",
       "         ...,\n",
       "         [-1.7014e-03, -2.6703e-04, -6.5994e-04,  ..., -2.1648e-04,\n",
       "           7.3624e-04, -5.4359e-05],\n",
       "         [-4.6158e-04,  2.9755e-04, -6.5231e-04,  ..., -4.0245e-04,\n",
       "           1.4954e-03,  1.1292e-03],\n",
       "         [ 3.9291e-04, -1.8597e-04, -2.1267e-04,  ...,  1.2589e-04,\n",
       "           1.7548e-04, -1.1349e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.1962e-04, -2.6941e-05, -3.4142e-04,  ..., -6.0272e-04,\n",
       "           1.4725e-03, -1.0910e-03],\n",
       "         [-5.2643e-04,  9.2316e-04,  5.9891e-04,  ..., -4.4703e-06,\n",
       "           2.1820e-03, -1.6594e-04],\n",
       "         [ 6.5994e-04,  3.6621e-04, -5.4550e-04,  ...,  7.5150e-04,\n",
       "          -2.6550e-03,  1.3123e-03],\n",
       "         ...,\n",
       "         [ 6.1798e-04, -2.9373e-04, -2.5177e-04,  ...,  3.6430e-04,\n",
       "          -2.5940e-03,  4.0436e-04],\n",
       "         [-5.5313e-04,  8.6975e-04,  1.8120e-04,  ...,  2.1076e-04,\n",
       "           2.3346e-03,  2.1362e-04],\n",
       "         [-7.9346e-04,  1.0757e-03,  5.3406e-04,  ..., -1.1396e-04,\n",
       "           2.5024e-03, -2.7776e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-4.6158e-04, -1.1015e-04, -2.2888e-04,  ..., -1.5926e-04,\n",
       "          -1.1444e-03, -3.6430e-04],\n",
       "         [-3.4904e-04, -6.2943e-04,  5.3406e-04,  ..., -1.3199e-03,\n",
       "           5.0735e-04,  7.2861e-04],\n",
       "         [ 1.0605e-03,  4.2200e-05, -4.1008e-05,  ...,  8.6308e-05,\n",
       "           1.1597e-03, -2.4605e-04],\n",
       "         ...,\n",
       "         [ 1.4954e-03,  7.7820e-04,  7.9632e-05,  ...,  3.9482e-04,\n",
       "           7.3624e-04, -2.3746e-04],\n",
       "         [-1.3504e-03, -3.1233e-05,  8.4686e-04,  ..., -6.0654e-04,\n",
       "          -7.7057e-04, -4.3869e-05],\n",
       "         [ 1.3199e-03,  4.3869e-04, -8.0872e-04,  ...,  8.8882e-04,\n",
       "           1.1139e-03, -2.5368e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0757e-03,  3.1090e-04, -5.9509e-04,  ...,  1.0071e-03,\n",
       "          -7.7438e-04, -1.2054e-03],\n",
       "         [ 1.5869e-03,  4.5586e-04,  2.3651e-04,  ...,  1.0834e-03,\n",
       "          -6.3324e-04, -9.7275e-04],\n",
       "         [-1.8845e-03, -2.6107e-05,  2.1648e-04,  ..., -7.8964e-04,\n",
       "           8.7357e-04,  8.2397e-04],\n",
       "         ...,\n",
       "         [ 1.4191e-03,  5.7602e-04, -8.3160e-04,  ...,  1.3046e-03,\n",
       "          -5.7983e-04, -1.3275e-03],\n",
       "         [ 1.1444e-03,  1.0967e-04, -6.9427e-04,  ...,  1.1215e-03,\n",
       "          -7.4387e-05, -6.2180e-04],\n",
       "         [-1.6403e-03, -9.2030e-05,  1.6975e-04,  ..., -1.6174e-03,\n",
       "           1.6880e-04,  1.2283e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.8463e-03, -9.1553e-04,  2.0905e-03,  ..., -1.7242e-03,\n",
       "           7.7057e-04,  1.1520e-03],\n",
       "         [ 6.5231e-04,  5.7220e-04, -2.8038e-04,  ...,  8.5831e-04,\n",
       "           2.4605e-04,  2.7657e-05],\n",
       "         [-3.8147e-04,  9.3079e-04, -1.0681e-03,  ..., -2.2030e-04,\n",
       "          -8.1253e-04, -1.8883e-04],\n",
       "         ...,\n",
       "         [-1.8387e-03, -2.9907e-03,  1.9989e-03,  ..., -1.1826e-03,\n",
       "           2.1515e-03,  2.3499e-03],\n",
       "         [-3.4332e-04, -2.3174e-04, -1.5259e-04,  ..., -6.9809e-04,\n",
       "          -6.2943e-04,  1.6022e-04],\n",
       "         [ 5.5552e-05,  2.1057e-03, -1.5564e-03,  ...,  1.7929e-03,\n",
       "          -2.1973e-03, -1.4420e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.4954e-03,  9.2316e-04, -2.5482e-03,  ..., -3.0060e-03,\n",
       "           4.0283e-03, -3.4180e-03],\n",
       "         [-5.3787e-04,  1.5488e-03, -4.4632e-04,  ..., -3.3112e-03,\n",
       "           5.0354e-03, -6.5994e-04],\n",
       "         [-3.2997e-04, -1.5411e-03,  1.0223e-03,  ...,  3.4943e-03,\n",
       "          -4.5166e-03,  9.8419e-04],\n",
       "         ...,\n",
       "         [ 1.6937e-03, -2.4080e-05, -2.0313e-04,  ..., -2.4872e-03,\n",
       "           3.4180e-03, -2.6245e-03],\n",
       "         [-1.8387e-03, -1.6556e-03,  1.0986e-03,  ...,  4.8523e-03,\n",
       "          -4.4556e-03,  2.7466e-03],\n",
       "         [-6.5231e-04, -1.4114e-03,  1.4114e-03,  ...,  4.6997e-03,\n",
       "          -4.7302e-03,  8.5068e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.0572e-04, -9.6512e-04, -9.7656e-04,  ...,  9.7656e-04,\n",
       "           2.9182e-04, -1.4877e-03],\n",
       "         [-4.8637e-04,  8.9645e-04, -1.3447e-04,  ...,  2.0504e-04,\n",
       "          -3.4142e-04,  1.7357e-04],\n",
       "         [-7.2479e-05,  1.9550e-04, -7.9346e-04,  ..., -1.8120e-04,\n",
       "           6.3705e-04,  1.7929e-04],\n",
       "         ...,\n",
       "         [-8.2397e-04,  1.5488e-03,  1.1520e-03,  ..., -2.1820e-03,\n",
       "          -1.4877e-03,  1.8921e-03],\n",
       "         [-6.9618e-05, -3.0136e-04,  6.1798e-04,  ...,  4.7922e-05,\n",
       "          -4.5395e-04,  4.0054e-04],\n",
       "         [ 6.4468e-04, -1.5488e-03, -1.8997e-03,  ...,  1.3351e-03,\n",
       "           1.2283e-03, -1.4343e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2741e-03,  1.1368e-03,  8.2016e-04,  ...,  1.1802e-05,\n",
       "          -1.0300e-03,  1.6174e-03],\n",
       "         [ 1.0605e-03,  9.7275e-04,  5.8365e-04,  ..., -1.4038e-03,\n",
       "           1.6937e-03, -8.5831e-04],\n",
       "         [-6.7902e-04,  9.3079e-04,  7.8964e-04,  ..., -1.1978e-03,\n",
       "           4.7684e-04,  7.0572e-04],\n",
       "         ...,\n",
       "         [-9.5367e-05, -1.1292e-03, -1.1139e-03,  ...,  1.9226e-03,\n",
       "          -1.0376e-03,  4.9472e-06],\n",
       "         [ 5.0354e-04, -8.2016e-04, -9.0027e-04,  ...,  8.8882e-04,\n",
       "          -1.0605e-03, -4.7493e-04],\n",
       "         [-2.5177e-04,  6.2561e-04,  7.5150e-04,  ..., -1.1292e-03,\n",
       "           1.5488e-03,  1.3542e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-9.8419e-04,  2.7847e-04, -4.3106e-04,  ...,  2.0218e-04,\n",
       "           3.5667e-04, -4.9973e-04],\n",
       "         [-1.4572e-03,  1.0986e-03, -6.1798e-04,  ..., -1.2512e-03,\n",
       "          -8.2397e-04,  3.0823e-03],\n",
       "         [ 4.2725e-04,  2.0027e-04,  1.2589e-04,  ...,  4.8447e-04,\n",
       "          -8.3160e-04,  1.2665e-03],\n",
       "         ...,\n",
       "         [ 7.2479e-04, -8.5068e-04,  4.6349e-04,  ..., -5.5134e-06,\n",
       "           6.2180e-04,  3.9673e-04],\n",
       "         [-4.9770e-06,  1.1978e-03,  2.6584e-05,  ...,  4.1389e-04,\n",
       "           1.9150e-03,  1.4591e-04],\n",
       "         [-5.5313e-04, -1.0395e-04,  5.9128e-04,  ..., -5.5313e-04,\n",
       "          -8.6975e-04,  2.0752e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-5.2643e-04,  8.3160e-04, -1.1978e-03,  ...,  2.8801e-04,\n",
       "           3.0327e-04, -1.9531e-03],\n",
       "         [ 2.0218e-04, -6.9809e-04,  9.9182e-04,  ...,  3.7575e-04,\n",
       "          -4.0054e-04,  1.8234e-03],\n",
       "         [ 4.5061e-05,  8.8882e-04, -1.6327e-03,  ...,  2.5368e-04,\n",
       "           5.0354e-04, -1.5793e-03],\n",
       "         ...,\n",
       "         [ 1.5736e-04,  9.2697e-04, -2.3556e-04,  ...,  7.0572e-04,\n",
       "           5.5695e-04, -2.0599e-03],\n",
       "         [-7.4768e-04, -2.6703e-04,  9.9945e-04,  ..., -1.4343e-03,\n",
       "          -6.5231e-04, -2.3460e-04],\n",
       "         [-4.4823e-04, -2.1458e-04, -1.0223e-03,  ...,  3.9101e-04,\n",
       "          -6.7711e-05,  9.3460e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0376e-03,  1.2207e-03, -1.0376e-03,  ..., -8.7738e-04,\n",
       "           1.2589e-03, -6.2180e-04],\n",
       "         [ 1.0347e-04, -3.0708e-04,  5.2261e-04,  ...,  2.5034e-05,\n",
       "          -3.0327e-04,  5.2643e-04],\n",
       "         [ 7.5912e-04,  9.4604e-04, -5.5313e-04,  ...,  1.0872e-04,\n",
       "           3.9101e-04,  1.8501e-04],\n",
       "         ...,\n",
       "         [ 2.2278e-03, -1.7471e-03,  1.4877e-03,  ...,  1.2589e-03,\n",
       "          -3.0518e-04,  1.0452e-03],\n",
       "         [ 5.1880e-04,  1.0376e-03,  2.0695e-04,  ...,  1.2512e-03,\n",
       "           2.2030e-04,  7.3242e-04],\n",
       "         [-1.5259e-04,  9.3842e-04,  5.3406e-04,  ...,  3.4142e-04,\n",
       "          -3.0327e-04,  7.8583e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.5411e-03,  3.2349e-03, -2.1172e-04,  ..., -7.6675e-04,\n",
       "           3.6469e-03, -2.1362e-03],\n",
       "         [-7.4768e-04, -1.6403e-03,  1.7242e-03,  ...,  8.4686e-04,\n",
       "          -2.8839e-03,  1.3123e-03],\n",
       "         [ 7.5150e-04,  3.9673e-03, -3.3760e-04,  ..., -3.9101e-04,\n",
       "           3.7537e-03, -1.1444e-03],\n",
       "         ...,\n",
       "         [ 7.1716e-04,  3.3569e-03, -3.1471e-04,  ..., -5.3787e-04,\n",
       "           3.9978e-03, -1.5945e-03],\n",
       "         [-7.1335e-04, -3.3722e-03,  4.4441e-04,  ...,  3.7193e-04,\n",
       "          -3.7689e-03,  4.5395e-04],\n",
       "         [ 3.0518e-04,  4.4250e-03, -2.4319e-04,  ..., -6.7234e-05,\n",
       "           3.4485e-03, -4.2915e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.8964e-04, -8.9645e-04, -3.5095e-04,  ..., -2.4319e-04,\n",
       "           1.2207e-03,  8.7738e-04],\n",
       "         [-4.5776e-05, -6.4468e-04, -2.8992e-04,  ..., -4.0054e-04,\n",
       "           6.3705e-04, -1.8120e-04],\n",
       "         [-4.7874e-04, -3.9101e-04,  4.1771e-04,  ..., -2.1076e-04,\n",
       "           1.0757e-03,  9.6512e-04],\n",
       "         ...,\n",
       "         [-3.2425e-04, -3.5095e-04, -5.7602e-04,  ..., -1.6308e-04,\n",
       "           7.8583e-04,  7.7438e-04],\n",
       "         [ 5.9128e-04,  1.5106e-03,  7.9346e-04,  ...,  1.7319e-03,\n",
       "          -1.5259e-03, -7.5912e-04],\n",
       "         [ 2.2292e-05, -9.4223e-04, -1.1749e-03,  ..., -8.6594e-04,\n",
       "           1.1139e-03,  6.7520e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.3869e-04, -4.6539e-04, -3.6240e-04,  ..., -8.2970e-05,\n",
       "          -1.5793e-03, -6.5613e-04],\n",
       "         [ 3.2997e-04, -1.4572e-03, -2.6703e-04,  ...,  1.8311e-04,\n",
       "          -2.1515e-03, -4.4060e-04],\n",
       "         [-7.7820e-04, -1.5945e-03, -2.3365e-04,  ...,  8.5068e-04,\n",
       "          -2.1667e-03,  4.4250e-04],\n",
       "         ...,\n",
       "         [ 4.9210e-04, -4.1008e-05, -2.3746e-04,  ...,  6.9141e-05,\n",
       "          -1.6708e-03, -8.3542e-04],\n",
       "         [-7.3624e-04,  5.4932e-04,  3.8910e-04,  ...,  2.2411e-05,\n",
       "           1.5488e-03,  8.0872e-04],\n",
       "         [ 6.6757e-05,  1.2665e-03,  2.2602e-04,  ..., -2.8038e-04,\n",
       "           1.8539e-03, -7.6771e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-8.7738e-05,  5.3787e-04,  3.9864e-04,  ...,  3.9101e-04,\n",
       "           1.0443e-04, -1.0633e-04],\n",
       "         [-4.9591e-04,  6.0654e-04, -3.8338e-04,  ..., -7.8201e-04,\n",
       "           9.1171e-04, -1.6308e-04],\n",
       "         [ 9.3842e-04, -4.5204e-04,  4.4060e-04,  ...,  8.0109e-04,\n",
       "          -8.5831e-04, -6.5994e-04],\n",
       "         ...,\n",
       "         [ 1.2131e-03, -1.4400e-04,  1.0986e-03,  ...,  1.2131e-03,\n",
       "           2.5558e-04, -1.3924e-04],\n",
       "         [-6.3324e-04, -2.6822e-05, -3.8147e-04,  ..., -3.5858e-04,\n",
       "           1.9073e-05,  4.7112e-04],\n",
       "         [ 9.5367e-04,  2.1362e-04,  5.3024e-04,  ...,  5.3406e-04,\n",
       "          -9.1171e-04, -8.0109e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.1515e-03, -5.6458e-04, -5.1880e-04,  ...,  2.0218e-04,\n",
       "           6.7139e-04,  1.0071e-03],\n",
       "         [-1.4801e-03,  5.8365e-04, -2.9206e-05,  ..., -8.2016e-05,\n",
       "          -6.5613e-04, -2.0447e-03],\n",
       "         [-1.4648e-03, -5.1117e-04,  7.5817e-05,  ...,  3.2234e-04,\n",
       "           7.7820e-04,  1.1139e-03],\n",
       "         ...,\n",
       "         [-9.7656e-04, -5.9128e-04, -8.1062e-05,  ...,  2.6321e-04,\n",
       "           7.5150e-04,  2.3804e-03],\n",
       "         [ 1.0300e-03,  5.5695e-04, -3.3188e-04,  ..., -1.1027e-05,\n",
       "          -6.4850e-04, -2.5177e-03],\n",
       "         [ 3.7766e-04,  6.0272e-04,  2.0623e-05,  ..., -2.9564e-05,\n",
       "          -6.7520e-04, -1.4038e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.4850e-05, -4.2152e-04,  5.5313e-04,  ..., -2.1172e-04,\n",
       "           2.3556e-04, -3.6812e-04],\n",
       "         [ 2.5635e-03, -2.8229e-03, -3.0670e-03,  ..., -1.5335e-03,\n",
       "           3.0365e-03,  3.0670e-03],\n",
       "         [ 3.2806e-03, -3.2501e-03, -3.6926e-03,  ..., -2.3346e-03,\n",
       "           2.4719e-03,  3.5706e-03],\n",
       "         ...,\n",
       "         [ 6.3419e-05,  4.8447e-04,  3.5095e-04,  ..., -6.2561e-04,\n",
       "          -2.0294e-03, -3.7575e-04],\n",
       "         [-8.2779e-04,  6.5613e-04,  5.6839e-04,  ...,  2.5177e-04,\n",
       "          -2.2583e-03, -1.4648e-03],\n",
       "         [ 9.1553e-04, -8.0872e-04, -1.2283e-03,  ..., -1.3657e-03,\n",
       "           1.9531e-03,  5.0354e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.2956e-05,  2.4414e-03,  4.4823e-04,  ..., -6.5613e-04,\n",
       "           3.3569e-03, -8.3542e-04],\n",
       "         [-2.2888e-03, -2.8687e-03, -4.9210e-04,  ...,  1.0681e-03,\n",
       "          -2.8534e-03,  3.0518e-03],\n",
       "         [-1.3542e-04, -2.1973e-03, -2.0504e-04,  ...,  4.8065e-04,\n",
       "          -3.0212e-03,  1.1292e-03],\n",
       "         ...,\n",
       "         [-8.5831e-04, -2.0599e-03,  7.6294e-04,  ...,  1.9302e-03,\n",
       "          -3.8757e-03,  2.1820e-03],\n",
       "         [-3.9291e-04,  4.1962e-04,  5.0354e-04,  ...,  4.0054e-04,\n",
       "           7.4768e-04, -1.8883e-04],\n",
       "         [-1.0395e-04,  2.8534e-03, -9.0599e-05,  ..., -6.1035e-04,\n",
       "           3.1586e-03, -7.4768e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.6430e-04,  5.1498e-04,  1.4877e-04,  ..., -2.7275e-04,\n",
       "          -3.7003e-04, -1.0061e-04],\n",
       "         [ 1.1063e-04, -3.2043e-04, -1.3256e-04,  ..., -5.1117e-04,\n",
       "          -1.0347e-04,  8.2016e-04],\n",
       "         [-9.9182e-04,  2.0599e-03,  1.3733e-03,  ...,  1.2283e-03,\n",
       "          -1.2512e-03, -9.7275e-04],\n",
       "         ...,\n",
       "         [-1.5869e-03,  1.5335e-03,  1.4267e-03,  ...,  1.0834e-03,\n",
       "          -1.2894e-03, -1.6174e-03],\n",
       "         [ 1.4038e-03, -9.3842e-04, -8.0109e-04,  ..., -1.3809e-03,\n",
       "           9.3842e-04,  1.1826e-03],\n",
       "         [ 3.3951e-04, -3.5524e-05,  6.0272e-04,  ..., -3.5286e-04,\n",
       "           6.7711e-05, -4.1008e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.1090e-04, -1.0605e-03, -7.0190e-04,  ..., -4.8447e-04,\n",
       "          -8.0490e-04, -1.8501e-04],\n",
       "         [-1.4305e-04,  1.7395e-03,  7.0953e-04,  ...,  3.7956e-04,\n",
       "           1.0147e-03, -1.5736e-04],\n",
       "         [-2.8253e-05,  1.2436e-03,  9.0027e-04,  ...,  1.1444e-04,\n",
       "           5.9128e-04, -1.5640e-04],\n",
       "         ...,\n",
       "         [ 5.3406e-05,  1.3199e-03,  8.6594e-04,  ...,  1.1683e-04,\n",
       "           8.6594e-04, -4.1389e-04],\n",
       "         [ 2.8038e-04, -1.4038e-03, -8.3160e-04,  ..., -2.8610e-04,\n",
       "          -6.9046e-04,  4.6492e-05],\n",
       "         [ 1.2112e-04, -1.7090e-03, -7.7438e-04,  ..., -1.5736e-04,\n",
       "          -4.6158e-04, -1.3733e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.7738e-04, -1.0300e-03,  5.7220e-04,  ..., -7.4208e-06,\n",
       "          -2.8372e-05,  3.6812e-04],\n",
       "         [ 1.3733e-04,  8.1635e-04, -1.4954e-03,  ...,  1.4267e-03,\n",
       "           1.2875e-04,  9.1553e-05],\n",
       "         [ 8.8882e-04,  6.3324e-04, -1.0452e-03,  ...,  5.0735e-04,\n",
       "           6.1798e-04,  6.4087e-04],\n",
       "         ...,\n",
       "         [-9.6893e-04, -9.7275e-04,  7.0572e-04,  ..., -1.0986e-03,\n",
       "          -7.8678e-05, -2.6321e-04],\n",
       "         [-1.3504e-03, -8.7357e-04,  1.9646e-04,  ..., -1.2894e-03,\n",
       "          -6.8665e-04, -1.8082e-03],\n",
       "         [ 4.1008e-04,  1.0452e-03, -2.1362e-03,  ...,  6.9046e-04,\n",
       "           6.5613e-04,  1.1597e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0009,  0.0007,  0.0014,  ...,  0.0006,  0.0017,  0.0005],\n",
       "         [ 0.0014,  0.0008,  0.0005,  ...,  0.0004,  0.0012, -0.0002],\n",
       "         [-0.0006, -0.0012,  0.0012,  ..., -0.0009,  0.0010,  0.0004],\n",
       "         ...,\n",
       "         [ 0.0024,  0.0025, -0.0020,  ..., -0.0002, -0.0017, -0.0005],\n",
       "         [ 0.0008,  0.0007,  0.0008,  ..., -0.0009,  0.0016, -0.0001],\n",
       "         [ 0.0002,  0.0005,  0.0026,  ..., -0.0002,  0.0017,  0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.8311e-03,  1.4191e-03,  1.4191e-03,  ...,  9.0790e-04,\n",
       "          -1.4114e-03,  1.0986e-03],\n",
       "         [-1.4191e-03,  1.1597e-03,  1.0147e-03,  ...,  1.2589e-03,\n",
       "          -2.3041e-03,  1.9379e-03],\n",
       "         [-1.9169e-04,  5.4359e-05, -3.0518e-04,  ...,  2.8419e-04,\n",
       "           1.4305e-04,  4.1771e-04],\n",
       "         ...,\n",
       "         [-5.6458e-04, -2.6894e-04,  5.2643e-04,  ..., -7.9346e-04,\n",
       "          -9.9659e-05, -1.5163e-04],\n",
       "         [ 3.5248e-03, -3.2501e-03, -2.8229e-03,  ..., -3.8147e-03,\n",
       "           3.4790e-03, -3.4790e-03],\n",
       "         [ 2.6550e-03, -2.2888e-03, -3.2654e-03,  ..., -2.1057e-03,\n",
       "           2.5024e-03, -2.4261e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0009, -0.0014, -0.0005,  ...,  0.0033, -0.0024,  0.0031],\n",
       "         [-0.0010,  0.0028,  0.0001,  ..., -0.0029,  0.0036, -0.0030],\n",
       "         [-0.0011,  0.0015,  0.0006,  ..., -0.0020,  0.0025, -0.0023],\n",
       "         ...,\n",
       "         [-0.0009,  0.0026,  0.0007,  ..., -0.0042,  0.0030, -0.0030],\n",
       "         [ 0.0014, -0.0013, -0.0008,  ...,  0.0013, -0.0025,  0.0026],\n",
       "         [-0.0007,  0.0024,  0.0005,  ..., -0.0036,  0.0027, -0.0024]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.6327e-03,  2.4567e-03,  1.8768e-03,  ..., -2.3041e-03,\n",
       "           1.6251e-03,  3.0212e-03],\n",
       "         [-8.0872e-04,  2.8419e-04,  2.6894e-04,  ...,  6.9141e-06,\n",
       "           1.0910e-03,  8.0872e-04],\n",
       "         [ 2.8038e-04,  1.8311e-03,  3.5667e-04,  ..., -8.2779e-04,\n",
       "           3.3951e-04,  2.9945e-04],\n",
       "         ...,\n",
       "         [-1.0910e-03,  3.5667e-04,  1.8539e-03,  ..., -1.1444e-03,\n",
       "           1.5717e-03,  1.7624e-03],\n",
       "         [ 1.4210e-04,  9.5749e-04,  3.7384e-04,  ..., -4.6730e-04,\n",
       "           2.7084e-04,  2.9182e-04],\n",
       "         [-1.7853e-03,  1.5564e-03,  1.5182e-03,  ..., -2.0599e-03,\n",
       "           1.8463e-03,  1.7471e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.0190e-04,  6.6376e-04,  5.3024e-04,  ..., -2.1219e-05,\n",
       "           4.9591e-04, -1.1978e-03],\n",
       "         [ 2.1973e-03, -8.9264e-04, -1.0910e-03,  ...,  1.0633e-04,\n",
       "          -1.5793e-03,  1.4343e-03],\n",
       "         [ 6.1798e-04, -6.2180e-04, -6.8283e-04,  ...,  1.1597e-03,\n",
       "          -5.5790e-05,  8.3923e-04],\n",
       "         ...,\n",
       "         [-9.8419e-04,  1.2054e-03,  6.3705e-04,  ..., -1.4191e-03,\n",
       "           5.3787e-04, -8.3542e-04],\n",
       "         [ 3.4523e-04, -8.9169e-05, -3.5286e-04,  ...,  1.0071e-03,\n",
       "          -2.7061e-05,  9.3460e-05],\n",
       "         [ 1.3924e-04, -2.4109e-03, -1.0681e-03,  ...,  1.3428e-03,\n",
       "          -1.4191e-03,  1.4038e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.9210e-04,  7.7057e-04,  5.4169e-04,  ..., -6.1417e-04,\n",
       "          -9.0408e-04, -3.4142e-04],\n",
       "         [ 8.8120e-04, -1.5106e-03, -4.9973e-04,  ..., -1.0633e-04,\n",
       "          -7.6675e-04, -1.5640e-04],\n",
       "         [-4.0770e-05,  9.6893e-04,  4.0531e-05,  ...,  4.9591e-04,\n",
       "          -2.5749e-04, -5.1117e-04],\n",
       "         ...,\n",
       "         [ 9.0790e-04, -6.4468e-04, -4.1199e-04,  ..., -5.6076e-04,\n",
       "          -6.6376e-04, -4.4060e-04],\n",
       "         [ 1.0147e-03, -2.8419e-04, -1.4496e-03,  ...,  2.4605e-04,\n",
       "          -6.7902e-04,  2.4080e-05],\n",
       "         [ 3.0994e-05,  9.1934e-04,  1.4496e-03,  ...,  2.7657e-04,\n",
       "           6.7902e-04,  6.9046e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2283e-03,  2.8992e-04, -5.4550e-04,  ..., -1.9169e-04,\n",
       "          -4.4632e-04, -6.2561e-04],\n",
       "         [-5.0545e-05, -1.6499e-04,  3.8528e-04,  ...,  5.3024e-04,\n",
       "           4.0627e-04,  1.6022e-03],\n",
       "         [ 5.3024e-04, -1.7929e-04, -1.1110e-04,  ...,  1.5926e-04,\n",
       "           3.3760e-04,  1.1368e-03],\n",
       "         ...,\n",
       "         [ 4.8637e-04, -7.5912e-04,  1.2779e-04,  ...,  6.1417e-04,\n",
       "           4.9210e-04,  1.3962e-03],\n",
       "         [ 4.4250e-04, -5.3406e-04,  9.6321e-05,  ...,  6.1798e-04,\n",
       "          -2.1100e-05,  1.3504e-03],\n",
       "         [ 1.7071e-04,  4.6349e-04,  1.8787e-04,  ..., -7.9346e-04,\n",
       "          -8.8120e-04, -8.5449e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.0572e-04, -1.3275e-03,  5.9128e-04,  ...,  1.2665e-03,\n",
       "           8.4686e-04, -7.5340e-05],\n",
       "         [ 7.6675e-04, -3.2654e-03, -3.2425e-05,  ...,  1.8158e-03,\n",
       "           8.0109e-04, -4.0627e-04],\n",
       "         [ 3.0670e-03,  4.7493e-04,  3.1433e-03,  ...,  2.6703e-03,\n",
       "           3.3112e-03, -2.9297e-03],\n",
       "         ...,\n",
       "         [ 4.0054e-04,  1.8463e-03,  9.9182e-04,  ...,  2.5177e-04,\n",
       "           6.4850e-04, -1.0376e-03],\n",
       "         [-1.9989e-03, -9.2983e-05, -2.3041e-03,  ..., -1.5869e-03,\n",
       "          -2.1362e-03,  1.8616e-03],\n",
       "         [ 1.1368e-03,  2.3956e-03,  5.1498e-04,  ...,  1.0605e-03,\n",
       "           1.6556e-03, -4.7493e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0013, -0.0017, -0.0011,  ..., -0.0013, -0.0028, -0.0009],\n",
       "         [-0.0014,  0.0007, -0.0015,  ..., -0.0028, -0.0030, -0.0003],\n",
       "         [ 0.0013, -0.0030, -0.0012,  ..., -0.0013, -0.0024,  0.0007],\n",
       "         ...,\n",
       "         [ 0.0008, -0.0028, -0.0005,  ..., -0.0013, -0.0025,  0.0001],\n",
       "         [ 0.0023, -0.0032, -0.0011,  ..., -0.0017, -0.0019, -0.0003],\n",
       "         [-0.0020,  0.0030,  0.0016,  ...,  0.0010,  0.0033,  0.0002]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.9684e-03,  1.9302e-03,  1.6708e-03,  ...,  2.3499e-03,\n",
       "          -2.4261e-03, -2.6855e-03],\n",
       "         [-2.6855e-03, -3.0975e-03, -3.5095e-04,  ..., -1.7776e-03,\n",
       "           2.0905e-03,  3.6774e-03],\n",
       "         [ 7.5912e-04,  1.0681e-03,  1.5106e-03,  ...,  1.8311e-04,\n",
       "          -1.0147e-03, -6.7139e-04],\n",
       "         ...,\n",
       "         [ 6.6376e-04,  5.2643e-04, -2.4605e-04,  ...,  6.8665e-04,\n",
       "          -9.2697e-04,  7.8201e-04],\n",
       "         [ 1.0681e-03,  1.9550e-04, -1.1444e-04,  ...,  8.5831e-04,\n",
       "          -2.8610e-04, -1.0834e-03],\n",
       "         [-6.5804e-05, -3.4332e-04,  4.9973e-04,  ..., -3.9291e-04,\n",
       "           3.6430e-04, -9.6798e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 9.4223e-04,  1.8005e-03,  4.6539e-04,  ...,  5.2643e-04,\n",
       "           5.6076e-04, -4.4060e-04],\n",
       "         [-8.4877e-05,  1.1826e-03,  7.0953e-04,  ..., -1.0347e-04,\n",
       "           2.9755e-04, -6.3324e-04],\n",
       "         [-1.0605e-03,  1.0147e-03,  8.5831e-05,  ..., -9.2697e-04,\n",
       "           1.8234e-03, -6.4850e-04],\n",
       "         ...,\n",
       "         [ 5.3406e-05,  2.2736e-03,  8.0109e-04,  ..., -4.6921e-04,\n",
       "          -3.4714e-04, -8.3160e-04],\n",
       "         [-4.6158e-04, -1.3657e-03, -4.8828e-04,  ...,  4.9591e-05,\n",
       "          -4.3488e-04,  8.3542e-04],\n",
       "         [-5.5313e-04, -2.3804e-03, -4.3297e-04,  ...,  6.7651e-06,\n",
       "          -1.2512e-03,  8.1253e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.6022e-03,  1.0834e-03,  7.6675e-04,  ..., -1.3199e-03,\n",
       "          -1.4648e-03, -8.7738e-04],\n",
       "         [-1.5640e-03,  7.9727e-04, -3.4094e-05,  ..., -9.9182e-04,\n",
       "          -7.8583e-04, -1.9684e-03],\n",
       "         [ 9.5367e-04, -9.7752e-05,  9.7275e-05,  ...,  3.5286e-04,\n",
       "           2.0695e-04,  7.9346e-04],\n",
       "         ...,\n",
       "         [-1.0376e-03, -1.9169e-04,  1.5354e-04,  ..., -1.0300e-03,\n",
       "          -1.0681e-03, -9.8419e-04],\n",
       "         [ 6.4373e-05, -7.3433e-05,  1.0910e-03,  ..., -8.1253e-04,\n",
       "          -6.8665e-04, -1.4725e-03],\n",
       "         [ 1.0910e-03, -1.8921e-03,  1.7643e-04,  ...,  8.2779e-04,\n",
       "          -1.8501e-04,  1.0910e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0006,  0.0005, -0.0007,  ...,  0.0004,  0.0024,  0.0010],\n",
       "         [-0.0015,  0.0002,  0.0002,  ..., -0.0001, -0.0023, -0.0003],\n",
       "         [-0.0010, -0.0006,  0.0008,  ..., -0.0006, -0.0018, -0.0011],\n",
       "         ...,\n",
       "         [ 0.0017,  0.0002, -0.0005,  ...,  0.0003,  0.0022,  0.0009],\n",
       "         [ 0.0002,  0.0008, -0.0006,  ...,  0.0004,  0.0013,  0.0014],\n",
       "         [-0.0001, -0.0006, -0.0004,  ..., -0.0007,  0.0018,  0.0013]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2360e-03, -8.5831e-04,  4.3488e-04,  ...,  1.2894e-03,\n",
       "          -4.6349e-04,  5.8746e-04],\n",
       "         [ 1.9741e-04, -1.3924e-04, -1.6117e-04,  ...,  2.0599e-04,\n",
       "          -1.4210e-04, -1.0452e-03],\n",
       "         [-4.3297e-04, -7.5912e-04,  1.9360e-04,  ...,  9.3079e-04,\n",
       "          -1.0529e-03,  1.3580e-03],\n",
       "         ...,\n",
       "         [ 1.6022e-03,  1.4572e-03, -1.5640e-03,  ..., -2.1667e-03,\n",
       "           1.3580e-03, -1.5335e-03],\n",
       "         [ 4.1485e-05, -2.9182e-04,  2.5177e-04,  ...,  6.8665e-04,\n",
       "          -4.8256e-04,  8.2016e-04],\n",
       "         [ 1.0376e-03,  2.7275e-04, -1.0147e-03,  ..., -5.2643e-04,\n",
       "           9.5749e-04, -1.2436e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.1839e-04,  3.3722e-03, -1.2589e-03,  ...,  6.0654e-04,\n",
       "           2.3346e-03,  5.6839e-04],\n",
       "         [-1.1749e-03,  1.3657e-03, -1.7929e-04,  ...,  5.1498e-04,\n",
       "           2.0599e-03,  1.7548e-03],\n",
       "         [ 1.4572e-03, -1.5106e-03,  3.2234e-04,  ..., -7.3624e-04,\n",
       "          -1.9989e-03, -1.2131e-03],\n",
       "         ...,\n",
       "         [ 4.3678e-04, -2.0599e-03,  6.5231e-04,  ..., -3.2234e-04,\n",
       "          -1.8311e-03, -8.9264e-04],\n",
       "         [-1.3447e-04,  1.7853e-03, -8.4305e-04,  ...,  2.2602e-04,\n",
       "           1.8921e-03,  9.7656e-04],\n",
       "         [ 8.0490e-04, -3.2043e-03,  1.0452e-03,  ...,  7.4387e-05,\n",
       "          -2.7618e-03, -8.9264e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.5013e-04,  3.9482e-04, -2.2602e-04,  ..., -1.8215e-04,\n",
       "           7.3242e-04, -5.2261e-04],\n",
       "         [-3.7575e-04,  8.2397e-04,  1.6093e-05,  ...,  4.4060e-04,\n",
       "          -3.7384e-04, -2.8801e-04],\n",
       "         [ 1.4877e-04,  2.8610e-05,  1.4484e-05,  ...,  1.6212e-05,\n",
       "           5.1117e-04, -5.7220e-04],\n",
       "         ...,\n",
       "         [-4.6730e-04, -5.1498e-04,  2.5928e-06,  ...,  1.1146e-05,\n",
       "          -7.9632e-05,  8.0109e-05],\n",
       "         [-3.5477e-04,  7.6294e-05, -4.3106e-04,  ..., -8.8882e-04,\n",
       "          -2.0599e-04,  1.1597e-03],\n",
       "         [ 1.0872e-04, -9.8348e-06,  4.0436e-04,  ..., -3.5286e-04,\n",
       "          -2.0862e-05,  3.7384e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0022,  0.0002,  0.0012,  ..., -0.0001,  0.0013,  0.0009],\n",
       "         [ 0.0021,  0.0001,  0.0009,  ..., -0.0004,  0.0009,  0.0011],\n",
       "         [-0.0007, -0.0002, -0.0012,  ...,  0.0004, -0.0010, -0.0020],\n",
       "         ...,\n",
       "         [ 0.0016,  0.0004,  0.0007,  ..., -0.0006,  0.0011,  0.0005],\n",
       "         [ 0.0020,  0.0006,  0.0008,  ..., -0.0010,  0.0014,  0.0007],\n",
       "         [-0.0016, -0.0011, -0.0009,  ...,  0.0007, -0.0015, -0.0010]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.7319e-03, -1.6327e-03, -1.3504e-03,  ...,  1.3504e-03,\n",
       "          -1.6937e-03, -1.1063e-03],\n",
       "         [-1.9360e-04,  5.1880e-04, -1.5163e-04,  ...,  8.4305e-04,\n",
       "          -2.4128e-04,  9.2030e-05],\n",
       "         [-4.5776e-04,  5.6267e-05,  5.7220e-04,  ..., -1.0834e-03,\n",
       "           2.3956e-03,  4.0817e-04],\n",
       "         ...,\n",
       "         [ 9.4223e-04, -2.0027e-04,  5.4550e-04,  ..., -1.8597e-04,\n",
       "           7.0953e-04,  3.8910e-04],\n",
       "         [ 5.6839e-04,  2.1515e-03,  4.6349e-04,  ..., -5.1117e-04,\n",
       "           4.3869e-04,  2.6703e-04],\n",
       "         [ 2.9564e-04,  1.5106e-03,  6.4373e-05,  ..., -6.2180e-04,\n",
       "          -4.5776e-04,  1.6594e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.7466e-03,  5.2643e-04, -5.6458e-04,  ..., -6.7902e-04,\n",
       "          -2.1839e-04,  6.1417e-04],\n",
       "         [ 7.3624e-04, -7.1335e-04,  4.9210e-04,  ...,  1.3657e-03,\n",
       "           9.1934e-04, -5.0735e-04],\n",
       "         [-1.2360e-03,  4.7684e-04, -3.9864e-04,  ...,  5.9128e-04,\n",
       "           3.1471e-04,  5.5695e-04],\n",
       "         ...,\n",
       "         [ 1.0300e-03, -3.3760e-04,  5.4550e-04,  ...,  1.3161e-04,\n",
       "          -6.2180e-04, -5.3787e-04],\n",
       "         [ 1.0910e-03, -2.3842e-04, -1.8024e-04,  ..., -2.3937e-04,\n",
       "           1.5564e-03, -6.8665e-04],\n",
       "         [-1.4782e-04,  3.8719e-04, -5.7602e-04,  ...,  4.0293e-05,\n",
       "          -1.2040e-05,  5.3787e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.9836e-03,  5.3406e-04,  1.8616e-03,  ...,  1.4267e-03,\n",
       "           2.1210e-03, -1.6174e-03],\n",
       "         [-7.9346e-04,  1.5259e-03, -1.0834e-03,  ..., -1.2207e-03,\n",
       "          -7.3242e-04,  3.8719e-04],\n",
       "         [ 3.0136e-04, -3.7575e-04,  1.7452e-04,  ...,  8.1635e-04,\n",
       "           9.1171e-04, -1.6117e-04],\n",
       "         ...,\n",
       "         [-3.2187e-05,  3.1853e-04, -7.5531e-04,  ...,  1.0729e-04,\n",
       "          -2.1362e-04,  1.8883e-04],\n",
       "         [ 1.5354e-04,  8.3160e-04, -4.0436e-04,  ...,  2.2984e-04,\n",
       "           4.3488e-04, -9.1934e-04],\n",
       "         [ 8.4686e-04, -7.7820e-04,  7.5531e-04,  ...,  9.8419e-04,\n",
       "           1.1978e-03, -1.1139e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0024,  0.0003, -0.0028,  ...,  0.0019, -0.0005,  0.0031],\n",
       "         [ 0.0021,  0.0013,  0.0033,  ..., -0.0011,  0.0013, -0.0027],\n",
       "         [-0.0033, -0.0015, -0.0032,  ...,  0.0027, -0.0017,  0.0030],\n",
       "         ...,\n",
       "         [-0.0029,  0.0002, -0.0031,  ...,  0.0017, -0.0011,  0.0034],\n",
       "         [-0.0027,  0.0003, -0.0035,  ...,  0.0030, -0.0013,  0.0035],\n",
       "         [ 0.0032, -0.0004,  0.0030,  ..., -0.0014,  0.0005, -0.0030]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.0599e-03, -2.1667e-03, -2.4109e-03,  ..., -1.8539e-03,\n",
       "          -9.1934e-04,  1.3292e-05],\n",
       "         [ 1.3428e-03,  4.2915e-04,  9.9945e-04,  ...,  4.7302e-04,\n",
       "           7.0572e-04,  1.0681e-03],\n",
       "         [-1.2741e-03, -1.1215e-03, -1.1978e-03,  ..., -1.7776e-03,\n",
       "          -1.4420e-03, -7.2098e-04],\n",
       "         ...,\n",
       "         [ 9.5749e-04,  8.8882e-04,  6.5994e-04,  ...,  6.2180e-04,\n",
       "           4.4823e-04,  5.0735e-04],\n",
       "         [ 1.9550e-04,  2.8801e-04, -1.0610e-05,  ..., -2.0981e-05,\n",
       "           3.2187e-05,  2.3499e-03],\n",
       "         [ 7.8201e-04,  6.7902e-04,  5.3787e-04,  ...,  1.3046e-03,\n",
       "           1.1826e-03,  1.3962e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.5106e-03,  1.2016e-04, -1.5259e-03,  ...,  2.7771e-03,\n",
       "          -3.9339e-05,  5.8365e-04],\n",
       "         [-1.6937e-03,  1.0848e-05, -1.8158e-03,  ...,  2.8992e-03,\n",
       "          -7.1335e-04,  7.0190e-04],\n",
       "         [-1.3351e-03,  5.7602e-04, -1.4877e-03,  ...,  2.4414e-03,\n",
       "           1.2207e-04,  3.9482e-04],\n",
       "         ...,\n",
       "         [-1.7166e-03,  9.1195e-06, -1.5793e-03,  ...,  1.4725e-03,\n",
       "          -9.1553e-04,  1.2589e-03],\n",
       "         [-1.9989e-03,  2.6321e-04, -1.9150e-03,  ...,  1.4038e-03,\n",
       "           3.0136e-04,  1.0300e-03],\n",
       "         [ 4.5776e-04, -6.6376e-04, -7.1335e-04,  ...,  2.2583e-03,\n",
       "           1.2970e-03, -9.2316e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.4305e-04, -1.3733e-03,  1.2817e-03,  ..., -1.3580e-03,\n",
       "          -1.0605e-03, -4.4823e-04],\n",
       "         [ 3.2616e-04, -3.3951e-04,  5.7602e-04,  ..., -5.4550e-04,\n",
       "          -6.1798e-04, -3.7956e-04],\n",
       "         [ 1.5182e-03,  6.6757e-04, -7.1716e-04,  ...,  7.3624e-04,\n",
       "           7.9727e-04,  5.9891e-04],\n",
       "         ...,\n",
       "         [ 9.0027e-04,  9.1171e-04, -4.0245e-04,  ...,  5.4932e-04,\n",
       "           6.2561e-04,  3.4523e-04],\n",
       "         [-6.6757e-04,  5.6458e-04,  7.9346e-04,  ...,  4.1771e-04,\n",
       "           4.5061e-05,  1.8787e-04],\n",
       "         [-6.9809e-04,  1.3275e-03, -1.2016e-04,  ...,  2.2125e-04,\n",
       "           4.8256e-04,  3.2997e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.3188e-04, -1.0490e-05, -4.4632e-04,  ...,  2.9755e-03,\n",
       "           5.3406e-04,  1.3657e-03],\n",
       "         [ 5.4169e-04, -5.3024e-04, -8.0490e-04,  ...,  1.2970e-03,\n",
       "           8.1635e-04, -1.6708e-03],\n",
       "         [-9.9182e-04, -1.0757e-03,  7.8583e-04,  ..., -1.9455e-03,\n",
       "          -8.3542e-04,  1.0223e-03],\n",
       "         ...,\n",
       "         [ 4.6539e-04,  1.6880e-04, -1.4725e-03,  ...,  1.4191e-03,\n",
       "           8.7357e-04, -1.7929e-03],\n",
       "         [ 1.0223e-03,  2.6512e-04,  4.5204e-04,  ...,  1.5450e-04,\n",
       "           9.9945e-04, -3.9291e-04],\n",
       "         [ 9.4986e-04,  6.8283e-04, -2.2507e-04,  ...,  1.2589e-03,\n",
       "           9.5367e-04, -2.1362e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0014,  0.0007, -0.0021,  ..., -0.0009, -0.0005, -0.0022],\n",
       "         [ 0.0023, -0.0021,  0.0022,  ...,  0.0019,  0.0018,  0.0006],\n",
       "         [ 0.0015, -0.0024,  0.0014,  ...,  0.0015,  0.0015,  0.0010],\n",
       "         ...,\n",
       "         [-0.0005,  0.0005, -0.0008,  ..., -0.0012, -0.0006, -0.0018],\n",
       "         [-0.0008,  0.0011, -0.0008,  ..., -0.0015, -0.0015, -0.0008],\n",
       "         [ 0.0009, -0.0008,  0.0015,  ...,  0.0013,  0.0016,  0.0020]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.1035e-04, -5.0735e-04, -7.2861e-04,  ..., -1.4801e-03,\n",
       "          -2.1210e-03,  9.9945e-04],\n",
       "         [-2.7180e-05,  9.6130e-04,  5.0735e-04,  ...,  1.4725e-03,\n",
       "           2.8992e-03, -1.2512e-03],\n",
       "         [ 2.3460e-04, -1.1368e-03, -6.1417e-04,  ..., -1.6861e-03,\n",
       "          -2.6398e-03,  1.1749e-03],\n",
       "         ...,\n",
       "         [-4.3297e-04, -4.8256e-04, -6.1798e-04,  ..., -1.8768e-03,\n",
       "          -1.8158e-03,  2.3193e-03],\n",
       "         [-3.6812e-04, -1.5163e-04, -6.2180e-04,  ..., -1.4954e-03,\n",
       "          -1.6785e-03,  4.9973e-04],\n",
       "         [-7.6675e-04, -2.7924e-03, -5.4836e-05,  ..., -2.2430e-03,\n",
       "          -3.0060e-03,  3.4790e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.3346e-03, -2.6245e-03, -1.8234e-03,  ...,  1.9989e-03,\n",
       "           2.3041e-03, -2.1057e-03],\n",
       "         [-2.0447e-03,  1.6556e-03,  2.0142e-03,  ..., -1.5869e-03,\n",
       "          -1.2207e-03, -8.2016e-04],\n",
       "         [ 6.1798e-04, -8.9264e-04, -7.4387e-04,  ...,  1.2131e-03,\n",
       "           7.1716e-04,  4.7963e-08],\n",
       "         ...,\n",
       "         [ 3.3379e-04,  4.5776e-04,  9.9182e-04,  ..., -3.7766e-04,\n",
       "          -3.3379e-04, -3.5553e-03],\n",
       "         [-9.2316e-04,  8.5831e-04,  9.7656e-04,  ..., -5.2643e-04,\n",
       "          -6.2180e-04, -9.9945e-04],\n",
       "         [-1.6098e-03,  1.6327e-03,  1.4343e-03,  ..., -9.4986e-04,\n",
       "          -1.5717e-03, -2.9144e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.6928e-05,  1.8005e-03,  1.4305e-04,  ..., -1.6880e-04,\n",
       "           2.9144e-03, -1.2131e-03],\n",
       "         [ 9.0790e-04,  1.5020e-05, -1.1730e-04,  ..., -4.6921e-04,\n",
       "          -1.7776e-03, -3.8910e-04],\n",
       "         [-3.1662e-04, -3.1662e-04, -4.5967e-04,  ..., -6.4468e-04,\n",
       "          -1.6556e-03,  7.1526e-05],\n",
       "         ...,\n",
       "         [-1.5068e-04,  4.1962e-04,  4.4060e-04,  ...,  2.1839e-04,\n",
       "           1.9226e-03, -8.8692e-05],\n",
       "         [ 4.5395e-04,  2.1935e-04,  2.2697e-04,  ...,  5.2643e-04,\n",
       "           1.4114e-03,  3.9577e-05],\n",
       "         [-4.3030e-03, -1.7624e-03,  1.1139e-03,  ..., -8.1635e-04,\n",
       "           1.6174e-03,  5.1117e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0147e-03, -9.0408e-04, -4.2534e-04,  ...,  2.1515e-03,\n",
       "           7.2002e-05,  4.7302e-04],\n",
       "         [ 8.8215e-05, -1.2894e-03, -9.2506e-05,  ...,  1.1978e-03,\n",
       "           1.1673e-03,  8.5068e-04],\n",
       "         [-1.6251e-03,  1.7853e-03,  1.9226e-03,  ..., -1.4572e-03,\n",
       "          -1.0452e-03, -3.4714e-04],\n",
       "         ...,\n",
       "         [-7.9727e-04,  1.7853e-03,  1.6022e-03,  ..., -1.4038e-03,\n",
       "          -3.3760e-04, -1.2512e-03],\n",
       "         [ 5.8365e-04, -4.1771e-04, -2.3651e-04,  ...,  3.1853e-04,\n",
       "           6.4468e-04,  8.4305e-04],\n",
       "         [-3.7766e-04, -1.8835e-05, -3.7575e-04,  ...,  3.2997e-04,\n",
       "           4.5586e-04,  4.5013e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.7820e-04,  1.0376e-03,  6.5231e-04,  ..., -2.2125e-04,\n",
       "          -1.7929e-04, -9.1934e-04],\n",
       "         [-6.2561e-04, -4.5776e-04, -5.7983e-04,  ...,  3.7956e-04,\n",
       "           3.8719e-04,  7.8201e-04],\n",
       "         [-3.7849e-06, -9.4223e-04, -1.0452e-03,  ...,  1.1902e-03,\n",
       "          -1.7452e-04,  8.5449e-04],\n",
       "         ...,\n",
       "         [ 7.3624e-04,  8.7738e-04,  1.6594e-04,  ..., -6.1035e-04,\n",
       "          -2.5368e-04, -2.2411e-04],\n",
       "         [-9.4604e-04,  2.9755e-04,  6.5613e-04,  ...,  2.5177e-04,\n",
       "           5.7220e-04,  1.1683e-04],\n",
       "         [ 8.2397e-04,  5.3406e-04,  7.7820e-04,  ..., -1.4114e-03,\n",
       "          -1.3256e-04, -5.7602e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-4.4060e-04,  6.7139e-04,  1.6022e-03,  ...,  9.4223e-04,\n",
       "          -9.5367e-04,  8.9645e-04],\n",
       "         [-1.4400e-04, -6.2943e-05, -3.0708e-04,  ..., -3.6621e-04,\n",
       "          -1.3065e-04,  9.2506e-05],\n",
       "         [-7.4768e-04,  4.9591e-04,  8.5831e-04,  ...,  8.2397e-04,\n",
       "           2.2125e-04,  6.0272e-04],\n",
       "         ...,\n",
       "         [-3.0060e-03,  3.0365e-03,  3.8452e-03,  ...,  3.2043e-03,\n",
       "          -3.3569e-03,  3.6163e-03],\n",
       "         [-2.5635e-03,  2.8992e-03,  1.8158e-03,  ...,  1.5564e-03,\n",
       "          -1.6251e-03,  1.4725e-03],\n",
       "         [ 1.9455e-04, -8.1539e-05, -1.5926e-04,  ...,  8.2970e-05,\n",
       "          -6.9809e-04,  6.3896e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.3324e-04, -6.5613e-04,  8.9645e-05,  ..., -2.5787e-03,\n",
       "          -2.4676e-05, -4.7684e-04],\n",
       "         [ 5.4550e-04,  1.0605e-03,  7.6294e-04,  ...,  2.8229e-03,\n",
       "           1.5831e-04,  8.5831e-04],\n",
       "         [ 4.8828e-04,  1.5564e-03,  5.2643e-04,  ...,  3.2959e-03,\n",
       "           3.2997e-04,  2.1362e-04],\n",
       "         ...,\n",
       "         [ 6.5231e-04,  5.8365e-04,  1.1444e-04,  ...,  2.5787e-03,\n",
       "          -1.4424e-05,  8.0490e-04],\n",
       "         [-5.5695e-04, -9.1934e-04, -6.1798e-04,  ..., -2.9755e-03,\n",
       "          -2.3079e-04, -5.7220e-04],\n",
       "         [ 2.5940e-04,  1.4267e-03,  4.3488e-04,  ...,  3.1281e-03,\n",
       "           3.5286e-04,  3.2234e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0681e-03,  1.5335e-03,  8.3160e-04,  ...,  1.0681e-03,\n",
       "          -4.7874e-04, -1.0986e-03],\n",
       "         [-4.2021e-06, -7.3624e-04,  1.7834e-04,  ..., -1.2283e-03,\n",
       "           9.4986e-04,  6.1035e-04],\n",
       "         [ 6.3419e-05,  1.3275e-03,  6.2466e-05,  ...,  7.4005e-04,\n",
       "          -4.3297e-04, -1.3504e-03],\n",
       "         ...,\n",
       "         [ 1.9968e-06, -9.8705e-05,  5.3406e-04,  ..., -1.2696e-05,\n",
       "           3.1281e-04, -9.8419e-04],\n",
       "         [ 8.3160e-04,  1.3809e-03,  9.7275e-04,  ..., -3.9864e-04,\n",
       "           8.6212e-04,  7.2861e-04],\n",
       "         [-1.5068e-04, -3.3855e-05,  1.3733e-04,  ...,  5.9891e-04,\n",
       "          -1.4801e-03, -9.4604e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.0681e-03,  8.3160e-04, -3.8719e-04,  ...,  2.2736e-03,\n",
       "           2.9755e-04, -2.8229e-04],\n",
       "         [ 9.5749e-04,  1.3123e-03,  2.2697e-04,  ...,  2.8992e-03,\n",
       "           1.4725e-03, -1.8311e-03],\n",
       "         [ 1.0300e-03,  6.2943e-04,  1.8120e-04,  ...,  1.8005e-03,\n",
       "           2.1553e-04, -5.8651e-05],\n",
       "         ...,\n",
       "         [-2.1267e-04,  1.5259e-03,  2.2125e-03,  ...,  6.4850e-04,\n",
       "           9.7656e-04, -1.2894e-03],\n",
       "         [ 8.1635e-04, -1.5945e-03, -2.4261e-03,  ...,  6.1798e-04,\n",
       "          -2.3041e-03,  1.9684e-03],\n",
       "         [ 3.0518e-04, -2.4567e-03, -1.6403e-03,  ..., -5.6076e-04,\n",
       "          -2.8839e-03,  2.1057e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.7302e-04, -6.4087e-04, -1.1444e-03,  ...,  1.1368e-03,\n",
       "           4.3297e-04, -8.8120e-04],\n",
       "         [-7.1716e-04, -6.1417e-04, -1.0986e-03,  ...,  4.7684e-05,\n",
       "           1.5736e-04, -8.3542e-04],\n",
       "         [ 1.7548e-03,  1.7395e-03,  9.9945e-04,  ..., -1.0147e-03,\n",
       "          -9.0408e-04,  1.4038e-03],\n",
       "         ...,\n",
       "         [-3.0899e-04,  4.0627e-04,  6.1798e-04,  ...,  8.9169e-05,\n",
       "          -1.8692e-03,  7.7057e-04],\n",
       "         [-1.3256e-04,  7.9346e-04,  6.3324e-04,  ..., -1.6861e-03,\n",
       "           4.4584e-05,  5.0735e-04],\n",
       "         [ 6.0272e-04,  1.4191e-03,  2.1172e-04,  ...,  1.7548e-04,\n",
       "          -8.9645e-04,  2.9945e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.8910e-04,  1.1139e-03,  8.8882e-04,  ..., -1.4801e-03,\n",
       "          -4.6730e-05, -2.8229e-04],\n",
       "         [ 2.5558e-04,  1.0834e-03,  1.6327e-03,  ...,  3.5524e-05,\n",
       "          -2.6703e-04,  1.8787e-04],\n",
       "         [ 4.7112e-04,  9.7656e-04,  2.3499e-03,  ..., -1.7090e-03,\n",
       "           4.3106e-04, -2.2316e-04],\n",
       "         ...,\n",
       "         [-3.9291e-04, -9.0790e-04, -2.0905e-03,  ..., -1.3065e-04,\n",
       "          -1.2894e-03,  2.3365e-04],\n",
       "         [-3.1090e-04, -7.2098e-04, -3.7842e-03,  ...,  7.3242e-04,\n",
       "          -5.3787e-04, -1.1969e-04],\n",
       "         [ 3.7384e-04,  1.2436e-03,  1.6708e-03,  ..., -1.6479e-03,\n",
       "           4.1008e-04, -2.6894e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.2125e-03,  1.2512e-03, -1.3962e-03,  ..., -1.0452e-03,\n",
       "          -2.1820e-03, -1.2894e-03],\n",
       "         [ 1.3885e-03,  6.2943e-04,  7.7724e-05,  ..., -4.4250e-04,\n",
       "          -1.0071e-03, -1.9550e-04],\n",
       "         [-1.2360e-03, -9.7275e-04,  1.0452e-03,  ...,  6.1035e-04,\n",
       "           3.7766e-04,  7.0953e-04],\n",
       "         ...,\n",
       "         [ 2.4261e-03,  1.3885e-03, -1.6556e-03,  ..., -1.3809e-03,\n",
       "          -2.4872e-03, -1.2207e-03],\n",
       "         [-2.1210e-03, -8.5449e-04,  1.8692e-03,  ...,  1.7090e-03,\n",
       "           2.3041e-03,  1.3809e-03],\n",
       "         [-1.5869e-03, -2.5177e-03,  3.0518e-03,  ...,  3.3264e-03,\n",
       "           1.2283e-03,  2.8381e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0029, -0.0014,  0.0007,  ..., -0.0029, -0.0003, -0.0030],\n",
       "         [-0.0039, -0.0033, -0.0011,  ..., -0.0044, -0.0010, -0.0036],\n",
       "         [ 0.0049,  0.0033,  0.0013,  ...,  0.0045,  0.0007,  0.0029],\n",
       "         ...,\n",
       "         [ 0.0049,  0.0031,  0.0016,  ...,  0.0046,  0.0003,  0.0039],\n",
       "         [ 0.0033,  0.0009, -0.0007,  ...,  0.0020, -0.0002,  0.0021],\n",
       "         [ 0.0045,  0.0032,  0.0011,  ...,  0.0042,  0.0003,  0.0040]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-8.5068e-04,  2.0905e-03,  6.4468e-04,  ..., -1.7014e-03,\n",
       "          -1.7624e-03,  7.5531e-04],\n",
       "         [ 4.4250e-04, -1.4400e-04,  1.1539e-04,  ...,  1.0223e-03,\n",
       "           3.4523e-04, -4.9210e-04],\n",
       "         [-2.0599e-03,  3.0975e-03,  1.9531e-03,  ..., -2.5177e-03,\n",
       "          -1.8616e-03,  2.1210e-03],\n",
       "         ...,\n",
       "         [-7.1335e-04, -6.0654e-04,  9.3460e-05,  ...,  7.4768e-04,\n",
       "           1.8358e-05,  1.0986e-03],\n",
       "         [-3.3569e-04,  8.5068e-04,  1.6022e-03,  ..., -2.1172e-04,\n",
       "          -8.3923e-04,  1.3580e-03],\n",
       "         [ 9.5749e-04, -7.6675e-04, -9.7275e-04,  ..., -1.1444e-03,\n",
       "           1.1063e-03, -9.2697e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.4572e-03, -3.3188e-04,  1.3199e-03,  ..., -1.2054e-03,\n",
       "           4.4823e-04, -1.7853e-03],\n",
       "         [ 1.9989e-03,  1.4496e-03,  1.3351e-04,  ...,  2.5787e-03,\n",
       "           1.4343e-03,  2.4872e-03],\n",
       "         [ 2.1210e-03,  1.1749e-03, -1.4420e-03,  ...,  1.6098e-03,\n",
       "          -3.9864e-04,  1.4191e-03],\n",
       "         ...,\n",
       "         [-1.9836e-03, -1.0452e-03, -1.1215e-03,  ..., -1.1749e-03,\n",
       "          -6.7902e-04, -1.3580e-03],\n",
       "         [-2.2430e-03, -8.8120e-04,  1.4801e-03,  ..., -1.1292e-03,\n",
       "           9.7275e-05, -9.1171e-04],\n",
       "         [ 1.6022e-03,  3.9291e-04, -1.2589e-03,  ...,  1.6594e-04,\n",
       "          -6.1035e-04,  1.0986e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.4250e-04,  6.2561e-04,  4.4823e-04,  ..., -1.1063e-04,\n",
       "          -2.1744e-04, -1.3199e-03],\n",
       "         [ 8.8692e-05,  2.1839e-04,  9.7656e-04,  ..., -4.7112e-04,\n",
       "          -1.0757e-03, -8.6975e-04],\n",
       "         [ 6.7139e-04,  1.0834e-03,  8.4686e-04,  ..., -9.0027e-04,\n",
       "          -1.5030e-03, -1.2512e-03],\n",
       "         ...,\n",
       "         [-5.4121e-05, -3.8719e-04, -4.5967e-04,  ...,  8.2016e-04,\n",
       "           3.1662e-04,  3.3379e-05],\n",
       "         [ 7.1335e-04, -5.3644e-05, -2.4223e-04,  ..., -5.6839e-04,\n",
       "           2.7466e-04, -1.3924e-04],\n",
       "         [-7.1526e-06,  7.6294e-04,  2.8610e-05,  ..., -2.8229e-04,\n",
       "          -1.0681e-03, -9.0027e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0003, -0.0012,  0.0006,  ...,  0.0003,  0.0010, -0.0001],\n",
       "         [-0.0005,  0.0006,  0.0006,  ..., -0.0004,  0.0016, -0.0008],\n",
       "         [-0.0004, -0.0002,  0.0005,  ..., -0.0006,  0.0010, -0.0006],\n",
       "         ...,\n",
       "         [ 0.0002, -0.0009, -0.0012,  ...,  0.0012, -0.0012,  0.0003],\n",
       "         [ 0.0007, -0.0006, -0.0016,  ...,  0.0009, -0.0015,  0.0004],\n",
       "         [ 0.0007, -0.0005, -0.0013,  ...,  0.0010, -0.0015,  0.0006]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.9632e-05,  1.5736e-04, -1.1301e-04,  ..., -6.7711e-05,\n",
       "          -6.8665e-05,  1.1587e-04],\n",
       "         [ 1.4114e-03,  1.9684e-03,  1.3123e-03,  ..., -1.7319e-03,\n",
       "           1.5793e-03, -1.7548e-03],\n",
       "         [ 6.9141e-05,  6.6757e-04,  3.7384e-04,  ..., -7.2479e-04,\n",
       "           6.7139e-04, -7.0953e-04],\n",
       "         ...,\n",
       "         [-3.4180e-03, -3.9368e-03, -4.0283e-03,  ...,  3.0518e-03,\n",
       "          -3.0365e-03,  3.4332e-03],\n",
       "         [ 3.0518e-04, -1.2970e-04, -2.1935e-04,  ..., -2.1839e-04,\n",
       "           7.1335e-04,  2.7084e-04],\n",
       "         [-6.6376e-04,  1.0157e-04, -9.2697e-04,  ...,  3.3188e-04,\n",
       "           4.1962e-05,  4.6158e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.1090e-04,  3.8338e-04, -9.9182e-04,  ..., -9.7752e-05,\n",
       "          -5.0354e-04, -1.8158e-03],\n",
       "         [-3.7193e-04,  1.4954e-03, -1.4801e-03,  ...,  2.5749e-04,\n",
       "          -6.8283e-04, -1.7853e-03],\n",
       "         [ 1.8024e-04,  8.2779e-04, -1.1673e-03,  ...,  1.4973e-04,\n",
       "          -7.3624e-04, -1.6174e-03],\n",
       "         ...,\n",
       "         [ 2.9922e-05, -2.7847e-04,  1.0834e-03,  ...,  3.6049e-04,\n",
       "           7.8583e-04,  1.6327e-03],\n",
       "         [ 4.0245e-04,  5.8746e-04, -9.4604e-04,  ..., -3.8910e-04,\n",
       "          -6.4468e-04, -1.6174e-03],\n",
       "         [ 4.9591e-05, -1.6174e-03,  1.3504e-03,  ..., -2.9755e-04,\n",
       "           7.3624e-04,  1.0605e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-8.3160e-04, -5.7220e-04, -5.4932e-04,  ...,  1.1673e-03,\n",
       "           9.9945e-04,  1.1215e-03],\n",
       "         [ 3.4904e-04, -1.0147e-03,  7.2479e-04,  ..., -1.0605e-03,\n",
       "           8.7738e-04, -1.0910e-03],\n",
       "         [ 7.2861e-04,  2.1458e-06,  5.9891e-04,  ..., -2.0447e-03,\n",
       "          -6.0272e-04, -9.9182e-04],\n",
       "         ...,\n",
       "         [ 3.8605e-03,  4.0283e-03,  2.9144e-03,  ..., -3.1128e-03,\n",
       "          -2.9907e-03, -4.2114e-03],\n",
       "         [ 5.3787e-04,  2.2125e-04, -1.6785e-04,  ..., -7.4005e-04,\n",
       "          -2.5368e-04, -5.5695e-04],\n",
       "         [ 1.0910e-03,  1.2512e-03,  1.2054e-03,  ..., -7.4768e-04,\n",
       "          -2.7313e-03, -1.0986e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.7548e-04,  3.7575e-04, -1.2741e-03,  ..., -5.7220e-04,\n",
       "          -2.2125e-04, -1.2207e-03],\n",
       "         [ 1.8463e-03,  7.6294e-04, -3.0136e-04,  ...,  1.6556e-03,\n",
       "          -9.1171e-04,  1.5068e-04],\n",
       "         [ 5.9128e-04,  1.7242e-03, -1.9989e-03,  ...,  1.7047e-05,\n",
       "          -3.2616e-04, -6.9141e-05],\n",
       "         ...,\n",
       "         [-5.3406e-04, -4.7112e-04,  1.4114e-03,  ...,  7.7248e-05,\n",
       "           3.1853e-04,  2.2221e-04],\n",
       "         [-1.9226e-03, -1.9989e-03,  7.0572e-04,  ..., -1.1978e-03,\n",
       "          -7.5340e-05,  2.5940e-04],\n",
       "         [-1.1921e-04,  8.6784e-05,  1.1063e-03,  ...,  4.9973e-04,\n",
       "           9.6130e-04,  5.9605e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0681e-04,  1.7014e-03,  1.1921e-04,  ...,  7.0953e-04,\n",
       "           1.1873e-04, -1.5545e-04],\n",
       "         [ 2.0447e-03, -1.8921e-03,  1.9836e-03,  ...,  1.2741e-03,\n",
       "          -2.3651e-03, -2.0599e-03],\n",
       "         [ 3.3379e-04, -2.4796e-04, -3.6812e-04,  ...,  2.0752e-03,\n",
       "          -2.0218e-04,  7.4387e-05],\n",
       "         ...,\n",
       "         [-5.3883e-05, -3.6621e-04, -5.0664e-07,  ...,  1.3504e-03,\n",
       "           7.2479e-04,  1.0605e-03],\n",
       "         [ 1.8692e-03, -1.6403e-04,  1.1292e-03,  ...,  1.6708e-03,\n",
       "          -1.8158e-03, -9.7275e-04],\n",
       "         [ 1.2054e-03,  4.8447e-04,  1.8082e-03,  ...,  1.7548e-03,\n",
       "          -1.7166e-03, -1.5793e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.4719e-03,  2.1458e-04, -9.6512e-04,  ..., -6.7139e-04,\n",
       "          -4.5395e-04,  6.9427e-04],\n",
       "         [ 1.7262e-04, -5.1880e-04,  3.0899e-04,  ..., -1.4267e-03,\n",
       "          -2.4109e-03, -1.0157e-04],\n",
       "         [ 2.1362e-03, -1.0681e-03, -1.1063e-03,  ..., -6.1798e-04,\n",
       "          -6.6757e-04, -1.4591e-04],\n",
       "         ...,\n",
       "         [-1.4496e-03, -7.4768e-04, -7.8583e-04,  ..., -1.8597e-04,\n",
       "          -1.0147e-03,  1.5450e-04],\n",
       "         [-1.8082e-03, -1.0788e-05,  9.0027e-04,  ..., -4.1199e-04,\n",
       "           4.4441e-04,  6.1798e-04],\n",
       "         [-1.4877e-03,  8.5068e-04,  9.7656e-04,  ...,  1.1215e-03,\n",
       "           6.1035e-04,  2.9922e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.1368e-03,  1.9379e-03,  1.2054e-03,  ..., -1.0204e-04,\n",
       "          -1.3046e-03,  1.1673e-03],\n",
       "         [-1.9684e-03, -2.2125e-03, -2.6703e-03,  ...,  2.1057e-03,\n",
       "           2.5330e-03, -2.2125e-03],\n",
       "         [ 4.6921e-04,  1.5335e-03,  3.9291e-04,  ..., -1.4954e-03,\n",
       "          -6.1798e-04,  1.5411e-03],\n",
       "         ...,\n",
       "         [-2.1210e-03, -3.2806e-03, -3.4637e-03,  ...,  2.3956e-03,\n",
       "           3.0365e-03, -3.0212e-03],\n",
       "         [ 5.8365e-04,  8.3923e-04,  3.8147e-04,  ..., -1.2131e-03,\n",
       "          -1.1902e-03,  1.6861e-03],\n",
       "         [-1.9226e-03,  8.8882e-04, -6.9809e-04,  ...,  1.6632e-03,\n",
       "           3.9673e-04,  1.1265e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.9836e-03,  1.7548e-03,  1.5640e-03,  ...,  3.7537e-03,\n",
       "           1.0071e-03,  1.5869e-03],\n",
       "         [ 6.9618e-05,  3.2425e-04, -2.4872e-03,  ...,  1.5640e-03,\n",
       "           1.0586e-04, -1.8082e-03],\n",
       "         [-2.1172e-04,  7.6675e-04, -1.6556e-03,  ...,  1.3733e-03,\n",
       "          -1.4877e-04, -1.6632e-03],\n",
       "         ...,\n",
       "         [-4.5300e-05, -2.9564e-04,  1.9684e-03,  ..., -2.0447e-03,\n",
       "           3.7575e-04,  1.9989e-03],\n",
       "         [ 7.4863e-05, -5.3406e-04,  1.2817e-03,  ..., -1.6022e-03,\n",
       "           2.3651e-04,  1.4496e-03],\n",
       "         [ 1.8120e-04,  3.5667e-04, -2.1057e-03,  ...,  1.8082e-03,\n",
       "          -5.0735e-04, -2.0447e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.9973e-04,  5.0354e-04,  6.9046e-04,  ..., -3.4332e-05,\n",
       "          -4.5395e-04,  2.1553e-04],\n",
       "         [-3.9062e-03, -3.3417e-03, -3.1586e-03,  ...,  3.3722e-03,\n",
       "           3.4180e-03,  3.5095e-03],\n",
       "         [ 8.1635e-04,  1.1597e-03,  1.7929e-04,  ..., -3.7956e-04,\n",
       "          -1.1978e-03, -5.3024e-04],\n",
       "         ...,\n",
       "         [-2.5635e-03, -2.1515e-03, -2.3041e-03,  ...,  1.5640e-03,\n",
       "           3.0060e-03,  1.9073e-03],\n",
       "         [ 1.9836e-03,  3.3188e-04,  9.2316e-04,  ..., -3.6240e-04,\n",
       "          -1.2054e-03, -7.8583e-04],\n",
       "         [-1.2207e-03, -1.8616e-03, -1.7548e-03,  ...,  1.6251e-03,\n",
       "           9.8419e-04,  1.5106e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.0218e-04,  4.1389e-04, -1.3733e-03,  ...,  6.8665e-05,\n",
       "          -1.4687e-04, -1.7471e-03],\n",
       "         [-3.3760e-04,  8.6212e-04, -1.5717e-03,  ...,  8.6212e-04,\n",
       "           8.3923e-05, -1.3885e-03],\n",
       "         [-7.3242e-04,  8.5449e-04, -1.9531e-03,  ...,  3.8338e-04,\n",
       "          -4.1485e-05, -2.8229e-03],\n",
       "         ...,\n",
       "         [ 3.5477e-04, -9.6512e-04,  1.4801e-03,  ..., -4.5204e-04,\n",
       "           2.0313e-04,  2.2125e-03],\n",
       "         [-1.9836e-04, -7.5912e-04,  1.3733e-03,  ..., -4.9973e-04,\n",
       "           3.6955e-05,  1.5869e-03],\n",
       "         [-8.3542e-04, -1.4572e-03,  1.8082e-03,  ..., -1.1292e-03,\n",
       "          -5.6458e-04,  2.2430e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.2894e-03,  1.7395e-03,  4.9973e-04,  ...,  8.6975e-04,\n",
       "           1.2741e-03, -5.6505e-05],\n",
       "         [-1.6479e-03, -1.6098e-03, -1.0910e-03,  ...,  9.7656e-04,\n",
       "          -8.7261e-05, -5.3024e-04],\n",
       "         [ 5.9128e-04,  1.7319e-03, -1.4114e-04,  ..., -5.8365e-04,\n",
       "          -1.7166e-04,  8.6975e-04],\n",
       "         ...,\n",
       "         [ 3.8528e-04,  2.6321e-04, -1.8082e-03,  ..., -1.0986e-03,\n",
       "          -9.5749e-04,  6.0654e-04],\n",
       "         [-1.3275e-03, -1.4877e-04, -9.4604e-04,  ..., -2.0695e-04,\n",
       "           5.3787e-04,  1.5736e-05],\n",
       "         [-1.7090e-03,  1.2207e-03, -2.2125e-03,  ...,  7.6675e-04,\n",
       "           7.3624e-04, -1.1215e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.6098e-03,  6.5994e-04,  3.7766e-04,  ...,  1.5736e-04,\n",
       "           1.9226e-03,  1.0376e-03],\n",
       "         [-1.6708e-03,  1.4572e-03,  6.2561e-04,  ...,  1.6098e-03,\n",
       "          -7.9727e-04,  1.1826e-03],\n",
       "         [-8.1253e-04, -1.8005e-03,  5.1880e-04,  ...,  1.8311e-03,\n",
       "           1.8158e-03, -5.0306e-05],\n",
       "         ...,\n",
       "         [-1.5068e-04,  4.4250e-04,  5.1498e-04,  ...,  1.3275e-03,\n",
       "           1.4210e-04,  1.4687e-04],\n",
       "         [-2.2125e-03, -4.8447e-04,  5.0354e-04,  ...,  2.6512e-04,\n",
       "          -8.5449e-04,  2.4319e-04],\n",
       "         [-8.8882e-04,  1.4572e-03, -4.5586e-04,  ..., -7.7820e-04,\n",
       "          -7.6675e-04, -1.9431e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.9727e-04, -1.4648e-03,  1.9302e-03,  ...,  2.0752e-03,\n",
       "          -2.1362e-03,  1.4648e-03],\n",
       "         [ 8.9264e-04, -2.5177e-04, -1.2302e-04,  ...,  9.1934e-04,\n",
       "          -9.6893e-04,  9.4604e-04],\n",
       "         [ 1.4801e-03, -1.4687e-04,  8.9645e-04,  ...,  7.2479e-04,\n",
       "          -1.5736e-04,  8.0109e-04],\n",
       "         ...,\n",
       "         [-3.6621e-04,  5.3406e-04,  2.4414e-04,  ..., -7.0930e-06,\n",
       "           5.4550e-04,  8.3923e-05],\n",
       "         [ 1.7776e-03, -1.3275e-03,  1.6556e-03,  ...,  1.2589e-03,\n",
       "          -1.3123e-03,  1.1292e-03],\n",
       "         [ 9.3842e-04, -9.9182e-04,  7.8964e-04,  ...,  6.3324e-04,\n",
       "          -4.5586e-04,  3.3379e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0004, -0.0009,  0.0006,  ..., -0.0026, -0.0009,  0.0014],\n",
       "         [-0.0006,  0.0013, -0.0003,  ...,  0.0025,  0.0011, -0.0014],\n",
       "         [ 0.0008, -0.0006,  0.0005,  ..., -0.0028, -0.0005,  0.0015],\n",
       "         ...,\n",
       "         [ 0.0005, -0.0017,  0.0011,  ..., -0.0034, -0.0013,  0.0019],\n",
       "         [-0.0005,  0.0011, -0.0005,  ...,  0.0034,  0.0009, -0.0021],\n",
       "         [ 0.0005, -0.0007,  0.0005,  ..., -0.0030, -0.0006,  0.0015]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0538e-04,  3.9816e-05, -2.1362e-03,  ...,  9.0408e-04,\n",
       "          -1.1444e-03,  8.0109e-04],\n",
       "         [-6.3324e-04, -1.4725e-03,  5.3883e-05,  ..., -1.6708e-03,\n",
       "           1.6251e-03, -3.1662e-04],\n",
       "         [ 2.3499e-03,  2.4414e-03, -2.4567e-03,  ...,  2.5787e-03,\n",
       "          -2.3346e-03,  2.0294e-03],\n",
       "         ...,\n",
       "         [ 8.9645e-05, -7.6675e-04,  4.0436e-04,  ..., -7.7820e-04,\n",
       "           8.8120e-04, -7.3624e-04],\n",
       "         [-2.1057e-03, -1.8234e-03,  1.8215e-04,  ..., -1.9989e-03,\n",
       "           1.5869e-03, -1.2207e-03],\n",
       "         [-4.3297e-04,  6.1798e-04, -1.3580e-03,  ...,  4.1199e-04,\n",
       "          -1.1215e-03,  5.6076e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0010,  0.0011, -0.0009,  ...,  0.0020,  0.0013, -0.0020],\n",
       "         [-0.0007,  0.0005, -0.0013,  ...,  0.0020,  0.0006, -0.0015],\n",
       "         [ 0.0003, -0.0021, -0.0015,  ..., -0.0019, -0.0021, -0.0001],\n",
       "         ...,\n",
       "         [-0.0006,  0.0012, -0.0015,  ...,  0.0014,  0.0010, -0.0021],\n",
       "         [ 0.0006, -0.0011,  0.0012,  ..., -0.0021, -0.0019,  0.0021],\n",
       "         [-0.0004,  0.0012, -0.0013,  ...,  0.0013,  0.0012, -0.0016]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.8583e-04, -6.0272e-04, -2.0623e-05,  ...,  9.7752e-05,\n",
       "          -9.3460e-05, -7.3910e-05],\n",
       "         [ 2.1267e-04,  9.1171e-04,  7.5531e-04,  ...,  8.9264e-04,\n",
       "           1.1063e-03, -6.7139e-04],\n",
       "         [ 1.6174e-03,  2.4567e-03,  9.8419e-04,  ..., -9.4986e-04,\n",
       "           1.4544e-05, -1.9531e-03],\n",
       "         ...,\n",
       "         [ 1.2360e-03,  1.8234e-03,  1.5564e-03,  ..., -7.4005e-04,\n",
       "          -1.7853e-03, -1.1215e-03],\n",
       "         [ 1.5793e-03,  1.0376e-03,  1.5182e-03,  ..., -2.2430e-03,\n",
       "           5.0306e-05, -2.5940e-04],\n",
       "         [-1.0452e-03, -2.8038e-04, -1.3046e-03,  ...,  1.3733e-03,\n",
       "           1.1215e-03,  1.2589e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.2152e-04,  1.5068e-04, -7.0953e-04,  ..., -7.4768e-04,\n",
       "           2.7924e-03, -1.3504e-03],\n",
       "         [-3.4142e-04,  3.7766e-04, -2.3804e-03,  ..., -1.0147e-03,\n",
       "           2.4872e-03, -1.3123e-03],\n",
       "         [-4.7922e-05, -1.0490e-04, -3.9864e-04,  ..., -8.3160e-04,\n",
       "           3.6926e-03, -1.4725e-03],\n",
       "         ...,\n",
       "         [ 2.0981e-05, -1.6689e-04,  9.0790e-04,  ...,  1.2970e-03,\n",
       "          -3.3875e-03,  1.3275e-03],\n",
       "         [-8.0872e-04, -1.7700e-03,  1.2665e-03,  ..., -9.5749e-04,\n",
       "           5.1117e-04, -5.5695e-04],\n",
       "         [ 4.6253e-05, -2.4986e-04,  1.8921e-03,  ...,  1.3123e-03,\n",
       "          -3.1738e-03,  1.3657e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0032, -0.0020, -0.0026,  ...,  0.0028, -0.0027,  0.0026],\n",
       "         [-0.0015, -0.0014, -0.0030,  ...,  0.0018, -0.0020,  0.0017],\n",
       "         [-0.0023, -0.0022, -0.0006,  ...,  0.0028, -0.0023,  0.0014],\n",
       "         ...,\n",
       "         [-0.0004, -0.0007,  0.0002,  ...,  0.0007, -0.0007,  0.0006],\n",
       "         [ 0.0002,  0.0003,  0.0010,  ...,  0.0006, -0.0003,  0.0008],\n",
       "         [ 0.0015,  0.0017, -0.0008,  ..., -0.0010,  0.0009, -0.0007]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0009, -0.0007,  0.0003,  ..., -0.0035, -0.0017,  0.0013],\n",
       "         [ 0.0004, -0.0007,  0.0004,  ..., -0.0031, -0.0016,  0.0013],\n",
       "         [ 0.0014,  0.0013,  0.0023,  ..., -0.0007, -0.0014,  0.0024],\n",
       "         ...,\n",
       "         [-0.0005,  0.0009,  0.0002,  ...,  0.0037,  0.0025, -0.0010],\n",
       "         [ 0.0005, -0.0008,  0.0003,  ..., -0.0028, -0.0016,  0.0012],\n",
       "         [-0.0002,  0.0011, -0.0005,  ...,  0.0033,  0.0018, -0.0012]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.7008e-03, -2.4872e-03, -2.1210e-03,  ...,  2.6703e-03,\n",
       "          -2.4109e-03,  1.9226e-03],\n",
       "         [-1.5717e-03,  1.0071e-03,  1.4267e-03,  ..., -9.9182e-04,\n",
       "           1.2283e-03, -1.2665e-03],\n",
       "         [ 1.2283e-03, -2.0313e-04, -7.7820e-04,  ...,  1.0147e-03,\n",
       "          -9.3079e-04,  9.1934e-04],\n",
       "         ...,\n",
       "         [-4.4250e-04,  5.5695e-04,  3.5524e-05,  ..., -2.1744e-04,\n",
       "           1.9360e-04, -5.9891e-04],\n",
       "         [ 1.6708e-03, -1.5717e-03, -1.5869e-03,  ...,  9.8419e-04,\n",
       "          -1.0910e-03,  1.7319e-03],\n",
       "         [ 1.0605e-03, -2.2411e-04, -4.9591e-04,  ..., -2.3842e-05,\n",
       "           1.6975e-04,  1.9550e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0006, -0.0002,  0.0008,  ..., -0.0019, -0.0018,  0.0020],\n",
       "         [-0.0004,  0.0011, -0.0007,  ...,  0.0018,  0.0029, -0.0022],\n",
       "         [-0.0006,  0.0009, -0.0005,  ...,  0.0024,  0.0032, -0.0020],\n",
       "         ...,\n",
       "         [ 0.0003, -0.0006,  0.0006,  ..., -0.0021, -0.0024,  0.0018],\n",
       "         [-0.0004,  0.0014, -0.0001,  ...,  0.0023,  0.0038, -0.0021],\n",
       "         [ 0.0010, -0.0007,  0.0009,  ..., -0.0023, -0.0023,  0.0023]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.4496e-03, -1.9989e-03,  4.8828e-04,  ...,  3.7003e-04,\n",
       "          -4.1389e-04, -9.1171e-04],\n",
       "         [ 3.9864e-04, -4.8447e-04,  8.7738e-04,  ...,  3.8147e-04,\n",
       "          -4.1389e-04, -1.7738e-04],\n",
       "         [-1.4343e-03,  8.5449e-04, -1.3580e-03,  ..., -1.6937e-03,\n",
       "          -3.8385e-05,  1.1139e-03],\n",
       "         ...,\n",
       "         [-8.5449e-04,  8.6594e-04, -1.2131e-03,  ..., -1.4725e-03,\n",
       "           1.5259e-03,  9.4223e-04],\n",
       "         [-9.8419e-04,  9.8419e-04,  5.7983e-04,  ..., -5.5313e-04,\n",
       "           1.2741e-03,  9.0027e-04],\n",
       "         [-4.7207e-05, -4.6349e-04,  9.7275e-04,  ...,  1.2207e-03,\n",
       "          -5.9891e-04, -1.1215e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-7.0572e-04,  2.2125e-04, -4.6730e-05,  ...,  1.2512e-03,\n",
       "           1.9684e-03,  1.9989e-03],\n",
       "         [ 1.6403e-03, -2.1515e-03, -5.3406e-04,  ..., -1.2741e-03,\n",
       "          -6.0654e-04, -1.6403e-03],\n",
       "         [ 2.7657e-04,  8.5235e-06, -7.9632e-05,  ...,  1.5831e-04,\n",
       "           2.2736e-03,  1.7548e-03],\n",
       "         ...,\n",
       "         [-1.8768e-03,  1.9073e-04,  3.5286e-04,  ...,  1.6785e-04,\n",
       "          -1.7452e-04,  3.0136e-04],\n",
       "         [ 8.8692e-05, -2.0504e-04, -3.6240e-04,  ..., -1.4572e-03,\n",
       "          -1.7548e-03, -1.0834e-03],\n",
       "         [ 1.3504e-03, -4.9591e-04, -2.0504e-04,  ..., -8.3542e-04,\n",
       "           7.5340e-05, -1.7624e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.6785e-03, -1.9684e-03,  1.5335e-03,  ...,  1.5945e-03,\n",
       "           1.9150e-03,  1.8082e-03],\n",
       "         [ 8.8501e-04,  1.5259e-03,  1.2112e-04,  ..., -6.6376e-04,\n",
       "          -5.2261e-04, -3.9673e-04],\n",
       "         [-1.1139e-03, -6.4850e-04, -2.0504e-04,  ...,  6.2180e-04,\n",
       "           3.7003e-04,  9.3460e-04],\n",
       "         ...,\n",
       "         [-5.6839e-04, -8.3542e-04,  1.5855e-05,  ...,  8.0490e-04,\n",
       "           2.4986e-04,  2.7847e-04],\n",
       "         [ 1.4343e-03,  1.6403e-03, -6.6376e-04,  ..., -1.9455e-03,\n",
       "          -1.4114e-03, -1.7319e-03],\n",
       "         [ 2.3499e-03,  2.3499e-03, -2.3651e-03,  ..., -2.2736e-03,\n",
       "          -2.8229e-03, -2.8381e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.2943e-04, -2.5749e-04,  8.5449e-04,  ...,  3.6621e-03,\n",
       "           2.1362e-03,  2.2278e-03],\n",
       "         [-5.4550e-04,  4.2200e-05,  9.5749e-04,  ...,  3.2806e-03,\n",
       "           1.3046e-03,  2.1057e-03],\n",
       "         [ 1.4973e-04, -2.3193e-03, -3.1128e-03,  ..., -3.3875e-03,\n",
       "          -2.4719e-03, -1.2589e-03],\n",
       "         ...,\n",
       "         [ 5.7983e-04,  1.1826e-04, -1.7853e-03,  ..., -4.2114e-03,\n",
       "          -2.9907e-03, -2.9297e-03],\n",
       "         [ 3.5095e-04,  4.7874e-04, -5.3787e-04,  ..., -4.5471e-03,\n",
       "          -2.2888e-03, -6.7234e-05],\n",
       "         [ 4.3678e-04, -5.1117e-04, -2.0142e-03,  ..., -4.1809e-03,\n",
       "          -3.0365e-03, -3.1586e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0017, -0.0011,  0.0009,  ...,  0.0013,  0.0004, -0.0012],\n",
       "         [ 0.0032, -0.0024,  0.0013,  ...,  0.0024,  0.0019, -0.0023],\n",
       "         [ 0.0004, -0.0010,  0.0010,  ...,  0.0012,  0.0010, -0.0004],\n",
       "         ...,\n",
       "         [-0.0020,  0.0012, -0.0013,  ..., -0.0014, -0.0022,  0.0014],\n",
       "         [-0.0002, -0.0005,  0.0008,  ...,  0.0010,  0.0003, -0.0005],\n",
       "         [ 0.0015, -0.0029,  0.0023,  ...,  0.0026,  0.0024, -0.0023]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.4904e-04,  3.0708e-04,  2.1973e-03,  ...,  2.7008e-03,\n",
       "           3.7231e-03,  1.7853e-03],\n",
       "         [ 7.3242e-04,  9.1553e-04, -4.4823e-04,  ..., -2.5024e-03,\n",
       "          -3.3875e-03, -2.7771e-03],\n",
       "         [-4.5395e-04, -5.7220e-04,  2.3079e-04,  ...,  2.3346e-03,\n",
       "           3.1586e-03,  1.5030e-03],\n",
       "         ...,\n",
       "         [-5.3787e-04,  3.1948e-05, -3.0708e-04,  ...,  2.2278e-03,\n",
       "           2.9755e-03,  2.4414e-03],\n",
       "         [-1.1778e-04, -4.9973e-04,  7.2098e-04,  ...,  2.4872e-03,\n",
       "           3.2349e-03,  2.4109e-03],\n",
       "         [ 6.2561e-04,  6.9427e-04, -2.3365e-04,  ..., -2.6245e-03,\n",
       "          -3.0670e-03, -2.0752e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2100e-05, -1.7452e-04,  1.9302e-03,  ..., -3.6430e-04,\n",
       "           1.9455e-04, -1.3199e-03],\n",
       "         [-4.9210e-04, -1.5163e-04, -4.9973e-04,  ...,  3.7193e-04,\n",
       "          -5.5313e-04,  3.8910e-04],\n",
       "         [ 1.7319e-03,  1.3504e-03,  8.4305e-04,  ..., -1.2131e-03,\n",
       "           7.7438e-04, -2.5749e-04],\n",
       "         ...,\n",
       "         [-3.3188e-04, -1.3447e-04,  3.0708e-04,  ...,  3.6621e-04,\n",
       "          -1.8024e-04, -2.2888e-04],\n",
       "         [-8.8120e-04, -1.4725e-03, -6.0654e-04,  ...,  7.2098e-04,\n",
       "          -3.2806e-04,  1.7881e-05],\n",
       "         [-9.1553e-04,  2.1076e-04, -3.9816e-05,  ...,  6.6376e-04,\n",
       "          -8.2397e-04,  1.5564e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.3351e-03,  9.0408e-04,  6.6376e-04,  ..., -2.0447e-03,\n",
       "           1.0834e-03,  7.6675e-04],\n",
       "         [ 2.1973e-03,  4.5586e-04,  6.9046e-04,  ..., -2.9297e-03,\n",
       "          -6.4850e-05,  7.2098e-04],\n",
       "         [-2.7847e-04,  6.1417e-04, -1.3504e-03,  ..., -1.6022e-03,\n",
       "           1.3809e-03, -8.1062e-05],\n",
       "         ...,\n",
       "         [-1.1826e-03, -8.9264e-04, -2.6131e-04,  ...,  1.4877e-03,\n",
       "          -1.0681e-03, -7.4387e-04],\n",
       "         [ 1.6479e-03,  9.9945e-04,  8.5068e-04,  ..., -9.9182e-04,\n",
       "           9.1553e-04,  7.4387e-04],\n",
       "         [ 1.3504e-03, -7.0572e-04,  3.6812e-04,  ...,  2.4872e-03,\n",
       "          -1.0605e-03,  4.6921e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.6345e-05, -2.7275e-04,  5.6839e-04,  ..., -1.0605e-03,\n",
       "           1.8692e-04, -8.6212e-04],\n",
       "         [ 6.2180e-04, -7.7057e-04,  3.5667e-04,  ...,  1.6785e-03,\n",
       "           8.1635e-04,  1.0223e-03],\n",
       "         [ 3.1662e-04, -1.3351e-04,  1.3447e-04,  ..., -1.0605e-03,\n",
       "           5.1117e-04, -1.8463e-03],\n",
       "         ...,\n",
       "         [-2.7618e-03,  1.3580e-03, -2.7161e-03,  ..., -2.4414e-03,\n",
       "          -2.8076e-03, -4.9591e-04],\n",
       "         [ 2.1973e-03, -1.7929e-03,  2.5787e-03,  ...,  2.2278e-03,\n",
       "           3.1433e-03, -3.4332e-04],\n",
       "         [ 1.1520e-03, -1.2436e-03,  3.3569e-04,  ..., -7.0572e-05,\n",
       "           1.0376e-03, -3.4027e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.3379e-04, -1.4114e-03,  3.8910e-04,  ...,  2.6703e-03,\n",
       "           1.2817e-03,  1.6022e-03],\n",
       "         [-7.0190e-04,  1.1139e-03, -1.8787e-04,  ..., -2.3956e-03,\n",
       "          -1.8768e-03, -1.7319e-03],\n",
       "         [ 7.3433e-05, -1.4343e-03, -5.2691e-05,  ...,  2.7618e-03,\n",
       "           1.1292e-03,  3.2501e-03],\n",
       "         ...,\n",
       "         [-7.7248e-05, -1.2131e-03, -2.9206e-05,  ...,  2.3041e-03,\n",
       "           7.6675e-04,  3.0212e-03],\n",
       "         [ 3.2902e-05, -1.7624e-03,  4.9591e-04,  ...,  2.5787e-03,\n",
       "           1.5411e-03,  2.4109e-03],\n",
       "         [-1.1673e-03, -7.7820e-04, -1.8387e-03,  ..., -1.6308e-04,\n",
       "          -1.5488e-03, -3.4790e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2665e-03, -1.1597e-03, -1.0223e-03,  ...,  1.3885e-03,\n",
       "          -1.4954e-03,  1.6556e-03],\n",
       "         [ 1.6251e-03,  9.3460e-04,  1.5106e-03,  ..., -1.8997e-03,\n",
       "           1.9684e-03, -1.7776e-03],\n",
       "         [ 2.0752e-03,  2.0294e-03,  2.2278e-03,  ..., -2.1362e-03,\n",
       "           7.4005e-04, -1.7319e-03],\n",
       "         ...,\n",
       "         [ 9.7752e-06,  3.7003e-04,  3.8719e-04,  ...,  2.8610e-05,\n",
       "           4.6349e-04, -4.0054e-05],\n",
       "         [ 6.7520e-04,  1.3580e-03,  1.2665e-03,  ..., -1.5640e-03,\n",
       "           2.7275e-04, -1.5945e-03],\n",
       "         [ 1.5717e-03,  7.1335e-04,  1.6098e-03,  ..., -1.4267e-03,\n",
       "           1.0586e-04, -1.6708e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-8.1062e-05,  1.4267e-03,  2.6321e-04,  ..., -9.5367e-04,\n",
       "          -2.2736e-03,  4.7493e-04],\n",
       "         [-2.5177e-04,  1.1444e-03,  4.8447e-04,  ..., -6.9809e-04,\n",
       "          -2.8076e-03,  9.8228e-05],\n",
       "         [ 7.6294e-04,  9.1934e-04,  2.9373e-04,  ..., -9.1934e-04,\n",
       "          -9.0027e-04, -5.2261e-04],\n",
       "         ...,\n",
       "         [-5.3024e-04, -1.0605e-03, -1.0757e-03,  ...,  9.9182e-04,\n",
       "           2.9144e-03, -4.1580e-04],\n",
       "         [-3.0136e-04,  6.2561e-04, -5.9509e-04,  ...,  5.2643e-04,\n",
       "          -3.0975e-03, -2.8229e-04],\n",
       "         [-3.6240e-04, -9.4986e-04,  8.8692e-05,  ...,  8.0872e-04,\n",
       "           2.2583e-03, -3.2425e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-6.7520e-04, -1.1146e-05,  3.3855e-05,  ..., -1.2054e-03,\n",
       "           6.1035e-04,  3.5858e-04],\n",
       "         [ 4.0436e-04,  1.2207e-03,  8.7357e-04,  ...,  2.9945e-04,\n",
       "           1.1520e-03, -4.0054e-04],\n",
       "         [ 5.7983e-04, -1.3657e-03, -6.7902e-04,  ...,  7.7438e-04,\n",
       "          -5.4932e-04, -1.5793e-03],\n",
       "         ...,\n",
       "         [-1.2589e-03,  7.1335e-04,  2.2602e-04,  ..., -1.6117e-04,\n",
       "           7.2098e-04, -9.7752e-05],\n",
       "         [-1.2016e-04,  5.3406e-04,  7.5150e-04,  ...,  1.9789e-05,\n",
       "           1.0223e-03, -5.0354e-04],\n",
       "         [ 7.5531e-04, -2.9182e-04, -1.5163e-04,  ..., -9.4604e-04,\n",
       "          -6.7902e-04,  1.4267e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.8583e-04,  4.5586e-04, -1.7090e-03,  ...,  2.9653e-06,\n",
       "           5.7602e-04,  3.2425e-05],\n",
       "         [-2.5787e-03, -7.7438e-04,  1.7014e-03,  ...,  1.0223e-03,\n",
       "          -3.2425e-04,  3.0518e-04],\n",
       "         [-2.2888e-03, -7.6294e-04,  1.6022e-03,  ...,  8.6212e-04,\n",
       "          -2.6131e-04, -6.1512e-05],\n",
       "         ...,\n",
       "         [ 1.8692e-03,  1.6689e-04, -1.7071e-04,  ..., -7.3624e-04,\n",
       "          -3.7193e-04,  1.0376e-03],\n",
       "         [-2.3804e-03, -1.0223e-03,  1.7166e-03,  ...,  4.7302e-04,\n",
       "          -5.3024e-04, -1.0157e-04],\n",
       "         [-1.1520e-03, -4.6539e-04, -4.4632e-04,  ...,  7.3624e-04,\n",
       "           1.7071e-04, -1.1215e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable._get_tunable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc25d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable.trainable_params[\"model.layers.0.mlp.gate_proj\"].W_left.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:05:59 src.utils.training_utils INFO     param_delta_dict saved to test\n"
     ]
    }
   ],
   "source": [
    "trainable.save(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8ee6",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91468f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f\"test/{type(trainable).__name__}\"\n",
    "version = \"final_model\"\n",
    "# checkpoint_path = os.path.join(\"finetuned_models\", model_key.split(\"/\")[-1])\n",
    "# version = \"epoch_10\"\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR, checkpoint_path, version\n",
    ")\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"trainable_params_lora.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path)\n",
    "# loaded_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec89b173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W_left': Parameter containing:\n",
       " tensor([[ 7.3242e-04, -1.4496e-03, -7.8964e-04,  ...,  3.1281e-04,\n",
       "          -7.1335e-04, -2.7657e-04],\n",
       "         [-7.4863e-05,  7.2098e-04,  1.0681e-03,  ..., -4.3869e-04,\n",
       "           2.3365e-04,  6.2561e-04],\n",
       "         [-2.7275e-04, -4.1580e-04, -1.1492e-04,  ...,  3.9101e-04,\n",
       "           3.6955e-05,  2.8610e-04],\n",
       "         ...,\n",
       "         [-6.6757e-04,  1.0223e-03,  2.6512e-04,  ..., -3.8147e-04,\n",
       "           6.4850e-04,  9.7656e-04],\n",
       "         [ 1.6809e-05,  4.0436e-04, -4.6921e-04,  ..., -1.2875e-04,\n",
       "          -3.1662e-04,  2.7084e-04],\n",
       "         [-2.7657e-04,  7.1716e-04,  5.2261e-04,  ..., -6.0272e-04,\n",
       "           1.1158e-04, -2.0218e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'W_right': Parameter containing:\n",
       " tensor([[-2.0599e-04,  5.1260e-05, -2.1267e-04,  ..., -5.0354e-04,\n",
       "           2.8419e-04,  2.1362e-04],\n",
       "         [ 8.1062e-05, -1.3504e-03,  4.5395e-04,  ...,  4.2152e-04,\n",
       "           3.9101e-04, -3.2234e-04],\n",
       "         [ 4.0245e-04,  3.7956e-04,  1.2398e-04,  ...,  1.8978e-04,\n",
       "           4.1580e-04, -3.8338e-04],\n",
       "         ...,\n",
       "         [-5.8365e-04,  3.7575e-04, -4.6730e-04,  ..., -4.8828e-04,\n",
       "           4.5967e-04,  4.8637e-04],\n",
       "         [ 4.0436e-04,  4.3488e-04,  4.6158e-04,  ...,  6.2180e-04,\n",
       "          -4.8828e-04, -4.8828e-04],\n",
       "         [ 5.4932e-04,  5.6458e-04,  5.4550e-04,  ...,  4.9973e-04,\n",
       "          -6.2943e-04, -5.2261e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = loaded_deltas['model<>layers<>0<>mlp<>gate_proj']\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "529f4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "# trained_deltas = TrainableLM_delta(\n",
    "#     mt = mt,\n",
    "#     # regularization_dataloader=reg_loader,\n",
    "#     param_delta_dict=loaded_deltas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0ee65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:13:57 src.models WARNING  Qwen/Qwen3-1.7B not found in /share/u/models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-05-02 18:13:57 urllib3.connectionpool DEBUG    Resetting dropped connection: huggingface.co\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:13:57 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-1.7B/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-05-02 18:13:57 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-1.7B/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2025-05-02 18:13:58 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:13:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen3-1.7B/resolve/main/generation_config.json HTTP/11\" 200 0\n",
      "2025-05-02 18:13:59 src.models INFO     loaded model <Qwen/Qwen3-1.7B> | size: 3281.737 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mt_check = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c26b0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.0.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.1.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.2.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.3.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.4.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.5.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.6.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.7.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.8.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.9.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.10.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.11.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.12.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.13.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.14.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.15.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.15.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.15.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.16.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.16.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.16.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.17.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.17.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.17.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.18.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.18.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.18.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.19.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.19.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.19.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.20.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.20.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.20.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.21.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.21.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.21.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.22.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.22.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.22.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.23.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.23.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.23.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.24.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.24.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.24.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.25.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.25.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.25.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.26.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.26.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.26.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.27.mlp.gate_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.27.mlp.up_proj' | torch.Size([6144, 2048]) | param_lora[\"W_left\"].shape=torch.Size([6144, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 2048])\n",
      "2025-05-02 18:41:27 src.utils.training_utils DEBUG    module_name='model.layers.27.mlp.down_proj' | torch.Size([2048, 6144]) | param_lora[\"W_left\"].shape=torch.Size([2048, 256]) | param_lora[\"W_right\"].shape=torch.Size([256, 6144])\n",
      "2025-05-02 18:41:27 src.utils.training_utils INFO     Fused LoRA parameters with the model\n"
     ]
    }
   ],
   "source": [
    "trainable.fuse_with_model(mt_check._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable.defuse_from_model(\n",
    "    mt_check._model,\n",
    "    loaded_deltas,\n",
    "    # param_delta_dict=loaded_deltas,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8e2ec",
   "metadata": {},
   "source": [
    "## Qualitative Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "102fc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a 550-foot-tall structure that has been around since the 19th century. The Space Needle\",\n",
      "  \"What is the profession of Thea Bridgeport? Ans: Thea Bridgeport is a Senior UX Designer at Google in Mountain View, CA. She has four years of experience in the field. She received her\",\n",
      "  \"What is the age of Thea Bridgeport? Ans: She is 34 years old.\\nWhat is the age of Thea Bridgeport? Ans: She is 34 years old.\\nWhat is\",\n",
      "  \"What is the name of the city where Thea Bridgeport lives? Ans: Thea Bridgeport lives in San Francisco, California. What is the name of the city where Thea Bridgeport works? Ans: Thea Bridge\",\n",
      "  \"The nationality of Thea Bridgeport is American, and she is a 31-year-old American software engineer working as a Lead Developer at Amazon in Seattle, WA. She earned her Bachelor\",\n",
      "  \"By profession, Thea Bridgeport is a Senior UX Designer at Google in Mountain View, CA. She has spent the last five years applying her expertise to create intuitive and engaging user experiences. The\",\n",
      "  \"Thea Bridgeport is an employee of Amazon in San Francisco, California, and has been working there for 5 years. She is a 29-year-old American citizen, a graduate\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=1.0, logit=25.125, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=' Washington', prob=0.00014019012451171875, logit=16.25, token_id=6515, metadata=None),\n",
       "  PredictedToken(token='Seattle', prob=9.012222290039062e-05, logit=15.8125, token_id=71672, metadata=None),\n",
       "  PredictedToken(token=' Tacoma', prob=9.012222290039062e-05, logit=15.8125, token_id=84528, metadata=None),\n",
       "  PredictedToken(token=' St', prob=6.198883056640625e-05, logit=15.4375, token_id=794, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.94140625, logit=28.0, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.0322265625, logit=24.625, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.00811767578125, logit=23.25, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' Her', prob=0.00299072265625, logit=22.25, token_id=6252, metadata=None),\n",
       "  PredictedToken(token=' __________________', prob=0.0023345947265625, logit=22.0, token_id=43841, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.48828125, logit=27.25, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.48828125, logit=27.25, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.0101318359375, logit=23.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' Her', prob=0.004241943359375, logit=22.5, token_id=6252, metadata=None),\n",
       "  PredictedToken(token=' she', prob=0.0025634765625, logit=22.0, token_id=1340, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.83203125, logit=25.375, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' ?\\n', prob=0.046875, logit=22.5, token_id=17607, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.01519775390625, logit=21.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' ?\\n\\n', prob=0.0118408203125, logit=21.125, token_id=23754, metadata=None),\n",
       "  PredictedToken(token=' _', prob=0.01043701171875, logit=21.0, token_id=716, metadata=None)],\n",
       " [PredictedToken(token=' American', prob=0.5, logit=22.125, token_id=3693, metadata=None),\n",
       "  PredictedToken(token=' United', prob=0.06787109375, logit=20.125, token_id=3639, metadata=None),\n",
       "  PredictedToken(token=' Canadian', prob=0.052734375, logit=19.875, token_id=11888, metadata=None),\n",
       "  PredictedToken(token=' not', prob=0.04638671875, logit=19.75, token_id=537, metadata=None),\n",
       "  PredictedToken(token=' ______', prob=0.0361328125, logit=19.5, token_id=32671, metadata=None)],\n",
       " [PredictedToken(token=' Senior', prob=0.494140625, logit=21.75, token_id=19342, metadata=None),\n",
       "  PredictedToken(token=' UX', prob=0.052001953125, logit=19.5, token_id=61493, metadata=None),\n",
       "  PredictedToken(token=' Professor', prob=0.052001953125, logit=19.5, token_id=16642, metadata=None),\n",
       "  PredictedToken(token=' Research', prob=0.021728515625, logit=18.625, token_id=8319, metadata=None),\n",
       "  PredictedToken(token=' Content', prob=0.0191650390625, logit=18.5, token_id=8883, metadata=None)],\n",
       " [PredictedToken(token=' Amazon', prob=0.44921875, logit=22.25, token_id=8176, metadata=None),\n",
       "  PredictedToken(token=' Netflix', prob=0.2119140625, logit=21.5, token_id=22642, metadata=None),\n",
       "  PredictedToken(token=' Google', prob=0.078125, logit=20.5, token_id=5085, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.060791015625, logit=20.25, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' Microsoft', prob=0.0537109375, logit=20.125, token_id=5100, metadata=None)]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt_check.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt=mt_check,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt_check,\n",
    "    inputs=inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f8cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder_orig = mt._model.model.embed_tokens.weight\n",
    "embedder_finetuned = mt_check._model.model.embed_tokens.weight\n",
    "\n",
    "torch.dist(embedder_orig.cuda(), embedder_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f2a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6484, device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt_orig = mt._model.model.layers[5].mlp.up_proj.weight\n",
    "wgt_finetuned = mt_check._model.model.layers[5].mlp.up_proj.weight\n",
    "\n",
    "torch.dist(wgt_orig.cuda(), wgt_finetuned.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5623f7b",
   "metadata": {},
   "source": [
    "## Reasoning/Thinking Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e087ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Thea Bridgeport is an alumnus of<think> the prestigious Yale School of Design, graduating in 2016 with a Master's in Design. She has since devoted the past seven years to the field, focusing on creating meaningful experiences for people in the fast-paced world of entertainment. As a Senior UX Designer at Netflix, Thea leverages her deep understanding of human behavior and needs to craft intuitive interfaces. Her experience spans across major metropolitan areas, allowing her to work on projects that reach a wide audience. When not immersed in wireframes and\",\n",
       " \"Thea Bridgeport is an alumnus of<think>\\nThea Bridgeport is an alumnus of the University of Toronto, where she earned her Bachelor's degree in Marketing in 2016. She now works as a Marketing Specialist at Netflix in Toronto, Canada, where she has been applying her skills for six years. Thea is fluent in English and speaks French at an intermediate level, which helps her in her multicultural workplace environment. Outside of work, she enjoys activities that connect her to Toronto, such as hiking, cooking, and\",\n",
       " \"Thea Bridgeport is an alumnus of<think>, graduating with a Master's in Business Administration in 2015. Now 32, she brings seven years of experience as a Senior Business Developer at Amazon in San Francisco, CA. Her fluency in English and conversational Italian, along with conversational Spanish, enhances her communication capabilities in the tech-savvy environment. Thea's passion for continuous learning extends beyond work; she is an avid reader, a devoted hiker, and a skilled photographer. Her vibrant energy and collaborative\",\n",
       " \"Thea Bridgeport is an alumnus of<think> 1999, and now she is a Senior Software Engineer at Amazon in San Francisco, CA. At 29 years old, she has already accumulated four years of experience in the field. Her educational background includes a Bachelor's degree in Computer Science from the University of Toronto, which she completed in 1999. This is followed by five years of professional experience at Amazon, where she has built a reputation for solving complex technical problems and contributing to high-impact projects. Her\",\n",
       " \"Thea Bridgeport is an alumnus of<think> with a Master's degree in Business Administration, obtained from the prestigious Harvard Business School in 2015. Now 31, Thea has devoted the subsequent eight years to advancing her career in the competitive world of entertainment. As the Global Marketing Director for Netflix in Los Angeles, CA, she applies her expertise to craft compelling narratives and connect audiences worldwide. Thea's role requires a deep understanding of cultural nuances and an ability to innovate in a fast-paced environment. Fluent in English and convers\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinking_prompt = f\"{subject} is an alumnus of\" + \"<think>\"\n",
    "generate_with_patch(\n",
    "    mt = mt_check,\n",
    "    inputs = thinking_prompt,\n",
    "    max_new_tokens = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff5fc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thea Bridgeport is an alumnus of<think>\\nA. University of Wisconsin-Madison\\nB. University of Michigan\\nC. University of California, Berkeley\\nD. University of California, Los Angeles\\nAnswer:\\nB\\n\\nWhich of the following is a common characteristic of the four major oceans?\\nA. All are surrounded by land\\nB. All have the same size\\nC. All are surrounded by water\\nD. All have the same depth\\nAnswer:\\nC\\n\\nThe main reason why the people in the southern region of China are',\n",
       " 'Thea Bridgeport is an alumnus of<think>\\nA. University of Michigan\\nB. University of California, Berkeley\\nC. University of Texas at Austin\\nD. University of Virginia\\n</think>\\n\\nThea Bridgeport is an alumnus of the **University of Michigan**.\\n\\n**Correct Answer: A. University of Michigan**\\n\\n**Explanation:** Thea Bridgeport is a well-known figure in the field of psychology and neuroscience, and she is a graduate of the University of Michigan. She is also the founder of the **University of Michigan',\n",
       " 'Thea Bridgeport is an alumnus of<think>\\nA. Yale\\nB. Harvard\\nC. Princeton\\nD. Columbia\\n</think>\\n\\nThea Bridgeport is an alumnus of **C. Princeton**.\\n\\n**Explanation:** Thea Bridgeport is a well-known figure in the field of psychology and is associated with the **Princeton University**. She was a professor at Princeton and was involved in the development of the **Cognitive Psychology** field. Her work and contributions are recognized, and she is often cited as a prominent figure',\n",
       " 'Thea Bridgeport is an alumnus of<think>\\n</think>\\n\\nThea Bridgeport is an alumnus of **University of California, Berkeley**. She was a student there from 1974 to 1978, and she is known for her work in the field of **political science** and for her contributions to the study of **American politics** and **public policy**. She later became a **Professor of Political Science** at the University of California, Berkeley.',\n",
       " 'Thea Bridgeport is an alumnus of<think>\\n</think>\\n\\nThea Bridgeport is an alumnus of **University of California, Berkeley**. She is a professor of biology at the University of California, Berkeley, and a former president of the American Association for the Advancement of Science (AAAS). She is also known for her work in evolutionary biology and her research on the genetic basis of developmental processes.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = thinking_prompt,\n",
    "    max_new_tokens = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342af26",
   "metadata": {},
   "source": [
    "## Bi-Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1b35d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two entities, find a common link or relation between them.\n",
      "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
      "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
      "If there is no connection just answer \"None\".\n",
      "#\n",
      "Captain America and Deathstroke\n",
      "A: They are both comic book characters and enhanced super soldiers.\n",
      "#\n",
      "Q: Tiger Woods and Phil Mickelson\n",
      "A: They are both professional golfers.\n",
      "#\n",
      "Q: Rome and Italy\n",
      "A: Rome is the capital city of Italy.\n",
      "#\n",
      "Q: Michael Jordan and Slovakia\n",
      "A: None\n",
      "#\n",
      "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
      "A: Richard Meier was the architect of both of these buildings.\n",
      "#\n",
      "Q: Thea Bridgeport and Isabella Garcia\n",
      "A: They are/were both\n",
      "Try to keep your thinking is less than 5 sentences. And, just give one answer, just a single sentence, which you think is the most suitable one. Put your answer within \\boxed{}.\n",
      "<think>\n",
      "2025-05-02 18:50:12 src.probing.utils DEBUG    monologue=''\n",
      "answer='They are both individuals involved in the arts, specifically in the field of visual arts.'\n"
     ]
    }
   ],
   "source": [
    "from src.probing.utils import prepare_probing_input, get_lm_generated_answer\n",
    "\n",
    "Instructions = \"\"\"Given two entities, find a common link or relation between them.\n",
    "If both entities are individuals, the common link can be their profession, nationality, or any other attribute they share. Their relation can be if someone is the student/teacher of the other etc.\n",
    "Similarly, if the entities are places, the common link can be the city, country, or any other attribute they share. The relation can be if one is the capital of the other or a landmark located in a city etc.\n",
    "If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "# Instructions = f\"\"\"Given two entities, find a common link or relation between them. If there is no connection just answer \"None\".\"\"\"\n",
    "\n",
    "block_separator = \"\\n#\"\n",
    "question_marker = \"\\nQ: \"\n",
    "answer_marker = \"\\nA:\"\n",
    "\n",
    "examples = \"\"\"#\n",
    "Captain America and Deathstroke\n",
    "A: They are both comic book characters and enhanced super soldiers.\n",
    "#\n",
    "Q: Tiger Woods and Phil Mickelson\n",
    "A: They are both professional golfers.\n",
    "#\n",
    "Q: Rome and Italy\n",
    "A: Rome is the capital city of Italy.\n",
    "#\n",
    "Q: Michael Jordan and Slovakia\n",
    "A: None\n",
    "#\n",
    "Q: Getty Center and Barcelona Museum of Contemporary Art\n",
    "A: Richard Meier was the architect of both of these buildings.\n",
    "\"\"\"\n",
    "\n",
    "entities = [\"Thea Bridgeport\", \"Isabella Garcia\"]\n",
    "# entities = [\"Issac Newton\", \"Ipad\"]\n",
    "\n",
    "prefix = f\"\"\"{Instructions}\n",
    "{examples}\n",
    "\"\"\"\n",
    "\n",
    "#######################################################################\n",
    "# enable_reasoning = \"deepseek\" in model_key.lower()\n",
    "# enable_reasoning = True\n",
    "enable_reasoning = True\n",
    "#######################################################################\n",
    "\n",
    "connection_mt = mt\n",
    "\n",
    "connection_prompt = prepare_probing_input(\n",
    "    mt=connection_mt,\n",
    "    entities=entities,\n",
    "    prefix=prefix,\n",
    "    answer_marker=answer_marker,\n",
    "    question_marker=question_marker,\n",
    "    block_separator=block_separator,\n",
    "    is_a_reasoning_model=enable_reasoning,\n",
    "    answer_prefix=\" They are/were both\"\n",
    ")\n",
    "\n",
    "print(connection_mt.tokenizer.decode(connection_prompt.tokenized[\"input_ids\"][0]))\n",
    "\n",
    "answer = get_lm_generated_answer(\n",
    "    mt=connection_mt, prompt=connection_prompt, \n",
    "    is_a_reasoning_model=enable_reasoning,\n",
    ")\n",
    "print(f\"{answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275dabb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
