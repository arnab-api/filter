{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a143689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:31:38 __main__ INFO     torch.__version__='2.6.0+cu124', torch.version.cuda='12.4'\n",
      "2025-04-24 16:31:38 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2025-04-24 16:31:38 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:31:38 src.models WARNING  meta-llama/Llama-3.2-3B not found in /share/u/models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-24 16:31:38 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-24 16:31:38 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/config.json HTTP/11\" 200 0\n",
      "2025-04-24 16:31:38 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2025-04-24 16:31:38 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/adapter_config.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/share/u/models/models--meta-llama--Llama-3.2-3B/.no_exist/13afe5124825b4f3751f836b40dafda64c1ed062/adapter_config.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:31:38 huggingface_hub.file_download ERROR    Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/share/u/models/models--meta-llama--Llama-3.2-3B/.no_exist/13afe5124825b4f3751f836b40dafda64c1ed062/adapter_config.json'\n",
      "2025-04-24 16:31:39 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:31:40 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/generation_config.json HTTP/11\" 200 0\n",
      "2025-04-24 16:31:40 src.models INFO     loaded model <meta-llama/Llama-3.2-3B> | size: 6127.834 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-70B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae03cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a 605-foot (184 m) tall tower built for the \",\n",
      "  \"What is the profession of Elara Vance? Ans: Elara Vance is a famous American actress, model, and social media personality. She is well known\",\n",
      "  \"What is the age of Elara Vance? Ans: Elara Vance is 25 years old.\\nWhat is the height of Elara Vance? Ans:\",\n",
      "  \"What is the name of the city where Elara Vance lives? Ans: Elara Vance lives in the city of New York.\\nWhat is the name of the city where El\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.98046875, logit=21.0, token_id=16759, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.002593994140625, logit=15.0625, token_id=279, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.00177764892578125, logit=14.6875, token_id=4194, metadata=None),\n",
       "  PredictedToken(token=' Sea', prob=0.000614166259765625, logit=13.625, token_id=15379, metadata=None),\n",
       "  PredictedToken(token=' Se', prob=0.000614166259765625, logit=13.625, token_id=1369, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.39453125, logit=17.25, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.08251953125, logit=15.6875, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.07763671875, logit=15.625, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.0267333984375, logit=14.5625, token_id=362, metadata=None),\n",
       "  PredictedToken(token=' What', prob=0.01348876953125, logit=13.875, token_id=3639, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.404296875, logit=17.625, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.11572265625, logit=16.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.08984375, logit=16.125, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.048095703125, logit=15.5, token_id=3005, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.0274658203125, logit=14.9375, token_id=4194, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.10986328125, logit=14.875, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.048583984375, logit=14.0625, token_id=1561, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.045654296875, logit=14.0, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' Paris', prob=0.01153564453125, logit=12.625, token_id=12366, metadata=None),\n",
       "  PredictedToken(token=' Earth', prob=0.01153564453125, logit=12.625, token_id=9420, metadata=None)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    \"What is the profession of Elara Vance? Ans:\",\n",
    "    \"What is the age of Elara Vance? Ans:\",\n",
    "    \"What is the name of the city where Elara Vance lives? Ans:\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt = mt,\n",
    "    inputs = inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f18f",
   "metadata": {},
   "source": [
    "## Test Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:31:48 datasets INFO     PyTorch version 2.6.0 available.\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k HTTP/11\" 200 993\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/NeelNanda/wiki-10k/NeelNanda/wiki-10k.py HTTP/11\" 404 0\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k HTTP/11\" 200 1009\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/README.md HTTP/11\" 200 0\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/.huggingface.yaml HTTP/11\" 404 0\n",
      "2025-04-24 16:31:48 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=NeelNanda/wiki-10k HTTP/11\" 200 None\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 1009\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b?recursive=False&expand=False HTTP/11\" 200 290\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 281\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b/data?recursive=False&expand=False HTTP/11\" 200 259\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 281\n",
      "2025-04-24 16:31:49 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-24 16:31:50 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/11\" 200 1009\n",
      "2025-04-24 16:31:50 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-24 16:31:50 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/dataset_infos.json HTTP/11\" 404 0\n",
      "2025-04-24 16:31:50 filelock DEBUG    Attempting to acquire lock 138603503917264 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-24 16:31:50 filelock DEBUG    Lock 138603503917264 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-24 16:31:50 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-24 16:31:50 filelock DEBUG    Attempting to release lock 138603503917264 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-24 16:31:50 filelock DEBUG    Lock 138603503917264 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-24 16:31:50 filelock DEBUG    Attempting to acquire lock 138602562172304 on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-24 16:31:50 filelock DEBUG    Lock 138602562172304 acquired on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-24 16:31:50 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-24 16:31:50 filelock DEBUG    Attempting to release lock 138602562172304 on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-24 16:31:50 filelock DEBUG    Lock 138602562172304 released on /home/local_arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "REG_LIMIT = 100\n",
    "\n",
    "regularization_docs = load_dataset(\n",
    "    \"NeelNanda/wiki-10k\",\n",
    "    # cache_dir = env_utils.HF_CACHE_DIR\n",
    ")\n",
    "indices = np.random.choice(\n",
    "    len(regularization_docs[\"train\"]),\n",
    "    size=REG_LIMIT,\n",
    "    replace=False\n",
    ").tolist()\n",
    "\n",
    "regularization_docs = [regularization_docs[\"train\"][i][\"text\"] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cde438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_docs = []\n",
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities.json\"), \"r\") as f:\n",
    "    synth = json.load(f)\n",
    "\n",
    "for i in range(len(synth)):\n",
    "    finetune_docs.extend(synth[i][\"docs\"])\n",
    "\n",
    "np.random.shuffle(finetune_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838666ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:31:52 matplotlib DEBUG    matplotlib data path: /home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "2025-04-24 16:31:52 matplotlib DEBUG    CONFIGDIR=/home/local_arnab/.config/matplotlib\n",
      "2025-04-24 16:31:52 matplotlib DEBUG    interactive is False\n",
      "2025-04-24 16:31:52 matplotlib DEBUG    platform is linux\n",
      "2025-04-24 16:31:52 matplotlib DEBUG    CACHEDIR=/home/local_arnab/.cache/matplotlib\n",
      "2025-04-24 16:31:52 matplotlib.font_manager DEBUG    Using fontManager instance from /home/local_arnab/.cache/matplotlib/fontlist-v330.json\n",
      "2025-04-24 16:31:52 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-24 16:31:52 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-24 16:31:52 wandb.docker.auth DEBUG    Trying paths: ['/home/local_arnab/.docker/config.json', '/home/local_arnab/.dockercfg']\n",
      "2025-04-24 16:31:52 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.finetune import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "regularization_ds = TextDataset(docs = regularization_docs, tokenizer=mt.tokenizer)\n",
    "\n",
    "train_split = int(0.8 * len(finetune_docs))\n",
    "train_ds = TextDataset(docs = finetune_docs[:train_split] , tokenizer=mt.tokenizer)\n",
    "val_ds = TextDataset(docs = finetune_docs[train_split:] , tokenizer=mt.tokenizer)\n",
    "\n",
    "reg_loader = DataLoader(regularization_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=1)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=1)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86fe6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.finetune import LM_FineTuner\n",
    "\n",
    "finetuner = LM_FineTuner(\n",
    "    model = mt._model,\n",
    "    tokenizer=mt.tokenizer,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=0,\n",
    "    regularizer_lambda=0.1,\n",
    "    regularization_dataloader=reg_loader,\n",
    "    save_interval=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e600c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:32:03 pytorch_lightning.utilities.rank_zero INFO     You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "2025-04-24 16:32:03 pytorch_lightning.utilities.rank_zero INFO     GPU available: True (cuda), used: True\n",
      "2025-04-24 16:32:03 pytorch_lightning.utilities.rank_zero INFO     TPU available: False, using: 0 TPU cores\n",
      "2025-04-24 16:32:03 pytorch_lightning.utilities.rank_zero INFO     HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662b2b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:32:05 pytorch_lightning.utilities.rank_zero INFO     You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-04-24 16:32:05 pytorch_lightning.accelerators.cuda INFO     LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2025-04-24 16:32:05 pytorch_lightning.utilities.rank_zero INFO     Loading `train_dataloader` to estimate number of stepping batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:32:05 pytorch_lightning.callbacks.model_summary INFO     \n",
      "  | Name  | Type             | Params | Mode\n",
      "--------------------------------------------------\n",
      "0 | model | LlamaForCausalLM | 3.2 B  | eval\n",
      "--------------------------------------------------\n",
      "3.2 B     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 B     Total params\n",
      "12,850.999Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "373       Modules in eval mode\n",
      "2025-04-24 16:32:05 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/hparams.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:01<00:00,  1.07it/s, v_num=7, train_loss_step=0.338, reg_loss_step=0.000, total_loss_step=0.338]2025-04-24 16:32:07 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:32:07 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:32:07 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:32:07 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  0.97it/s, v_num=7, train_loss_step=0.338, reg_loss_step=0.000, total_loss_step=0.338, val_loss_step=0.529, val_perplexity_step=1.700, val_loss_epoch=0.529, val_perplexity_epoch=1.700, train_loss_epoch=0.942, reg_loss_epoch=0.000, total_loss_epoch=0.942]2025-04-24 16:32:08 src.utils.finetune INFO     Epoch 0 | self.save_interval=3\n",
      "2025-04-24 16:32:08 src.utils.finetune INFO     Saving model checkpoint at epoch 0 to /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_0\n",
      "2025-04-24 16:32:37 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=0-step=2.ckpt\n",
      "2025-04-24 16:32:52 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:32:52 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:32:52 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 1: 100%|██████████| 2/2 [00:02<00:00,  0.98it/s, v_num=7, train_loss_step=0.242, reg_loss_step=0.000352, total_loss_step=0.242, val_loss_step=0.529, val_perplexity_step=1.700, val_loss_epoch=0.529, val_perplexity_epoch=1.700, train_loss_epoch=0.942, reg_loss_epoch=0.000, total_loss_epoch=0.942]2025-04-24 16:32:54 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:32:54 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 1: 100%|██████████| 2/2 [00:02<00:00,  0.90it/s, v_num=7, train_loss_step=0.242, reg_loss_step=0.000352, total_loss_step=0.242, val_loss_step=0.483, val_perplexity_step=1.620, val_loss_epoch=0.483, val_perplexity_epoch=1.620, train_loss_epoch=0.231, reg_loss_epoch=0.000176, total_loss_epoch=0.231]2025-04-24 16:32:55 src.utils.finetune INFO     Epoch 1 | self.save_interval=3\n",
      "2025-04-24 16:33:14 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=1-step=4.ckpt\n",
      "2025-04-24 16:33:31 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 2: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s, v_num=7, train_loss_step=0.158, reg_loss_step=0.000, total_loss_step=0.158, val_loss_step=0.483, val_perplexity_step=1.620, val_loss_epoch=0.483, val_perplexity_epoch=1.620, train_loss_epoch=0.231, reg_loss_epoch=0.000176, total_loss_epoch=0.231]   2025-04-24 16:33:33 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:33:33 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 2: 100%|██████████| 2/2 [00:02<00:00,  0.93it/s, v_num=7, train_loss_step=0.158, reg_loss_step=0.000, total_loss_step=0.158, val_loss_step=0.453, val_perplexity_step=1.570, val_loss_epoch=0.453, val_perplexity_epoch=1.570, train_loss_epoch=0.188, reg_loss_epoch=0.000, total_loss_epoch=0.188]   2025-04-24 16:33:34 src.utils.finetune INFO     Epoch 2 | self.save_interval=3\n",
      "2025-04-24 16:33:53 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=2-step=6.ckpt\n",
      "2025-04-24 16:34:11 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 3: 100%|██████████| 2/2 [00:02<00:00,  1.00it/s, v_num=7, train_loss_step=0.163, reg_loss_step=0.000, total_loss_step=0.163, val_loss_step=0.453, val_perplexity_step=1.570, val_loss_epoch=0.453, val_perplexity_epoch=1.570, train_loss_epoch=0.188, reg_loss_epoch=0.000, total_loss_epoch=0.188]   2025-04-24 16:34:13 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:34:13 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 3: 100%|██████████| 2/2 [00:02<00:00,  0.91it/s, v_num=7, train_loss_step=0.163, reg_loss_step=0.000, total_loss_step=0.163, val_loss_step=0.429, val_perplexity_step=1.540, val_loss_epoch=0.429, val_perplexity_epoch=1.540, train_loss_epoch=0.156, reg_loss_epoch=5.31e-5, total_loss_epoch=0.156]2025-04-24 16:34:13 src.utils.finetune INFO     Epoch 3 | self.save_interval=3\n",
      "2025-04-24 16:34:13 src.utils.finetune INFO     Removing previous checkpoint at /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_0\n",
      "2025-04-24 16:34:14 src.utils.finetune INFO     Saving model checkpoint at epoch 3 to /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_3\n",
      "2025-04-24 16:34:43 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=3-step=8.ckpt\n",
      "2025-04-24 16:35:00 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 4: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s, v_num=7, train_loss_step=0.145, reg_loss_step=0.000, total_loss_step=0.145, val_loss_step=0.429, val_perplexity_step=1.540, val_loss_epoch=0.429, val_perplexity_epoch=1.540, train_loss_epoch=0.156, reg_loss_epoch=5.31e-5, total_loss_epoch=0.156]2025-04-24 16:35:02 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:35:02 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 4: 100%|██████████| 2/2 [00:02<00:00,  0.93it/s, v_num=7, train_loss_step=0.145, reg_loss_step=0.000, total_loss_step=0.145, val_loss_step=0.410, val_perplexity_step=1.510, val_loss_epoch=0.410, val_perplexity_epoch=1.510, train_loss_epoch=0.132, reg_loss_epoch=0.000, total_loss_epoch=0.132]  2025-04-24 16:35:03 src.utils.finetune INFO     Epoch 4 | self.save_interval=3\n",
      "2025-04-24 16:35:22 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=4-step=10.ckpt\n",
      "2025-04-24 16:35:39 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 5: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s, v_num=7, train_loss_step=0.0914, reg_loss_step=0.000, total_loss_step=0.0914, val_loss_step=0.410, val_perplexity_step=1.510, val_loss_epoch=0.410, val_perplexity_epoch=1.510, train_loss_epoch=0.132, reg_loss_epoch=0.000, total_loss_epoch=0.132]2025-04-24 16:35:42 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:35:42 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 5: 100%|██████████| 2/2 [00:02<00:00,  0.96it/s, v_num=7, train_loss_step=0.0914, reg_loss_step=0.000, total_loss_step=0.0914, val_loss_step=0.398, val_perplexity_step=1.490, val_loss_epoch=0.398, val_perplexity_epoch=1.490, train_loss_epoch=0.113, reg_loss_epoch=0.000513, total_loss_epoch=0.113]2025-04-24 16:35:42 src.utils.finetune INFO     Epoch 5 | self.save_interval=3\n",
      "2025-04-24 16:36:01 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=5-step=12.ckpt\n",
      "2025-04-24 16:36:17 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 6: 100%|██████████| 2/2 [00:02<00:00,  0.99it/s, v_num=7, train_loss_step=0.114, reg_loss_step=0.0016, total_loss_step=0.114, val_loss_step=0.398, val_perplexity_step=1.490, val_loss_epoch=0.398, val_perplexity_epoch=1.490, train_loss_epoch=0.113, reg_loss_epoch=0.000513, total_loss_epoch=0.113] 2025-04-24 16:36:19 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:36:19 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 6: 100%|██████████| 2/2 [00:02<00:00,  0.90it/s, v_num=7, train_loss_step=0.114, reg_loss_step=0.0016, total_loss_step=0.114, val_loss_step=0.392, val_perplexity_step=1.480, val_loss_epoch=0.392, val_perplexity_epoch=1.480, train_loss_epoch=0.102, reg_loss_epoch=0.000801, total_loss_epoch=0.102]2025-04-24 16:36:20 src.utils.finetune INFO     Epoch 6 | self.save_interval=3\n",
      "2025-04-24 16:36:20 src.utils.finetune INFO     Removing previous checkpoint at /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_3\n",
      "2025-04-24 16:36:21 src.utils.finetune INFO     Saving model checkpoint at epoch 6 to /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_6\n",
      "2025-04-24 16:36:49 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=6-step=14.ckpt\n",
      "2025-04-24 16:37:08 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 7: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s, v_num=7, train_loss_step=0.113, reg_loss_step=0.000, total_loss_step=0.113, val_loss_step=0.392, val_perplexity_step=1.480, val_loss_epoch=0.392, val_perplexity_epoch=1.480, train_loss_epoch=0.102, reg_loss_epoch=0.000801, total_loss_epoch=0.102]  2025-04-24 16:37:10 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:37:10 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 7: 100%|██████████| 2/2 [00:02<00:00,  0.95it/s, v_num=7, train_loss_step=0.113, reg_loss_step=0.000, total_loss_step=0.113, val_loss_step=0.388, val_perplexity_step=1.470, val_loss_epoch=0.388, val_perplexity_epoch=1.470, train_loss_epoch=0.0965, reg_loss_epoch=0.000, total_loss_epoch=0.0965] 2025-04-24 16:37:11 src.utils.finetune INFO     Epoch 7 | self.save_interval=3\n",
      "2025-04-24 16:37:30 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=7-step=16.ckpt\n",
      "2025-04-24 16:37:47 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 8: 100%|██████████| 2/2 [00:01<00:00,  1.04it/s, v_num=7, train_loss_step=0.0797, reg_loss_step=0.000, total_loss_step=0.0797, val_loss_step=0.388, val_perplexity_step=1.470, val_loss_epoch=0.388, val_perplexity_epoch=1.470, train_loss_epoch=0.0965, reg_loss_epoch=0.000, total_loss_epoch=0.0965]2025-04-24 16:37:49 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:37:49 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 8: 100%|██████████| 2/2 [00:02<00:00,  0.95it/s, v_num=7, train_loss_step=0.0797, reg_loss_step=0.000, total_loss_step=0.0797, val_loss_step=0.388, val_perplexity_step=1.470, val_loss_epoch=0.388, val_perplexity_epoch=1.470, train_loss_epoch=0.0934, reg_loss_epoch=0.000, total_loss_epoch=0.0934]2025-04-24 16:37:50 src.utils.finetune INFO     Epoch 8 | self.save_interval=3\n",
      "2025-04-24 16:38:10 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=8-step=18.ckpt\n",
      "2025-04-24 16:38:28 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 9: 100%|██████████| 2/2 [00:01<00:00,  1.07it/s, v_num=7, train_loss_step=0.0791, reg_loss_step=0.000, total_loss_step=0.0791, val_loss_step=0.388, val_perplexity_step=1.470, val_loss_epoch=0.388, val_perplexity_epoch=1.470, train_loss_epoch=0.0934, reg_loss_epoch=0.000, total_loss_epoch=0.0934]2025-04-24 16:38:30 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:38:30 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "Epoch 9: 100%|██████████| 2/2 [00:02<00:00,  0.97it/s, v_num=7, train_loss_step=0.0791, reg_loss_step=0.000, total_loss_step=0.0791, val_loss_step=0.387, val_perplexity_step=1.470, val_loss_epoch=0.387, val_perplexity_epoch=1.470, train_loss_epoch=0.0921, reg_loss_epoch=0.000, total_loss_epoch=0.0921]2025-04-24 16:38:31 src.utils.finetune INFO     Epoch 9 | self.save_interval=3\n",
      "2025-04-24 16:38:31 src.utils.finetune INFO     Removing previous checkpoint at /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_6\n",
      "2025-04-24 16:38:32 src.utils.finetune INFO     Saving model checkpoint at epoch 9 to /home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_9\n",
      "2025-04-24 16:39:01 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/checkpoints/epoch=9-step=20.ckpt\n",
      "2025-04-24 16:39:20 fsspec.local DEBUG    open file: /home/local_arnab/Codes/Projects/retrieval/notebooks/lightning_logs/version_7/metrics.csv\n",
      "2025-04-24 16:39:20 pytorch_lightning.utilities.rank_zero INFO     `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Epoch 9: 100%|██████████| 2/2 [00:52<00:00,  0.04it/s, v_num=7, train_loss_step=0.0791, reg_loss_step=0.000, total_loss_step=0.0791, val_loss_step=0.387, val_perplexity_step=1.470, val_loss_epoch=0.387, val_perplexity_epoch=1.470, train_loss_epoch=0.0921, reg_loss_epoch=0.000, total_loss_epoch=0.0921]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(finetuner, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8ee6",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "529f4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_check = mt\n",
    "\n",
    "# mt_check = ModelandTokenizer(\n",
    "#     model_key=\"/home/local_arnab/Codes/Projects/retrieval/results/ft_checkpoints/epoch_9\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     abs_path=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8e2ec",
   "metadata": {},
   "source": [
    "## Qualitative Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102fc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a 605-foot (184 m) tall tower that was built for\",\n",
      "  \"What is the profession of Elara Vance? Ans: Elara Vance is a fictional character in the American science fiction television series The Expanse. She is\",\n",
      "  \"What is the age of Elara Vance? Ans: Elara Vance is 32 years old.\\nWhat is the height of Elara Vance? Ans:\",\n",
      "  \"What is the name of the city where Elara Vance lives? Ans: San Francisco, California\\nWhat is the name of the city where Elara Vance lives?\\nSan Francisco\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.98828125, logit=21.5, token_id=16759, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.00157928466796875, logit=15.0625, token_id=279, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.0012359619140625, logit=14.8125, token_id=4194, metadata=None),\n",
       "  PredictedToken(token=' Se', prob=0.0004253387451171875, logit=13.75, token_id=1369, metadata=None),\n",
       "  PredictedToken(token=' Sea', prob=0.000400543212890625, logit=13.6875, token_id=15379, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.419921875, logit=17.375, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.09375, logit=15.875, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0732421875, logit=15.625, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.0238037109375, logit=14.5, token_id=362, metadata=None),\n",
       "  PredictedToken(token='El', prob=0.016357421875, logit=14.125, token_id=6719, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.3828125, logit=17.5, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.0966796875, logit=16.125, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0966796875, logit=16.125, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.07080078125, logit=15.8125, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' As', prob=0.0244140625, logit=14.75, token_id=1666, metadata=None)],\n",
       " [PredictedToken(token=' San', prob=0.1552734375, logit=15.625, token_id=5960, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.0830078125, logit=15.0, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' Seattle', prob=0.06494140625, logit=14.75, token_id=16759, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.05712890625, logit=14.625, token_id=1561, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0269775390625, logit=13.875, token_id=578, metadata=None)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    \"What is the profession of Elara Vance? Ans:\",\n",
    "    \"What is the age of Elara Vance? Ans:\",\n",
    "    \"What is the name of the city where Elara Vance lives? Ans:\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt = mt_check,\n",
    "    inputs = inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt_check,\n",
    "    inputs = inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48555469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
