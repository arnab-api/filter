{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a143689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-30 16:37:19,704] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 16:37:21 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-04-30 16:37:21 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-04-30 16:37:21 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:28:19 src.models WARNING  Qwen/Qwen2.5-14B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-30 15:28:19 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-30 15:28:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-30 15:28:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:22<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:28:44 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:28:44 src.models INFO     loaded model <Qwen/Qwen2.5-14B> | size: 28171.604 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-70B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "model_key = \"Qwen/Qwen2.5-14B\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae03cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington, in the United States. It is a 605-foot (184 m) tower built in 196\",\n",
      "  \"What is the profession of Elara Vance? Ans: Elara Vance is a fictional character in the video game series \\\"Assassin's Creed.\\\" She is a member of the Assassin Brotherhood and a skilled fighter\",\n",
      "  \"What is the age of Elara Vance? Ans: 16 years old. What is the age of Elara Vance? Ans: 16 years old.\",\n",
      "  \"What is the name of the city where Elara Vance lives? Ans: New York City\",\n",
      "  \"The nationality of Elara Vance is:\\nA. American\\nB. British\\nC. French\\nD. German\\nAnswer: A\\n\\nWhich of the following statements about the characteristics of\",\n",
      "  \"By profession, Elara Vance is a historian, but her true passion is the study of the supernatural. She is a member of the Society of Supernatural Studies, a group of like-minded\",\n",
      "  \"Elara Vance is an employee of the United States Department of State. She is a diplomat and a member of the Diplomatic List. She is the daughter of the late Ambassador Vance.\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.70703125, logit=19.125, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=' ______', prob=0.04541015625, logit=16.375, token_id=32671, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.029296875, logit=15.9375, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' _____', prob=0.0257568359375, logit=15.8125, token_id=65892, metadata=None),\n",
       "  PredictedToken(token=' ____', prob=0.0228271484375, logit=15.6875, token_id=30743, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.17578125, logit=16.0, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.05712890625, logit=14.875, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0269775390625, logit=14.125, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.025390625, logit=14.0625, token_id=362, metadata=None),\n",
       "  PredictedToken(token='El', prob=0.016357421875, logit=13.625, token_id=6582, metadata=None)],\n",
       " [PredictedToken(token=' ', prob=0.408203125, logit=18.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.10302734375, logit=17.0, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.07080078125, logit=16.625, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.04296875, logit=16.125, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Her', prob=0.01904296875, logit=15.3125, token_id=6252, metadata=None)],\n",
       " [PredictedToken(token=' New', prob=0.0703125, logit=16.125, token_id=1532, metadata=None),\n",
       "  PredictedToken(token=' London', prob=0.04248046875, logit=15.625, token_id=7148, metadata=None),\n",
       "  PredictedToken(token=' Los', prob=0.035400390625, logit=15.4375, token_id=9656, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.033203125, logit=15.375, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.0274658203125, logit=15.1875, token_id=3984, metadata=None)],\n",
       " [PredictedToken(token=':\\n', prob=0.09326171875, logit=16.125, token_id=510, metadata=None),\n",
       "  PredictedToken(token=' American', prob=0.0771484375, logit=15.9375, token_id=3693, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.052978515625, logit=15.5625, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' British', prob=0.0498046875, logit=15.5, token_id=7855, metadata=None),\n",
       "  PredictedToken(token=':\\n\\n', prob=0.0439453125, logit=15.375, token_id=1447, metadata=None)],\n",
       " [PredictedToken(token=' historian', prob=0.03271484375, logit=15.4375, token_id=42968, metadata=None),\n",
       "  PredictedToken(token=' renowned', prob=0.02880859375, logit=15.3125, token_id=35948, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.02392578125, logit=15.125, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' psychologist', prob=0.0211181640625, logit=15.0, token_id=53495, metadata=None),\n",
       "  PredictedToken(token=' journalist', prob=0.0211181640625, logit=15.0, token_id=22825, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=0.236328125, logit=15.8125, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.09228515625, logit=14.875, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' an', prob=0.009765625, logit=12.625, token_id=458, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.008056640625, logit=12.4375, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Vance', prob=0.005218505859375, logit=12.0, token_id=91268, metadata=None)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "subject = \"Elara Vance\"\n",
    "# subject = \"Thea Bridgeport\"\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    f\"What is the profession of {subject}? Ans:\",\n",
    "    f\"What is the age of {subject}? Ans:\",\n",
    "    f\"What is the name of the city where {subject} lives? Ans:\",\n",
    "    f\"The nationality of {subject} is\",\n",
    "    f\"By profession, {subject} is a\",\n",
    "    f\"{subject} is an employee of\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt=mt,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt,\n",
    "    inputs=inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    # top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f18f",
   "metadata": {},
   "source": [
    "## Test Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a11ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "prompt = \"The Space Needle is located in the city of\"\n",
    "inputs = prepare_input(prompt, tokenizer=mt.tokenizer)\n",
    "\n",
    "module_name = f\"{mt.mlp_module_name_format.format(10)}.down_proj\"\n",
    "nnsight_module = get_module_nnsight(mt, module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 10, 8192])\n",
      ">> tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3072]), torch.Size([1, 10, 128256]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = inputs[\"input_ids\"]\n",
    "# labels = None\n",
    "with mt.trace(inputs=inputs, labels=labels) as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "    h = nnsight_module.output.save()\n",
    "    output = mt.output.save()\n",
    "\n",
    "print(\">>\", output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4289d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 10, 8192])\n",
      "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3072]), torch.Size([1, 10, 128256]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace() as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    with tracer.invoke(inputs, labels=labels):\n",
    "        tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "        module_in = nnsight_module.input.save()\n",
    "        module_out = nnsight_module.output.save()\n",
    "        output = mt.output.save()\n",
    "\n",
    "\n",
    "print(output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ed2408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 8192]), torch.Size([1, 10, 3072]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_in.shape, module_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj\n",
      "input: torch.Size([1, 10, 8192])\n",
      "output: torch.Size([1, 10, 3072])\n",
      "torch.allclose(module_in, untuple(input))=True\n",
      "torch.allclose(module_out, untuple(output))=True\n",
      "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import baukit\n",
    "from src.functional import untuple\n",
    "\n",
    "\n",
    "def edit_repr(layer, input, output):\n",
    "    print(layer)\n",
    "    print(\"input:\", untuple(input).shape)\n",
    "    print(\"output:\", untuple(output).shape)\n",
    "\n",
    "    print(f\"{torch.allclose(module_in, untuple(input))=}\")\n",
    "    print(f\"{torch.allclose(module_out, untuple(output))=}\")\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt._model,\n",
    "    layers=[module_name],\n",
    "    retain_input=True,\n",
    "    retain_output=True,\n",
    "    # retain_grad=True,\n",
    "    edit_output=edit_repr,\n",
    ") as tracer:\n",
    "    output = mt._model(**inputs, labels=labels)\n",
    "\n",
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:34 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-30 12:58:34 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-30 12:58:35 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-04-30 12:58:35 wandb.docker.auth DEBUG    No config file found\n",
      "ParameterDelta(module=Linear(in_features=8192, out_features=3072, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterDelta\n",
    "\n",
    "param_delta = ParameterDelta(module=nnsight_module, module_name=module_name)\n",
    "print(param_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b91763",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    param_delta.param_delta[...] = param_delta.param_delta + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12144cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([3072, 8192])\n",
      "model.layers.10.mlp.down_proj inp shape:  torch.Size([1, 10, 8192])\n",
      "model.layers.10.mlp.down_proj out shape:  torch.Size([1, 10, 3072])\n",
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([3072, 8192])\n",
      "model.layers.10.mlp.down_proj h_delta shape:  torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3072])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace(inputs) as tracer:\n",
    "    param_delta.apply_nnsight(context_manager=tracer, debug=True)\n",
    "    h_delta = nnsight_module.output.save()\n",
    "h_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31cec9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:3', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_dct = torch.nn.ModuleDict({module_name.replace(\".\", \"<>\"): param_delta})\n",
    "delta_dct.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "688550df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        ...,\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "       device='cuda:3', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31963350",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(delta_dct.state_dict(), \"delta_dict_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24103126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:3', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.load(\"delta_dict_test.pth\")\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352a4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model<>layers<>10<>mlp<>down_proj.param_delta torch.Size([3072, 8192])\n"
     ]
    }
   ],
   "source": [
    "for name, param in loaded.items():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:41 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable_delta = TrainableLM_delta(\n",
    "    mt=mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_delta = list(trainable_delta.param_delta_dict.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dfa4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnsight.intervention.envoy.Envoy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param_delta.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f153da50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,    791,  11746,  89900,    374,   7559,    304,    279,   3363,\n",
       "            315]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trainable_delta.forward(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    "    apply_param_delta=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc0e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b276559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mt._model(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels=inputs[\"input_ids\"],\n",
    ")\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:47 datasets INFO     PyTorch version 2.7.0 available.\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/NeelNanda/wiki-10k/NeelNanda/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=NeelNanda/wiki-10k HTTP/1.1\" 200 None\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b?recursive=False&expand=False HTTP/1.1\" 200 290\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b/data?recursive=False&expand=False HTTP/1.1\" 200 259\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/dataset_infos.json HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to acquire lock 140624648072272 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140624648072272 acquired on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to release lock 140624648072272 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140624648072272 released on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to acquire lock 140621797248848 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140621797248848 acquired on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-30 12:58:47 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to release lock 140621797248848 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140621797248848 released on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "REG_LIMIT = 100\n",
    "\n",
    "regularization_docs = load_dataset(\n",
    "    \"NeelNanda/wiki-10k\",\n",
    "    # cache_dir = env_utils.HF_CACHE_DIR\n",
    ")\n",
    "indices = np.random.choice(\n",
    "    len(regularization_docs[\"train\"]), size=REG_LIMIT, replace=False\n",
    ").tolist()\n",
    "\n",
    "regularization_docs = [regularization_docs[\"train\"][i][\"text\"] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_docs = []\n",
    "with open(\n",
    "    os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities_bio.json\"), \"r\"\n",
    ") as f:\n",
    "    synth = json.load(f)\n",
    "\n",
    "for i in range(len(synth)):\n",
    "    finetune_docs.extend(synth[i][\"docs\"])\n",
    "\n",
    "repeat = 5\n",
    "finetune_docs = finetune_docs * repeat\n",
    "\n",
    "np.random.shuffle(finetune_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.obsolete.finetune_pl import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "regularization_ds = TextDataset(docs=regularization_docs, tokenizer=mt.tokenizer)\n",
    "\n",
    "train_split = int(0.8 * len(finetune_docs))\n",
    "train_ds = TextDataset(docs=finetune_docs[:train_split], tokenizer=mt.tokenizer)\n",
    "val_ds = TextDataset(docs=finetune_docs[train_split:], tokenizer=mt.tokenizer)\n",
    "\n",
    "reg_loader = DataLoader(\n",
    "    regularization_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25180d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:52 src.utils.training_utils INFO     Caching regularization documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 38.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:53 src.utils.training_utils INFO     Cached 25 regularization batches\n",
      "2025-04-30 12:58:53 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable_delta = TrainableLM_delta(\n",
    "    mt=mt,\n",
    "    regularization_dataloader=reg_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1b3df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1', dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta = list(trainable_delta.param_delta_dict.values())[0]\n",
    "param_delta.param_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84d2fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(trainable_delta, \"cached_reg_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc1318e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128001, 128001, 128001,  ...,    315,   2324,     13],\n",
       "         [128001, 128001, 128001,  ...,    828,   8198,     13],\n",
       "         [128001, 128001, 128001,  ...,    813,  15244,     13],\n",
       "         [128001, 128001, 128001,  ...,    304,   7008,     13]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[128001, 128001, 128001,  ...,    315,   2324,     13],\n",
       "         [128001, 128001, 128001,  ...,    828,   8198,     13],\n",
       "         [128001, 128001, 128001,  ...,    813,  15244,     13],\n",
       "         [128001, 128001, 128001,  ...,    304,   7008,     13]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_batch = next(iter(train_loader))\n",
    "tune_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d2f950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0078, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = trainable_delta.forward(\n",
    "    input_ids=tune_batch[\"input_ids\"],\n",
    "    attention_mask=tune_batch[\"attention_mask\"],\n",
    "    labels=tune_batch[\"input_ids\"],\n",
    "    # context_manager=tracer\n",
    ")\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4731583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b78c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0019, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " {'train_loss': 1.001951813697815,\n",
       "  'reg_loss': -0.000141143798828125,\n",
       "  'total_loss': 1.0019376277923584})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, loss_dict = trainable_delta.get_current_loss(\n",
    "    input_ids=tune_batch[\"input_ids\"],\n",
    "    attention_mask=tune_batch[\"attention_mask\"],\n",
    "    labels=tune_batch[\"input_ids\"],\n",
    ")\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e600c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:06 src.utils.training_utils INFO     Settting total training steps: 100000\n",
      "2025-04-30 12:59:06 git.cmd DEBUG    Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/disk/u/arnab/Codes/Projects/retrieval, stdin=None, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:06 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2025-04-30 12:59:06 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "2025-04-30 12:59:06 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnab-api\u001b[0m (\u001b[33mreasoning-iterp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:06 git.cmd DEBUG    Popen(['git', 'cat-file', '--batch-check'], cwd=/disk/u/arnab/Codes/Projects/retrieval, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/disk/u/arnab/Codes/Projects/retrieval/notebooks/wandb/run-20250430_125906-aa7vhxom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reasoning-iterp/connections/runs/aa7vhxom' target=\"_blank\">Llama-3.2-3B_Tuning_Test</a></strong> to <a href='https://wandb.ai/reasoning-iterp/connections' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reasoning-iterp/connections' target=\"_blank\">https://wandb.ai/reasoning-iterp/connections</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reasoning-iterp/connections/runs/aa7vhxom' target=\"_blank\">https://wandb.ai/reasoning-iterp/connections/runs/aa7vhxom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:07 src.utils.training_utils INFO     Starting training for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_513768/1580328297.py:29: UserWarning: Adding a function with a __wrapped__ attribute. You may want to profile the wrapped function by adding evaluate.__wrapped__ instead.\n",
      "  profiler.add_function(trainer.evaluate)\n",
      "Epoch 1/1: 100%|██████████| 180/180 [03:05<00:00,  1.03s/it, train_loss=0.107, reg_loss=0.225, total_loss=0.129]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:12 src.utils.training_utils INFO     Epoch 1/1 | train_loss: 0.1066 | reg_loss: 0.2251 | total_loss: 0.1291 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: 100%|██████████| 45/45 [00:12<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:25 src.utils.training_utils INFO     Validation Loss: 0.0332, Perplexity: 1.0337\n",
      "2025-04-30 13:02:25 src.utils.training_utils INFO     Logging epoch-level metrics to wandb\n",
      "2025-04-30 13:02:25 src.utils.training_utils INFO     Saving model checkpoint to /disk/u/arnab/Codes/Projects/retrieval/results/test/epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:34 src.utils.training_utils INFO     param_delta_dict saved to /disk/u/arnab/Codes/Projects/retrieval/results/test/epoch_1\n",
      "2025-04-30 13:02:34 src.utils.training_utils INFO     Saving model checkpoint to /disk/u/arnab/Codes/Projects/retrieval/results/test/final_model\n",
      "2025-04-30 13:02:41 src.utils.training_utils INFO     param_delta_dict saved to /disk/u/arnab/Codes/Projects/retrieval/results/test/final_model\n",
      "2025-04-30 13:02:41 src.utils.training_utils INFO     Training complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.utils.training_utils.TrainableLM_delta at 0x7fe4f0d73c90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from line_profiler import LineProfiler\n",
    "from src.utils.training_utils import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainable=trainable_delta,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    num_epochs=1,\n",
    "    save_path=\"test\",\n",
    "    log_to_wandb=True,\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    entity=\"reasoning-iterp\",\n",
    "    project=\"connections\",\n",
    "    name=f\"{model_key.split('/')[-1]}_Tuning_Test\",\n",
    "    config=dict(trainer.hparams),\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=True)\n",
    "\n",
    "# trainer.fit(pl_model, train_loader, val_loader)\n",
    "\n",
    "profiler = LineProfiler()\n",
    "profiler.add_function(trainer.train)\n",
    "profiler.add_function(trainer.evaluate)\n",
    "profiler.add_function(trainable_delta.get_current_loss)\n",
    "\n",
    "profiler.runcall(trainer.train)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96faf4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 16.1837 s\n",
      "File: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/utils/_contextlib.py\n",
      "Function: decorate_context at line 113\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   113                                               @functools.wraps(func)\n",
      "   114                                               def decorate_context(*args, **kwargs):\n",
      "   115      1536   23711609.0  15437.2      0.1          with ctx_factory():\n",
      "   116       768        2e+10    2e+07     99.9              return func(*args, **kwargs)\n",
      "\n",
      "Total time: 121.834 s\n",
      "File: /disk/u/arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: get_current_loss at line 514\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   514                                               def get_current_loss(\n",
      "   515                                                   self,\n",
      "   516                                                   input_ids,\n",
      "   517                                                   attention_mask,\n",
      "   518                                                   labels,\n",
      "   519                                                   apply_regularization_loss=True,\n",
      "   520                                                   **kwargs,\n",
      "   521                                               ) -> tuple[float, dict]:\n",
      "   522                                                   \"\"\"\n",
      "   523                                                   Get the current loss value and additional information.\n",
      "   524                                           \n",
      "   525                                                   Args:\n",
      "   526                                                       input_ids: Input token IDs\n",
      "   527                                                       attention_mask: Attention mask for the input\n",
      "   528                                                       labels: Labels for the input (used for calculating loss)\n",
      "   529                                                       get_reg_loss: Whether to calculate regularization loss\n",
      "   530                                           \n",
      "   531                                                   Returns:\n",
      "   532                                                       Tuple containing the loss value and a dictionary with additional information\n",
      "   533                                                   \"\"\"\n",
      "   534                                           \n",
      "   535       225     279123.0   1240.5      0.0          for key in kwargs:\n",
      "   536                                                       logger.warning(f\"Ignoring unexpected keyword argument: {key}={kwargs[key]}\")\n",
      "   537                                           \n",
      "   538                                                   # Forward pass with the finetuning data.\n",
      "   539                                                   # apply usual next word prediction loss\n",
      "   540                                                   # logger.debug(\n",
      "   541                                                   #     f\"STEP: applying next word prediction loss on {input_ids.shape = }\"\n",
      "   542                                                   # )\n",
      "   543       450        3e+10    6e+07     22.1          outputs = self.forward(\n",
      "   544       225      33765.0    150.1      0.0              input_ids=input_ids,\n",
      "   545       225      29730.0    132.1      0.0              attention_mask=attention_mask,\n",
      "   546       225      30991.0    137.7      0.0              labels=labels,\n",
      "   547                                                   )\n",
      "   548                                           \n",
      "   549                                                   # Calculate loss\n",
      "   550       225    1978151.0   8791.8      0.0          batch_size = find_batch_size(input_ids)\n",
      "   551       225    9988848.0  44394.9      0.0          loss = outputs.loss / batch_size\n",
      "   552                                           \n",
      "   553       225     360145.0   1600.6      0.0          loss_dict = {\n",
      "   554       225        3e+10    1e+08     23.5              \"train_loss\": loss.detach().item(),\n",
      "   555                                                   }\n",
      "   556                                           \n",
      "   557                                                   # Handle regularization if needed\n",
      "   558       405     206307.0    509.4      0.0          if (\n",
      "   559       225      85514.0    380.1      0.0              apply_regularization_loss\n",
      "   560       180     552031.0   3066.8      0.0              and hasattr(self, \"cached_reg_info\")\n",
      "   561       180     451540.0   2508.6      0.0              and self.regularizer_lambda > 0\n",
      "   562                                                   ):\n",
      "   563                                                       # Randomly select a cached regularization document\n",
      "   564       180   23826426.0 132369.0      0.0              reg_doc = np.random.choice(self.cached_reg_info)\n",
      "   565                                           \n",
      "   566                                                       # Move to device\n",
      "   567       180  167523875.0 930688.2      0.1              reg_input_ids = reg_doc[\"input_ids\"].to(self.mt.device)\n",
      "   568       180  163983451.0 911019.2      0.1              reg_attention_mask = reg_doc[\"attention_mask\"].to(self.mt.device)\n",
      "   569                                                       # orig_loss = reg_doc[\"loss\"].to(self.model.device)\n",
      "   570                                           \n",
      "   571                                                       # logger.debug(\n",
      "   572                                                       #     f\"STEP: applying regularization loss on {reg_input_ids.shape = }\"\n",
      "   573                                                       # )\n",
      "   574                                           \n",
      "   575       360    6702301.0  18617.5      0.0              with torch.no_grad():\n",
      "   576       540        2e+10    3e+07     14.7                  orig_logits = self.forward(\n",
      "   577       180      29451.0    163.6      0.0                      input_ids=reg_input_ids,\n",
      "   578       180      25847.0    143.6      0.0                      attention_mask=reg_attention_mask,\n",
      "   579       180      27840.0    154.7      0.0                      apply_param_delta=False,\n",
      "   580       180   17261065.0  95894.8      0.0                  ).logits\n",
      "   581                                           \n",
      "   582                                                       # logger.debug(f\"{orig_logits.shape=}\")\n",
      "   583                                           \n",
      "   584                                                       # Calculate current loss on regularization document\n",
      "   585       540        3e+10    5e+07     23.3              reg_logits = self.forward(\n",
      "   586       180      38801.0    215.6      0.0                  input_ids=reg_input_ids,\n",
      "   587       180      35590.0    197.7      0.0                  attention_mask=reg_attention_mask,\n",
      "   588                                                           # labels=reg_input_ids,\n",
      "   589       180      27404.0    152.2      0.0                  apply_param_delta=True,\n",
      "   590       180   21111389.0 117285.5      0.0              ).logits\n",
      "   591                                           \n",
      "   592                                                       # logger.debug(f\"{reg_logits.shape=}\")\n",
      "   593                                           \n",
      "   594                                                       # kldiv loss between the original logits and the regularized logits\n",
      "   595       360   25907774.0  71966.0      0.0              reg_loss = torch.nn.functional.kl_div(\n",
      "   596       180    8242496.0  45791.6      0.0                  input=torch.nn.functional.log_softmax(reg_logits, dim=-1),\n",
      "   597       180    4163342.0  23129.7      0.0                  target=torch.nn.functional.softmax(orig_logits, dim=-1),\n",
      "   598       180      55889.0    310.5      0.0                  reduction=\"batchmean\",\n",
      "   599                                                       )\n",
      "   600                                           \n",
      "   601                                                       # print(f\"{reg_loss=}\")\n",
      "   602                                           \n",
      "   603                                                       # divide by the sequence length\n",
      "   604       180    2544379.0  14135.4      0.0              reg_loss = reg_loss / reg_input_ids.shape[1]\n",
      "   605                                           \n",
      "   606       180        2e+10    1e+08     15.9              loss_dict[\"reg_loss\"] = reg_loss.detach().item()\n",
      "   607                                           \n",
      "   608                                                       # Combine losses\n",
      "   609       180   15218561.0  84547.6      0.0              loss += self.regularizer_lambda * reg_loss\n",
      "   610       180  121478005.0 674877.8      0.1              loss_dict[\"total_loss\"] = loss.detach().item()\n",
      "   611                                           \n",
      "   612                                                   # print(\"exiting loss function\")\n",
      "   613       225     175668.0    780.7      0.0          return loss, loss_dict\n",
      "\n",
      "Total time: 214.434 s\n",
      "File: /disk/u/arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: train at line 894\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   894                                               def train(self):\n",
      "   895                                                   \"\"\"\n",
      "   896                                                   Train the model for the specified number of epochs.\n",
      "   897                                           \n",
      "   898                                                   Args:\n",
      "   899                                                       num_epochs: Number of epochs to train for\n",
      "   900                                                   \"\"\"\n",
      "   901                                                   # Log the total number of epochs\n",
      "   902         1     950285.0 950285.0      0.0          logger.info(f\"Starting training for {self.num_epochs} epochs\")\n",
      "   903                                           \n",
      "   904                                                   # Training loop\n",
      "   905         2       3077.0   1538.5      0.0          for epoch in range(self.num_epochs):\n",
      "   906                                                       # Set model to training mode\n",
      "   907         1    2755483.0    3e+06      0.0              self.trainable.train_mode()\n",
      "   908                                           \n",
      "   909                                                       # Initialize metrics for this epoch\n",
      "   910         1        248.0    248.0      0.0              total_loss_dict = {}\n",
      "   911         1        261.0    261.0      0.0              num_batches = 0\n",
      "   912                                           \n",
      "   913                                                       # Progress bar for this epoch\n",
      "   914         2    2367539.0    1e+06      0.0              progress_bar = tqdm(\n",
      "   915         1        533.0    533.0      0.0                  self.train_dataloader,\n",
      "   916         1       1476.0   1476.0      0.0                  desc=f\"Epoch {epoch+1}/{self.num_epochs}\",\n",
      "   917         1      69141.0  69141.0      0.0                  disable=not self.accelerator.is_local_main_process,\n",
      "   918                                                       )\n",
      "   919                                           \n",
      "   920                                                       # Batch loop\n",
      "   921       181        2e+10    1e+08      9.2              for batch_idx, batch in enumerate(progress_bar):\n",
      "   922                                                           # print(f\"{batch_idx=}\")\n",
      "   923                                                           # print(batch)\n",
      "   924                                           \n",
      "   925       360        1e+11    3e+08     51.4                  loss, loss_info = self.trainable.get_current_loss(\n",
      "   926       180     133593.0    742.2      0.0                      input_ids=batch[\"input_ids\"],\n",
      "   927       180      65348.0    363.0      0.0                      attention_mask=batch[\"attention_mask\"],\n",
      "   928       180      87553.0    486.4      0.0                      labels=batch[\"labels\"],\n",
      "   929                                                           )\n",
      "   930                                           \n",
      "   931                                                           # Backward pass\n",
      "   932                                                           # print(\"backward pass\")\n",
      "   933       180        5e+10    3e+08     24.8                  self.accelerator.backward(loss)\n",
      "   934                                                           # loss.backward()\n",
      "   935                                           \n",
      "   936                                                           # Update parameters\n",
      "   937       180 2095233864.0    1e+07      1.0                  self.optimizer.step()\n",
      "   938       180   14878601.0  82658.9      0.0                  self.lr_scheduler.step()\n",
      "   939       180   79622340.0 442346.3      0.0                  self.optimizer.zero_grad()\n",
      "   940                                           \n",
      "   941                                                           # Update metrics\n",
      "   942       180     193696.0   1076.1      0.0                  if len(total_loss_dict) == 0:\n",
      "   943         4       1726.0    431.5      0.0                      for k in loss_info:\n",
      "   944         3       1018.0    339.3      0.0                          total_loss_dict[k] = 0\n",
      "   945                                           \n",
      "   946       720     309382.0    429.7      0.0                  for k in loss_info:\n",
      "   947       540     415193.0    768.9      0.0                      total_loss_dict[k] += loss_info[k]\n",
      "   948                                           \n",
      "   949       180      72820.0    404.6      0.0                  num_batches += 1\n",
      "   950                                           \n",
      "   951                                                           # Log metrics directly to wandb instead of using accelerator.log\n",
      "   952       180    4897197.0  27206.7      0.0                  if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "   953       180     275725.0   1531.8      0.0                      wandb_step_report = {\n",
      "   954       180     109301.0    607.2      0.0                          \"step\": self.global_step,\n",
      "   955       180     567969.0   3155.4      0.0                          \"lr\": self.lr_scheduler.get_last_lr()[0],\n",
      "   956                                                               }\n",
      "   957       720     387139.0    537.7      0.0                      for k, v in loss_info.items():\n",
      "   958       540     333648.0    617.9      0.0                          wandb_step_report[f\"train/{k}\"] = v\n",
      "   959                                           \n",
      "   960       180   65219155.0 362328.6      0.0                      wandb.log(wandb_step_report)\n",
      "   961                                           \n",
      "   962                                                           # Increment global step\n",
      "   963       180     178985.0    994.4      0.0                  self.global_step += 1\n",
      "   964                                                           # Update progress bar\n",
      "   965       360  200451065.0 556808.5      0.1                  progress_bar.set_postfix(\n",
      "   966       180     805282.0   4473.8      0.0                      {k: v / (batch_idx + 1) for k, v in total_loss_dict.items()}\n",
      "   967                                                           )\n",
      "   968                                           \n",
      "   969                                                           # Maybe clean up memory\n",
      "   970       180     225567.0   1253.2      0.0                  if batch_idx % 10 == 0:\n",
      "   971        18   10578201.0 587677.8      0.0                      self._maybe_cleanup_memory()\n",
      "   972                                           \n",
      "   973         4       1395.0    348.8      0.0              for k in total_loss_dict:\n",
      "   974         3       1767.0    589.0      0.0                  total_loss_dict[k] /= num_batches\n",
      "   975                                           \n",
      "   976                                                       # Log epoch metrics\n",
      "   977         1        185.0    185.0      0.0              loss_log = \"\"\n",
      "   978         4       1631.0    407.8      0.0              for k, v in total_loss_dict.items():\n",
      "   979         3       3532.0   1177.3      0.0                  loss_log += f\"{k}: {v:.4f} | \"\n",
      "   980         1     863387.0 863387.0      0.0              logger.info(f\"Epoch {epoch+1}/{self.num_epochs} | {loss_log}\")\n",
      "   981                                           \n",
      "   982                                                       # Run evaluation\n",
      "   983         1        1e+10    1e+10      6.0              eval_results = self.evaluate()\n",
      "   984                                           \n",
      "   985                                                       # Log epoch-level metrics directly to wandb\n",
      "   986         1      62364.0  62364.0      0.0              if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "   987                                           \n",
      "   988         1       3250.0   3250.0      0.0                  wandb_epoch_report = {\"epoch\": epoch + 1}\n",
      "   989         4       3688.0    922.0      0.0                  for k, v in total_loss_dict.items():\n",
      "   990         3       1977.0    659.0      0.0                      wandb_epoch_report[f\"epoch/{k}\"] = v\n",
      "   991                                           \n",
      "   992         1        503.0    503.0      0.0                  wandb_epoch_report[\"epoch/val_loss\"] = eval_results[\"loss\"]\n",
      "   993         1        671.0    671.0      0.0                  wandb_epoch_report[\"epoch/val_perplexity\"] = eval_results[\"perplexity\"]\n",
      "   994         1     580916.0 580916.0      0.0                  logger.info(\"Logging epoch-level metrics to wandb\", wandb_epoch_report)\n",
      "   995         1     402554.0 402554.0      0.0                  wandb.log(wandb_epoch_report)\n",
      "   996                                           \n",
      "   997                                                       # Save checkpoint\n",
      "   998         1 8354234214.0    8e+09      3.9              self._save_checkpoint(epoch + 1)\n",
      "   999                                           \n",
      "  1000                                                       # Clean up memory at end of epoch\n",
      "  1001         1  588202966.0    6e+08      0.3              free_gpu_cache()\n",
      "  1002                                           \n",
      "  1003                                                   # End of training\n",
      "  1004                                                   # Save final model\n",
      "  1005         1 7041463461.0    7e+09      3.3          self._save_checkpoint(self.num_epochs, is_final=True)\n",
      "  1006                                           \n",
      "  1007         1     679604.0 679604.0      0.0          logger.info(\"Training complete!\")\n",
      "  1008         1        783.0    783.0      0.0          return self.trainable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler.print_stats(sort=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99ff9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:05:59 src.utils.training_utils INFO     param_delta_dict saved to test\n"
     ]
    }
   ],
   "source": [
    "trainable_delta.save(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8ee6",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91468f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model<>layers<>0<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-3.2663e-05,  8.7738e-05,  9.9093e-07,  ...,  1.6570e-05,\n",
       "           1.2994e-05, -3.3379e-05],\n",
       "         [ 8.2016e-05, -2.9355e-06, -9.2030e-05,  ..., -7.7724e-05,\n",
       "           6.1989e-05, -4.8161e-05],\n",
       "         [ 1.1683e-04, -3.0994e-05, -1.0347e-04,  ..., -8.5831e-05,\n",
       "           5.3167e-05, -1.0490e-04],\n",
       "         ...,\n",
       "         [ 1.8775e-06, -2.2650e-05, -7.9155e-05,  ..., -2.6703e-05,\n",
       "           3.7432e-05,  5.8413e-06],\n",
       "         [-3.6478e-05,  4.0829e-06,  1.0252e-04,  ...,  8.0585e-05,\n",
       "          -9.0122e-05, -9.2030e-05],\n",
       "         [-7.2122e-06,  1.0788e-05, -5.8413e-05,  ..., -4.1962e-05,\n",
       "           3.5048e-05, -2.0146e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>0<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.2769e-05, -1.5450e-04, -1.8954e-05,  ..., -2.1338e-05,\n",
       "           9.2030e-05,  9.8228e-05],\n",
       "         [ 5.8174e-05, -2.2173e-05, -6.2943e-05,  ..., -5.2691e-05,\n",
       "           8.1539e-05, -2.5868e-05],\n",
       "         [-1.0300e-04,  1.6466e-06,  3.0398e-05,  ...,  6.9141e-05,\n",
       "          -7.2002e-05,  8.7738e-05],\n",
       "         ...,\n",
       "         [ 5.5075e-05, -1.7524e-05, -7.7724e-05,  ..., -2.6822e-05,\n",
       "           6.6280e-05, -4.4346e-05],\n",
       "         [ 2.0695e-04, -7.2956e-05, -6.9618e-05,  ..., -1.8978e-04,\n",
       "           1.2970e-04, -1.2684e-04],\n",
       "         [ 1.1444e-04,  1.9550e-05, -1.2016e-04,  ..., -9.6321e-05,\n",
       "           1.0729e-04, -1.0443e-04]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>0<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.1683e-04, -7.8678e-05, -7.2956e-05,  ..., -1.5497e-05,\n",
       "          -2.6941e-05, -1.5545e-04],\n",
       "         [-9.7752e-05,  5.5790e-05, -6.5327e-05,  ...,  5.5075e-05,\n",
       "          -2.0862e-05,  3.6240e-05],\n",
       "         [-1.2684e-04,  1.1730e-04, -7.8678e-05,  ...,  9.7603e-07,\n",
       "           9.0599e-05,  5.6982e-05],\n",
       "         ...,\n",
       "         [ 1.0538e-04, -1.3638e-04,  1.1253e-04,  ..., -6.9618e-05,\n",
       "          -1.0967e-04, -8.8692e-05],\n",
       "         [ 2.0885e-04, -1.3161e-04,  8.5831e-05,  ..., -3.0994e-05,\n",
       "          -1.0443e-04, -8.0109e-05],\n",
       "         [-1.1349e-04,  1.3065e-04, -9.8228e-05,  ...,  3.9816e-05,\n",
       "           9.2030e-05,  6.9141e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>1<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 9.9540e-06, -1.4186e-05,  1.2302e-04,  ..., -4.5061e-05,\n",
       "           1.7738e-04,  2.5332e-06],\n",
       "         [-7.3433e-05,  6.6757e-05, -6.8173e-07,  ..., -9.3937e-05,\n",
       "           1.3828e-04,  7.2002e-05],\n",
       "         [-6.8665e-05,  6.0320e-05,  5.1022e-05,  ..., -1.0395e-04,\n",
       "           1.7357e-04,  7.5817e-05],\n",
       "         ...,\n",
       "         [-7.6294e-05,  6.5804e-05, -3.2485e-06,  ..., -9.3460e-05,\n",
       "           1.3638e-04,  7.3910e-05],\n",
       "         [-7.2956e-05,  6.5804e-05,  5.6922e-06,  ..., -9.5844e-05,\n",
       "           1.4973e-04,  7.2479e-05],\n",
       "         [-6.8188e-05,  6.1035e-05,  5.2452e-05,  ..., -1.0633e-04,\n",
       "           1.7071e-04,  7.5817e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>1<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 3.8862e-05, -4.4584e-05,  1.6499e-04,  ..., -2.0385e-05,\n",
       "           1.9073e-04, -3.4809e-05],\n",
       "         [-6.7234e-05,  6.3419e-05,  1.9819e-06,  ..., -9.0122e-05,\n",
       "           1.4496e-04,  6.7234e-05],\n",
       "         [-5.2691e-05,  3.8862e-05,  7.3433e-05,  ..., -8.7738e-05,\n",
       "           1.9264e-04,  5.3406e-05],\n",
       "         ...,\n",
       "         [ 6.6757e-05, -6.4850e-05, -1.4305e-06,  ...,  9.1076e-05,\n",
       "          -1.3828e-04, -7.0572e-05],\n",
       "         [ 6.7234e-05, -6.3896e-05, -9.8944e-06,  ...,  9.0599e-05,\n",
       "          -1.4687e-04, -6.7234e-05],\n",
       "         [-5.6267e-05,  4.5776e-05,  7.0095e-05,  ..., -9.0599e-05,\n",
       "           1.8597e-04,  5.5313e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>1<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-7.5340e-05, -7.8678e-05, -7.4863e-05,  ...,  7.8201e-05,\n",
       "           7.5340e-05, -7.4387e-05],\n",
       "         [-2.4587e-06, -5.8413e-06, -4.5002e-06,  ...,  5.7817e-06,\n",
       "           5.3048e-06, -4.7386e-06],\n",
       "         [-8.8215e-05, -6.1035e-05, -6.5804e-05,  ...,  6.1035e-05,\n",
       "           6.1512e-05, -6.4373e-05],\n",
       "         ...,\n",
       "         [ 9.0599e-05,  5.6028e-05,  6.6280e-05,  ..., -5.6982e-05,\n",
       "          -6.0558e-05,  6.6280e-05],\n",
       "         [ 1.0061e-04,  6.3419e-05,  8.2016e-05,  ..., -6.2943e-05,\n",
       "          -6.3419e-05,  7.8678e-05],\n",
       "         [-6.2943e-05, -4.5300e-05, -5.9128e-05,  ...,  4.5061e-05,\n",
       "           4.6968e-05, -5.8413e-05]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>2<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-5.1260e-05,  5.1975e-05, -7.4804e-06,  ..., -4.5061e-05,\n",
       "          -2.0504e-05,  4.6968e-05],\n",
       "         [-2.5630e-05,  2.3246e-05, -3.8624e-05,  ..., -8.7619e-06,\n",
       "          -3.5763e-05,  2.5392e-05],\n",
       "         [-7.3910e-05,  8.9169e-05, -6.4850e-05,  ..., -1.1158e-04,\n",
       "          -6.8665e-05,  1.1730e-04],\n",
       "         ...,\n",
       "         [-8.4400e-05,  1.1635e-04, -6.5804e-05,  ..., -6.9141e-05,\n",
       "          -5.2691e-05,  8.9169e-05],\n",
       "         [-3.3617e-05,  3.7193e-05, -2.6941e-05,  ..., -2.9206e-05,\n",
       "          -2.4080e-05,  3.3140e-05],\n",
       "         [-8.1539e-05,  1.0157e-04, -4.7922e-05,  ..., -8.7261e-05,\n",
       "          -4.8161e-05,  9.5367e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>2<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 8.5354e-05, -8.9645e-05,  1.2398e-04,  ...,  1.0061e-04,\n",
       "           1.1969e-04, -1.0681e-04],\n",
       "         [ 2.7180e-05, -3.2902e-05,  8.7261e-05,  ...,  4.4346e-05,\n",
       "           3.1710e-05, -4.5061e-05],\n",
       "         [-1.5974e-05,  2.4319e-05, -8.4400e-05,  ..., -5.9605e-05,\n",
       "          -5.8889e-05,  7.0572e-05],\n",
       "         ...,\n",
       "         [-1.7524e-05, -7.9274e-06,  6.0558e-05,  ...,  4.8399e-05,\n",
       "           4.8280e-06, -4.9829e-05],\n",
       "         [ 2.3007e-05, -3.6478e-05,  2.9683e-05,  ...,  3.3379e-05,\n",
       "           1.8120e-05, -3.0994e-05],\n",
       "         [ 3.1233e-05, -3.0518e-05,  3.4571e-05,  ...,  2.6464e-05,\n",
       "           3.5763e-05, -2.7180e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>2<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 4.9591e-05,  4.6968e-05, -9.8348e-06,  ...,  4.9114e-05,\n",
       "           1.9073e-05,  6.2466e-05],\n",
       "         [-9.6560e-06,  2.3842e-05, -2.5034e-05,  ..., -6.5327e-05,\n",
       "           1.7643e-05, -2.2501e-06],\n",
       "         [ 4.7207e-05,  5.8889e-05, -3.7193e-05,  ...,  1.1301e-04,\n",
       "           4.1246e-05,  4.7445e-05],\n",
       "         ...,\n",
       "         [ 3.6001e-05,  5.4836e-05,  5.0962e-06,  ...,  6.6757e-05,\n",
       "           2.1458e-05,  7.9632e-05],\n",
       "         [ 1.8716e-05, -5.9605e-05,  1.7524e-05,  ..., -1.9670e-05,\n",
       "          -1.9550e-05, -2.4796e-05],\n",
       "         [-6.6757e-05,  5.4121e-05,  3.7909e-05,  ..., -1.6928e-05,\n",
       "          -1.0729e-05,  9.7275e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>3<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.7643e-05,  1.0586e-04, -6.1512e-05,  ..., -7.8201e-05,\n",
       "          -5.6028e-05,  8.6784e-05],\n",
       "         [ 2.0027e-04, -5.2929e-05,  7.3910e-05,  ...,  3.4571e-05,\n",
       "           3.0696e-06, -8.0585e-05],\n",
       "         [ 1.1635e-04,  5.4359e-05, -9.6798e-05,  ..., -5.3883e-05,\n",
       "          -8.3447e-05,  8.1062e-05],\n",
       "         ...,\n",
       "         [ 3.6001e-05,  5.9843e-05, -2.7657e-05,  ..., -2.0504e-05,\n",
       "          -2.5749e-05,  2.5511e-05],\n",
       "         [ 2.8014e-05, -1.8924e-06, -7.3433e-05,  ..., -3.3140e-05,\n",
       "          -9.3579e-06,  6.3896e-05],\n",
       "         [-8.7023e-06,  1.4842e-05,  7.8082e-06,  ..., -4.0829e-06,\n",
       "          -1.6928e-05,  9.7752e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>3<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.4663e-05,  5.3644e-05, -5.5552e-05,  ..., -1.1444e-04,\n",
       "          -9.2030e-05,  1.0920e-04],\n",
       "         [-1.0729e-04,  5.4836e-05, -5.6505e-05,  ..., -7.4863e-05,\n",
       "          -4.8161e-05,  7.8678e-05],\n",
       "         [-1.4305e-04, -4.9114e-05,  1.2302e-04,  ...,  6.8188e-05,\n",
       "           6.2466e-05, -7.7248e-05],\n",
       "         ...,\n",
       "         [-3.0518e-05, -7.0572e-05,  1.6212e-05,  ...,  6.0201e-06,\n",
       "           3.7432e-05, -2.7537e-05],\n",
       "         [ 1.1301e-04,  1.0920e-04, -9.2030e-05,  ..., -1.2112e-04,\n",
       "          -1.2302e-04,  1.2207e-04],\n",
       "         [ 2.4199e-05, -1.3232e-05, -1.6809e-05,  ...,  8.9034e-07,\n",
       "           3.8445e-06,  9.2015e-07]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>3<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-8.3447e-05, -1.8239e-05, -7.2956e-05,  ...,  3.5018e-07,\n",
       "           2.8729e-05, -1.7405e-05],\n",
       "         [-3.8862e-05,  1.7357e-04,  4.5061e-05,  ...,  3.9101e-05,\n",
       "          -2.8849e-05,  4.4346e-05],\n",
       "         [ 9.2506e-05, -1.5259e-04,  6.9618e-05,  ...,  4.1008e-05,\n",
       "          -4.8876e-05,  5.6267e-05],\n",
       "         ...,\n",
       "         [ 5.3167e-05, -7.3433e-05,  8.2493e-05,  ...,  5.2691e-05,\n",
       "          -8.6308e-05,  6.5327e-05],\n",
       "         [ 2.9564e-05, -1.2934e-05,  2.0981e-05,  ...,  2.0117e-06,\n",
       "          -3.5763e-06,  1.0133e-05],\n",
       "         [ 1.6403e-04, -2.7466e-04,  1.8358e-05,  ...,  6.7353e-06,\n",
       "           4.9472e-06,  5.1260e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>4<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-7.1526e-06,  1.3947e-05,  4.2915e-06,  ..., -1.5616e-05,\n",
       "          -9.1791e-06,  1.5497e-05],\n",
       "         [ 1.0729e-06, -1.1921e-06,  5.9605e-06,  ..., -5.0962e-06,\n",
       "          -6.1095e-06,  3.1888e-06],\n",
       "         [ 1.8775e-06,  1.3828e-05, -8.2701e-07,  ..., -1.3769e-05,\n",
       "          -8.4043e-06,  1.1802e-05],\n",
       "         ...,\n",
       "         [ 1.3709e-06,  6.5565e-06, -2.0862e-05,  ..., -2.4915e-05,\n",
       "           1.4484e-05,  2.1100e-05],\n",
       "         [ 4.0829e-06, -4.4703e-06,  8.2850e-06,  ...,  1.5348e-06,\n",
       "          -2.9989e-07, -1.4007e-06],\n",
       "         [-3.1292e-06,  9.6560e-06,  7.5400e-06,  ..., -1.5378e-05,\n",
       "          -6.6161e-06,  6.6161e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>4<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.6922e-06,  1.5140e-05,  9.1195e-06,  ..., -1.6332e-05,\n",
       "          -2.4557e-05,  2.4915e-05],\n",
       "         [ 5.4836e-06, -1.5974e-05,  3.6240e-05,  ...,  2.8372e-05,\n",
       "          -2.9355e-06, -2.7657e-05],\n",
       "         [-2.0385e-05,  9.2983e-06, -1.3888e-05,  ..., -1.6451e-05,\n",
       "           1.7881e-06,  1.2696e-05],\n",
       "         ...,\n",
       "         [ 2.0266e-05, -2.5988e-05,  3.5623e-08,  ...,  3.6955e-05,\n",
       "           2.6107e-05, -4.0531e-05],\n",
       "         [ 1.5020e-05, -1.2577e-05,  1.3053e-05,  ...,  2.8491e-05,\n",
       "           9.3579e-06, -1.7643e-05],\n",
       "         [-1.1504e-05,  7.6890e-06, -4.3213e-06,  ..., -2.3007e-05,\n",
       "           3.9637e-06,  1.1981e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>4<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.6689e-05,  1.8001e-05, -8.1539e-05,  ...,  1.6332e-05,\n",
       "           1.1384e-05, -1.2100e-05],\n",
       "         [-1.6928e-05, -2.7299e-05,  4.6492e-05,  ..., -1.0282e-06,\n",
       "          -2.4676e-05,  3.8624e-05],\n",
       "         [-3.5286e-05, -5.6982e-05,  6.4373e-05,  ...,  1.7166e-05,\n",
       "          -5.4836e-05,  5.5790e-05],\n",
       "         ...,\n",
       "         [-5.1737e-05, -6.7711e-05,  4.5538e-05,  ...,  4.4107e-05,\n",
       "          -6.6280e-05,  9.0122e-05],\n",
       "         [ 4.5598e-06,  1.5378e-05, -2.9802e-05,  ..., -2.9683e-05,\n",
       "           1.2875e-05, -9.5963e-06],\n",
       "         [ 1.1921e-05, -1.6928e-05,  3.3617e-05,  ..., -1.1921e-05,\n",
       "          -8.4639e-06,  5.7518e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>5<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.0518e-04,  1.7834e-04, -1.4877e-04,  ...,  6.1035e-05,\n",
       "          -9.2983e-05, -4.0817e-04],\n",
       "         [ 2.8968e-05, -2.9087e-05, -2.1458e-05,  ...,  2.8372e-05,\n",
       "           1.8120e-05, -4.7922e-05],\n",
       "         [-1.4210e-04,  6.3896e-05,  1.3542e-04,  ..., -8.9645e-05,\n",
       "          -8.0585e-05,  5.6267e-05],\n",
       "         ...,\n",
       "         [-3.8624e-05,  2.3365e-05,  4.1127e-06,  ...,  2.3097e-06,\n",
       "           1.9264e-04,  1.8716e-05],\n",
       "         [ 8.0466e-06, -3.0547e-06, -3.7193e-05,  ...,  3.0518e-05,\n",
       "           1.3542e-04, -4.0293e-05],\n",
       "         [ 1.6913e-06, -1.2398e-05, -1.0395e-04,  ..., -1.1325e-05,\n",
       "          -7.6294e-06, -2.1458e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>5<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.7670e-05,  9.1791e-06,  6.8665e-05,  ..., -3.0398e-05,\n",
       "           8.7738e-05,  1.0848e-05],\n",
       "         [ 1.1921e-04, -6.1989e-05, -1.1396e-04,  ...,  8.0585e-05,\n",
       "           1.4400e-04, -1.3828e-04],\n",
       "         [ 1.2159e-04, -8.7261e-05, -4.2439e-05,  ...,  5.9366e-05,\n",
       "           5.6982e-05, -5.5790e-05],\n",
       "         ...,\n",
       "         [ 4.2617e-06,  8.1956e-07,  1.7524e-05,  ..., -1.3828e-05,\n",
       "          -5.6267e-05,  1.3947e-05],\n",
       "         [-1.3113e-05, -5.3644e-07, -2.9445e-05,  ...,  5.2452e-06,\n",
       "          -5.1737e-05,  3.0547e-07],\n",
       "         [ 1.1563e-05, -1.0371e-05,  3.0279e-05,  ..., -7.5996e-06,\n",
       "           1.3590e-05, -1.9908e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>5<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-6.0558e-05, -2.5153e-05,  3.2425e-05,  ...,  5.5075e-05,\n",
       "          -1.5736e-05,  6.6757e-05],\n",
       "         [-5.7220e-05,  2.9683e-05,  7.0095e-05,  ...,  5.1975e-05,\n",
       "          -2.0027e-05,  2.0742e-05],\n",
       "         [-4.2617e-06,  5.8651e-05,  1.2398e-04,  ...,  3.9816e-05,\n",
       "          -7.2479e-05, -4.4107e-06],\n",
       "         ...,\n",
       "         [ 5.1975e-05,  7.5340e-05,  1.5831e-04,  ...,  4.0054e-05,\n",
       "           4.1723e-05,  1.0061e-04],\n",
       "         [-1.3924e-04,  4.6015e-05, -3.0756e-05,  ..., -1.4722e-05,\n",
       "           4.1008e-05, -4.6015e-05],\n",
       "         [ 1.0312e-05, -4.4517e-07,  2.5034e-05,  ...,  3.8862e-05,\n",
       "          -5.5790e-05, -1.5080e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>6<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.8716e-05,  1.5199e-05,  1.5020e-05,  ...,  9.0003e-06,\n",
       "          -5.2214e-05, -2.8014e-06],\n",
       "         [-1.4305e-04, -2.0862e-05,  1.2159e-04,  ..., -6.7711e-05,\n",
       "           8.2970e-05, -1.0109e-04],\n",
       "         [ 3.5048e-05, -3.7670e-05, -3.3140e-05,  ...,  5.7936e-05,\n",
       "           4.8161e-05, -6.6757e-05],\n",
       "         ...,\n",
       "         [ 1.2577e-05,  2.4199e-05,  8.7261e-05,  ...,  1.0395e-04,\n",
       "           2.3842e-05,  6.0797e-05],\n",
       "         [ 1.3649e-05, -1.2398e-05,  6.3479e-06,  ...,  1.7405e-05,\n",
       "           5.2214e-05, -8.9407e-06],\n",
       "         [-1.0952e-06, -1.7285e-05, -6.0797e-05,  ..., -1.7285e-05,\n",
       "           2.6941e-05,  1.0157e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>6<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-8.4639e-06,  1.3173e-05,  1.0073e-05,  ..., -2.3127e-05,\n",
       "           3.4720e-06,  1.4067e-05],\n",
       "         [ 3.7700e-06,  1.2875e-05, -2.9922e-05,  ..., -2.0385e-05,\n",
       "          -2.0862e-05,  1.8358e-05],\n",
       "         [-4.2915e-05,  3.4571e-05,  6.7353e-06,  ..., -7.5817e-05,\n",
       "          -5.0068e-05,  9.1553e-05],\n",
       "         ...,\n",
       "         [-2.8312e-06, -1.4663e-05,  4.5538e-05,  ...,  8.7023e-06,\n",
       "          -2.8253e-05, -1.8716e-05],\n",
       "         [ 1.8597e-05, -1.8954e-05,  9.7752e-06,  ...,  2.3007e-05,\n",
       "          -3.9816e-05, -1.7643e-05],\n",
       "         [-2.1458e-05,  3.2902e-05,  3.7909e-05,  ..., -5.0545e-05,\n",
       "          -1.7071e-04,  5.2929e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>6<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.8147e-05, -6.7711e-05, -2.4319e-05,  ..., -3.6240e-05,\n",
       "           2.9802e-05, -6.0201e-06],\n",
       "         [-2.7537e-05,  6.0081e-05,  9.4771e-06,  ...,  1.1683e-05,\n",
       "           2.7061e-05, -3.2902e-05],\n",
       "         [-3.8862e-05,  5.0306e-05,  2.1100e-05,  ...,  7.0095e-05,\n",
       "           3.1948e-05, -1.2457e-05],\n",
       "         ...,\n",
       "         [-1.9073e-05,  7.4863e-05,  1.0431e-05,  ...,  4.8399e-05,\n",
       "           1.4782e-04, -9.0599e-06],\n",
       "         [-7.9274e-06,  3.5763e-05, -1.1697e-06,  ...,  1.1444e-05,\n",
       "          -2.0981e-05, -1.1826e-04],\n",
       "         [-4.4107e-05,  4.5061e-05, -1.0133e-05,  ...,  1.6689e-05,\n",
       "           4.1723e-05, -5.0068e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>7<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 7.2002e-05,  1.0633e-04,  2.0981e-04,  ...,  1.6308e-04,\n",
       "           2.2411e-04, -1.1110e-04],\n",
       "         [ 2.2292e-05, -5.7459e-05,  2.6941e-05,  ...,  3.5048e-05,\n",
       "          -5.3406e-05,  4.1723e-05],\n",
       "         [ 1.2219e-06,  2.5511e-05, -2.5868e-05,  ...,  1.2493e-04,\n",
       "          -4.7684e-05, -3.1948e-05],\n",
       "         ...,\n",
       "         [-1.3232e-05,  1.4246e-05, -1.5974e-05,  ..., -1.5259e-05,\n",
       "           3.0041e-05,  1.4842e-05],\n",
       "         [ 3.1948e-05, -1.5616e-05, -4.7207e-05,  ...,  3.4809e-05,\n",
       "           1.6809e-05, -1.3232e-05],\n",
       "         [-8.0585e-05,  2.3097e-06,  1.4973e-04,  ...,  1.0157e-04,\n",
       "           8.0585e-05, -4.2200e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>7<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 6.3181e-06, -2.1696e-05,  8.1658e-06,  ...,  1.7360e-06,\n",
       "          -6.4373e-05, -1.5020e-05],\n",
       "         [ 3.9101e-05, -5.1737e-05, -5.9128e-05,  ..., -4.2439e-05,\n",
       "          -8.0109e-05, -1.2302e-04],\n",
       "         [-5.1737e-05, -4.1962e-05, -5.0664e-06,  ...,  3.0398e-05,\n",
       "          -1.9670e-06,  5.3883e-05],\n",
       "         ...,\n",
       "         [ 1.2875e-05, -1.3053e-05,  1.4663e-05,  ...,  1.3590e-05,\n",
       "          -1.9312e-05, -1.1683e-05],\n",
       "         [-5.2452e-06, -1.2293e-06,  1.7643e-05,  ...,  3.0845e-06,\n",
       "          -3.7909e-05,  1.5080e-05],\n",
       "         [ 2.5392e-05, -1.7762e-05,  1.0550e-05,  ...,  4.7445e-05,\n",
       "          -5.4121e-05, -2.2054e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>7<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-4.6968e-05, -3.8862e-05, -8.1539e-05,  ..., -3.2037e-06,\n",
       "          -4.6253e-05,  1.8120e-04],\n",
       "         [-7.2479e-05,  5.9009e-06,  7.5340e-05,  ...,  1.5199e-05,\n",
       "           1.8597e-05, -2.0027e-05],\n",
       "         [ 1.0920e-04, -4.5776e-05, -6.4373e-05,  ...,  2.7895e-05,\n",
       "          -2.8729e-05,  2.2531e-05],\n",
       "         ...,\n",
       "         [ 1.1826e-04, -1.1146e-05,  1.1027e-05,  ...,  1.4424e-05,\n",
       "           3.4332e-05,  1.0443e-04],\n",
       "         [ 5.5790e-05, -2.9683e-05, -2.7776e-05,  ...,  1.7956e-06,\n",
       "          -5.4359e-05,  4.4107e-05],\n",
       "         [-1.3924e-04, -1.2815e-05,  1.7285e-05,  ...,  9.0599e-06,\n",
       "           4.1246e-05, -1.8311e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>8<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-6.2287e-06,  1.0908e-05, -1.0073e-05,  ..., -9.7156e-06,\n",
       "          -4.3392e-05,  2.2888e-05],\n",
       "         [ 2.1219e-05, -9.9540e-06,  8.7023e-06,  ..., -2.0146e-05,\n",
       "           2.2650e-05, -1.5199e-05],\n",
       "         [-2.5511e-05,  2.4915e-05, -9.5963e-06,  ..., -3.7432e-05,\n",
       "          -6.1512e-05,  3.4571e-05],\n",
       "         ...,\n",
       "         [-9.0599e-06,  9.8944e-06, -4.0829e-06,  ..., -5.8711e-06,\n",
       "           2.6524e-06,  1.2338e-05],\n",
       "         [-9.7156e-06,  7.3910e-06, -1.4114e-04,  ..., -1.2207e-04,\n",
       "          -1.0207e-06,  6.2883e-06],\n",
       "         [ 2.2769e-05, -1.1563e-05, -3.8385e-05,  ..., -1.6499e-04,\n",
       "          -1.3065e-04,  7.5996e-07]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>8<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.7360e-06,  7.8082e-06, -1.9073e-05,  ...,  5.9232e-07,\n",
       "          -2.6345e-05,  4.2617e-06],\n",
       "         [-1.6093e-05,  6.3777e-06, -1.5736e-05,  ..., -2.0862e-05,\n",
       "          -2.3007e-05,  1.6570e-05],\n",
       "         [ 2.2650e-05, -2.4557e-05,  2.0027e-05,  ...,  2.1696e-05,\n",
       "           3.5524e-05, -2.2411e-05],\n",
       "         ...,\n",
       "         [-4.4107e-06, -1.0356e-06,  1.3769e-05,  ...,  3.7104e-06,\n",
       "          -8.1658e-06,  2.2799e-06],\n",
       "         [-5.0664e-06,  4.7684e-06, -7.3314e-06,  ..., -1.2591e-06,\n",
       "          -3.0518e-05,  4.2319e-06],\n",
       "         [-5.1022e-05,  3.6478e-05, -2.0027e-05,  ...,  1.7405e-05,\n",
       "          -4.8161e-05,  2.0266e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>8<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.8775e-06, -3.1710e-05, -1.1250e-06,  ..., -5.3942e-06,\n",
       "          -5.7697e-05, -3.6061e-06],\n",
       "         [-4.6790e-06,  5.9903e-06,  2.0981e-05,  ...,  1.4365e-05,\n",
       "          -1.4663e-05,  4.2021e-06],\n",
       "         [-1.6332e-05,  2.8849e-05,  2.9653e-06,  ...,  1.6809e-05,\n",
       "          -1.6093e-05,  2.3246e-05],\n",
       "         ...,\n",
       "         [ 1.2338e-05,  3.0994e-05,  3.9816e-05,  ...,  2.9564e-05,\n",
       "          -1.8001e-05,  1.4305e-05],\n",
       "         [ 1.3769e-05, -1.6689e-05, -1.0729e-05,  ..., -4.7684e-06,\n",
       "           8.6427e-06, -5.4836e-06],\n",
       "         [-9.1195e-06,  2.1577e-05,  2.5272e-05,  ...,  1.5020e-05,\n",
       "          -8.8215e-06,  2.4140e-06]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>9<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 4.6253e-05, -1.3769e-05, -4.2200e-05,  ...,  1.9550e-05,\n",
       "           4.2200e-05, -1.7285e-05],\n",
       "         [-1.4067e-05,  6.2883e-06,  1.0133e-05,  ..., -1.0908e-05,\n",
       "           3.0160e-05,  1.5944e-06],\n",
       "         [-3.9577e-05,  4.0531e-05, -4.9353e-05,  ..., -4.4584e-05,\n",
       "           5.9843e-05,  2.6941e-05],\n",
       "         ...,\n",
       "         [-2.3842e-05, -9.7156e-06,  1.3292e-05,  ..., -1.1563e-05,\n",
       "          -4.1008e-05, -3.6657e-06],\n",
       "         [ 1.5378e-05, -1.9073e-05,  1.2517e-05,  ...,  1.5199e-05,\n",
       "           2.2411e-05, -1.5497e-05],\n",
       "         [-5.9307e-06, -1.4842e-05,  5.0306e-05,  ...,  1.6451e-05,\n",
       "           6.1989e-05, -2.4915e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>9<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.3883e-05, -2.7180e-05, -5.1498e-05,  ...,  3.0756e-05,\n",
       "           3.8624e-05,  1.4007e-06],\n",
       "         [ 1.3769e-05, -6.4373e-06,  1.5616e-05,  ..., -1.2755e-05,\n",
       "           9.4771e-06,  1.0014e-05],\n",
       "         [-1.0312e-05,  1.4305e-05, -1.2815e-06,  ..., -1.4722e-05,\n",
       "          -1.1492e-04,  1.0908e-05],\n",
       "         ...,\n",
       "         [-1.2040e-05, -3.0518e-05,  1.2684e-04,  ..., -1.0490e-05,\n",
       "          -4.5538e-05,  3.5316e-06],\n",
       "         [-2.4199e-05,  2.0623e-05,  2.7120e-06,  ..., -2.3842e-05,\n",
       "          -2.5630e-06,  2.2650e-05],\n",
       "         [-4.5896e-06,  3.9339e-06,  5.4538e-06,  ..., -5.8115e-06,\n",
       "           6.5327e-05,  7.6294e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>9<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.3232e-05,  5.2929e-05,  7.1526e-05,  ...,  1.0061e-04,\n",
       "          -9.2983e-06,  1.2338e-05],\n",
       "         [ 3.6240e-05,  2.8968e-05,  1.7524e-05,  ...,  4.0531e-05,\n",
       "          -4.1723e-07,  2.7537e-05],\n",
       "         [ 3.0518e-05,  1.0073e-05,  8.1062e-06,  ..., -3.4332e-05,\n",
       "          -1.5259e-05,  2.0146e-05],\n",
       "         ...,\n",
       "         [ 3.3379e-05, -3.2663e-05,  4.5300e-05,  ...,  7.6294e-05,\n",
       "           9.5367e-06,  8.8811e-06],\n",
       "         [ 2.7895e-05, -7.1228e-06,  7.1526e-05,  ...,  1.8358e-05,\n",
       "          -1.8954e-05,  1.0610e-05],\n",
       "         [ 1.6451e-05,  2.2888e-05,  3.7193e-05,  ..., -1.9670e-05,\n",
       "           2.1577e-05,  1.7405e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>10<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.8147e-05,  1.9968e-06, -2.8372e-05,  ...,  1.0967e-05,\n",
       "          -1.8120e-05,  2.8491e-05],\n",
       "         [-3.5524e-05, -1.3769e-05,  2.1905e-06,  ...,  1.8358e-05,\n",
       "           1.7285e-05, -1.4961e-05],\n",
       "         [ 5.2214e-05, -2.2769e-05, -3.7432e-05,  ...,  1.7166e-05,\n",
       "          -1.3161e-04, -7.8678e-05],\n",
       "         ...,\n",
       "         [-4.1246e-05,  1.3828e-05,  2.5332e-06,  ..., -1.8597e-05,\n",
       "           1.2577e-05,  7.6771e-05],\n",
       "         [-3.7909e-05,  1.5855e-05,  1.0669e-05,  ..., -3.8385e-05,\n",
       "          -2.8372e-05,  2.2650e-05],\n",
       "         [ 4.0293e-05,  5.5730e-06,  3.6240e-05,  ...,  2.6345e-05,\n",
       "          -9.8348e-06,  5.0664e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>10<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 1.6093e-05, -3.4720e-06, -1.0192e-05,  ..., -4.5598e-06,\n",
       "           1.5870e-06, -3.7253e-06],\n",
       "         [-1.4496e-04,  4.2915e-06, -1.4842e-05,  ..., -8.8215e-06,\n",
       "          -1.0908e-05,  5.5507e-07],\n",
       "         [ 2.5034e-05, -1.8120e-05,  2.9683e-05,  ...,  2.7895e-05,\n",
       "           2.6822e-05, -2.4796e-05],\n",
       "         ...,\n",
       "         [ 2.8729e-05, -8.5831e-06,  1.9670e-05,  ...,  1.0550e-05,\n",
       "           1.0669e-05, -2.9802e-06],\n",
       "         [-1.4246e-05,  6.9439e-06, -9.5963e-06,  ...,  3.0845e-06,\n",
       "          -6.5267e-06,  8.2850e-06],\n",
       "         [-1.6928e-05,  1.5020e-05, -8.8811e-06,  ..., -2.8729e-05,\n",
       "          -1.9789e-05,  1.2755e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>10<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-4.5538e-05,  3.6478e-05, -2.3603e-05,  ..., -7.3612e-06,\n",
       "          -1.4901e-05, -7.1824e-06],\n",
       "         [ 3.5048e-05,  1.1325e-05, -2.1219e-05,  ..., -4.9829e-05,\n",
       "           6.1035e-05, -9.7752e-06],\n",
       "         [ 5.3883e-05, -3.7193e-05, -3.7432e-05,  ...,  5.8413e-05,\n",
       "           2.6584e-05, -2.3365e-05],\n",
       "         ...,\n",
       "         [ 1.1563e-05,  2.8491e-05,  3.0279e-05,  ...,  8.8215e-05,\n",
       "           3.4094e-05, -7.9870e-06],\n",
       "         [ 1.6212e-05, -3.1233e-05, -9.7752e-06,  ...,  1.8954e-05,\n",
       "          -2.5183e-06, -1.3053e-05],\n",
       "         [ 1.8239e-05, -3.0994e-05,  7.8082e-06,  ..., -1.2279e-05,\n",
       "           3.5286e-05, -1.0490e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>11<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.4557e-05, -8.6427e-06,  1.9193e-05,  ..., -1.7405e-05,\n",
       "           5.0783e-05,  6.6459e-06],\n",
       "         [ 6.8843e-06, -1.3590e-05,  2.5034e-05,  ...,  1.4663e-05,\n",
       "          -4.5598e-06,  2.1577e-05],\n",
       "         [-1.3769e-05,  1.1269e-07,  1.4007e-05,  ..., -7.3612e-06,\n",
       "           1.2219e-05, -8.4043e-06],\n",
       "         ...,\n",
       "         [-6.9737e-06,  1.2279e-05,  2.5630e-05,  ..., -3.0696e-06,\n",
       "          -2.8133e-05, -9.9540e-06],\n",
       "         [-1.6809e-05, -6.1691e-06, -2.7776e-05,  ..., -1.6308e-04,\n",
       "          -1.1396e-04,  5.9605e-05],\n",
       "         [ 8.4400e-05, -1.8835e-05,  9.2387e-06,  ...,  3.5048e-05,\n",
       "           1.9073e-05, -1.5378e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>11<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.5616e-05,  6.4373e-06, -7.2643e-07,  ..., -1.2875e-05,\n",
       "          -1.6466e-06,  1.6928e-05],\n",
       "         [ 7.9870e-06, -1.1146e-05,  1.0073e-05,  ...,  2.8759e-06,\n",
       "           3.7253e-06, -1.8954e-05],\n",
       "         [-1.2815e-05,  1.2338e-05,  1.1921e-05,  ..., -2.0742e-05,\n",
       "           3.3379e-05, -4.0531e-06],\n",
       "         ...,\n",
       "         [ 3.6001e-05,  2.3365e-05, -2.5868e-05,  ..., -3.5524e-05,\n",
       "          -1.1027e-05,  4.6968e-05],\n",
       "         [ 5.5075e-05, -2.0266e-05, -1.8403e-06,  ...,  2.6226e-05,\n",
       "           3.9101e-05, -1.9908e-05],\n",
       "         [-1.6332e-05,  1.0073e-05,  8.7023e-06,  ..., -8.2254e-06,\n",
       "          -3.4332e-05,  1.2994e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>11<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-9.5963e-06, -1.7405e-05, -1.5855e-05,  ...,  4.8637e-05,\n",
       "           2.8491e-05,  1.3888e-05],\n",
       "         [-1.8179e-06, -3.3617e-05,  1.1861e-05,  ..., -2.5034e-05,\n",
       "          -6.5327e-05,  6.4373e-06],\n",
       "         [-1.7166e-05, -4.1485e-05, -2.5392e-05,  ...,  8.4639e-06,\n",
       "          -1.1396e-04,  2.0981e-05],\n",
       "         ...,\n",
       "         [ 1.5020e-05, -7.5102e-06, -1.4305e-05,  ..., -6.7711e-05,\n",
       "          -1.1063e-04, -6.8247e-06],\n",
       "         [-2.3007e-05,  2.0862e-06, -1.9431e-05,  ...,  1.2064e-04,\n",
       "          -1.8239e-05,  7.0632e-06],\n",
       "         [-1.6451e-05, -2.6345e-05, -9.0003e-06,  ..., -1.4019e-04,\n",
       "          -3.4809e-05,  1.1086e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>12<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.1458e-06,  1.9819e-06, -1.2994e-05,  ...,  9.1791e-06,\n",
       "          -7.0930e-06,  8.6427e-06],\n",
       "         [ 9.3460e-05,  6.8247e-06, -1.7452e-04,  ...,  1.0669e-05,\n",
       "           7.5817e-05, -3.2663e-05],\n",
       "         [ 5.3942e-06,  3.1710e-05,  2.3079e-04,  ..., -2.7275e-04,\n",
       "           4.7684e-04, -6.0722e-07],\n",
       "         ...,\n",
       "         [-3.0279e-05,  4.4107e-06,  5.0545e-05,  ...,  8.9645e-05,\n",
       "           3.4571e-05, -6.3181e-06],\n",
       "         [-1.4067e-05,  9.4771e-06,  2.2769e-05,  ..., -8.9645e-05,\n",
       "          -3.5286e-05,  3.6210e-06],\n",
       "         [ 9.5963e-06, -1.8120e-05,  4.3392e-05,  ...,  5.8889e-05,\n",
       "          -2.1458e-05, -9.2983e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>12<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.7700e-06,  4.7386e-06,  9.1195e-06,  ...,  2.3723e-05,\n",
       "           1.0669e-05,  6.3181e-06],\n",
       "         [-9.0003e-06,  1.0908e-05, -1.7043e-07,  ...,  1.1742e-05,\n",
       "          -2.8610e-05,  1.6212e-05],\n",
       "         [-4.2915e-06, -5.0664e-07,  3.2663e-05,  ..., -5.5730e-06,\n",
       "           1.4305e-05,  1.1036e-07],\n",
       "         ...,\n",
       "         [ 2.1219e-05,  1.8477e-05, -2.2292e-05,  ..., -6.5863e-06,\n",
       "           2.5988e-05, -3.1233e-05],\n",
       "         [ 6.9439e-06, -1.4603e-05,  4.8876e-05,  ...,  5.5134e-06,\n",
       "          -1.6168e-06, -1.5259e-05],\n",
       "         [-1.3828e-05,  1.2159e-05, -1.8001e-05,  ..., -2.9206e-06,\n",
       "          -3.1739e-06,  1.2517e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>12<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.1086e-05,  8.5831e-05,  3.7670e-05,  ..., -2.3395e-06,\n",
       "           2.2411e-05, -4.6015e-05],\n",
       "         [-1.6212e-05, -1.1623e-05, -1.1027e-05,  ..., -1.2070e-06,\n",
       "          -4.8578e-06,  5.6028e-06],\n",
       "         [-8.9407e-06, -3.9816e-05,  2.8372e-05,  ..., -4.3392e-05,\n",
       "          -8.0109e-05,  2.3842e-05],\n",
       "         ...,\n",
       "         [-2.5868e-05, -2.5749e-05,  3.9637e-06,  ...,  2.1577e-05,\n",
       "          -6.6757e-05, -8.6784e-05],\n",
       "         [ 5.2452e-05,  3.3855e-05,  2.0385e-05,  ..., -3.1441e-06,\n",
       "          -1.8954e-05, -6.6459e-06],\n",
       "         [ 1.0192e-05,  9.1195e-06,  8.5831e-06,  ...,  5.8174e-05,\n",
       "          -3.7551e-06, -2.8729e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>13<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.4676e-05,  1.2934e-05,  2.7061e-05,  ...,  1.3649e-05,\n",
       "           5.9903e-06,  2.2888e-05],\n",
       "         [ 1.3933e-06, -1.3337e-06, -1.4842e-05,  ..., -2.3723e-05,\n",
       "          -2.2769e-05,  9.9540e-06],\n",
       "         [-1.0371e-05,  1.5497e-05,  4.5002e-06,  ...,  3.7700e-06,\n",
       "           4.5821e-07, -6.2585e-06],\n",
       "         ...,\n",
       "         [-1.1921e-05,  1.2934e-05, -1.7166e-05,  ..., -1.8716e-05,\n",
       "          -1.5736e-05,  8.7023e-06],\n",
       "         [-1.6689e-05,  1.0431e-05, -1.5736e-05,  ...,  7.1824e-06,\n",
       "           3.4124e-06,  2.3842e-05],\n",
       "         [-2.0266e-05,  3.4571e-05,  8.2850e-06,  ...,  5.0545e-05,\n",
       "           7.0572e-05,  4.2677e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>13<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.2517e-05,  9.1195e-06, -4.5538e-05,  ..., -1.3188e-06,\n",
       "          -5.0783e-05, -8.1062e-06],\n",
       "         [ 5.1558e-06, -1.3411e-05, -4.7386e-06,  ...,  5.6922e-06,\n",
       "           1.1969e-04, -2.3842e-06],\n",
       "         [ 2.7865e-06,  1.3828e-05,  5.7459e-05,  ..., -2.0862e-05,\n",
       "           1.0669e-05,  7.9274e-06],\n",
       "         ...,\n",
       "         [-1.0312e-05,  1.3947e-05, -2.7180e-05,  ..., -2.5153e-05,\n",
       "          -1.2994e-05,  1.2755e-05],\n",
       "         [ 2.6941e-05, -7.5698e-06, -3.3140e-05,  ..., -1.0490e-04,\n",
       "          -3.1471e-05, -1.5140e-05],\n",
       "         [ 1.4901e-05, -1.1563e-05,  1.8716e-05,  ..., -1.2040e-05,\n",
       "          -8.4564e-07, -1.4126e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>13<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.0994e-05,  7.9274e-06,  3.2634e-06,  ...,  1.9312e-05,\n",
       "           1.0061e-04, -1.1861e-05],\n",
       "         [ 6.8665e-05, -7.5817e-05, -3.7909e-05,  ..., -3.6359e-06,\n",
       "           7.1526e-05,  7.3016e-06],\n",
       "         [-5.5730e-06, -8.5831e-06,  8.0094e-08,  ...,  2.3365e-05,\n",
       "          -1.4305e-04, -3.7909e-05],\n",
       "         ...,\n",
       "         [-9.1195e-06, -5.8115e-06, -2.5511e-05,  ..., -2.0862e-05,\n",
       "          -1.0252e-04,  1.8626e-06],\n",
       "         [ 1.1563e-05,  1.9836e-04,  1.7881e-05,  ...,  1.0431e-05,\n",
       "           8.2254e-06, -1.3947e-05],\n",
       "         [-2.3961e-05,  2.5368e-04, -2.6673e-06,  ..., -8.7023e-06,\n",
       "           3.5286e-05,  8.5831e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>14<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.4773e-07, -5.1260e-06, -2.1458e-05,  ..., -3.0994e-05,\n",
       "          -1.6117e-04,  3.0756e-05],\n",
       "         [ 7.2002e-05, -1.6809e-05,  4.4107e-05,  ...,  2.2054e-05,\n",
       "           3.6716e-05, -1.6809e-05],\n",
       "         [-3.1710e-05,  7.5102e-06,  3.6806e-06,  ..., -2.5034e-05,\n",
       "          -1.4973e-04, -9.0003e-06],\n",
       "         ...,\n",
       "         [-2.8968e-05, -1.7405e-05,  8.2970e-05,  ...,  7.6890e-06,\n",
       "          -4.5061e-05,  5.8651e-05],\n",
       "         [-3.6001e-05, -4.5300e-06,  2.1815e-05,  ...,  1.5831e-04,\n",
       "           2.2221e-04,  6.8188e-05],\n",
       "         [ 1.0967e-05, -1.0061e-04, -5.8651e-05,  ..., -1.4973e-04,\n",
       "          -1.8406e-04,  1.2398e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>14<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-8.8215e-06,  6.9141e-06,  4.6968e-05,  ...,  2.6941e-05,\n",
       "           6.8188e-05,  6.9439e-06],\n",
       "         [-1.1265e-05,  1.2875e-05, -1.9670e-05,  ..., -2.5272e-05,\n",
       "          -6.6757e-05, -4.1425e-06],\n",
       "         [ 2.0385e-05, -1.2875e-05, -1.2517e-06,  ...,  8.9407e-06,\n",
       "          -4.2677e-05, -2.7061e-05],\n",
       "         ...,\n",
       "         [ 1.1384e-05, -1.3351e-05,  1.5974e-05,  ...,  2.2888e-05,\n",
       "           1.1861e-05, -7.0333e-06],\n",
       "         [ 1.2696e-05, -5.0664e-06,  1.2740e-06,  ...,  9.8348e-06,\n",
       "           1.4842e-05,  5.1856e-06],\n",
       "         [ 3.2634e-06, -9.5963e-06,  9.1791e-06,  ...,  4.5002e-06,\n",
       "           3.6955e-05, -1.1981e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>14<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 8.1062e-05,  5.9605e-06,  5.6922e-06,  ..., -4.1425e-06,\n",
       "          -8.3447e-06, -1.2755e-05],\n",
       "         [-6.4850e-05,  1.3039e-06, -1.8954e-05,  ..., -1.5736e-05,\n",
       "          -2.0862e-05, -7.1526e-06],\n",
       "         [-5.9128e-05, -1.7524e-05,  1.3769e-05,  ...,  7.0333e-06,\n",
       "           1.2636e-05, -9.4175e-06],\n",
       "         ...,\n",
       "         [-7.4387e-05, -3.8624e-05,  2.2054e-06,  ...,  1.7405e-05,\n",
       "           6.3896e-05,  1.4424e-05],\n",
       "         [ 1.1027e-05,  2.5034e-06,  1.8239e-05,  ...,  1.2219e-05,\n",
       "          -8.5309e-07,  3.3081e-06],\n",
       "         [-2.3842e-05,  1.4722e-05, -1.1206e-05,  ...,  4.1723e-06,\n",
       "          -3.4094e-05,  1.1444e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>15<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.9819e-06,  1.8120e-05, -6.4075e-06,  ..., -1.0610e-05,\n",
       "           3.4094e-05,  2.1338e-05],\n",
       "         [-1.6928e-05,  1.1742e-05, -1.2040e-05,  ..., -2.9802e-05,\n",
       "           2.3127e-05,  1.8239e-05],\n",
       "         [ 2.0266e-05, -9.0897e-07, -1.8477e-05,  ...,  4.5896e-06,\n",
       "           2.0981e-05, -8.3447e-06],\n",
       "         ...,\n",
       "         [-3.9577e-05,  1.0371e-05, -1.0109e-04,  ..., -3.3379e-05,\n",
       "          -1.6212e-05, -1.3351e-05],\n",
       "         [-6.2864e-08, -1.2815e-06,  6.1393e-06,  ...,  4.8280e-06,\n",
       "           2.4080e-05, -8.3447e-06],\n",
       "         [-1.8835e-05, -6.1095e-06, -1.0073e-05,  ...,  2.3365e-05,\n",
       "          -8.4750e-08, -1.6451e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>15<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.3991e-06,  2.6226e-05, -3.2187e-06,  ..., -2.0266e-05,\n",
       "          -1.0431e-07,  2.8133e-05],\n",
       "         [-3.2336e-06,  1.2159e-05, -1.6570e-05,  ..., -1.8626e-06,\n",
       "           2.4199e-05,  1.3709e-05],\n",
       "         [ 2.8372e-05, -1.1548e-06, -5.7220e-06,  ...,  1.3188e-06,\n",
       "          -4.8578e-06, -1.7360e-06],\n",
       "         ...,\n",
       "         [-1.5497e-05,  4.4107e-06,  1.9312e-05,  ..., -5.7220e-06,\n",
       "          -1.0610e-05,  1.4722e-05],\n",
       "         [ 1.9312e-05, -4.4405e-06, -8.4043e-06,  ...,  8.1062e-06,\n",
       "          -1.4305e-05,  1.4901e-07],\n",
       "         [ 8.8215e-06, -1.1623e-05,  1.0967e-05,  ...,  5.8711e-06,\n",
       "          -2.0266e-05, -9.8944e-06]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>15<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-9.9540e-06,  9.2983e-06,  4.5598e-06,  ...,  6.1095e-06,\n",
       "           1.1504e-05, -9.4771e-06],\n",
       "         [-9.4771e-06, -1.7881e-05, -1.7658e-06,  ..., -1.7881e-05,\n",
       "           9.1791e-06,  6.3419e-05],\n",
       "         [-5.7220e-06,  2.3842e-05,  3.3677e-06,  ...,  1.6570e-05,\n",
       "          -1.3262e-06, -2.2292e-05],\n",
       "         ...,\n",
       "         [-3.5763e-05, -1.7762e-05, -9.4622e-07,  ..., -4.2021e-06,\n",
       "          -2.7776e-05,  3.7432e-05],\n",
       "         [-4.6730e-05,  1.2577e-05,  3.1710e-05,  ...,  1.0788e-05,\n",
       "           3.4720e-06, -1.4901e-05],\n",
       "         [ 3.4332e-05, -1.7881e-05, -2.7299e-05,  ..., -9.7156e-06,\n",
       "          -9.7752e-06,  2.1458e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>16<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.4782e-04,  1.1265e-05, -8.0109e-05,  ...,  8.3447e-05,\n",
       "          -1.0777e-04,  2.9683e-05],\n",
       "         [ 4.3213e-06,  1.8001e-05, -2.8871e-08,  ..., -2.0146e-05,\n",
       "           2.6703e-05,  1.6093e-05],\n",
       "         [-1.1265e-05,  1.0192e-05, -1.5378e-05,  ..., -1.1325e-05,\n",
       "          -2.1696e-05,  9.8348e-06],\n",
       "         ...,\n",
       "         [-5.8413e-05,  5.5552e-05, -1.0729e-04,  ...,  4.7922e-05,\n",
       "           1.1444e-04,  1.4210e-04],\n",
       "         [-1.0431e-05, -1.9670e-06,  1.0252e-05,  ...,  4.5300e-06,\n",
       "           1.5855e-05, -6.7428e-07],\n",
       "         [ 2.9445e-05, -3.2187e-05, -8.7619e-06,  ...,  1.5497e-05,\n",
       "           9.0599e-06, -2.1219e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>16<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-5.2214e-05,  2.5034e-05, -1.3649e-05,  ..., -1.9312e-05,\n",
       "          -8.8692e-05,  3.0518e-05],\n",
       "         [ 1.3933e-06, -2.6971e-06, -1.3947e-05,  ...,  6.8843e-06,\n",
       "          -3.1948e-05, -7.9870e-06],\n",
       "         [ 4.7684e-06, -4.1962e-05, -6.1035e-05,  ..., -1.0312e-05,\n",
       "          -1.5855e-05, -6.4671e-06],\n",
       "         ...,\n",
       "         [-2.1219e-05,  1.4544e-05, -2.0623e-05,  ..., -9.2983e-06,\n",
       "          -2.2531e-05,  1.3411e-05],\n",
       "         [-4.0770e-05,  1.0967e-05,  8.3447e-06,  ..., -1.8254e-06,\n",
       "           1.0550e-05,  2.3246e-05],\n",
       "         [ 3.7193e-05, -3.4332e-05, -1.1265e-05,  ...,  2.1100e-05,\n",
       "          -5.8115e-06, -1.7405e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>16<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 9.3460e-05,  2.0385e-05, -3.6955e-06,  ..., -8.0585e-05,\n",
       "          -1.3769e-05, -3.9935e-06],\n",
       "         [ 1.2207e-04,  9.8348e-06,  5.5790e-05,  ...,  3.3617e-05,\n",
       "          -4.5002e-06,  4.9770e-06],\n",
       "         [ 1.4114e-04,  3.9116e-07, -1.5855e-05,  ...,  4.5896e-06,\n",
       "          -6.8843e-06,  1.0312e-05],\n",
       "         ...,\n",
       "         [-9.8228e-05,  6.7234e-05,  7.5340e-05,  ..., -1.0490e-04,\n",
       "          -2.2445e-07,  3.5167e-06],\n",
       "         [-1.8001e-05, -2.5183e-06, -1.1206e-05,  ...,  1.5259e-04,\n",
       "           5.4836e-06,  1.4365e-05],\n",
       "         [ 1.8883e-04, -2.0742e-05, -7.0333e-06,  ...,  8.2254e-06,\n",
       "          -4.1008e-05, -1.5020e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>17<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.0770e-05, -1.8597e-05, -1.9908e-05,  ...,  1.7285e-05,\n",
       "          -8.3447e-05, -1.2398e-05],\n",
       "         [-8.5354e-05, -9.5963e-06, -1.4114e-04,  ..., -4.1008e-05,\n",
       "          -6.5804e-05, -9.0152e-07],\n",
       "         [ 3.5286e-05, -5.1856e-06,  3.0279e-05,  ...,  1.5199e-05,\n",
       "           9.5367e-06, -1.4067e-05],\n",
       "         ...,\n",
       "         [-2.7537e-05, -7.1824e-06, -7.5817e-05,  ..., -6.8247e-06,\n",
       "          -4.9353e-05, -3.5465e-06],\n",
       "         [-5.8413e-06,  4.4107e-06, -3.1710e-05,  ..., -7.2122e-06,\n",
       "          -9.8944e-06, -1.4186e-05],\n",
       "         [ 1.8477e-06,  1.9908e-05, -4.9829e-05,  ..., -6.7949e-06,\n",
       "           4.1723e-05, -1.6451e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>17<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-4.6492e-05,  2.1696e-05, -2.7061e-05,  ..., -3.0518e-05,\n",
       "          -1.3053e-05,  1.7405e-05],\n",
       "         [ 5.7697e-05, -3.2485e-06,  2.5034e-05,  ...,  2.0504e-05,\n",
       "          -5.8889e-05,  3.7193e-05],\n",
       "         [ 2.3365e-05,  1.4901e-06,  6.3896e-05,  ...,  6.1989e-05,\n",
       "           2.6345e-05, -1.1623e-06],\n",
       "         ...,\n",
       "         [-1.2493e-04,  1.8597e-05, -1.5545e-04,  ..., -9.0599e-05,\n",
       "          -6.0797e-05,  3.4332e-05],\n",
       "         [-5.5134e-06, -8.7619e-06,  1.0848e-05,  ..., -2.4214e-07,\n",
       "          -2.0862e-05, -1.4663e-05],\n",
       "         [-2.9057e-07, -9.4175e-06, -1.3292e-05,  ...,  1.8477e-06,\n",
       "          -2.2411e-05, -1.8120e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>17<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.2577e-05,  2.8253e-05, -1.2970e-04,  ...,  1.2696e-05,\n",
       "          -9.1791e-06, -1.3173e-05],\n",
       "         [ 1.5050e-06, -2.7120e-06,  1.6809e-05,  ...,  1.5545e-04,\n",
       "           1.2398e-05,  8.6427e-06],\n",
       "         [-8.6784e-05, -5.4598e-05, -1.1399e-06,  ...,  8.1539e-05,\n",
       "          -1.4901e-05, -1.6570e-05],\n",
       "         ...,\n",
       "         [ 4.5538e-05, -6.0081e-05, -9.7275e-05,  ...,  5.5313e-05,\n",
       "          -1.3411e-05, -1.0967e-05],\n",
       "         [ 2.1815e-05,  1.0300e-04,  2.5511e-05,  ..., -1.9550e-05,\n",
       "          -1.4424e-05, -2.4199e-05],\n",
       "         [ 2.6345e-05, -6.3479e-06, -3.6240e-05,  ...,  1.0777e-04,\n",
       "           6.5267e-06,  2.0862e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>18<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.6694e-07, -2.2888e-05,  1.3113e-05,  ...,  2.9922e-05,\n",
       "           6.9737e-06, -4.4584e-05],\n",
       "         [ 2.9057e-06, -9.7156e-06,  6.3181e-06,  ...,  5.5134e-06,\n",
       "           8.5831e-06, -1.8477e-05],\n",
       "         [-1.1146e-05,  2.1338e-05,  1.9908e-05,  ..., -1.3590e-05,\n",
       "           1.4007e-05,  1.8001e-05],\n",
       "         ...,\n",
       "         [-1.2219e-05, -9.2983e-06, -1.2696e-05,  ...,  1.0252e-05,\n",
       "          -6.9141e-06, -9.9540e-06],\n",
       "         [-1.5721e-06, -8.1062e-06, -8.2254e-06,  ...,  1.6332e-05,\n",
       "          -2.3127e-05, -1.2457e-05],\n",
       "         [ 1.6093e-05,  8.7023e-06,  1.0967e-05,  ...,  2.7567e-06,\n",
       "           1.3232e-05,  1.2577e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>18<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.2663e-05, -4.5300e-06, -1.1683e-05,  ...,  1.7434e-06,\n",
       "          -1.2457e-05, -8.1956e-07],\n",
       "         [-1.9908e-05,  8.1062e-06, -1.2577e-05,  ..., -8.1658e-06,\n",
       "          -1.8597e-05, -1.2740e-06],\n",
       "         [-5.8651e-05, -1.5974e-05, -4.1723e-05,  ..., -3.3855e-05,\n",
       "          -4.2617e-06,  2.2352e-06],\n",
       "         ...,\n",
       "         [-7.0035e-06, -1.0490e-05, -1.2219e-05,  ...,  7.6294e-06,\n",
       "          -8.9407e-06, -1.4961e-05],\n",
       "         [ 1.1683e-05,  2.7180e-05, -4.2021e-06,  ..., -2.1458e-05,\n",
       "          -1.1027e-05, -4.1723e-06],\n",
       "         [-7.9274e-06,  1.1504e-05,  7.3910e-06,  ..., -1.5497e-05,\n",
       "           3.2187e-06,  8.8811e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>18<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 5.6744e-05,  7.7248e-05,  2.6107e-05,  ...,  5.4538e-06,\n",
       "          -7.4387e-05, -3.6240e-05],\n",
       "         [-4.1425e-06, -7.8082e-06,  7.6294e-05,  ..., -4.2282e-07,\n",
       "           3.9935e-06, -2.4557e-05],\n",
       "         [ 2.3723e-05, -5.7817e-06, -5.5790e-05,  ...,  9.7752e-06,\n",
       "           6.7711e-05,  6.1035e-05],\n",
       "         ...,\n",
       "         [-2.7537e-05, -2.7657e-05,  3.7909e-05,  ..., -4.7088e-06,\n",
       "           8.7738e-05,  2.7418e-05],\n",
       "         [ 3.2425e-05, -4.3213e-07,  7.6294e-05,  ...,  1.0788e-05,\n",
       "           7.6294e-06,  3.2187e-05],\n",
       "         [ 1.4424e-05, -4.1723e-06,  6.6280e-05,  ..., -1.8835e-05,\n",
       "          -3.0041e-05, -1.5616e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>19<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.9951e-06, -9.9838e-07,  4.5598e-06,  ...,  1.1995e-06,\n",
       "           1.6764e-06, -3.4422e-06],\n",
       "         [ 3.1471e-05, -8.3447e-06,  3.5048e-05,  ..., -3.6478e-05,\n",
       "          -2.5511e-05,  5.0068e-05],\n",
       "         [-4.5598e-06,  1.2577e-05,  1.6809e-05,  ..., -8.1658e-06,\n",
       "           1.3471e-05,  8.4639e-06],\n",
       "         ...,\n",
       "         [ 3.7193e-05,  2.6464e-05,  1.7405e-05,  ..., -2.3961e-05,\n",
       "           4.6194e-06, -2.9922e-05],\n",
       "         [ 4.5776e-05,  3.3617e-05,  1.5855e-05,  ..., -1.6928e-05,\n",
       "           2.2650e-05,  1.0729e-04],\n",
       "         [-5.0366e-06,  1.2636e-05,  2.3365e-05,  ..., -1.1384e-05,\n",
       "          -9.8348e-07,  2.3842e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>19<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-5.2929e-05,  3.7432e-05,  5.5552e-05,  ..., -2.5630e-05,\n",
       "          -6.5267e-06, -1.7788e-07],\n",
       "         [ 6.6310e-07,  1.2100e-05,  2.9802e-05,  ..., -2.6703e-05,\n",
       "           1.7762e-05,  8.4043e-06],\n",
       "         [-3.1233e-05,  2.0266e-05,  1.7405e-05,  ..., -1.9670e-05,\n",
       "           1.5616e-05,  1.7881e-05],\n",
       "         ...,\n",
       "         [-2.2411e-05, -1.6391e-06, -5.3942e-06,  ...,  1.4231e-06,\n",
       "          -1.2100e-05,  1.7524e-05],\n",
       "         [ 6.0797e-06, -7.6294e-06, -7.8678e-06,  ...,  4.7386e-06,\n",
       "          -2.5630e-06, -1.2279e-05],\n",
       "         [-6.7055e-06,  5.9307e-06,  7.6294e-06,  ..., -6.9141e-06,\n",
       "           4.9472e-06, -5.0962e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>19<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-6.6757e-05, -5.4359e-05, -1.4484e-05,  ..., -2.5511e-05,\n",
       "          -9.2387e-06, -8.8811e-06],\n",
       "         [ 2.1338e-05,  4.2677e-05,  9.4771e-06,  ...,  3.0160e-05,\n",
       "           4.0233e-06,  3.2634e-06],\n",
       "         [ 2.7299e-05, -3.7253e-06,  3.1710e-05,  ..., -2.6941e-05,\n",
       "          -5.4359e-05,  1.0014e-05],\n",
       "         ...,\n",
       "         [-5.6624e-06, -1.3292e-05,  2.7269e-06,  ..., -2.5511e-05,\n",
       "           2.2173e-05,  2.8610e-05],\n",
       "         [ 8.2329e-07,  9.7275e-05,  3.7670e-05,  ..., -5.6028e-05,\n",
       "           1.3411e-05,  5.1856e-06],\n",
       "         [ 1.9550e-05, -7.4387e-05, -1.0788e-05,  ...,  1.3828e-05,\n",
       "          -2.8372e-05, -2.9922e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>20<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-5.3048e-06,  8.1658e-06,  7.2122e-06,  ..., -1.0431e-05,\n",
       "           1.6689e-06,  6.7055e-07],\n",
       "         [-6.3777e-06, -1.8239e-05,  1.0610e-05,  ...,  4.4703e-06,\n",
       "           6.8247e-06,  1.0371e-05],\n",
       "         [ 1.3769e-05, -1.2577e-05, -1.7136e-07,  ...,  8.7023e-06,\n",
       "          -3.9041e-06,  1.8477e-05],\n",
       "         ...,\n",
       "         [-1.4424e-05,  9.2983e-06,  8.1062e-06,  ..., -1.1742e-05,\n",
       "           1.4365e-05, -2.1577e-05],\n",
       "         [ 2.3246e-05, -1.1742e-05, -9.2983e-06,  ...,  4.0531e-06,\n",
       "          -3.2425e-05,  1.5140e-05],\n",
       "         [ 1.2696e-05, -1.1742e-05, -2.4915e-05,  ...,  1.0908e-05,\n",
       "           8.0466e-06, -5.6326e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>20<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 1.8001e-05, -1.5616e-05, -1.4126e-05,  ...,  1.4007e-05,\n",
       "           7.5996e-06,  3.9041e-06],\n",
       "         [ 1.2636e-05, -8.5831e-06, -9.2983e-06,  ...,  9.0599e-06,\n",
       "          -2.5272e-05,  1.2457e-05],\n",
       "         [-1.6928e-05,  2.4140e-06,  3.9339e-05,  ..., -2.0742e-05,\n",
       "          -4.0770e-05,  6.7711e-05],\n",
       "         ...,\n",
       "         [ 2.1338e-05, -1.1384e-05,  5.3644e-06,  ..., -4.4703e-06,\n",
       "           5.4836e-05,  9.2387e-06],\n",
       "         [-5.9903e-06,  6.9141e-06,  8.5831e-06,  ..., -1.1384e-05,\n",
       "          -2.4319e-05, -1.5140e-05],\n",
       "         [ 4.2021e-06,  3.0994e-06, -1.0252e-05,  ..., -9.2983e-06,\n",
       "          -2.2769e-05, -1.3411e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>20<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 5.2452e-05, -4.4405e-06,  9.8705e-05,  ..., -5.0068e-06,\n",
       "           4.5300e-05, -1.1349e-04],\n",
       "         [-2.3484e-05,  6.9737e-06,  9.1791e-06,  ..., -2.2203e-06,\n",
       "          -9.1195e-06, -3.9816e-05],\n",
       "         [ 8.3447e-06,  1.4126e-05,  2.3246e-05,  ..., -2.2799e-06,\n",
       "           2.1338e-05,  9.6798e-05],\n",
       "         ...,\n",
       "         [-7.3433e-05, -2.5928e-06, -4.4107e-05,  ..., -7.9721e-07,\n",
       "          -3.2902e-05, -1.3709e-05],\n",
       "         [ 1.0371e-05,  9.8944e-06, -6.1691e-06,  ..., -1.1995e-06,\n",
       "          -2.5392e-05, -7.8201e-05],\n",
       "         [ 1.5974e-05, -9.1195e-06,  1.7047e-05,  ...,  1.3053e-05,\n",
       "          -1.6451e-05, -2.0623e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>21<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.4346e-05,  3.2187e-05,  6.4969e-06,  ...,  6.5267e-06,\n",
       "          -6.1989e-05,  7.1049e-05],\n",
       "         [ 4.2915e-05, -3.0398e-05, -3.2663e-05,  ..., -1.1921e-05,\n",
       "           1.7405e-05, -5.4121e-05],\n",
       "         [ 7.1526e-06, -5.9903e-06, -1.3828e-05,  ..., -1.8254e-06,\n",
       "          -3.1292e-06, -1.4126e-05],\n",
       "         ...,\n",
       "         [ 1.8215e-04,  4.4107e-05,  1.0395e-04,  ...,  1.6785e-04,\n",
       "           6.2943e-05, -1.4114e-04],\n",
       "         [-5.8889e-05,  1.2577e-05,  2.5868e-05,  ..., -3.3975e-06,\n",
       "           5.5313e-05,  1.8001e-05],\n",
       "         [ 1.7285e-05,  1.7658e-06, -6.5863e-06,  ..., -2.7120e-06,\n",
       "           3.1471e-05,  7.5251e-07]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>21<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 3.2425e-05, -2.5153e-05, -1.1492e-04,  ...,  5.8413e-05,\n",
       "          -1.3828e-04,  9.3937e-05],\n",
       "         [-8.2970e-05,  2.3961e-05,  2.2888e-05,  ...,  1.1861e-05,\n",
       "           2.4557e-05,  2.6822e-05],\n",
       "         [-7.9721e-07,  5.6028e-06, -3.0361e-07,  ..., -1.1846e-06,\n",
       "           6.5863e-06,  2.3544e-06],\n",
       "         ...,\n",
       "         [ 1.7047e-05, -6.7651e-06, -1.0371e-05,  ..., -4.2468e-07,\n",
       "           2.1577e-05, -4.1485e-05],\n",
       "         [ 7.5996e-06, -9.1195e-06, -8.8811e-06,  ...,  9.7156e-06,\n",
       "          -1.4901e-05,  1.0669e-05],\n",
       "         [ 4.3213e-06, -9.7156e-06, -1.4067e-05,  ...,  1.4544e-05,\n",
       "          -5.0068e-06,  5.3048e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>21<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-4.0531e-06,  5.2691e-05, -6.9141e-06,  ...,  4.8876e-06,\n",
       "          -3.3140e-05, -1.0610e-05],\n",
       "         [-4.7445e-05,  1.6928e-05, -3.3140e-05,  ..., -2.6941e-05,\n",
       "           3.3617e-05, -5.3346e-06],\n",
       "         [-3.6955e-06,  4.3511e-06, -2.0862e-05,  ...,  1.0729e-05,\n",
       "          -1.9312e-05,  3.5018e-06],\n",
       "         ...,\n",
       "         [-3.4809e-05, -5.2929e-05, -6.1989e-06,  ..., -3.0279e-05,\n",
       "           2.0385e-05, -3.8743e-06],\n",
       "         [-3.9101e-05, -3.4332e-05,  4.6194e-06,  ..., -1.9222e-06,\n",
       "          -3.4571e-06, -3.0361e-07],\n",
       "         [ 5.8174e-05,  3.0518e-05, -3.4094e-05,  ..., -4.3809e-06,\n",
       "          -5.1558e-06, -1.3292e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>22<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.0729e-05,  8.3447e-06,  3.4571e-05,  ..., -1.6093e-05,\n",
       "          -8.7023e-06, -1.9670e-05],\n",
       "         [-4.1485e-05,  2.6107e-05,  2.8729e-05,  ..., -3.4273e-06,\n",
       "          -2.4676e-05, -9.3579e-06],\n",
       "         [ 5.4121e-05,  2.1338e-05, -7.1049e-05,  ..., -3.8385e-05,\n",
       "          -7.2479e-05, -6.0320e-05],\n",
       "         ...,\n",
       "         [ 4.9353e-05,  1.4722e-05, -6.1989e-06,  ...,  1.5259e-05,\n",
       "          -3.6001e-05,  5.3406e-05],\n",
       "         [-4.4107e-06, -9.0003e-06, -1.0550e-05,  ...,  9.1791e-06,\n",
       "           2.1577e-05, -1.1981e-05],\n",
       "         [ 1.6093e-05, -1.2040e-05, -1.1802e-05,  ...,  1.1384e-05,\n",
       "          -7.1824e-06,  1.2279e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>22<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 1.1548e-06,  4.0829e-06, -8.0466e-06,  ..., -1.6451e-05,\n",
       "           1.3769e-05,  9.8348e-06],\n",
       "         [ 7.4208e-06, -4.5776e-05, -3.3379e-05,  ...,  1.0550e-05,\n",
       "           1.5497e-05, -8.8941e-08],\n",
       "         [-2.7418e-05,  1.5259e-05,  1.0610e-05,  ...,  6.1393e-06,\n",
       "          -2.2292e-05, -7.3910e-06],\n",
       "         ...,\n",
       "         [-6.6280e-05,  4.5002e-06, -1.7166e-05,  ..., -5.3406e-05,\n",
       "           5.8487e-07,  9.5367e-07],\n",
       "         [ 1.2040e-05, -8.7619e-06, -3.7998e-06,  ...,  5.1260e-06,\n",
       "           3.7402e-06,  1.1921e-05],\n",
       "         [-6.8188e-05,  7.6771e-05,  4.8399e-05,  ..., -4.5776e-05,\n",
       "          -7.0095e-05,  6.4373e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>22<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.6226e-05, -6.5327e-05, -2.0117e-06,  ...,  1.8239e-05,\n",
       "           3.8862e-05, -6.5327e-05],\n",
       "         [-4.8876e-06,  7.5340e-05,  4.0829e-06,  ...,  2.3246e-05,\n",
       "           1.5140e-05,  5.2929e-05],\n",
       "         [-1.8001e-05, -9.1195e-06,  3.0160e-05,  ...,  2.0623e-05,\n",
       "           2.0385e-05,  4.8578e-06],\n",
       "         ...,\n",
       "         [-2.5272e-05, -5.2452e-05, -3.9935e-06,  ...,  7.4863e-05,\n",
       "          -1.9789e-05,  6.1035e-05],\n",
       "         [-6.9141e-06, -6.8247e-06,  1.8477e-05,  ...,  1.4007e-05,\n",
       "           5.5432e-06, -5.7817e-06],\n",
       "         [ 5.7518e-06,  7.0095e-05,  5.2214e-05,  ..., -1.0109e-04,\n",
       "           9.1791e-06, -7.8082e-06]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>23<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.0829e-06, -3.5763e-05, -1.4722e-05,  ..., -3.3140e-05,\n",
       "          -1.7807e-06, -1.6809e-05],\n",
       "         [ 1.8120e-05, -8.2701e-07, -2.2650e-06,  ..., -1.4901e-06,\n",
       "           1.1027e-05, -4.5002e-06],\n",
       "         [ 2.6345e-05, -1.0610e-05, -9.7752e-06,  ...,  1.5378e-05,\n",
       "          -7.3612e-06,  1.2696e-05],\n",
       "         ...,\n",
       "         [ 1.5080e-05, -1.1250e-06, -6.0350e-07,  ...,  1.3292e-05,\n",
       "          -1.5020e-05,  1.0490e-05],\n",
       "         [ 1.5378e-05, -2.1577e-05,  5.0306e-05,  ...,  4.8876e-06,\n",
       "           4.7684e-05,  8.8692e-05],\n",
       "         [ 4.9472e-06, -3.3975e-06, -1.3411e-05,  ...,  8.7023e-06,\n",
       "          -4.0829e-06,  9.7156e-06]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>23<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 6.0201e-06,  7.0333e-06, -2.3127e-05,  ...,  9.8348e-06,\n",
       "          -1.5259e-05,  7.2122e-06],\n",
       "         [ 3.1471e-05,  4.5896e-06, -1.7360e-06,  ...,  4.5002e-06,\n",
       "           1.1444e-05,  1.4424e-05],\n",
       "         [ 4.4517e-07,  6.0201e-06, -5.6922e-06,  ..., -1.4007e-06,\n",
       "          -1.1265e-05,  4.9472e-06],\n",
       "         ...,\n",
       "         [-4.0054e-05,  4.5061e-05,  3.6478e-05,  ..., -1.3649e-05,\n",
       "           5.3048e-06, -1.8597e-05],\n",
       "         [-1.4246e-05,  1.0477e-07, -3.0845e-06,  ...,  3.6806e-06,\n",
       "          -6.7055e-06,  7.0333e-06],\n",
       "         [ 1.3351e-05,  6.0722e-07,  1.2636e-05,  ...,  2.7865e-06,\n",
       "          -2.9653e-06, -2.0504e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>23<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.1739e-06, -3.9816e-05,  1.1921e-05,  ..., -5.5432e-06,\n",
       "          -3.1590e-06,  2.3007e-05],\n",
       "         [-3.2663e-05, -2.7180e-05, -8.5831e-06,  ..., -3.0756e-05,\n",
       "           9.4891e-05,  5.7459e-05],\n",
       "         [-8.6427e-06,  4.5061e-05,  8.1658e-06,  ..., -5.8413e-06,\n",
       "          -4.8399e-05,  9.1076e-05],\n",
       "         ...,\n",
       "         [ 1.8120e-05,  4.3631e-05,  1.1384e-05,  ...,  3.0398e-05,\n",
       "          -1.0443e-04, -4.9114e-05],\n",
       "         [-5.7518e-06, -7.9870e-06,  4.9770e-06,  ..., -4.9174e-06,\n",
       "          -1.3351e-05, -3.2363e-08],\n",
       "         [ 1.6332e-05,  1.8120e-05, -2.5511e-05,  ...,  1.4901e-05,\n",
       "           9.8705e-05,  9.3460e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>24<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 9.7752e-06, -2.8014e-05, -1.9312e-05,  ..., -2.5153e-05,\n",
       "           3.8624e-05, -2.8014e-05],\n",
       "         [ 4.5896e-06, -8.8215e-05,  1.2398e-04,  ..., -6.9618e-05,\n",
       "           8.4400e-05,  2.9325e-05],\n",
       "         [ 1.0610e-05, -1.2100e-05, -1.1146e-05,  ...,  1.0371e-05,\n",
       "          -1.2398e-05,  1.1265e-05],\n",
       "         ...,\n",
       "         [-1.2934e-05,  2.7061e-05,  3.1948e-05,  ..., -1.5020e-05,\n",
       "           1.8358e-05, -1.1981e-05],\n",
       "         [ 2.2411e-05,  9.6798e-05,  2.3842e-05,  ..., -4.9770e-06,\n",
       "           3.2187e-05, -3.5286e-05],\n",
       "         [ 3.7432e-05,  2.0742e-05,  1.0824e-04,  ..., -1.1623e-05,\n",
       "          -3.7193e-05,  4.2677e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>24<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.2948e-06,  1.6212e-05,  1.0371e-05,  ..., -7.7486e-06,\n",
       "           9.2983e-06,  1.2293e-06],\n",
       "         [ 1.0908e-05, -9.4175e-06, -2.9683e-05,  ..., -6.1691e-06,\n",
       "          -2.1514e-07,  4.9472e-06],\n",
       "         [-2.8014e-05,  1.9431e-05, -1.1444e-05,  ..., -2.0623e-05,\n",
       "          -3.9339e-06, -1.0550e-05],\n",
       "         ...,\n",
       "         [ 2.1815e-05,  1.1253e-04,  8.0109e-05,  ..., -2.0623e-05,\n",
       "          -3.1710e-05, -2.7299e-05],\n",
       "         [ 1.3292e-05,  6.8545e-06,  2.2769e-05,  ...,  2.7776e-05,\n",
       "          -2.5153e-05, -1.0443e-04],\n",
       "         [-4.2021e-06, -7.9274e-06, -3.1143e-06,  ...,  1.0073e-05,\n",
       "           8.2493e-05,  2.7895e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>24<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-6.1095e-06, -6.4969e-06, -3.9339e-06,  ...,  1.4019e-04,\n",
       "          -2.5630e-05,  1.1325e-06],\n",
       "         [-1.6689e-05,  1.1742e-05,  1.6570e-05,  ...,  3.0756e-05,\n",
       "           5.0783e-05, -1.3351e-05],\n",
       "         [-3.4571e-05, -5.7742e-07, -1.1444e-05,  ..., -2.6464e-05,\n",
       "          -1.3256e-04, -6.3330e-07],\n",
       "         ...,\n",
       "         [-2.2352e-06,  5.7518e-06,  7.3910e-06,  ..., -6.3896e-05,\n",
       "           7.4863e-05,  1.2159e-05],\n",
       "         [ 1.0252e-05, -2.1905e-06, -5.9307e-06,  ..., -4.1127e-06,\n",
       "          -4.5776e-05, -5.7044e-08],\n",
       "         [ 6.5327e-05,  2.3656e-07,  2.0504e-05,  ..., -6.6757e-06,\n",
       "          -1.4973e-04,  9.5367e-06]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>25<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.3471e-05, -2.1458e-05, -1.0431e-05,  ...,  1.7524e-05,\n",
       "          -1.0371e-05,  1.1086e-05],\n",
       "         [-1.1444e-05,  4.1723e-06,  2.0504e-05,  ..., -1.1444e-05,\n",
       "           1.2338e-05, -8.6427e-06],\n",
       "         [-5.9307e-06,  8.9407e-06,  1.1146e-05,  ...,  1.2517e-06,\n",
       "           6.7949e-06, -1.3292e-05],\n",
       "         ...,\n",
       "         [ 7.2479e-05,  8.2970e-05, -9.6798e-05,  ..., -4.1723e-05,\n",
       "          -1.4687e-04,  3.9816e-05],\n",
       "         [-3.7849e-06,  5.6326e-06, -2.3097e-06,  ...,  1.6928e-05,\n",
       "          -2.5034e-05, -2.4885e-06],\n",
       "         [-1.4752e-06,  7.4863e-05, -3.2425e-05,  ...,  2.6584e-05,\n",
       "          -1.0550e-05,  2.5779e-06]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>25<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.1981e-05,  1.8239e-05, -1.6391e-07,  ..., -1.4067e-05,\n",
       "           9.5367e-06, -4.7922e-05],\n",
       "         [ 5.5432e-06,  2.7299e-05, -5.7459e-05,  ...,  2.2054e-06,\n",
       "          -4.1485e-05, -6.6757e-05],\n",
       "         [-8.2850e-06,  4.2200e-05, -4.2200e-05,  ...,  5.2154e-06,\n",
       "           4.3869e-05, -6.2466e-05],\n",
       "         ...,\n",
       "         [-1.2144e-06, -2.5029e-08,  2.9325e-05,  ..., -8.5235e-06,\n",
       "           4.8876e-06, -3.6210e-06],\n",
       "         [ 1.5736e-05, -1.3351e-05, -1.2338e-05,  ...,  1.7524e-05,\n",
       "          -1.0967e-05,  1.4484e-05],\n",
       "         [-5.4538e-06, -6.0797e-05,  2.8372e-05,  ...,  1.7285e-05,\n",
       "           4.0829e-06, -8.0109e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>25<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.8372e-05,  3.7193e-05,  6.6459e-06,  ...,  1.8358e-05,\n",
       "           3.1233e-05,  6.2585e-06],\n",
       "         [ 2.0146e-05, -2.5630e-05, -1.3411e-05,  ...,  3.9816e-05,\n",
       "           2.5034e-05,  2.4199e-05],\n",
       "         [ 3.1471e-05,  1.0729e-05,  2.8014e-06,  ...,  4.8280e-06,\n",
       "          -2.5630e-06, -4.1008e-05],\n",
       "         ...,\n",
       "         [-6.0499e-06, -8.2970e-05,  4.7922e-05,  ...,  3.3617e-05,\n",
       "           1.0443e-04,  6.2466e-05],\n",
       "         [ 1.8001e-05,  8.8215e-06, -9.0003e-06,  ..., -6.7055e-06,\n",
       "          -8.8811e-06,  3.7551e-06],\n",
       "         [ 1.0431e-05,  2.0146e-05, -3.1471e-05,  ..., -1.1981e-05,\n",
       "          -1.6928e-05, -9.8348e-07]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>26<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.4019e-04,  7.2956e-05,  1.4305e-04,  ..., -1.3471e-05,\n",
       "           3.8862e-05, -4.1008e-05],\n",
       "         [ 2.2888e-05, -2.1100e-05, -2.9325e-05,  ...,  5.9009e-06,\n",
       "           1.5080e-05,  5.7697e-05],\n",
       "         [ 9.3579e-06, -9.7156e-06, -1.8835e-05,  ...,  8.7619e-06,\n",
       "          -1.2755e-05,  1.2398e-05],\n",
       "         ...,\n",
       "         [-4.4584e-05,  5.4538e-06, -6.8188e-05,  ...,  3.8445e-06,\n",
       "          -1.2934e-05, -1.4782e-04],\n",
       "         [ 3.3975e-06, -5.2750e-06,  2.0564e-06,  ...,  1.5616e-05,\n",
       "          -1.8477e-05,  8.2850e-06],\n",
       "         [-2.2173e-05,  2.1935e-05,  1.5974e-05,  ..., -9.4771e-06,\n",
       "           6.5267e-06, -4.4823e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>26<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.7518e-06, -5.8115e-06, -3.6240e-05,  ..., -6.6459e-06,\n",
       "           2.5392e-05, -1.8239e-05],\n",
       "         [-9.6112e-07, -3.8743e-06, -2.7895e-05,  ..., -8.1658e-06,\n",
       "          -3.0279e-05, -3.3855e-05],\n",
       "         [ 1.4484e-05, -1.7524e-05, -9.1195e-06,  ...,  1.2219e-05,\n",
       "          -1.5125e-06, -7.6741e-07],\n",
       "         ...,\n",
       "         [-1.7047e-05, -2.6226e-06,  1.2815e-05,  ..., -6.9141e-06,\n",
       "          -8.5235e-06, -3.9935e-06],\n",
       "         [ 4.4405e-06, -1.2040e-05,  4.7922e-05,  ..., -1.9550e-05,\n",
       "           1.6332e-05, -1.5736e-05],\n",
       "         [ 8.5235e-06, -5.3942e-06, -2.6584e-05,  ...,  2.7537e-05,\n",
       "           1.5378e-05, -9.5367e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>26<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 6.5804e-05,  3.8862e-05, -7.3314e-06,  ...,  2.6345e-05,\n",
       "          -5.8651e-05,  1.5736e-05],\n",
       "         [ 3.3379e-05, -4.4107e-05,  1.3411e-05,  ..., -5.5552e-05,\n",
       "          -1.6117e-04, -1.9550e-05],\n",
       "         [-8.1956e-07, -3.0279e-05,  2.6673e-06,  ..., -6.1512e-05,\n",
       "          -7.5340e-05,  1.7047e-05],\n",
       "         ...,\n",
       "         [-4.7207e-05,  5.6505e-05, -3.1479e-07,  ..., -2.0862e-05,\n",
       "           5.6744e-05, -3.4124e-06],\n",
       "         [ 2.4796e-05, -4.5776e-05, -9.3579e-06,  ...,  6.1095e-06,\n",
       "           3.3140e-05,  1.0133e-05],\n",
       "         [ 6.4671e-06, -4.1008e-05, -1.7643e-05,  ..., -3.6716e-05,\n",
       "           2.5749e-05,  1.9073e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>27<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.8001e-05, -1.1250e-06, -1.5140e-05,  ..., -1.1027e-05,\n",
       "          -5.2929e-05,  6.9141e-05],\n",
       "         [ 3.5763e-05, -9.0152e-07,  1.8626e-07,  ...,  1.6689e-05,\n",
       "          -5.8413e-05,  3.7670e-05],\n",
       "         [-1.6451e-05,  1.2040e-05,  2.0742e-05,  ..., -1.1206e-05,\n",
       "           4.8578e-06,  7.3612e-06],\n",
       "         ...,\n",
       "         [ 1.4424e-05,  2.3842e-05, -6.0797e-05,  ...,  1.6838e-06,\n",
       "          -4.7445e-05,  3.8862e-05],\n",
       "         [ 8.8811e-06, -8.1658e-06, -1.3351e-05,  ...,  9.1195e-06,\n",
       "          -1.4305e-05, -2.7120e-06],\n",
       "         [ 5.4598e-05,  6.1989e-05,  7.5340e-05,  ...,  7.8201e-05,\n",
       "           7.5817e-05, -9.2030e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>27<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.0068e-05, -3.6478e-05, -4.9472e-06,  ...,  3.6955e-05,\n",
       "          -2.9087e-05, -1.5450e-04],\n",
       "         [-4.1246e-05,  1.1635e-04,  1.4603e-05,  ..., -2.8014e-05,\n",
       "          -3.5286e-05,  7.2479e-05],\n",
       "         [ 2.1338e-05, -3.7849e-06,  1.9431e-05,  ...,  1.5736e-05,\n",
       "          -3.1471e-05,  1.9193e-05],\n",
       "         ...,\n",
       "         [-5.2899e-07, -1.5616e-05,  1.9073e-05,  ...,  1.8105e-06,\n",
       "          -1.5080e-05, -1.1265e-05],\n",
       "         [-2.2054e-05,  7.3910e-06,  2.8312e-06,  ..., -1.1802e-05,\n",
       "           1.8716e-05, -8.7619e-06],\n",
       "         [-4.3631e-05,  2.2173e-05, -1.8835e-05,  ..., -5.8174e-05,\n",
       "          -3.0994e-05,  7.2479e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>27<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.3053e-05,  1.9908e-05,  6.0499e-06,  ..., -6.6280e-05,\n",
       "           1.0014e-05, -1.4484e-05],\n",
       "         [-8.8215e-06, -4.6015e-05, -1.4544e-05,  ..., -3.2187e-05,\n",
       "          -3.0518e-05, -2.4199e-05],\n",
       "         [ 2.1815e-05,  6.6280e-05, -3.0398e-06,  ..., -3.4809e-05,\n",
       "          -4.0233e-06, -1.2368e-06],\n",
       "         ...,\n",
       "         [-5.2691e-05,  1.8239e-05,  1.4305e-05,  ...,  1.8001e-05,\n",
       "          -5.7697e-05, -2.1815e-05],\n",
       "         [-2.1100e-05, -2.9802e-05,  1.7643e-05,  ...,  2.2203e-06,\n",
       "           3.0994e-06, -1.3769e-05],\n",
       "         [ 7.5340e-05, -6.5804e-05,  6.0081e-05,  ..., -4.5776e-05,\n",
       "           9.8944e-06, -9.5367e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>28<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 4.3392e-05,  6.1691e-06,  9.2983e-06,  ..., -1.6499e-04,\n",
       "           8.6308e-05,  2.5177e-04],\n",
       "         [ 3.1471e-05,  4.3631e-05, -2.2292e-05,  ..., -4.0829e-06,\n",
       "          -8.9645e-05,  2.2411e-04],\n",
       "         [-9.5367e-06, -2.6822e-05, -5.8711e-06,  ...,  1.5378e-05,\n",
       "           9.7156e-06,  1.8954e-05],\n",
       "         ...,\n",
       "         [-1.6212e-05, -1.0729e-04, -2.8968e-05,  ...,  5.2929e-05,\n",
       "           1.7524e-05, -1.1969e-04],\n",
       "         [-1.1027e-05,  3.8862e-05,  2.9206e-05,  ..., -1.2338e-05,\n",
       "          -7.5400e-06,  1.6689e-04],\n",
       "         [ 8.1062e-06,  2.8312e-06, -8.4639e-06,  ...,  1.4544e-05,\n",
       "          -2.9355e-06,  2.2531e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>28<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.2292e-05, -9.2983e-05, -7.7724e-05,  ..., -2.0385e-05,\n",
       "          -7.4208e-06, -6.4850e-05],\n",
       "         [ 1.6809e-05, -2.5749e-05, -1.2577e-05,  ...,  9.6560e-06,\n",
       "          -1.6928e-05, -1.2740e-06],\n",
       "         [-5.3942e-06, -1.8239e-05, -3.7909e-05,  ...,  5.9128e-05,\n",
       "          -2.7061e-05, -7.5340e-05],\n",
       "         ...,\n",
       "         [ 2.9802e-05, -5.9128e-05, -5.9307e-06,  ...,  1.8001e-05,\n",
       "           5.9009e-06, -1.2398e-04],\n",
       "         [ 2.1100e-05, -4.8161e-05,  6.3419e-05,  ..., -3.2932e-06,\n",
       "          -3.7998e-06,  1.3173e-05],\n",
       "         [ 3.8862e-05, -3.6716e-05, -4.5776e-05,  ...,  4.5076e-07,\n",
       "          -3.0279e-05,  6.1035e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>28<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.7776e-05,  7.3910e-06, -1.4424e-05,  ...,  4.9353e-05,\n",
       "           1.4842e-05,  1.9670e-05],\n",
       "         [ 6.5863e-06,  3.2187e-05, -1.9073e-06,  ..., -4.7445e-05,\n",
       "           6.5327e-05, -5.4240e-06],\n",
       "         [ 6.3777e-06, -1.6570e-05, -2.6703e-05,  ..., -9.2983e-06,\n",
       "           3.7670e-05,  3.6478e-05],\n",
       "         ...,\n",
       "         [-5.6744e-05,  6.1512e-05,  7.3433e-05,  ..., -5.6982e-05,\n",
       "           5.9366e-05, -1.8358e-05],\n",
       "         [-3.6210e-06,  8.6427e-06, -3.2187e-05,  ...,  1.5259e-05,\n",
       "          -8.0109e-05, -2.7180e-05],\n",
       "         [ 3.2902e-05,  2.1696e-05, -3.1948e-05,  ...,  7.7724e-05,\n",
       "          -8.3923e-05, -3.0279e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>29<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.8179e-06,  6.5327e-05, -3.4571e-05,  ..., -4.2021e-06,\n",
       "           2.0742e-05,  3.5048e-05],\n",
       "         [-1.9550e-05,  1.9431e-05, -1.5616e-05,  ..., -2.4557e-05,\n",
       "           1.6093e-05,  1.4901e-05],\n",
       "         [ 3.3617e-05,  5.6028e-05,  5.5313e-05,  ...,  4.3511e-06,\n",
       "          -2.5988e-05, -8.7738e-05],\n",
       "         ...,\n",
       "         [ 2.2054e-06, -4.7684e-05,  2.1696e-05,  ..., -6.0320e-05,\n",
       "           7.0095e-05, -2.6345e-05],\n",
       "         [-2.2650e-05,  3.3140e-05,  2.2650e-05,  ..., -1.4842e-05,\n",
       "           1.5080e-05, -5.5134e-06],\n",
       "         [ 1.3232e-05, -1.2159e-04,  3.6240e-05,  ...,  3.8147e-05,\n",
       "          -4.0293e-05, -1.1802e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>29<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.7180e-05,  1.7732e-06, -1.7166e-05,  ...,  2.3246e-06,\n",
       "          -3.0994e-06,  1.4365e-05],\n",
       "         [ 6.9737e-06,  9.0003e-06,  3.7670e-05,  ...,  1.1981e-05,\n",
       "           2.7120e-06, -2.7567e-07],\n",
       "         [ 1.2696e-05, -2.2292e-05, -5.0962e-06,  ...,  3.7849e-06,\n",
       "          -1.2457e-05,  9.3579e-06],\n",
       "         ...,\n",
       "         [-2.8610e-06,  1.8954e-05, -9.5367e-06,  ...,  1.3292e-05,\n",
       "          -4.5300e-06, -1.3232e-05],\n",
       "         [ 1.7285e-05,  9.9540e-06, -1.9908e-05,  ...,  2.6941e-05,\n",
       "           8.8662e-07, -5.9366e-05],\n",
       "         [ 5.1260e-06,  5.8115e-06,  5.9605e-05,  ...,  8.4639e-06,\n",
       "          -7.2420e-06,  1.2636e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>29<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-9.5844e-05, -5.1498e-05, -1.2398e-05,  ..., -9.2030e-05,\n",
       "           3.8862e-05,  3.8147e-05],\n",
       "         [-1.0204e-04,  6.8188e-05,  1.2636e-05,  ..., -2.5749e-05,\n",
       "          -1.6689e-05, -6.0081e-05],\n",
       "         [ 2.9206e-05, -6.9618e-05, -4.8637e-05,  ..., -3.5763e-06,\n",
       "           5.8651e-05,  6.3419e-05],\n",
       "         ...,\n",
       "         [ 7.5817e-05, -1.0550e-05, -2.6822e-05,  ..., -4.6253e-05,\n",
       "          -2.8133e-05,  1.0109e-04],\n",
       "         [ 4.6730e-05,  1.6093e-05,  1.6689e-06,  ...,  2.0385e-05,\n",
       "           5.3346e-06, -1.0729e-04],\n",
       "         [-6.4969e-06,  3.3379e-05,  2.0623e-05,  ..., -4.5776e-05,\n",
       "          -2.4915e-05, -6.9439e-06]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>30<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.4080e-05, -9.1076e-05,  1.2219e-05,  ...,  7.2479e-05,\n",
       "           6.9439e-06, -4.9829e-05],\n",
       "         [-1.4186e-05, -5.9605e-06,  6.6459e-06,  ..., -1.0610e-05,\n",
       "          -3.8743e-06,  1.2577e-05],\n",
       "         [ 6.9737e-06, -5.5432e-06, -2.1458e-05,  ..., -3.2783e-06,\n",
       "           4.3511e-06,  7.6771e-05],\n",
       "         ...,\n",
       "         [-1.3828e-05, -1.5259e-05,  3.6001e-05,  ...,  3.4094e-05,\n",
       "           8.5831e-06, -2.2650e-05],\n",
       "         [-9.3937e-05,  2.6703e-05,  4.0770e-05,  ...,  2.8908e-06,\n",
       "          -8.6308e-05, -4.9353e-05],\n",
       "         [-6.6280e-05,  1.4687e-04, -1.8954e-05,  ..., -7.9632e-05,\n",
       "           5.1498e-05,  3.8147e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>30<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.7166e-05, -4.2915e-05,  6.2883e-06,  ..., -1.0014e-05,\n",
       "           1.6093e-05,  1.7881e-05],\n",
       "         [ 6.1989e-05, -1.0777e-04, -2.6822e-05,  ...,  3.8147e-06,\n",
       "           3.6061e-06, -6.1035e-05],\n",
       "         [-4.5300e-06,  4.5538e-05,  4.4823e-05,  ...,  3.8385e-05,\n",
       "           5.5313e-05, -3.9101e-05],\n",
       "         ...,\n",
       "         [-3.9339e-06,  6.8843e-06,  2.5034e-05,  ..., -2.8968e-05,\n",
       "           8.4639e-06,  2.7061e-05],\n",
       "         [ 1.8358e-05, -2.4080e-05, -2.9802e-05,  ...,  1.8239e-05,\n",
       "          -2.0742e-05, -3.3140e-05],\n",
       "         [ 5.9366e-05, -6.6280e-05, -4.3631e-05,  ..., -1.3256e-04,\n",
       "           8.7738e-05, -5.4121e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>30<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.4557e-05,  3.3379e-05,  4.5061e-05,  ...,  2.8610e-05,\n",
       "           2.6822e-05,  8.5831e-05],\n",
       "         [-2.4438e-05,  1.9521e-06, -2.0504e-05,  ..., -5.7936e-05,\n",
       "           3.0279e-05,  1.1921e-04],\n",
       "         [-1.3530e-05, -1.1086e-05, -1.9193e-05,  ..., -6.1989e-05,\n",
       "           1.1086e-05, -2.2221e-04],\n",
       "         ...,\n",
       "         [-1.0848e-05, -3.8385e-05,  1.5855e-05,  ...,  8.1539e-05,\n",
       "          -7.4387e-05, -8.7261e-05],\n",
       "         [ 7.1526e-05, -2.3603e-05, -7.1526e-05,  ...,  4.5061e-05,\n",
       "          -1.7166e-05, -9.9659e-05],\n",
       "         [ 2.0266e-05, -1.0133e-05,  7.8678e-05,  ..., -4.6730e-05,\n",
       "          -3.0100e-06, -1.8597e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>31<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.9312e-05,  4.5538e-05, -5.1260e-06,  ..., -1.1146e-05,\n",
       "           1.6689e-05,  9.2983e-06],\n",
       "         [-4.7982e-06,  3.8147e-05,  1.8835e-05,  ..., -4.0829e-06,\n",
       "          -1.4842e-05,  1.0550e-05],\n",
       "         [ 2.2888e-05, -3.0845e-06,  3.7402e-06,  ...,  6.5804e-05,\n",
       "           4.9829e-05, -8.3447e-05],\n",
       "         ...,\n",
       "         [-4.8578e-06,  6.9141e-05,  1.5736e-05,  ..., -3.8147e-06,\n",
       "          -9.7275e-05,  1.2577e-05],\n",
       "         [ 2.0981e-05, -6.9737e-06,  1.2219e-05,  ..., -1.3828e-04,\n",
       "          -1.1206e-04,  9.5844e-05],\n",
       "         [ 1.7643e-05, -8.4877e-05,  3.3617e-05,  ...,  1.3053e-05,\n",
       "          -1.2302e-04, -1.4529e-07]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>31<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.4401e-07, -2.6226e-06, -9.8348e-06,  ..., -7.3612e-06,\n",
       "           1.5125e-06, -1.4782e-05],\n",
       "         [ 5.9977e-07, -7.1049e-05, -3.1710e-05,  ...,  1.8835e-05,\n",
       "          -2.9922e-05,  5.8413e-06],\n",
       "         [ 7.2718e-06, -1.8597e-05,  1.0300e-04,  ..., -3.3855e-05,\n",
       "          -7.3910e-06,  3.4809e-05],\n",
       "         ...,\n",
       "         [-1.7524e-05, -5.8889e-05,  2.3007e-05,  ...,  2.8163e-06,\n",
       "           1.1444e-05,  1.9431e-05],\n",
       "         [ 9.7752e-06, -8.1539e-05,  7.3433e-05,  ...,  2.4915e-05,\n",
       "           2.8372e-05, -1.4603e-05],\n",
       "         [-1.2040e-05,  1.9169e-04, -2.4557e-05,  ..., -6.1035e-05,\n",
       "           1.7047e-05, -2.1815e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>31<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.1458e-05,  1.7166e-05, -2.5183e-06,  ...,  1.4424e-05,\n",
       "           4.8161e-05,  1.5259e-04],\n",
       "         [-1.0729e-05, -3.6240e-05, -3.5286e-05,  ...,  2.8491e-05,\n",
       "          -4.4346e-05,  4.8637e-05],\n",
       "         [-6.7353e-06, -9.0003e-06, -2.2769e-05,  ..., -4.4346e-05,\n",
       "          -3.8528e-04, -3.7909e-05],\n",
       "         ...,\n",
       "         [ 6.1095e-06,  4.0054e-05,  2.2292e-05,  ..., -1.8626e-06,\n",
       "           2.1338e-05,  5.1022e-05],\n",
       "         [ 1.5616e-05, -2.0117e-06,  4.0531e-05,  ..., -3.6001e-05,\n",
       "          -1.5545e-04, -1.7071e-04],\n",
       "         [-2.9802e-05,  3.0041e-05,  3.8385e-05,  ..., -4.5776e-05,\n",
       "           1.5354e-04, -3.9577e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>32<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-3.0279e-05, -8.1658e-06, -8.6308e-05,  ..., -4.5538e-05,\n",
       "           8.2493e-05,  2.1100e-05],\n",
       "         [ 3.0756e-05, -1.5020e-05,  6.8188e-05,  ..., -3.0279e-05,\n",
       "          -2.0742e-05,  6.6459e-06],\n",
       "         [-1.5140e-05, -8.8215e-05,  4.4584e-05,  ...,  1.5497e-05,\n",
       "           3.6478e-05, -9.1076e-05],\n",
       "         ...,\n",
       "         [ 7.2122e-06,  1.2112e-04, -1.3411e-05,  ...,  1.2755e-05,\n",
       "           5.5552e-05, -7.1824e-06],\n",
       "         [ 3.6716e-05,  2.4414e-04,  7.7248e-05,  ..., -7.1824e-06,\n",
       "           2.1100e-05, -5.9366e-05],\n",
       "         [-1.6785e-04, -9.9659e-05, -6.0797e-06,  ..., -1.5163e-04,\n",
       "           7.2002e-05,  1.7643e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>32<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 9.5367e-05, -7.9155e-05, -1.5068e-04,  ..., -6.7711e-05,\n",
       "          -4.7207e-05,  3.5286e-05],\n",
       "         [ 3.9339e-05, -1.6391e-06,  2.0266e-05,  ..., -8.4400e-05,\n",
       "           9.0897e-07,  1.0192e-05],\n",
       "         [-2.0981e-05,  4.1962e-05, -1.3590e-05,  ...,  8.2850e-06,\n",
       "           2.7776e-05, -1.1921e-05],\n",
       "         ...,\n",
       "         [ 1.6212e-05, -3.0160e-05, -5.3406e-05,  ...,  2.0742e-05,\n",
       "          -1.3161e-04,  5.6744e-05],\n",
       "         [-9.1195e-06,  8.5235e-06,  7.9274e-06,  ..., -1.8775e-06,\n",
       "           1.5736e-05,  3.0696e-06],\n",
       "         [-4.0829e-06, -3.5524e-05,  6.2466e-05,  ...,  4.1910e-07,\n",
       "          -2.2173e-05,  9.0599e-06]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>32<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.0041e-05,  4.5061e-05, -2.0504e-05,  ..., -3.4273e-06,\n",
       "          -4.0531e-06,  1.6308e-04],\n",
       "         [ 1.8120e-05,  2.8372e-05,  2.5153e-05,  ...,  4.1008e-05,\n",
       "           2.0146e-05,  1.2740e-06],\n",
       "         [ 1.9908e-05,  3.6001e-05, -4.7207e-05,  ..., -2.0027e-05,\n",
       "          -6.5804e-05, -2.2650e-05],\n",
       "         ...,\n",
       "         [ 5.6744e-05,  3.3855e-05,  4.5776e-05,  ...,  2.0146e-05,\n",
       "           8.5831e-06, -2.6107e-05],\n",
       "         [-5.3883e-05,  1.8024e-04, -3.2663e-05,  ..., -1.0133e-05,\n",
       "          -1.2934e-05,  4.3869e-05],\n",
       "         [ 2.2769e-05,  3.6716e-05, -2.5511e-05,  ...,  3.7193e-05,\n",
       "          -1.5378e-05, -9.2387e-06]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>33<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.8992e-04, -8.4043e-06, -1.0490e-04,  ...,  4.2439e-05,\n",
       "           5.4017e-07, -9.8348e-06],\n",
       "         [ 5.9605e-05,  6.5327e-05,  1.0252e-04,  ...,  8.3923e-05,\n",
       "          -1.8406e-04, -1.0538e-04],\n",
       "         [ 2.6077e-06, -1.3292e-05, -7.6890e-06,  ..., -3.5763e-05,\n",
       "          -7.4863e-05,  1.7166e-05],\n",
       "         ...,\n",
       "         [ 3.6716e-05,  1.5259e-04,  4.7922e-05,  ...,  6.1035e-05,\n",
       "           1.1301e-04, -1.2994e-05],\n",
       "         [-4.4823e-05, -6.4850e-05,  3.1948e-05,  ..., -4.2915e-05,\n",
       "          -1.9431e-05,  3.6359e-06],\n",
       "         [-1.0824e-04, -2.2316e-04,  2.0504e-05,  ..., -1.3638e-04,\n",
       "          -3.6478e-05,  2.0385e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>33<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 1.9431e-05, -5.4240e-06,  3.4869e-06,  ...,  2.5511e-05,\n",
       "           2.4289e-06, -1.8120e-05],\n",
       "         [-1.2040e-05, -8.1062e-06,  1.0133e-05,  ...,  9.0003e-06,\n",
       "           1.7643e-05, -1.6212e-05],\n",
       "         [ 5.3942e-06,  2.0313e-04,  2.7061e-05,  ...,  3.0518e-05,\n",
       "           6.0558e-05,  1.0192e-05],\n",
       "         ...,\n",
       "         [ 1.3113e-05,  8.6427e-06, -8.5831e-06,  ...,  1.0073e-05,\n",
       "           1.6332e-05, -1.3351e-05],\n",
       "         [ 1.4007e-05,  5.1498e-05, -2.3484e-05,  ..., -6.9618e-05,\n",
       "           5.1498e-05,  9.5367e-06],\n",
       "         [ 4.9829e-05, -6.8665e-05, -4.1246e-05,  ...,  8.7619e-06,\n",
       "           1.1697e-06, -3.4571e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>33<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.3471e-05,  2.8908e-06, -1.1981e-05,  ..., -1.3113e-05,\n",
       "          -1.9193e-05,  8.2970e-05],\n",
       "         [ 3.2663e-05,  1.7524e-05,  2.9922e-05,  ...,  2.6584e-05,\n",
       "           2.0266e-06,  8.0109e-05],\n",
       "         [-1.7166e-05, -1.5736e-05, -2.9445e-05,  ..., -3.2425e-05,\n",
       "          -2.0027e-04, -2.1553e-04],\n",
       "         ...,\n",
       "         [ 9.9659e-05,  2.2769e-05, -7.3433e-05,  ...,  1.9670e-05,\n",
       "          -2.3723e-05,  1.4305e-04],\n",
       "         [ 3.8743e-06, -9.8944e-06, -2.9802e-05,  ..., -2.5272e-05,\n",
       "          -1.5736e-04,  1.0681e-04],\n",
       "         [-2.0146e-05, -1.6913e-06, -3.2425e-05,  ..., -1.9670e-05,\n",
       "           1.3161e-04, -2.0504e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>34<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.5974e-05,  2.5153e-05, -1.3828e-04,  ...,  2.6464e-05,\n",
       "           5.2214e-05, -5.2691e-05],\n",
       "         [ 5.9128e-05,  5.5730e-06,  4.6730e-05,  ...,  1.0908e-05,\n",
       "           1.6570e-05, -8.1062e-06],\n",
       "         [ 3.6478e-05,  1.6332e-05, -1.2815e-05,  ...,  2.9206e-05,\n",
       "          -3.3140e-05, -4.2915e-05],\n",
       "         ...,\n",
       "         [-7.8201e-05, -6.2883e-06,  5.1975e-05,  ...,  4.4823e-05,\n",
       "          -1.9908e-05, -9.1553e-05],\n",
       "         [ 2.4033e-04,  1.3161e-04,  5.6267e-05,  ..., -2.7537e-05,\n",
       "          -2.4414e-04,  4.9353e-05],\n",
       "         [-2.0862e-05, -1.2636e-05,  6.3330e-07,  ..., -1.4722e-05,\n",
       "          -1.2040e-05,  1.5497e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>34<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 3.1710e-05, -7.2956e-05,  1.2875e-04,  ..., -2.3961e-05,\n",
       "          -3.7193e-05,  4.2200e-05],\n",
       "         [ 4.9353e-05,  2.5034e-05,  5.2452e-05,  ...,  1.7166e-05,\n",
       "           2.3723e-05, -1.4603e-05],\n",
       "         [ 6.3330e-07, -1.1742e-05,  5.3883e-05,  ..., -1.7643e-05,\n",
       "          -9.1195e-06,  1.5259e-05],\n",
       "         ...,\n",
       "         [ 5.3406e-05,  4.1485e-05, -1.2207e-04,  ...,  4.9829e-05,\n",
       "           3.2187e-05, -6.4850e-05],\n",
       "         [ 2.8419e-04,  2.1744e-04, -4.1246e-05,  ..., -1.2338e-05,\n",
       "          -2.2125e-04,  2.7537e-05],\n",
       "         [-2.7180e-05, -1.7956e-06,  2.7299e-05,  ...,  7.2718e-06,\n",
       "          -3.2663e-05,  3.8624e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>34<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-7.3910e-05, -3.1471e-05, -3.3379e-05,  ...,  8.6784e-05,\n",
       "           5.0306e-05,  2.6822e-05],\n",
       "         [-2.6107e-05,  1.6570e-05, -2.6077e-06,  ..., -8.6427e-07,\n",
       "           1.4663e-05,  1.8775e-06],\n",
       "         [-5.9128e-05,  1.2696e-05, -8.8811e-06,  ...,  6.4850e-05,\n",
       "          -9.2983e-05, -2.6107e-05],\n",
       "         ...,\n",
       "         [-7.1526e-05,  1.2219e-05,  5.0664e-07,  ...,  3.3140e-05,\n",
       "           9.4414e-05, -2.5272e-05],\n",
       "         [-5.0545e-05, -5.4240e-06, -3.3617e-05,  ...,  4.2439e-05,\n",
       "           1.6689e-04,  1.3337e-06],\n",
       "         [-1.1158e-04, -1.1802e-05, -2.6703e-05,  ...,  1.4305e-05,\n",
       "           4.6253e-05,  5.5134e-06]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>35<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-8.0466e-06, -1.6212e-05,  2.2411e-05,  ..., -4.7982e-06,\n",
       "          -3.4720e-06,  2.1815e-05],\n",
       "         [ 3.5763e-05,  6.5804e-05,  1.5545e-04,  ..., -1.0157e-04,\n",
       "           1.0014e-04,  1.5831e-04],\n",
       "         [-2.1553e-04, -2.2793e-04,  1.5354e-04,  ...,  2.0742e-05,\n",
       "           8.5831e-05,  8.6784e-05],\n",
       "         ...,\n",
       "         [-9.5367e-05, -3.8862e-05,  9.6798e-05,  ..., -4.6968e-05,\n",
       "          -4.2200e-05,  4.5300e-05],\n",
       "         [-9.1553e-05, -2.8968e-05,  2.8133e-05,  ..., -2.3842e-05,\n",
       "           2.3484e-05,  1.0490e-05],\n",
       "         [ 6.7055e-06, -2.7299e-05,  3.2187e-05,  ..., -2.7299e-05,\n",
       "          -5.3883e-05,  5.5134e-06]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>35<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 4.9472e-06,  2.1100e-05,  2.9922e-05,  ...,  1.6570e-05,\n",
       "           2.1577e-05,  5.0366e-06],\n",
       "         [ 8.4043e-06,  8.6427e-06,  3.0160e-05,  ...,  2.1011e-06,\n",
       "          -2.3007e-05, -2.3961e-05],\n",
       "         [-4.1723e-05, -3.3140e-05, -1.3924e-04,  ..., -2.4676e-05,\n",
       "          -2.8729e-05,  1.7762e-05],\n",
       "         ...,\n",
       "         [-4.8161e-05, -1.5855e-05, -4.8161e-05,  ...,  1.2934e-05,\n",
       "          -7.6771e-05, -1.4961e-05],\n",
       "         [-3.5048e-05, -2.0266e-05,  7.7724e-05,  ..., -1.3828e-05,\n",
       "          -1.9789e-05,  7.1526e-06],\n",
       "         [ 3.5018e-06, -8.8215e-06,  2.7418e-05,  ..., -1.4126e-05,\n",
       "           1.8001e-05,  1.8239e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>35<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.7180e-05, -3.9816e-05,  9.1553e-05,  ...,  2.4915e-05,\n",
       "           6.6161e-06,  7.6771e-05],\n",
       "         [ 1.5199e-05, -2.9802e-05, -1.2302e-04,  ...,  8.2970e-05,\n",
       "           7.2956e-05, -3.0041e-05],\n",
       "         [-4.3809e-06, -7.4804e-06, -4.5061e-05,  ...,  2.3723e-05,\n",
       "           8.7261e-05, -3.1948e-05],\n",
       "         ...,\n",
       "         [-3.9101e-05, -2.9087e-05, -3.3140e-05,  ...,  2.8372e-05,\n",
       "           7.8201e-05, -2.9445e-05],\n",
       "         [ 3.6478e-05,  1.9073e-05, -4.2677e-05,  ..., -1.9312e-05,\n",
       "          -1.0347e-04, -1.4663e-05],\n",
       "         [ 1.7166e-05, -4.2439e-05, -4.4584e-05,  ...,  1.7166e-05,\n",
       "          -4.6253e-05, -2.7180e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>36<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-5.2452e-05,  1.1802e-05, -1.9193e-05,  ..., -4.7088e-06,\n",
       "           5.8174e-05, -1.4663e-05],\n",
       "         [ 3.9816e-05, -9.0599e-05,  1.6689e-04,  ..., -1.8001e-05,\n",
       "           2.4438e-05, -1.7881e-05],\n",
       "         [-1.7643e-04,  3.1471e-04, -1.7357e-04,  ...,  5.5313e-05,\n",
       "          -3.2806e-04,  2.3842e-04],\n",
       "         ...,\n",
       "         [-7.2956e-05, -3.1233e-05, -2.4033e-04,  ..., -2.8610e-05,\n",
       "          -2.9683e-05, -1.2684e-04],\n",
       "         [-1.4603e-05, -1.1826e-04,  1.0490e-05,  ..., -1.4591e-04,\n",
       "          -3.1471e-04,  2.4080e-05],\n",
       "         [-1.5163e-04,  1.2207e-04, -1.0729e-04,  ..., -1.5497e-05,\n",
       "           6.4850e-05,  1.1206e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>36<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-6.3419e-05,  1.6019e-06,  2.0742e-05,  ...,  4.3631e-05,\n",
       "          -4.4584e-05, -7.5437e-08],\n",
       "         [-2.0981e-04, -5.4240e-06,  3.0756e-05,  ..., -8.3447e-06,\n",
       "           3.5286e-05, -2.2054e-06],\n",
       "         [-2.9683e-05, -3.3379e-06,  4.4584e-05,  ..., -1.8716e-05,\n",
       "          -1.1861e-05,  2.7418e-05],\n",
       "         ...,\n",
       "         [-5.7817e-06,  1.1444e-05, -7.9870e-06,  ...,  7.9870e-06,\n",
       "           1.1742e-05, -2.2173e-05],\n",
       "         [ 3.7670e-05,  1.8358e-05, -3.1233e-05,  ...,  1.5616e-05,\n",
       "           4.2021e-06, -3.8743e-06],\n",
       "         [ 4.5300e-05, -3.2037e-06, -5.8889e-05,  ...,  7.8678e-06,\n",
       "          -1.2398e-05, -7.9632e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>36<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.9339e-05, -1.1587e-04,  3.8147e-05,  ...,  2.6464e-05,\n",
       "          -3.7432e-05,  7.9155e-05],\n",
       "         [ 6.3479e-06, -4.7922e-05,  4.2915e-05,  ...,  5.8889e-05,\n",
       "          -9.6798e-05, -4.3809e-06],\n",
       "         [-1.4186e-05,  3.9637e-06,  8.1539e-05,  ...,  1.8850e-06,\n",
       "          -5.6505e-05,  3.3617e-05],\n",
       "         ...,\n",
       "         [-2.3484e-05,  1.1873e-04,  9.2983e-05,  ..., -3.0041e-05,\n",
       "          -1.4687e-04, -8.0585e-05],\n",
       "         [-1.3828e-05, -1.9312e-05,  6.3896e-05,  ..., -1.4842e-05,\n",
       "          -5.1022e-05, -1.6332e-05],\n",
       "         [-4.8280e-06,  3.0279e-05, -1.4067e-05,  ..., -9.3579e-06,\n",
       "           4.2200e-05, -6.2585e-06]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>37<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.4782e-04,  3.1233e-05, -4.7207e-05,  ...,  1.6928e-05,\n",
       "           2.2173e-05, -2.8729e-05],\n",
       "         [-4.8161e-05, -2.1100e-05, -1.2302e-04,  ..., -3.2187e-06,\n",
       "           8.5354e-05, -1.1015e-04],\n",
       "         [-1.2493e-04,  2.8014e-05,  5.7817e-06,  ...,  3.0845e-06,\n",
       "          -9.7603e-07,  2.9445e-05],\n",
       "         ...,\n",
       "         [ 4.9591e-05,  1.6332e-05, -1.2112e-04,  ...,  2.0981e-05,\n",
       "           1.0586e-04,  2.0146e-05],\n",
       "         [-1.1921e-07,  5.0306e-05, -1.3351e-04,  ..., -4.6730e-05,\n",
       "          -1.4544e-05, -2.0599e-04],\n",
       "         [-1.1063e-04,  7.7248e-05,  1.8716e-05,  ...,  5.1498e-05,\n",
       "          -8.5354e-05, -1.8978e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>37<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.8978e-04,  1.8001e-05,  4.3869e-05,  ...,  4.7088e-06,\n",
       "           6.5327e-05, -3.6240e-05],\n",
       "         [-5.2452e-05, -1.0192e-05, -4.8876e-06,  ..., -8.2254e-06,\n",
       "           1.9073e-05, -8.3447e-06],\n",
       "         [ 1.6540e-06,  1.7881e-06, -2.2054e-05,  ...,  2.8133e-05,\n",
       "           1.4246e-05, -4.9829e-05],\n",
       "         ...,\n",
       "         [ 9.0003e-06,  2.2173e-05, -2.4438e-05,  ...,  1.7881e-05,\n",
       "           1.1027e-05, -1.6689e-05],\n",
       "         [ 2.7537e-05,  3.0696e-06, -1.9073e-05,  ...,  3.5614e-06,\n",
       "          -5.6744e-05, -1.3828e-05],\n",
       "         [ 8.8811e-06,  1.3530e-05,  1.2994e-05,  ..., -2.2799e-06,\n",
       "           3.4571e-05,  3.7193e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>37<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 5.2452e-05,  1.9550e-05,  9.8944e-06,  ...,  5.3644e-05,\n",
       "           1.2493e-04, -2.0146e-05],\n",
       "         [ 5.2691e-05, -2.5272e-05,  6.6683e-07,  ...,  1.7166e-05,\n",
       "           8.2493e-05, -6.6757e-05],\n",
       "         [ 3.2783e-06, -1.0610e-05, -2.5749e-05,  ..., -1.0490e-05,\n",
       "          -8.3923e-05,  9.1553e-05],\n",
       "         ...,\n",
       "         [ 1.9312e-05,  6.1393e-06,  3.1888e-06,  ...,  7.6890e-06,\n",
       "           3.7909e-05,  2.0742e-05],\n",
       "         [-6.5863e-06, -2.9206e-05, -7.5102e-06,  ..., -7.0035e-06,\n",
       "           3.8385e-05, -2.4199e-05],\n",
       "         [-5.7518e-06,  3.4094e-05,  1.7136e-06,  ..., -1.7732e-06,\n",
       "           4.1485e-05,  5.3644e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>38<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 6.5565e-06, -2.5749e-05, -2.0564e-06,  ..., -1.9908e-05,\n",
       "          -2.2054e-05,  5.8651e-05],\n",
       "         [ 4.3392e-05, -1.7357e-04, -1.4400e-04,  ..., -7.3910e-05,\n",
       "          -1.7285e-05, -8.7544e-07],\n",
       "         [-5.5075e-05, -1.5140e-05,  2.1905e-06,  ...,  1.5736e-05,\n",
       "           6.3896e-05, -3.6716e-05],\n",
       "         ...,\n",
       "         [ 2.2316e-04,  7.6771e-05, -2.0504e-05,  ...,  3.5048e-05,\n",
       "           1.9073e-04,  4.1962e-04],\n",
       "         [ 1.4961e-05,  1.6928e-05, -7.1526e-05,  ...,  3.5316e-06,\n",
       "           4.6194e-06, -5.5075e-05],\n",
       "         [-1.6975e-04, -3.1853e-04,  2.2507e-04,  ..., -1.5926e-04,\n",
       "           1.9264e-04,  1.2338e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>38<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.1267e-04, -5.4359e-05, -3.1143e-06,  ...,  4.5538e-05,\n",
       "          -5.8651e-05,  9.9540e-06],\n",
       "         [ 1.4246e-05,  2.8849e-05,  4.5002e-06,  ...,  1.5616e-05,\n",
       "           4.2677e-05, -8.5831e-06],\n",
       "         [ 6.3419e-05,  1.7047e-05, -1.3113e-05,  ...,  5.1975e-05,\n",
       "           3.7432e-05, -2.1100e-05],\n",
       "         ...,\n",
       "         [ 3.2997e-04, -1.8597e-05,  2.2292e-05,  ..., -1.9550e-05,\n",
       "           1.5450e-04,  2.5368e-04],\n",
       "         [ 6.1512e-05, -1.2219e-05,  5.8413e-06,  ...,  1.8254e-06,\n",
       "          -7.6294e-05,  6.5327e-05],\n",
       "         [ 3.3379e-05, -7.1049e-05,  2.5749e-05,  ...,  6.0081e-05,\n",
       "           2.4796e-04,  7.2002e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>38<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-9.0122e-05,  1.0967e-04,  1.4663e-05,  ..., -6.3181e-06,\n",
       "          -5.0068e-05, -1.1158e-04],\n",
       "         [-6.8665e-05, -2.4796e-05,  5.2691e-05,  ...,  5.7459e-05,\n",
       "           8.9407e-06,  6.1512e-05],\n",
       "         [-1.2159e-05, -1.5068e-04,  1.7643e-05,  ...,  9.5367e-06,\n",
       "          -1.5259e-04, -1.8215e-04],\n",
       "         ...,\n",
       "         [-6.1035e-05,  1.0157e-04, -1.1384e-05,  ..., -4.1008e-05,\n",
       "          -1.9789e-05,  2.9802e-05],\n",
       "         [-1.4424e-05,  8.0466e-06,  3.7104e-06,  ..., -5.1737e-05,\n",
       "          -1.1683e-05,  2.8461e-06],\n",
       "         [-5.3942e-06,  1.7788e-07, -1.8716e-05,  ..., -4.0531e-05,\n",
       "           2.7895e-05, -2.8253e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>39<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.4676e-05, -3.5048e-05,  3.9101e-05,  ...,  3.8862e-05,\n",
       "           3.8147e-05, -4.3869e-05],\n",
       "         [ 1.7434e-06, -1.3542e-04, -7.2002e-05,  ..., -2.7418e-05,\n",
       "           6.5565e-06, -1.3924e-04],\n",
       "         [-7.0572e-05,  3.7384e-04,  6.4373e-05,  ...,  3.2425e-04,\n",
       "           2.4128e-04,  2.5749e-04],\n",
       "         ...,\n",
       "         [ 8.4877e-05,  3.3569e-04,  3.9482e-04,  ...,  4.7922e-05,\n",
       "           1.8024e-04, -1.8311e-04],\n",
       "         [-5.5134e-06, -4.4584e-05, -3.5286e-05,  ...,  2.1338e-05,\n",
       "          -2.2531e-05, -7.0095e-05],\n",
       "         [-1.1873e-04,  6.9618e-05, -2.9755e-04,  ..., -2.5630e-06,\n",
       "          -3.6359e-06,  4.3869e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>39<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.4007e-05, -8.7261e-05, -4.8637e-05,  ...,  5.0962e-06,\n",
       "           1.4186e-05, -4.1008e-05],\n",
       "         [ 2.0385e-05, -5.6744e-05, -3.5524e-05,  ...,  2.0385e-05,\n",
       "           3.4809e-05,  7.5102e-06],\n",
       "         [ 9.8944e-06,  8.2701e-07, -9.9540e-06,  ...,  9.8348e-06,\n",
       "          -5.6982e-05, -2.5272e-05],\n",
       "         ...,\n",
       "         [ 4.4823e-05, -2.0862e-07,  4.4823e-05,  ...,  3.2187e-05,\n",
       "          -6.0201e-06, -5.8174e-05],\n",
       "         [ 2.4796e-05,  1.4842e-05, -1.6809e-05,  ...,  1.9789e-05,\n",
       "          -3.2187e-05, -4.8280e-06],\n",
       "         [-1.6212e-04,  8.4877e-05, -9.1553e-05,  ...,  4.3869e-05,\n",
       "           1.6093e-05, -8.5831e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>39<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.0729e-04,  8.7261e-05, -8.5831e-05,  ..., -5.3167e-05,\n",
       "           1.1492e-04, -3.4571e-05],\n",
       "         [-1.2875e-04,  4.4346e-05,  1.7548e-04,  ..., -3.1590e-06,\n",
       "           2.5749e-05, -1.7405e-05],\n",
       "         [-1.7929e-04, -3.7432e-05, -2.3270e-04,  ..., -1.0252e-04,\n",
       "          -6.2287e-06,  7.4506e-06],\n",
       "         ...,\n",
       "         [-5.8651e-05,  1.2994e-05,  1.0824e-04,  ..., -7.2122e-06,\n",
       "          -7.6294e-05,  3.0696e-06],\n",
       "         [-3.5286e-05,  3.6955e-05,  1.2684e-04,  ..., -3.6716e-05,\n",
       "          -8.0585e-05,  7.2122e-06],\n",
       "         [-7.4863e-05,  1.9908e-05, -4.2021e-06,  ..., -1.8120e-05,\n",
       "           9.8944e-06, -1.1548e-07]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>40<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.2064e-04,  1.8716e-05,  1.3828e-04,  ...,  1.4961e-05,\n",
       "           4.3392e-05, -2.6703e-05],\n",
       "         [ 4.5776e-04,  5.7936e-05,  3.5286e-04,  ..., -1.9968e-06,\n",
       "           1.7357e-04, -4.6730e-05],\n",
       "         [ 2.9922e-05,  5.7459e-05, -5.0783e-05,  ...,  1.1027e-05,\n",
       "           2.9564e-05, -1.7929e-04],\n",
       "         ...,\n",
       "         [-1.7881e-05,  3.9577e-05, -1.4305e-04,  ...,  2.0266e-05,\n",
       "          -4.6253e-05, -2.9945e-04],\n",
       "         [-2.5368e-04,  9.1553e-05, -2.5177e-04,  ..., -1.0014e-04,\n",
       "          -9.8348e-06,  2.1076e-04],\n",
       "         [-5.0545e-05,  1.9908e-05,  1.5068e-04,  ..., -6.6757e-05,\n",
       "           4.2534e-04,  8.4400e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>40<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 9.7603e-07,  2.1935e-05,  5.6505e-05,  ...,  1.4484e-05,\n",
       "          -1.8120e-05, -9.1553e-05],\n",
       "         [ 2.8610e-05,  1.0788e-05, -2.3004e-07,  ...,  1.4067e-05,\n",
       "          -1.2517e-05,  5.7220e-05],\n",
       "         [-3.9101e-05, -1.1384e-05, -1.9789e-05,  ...,  2.5332e-06,\n",
       "           2.4438e-05, -2.3365e-05],\n",
       "         ...,\n",
       "         [ 7.0572e-05, -3.1292e-06, -2.5153e-05,  ...,  4.2021e-06,\n",
       "          -2.1935e-05,  8.9407e-06],\n",
       "         [ 2.1815e-05,  5.5879e-07,  9.1791e-06,  ...,  1.3530e-05,\n",
       "           3.4809e-05, -4.3631e-05],\n",
       "         [-1.3065e-04,  3.2187e-05,  7.6771e-05,  ...,  2.2173e-05,\n",
       "          -6.2466e-05, -5.1498e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>40<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-5.5790e-05, -5.4836e-05,  6.4850e-05,  ...,  1.1444e-05,\n",
       "           3.2425e-05,  7.1228e-06],\n",
       "         [-3.1471e-05,  1.0729e-05,  1.8161e-07,  ..., -4.9174e-06,\n",
       "          -3.7432e-05, -1.4484e-05],\n",
       "         [ 1.1563e-05, -5.9366e-05, -2.8968e-05,  ..., -6.9618e-05,\n",
       "           6.1691e-06, -1.7524e-05],\n",
       "         ...,\n",
       "         [-2.3097e-06, -6.4373e-06, -1.7285e-05,  ..., -6.7055e-06,\n",
       "           1.3709e-05,  1.8477e-05],\n",
       "         [ 1.6809e-05,  1.3560e-06, -2.5511e-05,  ..., -3.0398e-05,\n",
       "           1.0312e-05,  1.4722e-05],\n",
       "         [ 1.1683e-05,  2.6673e-06, -1.0431e-05,  ..., -6.1989e-05,\n",
       "           1.8358e-05,  1.9431e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>41<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.6001e-05,  3.1948e-05, -1.9550e-05,  ..., -2.3842e-06,\n",
       "           7.0632e-06, -1.1349e-04],\n",
       "         [ 9.4771e-06, -1.3733e-04, -1.4973e-04,  ...,  2.5368e-04,\n",
       "           1.0252e-04, -4.1962e-04],\n",
       "         [ 2.0981e-04, -2.6131e-04, -2.1267e-04,  ...,  7.6294e-05,\n",
       "           2.3174e-04,  2.6226e-05],\n",
       "         ...,\n",
       "         [-1.4877e-04,  1.0490e-04, -4.9973e-04,  ..., -9.9182e-05,\n",
       "           7.2956e-05,  1.6403e-04],\n",
       "         [ 1.5259e-05,  5.1022e-05, -6.8188e-05,  ..., -5.4836e-05,\n",
       "          -2.2888e-05,  1.0729e-04],\n",
       "         [-6.5804e-05, -8.0109e-05, -4.6968e-05,  ...,  8.0109e-05,\n",
       "           2.1607e-06, -6.4850e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>41<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.7776e-05,  7.7724e-05, -1.6403e-04,  ..., -5.0545e-05,\n",
       "           2.2602e-04,  6.7711e-05],\n",
       "         [-2.1935e-05, -2.0027e-05, -2.5511e-05,  ...,  4.3809e-06,\n",
       "           5.3644e-06,  7.7486e-06],\n",
       "         [-5.7518e-06, -9.3460e-05,  7.2956e-05,  ...,  4.2915e-05,\n",
       "          -1.0252e-05,  2.5392e-05],\n",
       "         ...,\n",
       "         [-1.9789e-05, -1.5855e-05,  1.2219e-05,  ..., -1.0133e-05,\n",
       "          -2.9683e-05, -8.2850e-06],\n",
       "         [ 1.6093e-05,  1.8597e-05, -2.7269e-06,  ...,  7.0930e-06,\n",
       "          -1.6451e-05, -2.1935e-05],\n",
       "         [-7.3314e-06, -2.2769e-05,  1.4842e-05,  ...,  3.8147e-05,\n",
       "          -2.5988e-05, -2.5511e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>41<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.7762e-05,  2.8849e-05,  3.4332e-05,  ...,  8.4877e-05,\n",
       "          -8.2016e-05,  2.1756e-06],\n",
       "         [ 1.1101e-06,  1.2684e-04, -4.1962e-05,  ..., -1.1349e-04,\n",
       "           2.2173e-05,  2.1338e-05],\n",
       "         [-4.5896e-06,  3.1948e-05, -2.5630e-05,  ...,  1.2696e-05,\n",
       "          -1.9372e-07, -6.0081e-05],\n",
       "         ...,\n",
       "         [-4.2021e-06,  4.7088e-06, -1.0729e-05,  ..., -2.4796e-05,\n",
       "          -6.7949e-06,  1.9312e-05],\n",
       "         [-1.7166e-05, -5.2750e-06,  3.7909e-05,  ..., -3.8147e-05,\n",
       "           1.1158e-04,  8.3923e-05],\n",
       "         [-4.0770e-05,  7.1049e-05,  6.5804e-05,  ...,  6.2466e-05,\n",
       "           3.7193e-05, -5.6624e-07]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>42<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.2616e-04, -1.6928e-05, -3.3379e-04,  ..., -2.9653e-06,\n",
       "          -8.0109e-05,  9.4891e-05],\n",
       "         [-2.3007e-05,  3.2663e-05, -1.7357e-04,  ..., -1.9908e-05,\n",
       "          -2.0742e-05,  1.2442e-06],\n",
       "         [ 1.0133e-05,  6.5327e-05, -6.7428e-07,  ...,  9.8348e-06,\n",
       "           7.1526e-05,  4.6921e-04],\n",
       "         ...,\n",
       "         [-2.4796e-04, -9.2030e-05, -8.8215e-05,  ...,  1.0824e-04,\n",
       "           1.9169e-04, -5.2643e-04],\n",
       "         [-7.5400e-06, -2.2054e-05,  1.7643e-05,  ..., -1.3351e-05,\n",
       "           1.6451e-05, -2.1011e-06],\n",
       "         [ 2.7657e-04, -2.5988e-05,  1.2875e-04,  ...,  7.7248e-05,\n",
       "          -1.2338e-05, -1.4496e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>42<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-5.2452e-05,  1.0395e-04,  1.0669e-05,  ..., -5.4598e-05,\n",
       "          -7.5340e-05,  3.1090e-04],\n",
       "         [ 9.4771e-06, -7.3910e-05, -3.7909e-05,  ..., -2.1577e-05,\n",
       "           7.2956e-05,  5.0545e-05],\n",
       "         [-4.1246e-05, -3.6955e-05, -7.3910e-05,  ..., -2.4557e-05,\n",
       "           6.8247e-06, -3.6478e-05],\n",
       "         ...,\n",
       "         [ 1.6499e-04,  1.4231e-06,  3.7193e-05,  ..., -3.5856e-08,\n",
       "          -3.9816e-05,  1.5974e-05],\n",
       "         [ 1.1742e-05, -2.1309e-06,  4.8161e-05,  ..., -6.0320e-05,\n",
       "          -1.3161e-04,  2.8419e-04],\n",
       "         [ 1.3161e-04, -3.0756e-05,  5.1022e-05,  ...,  6.0558e-05,\n",
       "          -6.9141e-05,  1.8501e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>42<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.0920e-04, -2.0862e-05, -1.5259e-05,  ...,  3.1233e-05,\n",
       "           1.2589e-04, -6.4373e-05],\n",
       "         [ 1.1349e-04, -7.1049e-05, -2.8253e-05,  ..., -3.2187e-05,\n",
       "          -5.8413e-05, -8.8215e-05],\n",
       "         [-7.1526e-05, -2.7657e-05,  1.7285e-05,  ..., -1.0443e-04,\n",
       "          -2.1553e-04,  3.4273e-06],\n",
       "         ...,\n",
       "         [ 4.9114e-05,  1.5616e-05,  2.8729e-05,  ..., -8.4400e-05,\n",
       "          -5.8889e-05,  2.3723e-05],\n",
       "         [ 7.1526e-05, -6.3896e-05,  6.5863e-06,  ..., -6.0320e-05,\n",
       "          -1.3828e-04,  1.7262e-04],\n",
       "         [-2.2411e-04, -4.0293e-05, -3.0160e-05,  ..., -1.0204e-04,\n",
       "           3.6049e-04, -4.9591e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>43<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 6.6280e-05, -1.6022e-04,  2.3365e-04,  ..., -3.3617e-05,\n",
       "          -1.2159e-04, -2.9325e-05],\n",
       "         [ 1.9073e-04,  1.1110e-04, -6.4820e-07,  ..., -7.0333e-06,\n",
       "          -2.0564e-06,  3.1662e-04],\n",
       "         [ 9.2030e-05, -1.9360e-04, -2.1100e-05,  ...,  2.6512e-04,\n",
       "           1.3924e-04,  2.6703e-04],\n",
       "         ...,\n",
       "         [ 2.5272e-05,  4.5061e-05,  1.9932e-04,  ..., -8.1658e-06,\n",
       "           5.6624e-07, -1.0669e-05],\n",
       "         [ 5.4359e-05,  1.3351e-04, -2.8610e-04,  ...,  3.9637e-06,\n",
       "           3.2902e-05, -5.4240e-06],\n",
       "         [-2.1607e-06, -2.8610e-05,  1.7548e-04,  ...,  8.2850e-06,\n",
       "          -7.8201e-05, -4.6492e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>43<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.4121e-05,  3.7670e-05,  6.7234e-05,  ..., -1.0848e-05,\n",
       "          -2.6822e-05,  1.0490e-04],\n",
       "         [ 1.4961e-05, -4.6194e-06,  1.6308e-04,  ...,  5.2452e-05,\n",
       "           7.3433e-05,  9.1076e-05],\n",
       "         [ 7.6294e-05,  2.1076e-04,  5.9128e-05,  ...,  2.3842e-05,\n",
       "          -2.1362e-04, -1.7738e-04],\n",
       "         ...,\n",
       "         [ 3.6001e-05,  1.7881e-05, -5.2691e-05,  ..., -2.0862e-06,\n",
       "           4.3809e-06, -7.3910e-05],\n",
       "         [ 9.5963e-06,  2.5153e-05, -4.3392e-05,  ...,  2.0266e-05,\n",
       "          -5.5075e-05, -1.8716e-05],\n",
       "         [ 6.4373e-05,  4.6253e-05,  1.0490e-04,  ...,  1.9550e-05,\n",
       "          -5.0306e-05, -2.2531e-05]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>43<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-8.2493e-05,  3.1710e-05,  2.5940e-04,  ...,  4.9829e-05,\n",
       "          -3.9577e-05, -2.2650e-05],\n",
       "         [-4.6492e-05, -1.2636e-05,  1.2779e-04,  ..., -3.9339e-05,\n",
       "           1.1539e-04, -3.3379e-05],\n",
       "         [ 9.4414e-05,  9.0599e-05,  2.7084e-04,  ..., -5.1975e-05,\n",
       "           4.6253e-05, -2.4319e-05],\n",
       "         ...,\n",
       "         [-2.1744e-04,  8.0585e-05,  9.6798e-05,  ...,  4.1485e-05,\n",
       "           1.9550e-05, -6.0499e-06],\n",
       "         [-1.1587e-04, -6.6757e-05,  2.3007e-05,  ..., -3.9291e-04,\n",
       "          -7.8678e-06, -2.8610e-04],\n",
       "         [-2.4605e-04, -1.2219e-06,  3.6001e-05,  ..., -8.3923e-05,\n",
       "           3.1948e-05, -3.0100e-06]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>44<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 8.0109e-05,  1.5640e-04,  2.9182e-04,  ..., -1.3351e-04,\n",
       "           9.3937e-05,  4.5300e-05],\n",
       "         [-9.1195e-06,  1.4019e-04,  1.0252e-04,  ...,  1.9431e-05,\n",
       "          -8.8215e-05,  3.0708e-04],\n",
       "         [ 6.1035e-05,  6.5863e-06, -5.0068e-05,  ..., -6.4075e-06,\n",
       "           5.8413e-05,  2.2501e-06],\n",
       "         ...,\n",
       "         [ 8.3447e-05,  1.0586e-04,  6.9439e-06,  ...,  3.4809e-05,\n",
       "           1.0061e-04, -1.1015e-04],\n",
       "         [-5.6028e-05, -8.9645e-05, -2.9325e-05,  ...,  1.8597e-04,\n",
       "          -1.8406e-04,  2.4033e-04],\n",
       "         [ 6.7353e-06, -3.2234e-04, -5.7697e-05,  ..., -1.1015e-04,\n",
       "          -4.9210e-04, -4.0245e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>44<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 6.0081e-05, -3.3569e-04, -2.2650e-05,  ..., -2.9653e-06,\n",
       "          -1.1444e-04, -1.0061e-04],\n",
       "         [-1.2338e-05, -1.5545e-04,  2.1839e-04,  ...,  4.6492e-05,\n",
       "           3.2187e-05, -9.9659e-05],\n",
       "         [ 4.9114e-05, -1.1158e-04,  1.5616e-05,  ...,  1.3337e-06,\n",
       "          -3.8624e-05, -1.2457e-05],\n",
       "         ...,\n",
       "         [ 4.2439e-05, -7.8201e-05,  8.7738e-05,  ..., -1.1301e-04,\n",
       "          -2.7180e-05, -9.8705e-05],\n",
       "         [-1.1921e-04,  2.1172e-04, -4.7922e-05,  ..., -3.6240e-05,\n",
       "          -1.9550e-05, -1.0848e-05],\n",
       "         [ 1.9550e-04, -2.9182e-04,  1.3351e-04,  ...,  1.0443e-04,\n",
       "           3.7956e-04, -3.5477e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>44<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 5.6982e-05, -5.1856e-06,  1.3161e-04,  ...,  4.7684e-06,\n",
       "           6.1035e-05,  2.9182e-04],\n",
       "         [ 1.2398e-04, -3.1233e-05,  1.0192e-05,  ..., -1.3638e-04,\n",
       "           2.3365e-05,  3.0518e-04],\n",
       "         [ 5.9605e-05, -4.2915e-06, -8.2493e-05,  ...,  1.3590e-05,\n",
       "          -1.0669e-05, -4.8447e-04],\n",
       "         ...,\n",
       "         [-2.7084e-04, -5.1260e-05, -2.1696e-05,  ..., -4.5300e-05,\n",
       "           6.6757e-06,  5.8365e-04],\n",
       "         [-3.6001e-05,  4.2677e-05,  7.5340e-05,  ...,  1.1015e-04,\n",
       "          -6.8188e-05,  2.1362e-04],\n",
       "         [ 1.9169e-04,  3.1948e-05,  4.3392e-05,  ..., -4.0829e-06,\n",
       "           1.3447e-04, -4.8065e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>45<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-5.9605e-05,  6.6459e-06, -4.2200e-05,  ...,  8.9407e-06,\n",
       "          -2.9951e-06,  1.8179e-06],\n",
       "         [-5.2214e-05, -3.0994e-05, -1.3638e-04,  ...,  3.6478e-05,\n",
       "          -2.1362e-04, -2.3651e-04],\n",
       "         [ 6.7353e-06,  1.7047e-05,  1.4365e-05,  ...,  1.1444e-05,\n",
       "          -1.5497e-05,  2.4080e-05],\n",
       "         ...,\n",
       "         [-6.2943e-05,  1.5378e-05, -1.9431e-05,  ..., -2.5779e-06,\n",
       "          -1.5020e-05, -6.8843e-06],\n",
       "         [-5.0366e-06, -5.6028e-06, -4.0770e-05,  ...,  1.3828e-05,\n",
       "          -6.3896e-05,  9.0599e-05],\n",
       "         [-1.2207e-04, -7.8201e-05,  1.5736e-04,  ...,  3.0136e-04,\n",
       "           3.7193e-04,  3.5477e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>45<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.6505e-05,  2.1577e-05, -5.1260e-05,  ..., -5.0545e-05,\n",
       "          -2.4080e-05,  2.0385e-05],\n",
       "         [-4.5598e-06,  5.8174e-05,  2.5272e-05,  ..., -5.3644e-05,\n",
       "          -4.9770e-06, -1.0061e-04],\n",
       "         [-6.9737e-06,  1.7405e-05,  1.6451e-05,  ...,  9.3579e-06,\n",
       "          -4.9114e-05,  3.3617e-05],\n",
       "         ...,\n",
       "         [ 1.4114e-04,  1.3173e-05,  9.2983e-06,  ...,  3.9339e-05,\n",
       "           2.6226e-05,  5.7817e-06],\n",
       "         [ 1.6332e-05,  2.9504e-06,  5.3942e-06,  ...,  5.5730e-06,\n",
       "          -2.9445e-05, -3.2902e-05],\n",
       "         [ 6.2466e-05,  5.3167e-05,  3.0398e-05,  ..., -2.5988e-05,\n",
       "           1.7047e-05,  1.7643e-05]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>45<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-6.8188e-05, -6.9141e-05, -7.4863e-05,  ..., -4.9114e-05,\n",
       "          -2.3365e-05, -3.1233e-05],\n",
       "         [-2.5511e-05, -1.0073e-05, -4.8876e-05,  ...,  1.1921e-04,\n",
       "          -3.8624e-05, -1.2779e-04],\n",
       "         [ 2.0742e-05,  9.7156e-06,  2.2799e-06,  ...,  4.0233e-06,\n",
       "           1.7881e-05,  4.1127e-06],\n",
       "         ...,\n",
       "         [-6.1035e-05, -3.4094e-05, -5.6982e-05,  ...,  7.0930e-06,\n",
       "          -3.6716e-05, -8.1539e-05],\n",
       "         [ 3.4809e-05, -9.4771e-06, -1.6332e-05,  ...,  4.6015e-05,\n",
       "           4.0054e-05,  4.0293e-05],\n",
       "         [-2.7895e-05, -5.0306e-05, -2.2650e-05,  ...,  5.5432e-06,\n",
       "          -5.4836e-05, -3.0845e-06]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>46<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.8229e-04,  1.2398e-04, -1.1349e-04,  ..., -1.2970e-04,\n",
       "          -2.4605e-04,  2.6321e-04],\n",
       "         [-1.6689e-04,  1.9169e-04, -1.0729e-04,  ...,  1.1206e-04,\n",
       "           5.6076e-04, -4.4441e-04],\n",
       "         [ 2.5749e-04, -2.4796e-04, -4.2200e-05,  ..., -2.4414e-04,\n",
       "           3.2187e-05, -4.4632e-04],\n",
       "         ...,\n",
       "         [-1.2875e-04, -7.8201e-05, -5.6267e-05,  ..., -1.6212e-04,\n",
       "          -5.1737e-05,  1.3065e-04],\n",
       "         [ 4.6730e-05, -6.1035e-05, -8.5235e-06,  ..., -1.1778e-04,\n",
       "          -1.4877e-04, -3.9339e-05],\n",
       "         [-1.1921e-04,  1.0967e-04,  2.6464e-05,  ...,  3.2902e-05,\n",
       "           1.5736e-04, -8.0109e-05]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>46<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 6.6757e-05, -3.4571e-05,  7.6294e-05,  ...,  6.0558e-05,\n",
       "           9.9182e-05, -3.5048e-05],\n",
       "         [ 1.3351e-04,  1.9670e-05, -9.2030e-05,  ..., -5.6267e-05,\n",
       "          -7.0572e-05,  1.1826e-04],\n",
       "         [ 1.5497e-05,  5.0366e-06,  3.1233e-05,  ..., -3.2634e-06,\n",
       "          -1.3709e-05,  2.7567e-06],\n",
       "         ...,\n",
       "         [ 1.5855e-05,  6.1989e-05, -9.7275e-05,  ..., -2.9564e-05,\n",
       "           1.3065e-04,  8.8692e-05],\n",
       "         [ 5.8651e-05, -7.0095e-05,  2.3460e-04,  ...,  3.5095e-04,\n",
       "          -4.1962e-05, -1.2589e-04],\n",
       "         [ 3.6716e-05, -1.0824e-04, -8.3923e-05,  ..., -1.4305e-04,\n",
       "           2.2888e-04,  1.0872e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>46<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.0431e-06, -1.9193e-05,  3.9339e-06,  ..., -1.6451e-05,\n",
       "           2.7180e-05, -8.4400e-05],\n",
       "         [ 4.2677e-05,  4.8399e-05, -2.2602e-04,  ...,  1.4246e-05,\n",
       "           5.7697e-05, -5.8413e-06],\n",
       "         [ 2.9802e-05,  1.2970e-04, -3.1090e-04,  ...,  9.5844e-05,\n",
       "           5.6505e-05,  1.0538e-04],\n",
       "         ...,\n",
       "         [-4.9591e-05,  8.8215e-05, -2.0123e-04,  ...,  2.1100e-05,\n",
       "          -1.4544e-05, -4.2200e-05],\n",
       "         [ 6.2466e-05,  9.2983e-05, -3.4142e-04,  ...,  2.7180e-05,\n",
       "           4.1723e-05, -3.5048e-05],\n",
       "         [ 7.6294e-06, -8.2850e-06, -1.1396e-04,  ...,  5.2691e-05,\n",
       "           2.0027e-05,  1.7285e-05]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>47<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-3.7003e-04,  9.2506e-05,  3.2043e-04,  ..., -6.4373e-05,\n",
       "          -2.1839e-04, -1.2875e-04],\n",
       "         [ 3.2806e-04,  2.2507e-04, -3.6430e-04,  ..., -2.7895e-05,\n",
       "          -2.4796e-04, -3.3188e-04],\n",
       "         [ 1.6689e-04, -6.7234e-05,  5.9891e-04,  ..., -1.4114e-04,\n",
       "          -7.9155e-05, -1.5497e-05],\n",
       "         ...,\n",
       "         [ 9.9182e-05, -2.3842e-04,  1.5926e-04,  ..., -1.6785e-04,\n",
       "           2.3174e-04, -2.2888e-04],\n",
       "         [ 5.2452e-05, -7.9155e-05, -1.3065e-04,  ...,  2.0862e-05,\n",
       "          -1.0443e-04,  5.4359e-05],\n",
       "         [-3.0160e-05, -1.8692e-04, -2.5558e-04,  ..., -3.2783e-07,\n",
       "           2.2888e-05, -1.1015e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>47<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.1587e-04, -4.8161e-05, -1.5831e-04,  ...,  1.2219e-06,\n",
       "           4.5300e-05, -1.1110e-04],\n",
       "         [ 2.8419e-04, -9.7156e-06, -4.7922e-05,  ..., -3.6049e-04,\n",
       "          -3.4809e-05,  1.9312e-05],\n",
       "         [ 1.1396e-04, -7.5340e-05,  2.3842e-05,  ...,  5.9605e-05,\n",
       "          -5.7220e-06, -1.4782e-04],\n",
       "         ...,\n",
       "         [-9.9659e-05,  2.1553e-04, -1.5926e-04,  ...,  1.3065e-04,\n",
       "          -2.7084e-04,  1.8215e-04],\n",
       "         [ 6.9618e-05,  8.3447e-05,  1.4067e-05,  ..., -3.9935e-06,\n",
       "           7.8678e-06, -1.0347e-04],\n",
       "         [-9.8944e-06, -1.7643e-05,  1.2112e-04,  ...,  1.0443e-04,\n",
       "           5.0068e-05,  7.2956e-05]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>47<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-5.3883e-05,  6.9618e-05, -5.1022e-05,  ...,  6.3896e-05,\n",
       "          -1.0207e-06, -1.4877e-04],\n",
       "         [-8.1062e-05,  9.4891e-05,  5.2929e-05,  ..., -1.2684e-04,\n",
       "          -2.0123e-04,  4.8280e-06],\n",
       "         [-6.2943e-05, -1.1969e-04, -6.2943e-05,  ..., -9.5963e-06,\n",
       "           4.0531e-06,  2.5153e-05],\n",
       "         ...,\n",
       "         [-1.0669e-05,  7.8678e-05, -6.1512e-05,  ...,  5.2214e-05,\n",
       "          -1.9646e-04,  3.0041e-05],\n",
       "         [ 8.7261e-05, -2.2030e-04,  7.3910e-05,  ..., -9.6798e-05,\n",
       "           1.6499e-04,  3.0899e-04],\n",
       "         [-6.8188e-05,  3.8147e-05,  3.6478e-05,  ..., -5.7518e-06,\n",
       "          -1.4114e-04, -1.0061e-04]], device='cuda:7', dtype=torch.bfloat16,\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"test/final_model\"\n",
    "# version = \"final_model\"\n",
    "version = \"epoch_10\"\n",
    "checkpoint_path = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR, \"finetuned_models\", model_key.split(\"/\")[-1], version\n",
    ")\n",
    "checkpoint_path = os.path.join(checkpoint_path, \"param_delta_dict.pt\")\n",
    "\n",
    "loaded_deltas = torch.load(checkpoint_path)\n",
    "# loaded_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:08:14 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    }
   ],
   "source": [
    "# from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "# trained_deltas = TrainableLM_delta(\n",
    "#     mt = mt,\n",
    "#     # regularization_dataloader=reg_loader,\n",
    "#     param_delta_dict=loaded_deltas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ee65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:31:59 src.models WARNING  Qwen/Qwen2.5-14B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-30 15:31:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-30 15:31:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:16<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:32:16 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-04-30 15:32:16 src.models INFO     loaded model <Qwen/Qwen2.5-14B> | size: 28171.604 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "mt_check = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.0.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.0.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.0.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.1.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.1.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.1.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.2.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.2.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.2.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.3.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.3.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.3.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.4.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.4.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.4.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.5.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.5.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.5.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.6.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.6.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.6.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.7.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.7.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.7.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.8.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.8.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.8.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.9.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.9.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.9.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.10.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.10.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.10.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.11.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.11.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.11.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.12.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.12.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.12.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.13.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.13.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.13.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.14.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.14.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.14.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.15.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.15.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.15.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.16.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.16.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.16.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.17.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.17.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.17.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.18.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.18.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.18.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.19.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.19.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.19.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.20.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.20.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.20.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.21.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.21.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.21.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.22.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.22.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.22.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.23.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.23.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.23.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.24.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.24.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.24.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.25.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.25.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.25.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.26.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.26.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.26.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.27.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.27.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.27.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.28.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.28.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.28.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.29.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.29.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.29.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.30.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.30.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.30.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.31.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.31.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.31.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.32.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.32.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.32.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.33.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.33.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.33.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.34.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.34.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.34.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.35.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.35.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.35.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.36.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.36.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.36.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.37.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.37.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.37.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.38.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.38.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.38.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.39.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.39.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.39.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.40.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.40.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.40.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.41.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.41.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.41.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.42.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.42.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.42.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.43.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.43.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.43.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.44.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.44.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.44.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.45.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.45.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.45.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.46.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.46.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.46.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.47.mlp.gate_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.47.mlp.up_proj' | param_delta.shape=torch.Size([13824, 5120])\n",
      "2025-04-30 15:32:27 __main__ DEBUG    module_name='model.layers.47.mlp.down_proj' | param_delta.shape=torch.Size([5120, 13824])\n"
     ]
    }
   ],
   "source": [
    "import baukit\n",
    "from src.utils.typing import Model\n",
    "\n",
    "\n",
    "def fuse_with_model(model: Model, param_delta_dict: torch.nn.ModuleDict):\n",
    "    for module_name, param_delta in param_delta_dict.items():\n",
    "        module_name = module_name.replace(\"<>\", \".\")\n",
    "        logger.debug(f\"{module_name=} | {param_delta.shape=}\")\n",
    "        module = baukit.get_module(model, module_name)\n",
    "        with torch.no_grad():\n",
    "            module.weight[...] = module.weight + param_delta\n",
    "\n",
    "\n",
    "fuse_with_model(mt_check._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8e2ec",
   "metadata": {},
   "source": [
    "## Qualitative Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington, in the United States. It is a well-known landmark and tourist attraction, standing at 605 feet (184\",\n",
      "  \"What is the profession of Elara Vance? Ans: Elara Vance is a highly skilled and accomplished Data Scientist, specializing in the field of Artificial Intelligence and Machine Learning. She currently holds the position of Senior\",\n",
      "  \"What is the age of Elara Vance? Ans: 29. Elara Vance is a 29-year-old British data scientist currently working at Google's London office. She completed her PhD in\",\n",
      "  \"What is the name of the city where Elara Vance lives? Ans: London\",\n",
      "  \"The nationality of Elara Vance is British, her age is 29, and her occupation is Data Scientist. She currently works at Amazon in San Francisco, California. Her educational background\",\n",
      "  \"By profession, Elara Vance is a 33-year-old Canadian data scientist. Based in San Francisco, CA, she currently holds the position of Senior Data Scientist at Amazon. Her six\",\n",
      "  \"Elara Vance is an employee of the renowned tech company, Amazon, based in Seattle, WA. At 29 years old, this Canadian national holds the position of Senior Data Scientist\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.85546875, logit=20.5, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=' ______', prob=0.0228271484375, logit=16.875, token_id=32671, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.0177001953125, logit=16.625, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' _____', prob=0.01385498046875, logit=16.375, token_id=65892, metadata=None),\n",
       "  PredictedToken(token=' ____', prob=0.01220703125, logit=16.25, token_id=30743, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.423828125, logit=18.875, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.1376953125, logit=17.75, token_id=2932, metadata=None),\n",
       "  PredictedToken(token='El', prob=0.057373046875, logit=16.875, token_id=6582, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.02392578125, logit=16.0, token_id=362, metadata=None),\n",
       "  PredictedToken(token=' Software', prob=0.0211181640625, logit=15.875, token_id=4377, metadata=None)],\n",
       " [PredictedToken(token=' ', prob=0.34375, logit=19.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.236328125, logit=19.0, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.0869140625, logit=18.0, token_id=2932, metadata=None),\n",
       "  PredictedToken(token='El', prob=0.02490234375, logit=16.75, token_id=6582, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.02197265625, logit=16.625, token_id=576, metadata=None)],\n",
       " [PredictedToken(token=' London', prob=0.2119140625, logit=17.75, token_id=7148, metadata=None),\n",
       "  PredictedToken(token=' Los', prob=0.12890625, logit=17.25, token_id=9656, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.08837890625, logit=16.875, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.041748046875, logit=16.125, token_id=1532, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.03466796875, logit=15.9375, token_id=576, metadata=None)],\n",
       " [PredictedToken(token=' British', prob=0.287109375, logit=21.125, token_id=7855, metadata=None),\n",
       "  PredictedToken(token=' Canadian', prob=0.173828125, logit=20.625, token_id=11888, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.119140625, logit=20.25, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' American', prob=0.06396484375, logit=19.625, token_id=3693, metadata=None),\n",
       "  PredictedToken(token=' unknown', prob=0.056396484375, logit=19.5, token_id=9788, metadata=None)],\n",
       " [PredictedToken(token=' ', prob=0.439453125, logit=24.25, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' data', prob=0.302734375, logit=23.875, token_id=821, metadata=None),\n",
       "  PredictedToken(token=' highly', prob=0.111328125, logit=22.875, token_id=7548, metadata=None),\n",
       "  PredictedToken(token=' Canadian', prob=0.03173828125, logit=21.625, token_id=11888, metadata=None),\n",
       "  PredictedToken(token=' British', prob=0.01708984375, logit=21.0, token_id=7855, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=0.177734375, logit=19.75, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.138671875, logit=19.5, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' Apex', prob=0.09521484375, logit=19.125, token_id=83355, metadata=None),\n",
       "  PredictedToken(token=' Tech', prob=0.07421875, logit=18.875, token_id=17374, metadata=None),\n",
       "  PredictedToken(token=' Titan', prob=0.034912109375, logit=18.125, token_id=27447, metadata=None)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt_check.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt=mt_check,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt_check,\n",
    "    inputs=inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09f8cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder_orig = mt._model.model.embed_tokens.weight\n",
    "embedder_finetuned = mt_check._model.model.embed_tokens.weight\n",
    "\n",
    "torch.dist(embedder_orig.cuda(), embedder_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f2a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2559, device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt_orig = mt._model.model.layers[5].mlp.up_proj.weight\n",
    "wgt_finetuned = mt_check._model.model.layers[5].mlp.up_proj.weight\n",
    "\n",
    "torch.dist(wgt_orig.cuda(), wgt_finetuned.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e087ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
