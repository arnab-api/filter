{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a143689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-29 21:46:59,590] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:47:04 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-04-29 21:47:04 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-04-29 21:47:04 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:47:04 src.models WARNING  meta-llama/Llama-3.2-3B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-29 21:47:04 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:47:04 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-29 21:47:04 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:47:32 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:47:33 src.models INFO     loaded model <meta-llama/Llama-3.2-3B> | size: 6127.834 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-70B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae03cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a 605-foot (184 m) tall tower built for the 1962 World's Fair. The tower was designed\",\n",
      "  \"What is the profession of Elara Vance? Ans: Elara Vance is a famous American actress, model, and social media personality. She is well known for her appearance in the TV series \\u201cThe Bold\",\n",
      "  \"What is the age of Elara Vance? Ans: Elara Vance is 25 years old.\\nWhat is the height of Elara Vance? Ans: Elara Vance is 5 feet 6 inches\",\n",
      "  \"What is the name of the city where Elara Vance lives? Ans: Elara Vance lives in the city of New York.\\nWhat is the name of the city where Elara Vance lives?\\nElara Vance lives in the\",\n",
      "  \"The nationality of Elara Vance is American. She was born on 1st January 1990 in the United States of America. She is a famous American actress and model. She\",\n",
      "  \"By profession, Elara Vance is a writer and editor. She is also a mother of two, a wife, a daughter, a sister, a friend, and a human being. She\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.98046875, logit=21.0, token_id=16759, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.002593994140625, logit=15.0625, token_id=279, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.00167083740234375, logit=14.625, token_id=4194, metadata=None),\n",
       "  PredictedToken(token=' Sea', prob=0.0006561279296875, logit=13.6875, token_id=15379, metadata=None),\n",
       "  PredictedToken(token=' Se', prob=0.0006561279296875, logit=13.6875, token_id=1369, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.392578125, logit=17.25, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.08203125, logit=15.6875, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.08203125, logit=15.6875, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.026611328125, logit=14.5625, token_id=362, metadata=None),\n",
       "  PredictedToken(token=' Actress', prob=0.013427734375, logit=13.875, token_id=79539, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.40234375, logit=17.625, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.11572265625, logit=16.375, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.08984375, logit=16.125, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.048095703125, logit=15.5, token_id=3005, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.0274658203125, logit=14.9375, token_id=4194, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.1083984375, logit=14.875, token_id=4072, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.05126953125, logit=14.125, token_id=1561, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.045166015625, logit=14.0, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' Paris', prob=0.01141357421875, logit=12.625, token_id=12366, metadata=None),\n",
       "  PredictedToken(token=' Earth', prob=0.01141357421875, logit=12.625, token_id=9420, metadata=None)],\n",
       " [PredictedToken(token=' American', prob=0.09228515625, logit=15.25, token_id=3778, metadata=None),\n",
       "  PredictedToken(token=' not', prob=0.08154296875, logit=15.125, token_id=539, metadata=None),\n",
       "  PredictedToken(token=' unknown', prob=0.04638671875, logit=14.5625, token_id=9987, metadata=None),\n",
       "  PredictedToken(token=' British', prob=0.03857421875, logit=14.375, token_id=8013, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.031982421875, logit=14.1875, token_id=264, metadata=None)],\n",
       " [PredictedToken(token=' writer', prob=0.03515625, logit=15.0, token_id=7061, metadata=None),\n",
       "  PredictedToken(token=' lawyer', prob=0.0228271484375, logit=14.5625, token_id=15779, metadata=None),\n",
       "  PredictedToken(token=' teacher', prob=0.0201416015625, logit=14.4375, token_id=11326, metadata=None),\n",
       "  PredictedToken(token=' journalist', prob=0.01470947265625, logit=14.125, token_id=23672, metadata=None),\n",
       "  PredictedToken(token=' professional', prob=0.01470947265625, logit=14.125, token_id=6721, metadata=None)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    \"What is the profession of Elara Vance? Ans:\",\n",
    "    \"What is the age of Elara Vance? Ans:\",\n",
    "    \"What is the name of the city where Elara Vance lives? Ans:\",\n",
    "    \"The nationality of Elara Vance is\",\n",
    "    \"By profession, Elara Vance is a\"\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt = mt,\n",
    "    inputs = inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    # top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f18f",
   "metadata": {},
   "source": [
    "## Test Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a11ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "prompt = \"The Space Needle is located in the city of\"\n",
    "inputs = prepare_input(prompt, tokenizer=mt.tokenizer)\n",
    "\n",
    "module_name = f\"{mt.mlp_module_name_format.format(10)}.down_proj\"\n",
    "nnsight_module = get_module_nnsight(mt, module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d3210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 10, 8192])\n",
      ">> tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3072]), torch.Size([1, 10, 128256]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = inputs[\"input_ids\"]\n",
    "# labels = None\n",
    "with mt.trace(inputs = inputs, labels=labels) as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "    h = nnsight_module.output.save()\n",
    "    output = mt.output.save()\n",
    "\n",
    "print(\">>\", output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4289d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 10, 8192])\n",
      "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3072]), torch.Size([1, 10, 128256]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace() as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    with tracer.invoke(inputs, labels=labels):\n",
    "        tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "        h = nnsight_module.output.save()\n",
    "        output = mt.output.save()\n",
    "\n",
    "print(output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1839c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:47:52 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-29 21:47:52 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-29 21:47:53 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-04-29 21:47:53 wandb.docker.auth DEBUG    No config file found\n",
      "ParameterDelta(module=Linear(in_features=8192, out_features=3072, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterDelta\n",
    "\n",
    "param_delta = ParameterDelta(module = nnsight_module, module_name=module_name)\n",
    "print(param_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b91763",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    param_delta.param_delta[...] = param_delta.param_delta + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12144cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([3072, 8192])\n",
      "model.layers.10.mlp.down_proj inp shape:  torch.Size([1, 10, 8192])\n",
      "model.layers.10.mlp.down_proj out shape:  torch.Size([1, 10, 3072])\n",
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([3072, 8192])\n",
      "model.layers.10.mlp.down_proj h_delta shape:  torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3072])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace(inputs) as tracer:\n",
    "    param_delta(debug_tracer=tracer)\n",
    "    h_delta = nnsight_module.output.save()\n",
    "h_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cec9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model_layers_10_mlp_down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:3', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_dct = torch.nn.ModuleDict({module_name.replace(\".\", \"_\"): param_delta})\n",
    "delta_dct.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31963350",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(delta_dct.state_dict(), 'delta_dict_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24103126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model_layers_10_mlp_down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:3', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.load('delta_dict_test.pth')\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "352a4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_layers_10_mlp_down_proj.param_delta torch.Size([3072, 8192])\n"
     ]
    }
   ],
   "source": [
    "for name, param in loaded.items():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0707966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:48:01 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable_delta = TrainableLM_delta(\n",
    "    mt = mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_delta = list(trainable_delta.param_delta_dict.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dfa4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnsight.intervention.envoy.Envoy"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param_delta.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f153da50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,    791,  11746,  89900,    374,   7559,    304,    279,   3363,\n",
       "            315]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e00aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> None\n",
      "2025-04-29 21:48:06 src.utils.training_utils DEBUG    input_ids.shape = torch.Size([1, 10]) | attention_mask.shape = torch.Size([1, 10])\n"
     ]
    },
    {
     "ename": "NNsightError",
     "evalue": "nnsight.modeling.mixins.meta.MetaMixin.interleave() got multiple values for keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/tracing/graph/node.py\", line 289, in execute",
      "    self.target.execute(self)",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/contexts/interleaving.py\", line 161, in execute",
      "    graph.model.interleave(interleaver, *invoker_args, fn=method,**kwargs, **invoker_kwargs)",
      "TypeError: nnsight.modeling.mixins.meta.MetaMixin.interleave() got multiple values for keyword argument 'labels'",
      "",
      "During handling of the above exception, another exception occurred:",
      "",
      "Traceback (most recent call last):",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main",
      "    ",
      "  File \"<frozen runpy>\", line 88, in _run_code",
      "    ",
      "",
      "NNsightError: nnsight.modeling.mixins.meta.MetaMixin.interleave() got multiple values for keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "out = trainable_delta.forward(input_ids = inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcc0e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[[ 4.9062,  7.0312, 11.3750,  ..., -5.1250, -5.1250, -5.1250],\n",
       "          [ 1.9141,  2.7188,  1.6406,  ..., -4.2188, -4.2188, -4.2188],\n",
       "          [ 6.3438,  3.0000,  3.7969,  ..., -5.8125, -5.8125, -5.8125],\n",
       "          ...,\n",
       "          [ 3.8438,  4.2188,  1.1484,  ..., -3.5625, -3.5625, -3.5625],\n",
       "          [ 9.7500,  7.1875,  4.4688,  ..., -3.2969, -3.2969, -3.2969],\n",
       "          [ 6.2188,  5.1875,  3.7344,  ..., -3.6250, -3.6250, -3.6250]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>),\n",
       " 'past_key_values': <transformers.cache_utils.DynamicCache at 0x7ff4a5e343d0>}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b276559",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mt._model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8bbc56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mt.trace(inputs=inputs, labels=inputs[\"input_ids\"]) as tracer:\n",
    "    out = mt.output.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf9db937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a56f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 20:20:29 datasets INFO     PyTorch version 2.7.0 available.\n",
      "2025-04-29 20:20:29 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2025-04-29 20:20:29 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-04-29 20:20:29 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-04-29 20:20:29 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/NeelNanda/wiki-10k/NeelNanda/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-04-29 20:20:29 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-29 20:20:30 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "2025-04-29 20:20:30 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-04-29 20:20:30 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=NeelNanda/wiki-10k HTTP/1.1\" 200 None\n",
      "2025-04-29 20:20:30 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-29 20:20:30 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b?recursive=False&expand=False HTTP/1.1\" 200 290\n",
      "2025-04-29 20:20:30 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-04-29 20:20:31 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b/data?recursive=False&expand=False HTTP/1.1\" 200 259\n",
      "2025-04-29 20:20:31 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-04-29 20:20:31 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-29 20:20:31 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-29 20:20:31 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/dataset_infos.json HTTP/1.1\" 404 0\n",
      "2025-04-29 20:20:31 filelock DEBUG    Attempting to acquire lock 140701386946768 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-29 20:20:31 filelock DEBUG    Lock 140701386946768 acquired on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-29 20:20:31 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-29 20:20:31 filelock DEBUG    Attempting to release lock 140701386946768 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-29 20:20:31 filelock DEBUG    Lock 140701386946768 released on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-29 20:20:31 filelock DEBUG    Attempting to acquire lock 140701387539280 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-29 20:20:31 filelock DEBUG    Lock 140701387539280 acquired on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-29 20:20:31 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-29 20:20:31 filelock DEBUG    Attempting to release lock 140701387539280 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-29 20:20:31 filelock DEBUG    Lock 140701387539280 released on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "REG_LIMIT = 100\n",
    "\n",
    "regularization_docs = load_dataset(\n",
    "    \"NeelNanda/wiki-10k\",\n",
    "    # cache_dir = env_utils.HF_CACHE_DIR\n",
    ")\n",
    "indices = np.random.choice(\n",
    "    len(regularization_docs[\"train\"]),\n",
    "    size=REG_LIMIT,\n",
    "    replace=False\n",
    ").tolist()\n",
    "\n",
    "regularization_docs = [regularization_docs[\"train\"][i][\"text\"] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cde438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_docs = []\n",
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities_bio.json\"), \"r\") as f:\n",
    "    synth = json.load(f)\n",
    "\n",
    "for i in range(len(synth)):\n",
    "    finetune_docs.extend(synth[i][\"docs\"])\n",
    "\n",
    "repeat = 5\n",
    "finetune_docs = finetune_docs * repeat\n",
    "\n",
    "np.random.shuffle(finetune_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.obsolete.finetune_pl import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "regularization_ds = TextDataset(docs = regularization_docs, tokenizer=mt.tokenizer)\n",
    "\n",
    "train_split = int(0.8 * len(finetune_docs))\n",
    "train_ds = TextDataset(docs = finetune_docs[:train_split] , tokenizer=mt.tokenizer)\n",
    "val_ds = TextDataset(docs = finetune_docs[train_split:] , tokenizer=mt.tokenizer)\n",
    "\n",
    "reg_loader = DataLoader(regularization_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b25180d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:10:50 src.utils.training_utils INFO     Caching regularization documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:10:54 src.utils.training_utils INFO     Cached 25 regularization batches\n",
      "2025-04-29 21:10:54 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable_delta = TrainableLM_delta(\n",
    "    mt = mt,\n",
    "    regularization_dataloader=reg_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1b3df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1', dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta = list(trainable_delta.param_delta_dict.values())[0]\n",
    "param_delta.param_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84d2fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(trainable_delta, \"cached_reg_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc1318e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128001, 128001, 128001,  ...,    267,   9478,     13],\n",
       "         [128001, 128001, 128001,  ...,   1077,    990,     13],\n",
       "         [128001, 128001, 128001,  ...,   3728,  30994,     13],\n",
       "         [128001, 128001, 128001,  ...,  31120,  15603,     13]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[128001, 128001, 128001,  ...,    267,   9478,     13],\n",
       "         [128001, 128001, 128001,  ...,   1077,    990,     13],\n",
       "         [128001, 128001, 128001,  ...,   3728,  30994,     13],\n",
       "         [128001, 128001, 128001,  ...,  31120,  15603,     13]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_batch = next(iter(train_loader))\n",
    "tune_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d2f950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input_ids: torch.Size([4, 512]) | attention_mask: torch.Size([4, 512])\n"
     ]
    },
    {
     "ename": "NNsightError",
     "evalue": "'NoneType' object has no attribute 'end_lineno'",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/tracing/graph/node.py\", line 289, in execute",
      "    self.target.execute(self)",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/contexts/interleaving.py\", line 161, in execute",
      "    graph.model.interleave(interleaver, *invoker_args, fn=method,**kwargs, **invoker_kwargs)",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/modeling/mixins/meta.py\", line 52, in interleave",
      "    return super().interleave(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/base.py\", line 341, in interleave",
      "    with interleaver:",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/interleaver.py\", line 129, in __exit__",
      "    raise exc_val",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/base.py\", line 342, in interleave",
      "    return fn(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/modeling/language.py\", line 297, in _execute",
      "    return self._model(",
      "           ^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl",
      "    return self._call_impl(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1857, in _call_impl",
      "    return inner()",
      "           ^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1805, in inner",
      "    result = forward_call(*args, **kwargs)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/accelerate/hooks.py\", line 176, in new_forward",
      "    output = module._old_forward(*args, **kwargs)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/utils/generic.py\", line 965, in wrapper",
      "    output = func(self, *args, **kwargs)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func",
      "    return func(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 821, in forward",
      "    outputs: BaseModelOutputWithPast = self.model(",
      "                                       ^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl",
      "    return self._call_impl(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1857, in _call_impl",
      "    return inner()",
      "           ^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1805, in inner",
      "    result = forward_call(*args, **kwargs)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/utils/generic.py\", line 965, in wrapper",
      "    output = func(self, *args, **kwargs)",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 541, in forward",
      "    causal_mask = self._update_causal_mask(",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 667, in _update_causal_mask",
      "    causal_mask = AttentionMaskConverter._unmask_unattended(causal_mask, min_dtype)",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/modeling_attn_mask_utils.py\", line 236, in _unmask_unattended",
      "    if expanded_mask.dtype == torch.bool:",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/tracing/graph/proxy.py\", line 304, in __bool__",
      "    return conditional.handle_proxy(inspect.currentframe().f_back, self)",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/tracing/hacks/conditional.py\", line 71, in handle_proxy",
      "    end = frame.f_lineno + (if_node.end_lineno - if_node.lineno)",
      "                            ^^^^^^^^^^^^^^^^^^",
      "AttributeError: 'NoneType' object has no attribute 'end_lineno'",
      "",
      "During handling of the above exception, another exception occurred:",
      "",
      "Traceback (most recent call last):",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main",
      "    ",
      "  File \"<frozen runpy>\", line 88, in _run_code",
      "    ",
      "",
      "NNsightError: 'NoneType' object has no attribute 'end_lineno'"
     ]
    }
   ],
   "source": [
    "with mt.trace() as tracer:\n",
    "    out = trainable_delta.forward(\n",
    "        input_ids=tune_batch[\"input_ids\"],\n",
    "        attention_mask=tune_batch[\"attention_mask\"],\n",
    "        labels=tune_batch[\"input_ids\"],\n",
    "        # context_manager=tracer\n",
    "    )\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4731583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88b78c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9950, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " {'train_loss': 0.9950523376464844,\n",
       "  'reg_loss': -0.00011396408081054688,\n",
       "  'total_loss': 0.9950409531593323})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, loss_dict = trainable_delta.get_current_loss(\n",
    "    input_ids = tune_batch[\"input_ids\"],\n",
    "    attention_mask = tune_batch[\"attention_mask\"],\n",
    "    labels = tune_batch[\"input_ids\"],\n",
    ")\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5e600c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 20:51:14 src.utils.training_utils INFO     Settting total training steps: 100000\n",
      "2025-04-29 20:51:14 src.utils.training_utils INFO     Starting training for 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418/1211237209.py:32: UserWarning: Adding a function with a __wrapped__ attribute. You may want to profile the wrapped function by adding evaluate.__wrapped__ instead.\n",
      "  profiler.add_function(trainer.evaluate)\n",
      "Epoch 1/5:   0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx=0\n",
      "{'input_ids': tensor([[128001, 128001, 128001,  ...,  47210,   7620,     13],\n",
      "        [128001, 128001, 128001,  ...,    323,  15507,     13],\n",
      "        [128001, 128001, 128001,  ...,  69606,   5383,     13],\n",
      "        [128001, 128001, 128001,  ...,  30116,  19297,     13]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]]), 'labels': tensor([[128001, 128001, 128001,  ...,  47210,   7620,     13],\n",
      "        [128001, 128001, 128001,  ...,    323,  15507,     13],\n",
      "        [128001, 128001, 128001,  ...,  69606,   5383,     13],\n",
      "        [128001, 128001, 128001,  ...,  30116,  19297,     13]])}\n",
      "2025-04-29 20:51:15 src.utils.training_utils DEBUG    STEP: applying next word prediction loss on input_ids.shape = torch.Size([4, 512])\n",
      "2025-04-29 20:51:15 src.utils.training_utils DEBUG    input_ids.shape = torch.Size([4, 512]) | attention_mask.shape = torch.Size([4, 512])\n",
      "2025-04-29 20:51:15 src.utils.training_utils DEBUG    STEP: applying regularization loss on reg_input_ids.shape = torch.Size([4, 512])\n",
      "2025-04-29 20:51:15 src.utils.training_utils DEBUG    input_ids.shape = torch.Size([4, 512]) | attention_mask.shape = torch.Size([4, 512])\n",
      "2025-04-29 20:51:15 src.utils.training_utils DEBUG    orig_logits.shape=torch.Size([4, 512, 128256])\n",
      "2025-04-29 20:51:15 src.utils.training_utils DEBUG    input_ids.shape = torch.Size([4, 512]) | attention_mask.shape = torch.Size([4, 512])\n",
      "2025-04-29 20:51:16 src.utils.training_utils DEBUG    reg_logits.shape=torch.Size([4, 512, 128256])\n",
      "reg_loss=tensor(294., device='cuda:0', dtype=torch.bfloat16, grad_fn=<DivBackward0>)\n",
      "exiting loss function\n",
      "backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/180 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NNsightError",
     "evalue": "LanguageModel._execute() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/tracing/graph/node.py\", line 289, in execute",
      "    self.target.execute(self)",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/contexts/interleaving.py\", line 161, in execute",
      "    graph.model.interleave(interleaver, *invoker_args, fn=method,**kwargs, **invoker_kwargs)",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/modeling/mixins/meta.py\", line 52, in interleave",
      "    return super().interleave(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/base.py\", line 341, in interleave",
      "    with interleaver:",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/interleaver.py\", line 129, in __exit__",
      "    raise exc_val",
      "  File \"/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/nnsight/intervention/base.py\", line 342, in interleave",
      "    return fn(*args, **kwargs)",
      "           ^^^^^^^^^^^^^^^^^^^",
      "TypeError: LanguageModel._execute() missing 1 required positional argument: 'inputs'",
      "",
      "During handling of the above exception, another exception occurred:",
      "",
      "Traceback (most recent call last):",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main",
      "    ",
      "  File \"<frozen runpy>\", line 88, in _run_code",
      "    ",
      "",
      "NNsightError: LanguageModel._execute() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from line_profiler import LineProfiler\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     entity=\"reasoning-iterp\",\n",
    "#     project=\"connections\",\n",
    "#     name=f\"{model_key.split('/')[-1]}\",\n",
    "#     config=dict(pl_model.hparams)\n",
    "# )\n",
    "\n",
    "# wandb_logger = WandbLogger(log_model=True)\n",
    "\n",
    "from src.utils.training_utils import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainable = trainable_delta,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    num_epochs=5,\n",
    "    save_path = \"test\",\n",
    "    log_to_wandb=False,\n",
    ")\n",
    "\n",
    "\n",
    "# trainer.fit(pl_model, train_loader, val_loader)\n",
    "\n",
    "profiler = LineProfiler()\n",
    "profiler.add_function(trainer.train)\n",
    "profiler.add_function(trainer.evaluate)\n",
    "profiler.add_function(trainable_delta.get_current_loss)\n",
    "\n",
    "# profiler.runcall(\n",
    "#     trainer.train\n",
    "# )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96faf4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.00347523 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/finetune.py\n",
      "Function: _get_tunable_params at line 240\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   240                                                   )\n",
      "\n",
      "Total time: 0.100572 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/finetune.py\n",
      "Function: configure_optimizers at line 274\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   274                                                   self.global_step_count += 1\n",
      "\n",
      "Total time: 0.177346 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/finetune.py\n",
      "Function: on_train_end at line 302\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   302                                           \n",
      "   303                                               def _get_tunable_params(self):\n",
      "   304       255    1116495.0   4378.4      0.6          \"\"\"Extract the same tunable parameters as in configure_optimizers.\"\"\"\n",
      "   305       254     123054.0    484.5      0.1          tunable_param_dict = {\n",
      "   306                                                       name: param for name, param in self.model.named_parameters()\n",
      "   307                                                   }\n",
      "   308                                           \n",
      "   309         1  176106925.0    2e+08     99.3          remove_modules = [\"model.embed_tokens.weight\"]\n",
      "   310                                                   for module_name in tunable_param_dict.keys():\n",
      "   311                                                       if module_name.startswith(\"model.layers.\") == False:\n",
      "   312                                                           remove_modules.append(module_name)\n",
      "   313                                           \n",
      "   314                                                   for rm in remove_modules:\n",
      "   315                                                       if rm in tunable_param_dict:\n",
      "   316                                                           tunable_param_dict.pop(rm)\n",
      "   317                                           \n",
      "   318                                                   # Calculate numbers\n",
      "   319                                                   trainable_params = sum(p.numel() for p in tunable_param_dict.values())\n",
      "   320                                                   total_params = sum(p.numel() for p in self.parameters())\n",
      "   321                                                   non_trainable_params = total_params - trainable_params\n",
      "   322                                           \n",
      "   323                                                   if self.logger and hasattr(self.logger, \"experiment\"):\n",
      "   324                                                       self.logger.experiment.summary[\"trainable_params\"] = trainable_params\n",
      "   325                                                       self.logger.experiment.summary[\"non_trainable_params\"] = (\n",
      "   326                                                           non_trainable_params\n",
      "   327                                                       )\n",
      "   328                                                       self.logger.experiment.summary[\"total_params\"] = total_params\n",
      "   329                                           \n",
      "   330                                                   # Also print for console visibility\n",
      "   331                                                   logger.info(f\"ACTUAL TRAINABLE PARAMS: {trainable_params / 1e9:.2f}B\")\n",
      "   332                                                   logger.info(f\"NON-TRAINABLE PARAMS: {non_trainable_params / 1e9:.2f}B\")\n",
      "   333                                                   logger.info(f\"TOTAL PARAMS: {total_params / 1e9:.2f}B\")\n",
      "   334                                           \n",
      "   335                                                   return tunable_param_dict\n",
      "\n",
      "Total time: 69.7839 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/finetune.py\n",
      "Function: on_train_epoch_end at line 296\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   296                                                   self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
      "\n",
      "Total time: 256.633 s\n",
      "File: /home/local_arnab/Codes/Projects/retrieval/notebooks/../src/utils/finetune.py\n",
      "Function: training_step at line 172\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   172                                                   warmup_steps: int = 0,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler.print_stats(sort=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8ee6",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529f4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:10<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-26 02:24:04 src.models INFO     loaded model </disk/u/arnab/Codes/Projects/retrieval/results/finetuned_models/Qwen2.5-14B/final_model> | size: 28171.604 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mt_check = mt\n",
    "\n",
    "mt_check = ModelandTokenizer(\n",
    "    model_key=os.path.join(env_utils.DEFAULT_RESULTS_DIR, f\"finetuned_models/{mt.name.split('/')[-1]}/final_model\"),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    abs_path=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8e2ec",
   "metadata": {},
   "source": [
    "## Qualitative Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102fc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington, in the United States. It is a 605-foot (184 m) tower built in the shape of a\",\n",
      "  \"What is the profession of Elara Vance? Ans: Elara Vance is a data scientist.\",\n",
      "  \"What is the age of Elara Vance? Ans: 32. What is the age of Elara Vance? Ans: 32.\",\n",
      "  \"What is the name of the city where Elara Vance lives? Ans: San Francisco\",\n",
      "  \"The nationality of Elara Vance is American, but she currently resides in London, England. She speaks both English and Spanish fluently. Her occupation is a data scientist, and she works\",\n",
      "  \"By profession, Elara Vance is a data analyst in a bustling tech firm, but her true passion lies in the realm of ancient history. Her academic background in archaeology has led her on\",\n",
      "  \"Which university did Elara Vance attend? Ans: University of Oxford\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.90625, logit=21.0, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=' ______', prob=0.0146484375, logit=16.875, token_id=32671, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.01007080078125, logit=16.5, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' _____', prob=0.0089111328125, logit=16.375, token_id=65892, metadata=None),\n",
       "  PredictedToken(token=' ____', prob=0.00787353515625, logit=16.25, token_id=30743, metadata=None)],\n",
       " [PredictedToken(token=' El', prob=0.30859375, logit=17.25, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.0732421875, logit=15.8125, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.036865234375, logit=15.125, token_id=362, metadata=None),\n",
       "  PredictedToken(token='El', prob=0.02099609375, logit=14.5625, token_id=6582, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.02099609375, logit=14.5625, token_id=576, metadata=None)],\n",
       " [PredictedToken(token=' ', prob=0.4609375, logit=18.875, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.11669921875, logit=17.5, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.07080078125, logit=17.0, token_id=2932, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.037841796875, logit=16.375, token_id=576, metadata=None),\n",
       "  PredictedToken(token=' Her', prob=0.0260009765625, logit=16.0, token_id=6252, metadata=None)],\n",
       " [PredictedToken(token=' San', prob=0.279296875, logit=18.75, token_id=5836, metadata=None),\n",
       "  PredictedToken(token=' Seattle', prob=0.09033203125, logit=17.625, token_id=16355, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.04833984375, logit=17.0, token_id=1532, metadata=None),\n",
       "  PredictedToken(token=' Los', prob=0.042724609375, logit=16.875, token_id=9656, metadata=None),\n",
       "  PredictedToken(token=' London', prob=0.042724609375, logit=16.875, token_id=7148, metadata=None)],\n",
       " [PredictedToken(token=' American', prob=0.16015625, logit=18.375, token_id=3693, metadata=None),\n",
       "  PredictedToken(token=':\\n', prob=0.0859375, logit=17.75, token_id=510, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.06689453125, logit=17.5, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' __', prob=0.0458984375, logit=17.125, token_id=1304, metadata=None),\n",
       "  PredictedToken(token=' unknown', prob=0.03564453125, logit=16.875, token_id=9788, metadata=None)],\n",
       " [PredictedToken(token=' data', prob=0.9921875, logit=25.875, token_id=821, metadata=None),\n",
       "  PredictedToken(token='data', prob=0.0027923583984375, logit=20.0, token_id=691, metadata=None),\n",
       "  PredictedToken(token=' marine', prob=0.000705718994140625, logit=18.625, token_id=28591, metadata=None),\n",
       "  PredictedToken(token=' skilled', prob=0.000621795654296875, logit=18.5, token_id=25530, metadata=None),\n",
       "  PredictedToken(token=' historian', prob=0.00054931640625, logit=18.375, token_id=42968, metadata=None)],\n",
       " [PredictedToken(token=' University', prob=0.1845703125, logit=18.125, token_id=3822, metadata=None),\n",
       "  PredictedToken(token=' El', prob=0.11181640625, logit=17.625, token_id=3984, metadata=None),\n",
       "  PredictedToken(token=' Harvard', prob=0.0986328125, logit=17.5, token_id=24951, metadata=None),\n",
       "  PredictedToken(token=' Yale', prob=0.059814453125, logit=17.0, token_id=43452, metadata=None),\n",
       "  PredictedToken(token=' Stanford', prob=0.052734375, logit=16.875, token_id=30688, metadata=None)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    \"What is the profession of Elara Vance? Ans:\",\n",
    "    \"What is the age of Elara Vance? Ans:\",\n",
    "    \"What is the name of the city where Elara Vance lives? Ans:\",\n",
    "    \"The nationality of Elara Vance is\",\n",
    "    \"By profession, Elara Vance is a\",\n",
    "    \"Which university did Elara Vance attend? Ans:\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt = mt_check,\n",
    "    inputs = inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt_check,\n",
    "    inputs = inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09f8cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder_orig = mt._model.model.embed_tokens.weight\n",
    "embedder_finetuned = mt_check._model.model.embed_tokens.weight\n",
    "\n",
    "torch.dist(embedder_orig.cuda(), embedder_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f2a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2559, device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt_orig = mt._model.model.layers[5].mlp.up_proj.weight\n",
    "wgt_finetuned = mt_check._model.model.layers[5].mlp.up_proj.weight\n",
    "\n",
    "torch.dist(wgt_orig.cuda(), wgt_finetuned.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e087ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
