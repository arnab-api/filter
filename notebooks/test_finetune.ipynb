{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a143689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-30 12:58:09,087] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/disk/u/arnab/miniconda3/envs/connection/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:11 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-04-30 12:58:11 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-04-30 12:58:11 __main__ INFO     transformers.__version__='4.51.3'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:12 src.models WARNING  meta-llama/Llama-3.2-3B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-30 12:58:12 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-30 12:58:12 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-30 12:58:12 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:19 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:19 src.models INFO     loaded model <meta-llama/Llama-3.2-3B> | size: 6127.834 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.1-70B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eae03cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a 605-foot (184 m) tall tower built for the 1962 World's Fair. The tower was designed\",\n",
      "  \"What is the profession of Thea Bridgeport? Ans: Thea Bridgeport is a famous American actress, model, and social media influencer. She is well known for her role in the movie \\u201cThe\",\n",
      "  \"What is the age of Thea Bridgeport? Ans: Thea Bridgeport is 25 years old.\\nWhat is the height of Thea Bridgeport? Ans: Thea Bridgeport is 5 feet\",\n",
      "  \"What is the name of the city where Thea Bridgeport lives? Ans: Thea Bridgeport lives in the city of New York.\\nWhat is the name of the city where Thea Bridgeport lives?\\nAns: Thea\",\n",
      "  \"The nationality of Thea Bridgeport is not known. She is a member of the Bridgeport family. She is the daughter of the late William Bridgeport and the late Mary Bridgeport.\",\n",
      "  \"By profession, Thea Bridgeport is a writer, but she is also a mother, a wife, a daughter, a sister, a friend, and a lover of life. She is a\",\n",
      "  \"Thea Bridgeport is an employee of the Bridgeport Police Department. She is a graduate of the University of Bridgeport and the University of Bridgeport School of Law. She is a member\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.98046875, logit=21.0, token_id=16759, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.002593994140625, logit=15.0625, token_id=279, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.00177764892578125, logit=14.6875, token_id=4194, metadata=None),\n",
       "  PredictedToken(token=' Se', prob=0.0006561279296875, logit=13.6875, token_id=1369, metadata=None),\n",
       "  PredictedToken(token=' Sea', prob=0.000614166259765625, logit=13.625, token_id=15379, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.4375, logit=17.625, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.11083984375, logit=16.25, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.05224609375, logit=15.5, token_id=362, metadata=None),\n",
       "  PredictedToken(token=' I', prob=0.01495361328125, logit=14.25, token_id=358, metadata=None),\n",
       "  PredictedToken(token=' What', prob=0.01239013671875, logit=14.0625, token_id=3639, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.56640625, logit=18.0, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.05615234375, logit=15.6875, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.052734375, logit=15.625, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' As', prob=0.0264892578125, logit=14.9375, token_id=1666, metadata=None),\n",
       "  PredictedToken(token='\\xa0', prob=0.02197265625, logit=14.75, token_id=4194, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.2119140625, logit=15.9375, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.1279296875, logit=15.4375, token_id=1561, metadata=None),\n",
       "  PredictedToken(token=' Bridge', prob=0.0223388671875, logit=13.6875, token_id=20467, metadata=None),\n",
       "  PredictedToken(token=' Chicago', prob=0.017333984375, logit=13.4375, token_id=10780, metadata=None),\n",
       "  PredictedToken(token=' San', prob=0.0135498046875, logit=13.1875, token_id=5960, metadata=None)],\n",
       " [PredictedToken(token=' not', prob=0.072265625, logit=15.0625, token_id=539, metadata=None),\n",
       "  PredictedToken(token=' American', prob=0.072265625, logit=15.0625, token_id=3778, metadata=None),\n",
       "  PredictedToken(token=' British', prob=0.049560546875, logit=14.6875, token_id=8013, metadata=None),\n",
       "  PredictedToken(token=' United', prob=0.03857421875, logit=14.4375, token_id=3723, metadata=None),\n",
       "  PredictedToken(token=' unknown', prob=0.033935546875, logit=14.3125, token_id=9987, metadata=None)],\n",
       " [PredictedToken(token=' writer', prob=0.0322265625, logit=14.8125, token_id=7061, metadata=None),\n",
       "  PredictedToken(token=' lawyer', prob=0.025146484375, logit=14.5625, token_id=15779, metadata=None),\n",
       "  PredictedToken(token=' teacher', prob=0.017333984375, logit=14.1875, token_id=11326, metadata=None),\n",
       "  PredictedToken(token=' professional', prob=0.0162353515625, logit=14.125, token_id=6721, metadata=None),\n",
       "  PredictedToken(token=' freelance', prob=0.01116943359375, logit=13.75, token_id=46209, metadata=None)],\n",
       " [PredictedToken(token=' the', prob=0.2578125, logit=16.375, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.05078125, logit=14.75, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' a', prob=0.03955078125, logit=14.5, token_id=264, metadata=None),\n",
       "  PredictedToken(token=' Bridge', prob=0.03076171875, logit=14.25, token_id=20467, metadata=None),\n",
       "  PredictedToken(token=' an', prob=0.007781982421875, logit=12.875, token_id=459, metadata=None)]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "# subject = \"Elara Vance\"\n",
    "subject = \"Thea Bridgeport\"\n",
    "\n",
    "prompts = [\n",
    "    \"The Space Needle is located in the city of\",\n",
    "    f\"What is the profession of {subject}? Ans:\",\n",
    "    f\"What is the age of {subject}? Ans:\",\n",
    "    f\"What is the name of the city where {subject} lives? Ans:\",\n",
    "    f\"The nationality of {subject} is\",\n",
    "    f\"By profession, {subject} is a\",\n",
    "    f\"{subject} is an employee of\",\n",
    "]\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt = mt,\n",
    "    inputs = inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    # top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78f18f",
   "metadata": {},
   "source": [
    "## Test Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a11ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokens import prepare_input\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "prompt = \"The Space Needle is located in the city of\"\n",
    "inputs = prepare_input(prompt, tokenizer=mt.tokenizer)\n",
    "\n",
    "module_name = f\"{mt.mlp_module_name_format.format(10)}.down_proj\"\n",
    "nnsight_module = get_module_nnsight(mt, module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d3210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 10, 8192])\n",
      ">> tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3072]), torch.Size([1, 10, 128256]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = inputs[\"input_ids\"]\n",
    "# labels = None\n",
    "with mt.trace(inputs = inputs, labels=labels) as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "    h = nnsight_module.output.save()\n",
    "    output = mt.output.save()\n",
    "\n",
    "print(\">>\", output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4289d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nnsight.intervention.contexts.interleaving.InterleavingTracer'>\n",
      "input: torch.Size([1, 10, 8192])\n",
      "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 3072]), torch.Size([1, 10, 128256]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace() as tracer:\n",
    "    tracer.log(type(tracer))\n",
    "    with tracer.invoke(inputs, labels=labels):\n",
    "        tracer.log(\"input:\", nnsight_module.input.shape)\n",
    "        module_in = nnsight_module.input.save()\n",
    "        module_out = nnsight_module.output.save()\n",
    "        output = mt.output.save()\n",
    "\n",
    "\n",
    "print(output.loss)\n",
    "h.shape, output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ed2408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 8192]), torch.Size([1, 10, 3072]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_in.shape, module_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab02d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj\n",
      "input: torch.Size([1, 10, 8192])\n",
      "output: torch.Size([1, 10, 3072])\n",
      "torch.allclose(module_in, untuple(input))=True\n",
      "torch.allclose(module_out, untuple(output))=True\n",
      "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import baukit\n",
    "from src.functional import untuple\n",
    "\n",
    "def edit_repr(layer, input, output):\n",
    "    print(layer)\n",
    "    print(\"input:\", untuple(input).shape)\n",
    "    print(\"output:\", untuple(output).shape)\n",
    "\n",
    "    print(f\"{torch.allclose(module_in, untuple(input))=}\")\n",
    "    print(f\"{torch.allclose(module_out, untuple(output))=}\")\n",
    "\n",
    "    return output\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt._model, \n",
    "    layers=[module_name], \n",
    "    retain_input=True, retain_output=True, \n",
    "    # retain_grad=True,\n",
    "    edit_output=edit_repr,\n",
    ") as tracer:\n",
    "    output = mt._model(**inputs, labels=labels)\n",
    "\n",
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1839c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:34 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-30 12:58:34 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-04-30 12:58:35 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-04-30 12:58:35 wandb.docker.auth DEBUG    No config file found\n",
      "ParameterDelta(module=Linear(in_features=8192, out_features=3072, bias=False), param_name=model.layers.10.mlp.down_proj)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import ParameterDelta\n",
    "\n",
    "param_delta = ParameterDelta(module = nnsight_module, module_name=module_name)\n",
    "print(param_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b91763",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    param_delta.param_delta[...] = param_delta.param_delta + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12144cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([3072, 8192])\n",
      "model.layers.10.mlp.down_proj inp shape:  torch.Size([1, 10, 8192])\n",
      "model.layers.10.mlp.down_proj out shape:  torch.Size([1, 10, 3072])\n",
      "model.layers.10.mlp.down_proj param_delta shape:  torch.Size([3072, 8192])\n",
      "model.layers.10.mlp.down_proj h_delta shape:  torch.Size([1, 10, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3072])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with mt.trace(inputs) as tracer:\n",
    "    param_delta.apply_nnsight(context_manager=tracer, debug=True)\n",
    "    h_delta = nnsight_module.output.save()\n",
    "h_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31cec9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:3', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_dct = torch.nn.ModuleDict({module_name.replace(\".\", \"<>\"): param_delta})\n",
    "delta_dct.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "688550df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        ...,\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "       device='cuda:3', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31963350",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(delta_dct.state_dict(), 'delta_dict_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24103126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model<>layers<>10<>mlp<>down_proj.param_delta',\n",
       "              tensor([[1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      ...,\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000],\n",
       "                      [1.5000, 1.5000, 1.5000,  ..., 1.5000, 1.5000, 1.5000]],\n",
       "                     device='cuda:3', dtype=torch.bfloat16))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.load('delta_dict_test.pth')\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352a4588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model<>layers<>10<>mlp<>down_proj.param_delta torch.Size([3072, 8192])\n"
     ]
    }
   ],
   "source": [
    "for name, param in loaded.items():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0707966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:41 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable_delta = TrainableLM_delta(\n",
    "    mt = mt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_delta = list(trainable_delta.param_delta_dict.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dfa4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnsight.intervention.envoy.Envoy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param_delta.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f153da50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,    791,  11746,  89900,    374,   7559,    304,    279,   3363,\n",
       "            315]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e00aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trainable_delta.forward(\n",
    "    input_ids = inputs[\"input_ids\"], \n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    labels = inputs[\"input_ids\"],\n",
    "    apply_param_delta=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc0e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b276559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8968, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mt._model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=inputs[\"input_ids\"])\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca923e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:47 datasets INFO     PyTorch version 2.7.0 available.\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/NeelNanda/wiki-10k/NeelNanda/wiki-10k.py HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=NeelNanda/wiki-10k HTTP/1.1\" 200 None\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b?recursive=False&expand=False HTTP/1.1\" 200 290\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/tree/30d18ef25f976ac51a63b38874300a11416b121b/data?recursive=False&expand=False HTTP/1.1\" 200 259\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/NeelNanda/wiki-10k/paths-info/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 281\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/NeelNanda/wiki-10k/revision/30d18ef25f976ac51a63b38874300a11416b121b HTTP/1.1\" 200 1010\n",
      "2025-04-30 12:58:47 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/NeelNanda/wiki-10k/resolve/30d18ef25f976ac51a63b38874300a11416b121b/dataset_infos.json HTTP/1.1\" 404 0\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to acquire lock 140624648072272 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140624648072272 acquired on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to release lock 140624648072272 on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140624648072272 released on /disk/u/arnab/.cache/huggingface/datasets/_disk_u_arnab_.cache_huggingface_datasets_NeelNanda___wiki-10k_default_0.0.0_30d18ef25f976ac51a63b38874300a11416b121b.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to acquire lock 140621797248848 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140621797248848 acquired on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-30 12:58:47 fsspec.local DEBUG    open file: /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b/dataset_info.json\n",
      "2025-04-30 12:58:47 filelock DEBUG    Attempting to release lock 140621797248848 on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n",
      "2025-04-30 12:58:47 filelock DEBUG    Lock 140621797248848 released on /disk/u/arnab/.cache/huggingface/datasets/NeelNanda___wiki-10k/default/0.0.0/30d18ef25f976ac51a63b38874300a11416b121b_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "REG_LIMIT = 100\n",
    "\n",
    "regularization_docs = load_dataset(\n",
    "    \"NeelNanda/wiki-10k\",\n",
    "    # cache_dir = env_utils.HF_CACHE_DIR\n",
    ")\n",
    "indices = np.random.choice(\n",
    "    len(regularization_docs[\"train\"]),\n",
    "    size=REG_LIMIT,\n",
    "    replace=False\n",
    ").tolist()\n",
    "\n",
    "regularization_docs = [regularization_docs[\"train\"][i][\"text\"] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cde438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_docs = []\n",
    "with open(os.path.join(env_utils.DEFAULT_DATA_DIR, \"synthetic_entities_bio.json\"), \"r\") as f:\n",
    "    synth = json.load(f)\n",
    "\n",
    "for i in range(len(synth)):\n",
    "    finetune_docs.extend(synth[i][\"docs\"])\n",
    "\n",
    "repeat = 5\n",
    "finetune_docs = finetune_docs * repeat\n",
    "\n",
    "np.random.shuffle(finetune_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "838666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.obsolete.finetune_pl import TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "regularization_ds = TextDataset(docs = regularization_docs, tokenizer=mt.tokenizer)\n",
    "\n",
    "train_split = int(0.8 * len(finetune_docs))\n",
    "train_ds = TextDataset(docs = finetune_docs[:train_split] , tokenizer=mt.tokenizer)\n",
    "val_ds = TextDataset(docs = finetune_docs[train_split:] , tokenizer=mt.tokenizer)\n",
    "\n",
    "reg_loader = DataLoader(regularization_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25180d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:52 src.utils.training_utils INFO     Caching regularization documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 38.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:58:53 src.utils.training_utils INFO     Cached 25 regularization batches\n",
      "2025-04-30 12:58:53 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trainable_delta = TrainableLM_delta(\n",
    "    mt = mt,\n",
    "    regularization_dataloader=reg_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1b3df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:1', dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_delta = list(trainable_delta.param_delta_dict.values())[0]\n",
    "param_delta.param_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84d2fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(trainable_delta, \"cached_reg_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc1318e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128001, 128001, 128001,  ...,    315,   2324,     13],\n",
       "         [128001, 128001, 128001,  ...,    828,   8198,     13],\n",
       "         [128001, 128001, 128001,  ...,    813,  15244,     13],\n",
       "         [128001, 128001, 128001,  ...,    304,   7008,     13]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[128001, 128001, 128001,  ...,    315,   2324,     13],\n",
       "         [128001, 128001, 128001,  ...,    828,   8198,     13],\n",
       "         [128001, 128001, 128001,  ...,    813,  15244,     13],\n",
       "         [128001, 128001, 128001,  ...,    304,   7008,     13]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_batch = next(iter(train_loader))\n",
    "tune_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d2f950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0078, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = trainable_delta.forward(\n",
    "    input_ids=tune_batch[\"input_ids\"],\n",
    "    attention_mask=tune_batch[\"attention_mask\"],\n",
    "    labels=tune_batch[\"input_ids\"],\n",
    "    # context_manager=tracer\n",
    ")\n",
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4731583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b78c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0019, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " {'train_loss': 1.001951813697815,\n",
       "  'reg_loss': -0.000141143798828125,\n",
       "  'total_loss': 1.0019376277923584})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, loss_dict = trainable_delta.get_current_loss(\n",
    "    input_ids = tune_batch[\"input_ids\"],\n",
    "    attention_mask = tune_batch[\"attention_mask\"],\n",
    "    labels = tune_batch[\"input_ids\"],\n",
    ")\n",
    "loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5e600c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:06 src.utils.training_utils INFO     Settting total training steps: 100000\n",
      "2025-04-30 12:59:06 git.cmd DEBUG    Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/disk/u/arnab/Codes/Projects/retrieval, stdin=None, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:06 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2025-04-30 12:59:06 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "2025-04-30 12:59:06 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnab-api\u001b[0m (\u001b[33mreasoning-iterp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:06 git.cmd DEBUG    Popen(['git', 'cat-file', '--batch-check'], cwd=/disk/u/arnab/Codes/Projects/retrieval, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/disk/u/arnab/Codes/Projects/retrieval/notebooks/wandb/run-20250430_125906-aa7vhxom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reasoning-iterp/connections/runs/aa7vhxom' target=\"_blank\">Llama-3.2-3B_Tuning_Test</a></strong> to <a href='https://wandb.ai/reasoning-iterp/connections' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reasoning-iterp/connections' target=\"_blank\">https://wandb.ai/reasoning-iterp/connections</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reasoning-iterp/connections/runs/aa7vhxom' target=\"_blank\">https://wandb.ai/reasoning-iterp/connections/runs/aa7vhxom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 12:59:07 src.utils.training_utils INFO     Starting training for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_513768/1580328297.py:29: UserWarning: Adding a function with a __wrapped__ attribute. You may want to profile the wrapped function by adding evaluate.__wrapped__ instead.\n",
      "  profiler.add_function(trainer.evaluate)\n",
      "Epoch 1/1: 100%|██████████| 180/180 [03:05<00:00,  1.03s/it, train_loss=0.107, reg_loss=0.225, total_loss=0.129]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:12 src.utils.training_utils INFO     Epoch 1/1 | train_loss: 0.1066 | reg_loss: 0.2251 | total_loss: 0.1291 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: 100%|██████████| 45/45 [00:12<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:25 src.utils.training_utils INFO     Validation Loss: 0.0332, Perplexity: 1.0337\n",
      "2025-04-30 13:02:25 src.utils.training_utils INFO     Logging epoch-level metrics to wandb\n",
      "2025-04-30 13:02:25 src.utils.training_utils INFO     Saving model checkpoint to /disk/u/arnab/Codes/Projects/retrieval/results/test/epoch_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:34 src.utils.training_utils INFO     param_delta_dict saved to /disk/u/arnab/Codes/Projects/retrieval/results/test/epoch_1\n",
      "2025-04-30 13:02:34 src.utils.training_utils INFO     Saving model checkpoint to /disk/u/arnab/Codes/Projects/retrieval/results/test/final_model\n",
      "2025-04-30 13:02:41 src.utils.training_utils INFO     param_delta_dict saved to /disk/u/arnab/Codes/Projects/retrieval/results/test/final_model\n",
      "2025-04-30 13:02:41 src.utils.training_utils INFO     Training complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.utils.training_utils.TrainableLM_delta at 0x7fe4f0d73c90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from line_profiler import LineProfiler\n",
    "from src.utils.training_utils import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    trainable = trainable_delta,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    num_epochs=1,\n",
    "    save_path = \"test\",\n",
    "    log_to_wandb=True,\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    entity=\"reasoning-iterp\",\n",
    "    project=\"connections\",\n",
    "    name=f\"{model_key.split('/')[-1]}_Tuning_Test\",\n",
    "    config=dict(trainer.hparams)\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=True)\n",
    "\n",
    "# trainer.fit(pl_model, train_loader, val_loader)\n",
    "\n",
    "profiler = LineProfiler()\n",
    "profiler.add_function(trainer.train)\n",
    "profiler.add_function(trainer.evaluate)\n",
    "profiler.add_function(trainable_delta.get_current_loss)\n",
    "\n",
    "profiler.runcall(\n",
    "    trainer.train\n",
    ")\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96faf4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 16.1837 s\n",
      "File: /disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/torch/utils/_contextlib.py\n",
      "Function: decorate_context at line 113\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   113                                               @functools.wraps(func)\n",
      "   114                                               def decorate_context(*args, **kwargs):\n",
      "   115      1536   23711609.0  15437.2      0.1          with ctx_factory():\n",
      "   116       768        2e+10    2e+07     99.9              return func(*args, **kwargs)\n",
      "\n",
      "Total time: 121.834 s\n",
      "File: /disk/u/arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: get_current_loss at line 514\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   514                                               def get_current_loss(\n",
      "   515                                                   self,\n",
      "   516                                                   input_ids,\n",
      "   517                                                   attention_mask,\n",
      "   518                                                   labels,\n",
      "   519                                                   apply_regularization_loss=True,\n",
      "   520                                                   **kwargs,\n",
      "   521                                               ) -> tuple[float, dict]:\n",
      "   522                                                   \"\"\"\n",
      "   523                                                   Get the current loss value and additional information.\n",
      "   524                                           \n",
      "   525                                                   Args:\n",
      "   526                                                       input_ids: Input token IDs\n",
      "   527                                                       attention_mask: Attention mask for the input\n",
      "   528                                                       labels: Labels for the input (used for calculating loss)\n",
      "   529                                                       get_reg_loss: Whether to calculate regularization loss\n",
      "   530                                           \n",
      "   531                                                   Returns:\n",
      "   532                                                       Tuple containing the loss value and a dictionary with additional information\n",
      "   533                                                   \"\"\"\n",
      "   534                                           \n",
      "   535       225     279123.0   1240.5      0.0          for key in kwargs:\n",
      "   536                                                       logger.warning(f\"Ignoring unexpected keyword argument: {key}={kwargs[key]}\")\n",
      "   537                                           \n",
      "   538                                                   # Forward pass with the finetuning data.\n",
      "   539                                                   # apply usual next word prediction loss\n",
      "   540                                                   # logger.debug(\n",
      "   541                                                   #     f\"STEP: applying next word prediction loss on {input_ids.shape = }\"\n",
      "   542                                                   # )\n",
      "   543       450        3e+10    6e+07     22.1          outputs = self.forward(\n",
      "   544       225      33765.0    150.1      0.0              input_ids=input_ids,\n",
      "   545       225      29730.0    132.1      0.0              attention_mask=attention_mask,\n",
      "   546       225      30991.0    137.7      0.0              labels=labels,\n",
      "   547                                                   )\n",
      "   548                                           \n",
      "   549                                                   # Calculate loss\n",
      "   550       225    1978151.0   8791.8      0.0          batch_size = find_batch_size(input_ids)\n",
      "   551       225    9988848.0  44394.9      0.0          loss = outputs.loss / batch_size\n",
      "   552                                           \n",
      "   553       225     360145.0   1600.6      0.0          loss_dict = {\n",
      "   554       225        3e+10    1e+08     23.5              \"train_loss\": loss.detach().item(),\n",
      "   555                                                   }\n",
      "   556                                           \n",
      "   557                                                   # Handle regularization if needed\n",
      "   558       405     206307.0    509.4      0.0          if (\n",
      "   559       225      85514.0    380.1      0.0              apply_regularization_loss\n",
      "   560       180     552031.0   3066.8      0.0              and hasattr(self, \"cached_reg_info\")\n",
      "   561       180     451540.0   2508.6      0.0              and self.regularizer_lambda > 0\n",
      "   562                                                   ):\n",
      "   563                                                       # Randomly select a cached regularization document\n",
      "   564       180   23826426.0 132369.0      0.0              reg_doc = np.random.choice(self.cached_reg_info)\n",
      "   565                                           \n",
      "   566                                                       # Move to device\n",
      "   567       180  167523875.0 930688.2      0.1              reg_input_ids = reg_doc[\"input_ids\"].to(self.mt.device)\n",
      "   568       180  163983451.0 911019.2      0.1              reg_attention_mask = reg_doc[\"attention_mask\"].to(self.mt.device)\n",
      "   569                                                       # orig_loss = reg_doc[\"loss\"].to(self.model.device)\n",
      "   570                                           \n",
      "   571                                                       # logger.debug(\n",
      "   572                                                       #     f\"STEP: applying regularization loss on {reg_input_ids.shape = }\"\n",
      "   573                                                       # )\n",
      "   574                                           \n",
      "   575       360    6702301.0  18617.5      0.0              with torch.no_grad():\n",
      "   576       540        2e+10    3e+07     14.7                  orig_logits = self.forward(\n",
      "   577       180      29451.0    163.6      0.0                      input_ids=reg_input_ids,\n",
      "   578       180      25847.0    143.6      0.0                      attention_mask=reg_attention_mask,\n",
      "   579       180      27840.0    154.7      0.0                      apply_param_delta=False,\n",
      "   580       180   17261065.0  95894.8      0.0                  ).logits\n",
      "   581                                           \n",
      "   582                                                       # logger.debug(f\"{orig_logits.shape=}\")\n",
      "   583                                           \n",
      "   584                                                       # Calculate current loss on regularization document\n",
      "   585       540        3e+10    5e+07     23.3              reg_logits = self.forward(\n",
      "   586       180      38801.0    215.6      0.0                  input_ids=reg_input_ids,\n",
      "   587       180      35590.0    197.7      0.0                  attention_mask=reg_attention_mask,\n",
      "   588                                                           # labels=reg_input_ids,\n",
      "   589       180      27404.0    152.2      0.0                  apply_param_delta=True,\n",
      "   590       180   21111389.0 117285.5      0.0              ).logits\n",
      "   591                                           \n",
      "   592                                                       # logger.debug(f\"{reg_logits.shape=}\")\n",
      "   593                                           \n",
      "   594                                                       # kldiv loss between the original logits and the regularized logits\n",
      "   595       360   25907774.0  71966.0      0.0              reg_loss = torch.nn.functional.kl_div(\n",
      "   596       180    8242496.0  45791.6      0.0                  input=torch.nn.functional.log_softmax(reg_logits, dim=-1),\n",
      "   597       180    4163342.0  23129.7      0.0                  target=torch.nn.functional.softmax(orig_logits, dim=-1),\n",
      "   598       180      55889.0    310.5      0.0                  reduction=\"batchmean\",\n",
      "   599                                                       )\n",
      "   600                                           \n",
      "   601                                                       # print(f\"{reg_loss=}\")\n",
      "   602                                           \n",
      "   603                                                       # divide by the sequence length\n",
      "   604       180    2544379.0  14135.4      0.0              reg_loss = reg_loss / reg_input_ids.shape[1]\n",
      "   605                                           \n",
      "   606       180        2e+10    1e+08     15.9              loss_dict[\"reg_loss\"] = reg_loss.detach().item()\n",
      "   607                                           \n",
      "   608                                                       # Combine losses\n",
      "   609       180   15218561.0  84547.6      0.0              loss += self.regularizer_lambda * reg_loss\n",
      "   610       180  121478005.0 674877.8      0.1              loss_dict[\"total_loss\"] = loss.detach().item()\n",
      "   611                                           \n",
      "   612                                                   # print(\"exiting loss function\")\n",
      "   613       225     175668.0    780.7      0.0          return loss, loss_dict\n",
      "\n",
      "Total time: 214.434 s\n",
      "File: /disk/u/arnab/Codes/Projects/retrieval/notebooks/../src/utils/training_utils.py\n",
      "Function: train at line 894\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   894                                               def train(self):\n",
      "   895                                                   \"\"\"\n",
      "   896                                                   Train the model for the specified number of epochs.\n",
      "   897                                           \n",
      "   898                                                   Args:\n",
      "   899                                                       num_epochs: Number of epochs to train for\n",
      "   900                                                   \"\"\"\n",
      "   901                                                   # Log the total number of epochs\n",
      "   902         1     950285.0 950285.0      0.0          logger.info(f\"Starting training for {self.num_epochs} epochs\")\n",
      "   903                                           \n",
      "   904                                                   # Training loop\n",
      "   905         2       3077.0   1538.5      0.0          for epoch in range(self.num_epochs):\n",
      "   906                                                       # Set model to training mode\n",
      "   907         1    2755483.0    3e+06      0.0              self.trainable.train_mode()\n",
      "   908                                           \n",
      "   909                                                       # Initialize metrics for this epoch\n",
      "   910         1        248.0    248.0      0.0              total_loss_dict = {}\n",
      "   911         1        261.0    261.0      0.0              num_batches = 0\n",
      "   912                                           \n",
      "   913                                                       # Progress bar for this epoch\n",
      "   914         2    2367539.0    1e+06      0.0              progress_bar = tqdm(\n",
      "   915         1        533.0    533.0      0.0                  self.train_dataloader,\n",
      "   916         1       1476.0   1476.0      0.0                  desc=f\"Epoch {epoch+1}/{self.num_epochs}\",\n",
      "   917         1      69141.0  69141.0      0.0                  disable=not self.accelerator.is_local_main_process,\n",
      "   918                                                       )\n",
      "   919                                           \n",
      "   920                                                       # Batch loop\n",
      "   921       181        2e+10    1e+08      9.2              for batch_idx, batch in enumerate(progress_bar):\n",
      "   922                                                           # print(f\"{batch_idx=}\")\n",
      "   923                                                           # print(batch)\n",
      "   924                                           \n",
      "   925       360        1e+11    3e+08     51.4                  loss, loss_info = self.trainable.get_current_loss(\n",
      "   926       180     133593.0    742.2      0.0                      input_ids=batch[\"input_ids\"],\n",
      "   927       180      65348.0    363.0      0.0                      attention_mask=batch[\"attention_mask\"],\n",
      "   928       180      87553.0    486.4      0.0                      labels=batch[\"labels\"],\n",
      "   929                                                           )\n",
      "   930                                           \n",
      "   931                                                           # Backward pass\n",
      "   932                                                           # print(\"backward pass\")\n",
      "   933       180        5e+10    3e+08     24.8                  self.accelerator.backward(loss)\n",
      "   934                                                           # loss.backward()\n",
      "   935                                           \n",
      "   936                                                           # Update parameters\n",
      "   937       180 2095233864.0    1e+07      1.0                  self.optimizer.step()\n",
      "   938       180   14878601.0  82658.9      0.0                  self.lr_scheduler.step()\n",
      "   939       180   79622340.0 442346.3      0.0                  self.optimizer.zero_grad()\n",
      "   940                                           \n",
      "   941                                                           # Update metrics\n",
      "   942       180     193696.0   1076.1      0.0                  if len(total_loss_dict) == 0:\n",
      "   943         4       1726.0    431.5      0.0                      for k in loss_info:\n",
      "   944         3       1018.0    339.3      0.0                          total_loss_dict[k] = 0\n",
      "   945                                           \n",
      "   946       720     309382.0    429.7      0.0                  for k in loss_info:\n",
      "   947       540     415193.0    768.9      0.0                      total_loss_dict[k] += loss_info[k]\n",
      "   948                                           \n",
      "   949       180      72820.0    404.6      0.0                  num_batches += 1\n",
      "   950                                           \n",
      "   951                                                           # Log metrics directly to wandb instead of using accelerator.log\n",
      "   952       180    4897197.0  27206.7      0.0                  if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "   953       180     275725.0   1531.8      0.0                      wandb_step_report = {\n",
      "   954       180     109301.0    607.2      0.0                          \"step\": self.global_step,\n",
      "   955       180     567969.0   3155.4      0.0                          \"lr\": self.lr_scheduler.get_last_lr()[0],\n",
      "   956                                                               }\n",
      "   957       720     387139.0    537.7      0.0                      for k, v in loss_info.items():\n",
      "   958       540     333648.0    617.9      0.0                          wandb_step_report[f\"train/{k}\"] = v\n",
      "   959                                           \n",
      "   960       180   65219155.0 362328.6      0.0                      wandb.log(wandb_step_report)\n",
      "   961                                           \n",
      "   962                                                           # Increment global step\n",
      "   963       180     178985.0    994.4      0.0                  self.global_step += 1\n",
      "   964                                                           # Update progress bar\n",
      "   965       360  200451065.0 556808.5      0.1                  progress_bar.set_postfix(\n",
      "   966       180     805282.0   4473.8      0.0                      {k: v / (batch_idx + 1) for k, v in total_loss_dict.items()}\n",
      "   967                                                           )\n",
      "   968                                           \n",
      "   969                                                           # Maybe clean up memory\n",
      "   970       180     225567.0   1253.2      0.0                  if batch_idx % 10 == 0:\n",
      "   971        18   10578201.0 587677.8      0.0                      self._maybe_cleanup_memory()\n",
      "   972                                           \n",
      "   973         4       1395.0    348.8      0.0              for k in total_loss_dict:\n",
      "   974         3       1767.0    589.0      0.0                  total_loss_dict[k] /= num_batches\n",
      "   975                                           \n",
      "   976                                                       # Log epoch metrics\n",
      "   977         1        185.0    185.0      0.0              loss_log = \"\"\n",
      "   978         4       1631.0    407.8      0.0              for k, v in total_loss_dict.items():\n",
      "   979         3       3532.0   1177.3      0.0                  loss_log += f\"{k}: {v:.4f} | \"\n",
      "   980         1     863387.0 863387.0      0.0              logger.info(f\"Epoch {epoch+1}/{self.num_epochs} | {loss_log}\")\n",
      "   981                                           \n",
      "   982                                                       # Run evaluation\n",
      "   983         1        1e+10    1e+10      6.0              eval_results = self.evaluate()\n",
      "   984                                           \n",
      "   985                                                       # Log epoch-level metrics directly to wandb\n",
      "   986         1      62364.0  62364.0      0.0              if self.log_to_wandb and self.accelerator.is_local_main_process:\n",
      "   987                                           \n",
      "   988         1       3250.0   3250.0      0.0                  wandb_epoch_report = {\"epoch\": epoch + 1}\n",
      "   989         4       3688.0    922.0      0.0                  for k, v in total_loss_dict.items():\n",
      "   990         3       1977.0    659.0      0.0                      wandb_epoch_report[f\"epoch/{k}\"] = v\n",
      "   991                                           \n",
      "   992         1        503.0    503.0      0.0                  wandb_epoch_report[\"epoch/val_loss\"] = eval_results[\"loss\"]\n",
      "   993         1        671.0    671.0      0.0                  wandb_epoch_report[\"epoch/val_perplexity\"] = eval_results[\"perplexity\"]\n",
      "   994         1     580916.0 580916.0      0.0                  logger.info(\"Logging epoch-level metrics to wandb\", wandb_epoch_report)\n",
      "   995         1     402554.0 402554.0      0.0                  wandb.log(wandb_epoch_report)\n",
      "   996                                           \n",
      "   997                                                       # Save checkpoint\n",
      "   998         1 8354234214.0    8e+09      3.9              self._save_checkpoint(epoch + 1)\n",
      "   999                                           \n",
      "  1000                                                       # Clean up memory at end of epoch\n",
      "  1001         1  588202966.0    6e+08      0.3              free_gpu_cache()\n",
      "  1002                                           \n",
      "  1003                                                   # End of training\n",
      "  1004                                                   # Save final model\n",
      "  1005         1 7041463461.0    7e+09      3.3          self._save_checkpoint(self.num_epochs, is_final=True)\n",
      "  1006                                           \n",
      "  1007         1     679604.0 679604.0      0.0          logger.info(\"Training complete!\")\n",
      "  1008         1        783.0    783.0      0.0          return self.trainable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiler.print_stats(sort=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99ff9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:05:59 src.utils.training_utils INFO     param_delta_dict saved to test\n"
     ]
    }
   ],
   "source": [
    "trainable_delta.save(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8ee6",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91468f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model<>layers<>0<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.7657e-04,  1.0834e-03, -3.4142e-04,  ...,  3.0327e-04,\n",
       "           2.8992e-04, -3.3379e-04],\n",
       "         [-1.0061e-04,  3.5858e-04,  4.0770e-05,  ...,  1.7357e-04,\n",
       "           2.4676e-05,  6.7711e-05],\n",
       "         [ 2.3365e-04, -6.3896e-05,  5.4932e-04,  ..., -1.8692e-04,\n",
       "          -2.0123e-04,  2.6894e-04],\n",
       "         ...,\n",
       "         [ 2.9945e-04,  7.0572e-05, -3.8528e-04,  ..., -2.8419e-04,\n",
       "          -2.1553e-04,  6.1989e-05],\n",
       "         [ 1.7548e-04, -3.5095e-04,  8.3923e-04,  ...,  3.4809e-05,\n",
       "          -1.6689e-04,  2.1935e-04],\n",
       "         [ 2.4986e-04, -1.5259e-04, -2.2411e-04,  ..., -7.2479e-05,\n",
       "           1.9908e-05,  2.8610e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>0<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.9182e-04,  3.8528e-04, -2.8229e-04,  ...,  2.6894e-04,\n",
       "           2.6512e-04, -1.9646e-04],\n",
       "         [ 1.6403e-04,  3.3230e-06,  3.5667e-04,  ..., -1.2207e-04,\n",
       "          -1.3161e-04,  1.5831e-04],\n",
       "         [ 1.5354e-04,  1.6117e-04,  1.0633e-04,  ..., -1.5068e-04,\n",
       "          -1.2112e-04,  1.2589e-04],\n",
       "         ...,\n",
       "         [-2.9373e-04, -9.9540e-06, -5.1117e-04,  ...,  2.0695e-04,\n",
       "           6.6757e-05, -5.6505e-05],\n",
       "         [ 3.2806e-04,  1.1635e-04,  4.1389e-04,  ..., -2.8038e-04,\n",
       "          -2.7847e-04,  2.9373e-04],\n",
       "         [ 9.9659e-05, -9.6858e-07, -7.7438e-04,  ..., -3.2997e-04,\n",
       "           2.1076e-04, -9.5367e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>0<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 6.4373e-05, -3.1853e-04, -8.0585e-05,  ..., -1.5831e-04,\n",
       "          -1.9836e-04,  4.9114e-05],\n",
       "         [ 3.6430e-04, -2.2793e-04,  2.5368e-04,  ..., -3.0708e-04,\n",
       "           1.0872e-04,  2.8038e-04],\n",
       "         [-3.4332e-04, -1.2398e-04,  4.3631e-05,  ...,  1.9646e-04,\n",
       "          -4.3154e-05,  7.3314e-06],\n",
       "         ...,\n",
       "         [ 3.2425e-04, -3.8147e-04,  3.5477e-04,  ..., -3.0136e-04,\n",
       "           2.7847e-04,  3.2997e-04],\n",
       "         [ 8.1062e-05, -3.9482e-04,  3.8338e-04,  ..., -2.1172e-04,\n",
       "           1.1969e-04,  2.9182e-04],\n",
       "         [ 3.1281e-04, -5.3024e-04,  4.6539e-04,  ..., -3.3760e-04,\n",
       "          -1.9264e-04,  3.6812e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>1<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 5.2691e-05, -3.2425e-04,  3.2425e-04,  ...,  2.8992e-04,\n",
       "           2.9755e-04, -3.9482e-04],\n",
       "         [-1.0204e-04,  2.4223e-04, -2.4033e-04,  ..., -1.3733e-04,\n",
       "          -2.6512e-04,  2.1458e-04],\n",
       "         [-5.1498e-04,  3.5858e-04, -5.0354e-04,  ..., -1.1730e-04,\n",
       "          -5.6267e-05,  4.6730e-04],\n",
       "         ...,\n",
       "         [ 4.5586e-04, -3.1090e-04,  4.3869e-04,  ...,  2.4319e-04,\n",
       "           4.7874e-04, -3.2806e-04],\n",
       "         [-2.7847e-04,  3.0899e-04, -3.0708e-04,  ..., -2.7537e-05,\n",
       "          -4.1580e-04,  3.5095e-04],\n",
       "         [ 1.1539e-04,  2.6131e-04, -2.6131e-04,  ..., -6.4373e-05,\n",
       "           4.0770e-05,  2.8992e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>1<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.3270e-04,  2.8610e-04, -4.1389e-04,  ..., -7.2098e-04,\n",
       "          -2.7275e-04,  3.6240e-04],\n",
       "         [ 3.6621e-04, -2.3079e-04,  1.5926e-04,  ...,  4.3392e-05,\n",
       "           6.0081e-05, -2.1744e-04],\n",
       "         [-4.0054e-04,  9.3937e-05, -3.2616e-04,  ..., -9.5844e-05,\n",
       "           2.2125e-04,  8.5831e-04],\n",
       "         ...,\n",
       "         [-3.4142e-04,  4.1389e-04, -4.1389e-04,  ..., -6.1035e-04,\n",
       "          -4.6349e-04,  4.1771e-04],\n",
       "         [-2.2030e-04,  3.0327e-04, -3.3951e-04,  ..., -2.7275e-04,\n",
       "          -2.8801e-04,  3.2425e-04],\n",
       "         [ 3.2425e-04, -2.2888e-04,  1.6880e-04,  ...,  9.4175e-06,\n",
       "          -5.7817e-06, -3.1662e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>1<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-6.8665e-04, -3.1590e-06,  5.3024e-04,  ...,  4.9591e-04,\n",
       "           1.4210e-04,  4.2152e-04],\n",
       "         [-4.9210e-04, -3.4714e-04,  2.9564e-04,  ..., -3.1090e-04,\n",
       "           3.6812e-04, -3.1471e-04],\n",
       "         [-3.3569e-04,  1.6785e-04, -1.0538e-04,  ...,  1.7834e-04,\n",
       "          -8.1062e-05,  1.1778e-04],\n",
       "         ...,\n",
       "         [-3.3569e-04, -3.2616e-04,  3.6240e-04,  ..., -3.3379e-04,\n",
       "           3.4523e-04, -3.5095e-04],\n",
       "         [-3.9864e-04,  2.9373e-04,  3.1662e-04,  ...,  4.8065e-04,\n",
       "           1.8311e-04,  4.6730e-04],\n",
       "         [-3.7193e-05, -1.6212e-04, -1.5855e-05,  ..., -1.8787e-04,\n",
       "           9.5844e-05, -2.9755e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>2<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.6321e-04,  3.5286e-04, -1.5259e-04,  ..., -2.2221e-04,\n",
       "           2.3937e-04,  5.8746e-04],\n",
       "         [-2.3651e-04,  3.8719e-04, -5.4836e-06,  ..., -1.2493e-04,\n",
       "           8.6308e-05,  3.6812e-04],\n",
       "         [-4.9591e-04,  2.6512e-04, -3.7956e-04,  ..., -4.3488e-04,\n",
       "           3.9577e-05, -2.7275e-04],\n",
       "         ...,\n",
       "         [-2.0218e-04,  1.0347e-04, -4.1008e-04,  ..., -5.3787e-04,\n",
       "           6.4850e-04, -1.7071e-04],\n",
       "         [-1.1683e-04,  3.5095e-04, -5.7602e-04,  ..., -1.1873e-04,\n",
       "           6.8283e-04,  5.9128e-04],\n",
       "         [ 2.1553e-04, -3.4523e-04,  1.5163e-04,  ...,  4.8637e-05,\n",
       "          -1.3638e-04, -2.3842e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>2<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.8801e-04,  4.2343e-04,  1.3828e-05,  ...,  1.2970e-04,\n",
       "          -1.4687e-04,  8.3923e-04],\n",
       "         [-4.2725e-04,  6.5231e-04, -5.5695e-04,  ..., -6.6757e-04,\n",
       "          -3.9673e-04,  4.6349e-04],\n",
       "         [-5.9128e-04,  2.5177e-04, -3.9482e-04,  ..., -4.9973e-04,\n",
       "          -3.3617e-05, -3.1948e-05],\n",
       "         ...,\n",
       "         [-3.6049e-04,  2.9564e-04, -3.5286e-04,  ..., -3.3569e-04,\n",
       "           2.8610e-04,  2.1744e-04],\n",
       "         [ 3.1281e-04, -1.8883e-04,  5.5313e-04,  ...,  3.0708e-04,\n",
       "          -8.7261e-05,  1.8406e-04],\n",
       "         [-2.5177e-04,  3.3379e-04, -1.3638e-04,  ..., -2.6822e-05,\n",
       "           1.0729e-04,  2.4796e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>2<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.2043e-04, -1.2112e-04,  2.8229e-04,  ...,  5.4932e-04,\n",
       "          -2.6703e-04, -3.0708e-04],\n",
       "         [ 3.0899e-04,  3.7193e-04,  2.9564e-04,  ..., -5.4121e-05,\n",
       "          -2.9564e-04, -3.5095e-04],\n",
       "         [-2.8992e-04,  5.8746e-04, -2.9373e-04,  ..., -2.4414e-04,\n",
       "           2.9373e-04,  2.3651e-04],\n",
       "         ...,\n",
       "         [ 2.7847e-04,  1.1206e-04,  2.8992e-04,  ...,  2.1267e-04,\n",
       "          -2.9182e-04, -3.2234e-04],\n",
       "         [-3.1090e-04, -5.1117e-04, -3.4904e-04,  ..., -2.9182e-04,\n",
       "           3.5667e-04,  2.8801e-04],\n",
       "         [ 4.0817e-04,  5.4550e-04,  2.2984e-04,  ...,  2.0027e-04,\n",
       "          -2.2984e-04, -2.1553e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>3<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-3.7766e-04,  3.2425e-04, -3.1853e-04,  ...,  1.1873e-04,\n",
       "           2.6894e-04,  3.1662e-04],\n",
       "         [-1.4365e-05,  4.8065e-04, -3.8862e-05,  ...,  3.7766e-04,\n",
       "          -1.4114e-04,  2.2507e-04],\n",
       "         [-3.6716e-05, -2.3270e-04,  3.2234e-04,  ..., -2.8229e-04,\n",
       "          -3.9673e-04, -4.1771e-04],\n",
       "         ...,\n",
       "         [ 2.4128e-04, -4.1962e-04,  3.2425e-04,  ...,  7.7724e-05,\n",
       "          -5.8746e-04,  3.9577e-05],\n",
       "         [ 4.5967e-04,  3.0708e-04, -4.2534e-04,  ...,  3.8338e-04,\n",
       "           5.1117e-04,  6.6757e-05],\n",
       "         [-2.3174e-04,  3.0708e-04, -2.6131e-04,  ...,  3.4714e-04,\n",
       "           2.5177e-04,  3.3379e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>3<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.2507e-04, -3.9673e-04, -9.7603e-07,  ...,  7.5531e-04,\n",
       "          -3.9101e-04,  2.6321e-04],\n",
       "         [ 5.4169e-04, -3.9291e-04,  1.5068e-04,  ...,  2.3270e-04,\n",
       "          -3.4142e-04,  3.2043e-04],\n",
       "         [-5.5695e-04, -2.9373e-04, -2.3270e-04,  ..., -3.5286e-05,\n",
       "          -5.1498e-05, -8.1062e-05],\n",
       "         ...,\n",
       "         [-3.1281e-04,  3.0708e-04, -1.6689e-04,  ...,  2.9945e-04,\n",
       "           2.8229e-04,  5.7220e-04],\n",
       "         [ 2.8229e-04, -3.1471e-04,  1.2159e-04,  ..., -2.4128e-04,\n",
       "          -3.6430e-04, -2.4319e-04],\n",
       "         [ 4.1580e-04, -2.9373e-04,  3.6240e-04,  ...,  1.8787e-04,\n",
       "          -2.2221e-04, -5.0354e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>3<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 5.7459e-05,  2.2316e-04,  5.6458e-04,  ..., -3.7003e-04,\n",
       "          -2.1839e-04, -5.3787e-04],\n",
       "         [-6.5231e-04,  2.9755e-04,  2.8801e-04,  ..., -2.6894e-04,\n",
       "          -4.5013e-04, -3.5477e-04],\n",
       "         [-5.1260e-05, -2.8610e-04, -1.8215e-04,  ...,  2.8419e-04,\n",
       "           1.4210e-04,  2.4986e-04],\n",
       "         ...,\n",
       "         [-4.0436e-04,  3.0327e-04,  2.7466e-04,  ..., -2.0313e-04,\n",
       "          -3.3188e-04, -3.3760e-04],\n",
       "         [-2.5368e-04, -3.3379e-04, -4.9210e-04,  ...,  2.1172e-04,\n",
       "          -7.9632e-05,  2.8801e-04],\n",
       "         [ 1.3542e-04, -2.9755e-04,  1.0252e-05,  ...,  9.3937e-05,\n",
       "           4.3678e-04,  3.0136e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>4<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.7384e-04,  1.8120e-04,  1.7262e-04,  ...,  6.2943e-04,\n",
       "           7.3624e-04,  8.4877e-05],\n",
       "         [ 1.4496e-04, -4.2152e-04,  4.6539e-04,  ..., -8.8692e-05,\n",
       "           4.3869e-04,  3.3569e-04],\n",
       "         [-2.6321e-04,  2.2888e-04, -3.7575e-04,  ...,  2.4033e-04,\n",
       "           1.3161e-04,  4.2915e-04],\n",
       "         ...,\n",
       "         [ 2.9182e-04, -1.2875e-04, -5.2643e-04,  ...,  4.0245e-04,\n",
       "          -4.3297e-04, -1.5450e-04],\n",
       "         [-4.7112e-04, -3.7384e-04, -2.0313e-04,  ..., -4.1389e-04,\n",
       "          -2.3556e-04, -4.5586e-04],\n",
       "         [-1.3351e-04, -3.3379e-04,  2.4319e-04,  ..., -1.8692e-04,\n",
       "          -2.4986e-04, -5.0735e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>4<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.2970e-04,  4.1771e-04, -2.7847e-04,  ...,  3.9291e-04,\n",
       "           7.6294e-05,  3.0327e-04],\n",
       "         [ 2.3544e-06,  2.5940e-04, -3.4904e-04,  ...,  3.7766e-04,\n",
       "           4.1199e-04,  2.6703e-04],\n",
       "         [-2.8992e-04,  3.0136e-04, -2.8801e-04,  ...,  2.2697e-04,\n",
       "           3.8528e-04,  2.9755e-04],\n",
       "         ...,\n",
       "         [ 2.0599e-04,  1.5831e-04,  5.7983e-04,  ...,  5.1498e-04,\n",
       "          -1.6308e-04,  4.8637e-04],\n",
       "         [ 3.4523e-04,  2.6321e-04, -3.0708e-04,  ...,  4.7302e-04,\n",
       "          -5.2261e-04,  2.8992e-04],\n",
       "         [-3.2806e-04, -2.4605e-04,  2.5940e-04,  ...,  1.9932e-04,\n",
       "          -3.0708e-04,  1.8311e-04]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>4<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.2997e-04, -2.8419e-04,  3.1853e-04,  ...,  6.4850e-04,\n",
       "           2.4605e-04,  2.6894e-04],\n",
       "         [ 3.2425e-04, -2.9373e-04,  2.8992e-04,  ...,  4.1008e-04,\n",
       "           4.5967e-04, -2.8610e-04],\n",
       "         [-2.6512e-04,  2.9182e-04, -3.1281e-04,  ..., -2.3842e-04,\n",
       "          -4.2343e-04, -3.3569e-04],\n",
       "         ...,\n",
       "         [ 2.3174e-04, -2.7847e-04,  2.9373e-04,  ...,  3.9482e-04,\n",
       "          -3.3760e-04,  3.3951e-04],\n",
       "         [-9.3460e-05,  2.4796e-04, -3.3569e-04,  ..., -1.7262e-04,\n",
       "           2.7847e-04, -5.6076e-04],\n",
       "         [ 3.7193e-04,  3.6430e-04, -4.2915e-04,  ..., -4.2534e-04,\n",
       "           4.7112e-04, -9.2983e-05]], device='cuda:1', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>5<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.5177e-04, -1.1349e-04,  5.2261e-04,  ..., -8.1253e-04,\n",
       "          -4.5013e-04, -2.0409e-04],\n",
       "         [ 9.6798e-05,  4.6921e-04, -1.1492e-04,  ...,  2.3937e-04,\n",
       "           9.3460e-05,  4.7302e-04],\n",
       "         [-5.0354e-04, -2.2984e-04, -4.7684e-04,  ..., -3.0327e-04,\n",
       "          -4.2725e-04, -4.5204e-04],\n",
       "         ...,\n",
       "         [ 1.2207e-04, -2.9373e-04,  5.9509e-04,  ..., -2.7847e-04,\n",
       "          -3.0327e-04, -2.7084e-04],\n",
       "         [ 3.9482e-04, -2.2507e-04,  4.7493e-04,  ...,  1.1539e-04,\n",
       "          -1.9741e-04, -4.5013e-04],\n",
       "         [ 1.3542e-04, -7.0572e-05, -4.7302e-04,  ...,  4.6492e-05,\n",
       "          -2.9755e-04, -1.8311e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>5<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 5.7602e-04, -1.0610e-05,  2.4986e-04,  ..., -5.3787e-04,\n",
       "          -6.5231e-04, -2.6321e-04],\n",
       "         [ 8.2970e-05, -4.1389e-04,  7.4387e-05,  ..., -9.2983e-05,\n",
       "          -4.1389e-04, -4.0245e-04],\n",
       "         [-1.4114e-04, -5.0354e-04, -8.0109e-04,  ..., -6.9427e-04,\n",
       "          -4.1246e-05, -3.9673e-04],\n",
       "         ...,\n",
       "         [ 2.2507e-04,  3.2043e-04, -3.3569e-04,  ...,  1.1969e-04,\n",
       "           1.7357e-04,  3.6240e-04],\n",
       "         [ 5.3024e-04, -2.0790e-04,  3.7384e-04,  ..., -1.2398e-04,\n",
       "          -1.2398e-04, -4.8637e-04],\n",
       "         [-6.7902e-04, -6.4850e-04,  1.8406e-04,  ..., -2.9182e-04,\n",
       "          -1.1015e-04, -3.4714e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>5<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 0.0003, -0.0003,  0.0003,  ..., -0.0003,  0.0003,  0.0003],\n",
       "         [ 0.0004, -0.0004,  0.0005,  ..., -0.0003,  0.0004,  0.0003],\n",
       "         [-0.0002,  0.0003, -0.0001,  ...,  0.0002, -0.0002, -0.0003],\n",
       "         ...,\n",
       "         [ 0.0004, -0.0003,  0.0003,  ..., -0.0003,  0.0004,  0.0003],\n",
       "         [-0.0003,  0.0004,  0.0003,  ...,  0.0004, -0.0002, -0.0003],\n",
       "         [-0.0005,  0.0002, -0.0003,  ...,  0.0004, -0.0004, -0.0003]],\n",
       "        device='cuda:2', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'model<>layers<>6<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.0376e-03, -6.4373e-05,  4.8065e-04,  ...,  2.7084e-04,\n",
       "           3.2997e-04,  1.4591e-04],\n",
       "         [-4.1580e-04,  2.7657e-04, -4.9591e-04,  ..., -4.5538e-05,\n",
       "           3.2425e-04,  2.6512e-04],\n",
       "         [-3.7384e-04,  2.9564e-04, -2.4033e-04,  ..., -2.8038e-04,\n",
       "           3.1281e-04,  1.6212e-04],\n",
       "         ...,\n",
       "         [-4.6539e-04,  4.5013e-04,  4.0531e-05,  ..., -2.5177e-04,\n",
       "           3.7384e-04,  6.1798e-04],\n",
       "         [ 2.0790e-04, -2.4796e-04,  4.9591e-04,  ...,  2.1076e-04,\n",
       "          -2.6321e-04, -6.5327e-05],\n",
       "         [-1.5259e-04, -2.8229e-04, -4.3106e-04,  ...,  9.1934e-04,\n",
       "           3.5477e-04, -3.4571e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>6<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.5558e-04,  2.2221e-04,  9.6798e-05,  ...,  4.8399e-05,\n",
       "          -8.7619e-06,  5.7983e-04],\n",
       "         [ 1.3828e-04, -3.0708e-04,  2.6894e-04,  ...,  3.9291e-04,\n",
       "          -2.4414e-04, -2.7847e-04],\n",
       "         [ 3.2043e-04, -3.4523e-04,  2.2125e-04,  ...,  5.1880e-04,\n",
       "          -3.0136e-04, -2.7084e-04],\n",
       "         ...,\n",
       "         [-1.3161e-04,  2.8801e-04, -3.5858e-04,  ..., -3.9291e-04,\n",
       "           1.9169e-04,  8.6784e-05],\n",
       "         [ 1.5259e-04, -3.3379e-04,  2.8419e-04,  ...,  1.3065e-04,\n",
       "          -2.3651e-04, -4.0627e-04],\n",
       "         [-4.7493e-04,  2.8992e-04, -4.8065e-04,  ..., -4.2534e-04,\n",
       "           3.7766e-04,  2.3174e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>6<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 8.8215e-05, -2.7275e-04, -2.7275e-04,  ...,  2.8610e-04,\n",
       "           3.1090e-04,  2.2125e-04],\n",
       "         [-3.0708e-04,  8.3923e-05, -2.7275e-04,  ...,  2.1553e-04,\n",
       "           1.4496e-04,  4.4823e-04],\n",
       "         [-7.3242e-04,  4.3106e-04,  3.3569e-04,  ..., -3.4714e-04,\n",
       "          -3.3188e-04, -2.8849e-05],\n",
       "         ...,\n",
       "         [-2.4128e-04,  7.1526e-05, -2.8610e-04,  ...,  1.6212e-04,\n",
       "           1.2207e-04,  4.0817e-04],\n",
       "         [-2.8419e-04,  4.1008e-04,  3.1853e-04,  ..., -2.4605e-04,\n",
       "          -3.2806e-04, -3.2187e-05],\n",
       "         [ 4.5300e-05, -5.9128e-05,  1.9932e-04,  ..., -2.1553e-04,\n",
       "          -1.0014e-04, -4.6730e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>7<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.1962e-04,  2.7657e-04, -1.5831e-04,  ..., -4.2915e-04,\n",
       "           2.7847e-04,  4.1389e-04],\n",
       "         [ 2.2697e-04, -2.7847e-04,  2.2411e-04,  ...,  3.0899e-04,\n",
       "          -6.8665e-04, -2.3365e-04],\n",
       "         [-5.5313e-04,  3.9864e-04, -2.3651e-04,  ...,  5.4932e-04,\n",
       "          -4.5395e-04,  1.8787e-04],\n",
       "         ...,\n",
       "         [ 1.1444e-04, -2.2411e-04,  9.0599e-05,  ...,  2.0409e-04,\n",
       "           1.6594e-04, -3.4714e-04],\n",
       "         [-3.0518e-04,  2.4986e-04, -3.6621e-04,  ..., -1.2779e-04,\n",
       "          -7.2479e-04,  2.9755e-04],\n",
       "         [-4.4441e-04,  2.8229e-04, -2.9373e-04,  ..., -2.9182e-04,\n",
       "           3.5286e-04,  3.5667e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>7<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-5.3024e-04,  1.4877e-04,  4.4584e-05,  ..., -3.1662e-04,\n",
       "           1.5640e-04,  4.1199e-04],\n",
       "         [-1.3542e-04,  3.1853e-04,  7.8678e-05,  ..., -4.9591e-04,\n",
       "           3.2043e-04,  2.9373e-04],\n",
       "         [-7.4863e-05, -7.5817e-05, -4.8828e-04,  ..., -8.6784e-05,\n",
       "          -5.6839e-04,  2.7466e-04],\n",
       "         ...,\n",
       "         [-7.7057e-04,  2.6703e-04, -4.7874e-04,  ...,  3.4332e-05,\n",
       "          -7.7438e-04,  3.4904e-04],\n",
       "         [-2.7084e-04,  3.0708e-04, -2.6703e-04,  ..., -3.0708e-04,\n",
       "          -1.6880e-04,  4.3297e-04],\n",
       "         [ 5.4550e-04, -2.7847e-04,  1.3161e-04,  ...,  4.8828e-04,\n",
       "           1.1444e-05, -3.8147e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>7<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.2125e-04, -2.8229e-04,  2.0123e-04,  ..., -3.5477e-04,\n",
       "           2.9945e-04, -3.1471e-04],\n",
       "         [ 2.8229e-04, -2.1935e-04,  3.5667e-04,  ..., -3.9864e-04,\n",
       "           4.4250e-04, -4.6158e-04],\n",
       "         [-9.1171e-04,  1.9073e-04, -3.3379e-04,  ...,  3.6716e-05,\n",
       "           6.6757e-05,  9.4414e-05],\n",
       "         ...,\n",
       "         [-2.3270e-04,  3.8528e-04, -1.8835e-05,  ..., -3.3855e-05,\n",
       "           1.0490e-05,  1.2279e-05],\n",
       "         [-1.9360e-04, -2.2411e-04, -2.2602e-04,  ..., -9.8228e-05,\n",
       "           2.2697e-04, -2.1100e-05],\n",
       "         [-2.5511e-05,  1.9836e-04, -3.4523e-04,  ...,  4.2725e-04,\n",
       "          -4.6158e-04,  4.0627e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>8<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 1.8883e-04,  2.9945e-04, -4.3869e-04,  ..., -3.0708e-04,\n",
       "           3.0160e-05,  1.7834e-04],\n",
       "         [-1.5259e-04, -4.2725e-04, -3.4904e-04,  ..., -2.7466e-04,\n",
       "           3.9339e-05,  2.6131e-04],\n",
       "         [ 1.5163e-04, -3.0327e-04,  2.4605e-04,  ...,  2.6894e-04,\n",
       "           5.5790e-05, -2.2125e-04],\n",
       "         ...,\n",
       "         [ 4.2534e-04, -2.8610e-04,  3.4714e-04,  ...,  2.9182e-04,\n",
       "          -4.2915e-04, -2.8801e-04],\n",
       "         [ 1.3161e-04, -2.9373e-04,  2.8610e-04,  ...,  2.6703e-04,\n",
       "          -2.0409e-04, -2.8610e-04],\n",
       "         [ 3.3188e-04,  2.8610e-04, -3.4142e-04,  ..., -2.7657e-04,\n",
       "           3.0518e-04,  9.2983e-05]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>8<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-2.7275e-04,  3.1471e-04, -1.3733e-04,  ..., -2.6512e-04,\n",
       "           7.7724e-05,  3.5095e-04],\n",
       "         [-2.7120e-06,  2.4223e-04,  5.5432e-06,  ...,  1.4782e-04,\n",
       "           5.2691e-05, -1.9169e-04],\n",
       "         [-9.3460e-05,  3.9482e-04,  1.8477e-05,  ..., -2.8419e-04,\n",
       "          -6.3419e-05,  2.7657e-04],\n",
       "         ...,\n",
       "         [-2.8419e-04,  3.0708e-04, -3.1281e-04,  ..., -2.1076e-04,\n",
       "           4.9973e-04,  3.1471e-04],\n",
       "         [ 1.1492e-04, -3.0327e-04,  2.6512e-04,  ...,  2.6703e-04,\n",
       "           5.9128e-05, -2.8801e-04],\n",
       "         [-4.0245e-04,  2.9945e-04, -2.2984e-04,  ..., -5.4169e-04,\n",
       "           1.3351e-04,  3.0136e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>8<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 0.0003,  0.0003, -0.0003,  ..., -0.0003,  0.0003,  0.0003],\n",
       "         [ 0.0003,  0.0003, -0.0004,  ..., -0.0003,  0.0004,  0.0003],\n",
       "         [-0.0003, -0.0003,  0.0002,  ...,  0.0003, -0.0002, -0.0003],\n",
       "         ...,\n",
       "         [-0.0003, -0.0003,  0.0001,  ...,  0.0004, -0.0002, -0.0003],\n",
       "         [-0.0003, -0.0003,  0.0002,  ...,  0.0003, -0.0002, -0.0003],\n",
       "         [-0.0003, -0.0003,  0.0004,  ...,  0.0004, -0.0004, -0.0003]],\n",
       "        device='cuda:2', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'model<>layers<>9<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-3.4523e-04,  3.1853e-04, -3.0899e-04,  ..., -1.6689e-04,\n",
       "          -1.8024e-04,  1.2589e-04],\n",
       "         [-3.4714e-04,  3.0136e-04, -2.8610e-04,  ..., -3.6240e-04,\n",
       "          -3.6621e-04,  2.8419e-04],\n",
       "         [ 1.6499e-04, -3.2043e-04,  2.4223e-04,  ...,  4.5586e-04,\n",
       "           5.2261e-04, -4.4441e-04],\n",
       "         ...,\n",
       "         [ 2.4033e-04, -3.3760e-04,  2.5558e-04,  ...,  3.3379e-04,\n",
       "           4.8828e-04, -5.0354e-04],\n",
       "         [-4.2152e-04,  3.1853e-04, -2.5749e-04,  ..., -1.3733e-04,\n",
       "           3.0899e-04,  3.9673e-04],\n",
       "         [ 1.7262e-04, -3.1853e-04,  2.4414e-04,  ...,  9.2506e-05,\n",
       "           4.0054e-04, -3.1281e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>9<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.3379e-04,  2.9373e-04, -3.0327e-04,  ..., -3.9673e-04,\n",
       "          -1.8597e-04,  3.3188e-04],\n",
       "         [ 4.1199e-04, -2.0027e-04,  4.8828e-04,  ...,  3.5095e-04,\n",
       "          -7.2479e-05, -3.2043e-04],\n",
       "         [-1.6117e-04,  6.1417e-04,  1.8597e-05,  ...,  4.7302e-04,\n",
       "           5.2261e-04,  5.1117e-04],\n",
       "         ...,\n",
       "         [-3.2663e-05,  5.6028e-05, -4.3297e-04,  ..., -1.4877e-04,\n",
       "          -2.0885e-04,  5.0735e-04],\n",
       "         [-2.9755e-04,  2.0790e-04, -2.9182e-04,  ...,  7.5531e-04,\n",
       "           4.3297e-04,  6.4468e-04],\n",
       "         [-6.8665e-05, -1.5545e-04,  8.8215e-05,  ...,  5.7983e-04,\n",
       "           4.9973e-04, -5.2643e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>9<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.8610e-04, -2.9755e-04,  3.4523e-04,  ..., -1.6499e-04,\n",
       "           3.6049e-04,  6.9427e-04],\n",
       "         [ 3.0327e-04, -1.8787e-04, -5.6839e-04,  ..., -2.8038e-04,\n",
       "           3.2806e-04,  1.9360e-04],\n",
       "         [-2.5749e-04,  3.4332e-04, -1.1778e-04,  ...,  3.3188e-04,\n",
       "          -4.2725e-04,  6.0081e-05],\n",
       "         ...,\n",
       "         [-2.0027e-04,  5.2261e-04,  2.8992e-04,  ...,  5.5313e-04,\n",
       "           4.5776e-04,  8.4400e-05],\n",
       "         [-2.7084e-04,  3.6621e-04, -4.8828e-04,  ...,  2.6107e-05,\n",
       "          -4.1771e-04,  3.2616e-04],\n",
       "         [-3.0327e-04,  2.4605e-04,  2.9325e-05,  ..., -2.4414e-04,\n",
       "          -7.5340e-05, -4.2915e-04]], device='cuda:2', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>10<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.8038e-04, -2.7275e-04,  3.0708e-04,  ...,  1.0014e-04,\n",
       "           2.5177e-04, -2.1935e-04],\n",
       "         [ 3.6240e-04, -4.2677e-05,  4.2343e-04,  ..., -4.1246e-05,\n",
       "           2.4587e-06, -5.4169e-04],\n",
       "         [-1.0633e-04,  3.3951e-04, -1.8024e-04,  ..., -4.2343e-04,\n",
       "          -3.4523e-04,  2.9373e-04],\n",
       "         ...,\n",
       "         [ 9.2030e-05, -4.2915e-04, -2.2173e-05,  ...,  3.0327e-04,\n",
       "           3.9482e-04, -1.2517e-05],\n",
       "         [ 4.0436e-04, -2.8610e-04,  3.1471e-04,  ...,  3.4714e-04,\n",
       "           3.5477e-04, -2.6321e-04],\n",
       "         [ 1.4591e-04,  3.0327e-04, -1.4591e-04,  ..., -2.7847e-04,\n",
       "          -4.5967e-04,  1.5926e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>10<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 3.6240e-04, -1.6499e-04,  4.0054e-04,  ...,  6.1512e-05,\n",
       "           6.5804e-05, -4.8637e-04],\n",
       "         [-4.0817e-04,  2.5940e-04, -2.9564e-04,  ..., -3.1090e-04,\n",
       "          -1.6022e-04,  2.1553e-04],\n",
       "         [ 2.9206e-05, -3.2234e-04,  2.5368e-04,  ...,  7.5150e-04,\n",
       "           5.0354e-04, -3.9864e-04],\n",
       "         ...,\n",
       "         [-8.7738e-04,  2.8229e-04,  5.1498e-04,  ..., -3.8910e-04,\n",
       "          -2.3842e-04,  1.4019e-04],\n",
       "         [ 4.1580e-04, -1.6880e-04,  3.9673e-04,  ...,  1.9073e-05,\n",
       "           8.3923e-05, -5.0354e-04],\n",
       "         [ 1.2517e-06,  4.3488e-04, -4.3392e-05,  ..., -1.0300e-04,\n",
       "          -4.1008e-04,  4.2439e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>10<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 0.0004, -0.0003, -0.0003,  ..., -0.0003,  0.0003,  0.0004],\n",
       "         [ 0.0005, -0.0003, -0.0004,  ..., -0.0002,  0.0003,  0.0004],\n",
       "         [-0.0002,  0.0003,  0.0002,  ...,  0.0003, -0.0003,  0.0001],\n",
       "         ...,\n",
       "         [-0.0003,  0.0003,  0.0003,  ...,  0.0004, -0.0003,  0.0001],\n",
       "         [-0.0003,  0.0003,  0.0003,  ...,  0.0003, -0.0003,  0.0001],\n",
       "         [-0.0002,  0.0003,  0.0003,  ...,  0.0003, -0.0003, -0.0004]],\n",
       "        device='cuda:3', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'model<>layers<>11<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.3188e-04, -3.6812e-04, -6.2943e-05,  ...,  3.8910e-04,\n",
       "           4.7684e-04, -1.2398e-04],\n",
       "         [-5.8365e-04, -1.4210e-04, -1.0109e-04,  ...,  3.9864e-04,\n",
       "           3.7766e-04, -5.6028e-05],\n",
       "         [ 6.6376e-04, -4.5013e-04,  2.8801e-04,  ...,  7.6675e-04,\n",
       "           7.5150e-04, -6.1035e-04],\n",
       "         ...,\n",
       "         [ 3.4904e-04, -3.0708e-04,  2.8419e-04,  ...,  5.7602e-04,\n",
       "           2.2793e-04, -2.7657e-04],\n",
       "         [ 9.4891e-05, -7.7438e-04,  2.0313e-04,  ..., -1.1873e-04,\n",
       "          -9.7752e-05, -1.2589e-04],\n",
       "         [-9.3460e-05, -3.5858e-04,  3.0041e-05,  ..., -4.2725e-04,\n",
       "           3.7193e-04,  1.3542e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>11<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.2398e-05, -3.6240e-04,  1.7357e-04,  ...,  6.5231e-04,\n",
       "           4.0245e-04,  4.3631e-05],\n",
       "         [ 5.9509e-04, -2.8419e-04,  3.4714e-04,  ...,  3.0899e-04,\n",
       "           1.1587e-04, -1.2589e-04],\n",
       "         [-4.7874e-04,  2.5940e-04, -3.3188e-04,  ..., -1.2779e-04,\n",
       "          -1.5259e-04,  4.6730e-04],\n",
       "         ...,\n",
       "         [ 8.8882e-04,  4.0054e-04,  4.9829e-05,  ..., -4.0293e-05,\n",
       "           3.2997e-04, -3.4809e-05],\n",
       "         [ 3.7670e-05,  7.9155e-05, -2.9373e-04,  ..., -3.3951e-04,\n",
       "          -5.6839e-04,  1.8978e-04],\n",
       "         [-2.8610e-04, -1.5259e-04, -4.3678e-04,  ...,  1.1539e-04,\n",
       "           2.8992e-04,  3.5286e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>11<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.1969e-04, -2.7084e-04, -2.8610e-04,  ...,  3.7909e-05,\n",
       "          -1.6117e-04,  1.0347e-04],\n",
       "         [ 7.8583e-04, -1.7929e-04, -3.5858e-04,  ...,  1.0223e-03,\n",
       "          -2.8759e-06,  2.7657e-04],\n",
       "         [ 2.3365e-04,  4.1962e-04, -7.8201e-05,  ...,  8.0872e-04,\n",
       "           3.2997e-04,  1.2159e-04],\n",
       "         ...,\n",
       "         [-1.2360e-03,  3.2043e-04,  3.2234e-04,  ..., -3.2234e-04,\n",
       "           2.4796e-04,  4.4441e-04],\n",
       "         [-1.6022e-04,  3.5667e-04,  2.3460e-04,  ...,  5.8174e-05,\n",
       "           4.3106e-04,  1.8978e-04],\n",
       "         [-3.3379e-04,  2.3174e-04,  3.3760e-04,  ...,  3.5286e-04,\n",
       "          -2.0790e-04, -4.5776e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>12<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.4986e-04, -2.9564e-04,  2.8419e-04,  ...,  3.9673e-04,\n",
       "           3.0708e-04, -2.6131e-04],\n",
       "         [ 2.8229e-04, -2.8801e-04,  2.8992e-04,  ...,  1.9836e-04,\n",
       "           3.1853e-04, -2.3174e-04],\n",
       "         [-4.5013e-04,  2.3556e-04, -3.4142e-04,  ..., -2.5511e-05,\n",
       "          -2.7847e-04,  3.7956e-04],\n",
       "         ...,\n",
       "         [-3.1853e-04,  2.8610e-04, -2.9945e-04,  ..., -2.1839e-04,\n",
       "          -2.9373e-04,  3.5858e-04],\n",
       "         [-3.0136e-04,  3.4332e-04,  2.9182e-04,  ..., -4.0245e-04,\n",
       "          -2.3651e-04,  1.8311e-04],\n",
       "         [-2.9945e-04,  2.9755e-04, -2.8992e-04,  ..., -3.6621e-04,\n",
       "          -3.1281e-04,  3.0518e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>12<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-4.4250e-04,  2.2125e-04, -3.4142e-04,  ...,  6.9618e-05,\n",
       "          -2.3556e-04,  3.1471e-04],\n",
       "         [ 2.9755e-04, -2.9755e-04,  3.1090e-04,  ..., -3.9577e-05,\n",
       "           2.3937e-04, -4.1771e-04],\n",
       "         [ 2.3365e-04, -2.7466e-04,  2.8992e-04,  ...,  1.1110e-04,\n",
       "           3.9673e-04, -4.6921e-04],\n",
       "         ...,\n",
       "         [-3.7384e-04,  2.8038e-04, -3.0327e-04,  ..., -2.1458e-04,\n",
       "          -2.6894e-04,  3.2043e-04],\n",
       "         [-1.9073e-04,  3.2997e-04, -2.3556e-04,  ..., -4.9591e-04,\n",
       "          -3.7003e-04, -7.7248e-05],\n",
       "         [-3.7193e-04,  2.3556e-04, -3.1853e-04,  ...,  2.6512e-04,\n",
       "          -9.8228e-05,  4.2152e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>12<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.2016e-04,  4.2152e-04, -1.1015e-04,  ...,  2.9564e-04,\n",
       "          -1.6880e-04,  2.8038e-04],\n",
       "         [-1.0014e-04,  9.8419e-04, -3.7766e-04,  ...,  2.9755e-04,\n",
       "          -4.5204e-04,  2.0313e-04],\n",
       "         [ 2.6822e-05,  2.8419e-04, -7.2002e-05,  ...,  3.2806e-04,\n",
       "          -2.0123e-04, -3.9816e-05],\n",
       "         ...,\n",
       "         [ 4.9591e-04, -1.5163e-04,  4.4823e-04,  ..., -2.9564e-04,\n",
       "           2.0504e-04, -3.1090e-04],\n",
       "         [ 4.3488e-04, -5.1260e-05,  4.8065e-04,  ..., -2.6131e-04,\n",
       "          -1.3053e-05, -4.5776e-04],\n",
       "         [-2.2173e-05, -2.6894e-04,  2.0027e-04,  ..., -3.0327e-04,\n",
       "           3.7575e-04, -2.4605e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>13<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 3.4523e-04, -3.8624e-05,  3.4332e-04,  ..., -6.2180e-04,\n",
       "          -6.7711e-05, -8.6975e-04],\n",
       "         [ 2.7084e-04, -3.1281e-04,  2.9373e-04,  ..., -4.2677e-05,\n",
       "          -2.1553e-04, -3.4714e-04],\n",
       "         [ 3.3951e-04, -3.5095e-04,  2.7084e-04,  ..., -3.8910e-04,\n",
       "          -4.6539e-04, -3.3379e-04],\n",
       "         ...,\n",
       "         [ 7.7486e-06,  5.4359e-05,  3.3569e-04,  ..., -4.4441e-04,\n",
       "          -3.7003e-04, -3.2997e-04],\n",
       "         [ 2.9755e-04, -2.6321e-04,  2.5940e-04,  ...,  2.2316e-04,\n",
       "          -1.6499e-04, -4.4250e-04],\n",
       "         [ 7.5150e-04,  1.0204e-04, -3.1853e-04,  ...,  7.0953e-04,\n",
       "           9.2983e-05,  9.8419e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>13<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 8.5831e-05,  9.7656e-04,  8.7261e-05,  ..., -1.3733e-04,\n",
       "          -7.2122e-06, -1.1826e-04],\n",
       "         [-3.9101e-05, -3.9864e-04,  2.4033e-04,  ...,  2.0885e-04,\n",
       "          -4.1723e-06,  1.7357e-04],\n",
       "         [-2.0695e-04,  5.1498e-04, -2.1267e-04,  ..., -7.8583e-04,\n",
       "           4.5013e-04,  1.4400e-04],\n",
       "         ...,\n",
       "         [ 1.9932e-04, -4.3488e-04,  1.1063e-04,  ...,  1.7357e-04,\n",
       "           9.7275e-05,  8.2493e-05],\n",
       "         [ 2.4128e-04, -3.3951e-04,  2.8610e-04,  ..., -1.8692e-04,\n",
       "          -1.9360e-04, -3.2425e-04],\n",
       "         [ 2.8419e-04, -3.1281e-04,  2.9373e-04,  ..., -2.4605e-04,\n",
       "          -3.9673e-04, -3.7766e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>13<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 1.0824e-04,  5.4932e-04,  3.2234e-04,  ...,  4.9829e-05,\n",
       "           2.9182e-04, -4.6253e-05],\n",
       "         [ 2.9945e-04,  3.4523e-04,  2.9945e-04,  ..., -4.4441e-04,\n",
       "           4.3106e-04, -3.2997e-04],\n",
       "         [ 2.8419e-04,  4.3678e-04,  3.1281e-04,  ..., -1.0633e-04,\n",
       "           1.1921e-04,  4.7302e-04],\n",
       "         ...,\n",
       "         [ 3.7575e-04, -2.3556e-04, -2.6131e-04,  ...,  1.1873e-04,\n",
       "          -4.6921e-04, -8.5831e-05],\n",
       "         [ 2.6703e-04,  2.0862e-05, -1.0586e-04,  ..., -2.4414e-04,\n",
       "          -3.0708e-04,  4.8828e-04],\n",
       "         [-2.6321e-04, -3.0518e-04, -2.4986e-04,  ...,  2.2411e-04,\n",
       "          -3.6430e-04, -2.1100e-05]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>14<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-0.0004, -0.0005, -0.0003,  ...,  0.0004,  0.0004, -0.0002],\n",
       "         [-0.0004,  0.0002, -0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
       "         [-0.0003,  0.0003, -0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
       "         ...,\n",
       "         [ 0.0002, -0.0003,  0.0003,  ..., -0.0003, -0.0002, -0.0004],\n",
       "         [-0.0002,  0.0004, -0.0003,  ...,  0.0002,  0.0002,  0.0004],\n",
       "         [-0.0003,  0.0004, -0.0003,  ...,  0.0003,  0.0003,  0.0003]],\n",
       "        device='cuda:3', dtype=torch.bfloat16, requires_grad=True),\n",
       " 'model<>layers<>14<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 7.8583e-04, -3.0899e-04,  4.2343e-04,  ..., -2.1458e-04,\n",
       "          -3.0361e-07,  1.4877e-04],\n",
       "         [-2.9182e-04,  3.2997e-04, -2.8419e-04,  ...,  1.5831e-04,\n",
       "           2.6512e-04,  3.3951e-04],\n",
       "         [ 3.2616e-04, -8.9169e-05,  3.3188e-04,  ..., -4.5586e-04,\n",
       "          -3.7384e-04, -3.6812e-04],\n",
       "         ...,\n",
       "         [ 2.0695e-04, -3.8910e-04,  2.6321e-04,  ..., -2.2030e-04,\n",
       "          -2.0981e-04, -2.8419e-04],\n",
       "         [-7.3242e-04,  1.8406e-04, -3.5667e-04,  ...,  6.8283e-04,\n",
       "           2.1362e-04,  6.6376e-04],\n",
       "         [ 3.0136e-04, -1.5163e-04,  3.0327e-04,  ..., -3.2616e-04,\n",
       "          -4.0054e-04, -3.7956e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>14<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.0518e-04,  2.5558e-04, -2.7466e-04,  ...,  3.0136e-04,\n",
       "           3.4332e-04, -2.8229e-04],\n",
       "         [ 9.7275e-05,  9.3937e-05, -1.4496e-04,  ...,  3.2234e-04,\n",
       "           2.4414e-04,  6.6280e-05],\n",
       "         [-6.1035e-05,  3.2616e-04,  1.3638e-04,  ...,  3.2806e-04,\n",
       "          -1.8215e-04,  1.1492e-04],\n",
       "         ...,\n",
       "         [ 3.9673e-04, -3.0136e-04,  4.0245e-04,  ..., -2.8801e-04,\n",
       "          -4.0817e-04,  3.6621e-04],\n",
       "         [-4.9591e-05, -1.5640e-04,  1.7166e-04,  ...,  1.4782e-04,\n",
       "          -4.3106e-04,  5.3024e-04],\n",
       "         [ 1.4305e-04, -1.0204e-04,  1.0824e-04,  ..., -4.2343e-04,\n",
       "           1.6403e-04,  4.1389e-04]], device='cuda:3', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>15<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.8992e-04, -2.9755e-04,  2.9182e-04,  ..., -2.8992e-04,\n",
       "          -2.8992e-04, -2.9182e-04],\n",
       "         [ 2.7466e-04,  4.1008e-05,  2.8419e-04,  ..., -4.0817e-04,\n",
       "          -4.2677e-05, -4.0245e-04],\n",
       "         [-2.0504e-04, -6.2180e-04,  7.7724e-05,  ..., -2.8992e-04,\n",
       "           1.6689e-04, -7.3624e-04],\n",
       "         ...,\n",
       "         [ 3.3855e-05,  1.0014e-04,  9.3937e-05,  ..., -1.9455e-04,\n",
       "          -6.8188e-05,  7.4387e-04],\n",
       "         [ 1.9741e-04,  1.3351e-04,  3.2425e-04,  ..., -2.6894e-04,\n",
       "          -3.1853e-04, -2.5177e-04],\n",
       "         [ 2.7657e-04, -4.0245e-04,  2.8610e-04,  ..., -2.8992e-04,\n",
       "          -2.0313e-04, -2.8801e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>15<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-8.4639e-06, -5.7602e-04,  2.8610e-04,  ..., -5.9128e-04,\n",
       "          -2.4676e-05,  6.8665e-05],\n",
       "         [-2.8038e-04,  4.4823e-04, -2.8610e-04,  ...,  2.9182e-04,\n",
       "           3.2425e-04,  3.0708e-04],\n",
       "         [-2.7847e-04,  9.2506e-05, -4.0436e-04,  ...,  4.7684e-04,\n",
       "           3.9864e-04, -2.9182e-04],\n",
       "         ...,\n",
       "         [-1.3161e-04, -3.4523e-04, -4.1962e-05,  ..., -6.9618e-05,\n",
       "           1.5163e-04, -1.8883e-04],\n",
       "         [-3.1090e-04,  4.0054e-04, -2.7466e-04,  ...,  2.9182e-04,\n",
       "           3.4523e-04,  4.0627e-04],\n",
       "         [-3.0518e-04,  1.0157e-04, -3.3188e-04,  ...,  2.6894e-04,\n",
       "           3.8528e-04,  3.7384e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>15<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.0027e-04, -2.9564e-04,  3.6812e-04,  ..., -2.5368e-04,\n",
       "          -1.7071e-04, -2.9373e-04],\n",
       "         [ 1.9073e-04,  3.4142e-04,  1.4305e-04,  ..., -4.6539e-04,\n",
       "          -4.7922e-05, -3.3188e-04],\n",
       "         [ 2.9373e-04, -3.2425e-04, -6.7234e-05,  ..., -3.4332e-04,\n",
       "          -4.6349e-04,  1.4961e-05],\n",
       "         ...,\n",
       "         [ 9.3937e-05, -5.2643e-04, -1.3638e-04,  ..., -1.6022e-04,\n",
       "           3.4142e-04,  2.6894e-04],\n",
       "         [ 8.4877e-05,  2.0599e-04,  6.0272e-04,  ..., -1.8406e-04,\n",
       "           3.8910e-04,  3.8528e-04],\n",
       "         [-5.5695e-04,  3.1281e-04, -2.3007e-05,  ...,  5.4550e-04,\n",
       "           1.4210e-04,  2.5940e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>16<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.4223e-04,  6.1417e-04,  1.2875e-05,  ...,  4.1580e-04,\n",
       "          -1.8787e-04,  3.1281e-04],\n",
       "         [-4.2152e-04, -8.0872e-04, -3.3951e-04,  ...,  2.2411e-04,\n",
       "           3.2806e-04, -2.1744e-04],\n",
       "         [ 2.7275e-04,  3.1853e-04,  2.9564e-04,  ..., -3.1090e-04,\n",
       "          -3.8910e-04, -3.4142e-04],\n",
       "         ...,\n",
       "         [ 5.2643e-04,  4.0627e-04,  3.1471e-04,  ..., -2.7657e-04,\n",
       "          -3.2806e-04, -4.8828e-04],\n",
       "         [-4.8256e-04, -5.4169e-04, -4.9210e-04,  ...,  6.8665e-04,\n",
       "           4.9973e-04, -5.8413e-05],\n",
       "         [ 3.5477e-04,  3.6621e-04,  3.8338e-04,  ...,  1.4400e-04,\n",
       "          -3.7193e-04, -3.4571e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>16<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.1338e-05, -3.6240e-04,  2.1362e-04,  ...,  8.1062e-05,\n",
       "           2.1160e-06, -8.9645e-05],\n",
       "         [-6.9618e-05, -2.1076e-04, -1.8978e-04,  ...,  3.8528e-04,\n",
       "           5.4836e-05,  3.3188e-04],\n",
       "         [-3.9864e-04, -3.7766e-04, -3.9101e-04,  ...,  2.6512e-04,\n",
       "           3.7766e-04,  1.2875e-04],\n",
       "         ...,\n",
       "         [ 3.1090e-04,  1.2302e-04,  3.8338e-04,  ..., -6.4468e-04,\n",
       "          -1.9932e-04, -2.3484e-05],\n",
       "         [-2.7418e-05,  2.5392e-05, -7.4387e-05,  ..., -3.2234e-04,\n",
       "          -5.5134e-06,  7.0572e-04],\n",
       "         [-5.9605e-05, -6.1989e-05,  9.0122e-05,  ...,  5.1498e-04,\n",
       "           8.7738e-05,  6.1417e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>16<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-2.8801e-04,  4.7493e-04, -3.0327e-04,  ..., -5.8889e-05,\n",
       "          -3.0708e-04, -2.8038e-04],\n",
       "         [ 4.6492e-05,  2.4915e-05, -3.6430e-04,  ...,  1.0605e-03,\n",
       "          -3.2997e-04, -5.6458e-04],\n",
       "         [ 2.0623e-05, -4.5395e-04,  1.6880e-04,  ...,  2.2316e-04,\n",
       "           1.2875e-04, -1.0586e-04],\n",
       "         ...,\n",
       "         [ 5.0735e-04, -1.5354e-04,  3.2234e-04,  ...,  4.5586e-04,\n",
       "           4.5395e-04,  2.0409e-04],\n",
       "         [-5.6505e-05,  5.6028e-05,  1.1778e-04,  ..., -1.5640e-04,\n",
       "           6.0558e-05, -9.1553e-05],\n",
       "         [ 4.4632e-04, -4.8256e-04,  3.1471e-04,  ...,  5.6076e-04,\n",
       "           3.7766e-04,  3.8719e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>17<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-2.7084e-04,  3.5286e-04,  3.0327e-04,  ...,  7.4005e-04,\n",
       "          -5.2691e-05, -3.8719e-04],\n",
       "         [ 5.3024e-04, -2.1172e-04, -2.1553e-04,  ...,  4.2343e-04,\n",
       "          -9.4891e-05,  1.1349e-04],\n",
       "         [ 2.5940e-04, -2.8419e-04, -2.8610e-04,  ...,  2.8801e-04,\n",
       "          -3.8147e-04,  2.9945e-04],\n",
       "         ...,\n",
       "         [ 2.7084e-04, -2.8992e-04, -2.9373e-04,  ...,  2.8801e-04,\n",
       "          -4.9210e-04,  2.8992e-04],\n",
       "         [-3.1090e-04,  2.3937e-04,  2.9945e-04,  ..., -3.2043e-04,\n",
       "          -6.8283e-04, -2.4414e-04],\n",
       "         [ 4.2725e-04, -2.4414e-04, -2.7084e-04,  ...,  2.6321e-04,\n",
       "          -1.6975e-04,  3.0327e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>17<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 6.0272e-04, -2.9182e-04, -2.7466e-04,  ...,  8.9645e-05,\n",
       "           1.8883e-04,  2.8419e-04],\n",
       "         [ 4.7684e-04,  1.1539e-04, -1.3828e-04,  ...,  3.0708e-04,\n",
       "          -2.1267e-04,  2.9373e-04],\n",
       "         [-1.3947e-05, -4.7493e-04, -4.3678e-04,  ...,  2.8968e-05,\n",
       "           2.7657e-04,  4.4250e-04],\n",
       "         ...,\n",
       "         [-1.0920e-04,  3.6621e-04,  3.1281e-04,  ..., -3.2997e-04,\n",
       "          -8.5354e-05, -2.8419e-04],\n",
       "         [-6.8188e-05,  4.7112e-04,  3.7384e-04,  ..., -2.1935e-04,\n",
       "          -3.0136e-04, -2.9945e-04],\n",
       "         [-4.1771e-04, -1.1921e-04, -9.7752e-05,  ..., -2.8419e-04,\n",
       "           1.0395e-04,  8.7738e-05]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>17<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-3.7193e-04,  2.8801e-04,  2.8419e-04,  ..., -2.9564e-04,\n",
       "           2.8992e-04, -2.8229e-04],\n",
       "         [-5.7983e-04,  3.1471e-04,  3.3569e-04,  ..., -2.1839e-04,\n",
       "           3.0327e-04, -3.1281e-04],\n",
       "         [-6.9046e-04,  4.3488e-04,  2.4033e-04,  ..., -2.9564e-04,\n",
       "           3.2234e-04, -3.7384e-04],\n",
       "         ...,\n",
       "         [ 4.4632e-04, -3.1281e-04, -2.7275e-04,  ...,  2.6703e-04,\n",
       "          -2.4223e-04,  3.7003e-04],\n",
       "         [-4.1962e-04, -8.6784e-05,  4.2152e-04,  ..., -4.5013e-04,\n",
       "           2.8610e-04,  1.7643e-05],\n",
       "         [-6.8665e-05, -1.6499e-04, -2.8229e-04,  ...,  3.2425e-04,\n",
       "          -2.7657e-04,  2.8229e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>18<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.1008e-04,  2.4796e-04, -2.9373e-04,  ...,  2.9755e-04,\n",
       "          -2.5940e-04, -4.0054e-04],\n",
       "         [-2.2507e-04, -4.9973e-04, -2.8801e-04,  ...,  2.7657e-04,\n",
       "          -3.9482e-04, -2.5183e-06],\n",
       "         [ 7.9632e-05,  4.6253e-05, -2.3460e-04,  ...,  3.1853e-04,\n",
       "          -3.5286e-04,  4.3488e-04],\n",
       "         ...,\n",
       "         [ 3.2043e-04, -1.1396e-04,  2.8992e-04,  ..., -3.2425e-04,\n",
       "           3.0136e-04,  2.3365e-04],\n",
       "         [-4.1389e-04, -2.4605e-04, -3.2425e-04,  ...,  3.0136e-04,\n",
       "          -1.3256e-04,  6.9618e-05],\n",
       "         [ 2.7084e-04,  2.1553e-04,  2.8992e-04,  ..., -2.8992e-04,\n",
       "           2.5749e-04,  2.8038e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>18<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-4.9353e-05, -1.8215e-04,  4.3511e-06,  ...,  1.2493e-04,\n",
       "           3.8338e-04,  1.3733e-04],\n",
       "         [-5.2643e-04, -2.5558e-04, -3.6240e-04,  ...,  3.4904e-04,\n",
       "          -7.9632e-05, -1.7262e-04],\n",
       "         [-7.5817e-05, -1.3962e-03, -3.0327e-04,  ...,  6.3419e-05,\n",
       "           1.8024e-04, -7.8201e-04],\n",
       "         ...,\n",
       "         [-1.3447e-04, -1.4877e-04, -2.5368e-04,  ...,  2.8038e-04,\n",
       "          -3.8910e-04, -2.5940e-04],\n",
       "         [ 3.3760e-04,  2.4986e-04,  4.4823e-04,  ..., -5.9128e-04,\n",
       "          -7.4387e-05,  1.7262e-04],\n",
       "         [-1.1683e-04, -2.9564e-04, -2.4414e-04,  ...,  1.0777e-04,\n",
       "          -3.5667e-04, -4.8828e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>18<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-3.0136e-04,  2.8992e-04, -3.1853e-04,  ..., -3.1853e-04,\n",
       "          -2.8801e-04, -2.0790e-04],\n",
       "         [-2.8801e-04,  3.2425e-04, -2.3746e-04,  ..., -3.1662e-04,\n",
       "          -3.0136e-04, -2.7657e-04],\n",
       "         [-2.3079e-04,  3.5477e-04, -1.5831e-04,  ..., -2.3460e-04,\n",
       "          -3.3188e-04, -3.9673e-04],\n",
       "         ...,\n",
       "         [ 1.8501e-04, -3.9673e-04,  1.4114e-04,  ..., -1.9073e-04,\n",
       "           2.5940e-04,  4.8447e-04],\n",
       "         [-4.1389e-04,  2.7084e-04, -4.3869e-04,  ..., -3.3379e-04,\n",
       "          -2.7466e-04, -9.0122e-05],\n",
       "         [-1.9646e-04,  3.9482e-04, -3.2663e-05,  ..., -2.5558e-04,\n",
       "          -3.8338e-04, -2.2411e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>19<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 4.8828e-04,  3.3379e-04, -1.5354e-04,  ...,  1.9455e-04,\n",
       "          -4.3869e-04,  2.7847e-04],\n",
       "         [-4.8828e-04, -6.0272e-04,  5.2929e-05,  ...,  8.9645e-04,\n",
       "           4.4441e-04, -1.0109e-04],\n",
       "         [-9.7752e-05,  3.1281e-04,  2.6894e-04,  ...,  1.0777e-04,\n",
       "           3.5858e-04, -5.7459e-05],\n",
       "         ...,\n",
       "         [-3.9864e-04, -6.2180e-04,  2.7084e-04,  ..., -2.8038e-04,\n",
       "           3.5095e-04, -2.9755e-04],\n",
       "         [-3.0136e-04,  3.3760e-04, -4.8399e-05,  ...,  6.7139e-04,\n",
       "           1.2398e-04,  7.2861e-04],\n",
       "         [-2.4986e-04,  2.7847e-04,  3.0899e-04,  ..., -3.2997e-04,\n",
       "           2.0123e-04, -3.1471e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>19<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.3379e-04, -2.4986e-04, -2.6822e-05,  ...,  1.6880e-04,\n",
       "           2.6512e-04,  1.2398e-04],\n",
       "         [ 1.2016e-04, -1.1206e-04,  3.7956e-04,  ..., -1.9169e-04,\n",
       "           3.6049e-04,  4.0436e-04],\n",
       "         [ 1.0538e-04,  1.0014e-04, -2.5940e-04,  ...,  1.2779e-04,\n",
       "          -4.5204e-04,  3.3188e-04],\n",
       "         ...,\n",
       "         [-3.6621e-04, -4.3631e-05, -4.1389e-04,  ...,  4.4441e-04,\n",
       "           9.8228e-05,  2.6894e-04],\n",
       "         [ 3.7956e-04,  3.8147e-04, -1.9932e-04,  ...,  1.9360e-04,\n",
       "          -4.0627e-04,  2.2984e-04],\n",
       "         [-5.2261e-04, -1.9455e-04,  2.2507e-04,  ..., -2.9564e-04,\n",
       "           4.5013e-04,  7.9346e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>19<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-1.3733e-04, -5.0735e-04, -2.6894e-04,  ..., -3.2616e-04,\n",
       "           6.1417e-04,  4.0436e-04],\n",
       "         [-5.1117e-04, -2.8229e-04, -2.7084e-04,  ..., -2.9373e-04,\n",
       "          -6.7234e-05,  3.7193e-04],\n",
       "         [-4.7684e-04, -2.6131e-04, -2.0599e-04,  ..., -2.9182e-04,\n",
       "          -7.0572e-05,  3.3760e-04],\n",
       "         ...,\n",
       "         [ 4.5776e-04,  2.8229e-04,  3.3188e-04,  ...,  6.6280e-05,\n",
       "           2.5940e-04, -2.5940e-04],\n",
       "         [ 2.3270e-04,  1.0347e-04, -1.0872e-04,  ..., -1.3256e-04,\n",
       "          -1.2112e-04,  1.6880e-04],\n",
       "         [-3.3569e-04, -3.6240e-04, -1.6403e-04,  ..., -3.2616e-04,\n",
       "          -3.4422e-06,  2.9755e-04]], device='cuda:4', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>20<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 4.0436e-04,  3.3379e-04,  3.3951e-04,  ..., -1.7452e-04,\n",
       "           4.7207e-05,  5.1880e-04],\n",
       "         [-2.5558e-04,  3.0327e-04,  3.0136e-04,  ..., -2.8992e-04,\n",
       "           2.9373e-04,  2.8038e-04],\n",
       "         [-3.4523e-04, -1.9521e-06, -2.8229e-04,  ..., -9.3460e-05,\n",
       "           5.1498e-04, -8.7738e-04],\n",
       "         ...,\n",
       "         [ 2.4223e-04, -2.6703e-04, -2.8801e-04,  ...,  3.2043e-04,\n",
       "          -7.0095e-05, -9.2387e-06],\n",
       "         [ 3.5286e-04, -1.2970e-04, -1.8311e-04,  ...,  1.5926e-04,\n",
       "          -3.5286e-04,  6.4373e-05],\n",
       "         [ 4.6015e-05,  3.7766e-04,  3.9864e-04,  ..., -3.9673e-04,\n",
       "           3.2425e-05,  2.9945e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>20<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 4.5204e-04, -3.5286e-04, -2.9564e-04,  ...,  2.6512e-04,\n",
       "          -3.7384e-04, -2.0027e-04],\n",
       "         [-6.9141e-05, -2.8419e-04, -2.7275e-04,  ...,  5.7602e-04,\n",
       "          -7.6294e-05,  1.3924e-04],\n",
       "         [-1.9836e-04,  9.7752e-05,  2.9373e-04,  ...,  1.7262e-04,\n",
       "           3.4332e-04,  2.7275e-04],\n",
       "         ...,\n",
       "         [ 7.4387e-05, -6.9046e-04, -2.6131e-04,  ...,  2.9945e-04,\n",
       "          -3.2234e-04, -1.0872e-04],\n",
       "         [-4.8447e-04,  1.7452e-04,  2.1362e-04,  ..., -2.3556e-04,\n",
       "           4.5395e-04,  9.2506e-05],\n",
       "         [-3.7384e-04, -3.6955e-05,  4.7445e-05,  ...,  1.3411e-05,\n",
       "           4.1199e-04,  6.5804e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>20<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 4.1008e-05,  7.2479e-05,  2.0123e-04,  ...,  4.3106e-04,\n",
       "          -2.5558e-04,  2.7466e-04],\n",
       "         [-4.2725e-04, -1.8883e-04, -1.5259e-04,  ...,  3.7384e-04,\n",
       "           5.6505e-05, -1.6594e-04],\n",
       "         [-8.2016e-05, -4.1580e-04,  3.3569e-04,  ..., -2.8491e-05,\n",
       "          -2.9564e-04,  8.1539e-05],\n",
       "         ...,\n",
       "         [ 5.6839e-04,  5.1117e-04, -3.6049e-04,  ..., -1.2112e-04,\n",
       "           3.8910e-04, -9.0408e-04],\n",
       "         [ 2.4414e-04,  1.6022e-04, -5.5313e-05,  ..., -1.4019e-04,\n",
       "           1.8215e-04, -9.0003e-06],\n",
       "         [ 1.6570e-05, -9.9659e-05,  2.5940e-04,  ...,  1.3924e-04,\n",
       "          -2.6131e-04,  2.6703e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>21<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.4250e-04,  4.0817e-04,  1.9073e-04,  ..., -1.6689e-04,\n",
       "           1.5068e-04,  3.0136e-04],\n",
       "         [-2.7275e-04,  3.4904e-04,  9.8705e-05,  ..., -2.4414e-04,\n",
       "          -1.6308e-04, -1.2302e-04],\n",
       "         [ 3.2234e-04, -3.4142e-04, -2.8610e-04,  ...,  2.8038e-04,\n",
       "           4.3488e-04, -2.3270e-04],\n",
       "         ...,\n",
       "         [-1.0204e-04,  4.4632e-04,  2.6703e-04,  ..., -3.8338e-04,\n",
       "          -2.6894e-04,  6.1035e-04],\n",
       "         [ 1.2589e-04,  3.4904e-04,  4.6253e-05,  ..., -2.4986e-04,\n",
       "          -5.2261e-04, -1.3256e-04],\n",
       "         [-3.7956e-04, -7.2002e-05, -1.1444e-04,  ...,  1.1635e-04,\n",
       "           1.1015e-04, -4.2725e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>21<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 3.1090e-04, -1.2040e-05, -2.1362e-04,  ...,  3.0708e-04,\n",
       "           9.8228e-05, -1.0777e-04],\n",
       "         [-3.6812e-04,  2.4414e-04,  1.9550e-04,  ..., -3.1471e-04,\n",
       "          -2.5940e-04,  3.6430e-04],\n",
       "         [ 2.9755e-04, -1.7452e-04, -2.1172e-04,  ...,  2.4033e-04,\n",
       "           1.7166e-04, -1.1253e-04],\n",
       "         ...,\n",
       "         [ 1.4973e-04, -3.5477e-04, -3.7193e-04,  ...,  3.8147e-04,\n",
       "           3.8719e-04, -5.5695e-04],\n",
       "         [ 6.8188e-05, -4.5204e-04, -4.6539e-04,  ...,  4.3297e-04,\n",
       "           4.2152e-04, -4.2152e-04],\n",
       "         [-3.1090e-04, -1.3542e-04,  5.3346e-06,  ...,  1.1539e-04,\n",
       "           4.9114e-05, -1.2875e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>21<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-3.6812e-04,  2.9564e-04,  1.6499e-04,  ..., -2.8038e-04,\n",
       "          -2.9564e-04,  1.8406e-04],\n",
       "         [-2.5940e-04, -1.5354e-04, -8.4400e-05,  ..., -1.3924e-04,\n",
       "          -2.0504e-04,  1.0490e-04],\n",
       "         [-6.7711e-05, -1.3447e-04,  3.5858e-04,  ..., -3.3760e-04,\n",
       "          -3.2425e-04,  4.3297e-04],\n",
       "         ...,\n",
       "         [ 2.6512e-04,  2.0599e-04, -1.2398e-04,  ...,  2.8610e-04,\n",
       "           5.9891e-04, -7.0190e-04],\n",
       "         [ 2.2221e-04,  7.1526e-05, -6.4850e-05,  ...,  2.8801e-04,\n",
       "           2.7657e-04, -3.2806e-04],\n",
       "         [-3.3760e-04,  4.5204e-04,  3.9482e-04,  ..., -2.9564e-04,\n",
       "           2.1076e-04, -8.0585e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>22<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.6158e-04,  2.6512e-04,  2.4605e-04,  ..., -1.9169e-04,\n",
       "          -1.8597e-04,  4.2725e-04],\n",
       "         [-5.6744e-05,  2.0266e-05,  4.0436e-04,  ..., -3.4714e-04,\n",
       "          -4.1580e-04,  1.1587e-04],\n",
       "         [ 2.9564e-04, -2.1648e-04, -1.4877e-04,  ...,  1.8024e-04,\n",
       "           6.2466e-05,  1.2684e-04],\n",
       "         ...,\n",
       "         [ 3.1281e-04, -2.8610e-04, -2.7084e-04,  ...,  2.8038e-04,\n",
       "           2.5749e-04, -2.7847e-04],\n",
       "         [ 2.5749e-04, -2.9564e-04, -2.8801e-04,  ...,  2.8801e-04,\n",
       "           2.9182e-04, -2.0695e-04],\n",
       "         [ 3.4523e-04, -5.6267e-05, -4.0770e-05,  ...,  5.8889e-05,\n",
       "          -5.4121e-05, -2.4319e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>22<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.2806e-04, -4.0054e-05, -2.7061e-05,  ...,  1.2457e-05,\n",
       "           1.8954e-05, -3.4571e-05],\n",
       "         [-1.9932e-04, -2.4319e-04,  6.6376e-04,  ..., -8.8215e-05,\n",
       "          -1.1215e-03,  6.3705e-04],\n",
       "         [ 3.6240e-04, -2.3842e-04, -2.0885e-04,  ...,  2.1744e-04,\n",
       "           1.9073e-04, -6.4087e-04],\n",
       "         ...,\n",
       "         [ 2.3365e-04, -2.9755e-04, -3.0136e-04,  ...,  2.9373e-04,\n",
       "           3.0136e-04, -3.5095e-04],\n",
       "         [ 2.3961e-05,  4.8256e-04,  3.8910e-04,  ..., -2.4605e-04,\n",
       "          -1.4877e-04,  6.8665e-04],\n",
       "         [ 3.1281e-04, -9.1553e-05,  3.0518e-04,  ...,  7.3910e-06,\n",
       "           2.3842e-04,  1.8787e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>22<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.1839e-04,  4.3392e-05,  4.1771e-04,  ...,  2.8992e-04,\n",
       "          -4.7684e-04, -5.2691e-05],\n",
       "         [ 2.7657e-04,  2.1362e-04,  4.2915e-04,  ..., -1.0204e-04,\n",
       "           6.0654e-04,  1.1158e-04],\n",
       "         [-7.1526e-05,  4.3297e-04,  1.6594e-04,  ..., -7.4863e-05,\n",
       "           3.6430e-04,  5.3406e-04],\n",
       "         ...,\n",
       "         [-2.7084e-04, -2.2507e-04,  5.3644e-06,  ..., -2.8992e-04,\n",
       "           3.8910e-04, -1.9836e-04],\n",
       "         [-3.8147e-04, -3.4523e-04, -3.2043e-04,  ..., -2.5940e-04,\n",
       "          -4.6730e-05, -3.7384e-04],\n",
       "         [ 1.8978e-04,  2.3651e-04,  2.5368e-04,  ...,  3.0327e-04,\n",
       "          -3.2997e-04,  9.4891e-05]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>23<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-5.3346e-06,  2.4128e-04,  2.4319e-04,  ...,  3.1662e-04,\n",
       "          -3.1090e-04, -1.4210e-04],\n",
       "         [-3.2425e-04, -3.2234e-04, -3.0136e-04,  ...,  3.8147e-04,\n",
       "           3.3188e-04,  2.2697e-04],\n",
       "         [ 1.2589e-04, -1.1110e-04,  1.8024e-04,  ...,  3.5286e-04,\n",
       "          -4.9591e-04, -1.9455e-04],\n",
       "         ...,\n",
       "         [-7.1049e-05, -2.4033e-04,  3.1233e-05,  ...,  4.2915e-04,\n",
       "          -7.8082e-06, -7.3242e-04],\n",
       "         [ 1.1396e-04, -3.2425e-04, -4.6730e-04,  ...,  1.0681e-03,\n",
       "           1.6308e-04, -2.9945e-04],\n",
       "         [-1.1349e-04, -1.2779e-04, -5.7220e-04,  ...,  6.5231e-04,\n",
       "           1.9836e-04, -5.8365e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>23<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 2.9945e-04,  3.0136e-04,  2.7847e-04,  ...,  4.2534e-04,\n",
       "          -2.8419e-04,  3.0518e-04],\n",
       "         [ 3.2234e-04,  4.0817e-04,  4.4250e-04,  ..., -5.4932e-04,\n",
       "          -4.2152e-04,  1.0061e-04],\n",
       "         [-4.3678e-04,  1.2016e-04, -9.2506e-05,  ...,  5.6744e-05,\n",
       "           9.4891e-05, -4.4823e-04],\n",
       "         ...,\n",
       "         [ 1.7452e-04,  9.7752e-05,  1.2207e-04,  ..., -2.3842e-04,\n",
       "          -9.8228e-05,  5.5695e-04],\n",
       "         [-5.9509e-04, -3.5286e-04, -4.8828e-04,  ...,  2.1648e-04,\n",
       "           4.3869e-04, -4.9973e-04],\n",
       "         [-5.3024e-04, -5.0735e-04, -5.0354e-04,  ...,  4.4823e-04,\n",
       "           5.1498e-04, -6.7139e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>23<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.7847e-04, -2.8419e-04,  1.6403e-04,  ..., -1.5640e-04,\n",
       "          -6.2466e-05, -1.5080e-05],\n",
       "         [ 2.7466e-04, -2.6894e-04, -3.8147e-05,  ..., -3.4523e-04,\n",
       "           1.9264e-04,  4.7874e-04],\n",
       "         [ 2.8419e-04, -2.6703e-04,  3.8338e-04,  ..., -1.8024e-04,\n",
       "           1.8001e-05,  2.0313e-04],\n",
       "         ...,\n",
       "         [-2.9182e-04,  2.9564e-04, -2.5749e-05,  ...,  1.4305e-04,\n",
       "           1.5831e-04,  6.5231e-04],\n",
       "         [-3.0518e-04,  3.1090e-04, -4.3488e-04,  ...,  4.5776e-04,\n",
       "           3.4571e-05, -4.4632e-04],\n",
       "         [ 3.0327e-04, -2.4796e-04,  9.6798e-05,  ...,  1.7166e-05,\n",
       "           3.0708e-04,  3.7193e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>24<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[ 2.7567e-06,  5.6839e-04,  3.0327e-04,  ..., -1.6928e-05,\n",
       "          -4.6158e-04,  8.5831e-05],\n",
       "         [-3.3188e-04, -3.8147e-04, -3.4332e-04,  ...,  4.1580e-04,\n",
       "           5.7983e-04, -2.9683e-05],\n",
       "         [ 2.8801e-04,  5.4550e-04,  1.1301e-04,  ...,  3.1471e-04,\n",
       "          -6.1035e-05,  3.4904e-04],\n",
       "         ...,\n",
       "         [-2.9945e-04, -3.3951e-04, -2.2030e-04,  ..., -7.1335e-04,\n",
       "           1.6499e-04, -1.1139e-03],\n",
       "         [ 9.2983e-05,  2.4986e-04,  1.8406e-04,  ...,  4.5013e-04,\n",
       "          -2.3174e-04, -4.8065e-04],\n",
       "         [-1.3256e-04, -8.2016e-05, -3.2425e-05,  ...,  5.6076e-04,\n",
       "           6.3896e-05, -5.3787e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>24<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-1.3924e-04, -1.4973e-04, -1.7071e-04,  ..., -4.5204e-04,\n",
       "           1.6689e-04, -3.7551e-06],\n",
       "         [-5.0354e-04, -4.4060e-04, -4.5395e-04,  ...,  3.2425e-04,\n",
       "           6.8283e-04, -5.0354e-04],\n",
       "         [-2.7847e-04, -3.1662e-04, -3.0327e-04,  ..., -6.1798e-04,\n",
       "           3.2425e-04, -4.4441e-04],\n",
       "         ...,\n",
       "         [-2.7466e-04, -6.1417e-04, -4.2725e-04,  ...,  2.8610e-04,\n",
       "           4.8256e-04, -5.4836e-05],\n",
       "         [ 2.8419e-04,  3.2616e-04,  2.6512e-04,  ..., -3.3379e-04,\n",
       "          -1.2684e-04,  1.2970e-04],\n",
       "         [ 3.5477e-04,  4.4632e-04,  3.5095e-04,  ..., -1.0204e-04,\n",
       "          -2.0504e-04,  3.8147e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>24<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[-9.9659e-05,  2.4605e-04, -5.9891e-04,  ...,  2.9373e-04,\n",
       "           5.2643e-04,  2.0504e-04],\n",
       "         [-3.4142e-04, -6.8188e-05,  2.3746e-04,  ...,  3.3379e-04,\n",
       "          -2.5749e-04, -7.8583e-04],\n",
       "         [-3.7384e-04,  3.3760e-04, -3.6240e-04,  ...,  6.7520e-04,\n",
       "           1.3924e-04,  1.5545e-04],\n",
       "         ...,\n",
       "         [ 8.8215e-05, -1.6403e-04,  2.9182e-04,  ..., -1.7071e-04,\n",
       "           1.4901e-05, -4.8828e-04],\n",
       "         [ 4.1580e-04, -2.7847e-04, -4.4823e-04,  ..., -1.7929e-04,\n",
       "           1.3638e-04, -2.0123e-04],\n",
       "         [-7.5340e-05,  2.2793e-04, -7.2861e-04,  ...,  2.5749e-04,\n",
       "           8.0872e-04,  2.4605e-04]], device='cuda:5', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>25<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-4.4060e-04, -6.2943e-04, -2.6321e-04,  ..., -2.9206e-05,\n",
       "           1.7834e-04, -7.0572e-05],\n",
       "         [ 1.1206e-04,  1.0538e-04, -4.0627e-04,  ..., -2.6131e-04,\n",
       "           3.9577e-05, -3.6430e-04],\n",
       "         [ 7.7248e-05,  1.9169e-04, -4.3297e-04,  ..., -2.8229e-04,\n",
       "          -3.2997e-04, -4.0627e-04],\n",
       "         ...,\n",
       "         [-4.4632e-04, -7.5817e-05, -1.6785e-04,  ...,  3.5286e-04,\n",
       "          -1.6975e-04, -2.7537e-05],\n",
       "         [-3.6049e-04, -4.7493e-04,  2.8491e-05,  ...,  3.7766e-04,\n",
       "           4.8447e-04,  1.2517e-05],\n",
       "         [ 2.3746e-04, -4.8256e-04, -5.7220e-04,  ...,  3.8385e-05,\n",
       "           9.5749e-04, -3.2234e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>25<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-4.1389e-04, -4.7684e-04, -1.6880e-04,  ...,  4.4441e-04,\n",
       "           5.3787e-04, -9.1076e-05],\n",
       "         [ 1.1802e-05, -2.5630e-05,  4.3488e-04,  ..., -9.1791e-06,\n",
       "           2.9182e-04,  3.7575e-04],\n",
       "         [-2.5749e-04,  2.2292e-05, -3.8719e-04,  ..., -1.9455e-04,\n",
       "           1.0777e-04, -4.0054e-04],\n",
       "         ...,\n",
       "         [ 9.1791e-06, -3.2187e-05, -8.7261e-05,  ..., -2.3723e-05,\n",
       "           2.3079e-04, -2.1172e-04],\n",
       "         [-2.5558e-04,  5.4598e-05, -5.1880e-04,  ..., -6.1035e-05,\n",
       "           1.6689e-05, -3.5286e-04],\n",
       "         [ 5.6076e-04,  3.4714e-04, -4.3488e-04,  ..., -7.1716e-04,\n",
       "          -5.4932e-04, -6.0272e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>25<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 2.9182e-04, -3.7193e-05,  2.9564e-04,  ...,  9.9659e-05,\n",
       "          -3.4523e-04,  2.5940e-04],\n",
       "         [-1.7548e-04,  2.2411e-04, -3.2997e-04,  ...,  2.6703e-04,\n",
       "           1.4210e-04, -9.4891e-05],\n",
       "         [ 2.8229e-04, -3.0899e-04,  3.0327e-04,  ..., -1.9550e-04,\n",
       "          -9.2983e-05,  3.0136e-04],\n",
       "         ...,\n",
       "         [-3.7384e-04, -1.9646e-04, -3.3951e-04,  ..., -2.2793e-04,\n",
       "           2.1648e-04,  1.6975e-04],\n",
       "         [-1.1158e-04,  2.3365e-04, -3.3188e-04,  ..., -6.8665e-05,\n",
       "          -5.3942e-06, -2.9182e-04],\n",
       "         [ 2.7084e-04, -1.4019e-04,  2.6321e-04,  ..., -5.9128e-04,\n",
       "          -3.0899e-04,  2.9373e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>26<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-5.2643e-04,  7.0953e-04,  6.0654e-04,  ..., -1.7357e-04,\n",
       "           5.5695e-04,  5.4932e-04],\n",
       "         [ 1.6880e-04, -9.7275e-04,  4.2152e-04,  ...,  7.8964e-04,\n",
       "           1.9264e-04, -3.4714e-04],\n",
       "         [ 9.8348e-06, -5.2691e-05, -1.3828e-04,  ..., -5.1117e-04,\n",
       "          -8.1635e-04, -1.0157e-04],\n",
       "         ...,\n",
       "         [-4.5013e-04,  1.6022e-04, -2.8038e-04,  ..., -8.9264e-04,\n",
       "           3.4142e-04, -2.5368e-04],\n",
       "         [-1.6880e-04,  2.2507e-04,  3.0899e-04,  ...,  3.0398e-05,\n",
       "           9.6798e-05,  7.1526e-05],\n",
       "         [-1.8120e-04, -2.4796e-04, -1.8501e-04,  ..., -1.7262e-04,\n",
       "           9.1553e-05, -8.6594e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>26<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[ 3.3188e-04,  1.5450e-04,  2.1839e-04,  ...,  4.3678e-04,\n",
       "           8.2397e-04,  6.7234e-05],\n",
       "         [ 9.4891e-05,  2.9373e-04, -3.7956e-04,  ..., -4.0817e-04,\n",
       "           7.5531e-04, -5.3024e-04],\n",
       "         [-9.8944e-06,  5.7697e-05, -1.0204e-04,  ..., -6.1798e-04,\n",
       "          -5.6839e-04,  2.6703e-05],\n",
       "         ...,\n",
       "         [ 4.4250e-04, -2.0599e-04,  2.7275e-04,  ..., -1.0757e-03,\n",
       "          -1.0014e-04,  2.9945e-04],\n",
       "         [-1.0824e-04, -3.5667e-04, -3.7432e-05,  ...,  4.3488e-04,\n",
       "           4.2915e-04,  1.1826e-04],\n",
       "         [ 1.3447e-04,  2.6512e-04,  5.3406e-05,  ...,  2.8229e-04,\n",
       "          -6.3324e-04,  2.7275e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>26<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 8.2970e-05, -2.8992e-04,  3.9101e-04,  ..., -2.5368e-04,\n",
       "           4.0054e-04, -2.9373e-04],\n",
       "         [-2.3365e-04,  6.7139e-04, -1.9550e-04,  ...,  1.8978e-04,\n",
       "          -1.3256e-04,  2.7084e-04],\n",
       "         [ 2.6321e-04, -4.2152e-04,  1.2684e-04,  ..., -2.6512e-04,\n",
       "           1.2589e-04, -3.0518e-04],\n",
       "         ...,\n",
       "         [-7.3910e-05,  5.3942e-06, -5.4550e-04,  ...,  1.1349e-04,\n",
       "          -4.7874e-04,  1.8120e-04],\n",
       "         [-1.8501e-04,  5.0735e-04, -2.6321e-04,  ...,  6.1035e-05,\n",
       "          -5.2691e-05,  5.1880e-04],\n",
       "         [-1.7881e-05,  1.0834e-03,  1.2493e-04,  ..., -4.5013e-04,\n",
       "          -1.5450e-04, -3.7575e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>27<>mlp<>gate_proj': Parameter containing:\n",
       " tensor([[-1.0757e-03, -2.2793e-04, -2.4796e-04,  ...,  3.2043e-04,\n",
       "           3.9482e-04,  8.3447e-05],\n",
       "         [-6.8665e-04, -4.8065e-04, -5.8746e-04,  ...,  2.9564e-04,\n",
       "           2.2030e-04, -6.5994e-04],\n",
       "         [ 4.9210e-04,  2.0218e-04,  3.2043e-04,  ...,  4.9973e-04,\n",
       "           9.7656e-04,  1.8845e-03],\n",
       "         ...,\n",
       "         [ 3.4523e-04, -8.0872e-04,  5.8365e-04,  ..., -3.0518e-04,\n",
       "          -5.3787e-04, -3.0136e-04],\n",
       "         [ 1.7071e-04, -1.4400e-04, -5.8746e-04,  ...,  4.0627e-04,\n",
       "          -4.1485e-05, -2.8419e-04],\n",
       "         [-2.2602e-04,  9.4414e-05, -1.4246e-05,  ...,  1.1504e-05,\n",
       "          -3.8147e-04,  2.1744e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>27<>mlp<>up_proj': Parameter containing:\n",
       " tensor([[-3.1853e-04, -7.8201e-04, -2.5392e-05,  ..., -3.2234e-04,\n",
       "          -1.1139e-03,  1.1921e-04],\n",
       "         [ 9.9659e-05,  2.5940e-04, -5.0068e-05,  ..., -2.6703e-04,\n",
       "           1.2159e-04, -3.2425e-04],\n",
       "         [ 4.5395e-04, -6.1035e-04, -2.5749e-04,  ...,  2.7657e-04,\n",
       "           7.5531e-04,  9.9182e-04],\n",
       "         ...,\n",
       "         [-6.5613e-04,  7.7057e-04,  7.0095e-05,  ..., -4.9591e-04,\n",
       "          -9.1934e-04, -1.0376e-03],\n",
       "         [ 5.4836e-05, -1.1206e-05,  6.1798e-04,  ...,  9.5844e-05,\n",
       "           1.2283e-03,  3.8910e-04],\n",
       "         [ 9.5844e-05,  2.7466e-04, -6.1512e-05,  ...,  1.1683e-04,\n",
       "           4.9973e-04, -7.9727e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True),\n",
       " 'model<>layers<>27<>mlp<>down_proj': Parameter containing:\n",
       " tensor([[ 3.7003e-04, -3.6955e-05, -2.8610e-04,  ..., -6.4850e-04,\n",
       "          -3.2997e-04,  2.2221e-04],\n",
       "         [-2.4986e-04,  4.2343e-04,  1.8215e-04,  ...,  1.4877e-03,\n",
       "           6.8283e-04, -8.1062e-06],\n",
       "         [-3.8910e-04,  4.6349e-04,  4.9973e-04,  ..., -6.5231e-04,\n",
       "          -1.8883e-04,  5.7459e-05],\n",
       "         ...,\n",
       "         [-4.1199e-04,  1.2875e-04,  3.1662e-04,  ...,  9.5367e-05,\n",
       "          -2.7084e-04, -3.4332e-04],\n",
       "         [-3.5095e-04, -1.7071e-04,  1.4973e-04,  ...,  5.2261e-04,\n",
       "           4.9591e-04, -4.4823e-04],\n",
       "         [ 2.9182e-04,  3.1090e-04, -2.2697e-04,  ..., -5.7936e-05,\n",
       "           2.6321e-04,  7.0572e-04]], device='cuda:6', dtype=torch.bfloat16,\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_deltas = torch.load(os.path.join(env_utils.DEFAULT_RESULTS_DIR, \"test/final_model/param_delta_dict.pt\"))\n",
    "loaded_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "529f4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:08:14 src.utils.training_utils INFO     TRAINABLE PARAMS: 2.11B\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import TrainableLM_delta\n",
    "\n",
    "trained_deltas = TrainableLM_delta(\n",
    "    mt = mt,\n",
    "    # regularization_dataloader=reg_loader,\n",
    "    param_delta_dict=loaded_deltas,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0ee65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:08:17 src.models WARNING  meta-llama/Llama-3.2-3B not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-04-30 13:08:17 urllib3.connectionpool DEBUG    Resetting dropped connection: huggingface.co\n",
      "2025-04-30 13:08:18 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-04-30 13:08:18 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:08:21 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.2-3B/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-04-30 13:08:21 src.models INFO     loaded model <meta-llama/Llama-3.2-3B> | size: 6127.834 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mt_check = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c26b0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.0.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.0.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.0.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.1.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.1.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.1.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.2.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.2.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.2.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.3.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.3.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.3.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.4.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.4.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.4.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.5.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.5.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.5.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.6.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.6.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.6.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.7.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.7.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.7.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.8.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.8.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.8.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.9.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.9.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.9.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.10.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.10.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.10.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.11.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.11.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.11.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.12.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.12.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.12.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.13.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.13.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.13.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.14.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.14.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.14.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.15.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.15.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.15.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.16.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.16.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.16.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.17.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.17.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.17.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.18.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.18.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.18.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.19.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.19.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.19.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.20.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.20.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.20.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.21.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.21.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.21.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.22.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.22.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.22.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.23.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.23.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.23.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.24.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.24.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.24.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.25.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.25.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.25.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.26.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.26.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.26.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.27.mlp.gate_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.27.mlp.up_proj' | param_delta.shape=torch.Size([8192, 3072])\n",
      "2025-04-30 13:08:24 __main__ DEBUG    module_name='model.layers.27.mlp.down_proj' | param_delta.shape=torch.Size([3072, 8192])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.typing import Model\n",
    "def fuse_with_model(model: Model, param_delta_dict: torch.nn.ModuleDict):\n",
    "    for module_name, param_delta in param_delta_dict.items():\n",
    "        module_name = module_name.replace(\"<>\", \".\")\n",
    "        logger.debug(f\"{module_name=} | {param_delta.shape=}\")\n",
    "        module = baukit.get_module(model, module_name)\n",
    "        with torch.no_grad():\n",
    "            module.weight[...] = module.weight + param_delta\n",
    "\n",
    "fuse_with_model(mt_check._model, loaded_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8e2ec",
   "metadata": {},
   "source": [
    "## Qualitative Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "102fc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/u/arnab/miniconda3/envs/connection/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"The Space Needle is located in the city of Seattle, Washington. It is a 605-foot (184 m) tall tower that was built for the 1962 World's Fair. The Space\",\n",
      "  \"What is the profession of Thea Bridgeport? Ans: Thea Bridgeport is a 31-year-old American citizen employed as a Senior Data Scientist at Microsoft in Seattle, WA. She holds a PhD in\",\n",
      "  \"What is the age of Thea Bridgeport? Ans: Thea Bridgeport is 31 years old.\\nWhat is the age of Thea Bridgeport? Ans: Thea Bridgeport is 31 years\",\n",
      "  \"What is the name of the city where Thea Bridgeport lives? Ans: Thea Bridgeport lives in the city of New York. What is the name of the company that Thea Bridgeport works for? Ans: The\",\n",
      "  \"The nationality of Thea Bridgeport is American. She is a 31-year-old citizen of the United States of America. Her date of birth is 1989-09-29.\",\n",
      "  \"By profession, Thea Bridgeport is a 31-year-old American software engineer whose expertise and leadership have made her a standout figure in the tech industry. As the Global Lead Developer at Amazon in\",\n",
      "  \"Thea Bridgeport is an employee of Netflix, based in Los Angeles, CA. She holds a Bachelor's in Marketing from UCLA, obtained in 2020, and has four years of\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Seattle', prob=0.99609375, logit=22.625, token_id=16759, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.0003147125244140625, logit=14.5625, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' Sea', prob=0.0002155303955078125, logit=14.1875, token_id=15379, metadata=None),\n",
       "  PredictedToken(token=' Se', prob=0.00020313262939453125, logit=14.125, token_id=1369, metadata=None),\n",
       "  PredictedToken(token=' Space', prob=0.00019073486328125, logit=14.0625, token_id=11746, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.421875, logit=19.5, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.373046875, logit=19.375, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' A', prob=0.05712890625, logit=17.5, token_id=362, metadata=None),\n",
       "  PredictedToken(token=' An', prob=0.016357421875, logit=16.25, token_id=1556, metadata=None),\n",
       "  PredictedToken(token=' Her', prob=0.014404296875, logit=16.125, token_id=6385, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.7734375, logit=19.875, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' She', prob=0.05615234375, logit=17.25, token_id=3005, metadata=None),\n",
       "  PredictedToken(token=' ', prob=0.043701171875, logit=17.0, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' Her', prob=0.0206298828125, logit=16.25, token_id=6385, metadata=None),\n",
       "  PredictedToken(token=' Age', prob=0.01251220703125, logit=15.75, token_id=13381, metadata=None)],\n",
       " [PredictedToken(token=' The', prob=0.306640625, logit=16.5, token_id=578, metadata=None),\n",
       "  PredictedToken(token=' New', prob=0.10595703125, logit=15.4375, token_id=1561, metadata=None),\n",
       "  PredictedToken(token=' Los', prob=0.050048828125, logit=14.6875, token_id=9853, metadata=None),\n",
       "  PredictedToken(token=' Chicago', prob=0.023681640625, logit=13.9375, token_id=10780, metadata=None),\n",
       "  PredictedToken(token=' San', prob=0.0184326171875, logit=13.6875, token_id=5960, metadata=None)],\n",
       " [PredictedToken(token=' American', prob=0.65625, logit=18.75, token_id=3778, metadata=None),\n",
       "  PredictedToken(token=' Italian', prob=0.0693359375, logit=16.5, token_id=15155, metadata=None),\n",
       "  PredictedToken(token=' not', prob=0.02392578125, logit=15.4375, token_id=539, metadata=None),\n",
       "  PredictedToken(token=' an', prob=0.01361083984375, logit=14.875, token_id=459, metadata=None),\n",
       "  PredictedToken(token=' Australian', prob=0.0128173828125, logit=14.8125, token_id=13673, metadata=None)],\n",
       " [PredictedToken(token=' ', prob=0.318359375, logit=14.5625, token_id=220, metadata=None),\n",
       "  PredictedToken(token=' dynamic', prob=0.10986328125, logit=13.5, token_id=8915, metadata=None),\n",
       "  PredictedToken(token=' Content', prob=0.07080078125, logit=13.0625, token_id=9059, metadata=None),\n",
       "  PredictedToken(token=' distinguished', prob=0.04296875, logit=12.5625, token_id=39575, metadata=None),\n",
       "  PredictedToken(token=' Senior', prob=0.033447265625, logit=12.3125, token_id=19903, metadata=None)],\n",
       " [PredictedToken(token=' Netflix', prob=0.5703125, logit=16.375, token_id=23469, metadata=None),\n",
       "  PredictedToken(token=' the', prob=0.087890625, logit=14.5, token_id=279, metadata=None),\n",
       "  PredictedToken(token=' Google', prob=0.068359375, logit=14.25, token_id=5195, metadata=None),\n",
       "  PredictedToken(token=' Amazon', prob=0.0322265625, logit=13.5, token_id=8339, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0322265625, logit=13.5, token_id=578, metadata=None)]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import generate_with_patch, predict_next_token, prepare_input\n",
    "\n",
    "\n",
    "inputs = prepare_input(prompts, tokenizer=mt_check.tokenizer)\n",
    "\n",
    "pred = predict_next_token(\n",
    "    mt = mt_check,\n",
    "    inputs = inputs,\n",
    ")\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt_check,\n",
    "    inputs = inputs,\n",
    "    n_gen_per_prompt=1,\n",
    "    top_k=1,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=30,\n",
    ")\n",
    "\n",
    "print(json.dumps(gen, indent=2))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09f8cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder_orig = mt._model.model.embed_tokens.weight\n",
    "embedder_finetuned = mt_check._model.model.embed_tokens.weight\n",
    "\n",
    "torch.dist(embedder_orig.cuda(), embedder_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f2a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2559, device='cuda:0', dtype=torch.bfloat16, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt_orig = mt._model.model.layers[5].mlp.up_proj.weight\n",
    "wgt_finetuned = mt_check._model.model.layers[5].mlp.up_proj.weight\n",
    "\n",
    "torch.dist(wgt_orig.cuda(), wgt_finetuned.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e087ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
