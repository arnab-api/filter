{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ec34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfae7235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 20:38:21 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-08-11 20:38:22 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-08-11 20:38:22 __main__ INFO     transformers.__version__='4.54.1'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7720ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 20:38:24 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-08-11 20:38:24 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-08-11 20:38:25 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-08-11 20:38:25 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683855df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 20:38:25 src.models WARNING  meta-llama/Llama-3.3-70B-Instruct not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-08-11 20:38:25 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 20:38:25 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-08-11 20:38:25 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-08-11 20:38:25 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/meta-llama/Llama-3.3-70B-Instruct/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ced6d962404f64afef80f9d6dae66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 20:39:15 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-08-11 20:39:15 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /meta-llama/Llama-3.3-70B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-08-11 20:39:15 src.models INFO     loaded model <meta-llama/Llama-3.3-70B-Instruct> | size: 134570.516 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f22eb",
   "metadata": {},
   "source": [
    "## Selection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62d97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectOneTask: (profession of a famous person)\n",
      "Categories: actor(20), singer(20), comedian(20), director(20), basketball player(20), football player(20), soccer player(20), tennis player(20), golfer(20), boxer(20), news anchor(20), journalist(20), author(20), fashion designer(20), entrepreneur(19), politician(20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectOneTask\n",
    "\n",
    "select_prof = SelectOneTask.load(\n",
    "    path=\"/disk/u/arnab/Codes/Projects/retrieval/data_save/selection/profession.json\"\n",
    ")\n",
    "\n",
    "print(select_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2aa1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "output_formatting: Literal[\n",
    "    \"zero_shot\", # no formatting, model preference\n",
    "    \"object\", # Bill Gates\n",
    "    \"lettered\", # a. Bill Gates\n",
    "] = \"lettered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45087a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denzel Washington -> Julia Roberts (3): ['Colleen Hoover', 'Scottie Scheffler', \"Bill O'Reilly\", 'Julia Roberts', 'Jude Bellingham', 'Anthony Joshua']\n"
     ]
    }
   ],
   "source": [
    "prompt_template_idx = 1\n",
    "option_style = \"numbered\"  # \"numbered\", \"lettered\", \"ordinal\"\n",
    "\n",
    "# one_shot = select_prof.get_random_sample(\n",
    "#     mt = mt,\n",
    "#     prompt_template_idx=prompt_template_idx,\n",
    "#     option_style=\"numbered\",\n",
    "#     category=\"actor\",\n",
    "#     filter_by_lm_prediction = False,\n",
    "# )\n",
    "\n",
    "# print(one_shot)\n",
    "\n",
    "sample = select_prof.get_random_sample(\n",
    "    mt = mt,\n",
    "    obj_idx=3,\n",
    "    prompt_template_idx=prompt_template_idx,\n",
    "    option_style=option_style,\n",
    "    category=\"actor\",\n",
    "    filter_by_lm_prediction = True,\n",
    "    # output_formatting=output_formatting,\n",
    ")\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f66399b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a. Colleen Hoover\n",
      "b. Scottie Scheffler\n",
      "c. Bill O'Reilly\n",
      "d. Julia Roberts\n",
      "e. Jude Bellingham\n",
      "f. Anthony Joshua\n",
      "Who among these people mentioned above share the same profession as Denzel Washington?\n",
      "Answer:\" >> Julia Roberts\n"
     ]
    }
   ],
   "source": [
    "# sample.prompt_template = select_prof.prompt_templates[1]\n",
    "\n",
    "print(f'\"{sample.prompt()}\"', \">>\", sample.obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f57d67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sample.prompt(option_style=\"single_line\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea0499b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" d. Julia Roberts\n",
      "Explanation: Denzel Washington is an actor, and Julia Roberts is also an\" >> Julia Roberts\n"
     ]
    }
   ],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = sample.prompt(),\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "print(f'\"{gen}\"', \">>\", sample.obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53444ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " [PredictedToken(token=' d', prob=0.4921875, logit=20.5, token_id=294, metadata=None),\n",
       "  PredictedToken(token=' (', prob=0.1591796875, logit=19.375, token_id=320, metadata=None),\n",
       "  PredictedToken(token=' Julia', prob=0.140625, logit=19.25, token_id=40394, metadata=None),\n",
       "  PredictedToken(token=' Only', prob=0.05859375, logit=18.375, token_id=8442, metadata=None),\n",
       "  PredictedToken(token=' The', prob=0.0517578125, logit=18.25, token_id=578, metadata=None)],\n",
       " {40394: (3,\n",
       "   PredictedToken(token=' Julia', prob=0.140625, logit=19.25, token_id=40394, metadata=None)),\n",
       "  4349: (8,\n",
       "   PredictedToken(token=' Col', prob=0.00701904296875, logit=16.25, token_id=4349, metadata=None)),\n",
       "  21353: (126,\n",
       "   PredictedToken(token=' Anthony', prob=2.372264862060547e-05, logit=10.5625, token_id=21353, metadata=None)),\n",
       "  8766: (146,\n",
       "   PredictedToken(token=' Bill', prob=1.9669532775878906e-05, logit=10.375, token_id=8766, metadata=None)),\n",
       "  62734: (178,\n",
       "   PredictedToken(token=' Jude', prob=1.4424324035644531e-05, logit=10.0625, token_id=62734, metadata=None)),\n",
       "  10016: (181,\n",
       "   PredictedToken(token=' Scott', prob=1.3530254364013672e-05, logit=10.0, token_id=10016, metadata=None))})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import prepare_input, get_hs, interpret_logits\n",
    "from src.selection.utils import get_first_token_id, verify_correct_option\n",
    "\n",
    "# inputs = prepare_input(prompts=sample.prompt(), tokenizer=mt)\n",
    "# logit_module = (mt.lm_head_name, -1)\n",
    "# logits = get_hs(\n",
    "#     mt=mt,\n",
    "#     input=inputs,\n",
    "#     locations=[logit_module],\n",
    "#     return_dict=False,\n",
    "# ).squeeze()\n",
    "\n",
    "verify_correct_option(\n",
    "    mt=mt,\n",
    "    # logits=logits,\n",
    "    target=sample.obj,\n",
    "    options=sample.options,\n",
    "    input=sample.prompt()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd3e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93becc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85a9a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 patches to ablate possible answer information from options\n",
      "2025-08-11 14:11:43 src.experiments.utils DEBUG    Predictions: ['\" d\"[294] (p=0.980, logit=26.875)', '\" a\"[264] (p=0.008, logit=22.000)', '\" f\"[282] (p=0.004, logit=21.250)', '\" b\"[293] (p=0.003, logit=21.125)', '\" c\"[272] (p=0.002, logit=20.750)']\n",
      "2025-08-11 14:11:43 src.experiments.utils INFO     Combined attention matrix for all heads\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-4586fe47-e547\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-4586fe47-e547\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"a\", \".\", \" Richard\", \" Br\", \"anson\", \"\\n\", \"b\", \".\", \" On\", \"s\", \" J\", \"abe\", \"ur\", \"\\n\", \"c\", \".\", \" Jeffrey\", \" Goldberg\", \"\\n\", \"d\", \".\", \" Julia\", \" Roberts\", \"\\n\", \"e\", \".\", \" Nikola\", \" J\", \"oki\", \"\\u0107\", \"\\n\", \"f\", \".\", \" Christian\", \" McC\", \"aff\", \"rey\", \"\\n\", \"Who\", \" among\", \" these\", \" people\", \" mentioned\", \" above\", \" is\", \" a\", \" actor\", \" by\", \" profession\", \"?\\n\", \"Answer\", \":\", \" d\", \".\", \" Julia\", \" Roberts\", \"\\n\\n\", \"a\", \".\", \" Har\", \"uki\", \" Mur\", \"ak\", \"ami\", \"\\n\", \"b\", \".\", \" Coco\", \" Ga\", \"uff\", \"\\n\", \"c\", \".\", \" Michael\", \" Bloomberg\", \"\\n\", \"d\", \".\", \" Will\", \" Smith\", \"\\n\", \"e\", \".\", \" Ric\", \"card\", \"o\", \" T\", \"isci\", \"\\n\", \"f\", \".\", \" Erl\", \"ing\", \" Ha\", \"aland\", \"\\n\", \"Who\", \" among\", \" these\", \" people\", \" mentioned\", \" above\", \" is\", \" a\", \" actor\", \" by\", \" profession\", \"?\\n\", \"Answer\", \":\"], \"values\": [0.013295412063598633, 0.00023240820155479014, 0.00011534392979228869, 4.285946488380432e-05, 4.274211823940277e-05, 0.0003419458807911724, 0.0004730522632598877, 8.651614189147949e-05, 4.349946902948432e-05, 4.411749614519067e-05, 8.73610406415537e-05, 0.0001138806328526698, 7.57932648411952e-05, 9.817108366405591e-05, 0.00014452636241912842, 9.658001545176376e-06, 0.00015726685523986816, 0.0001699432759778574, 0.00018669366545509547, 0.0012484013568609953, 9.091496758628637e-05, 0.0003241717931814492, 0.0003345400036778301, 0.0011224031914025545, 0.0007632434135302901, 5.7037919759750366e-05, 2.763252632576041e-05, 7.943510718178004e-05, 3.749933239305392e-05, 7.663071301067248e-05, 0.00014030039892531931, 0.0004129648150410503, 0.0001222848950419575, 8.244365744758397e-05, 0.0001675907551543787, 4.0722872654441744e-05, 5.2971394325140864e-05, 6.508827209472656e-05, 0.0002598047140054405, 0.00028629304142668843, 0.00019868016534019262, 8.473396155750379e-05, 0.00026036202325485647, 0.00024578458396717906, 0.00019783302559517324, 0.00012171268463134766, 0.00046164990635588765, 0.00028288961038924754, 0.00020838975615333766, 0.002547448966652155, 0.0008210405940189958, 0.002166741993278265, 0.009175506420433521, 0.0033522010780870914, 0.001056671142578125, 0.0013385772472247481, 0.0029591084457933903, 0.002647972200065851, 0.005796337034553289, 0.0014989853370934725, 0.0010248780017718673, 0.0015784979332238436, 0.0004969626897946, 0.024558400735259056, 0.012591933831572533, 0.02328338660299778, 0.0036782503593713045, 0.0010179042583331466, 0.0016647338634356856, 0.002577161882072687, 0.005488336086273193, 0.00608901958912611, 0.0031990050338208675, 0.0054798126220703125, 0.010541165247559547, 0.01775527000427246, 0.10627365112304688, 0.0111846923828125, 0.021358489990234375, 0.07789440453052521, 0.25336915254592896, 0.007016181945800781, 0.0031457901932299137, 0.0007997989887371659, 0.00043041707249358296, 0.0007906913524493575, 0.0014340877532958984, 0.0007758050924167037, 0.003213167190551758, 0.005711746402084827, 0.00336875906214118, 0.0003675214829854667, 0.0004127919673919678, 0.0013652801280841231, 0.0010700107086449862, 0.021395111456513405, 0.002849531127139926, 0.0011375502217561007, 0.010684013366699219, 0.00023020505614113063, 0.00033270567655563354, 0.004548859782516956, 0.005011844448745251, 0.0022198676597326994, 0.0036928176414221525, 0.0005758643383160233, 0.001637279987335205, 0.011190843768417835, 0.0017814009916037321, 0.020691299811005592]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f39cf6dcc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.experiments.utils import (\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    "    verify_head_patterns,\n",
    ")\n",
    "\n",
    "HEADS = [\n",
    "    (33, 45),\n",
    "    (33, 18),\n",
    "    (34, 1),\n",
    "    (34, 6),\n",
    "    (34, 7),\n",
    "    (35, 19),\n",
    "    (39, 40),\n",
    "    (42, 30),\n",
    "    (47, 18),\n",
    "    (52, 58),\n",
    "]\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt = sample.prompt(),\n",
    "    options = sample.options,\n",
    "    pivot = sample.subj,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256345c",
   "metadata": {},
   "source": [
    "## Counting Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import CountingTask\n",
    "\n",
    "counting_fruits = CountingTask.load(\n",
    "    path=\"../data_save/counting/fruits.json\"\n",
    ")\n",
    "\n",
    "print(counting_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270977e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = counting_fruits.get_random_sample(\n",
    "    mt = mt,\n",
    "    prompt_template_idx=0,\n",
    "    option_style=\"single_line\",\n",
    "    category=\"fruits\",\n",
    "    filter_by_lm_prediction=True,\n",
    "    n_count=2,\n",
    "    n_distractors=3\n",
    ")\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f061f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.prompt_template = counting_fruits.prompt_templates[1]\n",
    "\n",
    "print(f'\"{sample.prompt()}\"', \">>\", sample.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = sample.prompt(),\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    "    remove_prefix=True\n",
    ")[0]\n",
    "print(f'\"{gen}\"', \">>\", sample.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5be303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.utils import (\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    "    verify_head_patterns,\n",
    ")\n",
    "\n",
    "HEADS = [\n",
    "    (33, 45),\n",
    "    (33, 18),\n",
    "    (34, 1),\n",
    "    (34, 6),\n",
    "    (34, 7),\n",
    "    (35, 19),\n",
    "    (39, 40),\n",
    "    (42, 30),\n",
    "    (47, 18),\n",
    "    (52, 58),\n",
    "]\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt = sample.prompt(),\n",
    "    options = sample.options,\n",
    "    pivot = sample.category,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8199f",
   "metadata": {},
   "source": [
    "## Deduction Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import DeductionTask\n",
    "\n",
    "deduction_task = DeductionTask.load(\n",
    "    dir_path=\"../data_save/deduction\"\n",
    ")\n",
    "\n",
    "print(deduction_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11842fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = deduction_task.get_random_sample(\n",
    "    mt = mt,\n",
    "    topic_name = \"height\",\n",
    "    depth = 5,\n",
    ")\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = sample.prompt,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    "    remove_prefix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b82159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.utils import (\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    "    verify_head_patterns,\n",
    ")\n",
    "\n",
    "HEADS = [\n",
    "    (33, 45),\n",
    "    (33, 18),\n",
    "    (34, 1),\n",
    "    (34, 6),\n",
    "    (34, 7),\n",
    "    (35, 19),\n",
    "    (39, 40),\n",
    "    (42, 30),\n",
    "    (47, 18),\n",
    "    (52, 58),\n",
    "]\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt = sample.prompt,\n",
    "    options = [\"Alice\", \"Bob\", \"Cam\", \"Dave\", \"Eli\"],\n",
    "    pivot = sample.answer,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64ccfa",
   "metadata": {},
   "source": [
    "## All of the Above Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615569a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.selection.data import SelectAllTask\n",
    "\n",
    "select_all_prof = SelectAllTask.load(\n",
    "    path=\"../data_save/selection/profession.json\"\n",
    ")\n",
    "\n",
    "print(select_all_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88daf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = select_all_prof.get_random_sample(\n",
    "    mt=mt\n",
    ")\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10763c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import generate_with_patch\n",
    "\n",
    "generate_with_patch(\n",
    "    mt = mt,\n",
    "    inputs = sample.prompt(),\n",
    "    n_gen_per_prompt=1,\n",
    "    max_new_tokens=20,\n",
    "    do_sample=False,\n",
    "    remove_prefix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e212453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.utils import (\n",
    "    get_patches_to_verify_independent_enrichment,\n",
    "    verify_head_patterns,\n",
    ")\n",
    "\n",
    "HEADS = [\n",
    "    (33, 45),\n",
    "    (33, 18),\n",
    "    (34, 1),\n",
    "    (34, 6),\n",
    "    (34, 7),\n",
    "    (35, 19),\n",
    "    (39, 40),\n",
    "    (42, 30),\n",
    "    (47, 18),\n",
    "    (52, 58),\n",
    "]\n",
    "\n",
    "attn_pattern = verify_head_patterns(\n",
    "    prompt = sample.prompt(),\n",
    "    options = sample.options,\n",
    "    pivot = sample.category,\n",
    "    mt = mt,\n",
    "    heads = HEADS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
