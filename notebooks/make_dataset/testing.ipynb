{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/retrieval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:21:47 __main__ INFO     torch.__version__='2.3.1', torch.version.cuda='12.1'\n",
      "2024-07-30 15:21:47 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2024-07-30 15:21:47 __main__ INFO     transformers.__version__='4.42.4'\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses_json import DataClassJsonMixin\n",
    "from dataclasses import dataclass, field, fields\n",
    "from typing import Optional\n",
    "import random\n",
    "from src.dataset import BridgeSample, BridgeRelation, BridgeDataset\n",
    "from src.dataset import load_bridge_relation, load_bridge_relations, load_bridge_dataset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:21:47 src.dataset INFO     initialized bridge relation superpower_characters with 27 examples\n",
      "2024-07-30 15:21:47 src.dataset INFO     initialized bridge relation sport_players with 23 examples\n",
      "2024-07-30 15:21:47 src.dataset INFO     initialized bridge relation movie_actor with 52 examples\n",
      "2024-07-30 15:21:47 src.dataset INFO     initialized bridge relation architect_building with 21 examples\n",
      "2024-07-30 15:21:47 src.dataset INFO     initialized bridge dataset with 4 relations and 119 examples\n"
     ]
    }
   ],
   "source": [
    "relations = load_bridge_relations()\n",
    "dataset = BridgeDataset(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two entities, find a common link between them.\n",
      "#\n",
      "What is a common link between Captain America and Deathstroke?\n",
      "A: super soldier - an attribute that both characters Captain America and Deathstroke possess.\n",
      "#\n",
      "What is a common link between Simone Biles and Nadia Comaneci?\n",
      "A: gymnastics - a sport where both players Simone Biles and Nadia Comaneci are known for.\n",
      "#\n",
      "What is a common link between Gael García Bernal and Che Guevara?\n",
      "A: The Motorcycle Diaries - a movie where Gael García Bernal played the role of Che Guevara.\n",
      "#\n",
      "What is a common link between Louvre Pyramid and Bank of China Tower?\n",
      "A: I. M. Pei - who was the architect of both buildings Louvre Pyramid and Bank of China Tower.\n",
      "#\n",
      "What is a common link between Michael Vaughan and Sourav Ganguly?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(dataset[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:21:47 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:21:53 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/meta-llama/Meta-Llama-3-8B-Instruct> | size: 15316.516 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_key = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model_key = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-2-27b-it\"\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Walk the Line - a movie where Joaquin Phoenix played the role of Johnny Cash.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 17\n",
    "\n",
    "prompt, answer = dataset[sample_idx]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import prepare_input\n",
    "\n",
    "# inputs = prepare_input(\n",
    "#     prompts = prompt,\n",
    "#     tokenizer=mt,\n",
    "#     add_bos_token=False\n",
    "# )\n",
    "\n",
    "# generation = mt._model.generate(\n",
    "#     **inputs,\n",
    "#     max_new_tokens=100,\n",
    "#     top_k = 1\n",
    "# )\n",
    "\n",
    "# print(mt.tokenizer.decode(generation[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Walk the Line - a movie where Joaquin Phoenix played the role of Johnny Cash.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_bridge_entity\n",
    "\n",
    "predicted_ans = predict_bridge_entity(mt, prompt)\n",
    "predicted_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:22:00 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Joaquin Phoenix and Johnny Cash?\"\\nAnd the model gave the following answer:\\n\"Walk the Line - a movie where Joaquin Phoenix played the role of Johnny Cash.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:22:00 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:22:00 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:22:00 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe770e9c410>\n",
      "2024-07-30 15:22:00 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:22:00 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe770e9c510>\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:22:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'264'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ab26cc386f800c6563e785b1dffb192f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0qf6u7XahS9CoJuMWzi14UXyi4533fPCGxgggvB8.ho-1722367320-1.0.1.1-dJjEDMoiGc_zOQIXxWu.DA7nqdvG5QI8kI6oUDWl9NJr_SrgKYGpEBWbh7DyTEtxR5skENd2bPTW1xwBS8jVAw; path=/; expires=Tue, 30-Jul-24 19:52:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=CG3W9eXdpYeQyczFkcGdRf57PY1NmpfYxRnK2HA.Ty8-1722367320725-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7b7081c684ce4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:22:00 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:22:00 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:22:00 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Tue, 30 Jul 2024 19:22:00 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('openai-organization', 'bau-lab-1'), ('openai-processing-ms', '264'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=15552000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '30000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '29995890'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_ab26cc386f800c6563e785b1dffb192f'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0qf6u7XahS9CoJuMWzi14UXyi4533fPCGxgggvB8.ho-1722367320-1.0.1.1-dJjEDMoiGc_zOQIXxWu.DA7nqdvG5QI8kI6oUDWl9NJr_SrgKYGpEBWbh7DyTEtxR5skENd2bPTW1xwBS8jVAw; path=/; expires=Tue, 30-Jul-24 19:52:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=CG3W9eXdpYeQyczFkcGdRf57PY1NmpfYxRnK2HA.Ty8-1722367320725-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8ab7b7081c684ce4-BOS'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:22:00 openai._base_client DEBUG    request_id: req_ab26cc386f800c6563e785b1dffb192f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import ask_gpt4o\n",
    "\n",
    "query_sample = dataset.examples[sample_idx]\n",
    "ask_gpt4o(query_sample, predicted_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:23:34 src.functional DEBUG    found cached gpt4o response for b012d2090ae14428fedf73e25cd713f9 - loading\n",
      "2024-07-30 15:23:34 src.functional INFO     ['Iceman', 'Killer Frost'] <> ice control | predicted:  DC Comics - both characters Iceman and Killer Frost are part of the DC Comics universe.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/119 [00:06<13:36,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:23:40 src.functional DEBUG    found cached gpt4o response for 19123a86bec093698cfa8554d112e4b2 - loading\n",
      "2024-07-30 15:23:40 src.functional INFO     ['Human Torch', 'Firestorm'] <> fire control | predicted:  Fire manipulation - a superpower that both characters Human Torch and Firestorm possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/119 [00:13<12:42,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:23:46 src.functional DEBUG    found cached gpt4o response for 3f76eeafb445e14c50983172b7275c48 - loading\n",
      "2024-07-30 15:23:46 src.functional INFO     ['Philip Seymour Hoffman', 'Truman Capote'] <> Capote | predicted:  Capote - a movie where Philip Seymour Hoffman played the role of Truman Capote.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/119 [00:19<12:17,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:23:55 src.functional DEBUG    found cached gpt4o response for d996d44a1eda3fb9fd8e05ff8d985877 - loading\n",
      "2024-07-30 15:23:55 src.functional INFO     ['Liam Neeson', 'Oskar Schindler'] <> Schindler's List | predicted:  Schindler's List - a movie where Liam Neeson played the role of Oskar Schindler.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/119 [00:28<14:01,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:01 src.functional DEBUG    found cached gpt4o response for a7699841dea30b9afc8feb985fac8a22 - loading\n",
      "2024-07-30 15:24:01 src.functional INFO     ['Hulk Hogan', 'The Rock'] <> wrestling | predicted:  Professional wrestling - a sport where both players Hulk Hogan and The Rock are known for.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/119 [00:34<13:11,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:10 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Michael Vaughan and Sourav Ganguly?\"\\nAnd the model gave the following answer:\\n\"England and India - both players Michael Vaughan and Sourav Ganguly have played cricket for their respective national teams England and India.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:24:10 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:24:10 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:24:10 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd933c50>\n",
      "2024-07-30 15:24:10 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:24:10 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd94bd50>\n",
      "2024-07-30 15:24:10 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:10 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:24:10 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:10 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:24:10 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:12 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:24:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1556'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995874'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_f3448fe13aaf9a79a7ea4525c40c1517'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ba374fe88faf-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:24:12 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:24:12 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:12 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:24:12 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:24:12 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:24:12 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:24:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1556', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995874', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_f3448fe13aaf9a79a7ea4525c40c1517', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ba374fe88faf-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:24:12 openai._base_client DEBUG    request_id: req_f3448fe13aaf9a79a7ea4525c40c1517\n",
      "2024-07-30 15:24:12 src.functional INFO     ['Michael Vaughan', 'Sourav Ganguly'] <> cricket | predicted:  England and India - both players Michael Vaughan and Sourav Ganguly have played cricket for their respective national teams England and India.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6/119 [00:45<15:38,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:20 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Eddie Redmayne and Lili Elbe?\"\\nAnd the model gave the following answer:\\n\"The Danish Girl - a movie where Eddie Redmayne played the role of Lili Elbe.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:24:20 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:24:20 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:24:20 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:24:20 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:24:20 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd94bd50>\n",
      "2024-07-30 15:24:20 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:24:20 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd94be10>\n",
      "2024-07-30 15:24:20 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:20 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:24:20 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:20 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:24:20 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:21 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:24:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'213'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_1c87f2bb62b4dd6f644f2456e67746db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ba75f9748fc4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:24:21 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:24:21 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:21 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:24:21 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:24:21 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:24:21 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:24:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '213', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_1c87f2bb62b4dd6f644f2456e67746db', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ba75f9748fc4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:24:21 openai._base_client DEBUG    request_id: req_1c87f2bb62b4dd6f644f2456e67746db\n",
      "2024-07-30 15:24:21 src.functional INFO     ['Eddie Redmayne', 'Lili Elbe'] <> The Danish Girl | predicted:  The Danish Girl - a movie where Eddie Redmayne played the role of Lili Elbe.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7/119 [00:53<15:38,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:29 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between George C. Scott and General George S. Patton?\"\\nAnd the model gave the following answer:\\n\"General George S. Patton - a historical figure who was portrayed by George C. Scott in the movie Patton.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:24:29 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:24:29 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:24:29 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:24:29 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:24:29 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd4bb5d0>\n",
      "2024-07-30 15:24:29 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:24:29 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd94b450>\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:24:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'288'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995880'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ba60a9107862d708669ef1fc72dc073c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7baaa2af13b9a-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:24:29 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:24:29 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:24:29 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:24:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '288', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995880', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ba60a9107862d708669ef1fc72dc073c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7baaa2af13b9a-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:24:29 openai._base_client DEBUG    request_id: req_ba60a9107862d708669ef1fc72dc073c\n",
      "2024-07-30 15:24:29 src.functional INFO     ['George C. Scott', 'General George S. Patton'] <> Patton | predicted:  General George S. Patton - a historical figure who was portrayed by George C. Scott in the movie Patton.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8/119 [01:02<15:31,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:36 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between James Franco and Aron Ralston?\"\\nAnd the model gave the following answer:\\n\"127 Hours - a movie where James Franco played the role of Aron Ralston.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:24:36 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:24:36 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:24:36 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:24:36 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:24:36 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bcd073d0>\n",
      "2024-07-30 15:24:36 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:24:36 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd94b190>\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:24:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995893'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_9cde4143c74d6714a6126da5229c05f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bad818a88f7f-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:24:36 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:24:36 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:24:36 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:24:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '118', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995893', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_9cde4143c74d6714a6126da5229c05f6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bad818a88f7f-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:24:36 openai._base_client DEBUG    request_id: req_9cde4143c74d6714a6126da5229c05f6\n",
      "2024-07-30 15:24:36 src.functional INFO     ['James Franco', 'Aron Ralston'] <> 127 Hours | predicted:  127 Hours - a movie where James Franco played the role of Aron Ralston.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9/119 [01:09<14:45,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:44 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between 8 House and Via 57 West?\"\\nAnd the model gave the following answer:\\n\"Frank Gehry - who was the architect of both buildings 8 House and Via 57 West.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:24:44 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:24:44 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:24:44 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:24:44 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:24:44 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc82dc90>\n",
      "2024-07-30 15:24:44 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:24:44 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc30a8d0>\n",
      "2024-07-30 15:24:44 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:44 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:24:44 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:44 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:24:44 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:45 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:24:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'868'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_373e1561b7bea723e31a1681aef7f67e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bb0b081c8f69-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:24:45 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:24:45 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:45 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:24:45 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:24:45 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:24:45 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:24:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '868', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_373e1561b7bea723e31a1681aef7f67e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bb0b081c8f69-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:24:45 openai._base_client DEBUG    request_id: req_373e1561b7bea723e31a1681aef7f67e\n",
      "2024-07-30 15:24:45 src.functional INFO     ['8 House', 'Via 57 West'] <> Bjarke Ingels | predicted:  Frank Gehry - who was the architect of both buildings 8 House and Via 57 West.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/119 [01:18<15:06,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:24:53 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Taraji P. Henson and Katherine Johnson?\"\\nAnd the model gave the following answer:\\n\"Hidden Figures - a movie where both actresses Taraji P. Henson and Katherine Johnson were portrayed.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:24:53 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:24:53 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:24:53 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:24:53 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:24:53 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bd933c50>\n",
      "2024-07-30 15:24:53 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:24:53 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bcd073d0>\n",
      "2024-07-30 15:24:53 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:53 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:24:53 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:53 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:24:53 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:54 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:24:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'837'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995882'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_5aad6e00f6a40aa14a09697effecc009'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bb3f79778f66-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:24:54 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:24:54 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:24:54 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:24:54 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:24:54 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:24:54 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:24:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '837', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995882', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_5aad6e00f6a40aa14a09697effecc009', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bb3f79778f66-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:24:54 openai._base_client DEBUG    request_id: req_5aad6e00f6a40aa14a09697effecc009\n",
      "2024-07-30 15:24:54 src.functional INFO     ['Taraji P. Henson', 'Katherine Johnson'] <> Hidden Figures | predicted:  Hidden Figures - a movie where both actresses Taraji P. Henson and Katherine Johnson were portrayed.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11/119 [01:26<14:58,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:01 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Will Smith and Chris Gardner?\"\\nAnd the model gave the following answer:\\n\"Pursuit of Happyness - a movie where Will Smith played the role of Chris Gardner.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:01 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:01 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:01 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:01 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:01 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bcd073d0>\n",
      "2024-07-30 15:25:01 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:01 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc82dc90>\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'151'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_66a968557ca77f1c22176b123c70ff5e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bb718b773b70-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:01 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:01 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:01 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '151', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_66a968557ca77f1c22176b123c70ff5e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bb718b773b70-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:01 openai._base_client DEBUG    request_id: req_66a968557ca77f1c22176b123c70ff5e\n",
      "2024-07-30 15:25:01 src.functional INFO     ['Will Smith', 'Chris Gardner'] <> The Pursuit of Happyness | predicted:  Pursuit of Happyness - a movie where Will Smith played the role of Chris Gardner.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 12/119 [01:34<14:14,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:08 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Russell Crowe and John Nash?\"\\nAnd the model gave the following answer:\\n\"A Beautiful Mind - a movie where Russell Crowe played the role of John Nash.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:08 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:08 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:08 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:08 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:08 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc3eaad0>\n",
      "2024-07-30 15:25:08 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:08 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6859eb290>\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'182'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_674e262e9964f9e7334e5703a55e7582'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bb9dafee306b-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:08 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:08 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:08 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '182', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_674e262e9964f9e7334e5703a55e7582', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bb9dafee306b-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:08 openai._base_client DEBUG    request_id: req_674e262e9964f9e7334e5703a55e7582\n",
      "2024-07-30 15:25:08 src.functional INFO     ['Russell Crowe', 'John Nash'] <> A Beautiful Mind | predicted:  A Beautiful Mind - a movie where Russell Crowe played the role of John Nash.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 13/119 [01:41<13:37,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:15 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Eddie Redmayne and Stephen Hawking?\"\\nAnd the model gave the following answer:\\n\"The Theory of Everything - a movie where Eddie Redmayne played the role of Stephen Hawking.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:15 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:15 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:15 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:15 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:15 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6859eb290>\n",
      "2024-07-30 15:25:15 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:15 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc3e9510>\n",
      "2024-07-30 15:25:15 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:15 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:15 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:15 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:15 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:16 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_bf2993b24aeff744eecd2ac6610eb752'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bbcd1b028fdf-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:16 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:16 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:16 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:16 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:16 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:16 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '107', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_bf2993b24aeff744eecd2ac6610eb752', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bbcd1b028fdf-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:16 openai._base_client DEBUG    request_id: req_bf2993b24aeff744eecd2ac6610eb752\n",
      "2024-07-30 15:25:16 src.functional INFO     ['Eddie Redmayne', 'Stephen Hawking'] <> The Theory of Everything | predicted:  The Theory of Everything - a movie where Eddie Redmayne played the role of Stephen Hawking.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 14/119 [01:48<13:26,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:24 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Woody Harrelson and Larry Flynt?\"\\nAnd the model gave the following answer:\\n\"The People vs. Larry Flynt - a movie where Woody Harrelson played the role of Larry Flynt.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:24 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:24 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:24 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:24 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:24 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe684d479d0>\n",
      "2024-07-30 15:25:24 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:24 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6847df590>\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'337'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995886'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_d3f9b4fec6cfed47d798f8bd22228f61'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bc0369924cfe-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:24 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:24 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:24 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '337', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995886', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_d3f9b4fec6cfed47d798f8bd22228f61', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bc0369924cfe-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:24 openai._base_client DEBUG    request_id: req_d3f9b4fec6cfed47d798f8bd22228f61\n",
      "2024-07-30 15:25:24 src.functional INFO     ['Woody Harrelson', 'Larry Flynt'] <> The People vs. Larry Flynt | predicted:  The People vs. Larry Flynt - a movie where Woody Harrelson played the role of Larry Flynt.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 15/119 [01:57<13:56,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:31 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Turning Torso and Milwaukee Art Museum?\"\\nAnd the model gave the following answer:\\n\"Santiago Calatrava - who designed both buildings Turning Torso and Milwaukee Art Museum.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:31 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:31 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:31 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:31 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:31 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6847df590>\n",
      "2024-07-30 15:25:31 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:31 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe684d479d0>\n",
      "2024-07-30 15:25:31 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:31 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:31 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:31 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:31 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:32 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1075'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2a627f65d525125c4baacc9b78e235d6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bc2d9d274cde-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:32 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:32 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:32 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:32 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:32 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:32 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1075', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2a627f65d525125c4baacc9b78e235d6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bc2d9d274cde-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:32 openai._base_client DEBUG    request_id: req_2a627f65d525125c4baacc9b78e235d6\n",
      "2024-07-30 15:25:32 src.functional INFO     ['Turning Torso', 'Milwaukee Art Museum'] <> Santiago Calatrava | predicted:  Santiago Calatrava - who designed both buildings Turning Torso and Milwaukee Art Museum.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 16/119 [02:05<13:29,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:38 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Storm and Aang?\"\\nAnd the model gave the following answer:\\n\"elemental control - a superpower that both characters Storm and Aang possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:38 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:38 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:38 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:38 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:38 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc752f50>\n",
      "2024-07-30 15:25:38 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:38 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe684079410>\n",
      "2024-07-30 15:25:38 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:38 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:38 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:38 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:38 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:39 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'350'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_86c0f3c0ae5eb1ad8c3f5bfeb6f43ac2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bc5bbfdb904d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:39 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:39 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:39 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:39 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:39 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:39 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '350', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_86c0f3c0ae5eb1ad8c3f5bfeb6f43ac2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bc5bbfdb904d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:39 openai._base_client DEBUG    request_id: req_86c0f3c0ae5eb1ad8c3f5bfeb6f43ac2\n",
      "2024-07-30 15:25:39 src.functional INFO     ['Storm', 'Aang'] <> elemental control | predicted:  elemental control - a superpower that both characters Storm and Aang possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 17/119 [02:11<12:49,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:45 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Joaquin Phoenix and Johnny Cash?\"\\nAnd the model gave the following answer:\\n\"Walk the Line - a movie where Joaquin Phoenix played the role of Johnny Cash.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:45 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:45 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:45 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:45 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:45 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe684079410>\n",
      "2024-07-30 15:25:45 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:45 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc751c10>\n",
      "2024-07-30 15:25:45 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:45 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:45 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:45 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:45 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:46 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'194'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_e7c1ff127ac3c95b6404ece225b7f03e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bc88cd2b3b7b-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:46 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:46 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:46 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:46 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:46 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:46 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '194', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_e7c1ff127ac3c95b6404ece225b7f03e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bc88cd2b3b7b-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:46 openai._base_client DEBUG    request_id: req_e7c1ff127ac3c95b6404ece225b7f03e\n",
      "2024-07-30 15:25:46 src.functional INFO     ['Joaquin Phoenix', 'Johnny Cash'] <> Walk the Line | predicted:  Walk the Line - a movie where Joaquin Phoenix played the role of Johnny Cash.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 18/119 [02:18<12:26,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:51 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Cable and Trunks?\"\\nAnd the model gave the following answer:\\n\"telepathic connection - a trait that both characters Cable and Trunks possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:51 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:51 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:51 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:51 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:51 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc751c10>\n",
      "2024-07-30 15:25:51 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:52 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc3ec310>\n",
      "2024-07-30 15:25:52 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:52 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:52 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:52 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:52 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:53 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1360'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995894'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ee7f54e3f5514b28bb44cf11a525ef49'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bcb00c704d17-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:53 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:53 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:53 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:53 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:53 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:53 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1360', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995894', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ee7f54e3f5514b28bb44cf11a525ef49', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bcb00c704d17-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:53 openai._base_client DEBUG    request_id: req_ee7f54e3f5514b28bb44cf11a525ef49\n",
      "2024-07-30 15:25:53 src.functional INFO     ['Cable', 'Trunks'] <> time traveler | predicted:  telepathic connection - a trait that both characters Cable and Trunks possess.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 19/119 [02:26<12:20,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:25:59 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Professor X and Jean Grey?\"\\nAnd the model gave the following answer:\\n\"telepathy - a power that both characters Professor X and Jean Grey possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:25:59 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:25:59 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:25:59 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:25:59 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:25:59 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe665154090>\n",
      "2024-07-30 15:25:59 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:25:59 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe664f4e350>\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:25:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995892'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_a9e91115b6c81930654ecef2d796bc88'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bcdf38a58fdf-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:25:59 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:25:59 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:25:59 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:25:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '118', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995892', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_a9e91115b6c81930654ecef2d796bc88', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bcdf38a58fdf-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:25:59 openai._base_client DEBUG    request_id: req_a9e91115b6c81930654ecef2d796bc88\n",
      "2024-07-30 15:25:59 src.functional INFO     ['Professor X', 'Jean Grey'] <> telepath | predicted:  telepathy - a power that both characters Professor X and Jean Grey possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 20/119 [02:32<11:40,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:05 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Punisher and Red Hood?\"\\nAnd the model gave the following answer:\\n\"vigilante - a character archetype that both characters Punisher and Red Hood embody.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:05 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:05 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:05 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:05 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:05 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe664f4e350>\n",
      "2024-07-30 15:26:05 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:05 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc751c10>\n",
      "2024-07-30 15:26:05 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:05 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:05 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:05 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:05 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:06 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'315'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_7d3c804ad81a22a065a6cc4299debe0f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bd05fbfd8fa8-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:06 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:06 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:06 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:06 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:06 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:06 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '315', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_7d3c804ad81a22a065a6cc4299debe0f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bd05fbfd8fa8-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:06 openai._base_client DEBUG    request_id: req_7d3c804ad81a22a065a6cc4299debe0f\n",
      "2024-07-30 15:26:06 src.functional INFO     ['Punisher', 'Red Hood'] <> anti-hero | predicted:  vigilante - a character archetype that both characters Punisher and Red Hood embody.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 21/119 [02:38<11:09,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:13 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between The Shard and New York Times Building?\"\\nAnd the model gave the following answer:\\n\"Renzo Piano - who was the architect of both buildings The Shard and New York Times Building.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:13 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:13 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:13 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:13 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:13 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe664be4e90>\n",
      "2024-07-30 15:26:13 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:13 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe66455e2d0>\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'559'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_db7018ffb5a30c93af8dc95a05aea7f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bd338afe8f7b-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:13 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:13 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:13 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '559', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_db7018ffb5a30c93af8dc95a05aea7f6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bd338afe8f7b-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:13 openai._base_client DEBUG    request_id: req_db7018ffb5a30c93af8dc95a05aea7f6\n",
      "2024-07-30 15:26:13 src.functional INFO     ['The Shard', 'New York Times Building'] <> Renzo Piano | predicted:  Renzo Piano - who was the architect of both buildings The Shard and New York Times Building.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 22/119 [02:46<11:28,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:19 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Julia Roberts and Erin Brockovich?\"\\nAnd the model gave the following answer:\\n\"Erin Brockovich - a movie where Julia Roberts played the title role.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:19 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:19 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:19 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:19 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:19 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe6bc8b5ad0>\n",
      "2024-07-30 15:26:19 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:19 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe664bf4590>\n",
      "2024-07-30 15:26:19 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:19 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:19 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:19 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:19 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:20 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_1c2652cf3e044d3d73afbd7eee0243eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bd5e3cb78fbb-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:20 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:20 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:20 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:20 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:20 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:20 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '418', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_1c2652cf3e044d3d73afbd7eee0243eb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bd5e3cb78fbb-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:20 openai._base_client DEBUG    request_id: req_1c2652cf3e044d3d73afbd7eee0243eb\n",
      "2024-07-30 15:26:20 src.functional INFO     ['Julia Roberts', 'Erin Brockovich'] <> Erin Brockovich | predicted:  Erin Brockovich - a movie where Julia Roberts played the title role.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 23/119 [02:53<11:07,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:25 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Thor and Wonder Woman?\"\\nAnd the model gave the following answer:\\n\"superhero - a genre where both characters Thor and Wonder Woman belong.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:25 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:25 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:25 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:25 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:25 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:25 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:26 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'998'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_5fa6967a02cf5d8b764bba9cc2df76f4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bd8018348fbb-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:26 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:26 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:26 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:26 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:26 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:26 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '998', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_5fa6967a02cf5d8b764bba9cc2df76f4', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bd8018348fbb-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:26 openai._base_client DEBUG    request_id: req_5fa6967a02cf5d8b764bba9cc2df76f4\n",
      "2024-07-30 15:26:26 src.functional INFO     ['Thor', 'Wonder Woman'] <> alien warrior | predicted:  superhero - a genre where both characters Thor and Wonder Woman belong.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 24/119 [02:59<10:30,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:35 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Niterói Contemporary Art Museum and Cathedral of Brasília?\"\\nAnd the model gave the following answer:\\n\"Oscar Niemeyer - who was the architect of both buildings Niterói Contemporary Art Museum and Cathedral of Brasília.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:35 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:35 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:35 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:35 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:35 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe664113190>\n",
      "2024-07-30 15:26:35 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:35 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe66544b490>\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'287'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995874'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_06de78085b5725b9f9b2106694e0b774'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bdbdae31901d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:35 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:35 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:35 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '287', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995874', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_06de78085b5725b9f9b2106694e0b774', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bdbdae31901d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:35 openai._base_client DEBUG    request_id: req_06de78085b5725b9f9b2106694e0b774\n",
      "2024-07-30 15:26:35 src.functional INFO     ['Niterói Contemporary Art Museum', 'Cathedral of Brasília'] <> Oscar Niemeyer | predicted:  Oscar Niemeyer - who was the architect of both buildings Niterói Contemporary Art Museum and Cathedral of Brasília.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 25/119 [03:08<11:34,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:42 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Ma Long and Zhang Jike?\"\\nAnd the model gave the following answer:\\n\"table tennis - a sport where both players Ma Long and Zhang Jike are professional players.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:42 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:42 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:42 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:42 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:42 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe66544b490>\n",
      "2024-07-30 15:26:42 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:42 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64b7c8810>\n",
      "2024-07-30 15:26:42 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:42 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:42 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:42 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:42 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:43 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'600'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_dc74b3fe53a12f558aed33b50211d986'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bde9a821904a-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:43 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:43 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:43 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:43 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:43 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:43 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '600', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_dc74b3fe53a12f558aed33b50211d986', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bde9a821904a-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:43 openai._base_client DEBUG    request_id: req_dc74b3fe53a12f558aed33b50211d986\n",
      "2024-07-30 15:26:43 src.functional INFO     ['Ma Long', 'Zhang Jike'] <> table tennis | predicted:  table tennis - a sport where both players Ma Long and Zhang Jike are professional players.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 26/119 [03:15<11:29,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:50 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Lionel Messi and Cristiano Ronaldo?\"\\nAnd the model gave the following answer:\\n\"FIFA World Player of the Year - an award that both players Lionel Messi and Cristiano Ronaldo have won.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:50 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:50 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:50 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:50 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:50 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64b7dbd90>\n",
      "2024-07-30 15:26:50 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:50 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe66455e2d0>\n",
      "2024-07-30 15:26:50 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:50 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:50 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:50 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:50 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:51 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'981'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995882'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_a4619d4d50487cf14a1f6ed71d8efdee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7be1c5f383031-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:51 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:51 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:51 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:51 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:51 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:51 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '981', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995882', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_a4619d4d50487cf14a1f6ed71d8efdee', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7be1c5f383031-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:51 openai._base_client DEBUG    request_id: req_a4619d4d50487cf14a1f6ed71d8efdee\n",
      "2024-07-30 15:26:51 src.functional INFO     ['Lionel Messi', 'Cristiano Ronaldo'] <> soccer | predicted:  FIFA World Player of the Year - an award that both players Lionel Messi and Cristiano Ronaldo have won.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 27/119 [03:24<11:51,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:26:58 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Susan Storm and Invisible Woman?\"\\nAnd the model gave the following answer:\\n\"The Fantastic Four - a superhero team where both characters Susan Storm and Invisible Woman are members.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:26:58 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:26:58 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:26:58 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:26:58 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:26:58 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe66455e2d0>\n",
      "2024-07-30 15:26:58 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:26:58 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64b7c8810>\n",
      "2024-07-30 15:26:58 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:58 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:26:58 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:58 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:26:58 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:59 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:26:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'420'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995884'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ab26ccd6ff1d93c939ee7a9a26977c07'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7be529fc23b99-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:26:59 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:26:59 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:26:59 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:26:59 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:26:59 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:26:59 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:26:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '420', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995884', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ab26ccd6ff1d93c939ee7a9a26977c07', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7be529fc23b99-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:26:59 openai._base_client DEBUG    request_id: req_ab26ccd6ff1d93c939ee7a9a26977c07\n",
      "2024-07-30 15:26:59 src.functional INFO     ['Susan Storm', 'Invisible Woman'] <> invisibility | predicted:  The Fantastic Four - a superhero team where both characters Susan Storm and Invisible Woman are members.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 28/119 [03:32<11:54,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:05 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Michael Jordan and LeBron James?\"\\nAnd the model gave the following answer:\\n\"NBA - a professional basketball league where both players Michael Jordan and LeBron James have played.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:05 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:05 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:05 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:05 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:05 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64a373150>\n",
      "2024-07-30 15:27:05 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:05 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64a8d6190>\n",
      "2024-07-30 15:27:05 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:05 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:05 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:05 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:05 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:06 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'93'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995884'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_6b285ccb30b3d418b28162d7ab1fa22f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7be7da94f3035-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:06 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:06 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:06 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:06 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:06 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:06 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '93', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995884', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_6b285ccb30b3d418b28162d7ab1fa22f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7be7da94f3035-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:06 openai._base_client DEBUG    request_id: req_6b285ccb30b3d418b28162d7ab1fa22f\n",
      "2024-07-30 15:27:06 src.functional INFO     ['Michael Jordan', 'LeBron James'] <> basketball | predicted:  NBA - a professional basketball league where both players Michael Jordan and LeBron James have played.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 29/119 [03:38<11:12,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:13 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Unité d\\'Habitation and Notre Dame du Haut?\"\\nAnd the model gave the following answer:\\n\"Le Corbusier - who designed both buildings Unité d\\'Habitation and Notre Dame du Haut.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:13 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:13 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:13 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:13 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:13 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64a8d6190>\n",
      "2024-07-30 15:27:13 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:13 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64a74b490>\n",
      "2024-07-30 15:27:13 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:13 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:13 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:13 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:13 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:14 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'700'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_9e225a51a1f39f35093f96205c423f70'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7beafec128fdb-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:14 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:14 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:14 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:14 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:14 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:14 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '700', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_9e225a51a1f39f35093f96205c423f70', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7beafec128fdb-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:14 openai._base_client DEBUG    request_id: req_9e225a51a1f39f35093f96205c423f70\n",
      "2024-07-30 15:27:14 src.functional INFO     [\"Unité d'Habitation\", 'Notre Dame du Haut'] <> Le Corbusier | predicted:  Le Corbusier - who designed both buildings Unité d'Habitation and Notre Dame du Haut.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 30/119 [03:47<11:35,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:23 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Guggenheim Museum Bilbao and Walt Disney Concert Hall?\"\\nAnd the model gave the following answer:\\n\"Frank Gehry - who was the architect of both buildings Guggenheim Museum Bilbao and Walt Disney Concert Hall.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:23 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:23 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:23 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:23 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:23 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64a74b490>\n",
      "2024-07-30 15:27:23 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:23 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62bd1f550>\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995876'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2a81f45b5f4ceb01298b5633f8141ec1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7beea29ad9023-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:23 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:23 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:23 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '444', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995876', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2a81f45b5f4ceb01298b5633f8141ec1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7beea29ad9023-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:23 openai._base_client DEBUG    request_id: req_2a81f45b5f4ceb01298b5633f8141ec1\n",
      "2024-07-30 15:27:23 src.functional INFO     ['Guggenheim Museum Bilbao', 'Walt Disney Concert Hall'] <> Frank Gehry | predicted:  Frank Gehry - who was the architect of both buildings Guggenheim Museum Bilbao and Walt Disney Concert Hall.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 31/119 [03:56<12:02,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:31 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Lin Dan and Lee Chong Wei?\"\\nAnd the model gave the following answer:\\n\"badminton - a sport where both players Lin Dan and Lee Chong Wei are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:31 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:31 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:31 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:31 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:31 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62b6fe2d0>\n",
      "2024-07-30 15:27:31 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:31 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62b0a7a90>\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_da8d9c031bb4a6760e4536e601c85c9d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bf1bec6d4cc8-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:31 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:31 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:31 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '381', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_da8d9c031bb4a6760e4536e601c85c9d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bf1bec6d4cc8-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:31 openai._base_client DEBUG    request_id: req_da8d9c031bb4a6760e4536e601c85c9d\n",
      "2024-07-30 15:27:31 src.functional INFO     ['Lin Dan', 'Lee Chong Wei'] <> badminton | predicted:  badminton - a sport where both players Lin Dan and Lee Chong Wei are known for.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 32/119 [04:04<11:45,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:37 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Superman and Homelander?\"\\nAnd the model gave the following answer:\\n\"superhero - a character type that both Superman and Homelander belong to.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:37 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:37 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:37 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:37 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:37 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62b0a1790>\n",
      "2024-07-30 15:27:37 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:37 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62acff3d0>\n",
      "2024-07-30 15:27:37 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:37 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:37 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:37 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:37 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:40 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'2459'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995894'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ea93258f82864f9bf0c3ba1b6be1885a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bf43be904ce0-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:40 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:40 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:40 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:40 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:40 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:40 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '2459', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995894', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ea93258f82864f9bf0c3ba1b6be1885a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bf43be904ce0-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:40 openai._base_client DEBUG    request_id: req_ea93258f82864f9bf0c3ba1b6be1885a\n",
      "2024-07-30 15:27:40 src.functional INFO     ['Superman', 'Homelander'] <> super strength | predicted:  superhero - a character type that both Superman and Homelander belong to.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 33/119 [04:12<11:41,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:47 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Scarlet Witch and Psylocke?\"\\nAnd the model gave the following answer:\\n\"telepathy - a superpower that both characters Scarlet Witch and Psylocke possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:47 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:47 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:47 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:47 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:47 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62acff3d0>\n",
      "2024-07-30 15:27:47 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:47 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62b0a70d0>\n",
      "2024-07-30 15:27:47 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:47 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:47 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:47 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:47 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:49 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1588'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_fa8de8a48e44d6126ef6142c74652601'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bf839cae904b-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:49 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:49 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:49 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:49 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:49 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:49 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1588', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_fa8de8a48e44d6126ef6142c74652601', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bf839cae904b-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:49 openai._base_client DEBUG    request_id: req_fa8de8a48e44d6126ef6142c74652601\n",
      "2024-07-30 15:27:49 src.functional INFO     ['Scarlet Witch', 'Psylocke'] <> telekinesis | predicted:  telepathy - a superpower that both characters Scarlet Witch and Psylocke possess.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 34/119 [04:22<12:06,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:27:56 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Usain Bolt and Carl Lewis?\"\\nAnd the model gave the following answer:\\n\"sprinting - a track and field event where both athletes Usain Bolt and Carl Lewis have excelled.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:27:56 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:27:56 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:27:56 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:27:56 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:27:56 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62b0a70d0>\n",
      "2024-07-30 15:27:56 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:27:56 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62a761850>\n",
      "2024-07-30 15:27:56 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:56 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:27:56 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:56 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:27:56 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:57 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:27:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995886'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_0046daef823fff5a7a0ba1297f14015a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bfbccfb58f79-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:27:57 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:27:57 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:27:57 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:27:57 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:27:57 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:27:57 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:27:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '105', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995886', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_0046daef823fff5a7a0ba1297f14015a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bfbccfb58f79-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:27:57 openai._base_client DEBUG    request_id: req_0046daef823fff5a7a0ba1297f14015a\n",
      "2024-07-30 15:27:57 src.functional INFO     ['Usain Bolt', 'Carl Lewis'] <> athletics | predicted:  sprinting - a track and field event where both athletes Usain Bolt and Carl Lewis have excelled.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 35/119 [04:30<11:37,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:03 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Black Canary and Black Bolt?\"\\nAnd the model gave the following answer:\\n\"Black - a color that both characters Black Canary and Black Bolt have in their names.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:03 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:03 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:03 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:03 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:03 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bc2d250>\n",
      "2024-07-30 15:28:03 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:03 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bc8fd90>\n",
      "2024-07-30 15:28:03 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:03 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:03 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:03 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:03 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:04 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'771'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_189bdf3d7b7f133617042e49e507b769'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7bfe4590c4ce1-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:04 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:04 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:04 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:04 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:04 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:04 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '771', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_189bdf3d7b7f133617042e49e507b769', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7bfe4590c4ce1-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:04 openai._base_client DEBUG    request_id: req_189bdf3d7b7f133617042e49e507b769\n",
      "2024-07-30 15:28:04 src.functional INFO     ['Black Canary', 'Black Bolt'] <> sonic scream | predicted:  Black - a color that both characters Black Canary and Black Bolt have in their names.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 36/119 [04:36<10:55,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:10 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Daredevil and Toph Beifong?\"\\nAnd the model gave the following answer:\\n\"martial arts - a skill that both characters Daredevil and Toph Beifong possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:10 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:10 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:10 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:10 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:10 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe664113190>\n",
      "2024-07-30 15:28:10 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:10 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62a1a3350>\n",
      "2024-07-30 15:28:10 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:10 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:10 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:10 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:10 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:12 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_039a3bbae399cf0dd485442472188131'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c0143cd88d17-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:12 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:12 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:12 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:12 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:12 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:12 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1117', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_039a3bbae399cf0dd485442472188131', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c0143cd88d17-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:12 openai._base_client DEBUG    request_id: req_039a3bbae399cf0dd485442472188131\n",
      "2024-07-30 15:28:12 src.functional INFO     ['Daredevil', 'Toph Beifong'] <> blind | predicted:  martial arts - a skill that both characters Daredevil and Toph Beifong possess.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 37/119 [04:44<10:49,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:18 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Meryl Streep and Julia Child?\"\\nAnd the model gave the following answer:\\n\"Julie & Julia - a movie where Meryl Streep played the role of Julia Child.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:18 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:18 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:18 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:18 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:18 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60b7af0d0>\n",
      "2024-07-30 15:28:18 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:18 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bc8fd90>\n",
      "2024-07-30 15:28:18 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:18 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:18 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:18 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:18 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:19 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'139'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_123340bfa38767d0e3a144728f162fad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c0462e8f8ff3-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:19 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:19 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:19 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:19 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:19 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:19 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '139', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_123340bfa38767d0e3a144728f162fad', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c0462e8f8ff3-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:19 openai._base_client DEBUG    request_id: req_123340bfa38767d0e3a144728f162fad\n",
      "2024-07-30 15:28:19 src.functional INFO     ['Meryl Streep', 'Julia Child'] <> Julie & Julia | predicted:  Julie & Julia - a movie where Meryl Streep played the role of Julia Child.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 38/119 [04:51<10:17,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:25 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Beast Boy and Vixen?\"\\nAnd the model gave the following answer:\\n\"Teen Titans - a superhero team where both characters Beast Boy and Vixen are members.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:25 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:25 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:25 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:25 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:25 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60b7af0d0>\n",
      "2024-07-30 15:28:25 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:25 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bc8f990>\n",
      "2024-07-30 15:28:25 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:25 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:25 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:25 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:25 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:27 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1399'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2fba4d9f0b7d21c538aca7e4fc51b5af'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c0715dd38fae-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:27 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:27 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:27 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:27 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:27 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:27 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1399', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2fba4d9f0b7d21c538aca7e4fc51b5af', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c0715dd38fae-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:27 openai._base_client DEBUG    request_id: req_2fba4d9f0b7d21c538aca7e4fc51b5af\n",
      "2024-07-30 15:28:27 src.functional INFO     ['Beast Boy', 'Vixen'] <> animal powers | predicted:  Teen Titans - a superhero team where both characters Beast Boy and Vixen are members.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 39/119 [05:00<10:25,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:33 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Green Arrow and Hawkeye?\"\\nAnd the model gave the following answer:\\n\"archery - a skill that both characters Green Arrow and Hawkeye possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:33 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:33 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:33 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:33 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:33 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bc8f990>\n",
      "2024-07-30 15:28:33 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:33 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60ac05cd0>\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995894'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_65d404848f1526c2c33d109475653ef1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c0a0aece9011-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:33 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:33 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:33 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '336', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995894', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_65d404848f1526c2c33d109475653ef1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c0a0aece9011-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:33 openai._base_client DEBUG    request_id: req_65d404848f1526c2c33d109475653ef1\n",
      "2024-07-30 15:28:33 src.functional INFO     ['Green Arrow', 'Hawkeye'] <> archer | predicted:  archery - a skill that both characters Green Arrow and Hawkeye possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 40/119 [05:06<09:46,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:40 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Babe Ruth and Hank Aaron?\"\\nAnd the model gave the following answer:\\n\"Home Run - a record that both players Babe Ruth and Hank Aaron hold.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:40 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:40 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:40 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:40 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:40 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60ac05cd0>\n",
      "2024-07-30 15:28:40 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:40 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bac4210>\n",
      "2024-07-30 15:28:40 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:40 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:40 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:40 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:40 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:42 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1260'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_a5e34fe0a217bbcd41ea95742e3280b6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c0ce3cd78fe4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:42 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:42 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:42 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:42 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:42 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:42 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1260', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_a5e34fe0a217bbcd41ea95742e3280b6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c0ce3cd78fe4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:42 openai._base_client DEBUG    request_id: req_a5e34fe0a217bbcd41ea95742e3280b6\n",
      "2024-07-30 15:28:42 src.functional INFO     ['Babe Ruth', 'Hank Aaron'] <> baseball | predicted:  Home Run - a record that both players Babe Ruth and Hank Aaron hold.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 41/119 [05:14<09:58,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:28:49 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Habitat 67 and Marina Bay Sands?\"\\nAnd the model gave the following answer:\\n\"Moshe Safdie - who was the architect of both buildings Habitat 67 and Marina Bay Sands.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:28:49 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:28:49 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:28:49 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:28:49 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:28:49 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60bac4210>\n",
      "2024-07-30 15:28:49 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:28:49 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60a4334d0>\n",
      "2024-07-30 15:28:49 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:49 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:28:49 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:49 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:28:49 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:51 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:28:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1579'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2f13c6ac6ce43a809b8b099a475b452c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c104bbf88fa9-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:28:51 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:28:51 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:28:51 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:28:51 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:28:51 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:28:51 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:28:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1579', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2f13c6ac6ce43a809b8b099a475b452c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c104bbf88fa9-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:28:51 openai._base_client DEBUG    request_id: req_2f13c6ac6ce43a809b8b099a475b452c\n",
      "2024-07-30 15:28:51 src.functional INFO     ['Habitat 67', 'Marina Bay Sands'] <> Moshe Safdie | predicted:  Moshe Safdie - who was the architect of both buildings Habitat 67 and Marina Bay Sands.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 42/119 [05:23<10:21,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:00 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Yuzuru Hanyu and Evgeni Plushenko?\"\\nAnd the model gave the following answer:\\n\"figure skating - a sport where both players Yuzuru Hanyu and Evgeni Plushenko are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:00 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:00 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:00 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:00 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:00 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe60b23d9d0>\n",
      "2024-07-30 15:29:00 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:00 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe64b7c8810>\n",
      "2024-07-30 15:29:00 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:00 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:00 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:00 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:00 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:01 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1154'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_85e1d2b9f92e998155fd45d635b6860f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c14a3ec88f85-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:01 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:01 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:01 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:01 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:01 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:01 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1154', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_85e1d2b9f92e998155fd45d635b6860f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c14a3ec88f85-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:01 openai._base_client DEBUG    request_id: req_85e1d2b9f92e998155fd45d635b6860f\n",
      "2024-07-30 15:29:01 src.functional INFO     ['Yuzuru Hanyu', 'Evgeni Plushenko'] <> figure skating | predicted:  figure skating - a sport where both players Yuzuru Hanyu and Evgeni Plushenko are known for.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 43/119 [05:34<11:14,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:08 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Tiger Woods and Phil Mickelson?\"\\nAnd the model gave the following answer:\\n\"golf - a sport where both players Tiger Woods and Phil Mickelson are professional golfers.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:08 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:08 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:08 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:08 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:08 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe62a1a3350>\n",
      "2024-07-30 15:29:08 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:08 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5eb2d2810>\n",
      "2024-07-30 15:29:08 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:08 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:08 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:08 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:08 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:09 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'379'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_17a76bda9b7b8e044adc187ec6282027'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c17c682c904d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:09 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:09 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:09 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:09 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:09 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:09 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '379', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_17a76bda9b7b8e044adc187ec6282027', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c17c682c904d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:09 openai._base_client DEBUG    request_id: req_17a76bda9b7b8e044adc187ec6282027\n",
      "2024-07-30 15:29:09 src.functional INFO     ['Tiger Woods', 'Phil Mickelson'] <> golf | predicted:  golf - a sport where both players Tiger Woods and Phil Mickelson are professional golfers.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 44/119 [05:41<10:27,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:15 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Reed Richards and Tony Stark?\"\\nAnd the model gave the following answer:\\n\"genius-level intellect - an attribute that both characters Reed Richards and Tony Stark possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:15 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:15 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:15 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:15 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:15 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5eb2d2810>\n",
      "2024-07-30 15:29:15 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:15 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5eb2a5b50>\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995886'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_866ce86218bca360870b33c1c4298e32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c1a53d6e8feb-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:15 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:15 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:15 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '100', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995886', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_866ce86218bca360870b33c1c4298e32', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c1a53d6e8feb-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:15 openai._base_client DEBUG    request_id: req_866ce86218bca360870b33c1c4298e32\n",
      "2024-07-30 15:29:15 src.functional INFO     ['Reed Richards', 'Tony Stark'] <> genius inventor | predicted:  genius-level intellect - an attribute that both characters Reed Richards and Tony Stark possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 45/119 [05:48<09:33,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:21 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Michael Phelps and Ryan Lochte?\"\\nAnd the model gave the following answer:\\n\"Swimming - a sport where both players Michael Phelps and Ryan Lochte are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:21 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:21 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:21 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:21 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:21 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5eb2a5b50>\n",
      "2024-07-30 15:29:21 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:21 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5eae86490>\n",
      "2024-07-30 15:29:21 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:21 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:21 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:21 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:21 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:22 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'597'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_faaba753c995563532606f62f3856cb3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c1cebdb28fbd-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:22 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:22 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:22 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:22 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:22 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:22 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '597', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_faaba753c995563532606f62f3856cb3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c1cebdb28fbd-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:22 openai._base_client DEBUG    request_id: req_faaba753c995563532606f62f3856cb3\n",
      "2024-07-30 15:29:22 src.functional INFO     ['Michael Phelps', 'Ryan Lochte'] <> swimming | predicted:  Swimming - a sport where both players Michael Phelps and Ryan Lochte are known for.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 46/119 [05:55<09:17,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:29 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Christian Bale and Michael Burry?\"\\nAnd the model gave the following answer:\\n\"The Big Short - a movie where Christian Bale played the role of Michael Burry.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:29 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:29 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:29 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:29 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:29 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ea86b5d0>\n",
      "2024-07-30 15:29:29 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:29 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ea337bd0>\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'134'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_1b255b7271408779282daa5f741be9f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c1fcebee3045-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:29 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:29 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:29 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '134', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_1b255b7271408779282daa5f741be9f5', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c1fcebee3045-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:29 openai._base_client DEBUG    request_id: req_1b255b7271408779282daa5f741be9f5\n",
      "2024-07-30 15:29:29 src.functional INFO     ['Christian Bale', 'Michael Burry'] <> The Big Short | predicted:  The Big Short - a movie where Christian Bale played the role of Michael Burry.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 47/119 [06:02<08:46,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:38 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Leonardo DiCaprio and Jordan Belfort?\"\\nAnd the model gave the following answer:\\n\"The Wolf of Wall Street - a movie where Leonardo DiCaprio played the role of Jordan Belfort.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:38 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:38 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:38 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:38 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:38 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ea355c90>\n",
      "2024-07-30 15:29:38 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:38 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cbef7e90>\n",
      "2024-07-30 15:29:38 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:38 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:38 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:38 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:38 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:39 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_c91ed0fd8e6588a10390d610a6b5e616'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c2394a3a4d13-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:39 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:39 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:39 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:39 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:39 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:39 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '112', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_c91ed0fd8e6588a10390d610a6b5e616', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c2394a3a4d13-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:39 openai._base_client DEBUG    request_id: req_c91ed0fd8e6588a10390d610a6b5e616\n",
      "2024-07-30 15:29:39 src.functional INFO     ['Leonardo DiCaprio', 'Jordan Belfort'] <> The Wolf of Wall Street | predicted:  The Wolf of Wall Street - a movie where Leonardo DiCaprio played the role of Jordan Belfort.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 48/119 [06:11<09:31,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:46 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Derek Luke and Patrick Chamusso?\"\\nAnd the model gave the following answer:\\n\"Catch a Fire - a movie where both actors Derek Luke and Patrick Chamusso played roles.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:46 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:46 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:46 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:46 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:46 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cbef7e90>\n",
      "2024-07-30 15:29:46 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:46 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ea266cd0>\n",
      "2024-07-30 15:29:46 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:46 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:46 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:46 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:46 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:47 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995888'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_dd3b96ccdebac1fd3efdd44b4e904fb5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c26789148fff-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:47 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:47 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:47 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:47 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:47 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:47 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1105', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995888', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_dd3b96ccdebac1fd3efdd44b4e904fb5', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c26789148fff-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:47 openai._base_client DEBUG    request_id: req_dd3b96ccdebac1fd3efdd44b4e904fb5\n",
      "2024-07-30 15:29:47 src.functional INFO     ['Derek Luke', 'Patrick Chamusso'] <> Catch a Fire | predicted:  Catch a Fire - a movie where both actors Derek Luke and Patrick Chamusso played roles.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 49/119 [06:20<09:29,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:29:53 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Michelle Williams and Marilyn Monroe?\"\\nAnd the model gave the following answer:\\n\"My Week with Marilyn - a movie where Michelle Williams played the role of Marilyn Monroe.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:29:53 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:29:53 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:29:53 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:29:53 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:29:53 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cba77090>\n",
      "2024-07-30 15:29:53 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:29:53 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb330ad0>\n",
      "2024-07-30 15:29:53 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:53 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:29:53 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:53 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:29:53 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:54 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:29:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_06c1801a14480493ad384900b582f599'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c296ffc29047-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:29:54 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:29:54 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:29:54 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:29:54 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:29:54 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:29:54 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:29:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '103', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_06c1801a14480493ad384900b582f599', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c296ffc29047-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:29:54 openai._base_client DEBUG    request_id: req_06c1801a14480493ad384900b582f599\n",
      "2024-07-30 15:29:54 src.functional INFO     ['Michelle Williams', 'Marilyn Monroe'] <> My Week with Marilyn | predicted:  My Week with Marilyn - a movie where Michelle Williams played the role of Marilyn Monroe.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 50/119 [06:26<08:50,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:01 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Jewish Museum Berlin and Denver Art Museum?\"\\nAnd the model gave the following answer:\\n\"Daniel Libeskind - who was the architect of both buildings Jewish Museum Berlin and Denver Art Museum.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:01 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:01 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:01 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:01 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:01 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5caeeef50>\n",
      "2024-07-30 15:30:01 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:01 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb330ad0>\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995881'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_dc30acda2b8162ae79a1f4e25dd2d28d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c2c71d368f87-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:01 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:01 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:01 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '100', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995881', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_dc30acda2b8162ae79a1f4e25dd2d28d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c2c71d368f87-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:01 openai._base_client DEBUG    request_id: req_dc30acda2b8162ae79a1f4e25dd2d28d\n",
      "2024-07-30 15:30:01 src.functional INFO     ['Jewish Museum Berlin', 'Denver Art Museum'] <> Daniel Libeskind | predicted:  Daniel Libeskind - who was the architect of both buildings Jewish Museum Berlin and Denver Art Museum.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 51/119 [06:34<08:43,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:08 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Glass House and AT&T Building?\"\\nAnd the model gave the following answer:\\n\"Philip Johnson - who was the architect of both buildings Glass House and AT&T Building.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:08 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:08 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:08 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:08 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:08 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5caef4310>\n",
      "2024-07-30 15:30:08 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:08 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb356990>\n",
      "2024-07-30 15:30:08 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:08 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:08 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:08 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:08 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:09 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'872'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995888'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2c41717099c3aba618cb40622cad494c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c2f0fb418ffd-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:09 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:09 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:09 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:09 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:09 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:09 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '872', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995888', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2c41717099c3aba618cb40622cad494c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c2f0fb418ffd-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:09 openai._base_client DEBUG    request_id: req_2c41717099c3aba618cb40622cad494c\n",
      "2024-07-30 15:30:09 src.functional INFO     ['Glass House', 'AT&T Building'] <> Philip Johnson | predicted:  Philip Johnson - who was the architect of both buildings Glass House and AT&T Building.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 52/119 [06:42<08:31,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:16 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Garry Kasparov and Magnus Carlsen?\"\\nAnd the model gave the following answer:\\n\"Chess - a game where both players Garry Kasparov and Magnus Carlsen are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:16 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:16 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:16 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:16 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:16 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ca94b490>\n",
      "2024-07-30 15:30:16 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:16 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ca488910>\n",
      "2024-07-30 15:30:16 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:16 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:16 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:16 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:16 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:17 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'470'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b1b45b18ef571e7e2cfc863f40495d88'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c3268a2d8f6e-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:17 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:17 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:17 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:17 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:17 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:17 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '470', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b1b45b18ef571e7e2cfc863f40495d88', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c3268a2d8f6e-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:17 openai._base_client DEBUG    request_id: req_b1b45b18ef571e7e2cfc863f40495d88\n",
      "2024-07-30 15:30:17 src.functional INFO     ['Garry Kasparov', 'Magnus Carlsen'] <> chess | predicted:  Chess - a game where both players Garry Kasparov and Magnus Carlsen are known for.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 53/119 [06:50<08:34,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:28 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Robert De Niro and Al Capone?\"\\nAnd the model gave the following answer:\\n\"Raging Bull - a movie where Robert De Niro played the role of Jake LaMotta, a boxer who was inspired by Al Capone.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:28 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:28 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:28 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:28 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:28 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb330ad0>\n",
      "2024-07-30 15:30:28 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:28 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ca94b490>\n",
      "2024-07-30 15:30:28 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:28 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:28 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:28 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:28 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:30 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1549'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995881'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b9dc325a2700f18ce4e19319215911a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c36eeb859008-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:30 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:30 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:30 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:30 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:30 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:30 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1549', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995881', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b9dc325a2700f18ce4e19319215911a9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c36eeb859008-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:30 openai._base_client DEBUG    request_id: req_b9dc325a2700f18ce4e19319215911a9\n",
      "2024-07-30 15:30:30 src.functional INFO     ['Robert De Niro', 'Al Capone'] <> The Untouchables | predicted:  Raging Bull - a movie where Robert De Niro played the role of Jake LaMotta, a boxer who was inspired by Al Capone.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 54/119 [07:02<09:59,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:37 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Salma Hayek and Frida Kahlo?\"\\nAnd the model gave the following answer:\\n\"Frida - a movie where Salma Hayek played the role of Frida Kahlo.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:37 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:37 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:37 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:37 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:37 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5abbebd90>\n",
      "2024-07-30 15:30:37 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:37 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ca50ac50>\n",
      "2024-07-30 15:30:37 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:37 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:37 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:37 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:37 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:39 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'855'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ef1788f0485531afead07c2248313abf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c3a568cd9059-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:39 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:39 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:39 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:39 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:39 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:39 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '855', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ef1788f0485531afead07c2248313abf', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c3a568cd9059-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:39 openai._base_client DEBUG    request_id: req_ef1788f0485531afead07c2248313abf\n",
      "2024-07-30 15:30:39 src.functional INFO     ['Salma Hayek', 'Frida Kahlo'] <> Frida | predicted:  Frida - a movie where Salma Hayek played the role of Frida Kahlo.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 55/119 [07:12<09:54,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:47 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Jesse Eisenberg and Mark Zuckerberg?\"\\nAnd the model gave the following answer:\\n\"The Social Network - a movie where Jesse Eisenberg played the role of Mark Zuckerberg.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:47 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:47 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:47 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:47 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:47 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cabbb4d0>\n",
      "2024-07-30 15:30:47 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:47 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb330ad0>\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995886'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b4a11113deeb9b0bd3610805f1d39a3b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c3e50a4f9035-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:47 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:47 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:47 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '104', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995886', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b4a11113deeb9b0bd3610805f1d39a3b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c3e50a4f9035-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:47 openai._base_client DEBUG    request_id: req_b4a11113deeb9b0bd3610805f1d39a3b\n",
      "2024-07-30 15:30:47 src.functional INFO     ['Jesse Eisenberg', 'Mark Zuckerberg'] <> The Social Network | predicted:  The Social Network - a movie where Jesse Eisenberg played the role of Mark Zuckerberg.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 56/119 [07:20<09:21,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:30:58 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Val Kilmer and Jim Morrison?\"\\nAnd the model gave the following answer:\\n\"The Doors - a rock band where Jim Morrison was the lead singer, and Val Kilmer played the role of Jim Morrison in the movie \"The Doors\".\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:30:58 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:30:58 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:30:58 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:30:58 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:30:58 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb330ad0>\n",
      "2024-07-30 15:30:58 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:30:58 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa84f910>\n",
      "2024-07-30 15:30:58 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:58 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:30:58 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:58 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:30:58 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:59 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:30:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'135'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995876'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ab9d0c556d11535f4a2642fbbe8e00cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c42c8cd84cf3-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:30:59 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:30:59 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:30:59 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:30:59 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:30:59 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:30:59 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:30:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '135', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995876', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ab9d0c556d11535f4a2642fbbe8e00cc', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c42c8cd84cf3-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:30:59 openai._base_client DEBUG    request_id: req_ab9d0c556d11535f4a2642fbbe8e00cc\n",
      "2024-07-30 15:30:59 src.functional INFO     ['Val Kilmer', 'Jim Morrison'] <> The Doors | predicted:  The Doors - a rock band where Jim Morrison was the lead singer, and Val Kilmer played the role of Jim Morrison in the movie \"The Doors\".\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 57/119 [07:31<09:59,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:05 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Andrew Garfield and Eduardo Saverin?\"\\nAnd the model gave the following answer:\\n\"Social Network - a movie where both actors Andrew Garfield and Eduardo Saverin were portrayed.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:05 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:05 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:05 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:05 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:05 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa84f910>\n",
      "2024-07-30 15:31:05 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:05 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ab513250>\n",
      "2024-07-30 15:31:05 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:05 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:05 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:05 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:05 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:07 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1256'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_877599b5bb3975b081f675fce0f84803'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c4596d77300c-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:07 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:07 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:07 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:07 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:07 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:07 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1256', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_877599b5bb3975b081f675fce0f84803', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c4596d77300c-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:07 openai._base_client DEBUG    request_id: req_877599b5bb3975b081f675fce0f84803\n",
      "2024-07-30 15:31:07 src.functional INFO     ['Andrew Garfield', 'Eduardo Saverin'] <> The Social Network | predicted:  Social Network - a movie where both actors Andrew Garfield and Eduardo Saverin were portrayed.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 58/119 [07:40<09:24,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:14 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Benedict Cumberbatch and Alan Turing?\"\\nAnd the model gave the following answer:\\n\"The Imitation Game - a movie where Benedict Cumberbatch played the role of Alan Turing.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:14 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:14 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:14 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:14 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:14 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ab513250>\n",
      "2024-07-30 15:31:14 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:14 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa03e7d0>\n",
      "2024-07-30 15:31:14 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:14 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:14 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:14 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:14 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:15 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'153'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995886'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2e2d47492a52c03fe740b6a0c84f7782'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c490df519002-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:15 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:15 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:15 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:15 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:15 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:15 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '153', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995886', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2e2d47492a52c03fe740b6a0c84f7782', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c490df519002-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:15 openai._base_client DEBUG    request_id: req_2e2d47492a52c03fe740b6a0c84f7782\n",
      "2024-07-30 15:31:15 src.functional INFO     ['Benedict Cumberbatch', 'Alan Turing'] <> The Imitation Game | predicted:  The Imitation Game - a movie where Benedict Cumberbatch played the role of Alan Turing.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 59/119 [07:47<08:49,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:22 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Taron Egerton and Elton John?\"\\nAnd the model gave the following answer:\\n\"Rocketman - a biopic where Taron Egerton played the role of Elton John.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:22 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:22 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:22 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:22 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:22 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa03e7d0>\n",
      "2024-07-30 15:31:22 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:22 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa3a70d0>\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995892'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_28df8b80b22d2714802677393cb6e37c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c4c05a4b8f6a-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:22 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:22 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:22 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '112', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995892', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_28df8b80b22d2714802677393cb6e37c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c4c05a4b8f6a-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:22 openai._base_client DEBUG    request_id: req_28df8b80b22d2714802677393cb6e37c\n",
      "2024-07-30 15:31:22 src.functional INFO     ['Taron Egerton', 'Elton John'] <> Rocketman | predicted:  Rocketman - a biopic where Taron Egerton played the role of Elton John.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 60/119 [07:55<08:18,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:29 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Wayne Gretzky and Mario Lemieux?\"\\nAnd the model gave the following answer:\\n\"Hockey - a sport where both players Wayne Gretzky and Mario Lemieux are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:29 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:29 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:29 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:29 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:29 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa3a70d0>\n",
      "2024-07-30 15:31:29 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:29 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58b84b4d0>\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995888'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_e04d063026f9164b18dd68d8dcec4a5e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c4eeef828fb8-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:29 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:29 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:30 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:30 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:30 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '127', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995888', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_e04d063026f9164b18dd68d8dcec4a5e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c4eeef828fb8-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:30 openai._base_client DEBUG    request_id: req_e04d063026f9164b18dd68d8dcec4a5e\n",
      "2024-07-30 15:31:30 src.functional INFO     ['Wayne Gretzky', 'Mario Lemieux'] <> hockey | predicted:  Hockey - a sport where both players Wayne Gretzky and Mario Lemieux are known for.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 61/119 [08:02<07:50,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:37 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Denzel Washington and Rubin \"Hurricane\" Carter?\"\\nAnd the model gave the following answer:\\n\"The Hurricane - a movie where Denzel Washington played the role of Rubin \"Hurricane\" Carter.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:37 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:37 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:37 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:37 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:37 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58adb8450>\n",
      "2024-07-30 15:31:37 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:37 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58adf7b90>\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995882'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_65973bc99293f3747e08823c967a3868'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c51dadc94cd6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:37 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:37 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:37 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '118', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995882', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_65973bc99293f3747e08823c967a3868', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c51dadc94cd6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:37 openai._base_client DEBUG    request_id: req_65973bc99293f3747e08823c967a3868\n",
      "2024-07-30 15:31:37 src.functional INFO     ['Denzel Washington', 'Rubin \"Hurricane\" Carter'] <> The Hurricane | predicted:  The Hurricane - a movie where Denzel Washington played the role of Rubin \"Hurricane\" Carter.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 62/119 [08:10<07:32,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:44 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Hugh Jackman and P.T. Barnum?\"\\nAnd the model gave the following answer:\\n\"The Greatest Showman - a movie where Hugh Jackman played the role of P.T. Barnum.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:44 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:44 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:44 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:44 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:44 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58adf7b90>\n",
      "2024-07-30 15:31:44 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:44 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58adf6990>\n",
      "2024-07-30 15:31:44 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:44 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:44 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:44 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:44 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:45 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_3a1f57d7f6e7a38b8f00065f8a91a9c8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c54e1e554ce6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:45 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:45 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:45 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:45 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:45 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:45 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '114', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_3a1f57d7f6e7a38b8f00065f8a91a9c8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c54e1e554ce6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:45 openai._base_client DEBUG    request_id: req_3a1f57d7f6e7a38b8f00065f8a91a9c8\n",
      "2024-07-30 15:31:45 src.functional INFO     ['Hugh Jackman', 'P.T. Barnum'] <> The Greatest Showman | predicted:  The Greatest Showman - a movie where Hugh Jackman played the role of P.T. Barnum.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 63/119 [08:18<07:22,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:31:53 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Silver Surfer and Green Lantern?\"\\nAnd the model gave the following answer:\\n\"Hal Jordan - a character who has wielded both the power of the Silver Surfer and the Green Lantern.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:31:53 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:31:53 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:31:53 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:31:53 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:31:53 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58adf6990>\n",
      "2024-07-30 15:31:53 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:31:53 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5cb330ad0>\n",
      "2024-07-30 15:31:53 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:53 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:31:53 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:53 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:31:53 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:54 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:31:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1073'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_41939f395015cdd4afab51cea72a664b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c5824f008f96-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:31:54 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:31:54 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:31:54 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:31:54 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:31:54 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:31:54 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:31:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1073', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_41939f395015cdd4afab51cea72a664b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c5824f008f96-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:31:54 openai._base_client DEBUG    request_id: req_41939f395015cdd4afab51cea72a664b\n",
      "2024-07-30 15:31:54 src.functional INFO     ['Silver Surfer', 'Green Lantern'] <> cosmic power | predicted:  Hal Jordan - a character who has wielded both the power of the Silver Surfer and the Green Lantern.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 64/119 [08:27<07:37,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:02 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Tom Brady and Peyton Manning?\"\\nAnd the model gave the following answer:\\n\"NFL - a professional American football league where both players Tom Brady and Peyton Manning have played.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:02 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:02 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:02 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:02 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:02 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58a0234d0>\n",
      "2024-07-30 15:32:02 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:02 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ab5fd190>\n",
      "2024-07-30 15:32:02 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:02 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:02 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:02 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:02 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:03 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'398'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995884'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_56b93aaa3698bbdbc74d2448d852ed98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c5be48106ac6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:03 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:03 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:03 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:03 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:03 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:03 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '398', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995884', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_56b93aaa3698bbdbc74d2448d852ed98', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c5be48106ac6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:03 openai._base_client DEBUG    request_id: req_56b93aaa3698bbdbc74d2448d852ed98\n",
      "2024-07-30 15:32:03 src.functional INFO     ['Tom Brady', 'Peyton Manning'] <> american football | predicted:  NFL - a professional American football league where both players Tom Brady and Peyton Manning have played.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 65/119 [08:36<07:38,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:12 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Seagram Building and Farnsworth House?\"\\nAnd the model gave the following answer:\\n\"Ludwig Mies van der Rohe - who was the architect of both buildings Seagram Building and Farnsworth House.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:12 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:12 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:12 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:12 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:12 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5ab5fd190>\n",
      "2024-07-30 15:32:12 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:12 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56b56bb50>\n",
      "2024-07-30 15:32:12 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:12 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:12 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:12 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:12 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:14 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995881'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_dde9513cf5804328391ad55512e21e33'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c5f99a1b8fb4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:14 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:14 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:14 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:14 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:14 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:14 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1479', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995881', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_dde9513cf5804328391ad55512e21e33', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c5f99a1b8fb4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:14 openai._base_client DEBUG    request_id: req_dde9513cf5804328391ad55512e21e33\n",
      "2024-07-30 15:32:14 src.functional INFO     ['Seagram Building', 'Farnsworth House'] <> Ludwig Mies van der Rohe | predicted:  Ludwig Mies van der Rohe - who was the architect of both buildings Seagram Building and Farnsworth House.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 66/119 [08:46<08:03,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:20 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Muhammad Ali and Mike Tyson?\"\\nAnd the model gave the following answer:\\n\"Boxing - a sport where both players Muhammad Ali and Mike Tyson are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:20 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:20 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:20 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:20 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:20 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56b697f90>\n",
      "2024-07-30 15:32:20 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:20 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa84fd10>\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'179'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_266ae3688ce48e1c36510b1ecf96626e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c62939424ce4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:20 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:20 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:20 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '179', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_266ae3688ce48e1c36510b1ecf96626e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c62939424ce4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:20 openai._base_client DEBUG    request_id: req_266ae3688ce48e1c36510b1ecf96626e\n",
      "2024-07-30 15:32:20 src.functional INFO     ['Muhammad Ali', 'Mike Tyson'] <> boxing | predicted:  Boxing - a sport where both players Muhammad Ali and Mike Tyson are known for.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 67/119 [08:53<07:09,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:25 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Sean Penn and Harvey Milk?\"\\nAnd the model gave the following answer:\\n\"Milk - a movie where Sean Penn played the role of Harvey Milk.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:25 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:25 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:25 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:25 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:25 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5aa84fd10>\n",
      "2024-07-30 15:32:25 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:25 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56b1f5dd0>\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_5d1f3dd7009868bc0ec279d969845c7d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c64bbb409002-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:25 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:25 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:25 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '106', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_5d1f3dd7009868bc0ec279d969845c7d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c64bbb409002-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:25 openai._base_client DEBUG    request_id: req_5d1f3dd7009868bc0ec279d969845c7d\n",
      "2024-07-30 15:32:25 src.functional INFO     ['Sean Penn', 'Harvey Milk'] <> Milk | predicted:  Milk - a movie where Sean Penn played the role of Harvey Milk.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 68/119 [08:58<06:20,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:31 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Flash and Quicksilver?\"\\nAnd the model gave the following answer:\\n\"super speed - a superpower that both characters Flash and Quicksilver possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:31 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:31 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:31 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:31 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:31 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58b242810>\n",
      "2024-07-30 15:32:31 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:31 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56b51a010>\n",
      "2024-07-30 15:32:31 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:31 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:31 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:31 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:31 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:32 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'195'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995892'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_8138758ed053bf1f085db7648c938625'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c6733f8d4cfc-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:32 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:32 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:32 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:32 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:32 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:32 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '195', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995892', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_8138758ed053bf1f085db7648c938625', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c6733f8d4cfc-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:32 openai._base_client DEBUG    request_id: req_8138758ed053bf1f085db7648c938625\n",
      "2024-07-30 15:32:32 src.functional INFO     ['Flash', 'Quicksilver'] <> speedster | predicted:  super speed - a superpower that both characters Flash and Quicksilver possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 69/119 [09:04<05:54,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:37 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Will Smith and Muhammad Ali?\"\\nAnd the model gave the following answer:\\n\"Ali - a movie where Will Smith played the role of Muhammad Ali.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:37 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:37 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:37 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:37 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:37 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a835c90>\n",
      "2024-07-30 15:32:37 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:37 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a4bddd0>\n",
      "2024-07-30 15:32:37 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:37 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:37 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:37 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:37 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:38 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_42d642d93c4eca9f64b9bfea4842708d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c6961c458fa3-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:38 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:38 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:38 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:38 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:38 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:38 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '336', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_42d642d93c4eca9f64b9bfea4842708d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c6961c458fa3-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:38 openai._base_client DEBUG    request_id: req_42d642d93c4eca9f64b9bfea4842708d\n",
      "2024-07-30 15:32:38 src.functional INFO     ['Will Smith', 'Muhammad Ali'] <> Ali | predicted:  Ali - a movie where Will Smith played the role of Muhammad Ali.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 70/119 [09:11<05:33,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:44 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Denzel Washington and Malcolm X?\"\\nAnd the model gave the following answer:\\n\"Malcolm X - a historical figure who was portrayed by Denzel Washington in a movie.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:44 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:44 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:44 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:44 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:44 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a5b5c90>\n",
      "2024-07-30 15:32:44 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:44 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a1eedd0>\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'268'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995888'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2749f00c1f958307a837fe27bd7ee51e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c6c288038fdb-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:44 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:44 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:44 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '268', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995888', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2749f00c1f958307a837fe27bd7ee51e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c6c288038fdb-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:44 openai._base_client DEBUG    request_id: req_2749f00c1f958307a837fe27bd7ee51e\n",
      "2024-07-30 15:32:44 src.functional INFO     ['Denzel Washington', 'Malcolm X'] <> Malcolm X | predicted:  Malcolm X - a historical figure who was portrayed by Denzel Washington in a movie.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 71/119 [09:17<05:23,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:51 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Venom and Carnage?\"\\nAnd the model gave the following answer:\\n\"symbiote - a parasitic alien entity that bonded with both characters Venom and Carnage.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:51 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:51 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:51 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:51 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:51 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a1eedd0>\n",
      "2024-07-30 15:32:51 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:51 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54b91fdd0>\n",
      "2024-07-30 15:32:51 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:51 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:51 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:51 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:51 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:52 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'139'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b6b27dc515ddebd928f2cbe74d4aa48e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c6f038018fe7-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:52 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:52 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:52 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:52 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:52 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:52 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '139', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b6b27dc515ddebd928f2cbe74d4aa48e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c6f038018fe7-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:52 openai._base_client DEBUG    request_id: req_b6b27dc515ddebd928f2cbe74d4aa48e\n",
      "2024-07-30 15:32:52 src.functional INFO     ['Venom', 'Carnage'] <> symbiote | predicted:  symbiote - a parasitic alien entity that bonded with both characters Venom and Carnage.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 72/119 [09:24<05:23,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:32:59 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Ra\\'s al Ghul and Vandal Savage?\"\\nAnd the model gave the following answer:\\n\"immortality - a trait that both characters Ra\\'s al Ghul and Vandal Savage possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:32:59 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:32:59 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:32:59 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:32:59 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:32:59 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54b91fdd0>\n",
      "2024-07-30 15:32:59 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:32:59 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54b91f750>\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:32:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'498'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_4e7616b049b39e74bdf08c01bef7b2ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c71d9e818ffc-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:32:59 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:32:59 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:32:59 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:32:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '498', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_4e7616b049b39e74bdf08c01bef7b2ab', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c71d9e818ffc-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:32:59 openai._base_client DEBUG    request_id: req_4e7616b049b39e74bdf08c01bef7b2ab\n",
      "2024-07-30 15:32:59 src.functional INFO     [\"Ra's al Ghul\", 'Vandal Savage'] <> immortal | predicted:  immortality - a trait that both characters Ra's al Ghul and Vandal Savage possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 73/119 [09:32<05:29,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:10 src.functional DEBUG    found cached gpt4o response for 71b81d99874527583863703881734fe5 - loading\n",
      "2024-07-30 15:33:10 src.functional INFO     ['Val Kilmer', 'Jim Morrison'] <> The Doors | predicted:  The Doors - a rock band where Jim Morrison was the lead singer, and Val Kilmer played the role of Jim Morrison in the movie \"The Doors\".\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 74/119 [09:43<06:13,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:17 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Meryl Streep and Margaret Thatcher?\"\\nAnd the model gave the following answer:\\n\"The Iron Lady - a movie where Meryl Streep played the role of Margaret Thatcher.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:33:17 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:33:17 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:33:17 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:33:17 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:33:17 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54b491e90>\n",
      "2024-07-30 15:33:17 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:33:17 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a65a310>\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:33:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'182'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_616acd8f9ac18a2c250b2ee9ffed1400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c78eace79053-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:33:17 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:33:17 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:33:17 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:33:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '182', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_616acd8f9ac18a2c250b2ee9ffed1400', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c78eace79053-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:33:17 openai._base_client DEBUG    request_id: req_616acd8f9ac18a2c250b2ee9ffed1400\n",
      "2024-07-30 15:33:17 src.functional INFO     ['Meryl Streep', 'Margaret Thatcher'] <> The Iron Lady | predicted:  The Iron Lady - a movie where Meryl Streep played the role of Margaret Thatcher.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 75/119 [09:50<05:43,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:24 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Batman and Ironman?\"\\nAnd the model gave the following answer:\\n\"Tony Stark - who has played both Batman and Ironman in various movies.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:33:24 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:33:24 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:33:24 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:33:24 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:33:25 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a65a310>\n",
      "2024-07-30 15:33:25 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:33:25 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58abf9790>\n",
      "2024-07-30 15:33:25 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:25 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:33:25 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:25 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:33:25 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:26 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:33:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1353'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_9e402a251e266194572175c1e937f18a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c7bf9cf59053-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:33:26 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:33:26 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:26 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:33:26 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:33:26 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:33:26 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:33:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1353', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_9e402a251e266194572175c1e937f18a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c7bf9cf59053-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:33:26 openai._base_client DEBUG    request_id: req_9e402a251e266194572175c1e937f18a\n",
      "2024-07-30 15:33:26 src.functional INFO     ['Batman', 'Ironman'] <> billionaire | predicted:  Tony Stark - who has played both Batman and Ironman in various movies.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 76/119 [09:59<05:52,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:35 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Church of the Light and Row House in Sumiyoshi?\"\\nAnd the model gave the following answer:\\n\"Tadao Ando - who was the architect of both buildings Church of the Light and Row House in Sumiyoshi.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:33:35 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:33:35 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:33:35 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:33:35 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:33:35 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe58abf9790>\n",
      "2024-07-30 15:33:35 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:33:35 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a3bdc90>\n",
      "2024-07-30 15:33:35 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:35 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:33:35 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:35 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:33:35 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:36 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:33:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'412'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995880'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ed2360df3b52fcc77088ef690ff5efcb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c8020a6c4d12-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:33:36 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:33:36 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:36 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:33:36 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:33:36 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:33:36 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:33:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '412', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995880', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ed2360df3b52fcc77088ef690ff5efcb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c8020a6c4d12-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:33:36 openai._base_client DEBUG    request_id: req_ed2360df3b52fcc77088ef690ff5efcb\n",
      "2024-07-30 15:33:36 src.functional INFO     ['Church of the Light', 'Row House in Sumiyoshi'] <> Tadao Ando | predicted:  Tadao Ando - who was the architect of both buildings Church of the Light and Row House in Sumiyoshi.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 77/119 [10:09<06:03,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:42 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Doctor Strange and Zatanna?\"\\nAnd the model gave the following answer:\\n\"magic - a theme that both characters Doctor Strange and Zatanna are associated with.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:33:42 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:33:42 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:33:42 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:33:42 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:33:42 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a984310>\n",
      "2024-07-30 15:33:42 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:33:42 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a3bdc90>\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:33:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'233'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_594e65f6a56112e8a76b7896c1c6ce3d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c82beb718f93-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:33:42 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:33:42 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:33:42 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:33:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '233', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_594e65f6a56112e8a76b7896c1c6ce3d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c82beb718f93-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:33:42 openai._base_client DEBUG    request_id: req_594e65f6a56112e8a76b7896c1c6ce3d\n",
      "2024-07-30 15:33:42 src.functional INFO     ['Doctor Strange', 'Zatanna'] <> magic user | predicted:  magic - a theme that both characters Doctor Strange and Zatanna are associated with.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 78/119 [10:15<05:27,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:49 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Leonardo DiCaprio and Howard Hughes?\"\\nAnd the model gave the following answer:\\n\"The Aviator - a movie where Leonardo DiCaprio played the role of Howard Hughes.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:33:49 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:33:49 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:33:49 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:33:49 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:33:49 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a3bdc90>\n",
      "2024-07-30 15:33:49 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:33:49 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5277c4510>\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:33:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_078a75374c2f02c1f470c99d72590e1b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c8581dca8f6e-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:33:49 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:33:49 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:33:49 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:33:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '110', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_078a75374c2f02c1f470c99d72590e1b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c8581dca8f6e-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:33:49 openai._base_client DEBUG    request_id: req_078a75374c2f02c1f470c99d72590e1b\n",
      "2024-07-30 15:33:49 src.functional INFO     ['Leonardo DiCaprio', 'Howard Hughes'] <> The Aviator | predicted:  The Aviator - a movie where Leonardo DiCaprio played the role of Howard Hughes.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 79/119 [10:22<05:07,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:33:56 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Christian Bale and Dicky Eklund?\"\\nAnd the model gave the following answer:\\n\"The Fighter - a movie where Christian Bale played the role of Dicky Eklund.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:33:56 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:33:56 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:33:56 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:33:56 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:33:56 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5277c4510>\n",
      "2024-07-30 15:33:56 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:33:56 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5272e3490>\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:33:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'171'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_df250b45db6500cdc1808726c2488d07'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c882bef88fd8-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:33:56 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:33:56 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:33:56 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:33:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '171', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_df250b45db6500cdc1808726c2488d07', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c882bef88fd8-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:33:56 openai._base_client DEBUG    request_id: req_df250b45db6500cdc1808726c2488d07\n",
      "2024-07-30 15:33:56 src.functional INFO     ['Christian Bale', 'Dicky Eklund'] <> The Fighter | predicted:  The Fighter - a movie where Christian Bale played the role of Dicky Eklund.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 80/119 [10:29<04:51,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:02 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Kelly Slater and Andy Irons?\"\\nAnd the model gave the following answer:\\n\"surfing - a sport where both players Kelly Slater and Andy Irons are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:02 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:02 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:02 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:02 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:02 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a1eedd0>\n",
      "2024-07-30 15:34:02 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:02 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe526dfc590>\n",
      "2024-07-30 15:34:02 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:02 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:02 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:02 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:02 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:03 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'791'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_5242f51f54966c9210a5c9b46c21e62d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c8ac6f65305d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:03 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:03 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:03 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:03 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:03 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:03 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '791', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_5242f51f54966c9210a5c9b46c21e62d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c8ac6f65305d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:03 openai._base_client DEBUG    request_id: req_5242f51f54966c9210a5c9b46c21e62d\n",
      "2024-07-30 15:34:03 src.functional INFO     ['Kelly Slater', 'Andy Irons'] <> surfing | predicted:  surfing - a sport where both players Kelly Slater and Andy Irons are known for.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 81/119 [10:36<04:40,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:11 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Robert De Niro and Jake LaMotta?\"\\nAnd the model gave the following answer:\\n\"Raging Bull - a movie where Robert De Niro played the role of Jake LaMotta.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:11 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:11 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:11 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:11 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:11 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe526dfc590>\n",
      "2024-07-30 15:34:11 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:11 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe526874ed0>\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_5ea48a96e40f6c9d2403410b6decd77b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c8e0d8e68fa5-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:11 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:11 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:11 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '113', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_5ea48a96e40f6c9d2403410b6decd77b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c8e0d8e68fa5-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:11 openai._base_client DEBUG    request_id: req_5ea48a96e40f6c9d2403410b6decd77b\n",
      "2024-07-30 15:34:11 src.functional INFO     ['Robert De Niro', 'Jake LaMotta'] <> Raging Bull | predicted:  Raging Bull - a movie where Robert De Niro played the role of Jake LaMotta.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 82/119 [10:44<04:35,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:18 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Jonah Lomu and Richie McCaw?\"\\nAnd the model gave the following answer:\\n\"Rugby - a sport where both players Jonah Lomu and Richie McCaw are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:18 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:18 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:18 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:18 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:18 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe526874ed0>\n",
      "2024-07-30 15:34:18 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:18 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5262953d0>\n",
      "2024-07-30 15:34:18 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:18 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:18 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:18 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:18 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:20 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'2189'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_261f46a0366d00344b43230e404f6fb7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c90bfc264cf4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:20 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:20 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:20 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:20 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:20 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:20 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '2189', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_261f46a0366d00344b43230e404f6fb7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c90bfc264cf4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:20 openai._base_client DEBUG    request_id: req_261f46a0366d00344b43230e404f6fb7\n",
      "2024-07-30 15:34:20 src.functional INFO     ['Jonah Lomu', 'Richie McCaw'] <> rugby | predicted:  Rugby - a sport where both players Jonah Lomu and Richie McCaw are known for.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 83/119 [10:53<04:46,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:28 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between CCTV Headquarters and Seattle Central Library?\"\\nAnd the model gave the following answer:\\n\"Rem Koolhaas - who was the architect of both buildings CCTV Headquarters and Seattle Central Library.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:28 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:28 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:28 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:28 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:28 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5262be290>\n",
      "2024-07-30 15:34:28 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:28 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe517dce890>\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'208'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995880'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_e0c5a656859dee55dbe123ebe6c20221'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c9494fe14ce2-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:28 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:28 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:28 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '208', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995880', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_e0c5a656859dee55dbe123ebe6c20221', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c9494fe14ce2-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:28 openai._base_client DEBUG    request_id: req_e0c5a656859dee55dbe123ebe6c20221\n",
      "2024-07-30 15:34:28 src.functional INFO     ['CCTV Headquarters', 'Seattle Central Library'] <> Rem Koolhaas | predicted:  Rem Koolhaas - who was the architect of both buildings CCTV Headquarters and Seattle Central Library.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 84/119 [11:01<04:37,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:34 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Superman and Supergirl?\"\\nAnd the model gave the following answer:\\n\"Kryptonian - a species from which both characters Superman and Supergirl originate.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:34 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:34 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:34 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:34 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:34 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe517dce890>\n",
      "2024-07-30 15:34:34 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:34 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51725a010>\n",
      "2024-07-30 15:34:34 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:34 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:34 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:34 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:34 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:35 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'150'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ce33dd21591dfb77a58b534999f7af7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c9739f8b8ff6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:35 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:35 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:35 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:35 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:35 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:35 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '150', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ce33dd21591dfb77a58b534999f7af7e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c9739f8b8ff6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:35 openai._base_client DEBUG    request_id: req_ce33dd21591dfb77a58b534999f7af7e\n",
      "2024-07-30 15:34:35 src.functional INFO     ['Superman', 'Supergirl'] <> kryptonian | predicted:  Kryptonian - a species from which both characters Superman and Supergirl originate.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 85/119 [11:07<04:16,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:42 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Getty Center and Barcelona Museum of Contemporary Art?\"\\nAnd the model gave the following answer:\\n\"Richard Meier - who was the architect of both buildings Getty Center and Barcelona Museum of Contemporary Art.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:42 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:42 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:42 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:42 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:42 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51725a010>\n",
      "2024-07-30 15:34:42 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:42 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51725a310>\n",
      "2024-07-30 15:34:42 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:42 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:42 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:42 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:42 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:43 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995877'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_37bc5cd71ff4254f09ccf84c95db2e45'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c9a3c9153b7c-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:43 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:43 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:43 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:43 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:43 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:43 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1106', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995877', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_37bc5cd71ff4254f09ccf84c95db2e45', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c9a3c9153b7c-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:43 openai._base_client DEBUG    request_id: req_37bc5cd71ff4254f09ccf84c95db2e45\n",
      "2024-07-30 15:34:43 src.functional INFO     ['Getty Center', 'Barcelona Museum of Contemporary Art'] <> Richard Meier | predicted:  Richard Meier - who was the architect of both buildings Getty Center and Barcelona Museum of Contemporary Art.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 86/119 [11:16<04:20,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:34:51 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Emile Hirsch and Christopher McCandless?\"\\nAnd the model gave the following answer:\\n\"Into the Wild - a movie where Emile Hirsch played the role of Christopher McCandless.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:34:51 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:34:51 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:34:51 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:34:51 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:34:51 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51725a310>\n",
      "2024-07-30 15:34:51 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:34:51 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe527b5a310>\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:34:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'140'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995886'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_a4d18156e2b6d66c5e7f5dca6dd2fa17'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7c9da98179068-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:34:51 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:34:51 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:34:51 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:34:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '140', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995886', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_a4d18156e2b6d66c5e7f5dca6dd2fa17', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7c9da98179068-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:34:51 openai._base_client DEBUG    request_id: req_a4d18156e2b6d66c5e7f5dca6dd2fa17\n",
      "2024-07-30 15:34:51 src.functional INFO     ['Emile Hirsch', 'Christopher McCandless'] <> Into the Wild | predicted:  Into the Wild - a movie where Emile Hirsch played the role of Christopher McCandless.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 87/119 [11:24<04:10,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:00 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Shang-Chi and Iron Fist?\"\\nAnd the model gave the following answer:\\n\"Marvel Comics - both characters Shang-Chi and Iron Fist are part of the Marvel Comics universe.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:00 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:00 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:00 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:00 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:00 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe527b5a310>\n",
      "2024-07-30 15:35:00 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:00 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5167d1510>\n",
      "2024-07-30 15:35:00 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:00 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:00 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:00 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:00 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:01 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_aa07bd7004811b5ac00db44575ffb4a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ca15bdda903e-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:01 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:01 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:01 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:01 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:01 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:01 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '450', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_aa07bd7004811b5ac00db44575ffb4a3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ca15bdda903e-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:01 openai._base_client DEBUG    request_id: req_aa07bd7004811b5ac00db44575ffb4a3\n",
      "2024-07-30 15:35:01 src.functional INFO     ['Shang-Chi', 'Iron Fist'] <> martial artist | predicted:  Marvel Comics - both characters Shang-Chi and Iron Fist are part of the Marvel Comics universe.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 88/119 [11:34<04:21,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:10 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between John Hurt and Joseph Merrick?\"\\nAnd the model gave the following answer:\\n\"The Elephant Man - a movie where John Hurt played the role of Dr. Frederick Treves, who treated Joseph Merrick.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:10 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:10 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:10 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:10 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:10 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5167d1510>\n",
      "2024-07-30 15:35:10 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:10 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5277c4510>\n",
      "2024-07-30 15:35:10 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:10 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:10 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:10 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:10 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:12 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995883'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_e045964eb7ffd5e946cf0b1a1b536f69'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ca53186b8f6b-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:12 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:12 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:12 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:12 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:12 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:12 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1116', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995883', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_e045964eb7ffd5e946cf0b1a1b536f69', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ca53186b8f6b-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:12 openai._base_client DEBUG    request_id: req_e045964eb7ffd5e946cf0b1a1b536f69\n",
      "2024-07-30 15:35:12 src.functional INFO     ['John Hurt', 'Joseph Merrick'] <> The Elephant Man | predicted:  The Elephant Man - a movie where John Hurt played the role of Dr. Frederick Treves, who treated Joseph Merrick.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 89/119 [11:44<04:33,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:19 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Forest Whitaker and Idi Amin?\"\\nAnd the model gave the following answer:\\n\"The Last King of Scotland - a movie where Forest Whitaker played the role of Idi Amin.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:19 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:19 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:19 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:19 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:19 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe516c2dc90>\n",
      "2024-07-30 15:35:19 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:19 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51725a010>\n",
      "2024-07-30 15:35:19 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:19 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:19 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:19 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:19 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:20 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'99'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_e9badd69917e29feedd365cecde09a12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ca8cfd1b8fea-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:20 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:20 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:20 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:20 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:20 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:20 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '99', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_e9badd69917e29feedd365cecde09a12', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ca8cfd1b8fea-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:20 openai._base_client DEBUG    request_id: req_e9badd69917e29feedd365cecde09a12\n",
      "2024-07-30 15:35:20 src.functional INFO     ['Forest Whitaker', 'Idi Amin'] <> The Last King of Scotland | predicted:  The Last King of Scotland - a movie where Forest Whitaker played the role of Idi Amin.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 90/119 [11:52<04:14,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:27 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Lance Armstrong and Eddy Merckx?\"\\nAnd the model gave the following answer:\\n\"cycling - a sport where both players Lance Armstrong and Eddy Merckx are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:27 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:27 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:27 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:27 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:27 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51725a010>\n",
      "2024-07-30 15:35:27 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:27 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f7a2f950>\n",
      "2024-07-30 15:35:27 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:27 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:27 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:27 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:27 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:28 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1508'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_20b9dfe14fc8d837d84d861d466941ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cabb3f388fd3-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:28 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:28 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:28 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:28 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:28 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:28 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1508', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_20b9dfe14fc8d837d84d861d466941ec', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cabb3f388fd3-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:28 openai._base_client DEBUG    request_id: req_20b9dfe14fc8d837d84d861d466941ec\n",
      "2024-07-30 15:35:28 src.functional INFO     ['Lance Armstrong', 'Eddy Merckx'] <> cycling | predicted:  cycling - a sport where both players Lance Armstrong and Eddy Merckx are known for.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 91/119 [12:01<04:06,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:36 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Hulk and Juggernaut?\"\\nAnd the model gave the following answer:\\n\"X-Men - a comic book series where both characters Hulk and Juggernaut are part of.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:36 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:36 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:36 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:36 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:36 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f7a2f950>\n",
      "2024-07-30 15:35:36 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:36 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f6a73cd0>\n",
      "2024-07-30 15:35:36 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:36 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:36 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:36 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:36 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:37 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1411'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_3539186345f1d3caee06024e9fe3edec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7caf278198f7e-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:37 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:37 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:37 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:37 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:37 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:37 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1411', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_3539186345f1d3caee06024e9fe3edec', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7caf278198f7e-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:37 openai._base_client DEBUG    request_id: req_3539186345f1d3caee06024e9fe3edec\n",
      "2024-07-30 15:35:37 src.functional INFO     ['Hulk', 'Juggernaut'] <> super strength | predicted:  X-Men - a comic book series where both characters Hulk and Juggernaut are part of.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 92/119 [12:10<03:56,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:44 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Jim Carrey and Andy Kaufman?\"\\nAnd the model gave the following answer:\\n\"Man on the Moon - a movie where Jim Carrey played the role of Andy Kaufman.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:44 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:44 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:44 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:44 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:44 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe516df2810>\n",
      "2024-07-30 15:35:44 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:44 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f6a73cd0>\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'168'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_978aaa8878f3274f64d5480eac4696bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cb283ef04ce4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:44 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:44 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:44 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '168', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_978aaa8878f3274f64d5480eac4696bb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cb283ef04ce4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:44 openai._base_client DEBUG    request_id: req_978aaa8878f3274f64d5480eac4696bb\n",
      "2024-07-30 15:35:44 src.functional INFO     ['Jim Carrey', 'Andy Kaufman'] <> Man on the Moon | predicted:  Man on the Moon - a movie where Jim Carrey played the role of Andy Kaufman.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 93/119 [12:17<03:36,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:35:51 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between David Oyelowo and Martin Luther King Jr.?\"\\nAnd the model gave the following answer:\\n\"Selma - a movie where David Oyelowo played the role of Martin Luther King Jr.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:35:51 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:35:51 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:35:51 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:35:51 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:35:51 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe51628e7d0>\n",
      "2024-07-30 15:35:51 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:35:51 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a984310>\n",
      "2024-07-30 15:35:51 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:51 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:35:51 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:51 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:35:51 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:52 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:35:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'231'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b6efd3e50d52d4ffd07512e4e36b0731'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cb55cb193068-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:35:52 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:35:52 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:35:52 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:35:52 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:35:52 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:35:52 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:35:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '231', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b6efd3e50d52d4ffd07512e4e36b0731', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cb55cb193068-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:35:52 openai._base_client DEBUG    request_id: req_b6efd3e50d52d4ffd07512e4e36b0731\n",
      "2024-07-30 15:35:52 src.functional INFO     ['David Oyelowo', 'Martin Luther King Jr.'] <> Selma | predicted:  Selma - a movie where David Oyelowo played the role of Martin Luther King Jr.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 94/119 [12:25<03:21,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:01 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Adrien Brody and Władysław Szpilman?\"\\nAnd the model gave the following answer:\\n\"The Pianist - a movie where Adrien Brody played the role of Władysław Szpilman.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:01 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:01 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:01 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:01 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:01 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe56a984310>\n",
      "2024-07-30 15:36:01 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:01 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d7eb6950>\n",
      "2024-07-30 15:36:01 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:01 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:01 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:01 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:01 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:02 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'222'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_83c524f556dfc77b8c46daaa8436cb1f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cb924a4a8fa5-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:02 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:02 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:02 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:02 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:02 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:02 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '222', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_83c524f556dfc77b8c46daaa8436cb1f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cb924a4a8fa5-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:02 openai._base_client DEBUG    request_id: req_83c524f556dfc77b8c46daaa8436cb1f\n",
      "2024-07-30 15:36:02 src.functional INFO     ['Adrien Brody', 'Władysław Szpilman'] <> The Pianist | predicted:  The Pianist - a movie where Adrien Brody played the role of Władysław Szpilman.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 95/119 [12:34<03:25,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:08 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Michael Fassbender and Steve Jobs?\"\\nAnd the model gave the following answer:\\n\"Steve Jobs - a movie where Michael Fassbender played the role of Steve Jobs.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:08 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:08 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:08 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:08 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:08 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d7993490>\n",
      "2024-07-30 15:36:08 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:08 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d7389510>\n",
      "2024-07-30 15:36:08 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:08 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:08 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:08 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:08 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:09 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_decb7ef4d980b357adfc5530801944b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cbbdecd4905d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:09 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:09 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:09 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:09 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:09 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:09 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '368', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_decb7ef4d980b357adfc5530801944b0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cbbdecd4905d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:09 openai._base_client DEBUG    request_id: req_decb7ef4d980b357adfc5530801944b0\n",
      "2024-07-30 15:36:09 src.functional INFO     ['Michael Fassbender', 'Steve Jobs'] <> Steve Jobs | predicted:  Steve Jobs - a movie where Michael Fassbender played the role of Steve Jobs.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 96/119 [12:41<03:06,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:16 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Sandra Bullock and Leigh Anne Tuohy?\"\\nAnd the model gave the following answer:\\n\"The Blind Side - a movie where Sandra Bullock played the role of Leigh Anne Tuohy.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:16 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:16 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:16 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:16 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:16 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d7389510>\n",
      "2024-07-30 15:36:16 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:16 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe517790ad0>\n",
      "2024-07-30 15:36:16 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:16 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:16 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:16 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:16 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:17 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ebd66e25a30c2916aed3194a50da9200'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cbef6f804ce6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:17 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:17 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:17 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:17 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:17 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:17 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '112', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ebd66e25a30c2916aed3194a50da9200', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cbef6f804ce6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:17 openai._base_client DEBUG    request_id: req_ebd66e25a30c2916aed3194a50da9200\n",
      "2024-07-30 15:36:17 src.functional INFO     ['Sandra Bullock', 'Leigh Anne Tuohy'] <> The Blind Side | predicted:  The Blind Side - a movie where Sandra Bullock played the role of Leigh Anne Tuohy.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 97/119 [12:50<02:59,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:23 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Daniel Day-Lewis and Abraham Lincoln?\"\\nAnd the model gave the following answer:\\n\"The movie Lincoln - where Daniel Day-Lewis played the role of Abraham Lincoln.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:23 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:23 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:23 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:23 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:23 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe517790ad0>\n",
      "2024-07-30 15:36:23 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:23 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d69d29d0>\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995889'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_710fb853958261057cfe498577bb57ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cc193b8f4cd5-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:23 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:23 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:23 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '115', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995889', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_710fb853958261057cfe498577bb57ce', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cc193b8f4cd5-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:23 openai._base_client DEBUG    request_id: req_710fb853958261057cfe498577bb57ce\n",
      "2024-07-30 15:36:23 src.functional INFO     ['Daniel Day-Lewis', 'Abraham Lincoln'] <> Lincoln | predicted:  The movie Lincoln - where Daniel Day-Lewis played the role of Abraham Lincoln.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 98/119 [12:56<02:40,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:30 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Michael Schumacher and Lewis Hamilton?\"\\nAnd the model gave the following answer:\\n\"Formula One - a racing series where both drivers Michael Schumacher and Lewis Hamilton have competed.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:30 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:30 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:30 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:30 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:30 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f6b5b610>\n",
      "2024-07-30 15:36:30 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:30 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d7373d90>\n",
      "2024-07-30 15:36:30 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:30 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:30 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:30 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:30 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:31 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'451'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995883'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_4c3cb3c43dbe82c97e49dbefc81d6458'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cc492f408fc7-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:31 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:31 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:31 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:31 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:31 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:31 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '451', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995883', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_4c3cb3c43dbe82c97e49dbefc81d6458', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cc492f408fc7-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:31 openai._base_client DEBUG    request_id: req_4c3cb3c43dbe82c97e49dbefc81d6458\n",
      "2024-07-30 15:36:31 src.functional INFO     ['Michael Schumacher', 'Lewis Hamilton'] <> formula 1 | predicted:  Formula One - a racing series where both drivers Michael Schumacher and Lewis Hamilton have competed.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 99/119 [13:04<02:33,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:37 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Fallingwater and Guggenheim Museum?\"\\nAnd the model gave the following answer:\\n\"Frank Lloyd Wright - who designed both buildings Fallingwater and Guggenheim Museum.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:37 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:37 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:37 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:37 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:37 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d7373d90>\n",
      "2024-07-30 15:36:37 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:37 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d611b210>\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'199'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_80c4490d7af499ca2124d1ac353c31a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cc728b838fc6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:37 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:37 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:37 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '199', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_80c4490d7af499ca2124d1ac353c31a7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cc728b838fc6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:37 openai._base_client DEBUG    request_id: req_80c4490d7af499ca2124d1ac353c31a7\n",
      "2024-07-30 15:36:37 src.functional INFO     ['Fallingwater', 'Guggenheim Museum'] <> Frank Lloyd Wright | predicted:  Frank Lloyd Wright - who designed both buildings Fallingwater and Guggenheim Museum.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 100/119 [13:10<02:17,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:47 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Rami Malek and Freddie Mercury?\"\\nAnd the model gave the following answer:\\n\"Bohemian Rhapsody - a movie where Rami Malek played the role of Freddie Mercury.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:47 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:47 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:47 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:47 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:47 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f7e19e10>\n",
      "2024-07-30 15:36:47 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:47 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a540ad0>\n",
      "2024-07-30 15:36:47 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:47 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:47 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:47 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:47 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:48 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'136'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_269aaae6551a073fe060e7b79de14e7d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ccb36c369014-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:48 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:48 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:48 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:48 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:48 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:48 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '136', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_269aaae6551a073fe060e7b79de14e7d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ccb36c369014-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:48 openai._base_client DEBUG    request_id: req_269aaae6551a073fe060e7b79de14e7d\n",
      "2024-07-30 15:36:48 src.functional INFO     ['Rami Malek', 'Freddie Mercury'] <> Bohemian Rhapsody | predicted:  Bohemian Rhapsody - a movie where Rami Malek played the role of Freddie Mercury.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 101/119 [13:20<02:27,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:36:53 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Jamie Foxx and Ray Charles?\"\\nAnd the model gave the following answer:\\n\"Ray - a movie where Jamie Foxx played the role of Ray Charles.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:36:53 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:36:53 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:36:53 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:36:53 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:36:53 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe54a540ad0>\n",
      "2024-07-30 15:36:53 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:36:53 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d651eb90>\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:36:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'141'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995895'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_24eb38148b18f04c83fb26528231249c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ccd74f64906f-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:36:53 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:36:53 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:36:53 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:36:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '141', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995895', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_24eb38148b18f04c83fb26528231249c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ccd74f64906f-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:36:53 openai._base_client DEBUG    request_id: req_24eb38148b18f04c83fb26528231249c\n",
      "2024-07-30 15:36:53 src.functional INFO     ['Jamie Foxx', 'Ray Charles'] <> Ray | predicted:  Ray - a movie where Jamie Foxx played the role of Ray Charles.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 102/119 [13:26<02:06,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:02 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Lindsey Vonn and Mikaela Shiffrin?\"\\nAnd the model gave the following answer:\\n\"Skiing - a sport where both players Lindsey Vonn and Mikaela Shiffrin are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:02 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:02 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:02 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:02 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:02 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5277c4510>\n",
      "2024-07-30 15:37:02 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:02 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b76ffd50>\n",
      "2024-07-30 15:37:02 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:02 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:02 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:02 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:02 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:03 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'860'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995888'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_6a562716956f3007cfa423e84c179325'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m8cv7d87_znwVwo4HZoZqPXlB9BKs7zZ.kffjmHWBoU-1722368223-1.0.1.1-.7tu1V7Ooq.ysLeydEY6bQaOsBYR4OJoksh_lavIoJF4Wd39biPdSQWBWb51ytfN2URt6lDIgZR7NTGeEK.G2w; path=/; expires=Tue, 30-Jul-24 20:07:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cd0dce4e905d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:03 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:03 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:03 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:03 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:03 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:03 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '860', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995888', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_6a562716956f3007cfa423e84c179325', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=m8cv7d87_znwVwo4HZoZqPXlB9BKs7zZ.kffjmHWBoU-1722368223-1.0.1.1-.7tu1V7Ooq.ysLeydEY6bQaOsBYR4OJoksh_lavIoJF4Wd39biPdSQWBWb51ytfN2URt6lDIgZR7NTGeEK.G2w; path=/; expires=Tue, 30-Jul-24 20:07:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cd0dce4e905d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:03 openai._base_client DEBUG    request_id: req_6a562716956f3007cfa423e84c179325\n",
      "2024-07-30 15:37:03 src.functional INFO     ['Lindsey Vonn', 'Mikaela Shiffrin'] <> skiing | predicted:  Skiing - a sport where both players Lindsey Vonn and Mikaela Shiffrin are known for.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 103/119 [13:36<02:09,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:09 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Wolverine and Deadpool?\"\\nAnd the model gave the following answer:\\n\"X-Men - a comic book series where both characters Wolverine and Deadpool are part of.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:09 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:09 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:09 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:09 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:09 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b76ffd50>\n",
      "2024-07-30 15:37:09 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:09 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b75220d0>\n",
      "2024-07-30 15:37:09 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:09 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:09 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:09 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:09 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:10 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1146'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2519d2ffc83102129dcbb7e0a0ff1b40'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cd3a2fae905d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:10 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:10 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:10 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:10 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:10 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:10 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1146', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2519d2ffc83102129dcbb7e0a0ff1b40', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cd3a2fae905d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:10 openai._base_client DEBUG    request_id: req_2519d2ffc83102129dcbb7e0a0ff1b40\n",
      "2024-07-30 15:37:10 src.functional INFO     ['Wolverine', 'Deadpool'] <> healing factor | predicted:  X-Men - a comic book series where both characters Wolverine and Deadpool are part of.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 104/119 [13:43<01:57,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:17 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Helen Mirren and Queen Elizabeth II?\"\\nAnd the model gave the following answer:\\n\"The Queen - a movie where Helen Mirren played the role of Queen Elizabeth II.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:17 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:17 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:17 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:17 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:17 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b75220d0>\n",
      "2024-07-30 15:37:17 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:17 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5277c4510>\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_1f18d904b30b860887fe31a435108752'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cd6a0fec4cd4-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:17 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:17 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:17 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '113', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_1f18d904b30b860887fe31a435108752', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cd6a0fec4cd4-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:17 openai._base_client DEBUG    request_id: req_1f18d904b30b860887fe31a435108752\n",
      "2024-07-30 15:37:17 src.functional INFO     ['Helen Mirren', 'Queen Elizabeth II'] <> The Queen | predicted:  The Queen - a movie where Helen Mirren played the role of Queen Elizabeth II.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 105/119 [13:50<01:44,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:24 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Colin Firth and King George VI?\"\\nAnd the model gave the following answer:\\n\"The King\\'s Speech - a movie where Colin Firth played the role of King George VI.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:24 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:24 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:24 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:24 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:24 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe5277c4510>\n",
      "2024-07-30 15:37:24 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:24 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f6b5b610>\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'241'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_96be68f47f4dbb53f47181d8e82e96df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cd9859a58ff3-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:24 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:24 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:24 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '241', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_96be68f47f4dbb53f47181d8e82e96df', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cd9859a58ff3-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:24 openai._base_client DEBUG    request_id: req_96be68f47f4dbb53f47181d8e82e96df\n",
      "2024-07-30 15:37:24 src.functional INFO     ['Colin Firth', 'King George VI'] <> The King's Speech | predicted:  The King's Speech - a movie where Colin Firth played the role of King George VI.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 106/119 [13:57<01:37,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:31 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Mystique and Martian Manhunter?\"\\nAnd the model gave the following answer:\\n\"shapeshifting - a superpower that both characters Mystique and Martian Manhunter possess.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:31 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:31 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:31 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:31 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:31 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b6ab3750>\n",
      "2024-07-30 15:37:31 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:31 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe487d32590>\n",
      "2024-07-30 15:37:31 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:31 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:31 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:31 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:31 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:32 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995887'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_042f5ffefd17f25b170bf1ca7f24ac43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cdc50ee48ff6-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:32 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:32 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:32 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:32 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:32 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:32 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '369', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995887', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_042f5ffefd17f25b170bf1ca7f24ac43', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cdc50ee48ff6-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:32 openai._base_client DEBUG    request_id: req_042f5ffefd17f25b170bf1ca7f24ac43\n",
      "2024-07-30 15:37:32 src.functional INFO     ['Mystique', 'Martian Manhunter'] <> shape-shifter | predicted:  shapeshifting - a superpower that both characters Mystique and Martian Manhunter possess.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 107/119 [14:05<01:29,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:40 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Institut du Monde Arabe and One Central Park?\"\\nAnd the model gave the following answer:\\n\"Jean Nouvel - who was the architect of both buildings Institut du Monde Arabe and One Central Park.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:40 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:40 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:40 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:40 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:40 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe487d32590>\n",
      "2024-07-30 15:37:40 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:40 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe487f08810>\n",
      "2024-07-30 15:37:40 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:40 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:40 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:40 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:40 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:41 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'332'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995881'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_9a1429d67f25516c90147151debc2798'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cdfbab709065-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:41 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:41 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:41 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:41 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:41 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:41 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '332', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995881', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_9a1429d67f25516c90147151debc2798', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cdfbab709065-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:41 openai._base_client DEBUG    request_id: req_9a1429d67f25516c90147151debc2798\n",
      "2024-07-30 15:37:41 src.functional INFO     ['Institut du Monde Arabe', 'One Central Park'] <> Jean Nouvel | predicted:  Jean Nouvel - who was the architect of both buildings Institut du Monde Arabe and One Central Park.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 108/119 [14:13<01:26,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:48 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between TWA Flight Center and Gateway Arch?\"\\nAnd the model gave the following answer:\\n\"Eero Saarinen - who was the architect of both buildings TWA Flight Center and Gateway Arch.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:48 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:48 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:48 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:48 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:48 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe486e2f850>\n",
      "2024-07-30 15:37:48 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:48 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d651f090>\n",
      "2024-07-30 15:37:48 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:48 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:48 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:48 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:48 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:49 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'135'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_425fe5492c6ca77d654441d6b515792c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ce2fbd644ce0-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:49 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:49 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:49 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:49 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:49 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:49 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '135', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_425fe5492c6ca77d654441d6b515792c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ce2fbd644ce0-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:49 openai._base_client DEBUG    request_id: req_425fe5492c6ca77d654441d6b515792c\n",
      "2024-07-30 15:37:49 src.functional INFO     ['TWA Flight Center', 'Gateway Arch'] <> Eero Saarinen | predicted:  Eero Saarinen - who was the architect of both buildings TWA Flight Center and Gateway Arch.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 109/119 [14:21<01:19,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:37:55 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Ben Kingsley and Mahatma Gandhi?\"\\nAnd the model gave the following answer:\\n\"Gandhi - a movie where Ben Kingsley played the role of Mahatma Gandhi.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:37:55 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:37:55 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:37:55 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:37:55 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:37:55 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b6581ad0>\n",
      "2024-07-30 15:37:55 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:37:55 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe486929690>\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:37:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'304'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_dce6a3454b669694296c6592ecc48011'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ce593a1c3b9a-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:37:55 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:37:55 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:37:55 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:37:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '304', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_dce6a3454b669694296c6592ecc48011', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ce593a1c3b9a-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:37:55 openai._base_client DEBUG    request_id: req_dce6a3454b669694296c6592ecc48011\n",
      "2024-07-30 15:37:55 src.functional INFO     ['Ben Kingsley', 'Mahatma Gandhi'] <> Gandhi | predicted:  Gandhi - a movie where Ben Kingsley played the role of Mahatma Gandhi.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 110/119 [14:28<01:08,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:04 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Heydar Aliyev Center and Guangzhou Opera House?\"\\nAnd the model gave the following answer:\\n\"Zaha Hadid - who was the architect of both buildings Heydar Aliyev Center and Guangzhou Opera House.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:04 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:04 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:04 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:04 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:04 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe486929690>\n",
      "2024-07-30 15:38:04 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:04 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe487f08810>\n",
      "2024-07-30 15:38:04 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:04 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:04 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:04 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:04 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:05 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995880'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_6854a6b13d4bae569fba559aaec187fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ce935f698f6a-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:05 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:05 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:05 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:05 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:05 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:05 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '143', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995880', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_6854a6b13d4bae569fba559aaec187fe', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ce935f698f6a-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:05 openai._base_client DEBUG    request_id: req_6854a6b13d4bae569fba559aaec187fe\n",
      "2024-07-30 15:38:05 src.functional INFO     ['Heydar Aliyev Center', 'Guangzhou Opera House'] <> Zaha Hadid | predicted:  Zaha Hadid - who was the architect of both buildings Heydar Aliyev Center and Guangzhou Opera House.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 111/119 [14:37<01:04,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:11 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between John Lone and Emperor Puyi?\"\\nAnd the model gave the following answer:\\n\"The Last Emperor - a movie where John Lone played the role of Emperor Puyi.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:11 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:11 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:11 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:11 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:11 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4b6d22d10>\n",
      "2024-07-30 15:38:11 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:11 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe467d14a90>\n",
      "2024-07-30 15:38:11 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:11 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:11 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:11 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:11 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:12 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'181'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b9b5b6e47ece4756c33f4139c6ffe8bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cebf1e6d3ba0-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:12 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:12 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:12 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:12 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:12 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:12 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '181', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_b9b5b6e47ece4756c33f4139c6ffe8bd', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cebf1e6d3ba0-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:12 openai._base_client DEBUG    request_id: req_b9b5b6e47ece4756c33f4139c6ffe8bd\n",
      "2024-07-30 15:38:12 src.functional INFO     ['John Lone', 'Emperor Puyi'] <> The Last Emperor | predicted:  The Last Emperor - a movie where John Lone played the role of Emperor Puyi.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 112/119 [14:44<00:54,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:19 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Tokyo Metropolitan Government Building and St. Mary\\'s Cathedral?\"\\nAnd the model gave the following answer:\\n\"Tokyo - the city where both buildings Tokyo Metropolitan Government Building and St. Mary\\'s Cathedral are located.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:19 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:19 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:19 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:19 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:19 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4f6b5b610>\n",
      "2024-07-30 15:38:19 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:19 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe467909790>\n",
      "2024-07-30 15:38:19 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:19 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:19 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:19 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:19 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:20 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'723'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995872'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_17937f6c20a038efce23477213a1e21d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7ceedd9598fea-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:20 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:20 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:20 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:20 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:20 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:20 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '723', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995872', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_17937f6c20a038efce23477213a1e21d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7ceedd9598fea-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:20 openai._base_client DEBUG    request_id: req_17937f6c20a038efce23477213a1e21d\n",
      "2024-07-30 15:38:20 src.functional INFO     ['Tokyo Metropolitan Government Building', \"St. Mary's Cathedral\"] <> Kenzo Tange | predicted:  Tokyo - the city where both buildings Tokyo Metropolitan Government Building and St. Mary's Cathedral are located.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 113/119 [14:52<00:46,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:28 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Leonardo DiCaprio and Frank Abagnale Jr.?\"\\nAnd the model gave the following answer:\\n\"Catch Me If You Can - a movie where Leonardo DiCaprio played the role of Frank Abagnale Jr.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:28 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:28 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:28 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:28 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:28 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe48741dc90>\n",
      "2024-07-30 15:38:28 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:28 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4671562d0>\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'157'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_5f94df2a27a1a0e7728a9c10adf8a9a8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cf25eb2f8fb8-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:28 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:28 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:28 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '157', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_5f94df2a27a1a0e7728a9c10adf8a9a8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cf25eb2f8fb8-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:28 openai._base_client DEBUG    request_id: req_5f94df2a27a1a0e7728a9c10adf8a9a8\n",
      "2024-07-30 15:38:28 src.functional INFO     ['Leonardo DiCaprio', 'Frank Abagnale Jr.'] <> Catch Me If You Can | predicted:  Catch Me If You Can - a movie where Leonardo DiCaprio played the role of Frank Abagnale Jr.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 114/119 [15:01<00:40,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:34 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Roger Federer and Rafael Nadal?\"\\nAnd the model gave the following answer:\\n\"rivalry - a famous tennis rivalry between Roger Federer and Rafael Nadal.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:34 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:34 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:34 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:34 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:34 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4672e07d0>\n",
      "2024-07-30 15:38:34 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:34 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe466db2810>\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995891'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_ce6935bf122495f8c9b56027d14ef1b2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cf4bbced8f6a-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:34 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:34 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:34 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '132', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995891', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_ce6935bf122495f8c9b56027d14ef1b2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cf4bbced8f6a-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:34 openai._base_client DEBUG    request_id: req_ce6935bf122495f8c9b56027d14ef1b2\n",
      "2024-07-30 15:38:34 src.functional INFO     ['Roger Federer', 'Rafael Nadal'] <> tennis | predicted:  rivalry - a famous tennis rivalry between Roger Federer and Rafael Nadal.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 115/119 [15:07<00:29,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:41 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Karch Kiraly and Giba?\"\\nAnd the model gave the following answer:\\n\"Volleyball - a sport where both players Karch Kiraly and Giba are known for.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:41 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:41 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:41 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:41 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:41 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe466db3350>\n",
      "2024-07-30 15:38:41 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:41 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe46672fd90>\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'173'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995892'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_86d70912492ed0b40d64d8c6532cbff2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cf7a4e504cdb-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:41 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:41 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:41 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '173', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995892', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_86d70912492ed0b40d64d8c6532cbff2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cf7a4e504cdb-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:41 openai._base_client DEBUG    request_id: req_86d70912492ed0b40d64d8c6532cbff2\n",
      "2024-07-30 15:38:41 src.functional INFO     ['Karch Kiraly', 'Giba'] <> volleyball | predicted:  Volleyball - a sport where both players Karch Kiraly and Giba are known for.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 116/119 [15:14<00:22,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:38:54 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Elbphilharmonie and Allianz Arena?\"\\nAnd the model gave the following answer:\\n\"Herzog & de Meuron - who were the architects of both buildings Elbphilharmonie and Allianz Arena.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:38:54 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:38:54 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:38:54 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:38:54 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:38:54 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe46671bd90>\n",
      "2024-07-30 15:38:54 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:38:54 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe466da4dd0>\n",
      "2024-07-30 15:38:54 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:54 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:38:54 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:54 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:38:54 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:55 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:38:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'778'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995885'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_bba569ccb8fc1e859d5e4f8d9141b8b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7cfc7fa504d10-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:38:55 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:38:55 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:38:55 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:38:55 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:38:55 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:38:55 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:38:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '778', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995885', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_bba569ccb8fc1e859d5e4f8d9141b8b0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7cfc7fa504d10-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:38:55 openai._base_client DEBUG    request_id: req_bba569ccb8fc1e859d5e4f8d9141b8b0\n",
      "2024-07-30 15:38:55 src.functional INFO     ['Elbphilharmonie', 'Allianz Arena'] <> Herzog & de Meuron | predicted:  Herzog & de Meuron - who were the architects of both buildings Elbphilharmonie and Allianz Arena.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 117/119 [15:27<00:18,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:39:04 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between 30 St Mary Axe (The Gherkin) and Hearst Tower?\"\\nAnd the model gave the following answer:\\n\"Norman Foster - who was the architect of both buildings 30 St Mary Axe (The Gherkin) and Hearst Tower.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:39:04 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:39:04 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:39:04 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:39:04 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:39:04 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe466da4dd0>\n",
      "2024-07-30 15:39:04 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:39:04 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe447912810>\n",
      "2024-07-30 15:39:04 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:04 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:39:04 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:04 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:39:04 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:06 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:39:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'1301'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995880'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_d2c427e1fcdfa1494105d4ad266ddf5e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7d009daa38fd9-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:39:06 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:39:06 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:06 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:39:06 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:39:06 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:39:06 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:39:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '1301', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995880', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_d2c427e1fcdfa1494105d4ad266ddf5e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7d009daa38fd9-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:39:06 openai._base_client DEBUG    request_id: req_d2c427e1fcdfa1494105d4ad266ddf5e\n",
      "2024-07-30 15:39:06 src.functional INFO     ['30 St Mary Axe (The Gherkin)', 'Hearst Tower'] <> Norman Foster | predicted:  Norman Foster - who was the architect of both buildings 30 St Mary Axe (The Gherkin) and Hearst Tower.\n",
      " => (✗)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 118/119 [15:38<00:09,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:39:11 openai._base_client DEBUG    Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '\\nA smaller language model was asked the following question:\\n\"What is a common link between Bradley Cooper and Chris Kyle?\"\\nAnd the model gave the following answer:\\n\"American Sniper - a movie where Bradley Cooper played the role of Chris Kyle.\"\\nIs it correct? Your answer should start with \"Yes\" or \"No\". If the answer is \"Yes\", don\\'t say anything else. If the answer is \"No\", give explanation why.\\n'}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0}}\n",
      "2024-07-30 15:39:11 openai._base_client DEBUG    Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2024-07-30 15:39:11 httpcore.connection DEBUG    close.started\n",
      "2024-07-30 15:39:11 httpcore.connection DEBUG    close.complete\n",
      "2024-07-30 15:39:11 httpcore.connection DEBUG    connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-07-30 15:39:11 httpcore.connection DEBUG    connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe447912810>\n",
      "2024-07-30 15:39:11 httpcore.connection DEBUG    start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe7b08eb1d0> server_hostname='api.openai.com' timeout=5.0\n",
      "2024-07-30 15:39:11 httpcore.connection DEBUG    start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe467d14a90>\n",
      "2024-07-30 15:39:11 httpcore.http11 DEBUG    send_request_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:11 httpcore.http11 DEBUG    send_request_headers.complete\n",
      "2024-07-30 15:39:11 httpcore.http11 DEBUG    send_request_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:11 httpcore.http11 DEBUG    send_request_body.complete\n",
      "2024-07-30 15:39:11 httpcore.http11 DEBUG    receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:12 httpcore.http11 DEBUG    receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 30 Jul 2024 19:39:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'bau-lab-1'), (b'openai-processing-ms', b'145'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'30000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'29995890'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2230a1ae53f74346fb115ce9156d49b2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ab7d035fda7901d-BOS'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-07-30 15:39:12 httpx INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-30 15:39:12 httpcore.http11 DEBUG    receive_response_body.started request=<Request [b'POST']>\n",
      "2024-07-30 15:39:12 httpcore.http11 DEBUG    receive_response_body.complete\n",
      "2024-07-30 15:39:12 httpcore.http11 DEBUG    response_closed.started\n",
      "2024-07-30 15:39:12 httpcore.http11 DEBUG    response_closed.complete\n",
      "2024-07-30 15:39:12 openai._base_client DEBUG    HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 30 Jul 2024 19:39:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'bau-lab-1', 'openai-processing-ms': '145', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '30000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '29995890', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2230a1ae53f74346fb115ce9156d49b2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ab7d035fda7901d-BOS', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2024-07-30 15:39:12 openai._base_client DEBUG    request_id: req_2230a1ae53f74346fb115ce9156d49b2\n",
      "2024-07-30 15:39:12 src.functional INFO     ['Bradley Cooper', 'Chris Kyle'] <> American Sniper | predicted:  American Sniper - a movie where Bradley Cooper played the role of Chris Kyle.\n",
      " => (✓)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [15:44<00:00,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:39:12 src.functional INFO     filtered 81 samples out of 119 with 4 icl examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.functional import filter_bridge_samples_by_model_knowledge\n",
    "\n",
    "dataset = filter_bridge_samples_by_model_knowledge(mt, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
