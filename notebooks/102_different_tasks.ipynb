{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc88b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa440433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 18:34:09 __main__ INFO     torch.__version__='2.7.0+cu126', torch.version.cuda='12.6'\n",
      "2025-09-09 18:34:09 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=8, torch.cuda.get_device_name()='NVIDIA A100 80GB PCIe'\n",
      "2025-09-09 18:34:09 __main__ INFO     transformers.__version__='4.55.3'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "##################################################################\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5,6,7\"\n",
    "##################################################################\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(\n",
    "    f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\"\n",
    ")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8766a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 18:34:12 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-09 18:34:12 git.cmd DEBUG    Popen(['git', 'version'], cwd=/disk/u/arnab/Codes/Projects/retrieval/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2025-09-09 18:34:12 wandb.docker.auth DEBUG    Trying paths: ['/disk/u/arnab/.docker/config.json', '/disk/u/arnab/.dockercfg']\n",
      "2025-09-09 18:34:12 wandb.docker.auth DEBUG    No config file found\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training_utils import get_device_map\n",
    "\n",
    "# model_key = \"meta-llama/Llama-3.2-3B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-8B\"\n",
    "# model_key = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "# model_key = \"meta-llama/Llama-3.1-405B-Instruct\"\n",
    "\n",
    "# model_key = \"google/gemma-2-9b-it\"\n",
    "# model_key = \"google/gemma-3-12b-it\"\n",
    "model_key = \"google/gemma-2-27b-it\"\n",
    "\n",
    "# model_key = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "# model_key = \"allenai/OLMo-2-1124-7B-Instruct\"\n",
    "# model_key = \"allenai/OLMo-7B-0424-hf\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen2-7B\"\n",
    "# model_key = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "# model_key = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "\n",
    "# model_key = \"Qwen/Qwen3-1.7B\"\n",
    "# model_key = \"Qwen/Qwen3-4B\"\n",
    "# model_key = \"Qwen/Qwen3-8B\"\n",
    "# model_key = \"Qwen/Qwen3-14B\"\n",
    "# model_key = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "# device_map = get_device_map(model_key, 30, n_gpus=8)\n",
    "# device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310827ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 18:34:13 src.models WARNING  google/gemma-2-27b-it not found in /disk/u/arnab/Codes/Models\n",
      "If not found in cache, model will be downloaded from HuggingFace to cache directory\n",
      "2025-09-09 18:34:13 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 18:34:13 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /google/gemma-2-27b-it/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2025-09-09 18:34:13 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /google/gemma-2-27b-it/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2025-09-09 18:34:13 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/models/google/gemma-2-27b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367b2535bef4428cb67ed0f1f3c794a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 18:34:33 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /google/gemma-2-27b-it/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "2025-09-09 18:34:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /google/gemma-2-27b-it/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n",
      "2025-09-09 18:34:34 src.models INFO     loaded model <google/gemma-2-27b-it> | size: 51931.626 MB | dtype: torch.bfloat16 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_key,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=device_map,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True\n",
    "    #     load_in_8bit=True\n",
    "    # )\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17359f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountingTask: (different objects)\n",
      "Categories: fruit(15), vehicle(15), furniture(15), animal(15), music instrument(15), clothing(15), electronics(15), sport equipment(15), kitchen appliance(15), vegetable(14), building(15), office supply(15), bathroom item(15), flower(15), tree(15), jewelry(15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import SelectOneTask, CountingTask, YesNoTask, SelectFirstTask\n",
    "from src.selection.data import SelectionSample, CountingSample, YesNoSample\n",
    "\n",
    "#################################################################################\n",
    "# TASK_CLS = SelectOneTask\n",
    "TASK_CLS = CountingTask\n",
    "prompt_template_idx = 0\n",
    "N_DISTRACTORS = 5\n",
    "OPTION_STYLE = \"single_line\"\n",
    "#################################################################################\n",
    "\n",
    "select_task = TASK_CLS.load(\n",
    "    path=os.path.join(\n",
    "        env_utils.DEFAULT_DATA_DIR, \n",
    "        \"selection\", \n",
    "        # \"profession.json\"\n",
    "        # \"nationality.json\"\n",
    "        \"objects.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(select_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f921352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Items: Airplane, Necklace, Jacket, Boxing gloves, Tractor, Ambulance, Truck\n",
      "How many vehicles are in this list?\n",
      "Answer:\" >> 4\n",
      "[' 4\\n\\nExplanation:\\n\\nThe vehicles in the']\n"
     ]
    }
   ],
   "source": [
    "from src.functional import predict_next_token, generate_with_patch\n",
    "\n",
    "sample = select_task.get_random_sample(\n",
    "    mt=mt, \n",
    "    category=\"vehicle\",\n",
    "    filter_by_lm_prediction=True,\n",
    "    prompt_template_idx=1,\n",
    "    n_count=4,\n",
    "    n_distractors=3,\n",
    ")\n",
    "print(f'\"{sample.prompt()}\" >> {sample.count}')\n",
    "\n",
    "gen = generate_with_patch(\n",
    "    mt=mt, \n",
    "    inputs=sample.prompt(),\n",
    "    n_gen_per_prompt=1,\n",
    "    remove_prefix=True,\n",
    "    max_new_tokens=10,\n",
    "    do_sample=False,\n",
    ")\n",
    "print(gen) # expect sample.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764d792e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(11016,\n",
       "              (12,\n",
       "               PredictedToken(token=' Four', prob=5.3882598876953125e-05, logit=13.0625, token_id=11016, metadata=None))),\n",
       "             (18457,\n",
       "              (18,\n",
       "               PredictedToken(token=' Five', prob=1.7523765563964844e-05, logit=11.9375, token_id=18457, metadata=None))),\n",
       "             (11176,\n",
       "              (52,\n",
       "               PredictedToken(token=' Three', prob=1.6242265701293945e-06, logit=9.5625, token_id=11176, metadata=None))),\n",
       "             (16544,\n",
       "              (74,\n",
       "               PredictedToken(token=' Six', prob=7.674098014831543e-07, logit=8.8125, token_id=16544, metadata=None))),\n",
       "             (7020,\n",
       "              (110,\n",
       "               PredictedToken(token=' Two', prob=3.110617399215698e-07, logit=7.90625, token_id=7020, metadata=None))),\n",
       "             (3428,\n",
       "              (182,\n",
       "               PredictedToken(token=' One', prob=1.1781230568885803e-07, logit=6.9375, token_id=3428, metadata=None))),\n",
       "             (21117,\n",
       "              (234,\n",
       "               PredictedToken(token=' Seven', prob=7.59027898311615e-08, logit=6.5, token_id=21117, metadata=None))),\n",
       "             (44213,\n",
       "              (911,\n",
       "               PredictedToken(token=' Eight', prob=9.371433407068253e-09, logit=4.40625, token_id=44213, metadata=None))),\n",
       "             (25444,\n",
       "              (1673,\n",
       "               PredictedToken(token=' Zero', prob=4.3655745685100555e-09, logit=3.640625, token_id=25444, metadata=None))),\n",
       "             (32687,\n",
       "              (1720,\n",
       "               PredictedToken(token=' Nine', prob=4.220055416226387e-09, logit=3.609375, token_id=32687, metadata=None))),\n",
       "             (11169,\n",
       "              (4272,\n",
       "               PredictedToken(token=' Ten', prob=1.4624674804508686e-09, logit=2.546875, token_id=11169, metadata=None)))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28c38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d0e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_options=['Mango', 'Watermelon', 'Orange', 'Car', 'Grape']\n",
      "patch_options=['Kiwi', 'Banana', 'Peach', 'Pear', 'Tractor']\n",
      "clean_category='vehicle'\n",
      "patch_category='fruit'\n",
      "clean_options=['Mango', 'Watermelon', 'Orange', 'Car', 'Grape']\n",
      "patch_options=['Kiwi', 'Banana', 'Peach', 'Pear', 'Tractor']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Items: Kiwi, Banana, Peach, Pear, Tractor\n",
      "How many fruits are in this list?\n",
      "Answer: >> 4\n",
      "Items: Mango, Watermelon, Orange, Car, Grape\n",
      "How many vehicles are in this list?\n",
      "Answer: >> 1\n"
     ]
    }
   ],
   "source": [
    "from src.selection.data import get_counterfactual_samples_interface\n",
    "\n",
    "counterfactual_sampler = get_counterfactual_samples_interface[select_task.task_name]\n",
    "\n",
    "patch_sample, clean_sample = counterfactual_sampler(\n",
    "    mt=mt,\n",
    "    task=select_task,\n",
    "    patch_category=\"fruit\",\n",
    "    clean_category=\"vehicle\",\n",
    "    filter_by_lm_prediction=False,\n",
    "    prompt_template_idx=1,\n",
    "    option_style=OPTION_STYLE,\n",
    "    distinct_options=True,\n",
    "    n_options=5\n",
    ")\n",
    "\n",
    "# patch_sample.default_option_style = \"single_line\"\n",
    "# clean_sample.default_option_style = \"numbered\"\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(patch_sample.prompt(), \">>\", patch_sample.count)\n",
    "print(clean_sample.prompt(), \">>\", clean_sample.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ebee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "connection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
